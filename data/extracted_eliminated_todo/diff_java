public class handler implements pagehandler < context > { <nl> model . setcodes ( m_appconfigmanager . queryinternalcodes ( commandid ) ) ; <nl> break ; <nl> case statistics : <nl> - / / appreport report = queryappreport ( payload ) ; <nl> - string xml = files . forio ( ) . readfrom ( new fileinputstream ( " / users / jialinsun / downloads / appreport . xml " ) , " utf - 8 " ) ; <nl> - appreport report = null ; <nl> - try { <nl> - report = defaultsaxparser . parse ( xml ) ; <nl> - } catch ( saxexception e ) { <nl> - <nl> - e . printstacktrace ( ) ; <nl> - } <nl> + appreport report = queryappreport ( payload ) ; <nl> displaycommands displaycommands = builddisplaycommands ( report , payload . getsort ( ) ) ; <nl> - <nl> + <nl> model . setdisplaycommands ( displaycommands ) ; <nl> model . setappreport ( report ) ; <nl> model . setcodedistributions ( buildcodedistributions ( displaycommands ) ) ;
public class transactionanalyzer extends abstractmessageanalyzer < transactionrepo <nl> protected void processtransaction ( transactionreport report , messagetree tree , transaction t ) { <nl> if ( m_serverconfigmanager . discardtransaction ( t ) ) { <nl> return ; <nl> - <nl> } else if ( " abtest " . equals ( t . gettype ( ) ) ) { <nl> return ; <nl> } else { <nl> mmm a / cat - core / src / main / java / com / dianping / cat / serverconfigmanager . java <nl> ppp b / cat - core / src / main / java / com / dianping / cat / serverconfigmanager . java <nl>
public class exceptionalert implements task , logenabled { <nl> } <nl> transaction t = cat . newtransaction ( " exceptionalert " , " m " + minutestr ) ; <nl> long current = system . currenttimemillis ( ) ; <nl> - try { <nl> - system . out . println ( m_projectdao . findall ( projectentity . readset_full ) ) ; <nl> - } catch ( dalexception e1 ) { <nl> - <nl> - e1 . printstacktrace ( ) ; <nl> - } <nl> try { <nl> topmetric topmetric = buildtopmetric ( new date ( current - timeutil . one_minute * num ) ) ; <nl> collection < list < item > > items = topmetric . geterror ( ) . getresult ( ) . values ( ) ;
public class transactionanalyzer extends abstractmessageanalyzer < transactionrepo <nl>  <nl> if ( message instanceof transaction ) { <nl> transaction root = ( transaction ) message ; <nl> - <nl> - <nl> - string type = message . gettype ( ) ; <nl>  <nl> - if ( ! " abtest " . equals ( type ) ) { <nl> - processtransaction ( report , tree , root ) ; <nl> - } <nl> + processtransaction ( report , tree , root ) ; <nl> } <nl> } <nl>  <nl>
public class topanalyzer extends abstractmessageanalyzer < topreport > implements l <nl>  <nl> @ override <nl> public synchronized topreport getreport ( string domain ) { <nl> - <nl> set < string > domains = m_transactionanalyzer . getdomains ( ) ; <nl> - topreport topreport = new topreport ( " cat " ) ; <nl> + topreport topreport = new topreport ( reportconstants . cat ) ; <nl>  <nl> topreport . setstarttime ( new date ( m_starttime ) ) ; <nl> topreport . setendtime ( new date ( m_starttime + num * minute - num ) ) ; <nl> for ( string domainname : domains ) { <nl> - if ( validate ( domainname ) ) { <nl> + if ( validate ( domainname ) & & ! domainname . equals ( reportconstants . all ) ) { <nl> transactionreport report = m_transactionanalyzer . getreport ( domainname ) ; <nl>  <nl> new transactionreportvisitor ( topreport ) . visittransactionreport ( report ) ; <nl> } <nl> } <nl> for ( string domainname : domains ) { <nl> - if ( validate ( domainname ) ) { <nl> + if ( validate ( domainname ) & & ! domainname . equals ( reportconstants . all ) ) { <nl> problemreport report = m_problemanalyzer . getreport ( domainname ) ; <nl>  <nl> new problemreportvisitor ( topreport ) . visitproblemreport ( report ) ;
public class transactionanalyzer extends abstractmessageanalyzer < transactionrepo <nl> m_logger = logger ; <nl> } <nl>  <nl> - <nl> public set < string > getdomains ( ) { <nl> return m_reports . keyset ( ) ; <nl> } <nl> mmm a / cat - consumer / src / main / java / com / dianping / cat / consumer / transaction / transactionreportmerger . java <nl> ppp b / cat - consumer / src / main / java / com / dianping / cat / consumer / transaction / transactionreportmerger . java <nl>
<nl> - . jpaginate { <nl> - height : 34px ; <nl> - position : relative ; <nl> - color : # a5a5a5 ; <nl> - font - size : small ; <nl> - width : 100 % ; <nl> - } <nl> - . jpaginate a { <nl> - line - height : 15px ; <nl> - height : 18px ; <nl> - cursor : pointer ; <nl> - padding : 2px num px ; <nl> - margin : 2px ; <nl> - float : left ; <nl> - } <nl> - <nl> - . jpag - control - back { <nl> - position : absolute ; <nl> - left : 0px ; <nl> - } <nl> - . jpag - control - front { <nl> - position : absolute ; <nl> - top : 0px ; <nl> - } <nl> - . jpaginate span { <nl> - cursor : pointer ; <nl> - } <nl> - <nl> - <nl> - . tasktable { <nl> - table - layout : fixed <nl> - } <nl> - . tasktable td { text - overflow : ellipsis ; overflow : hidden ; white - space : nowrap ; padding : 2px } <nl> - <nl> - . class1 { <nl> - background - image : url ( . . / images / <nl> - } <nl> - . class2 { <nl> - background - image : url ( . . / images / doing . png ) ; <nl> - } <nl> - . class3 { <nl> - background - image : url ( . . / images / done . jpg ) ; <nl> - } <nl> - . class4 { <nl> - background - image : url ( . . / images / failure . png ) ; <nl> - } <nl> - <nl> - ul . jpag - pages { <nl> - float : left ; <nl> - list - style - type : none ; <nl> - margin : 0px num px num px num px ; <nl> - padding : 0px ; <nl> - } <nl> - ul . jpag - pages li { <nl> - display : inline ; <nl> - float : left ; <nl> - padding : 0px ; <nl> - margin : 0px ; <nl> - } <nl> - ul . jpag - pages li a { <nl> - float : left ; <nl> - padding : 2px num px ; <nl> - } <nl> - <nl> - span . jpag - current { <nl> - cursor : default ; <nl> - font - weight : normal ; <nl> - line - height : 15px ; <nl> - height : 18px ; <nl> - padding : 2px num px ; <nl> - margin : 2px ; <nl> - float : left ; <nl> - } <nl> - ul . jpag - pages li span . jpag - previous , <nl> - ul . jpag - pages li span . jpag - next , <nl> - span . jpag - sprevious , <nl> - span . jpag - snext , <nl> - ul . jpag - pages li span . jpag - previous - img , <nl> - ul . jpag - pages li span . jpag - next - img , <nl> - span . jpag - sprevious - img , <nl> - span . jpag - snext - img { <nl> - height : 22px ; <nl> - margin : 2px ; <nl> - float : left ; <nl> - line - height : 18px ; <nl> - } <nl> - <nl> - ul . jpag - pages li span . jpag - previous , <nl> - ul . jpag - pages li span . jpag - previous - img { <nl> - margin : 2px num px num px num px ; <nl> - font - size : 12px ; <nl> - font - weight : bold ; <nl> - width : 10px ; <nl> - <nl> - } <nl> - ul . jpag - pages li span . jpag - next , <nl> - ul . jpag - pages li span . jpag - next - img { <nl> - margin : 2px num px num px num px ; <nl> - font - size : 12px ; <nl> - font - weight : bold ; <nl> - width : 10px ; <nl> - } <nl> - span . jpag - sprevious , <nl> - span . jpag - sprevious - img { <nl> - margin : 2px num px num px num px ; <nl> - font - size : 18px ; <nl> - width : 15px ; <nl> - text - align : right ; <nl> - } <nl> - span . jpag - snext , <nl> - span . jpag - snext - img { <nl> - margin : 2px num px num px num px ; <nl> - font - size : 18px ; <nl> - width : 15px ; <nl> - text - align : right ; <nl> - } <nl> - ul . jpag - pages li span . jpag - previous - img { <nl> - background : transparent url ( . . / images / previous . png ) no - repeat center right ; <nl> - } <nl> - ul . jpag - pages li span . jpag - next - img { <nl> - background : transparent url ( . . / images / next . png ) no - repeat center left ; <nl> - } <nl> - span . jpag - sprevious - img { <nl> - background : transparent url ( . . / images / sprevious . png ) no - repeat center right ; <nl> - } <nl> - span . jpag - snext - img { <nl> - background : transparent url ( . . / images / snext . png ) no - repeat center left ; <nl> - } <nl> - <nl> - . content { <nl> - margin - top : 100px ; <nl> - padding : 0px ; <nl> - bottom : 0px ; <nl> - } <nl> - . demo { <nl> - width : 580px ; <nl> - padding : 10px ; <nl> - margin : 10px auto ; <nl> - border : num px solid # fff ; <nl> - background - color : # f7f7f7 ; <nl> - } <nl> -
public class subscriberdaotest extends basetest { <nl> subscriber . getaddress ( ) ; <nl> } <nl> } catch ( exception e ) { <nl> - <nl> e . printstacktrace ( ) ; <nl> } <nl> } <nl> - <nl> }
public class remotemessagebucket implements bucket < messagetree > , logenabled { <nl>  <nl> @ override <nl> public void initialize ( class < ? > type , string name , date timestamp ) throws ioexception { <nl> - string ipaddress = inetaddress . getlocalhost ( ) . gethostaddress ( ) ; <nl> + string ipaddress = localip . getaddress ( ) ; <nl> string logicalpath = m_pathbuilder . getmessagepath ( name , timestamp ) ; <nl> - <nl> - <nl> m_path = logicalpath + " - " + ipaddress + " - " + system . currenttimemillis ( ) ; <nl> m_outputchannel = m_outputchannelmanager . openchannel ( m_path , false ) ; <nl> } <nl> mmm a / cat - job / src / main / java / com / dianping / cat / job / storage / remotestringbucket . java <nl> ppp b / cat - job / src / main / java / com / dianping / cat / job / storage / remotestringbucket . java <nl>
public class defaultoutputchannelmanager extends containerholder implements outp <nl> filesystem fs ; <nl>  <nl> config . setint ( " io . file . buffer . size " , num ) ; <nl> - <nl> if ( m_serveruri = = null ) { <nl> fs = filesystem . getlocal ( config ) ; <nl> + m_basepath = new path ( fs . getworkingdirectory ( ) , m_basedir ) ; <nl> } else { <nl> - fs = filesystem . get ( m_serveruri , config ) ; <nl> + fs = filesystem . get ( m_serveruri , config ) ; <nl> + m_basepath = new path ( new path ( m_serveruri ) , m_basedir ) ; <nl> } <nl>  <nl> m_fs = fs ; <nl> - m_basepath = new path ( m_fs . getworkingdirectory ( ) , m_basedir ) ; <nl> } catch ( exception e ) { <nl> throw new initializationexception ( " error when getting hdfs file system . " , e ) ; <nl> }
public class manyanalyzertest extends componenttestcase { <nl> protected void store ( list < analyzerresult > result ) { <nl> } <nl>  <nl> - @ override <nl> - public analyzerresult generate ( string domain ) { <nl> - <nl> - return null ; <nl> - } <nl> } <nl>  <nl> public static class mockanalyzer2 extends <nl>
public class manyanalyzertest extends componenttestcase { <nl> protected void store ( list < analyzerresult > result ) { <nl> } <nl>  <nl> - @ override <nl> - public analyzerresult generate ( string domain ) { <nl> - <nl> - return null ; <nl> - } <nl> } <nl>  <nl> public static class mockanalyzer3 extends <nl>
public class manyanalyzertest extends componenttestcase { <nl> protected void store ( list < analyzerresult > result ) { <nl> } <nl>  <nl> - @ override <nl> - public analyzerresult generate ( string domain ) { <nl> - <nl> - return null ; <nl> - } <nl> } <nl>  <nl> public static class analyzerresult { <nl> mmm a / cat - consumer / src / test / java / com / dianping / cat / consumer / oneanalyzertwodurationtest . java <nl> ppp b / cat - consumer / src / test / java / com / dianping / cat / consumer / oneanalyzertwodurationtest . java <nl>
public class oneanalyzertwodurationtest extends componenttestcase { <nl> protected void store ( list < analyzerresult > result ) { <nl> } <nl>  <nl> - @ override <nl> - public analyzerresult generate ( string domain ) { <nl> - <nl> - return null ; <nl> - } <nl> } <nl>  <nl> public static class analyzerresult { <nl> mmm a / cat - core / src / main / java / com / dianping / cat / message / spi / abstractmessageanalyzer . java <nl> ppp b / cat - core / src / main / java / com / dianping / cat / message / spi / abstractmessageanalyzer . java <nl>
public class appcontroller { <nl> } catch ( nullpointerexception e ) { <nl> model . addattribute ( " authorized " , false ) ; <nl> } catch ( exception e ) { <nl> - <nl> + logger . error ( e ) ; <nl> } <nl>  <nl> return " app / base " ; <nl>
public class appcontroller { <nl> model . addattribute ( " authorized " , true ) ; <nl> model . addattribute ( " demo " , true ) ; <nl> } catch ( exception e ) { <nl> - <nl> + logger . error ( e ) ; <nl> } <nl>  <nl> return " app / base " ; <nl> mmm a / src / main / webapp / web - inf / web . xml <nl> ppp b / src / main / webapp / web - inf / web . xml <nl>
public final class logsqlparseresultreporter implements sqlparseresultreporter { <nl>  <nl> @ override <nl> public void printresult ( final string sqlcaseid , final string databasetype , final boolean issuccess , final string sql ) { <nl> - <nl> - log . info ( " printing the sql parser process result " ) ; <nl> + if ( ! issuccess ) { <nl> + log . warn ( " sql parse failed . sql case id is : { } , database type is : { } , sql is : { } " , sqlcaseid , databasetype , sql ) ; <nl> + } <nl> } <nl> }
<nl> < artifactid > shardingsphere - infra - datetime - spi < / artifactid > <nl> < version > $ { project . version } < / version > <nl> < / dependency > <nl> - < ! - - <nl> - < dependency > <nl> - < groupid > org . apache . shardingsphere < / groupid > <nl> - < artifactid > shardingsphere - sharding - core < / artifactid > <nl> - < version > $ { project . version } < / version > <nl> - < / dependency > <nl>  <nl> < dependency > <nl> < groupid > org . apache . shardingsphere < / groupid >
public final class csvresultgenerator { <nl> public void processresult ( final object . . . params ) { <nl> try { <nl> printer . printrecord ( params ) ; <nl> - <nl> printer . flush ( ) ; <nl> } catch ( final ioexception ex ) { <nl> throw new runtimeexception ( " write csv file failed . " , ex ) ; <nl> mmm a / test / integration - test / sql - parser / src / test / resources / env / it - env . properties <nl> ppp b / test / integration - test / sql - parser / src / test / resources / env / it - env . properties <nl>
the following code of conduct is based on full compliance with [ asf code of cond <nl> - include javadoc , <nl> - only ` public ` classes and methods need javadoc , other methods , classes and override methods do not need javadoc . <nl> - conditional operator ( < expression1 > ? < expression2 > : < expression3 > ) ` nested use ` is forbidden . <nl> + - avoid using java stream in hot methods , unless the performance of using stream is better than using loop in that situation . <nl>  <nl> # # contributor covenant unit test of conduct
public final class postgresqlcontainer extends dockerstoragecontainer { <nl>  <nl> @ override <nl> protected void configure ( ) { <nl> - withcommand ( " - - max_connections = 600 " ) ; <nl> - <nl> - / / withcommand ( " - - wal_level = logical " ) ; <nl> + withcommand ( " - - max_connections = 600 " , " - - wal_level = logical " ) ; <nl> addenv ( " postgres_user " , " root " ) ; <nl> addenv ( " postgres_password " , " root " ) ; <nl> withexposedports ( getport ( ) ) ;
public final class scalingregistrysubscribertest { <nl>  <nl> @ mock <nl> private metadataversionpersistservice metadataversionpersistservice ; <nl> + <nl> + @ mock <nl> + private eventbuscontext eventbuscontext ; <nl> + <nl> + private scalingregistrysubscriber scalingregistrysubscriber ; <nl>  <nl> @ before <nl> public void setup ( ) throws reflectiveoperationexception { <nl> - scalingregistrysubscriber scalingregistrysubscriber = new scalingregistrysubscriber ( repository , new eventbuscontext ( ) ) ; <nl> + scalingregistrysubscriber = new scalingregistrysubscriber ( repository , eventbuscontext ) ; <nl> field persistservicefield = scalingregistrysubscriber . class . getdeclaredfield ( " metadataversionpersistservice " ) ; <nl> persistservicefield . setaccessible ( true ) ; <nl> persistservicefield . set ( scalingregistrysubscriber , metadataversionpersistservice ) ; <nl> } <nl> - <nl> + <nl> + @ test <nl> + public void assertstartscaling ( ) { <nl> + verify ( eventbuscontext ) . register ( scalingregistrysubscriber ) ; <nl> + when ( metadataversionpersistservice . getactiveversion ( " ds_0 " ) ) . thenreturn ( optional . of ( " 1 " ) ) ; <nl> + when ( repository . get ( any ( ) ) ) . thenreturn ( " " ) ; <nl> + scalingregistrysubscriber . startscaling ( new metadataversionpreparedevent ( " 2 " , " ds_0 " ) ) ; <nl> + startscalingevent startscalingevent = new startscalingevent ( " ds_0 " , " " , " " , " " , " " , num , num ) ; <nl> + verify ( eventbuscontext ) . post ( argumentmatchers . refeq ( startscalingevent ) ) ; <nl> + } <nl> + <nl> @ test <nl> - public void assertcacheruleconfiguration ( ) { <nl> - <nl> + public void assertscalingtaskfinished ( ) { <nl> + when ( metadataversionpersistservice . getactiveversion ( " ds_0 " ) ) . thenreturn ( optional . of ( " 1 " ) ) ; <nl> + scalingregistrysubscriber . scalingtaskfinished ( new scalingtaskfinishedevent ( " ds_0 " , num , num ) ) ; <nl> + verify ( metadataversionpersistservice ) . persistactiveversion ( " ds_0 " , " 2 " ) ; <nl> + verify ( metadataversionpersistservice ) . deleteversion ( " ds_0 " , " 1 " ) ; <nl> } <nl> }
public final class standaloneworkeridgenerator implements workeridgenerator { <nl> return default_worker_id ; <nl> } <nl> object workerid = props . get ( worker_id_key ) ; <nl> - <nl> - return null = = workerid ? default_worker_id : long . parselong ( workerid . tostring ( ) ) ; <nl> + if ( null = = workerid ) { <nl> + return default_worker_id ; <nl> + } <nl> + long result = long . parselong ( workerid . tostring ( ) ) ; <nl> + preconditions . checkstate ( result < = max_worker_id , " % s can not exceed % s " , worker_id_key , max_worker_id ) ; <nl> + return result ; <nl> } <nl> } <nl> mmm a / shardingsphere - mode / shardingsphere - mode - type / shardingsphere - standalone - mode / shardingsphere - standalone - mode - core / src / test / java / org / apache / shardingsphere / mode / manager / standalone / workerid / generator / standaloneworkeridgeneratortest . java <nl> ppp b / shardingsphere - mode / shardingsphere - mode - type / shardingsphere - standalone - mode / shardingsphere - standalone - mode - core / src / test / java / org / apache / shardingsphere / mode / manager / standalone / workerid / generator / standaloneworkeridgeneratortest . java <nl>
public final class computenodestatusservicetest { <nl> when ( repository . get ( " / nodes / compute_nodes / online / proxy / foo_instance_3308 " ) ) . thenreturn ( " 127 . 0 . 0 . 1 @ 3308 " ) ; <nl> list < computenodeinstance > actual = new arraylist < > ( new computenodestatusservice ( repository ) . loadallcomputenodeinstances ( ) ) ; <nl> assertthat ( actual . size ( ) , is ( 2 ) ) ; <nl> - <nl> + assertthat ( actual . get ( 0 ) . getinstancemetadata ( ) . getid ( ) , is ( " foo_instance_3307 " ) ) ; <nl> + assertthat ( actual . get ( 0 ) . getinstancemetadata ( ) . getip ( ) , is ( iputils . getip ( ) ) ) ; <nl> + assertthat ( actual . get ( 1 ) . getinstancemetadata ( ) . getid ( ) , is ( " foo_instance_3308 " ) ) ; <nl> + assertthat ( actual . get ( 1 ) . getinstancemetadata ( ) . getip ( ) , is ( " 127 . 0 . 0 . 1 " ) ) ; <nl> + assertthat ( actual . get ( 1 ) . getinstancemetadata ( ) . gettype ( ) , is ( instancetype . proxy ) ) ; <nl> + assertthat ( ( ( proxyinstancemetadata ) actual . get ( 1 ) . getinstancemetadata ( ) ) . getport ( ) , is ( 3308 ) ) ; <nl> } <nl>  <nl> @ test
public class assistqueryandplaininsertcolumnstokengeneratortest { <nl> tokengenerator . setencryptrule ( mockencryptrule ( ) ) ; <nl> collection < insertcolumnstoken > actual = tokengenerator . generatesqltokens ( mockinsertstatementcontext ( ) ) ; <nl> assertthat ( actual . size ( ) , is ( 1 ) ) ; <nl> - <nl> + <nl> + insertstatementcontext insertstatementcontext = mock ( insertstatementcontext . class , returns_deep_stubs ) ; <nl> + when ( insertstatementcontext . getsqlstatement ( ) . gettable ( ) . gettablename ( ) . getidentifier ( ) . getvalue ( ) ) . thenreturn ( " foo_tbl " ) ; <nl> + actual = tokengenerator . generatesqltokens ( insertstatementcontext ) ; <nl> + assertthat ( actual . size ( ) , is ( 0 ) ) ; <nl> + <nl> + columnsegment columnsegment = mock ( columnsegment . class , returns_deep_stubs ) ; <nl> + when ( columnsegment . getidentifier ( ) . getvalue ( ) ) . thenreturn ( " bar_col " ) ; <nl> + when ( insertstatementcontext . getsqlstatement ( ) . getcolumns ( ) ) . thenreturn ( collections . singleton ( columnsegment ) ) ; <nl> + actual = tokengenerator . generatesqltokens ( insertstatementcontext ) ; <nl> + assertthat ( actual . size ( ) , is ( 0 ) ) ; <nl> } <nl>  <nl> private encryptrule mockencryptrule ( ) {
public final class mysqladminexecutorcreator implements databaseadminexecutorcre <nl>  <nl> private databaseadminexecutor mockexecutor ( final string schemaname , final selectstatement sqlstatement , final string sql ) { <nl> boolean isnotuseschema = ! optional . ofnullable ( schemaname ) . ispresent ( ) & & sqlstatement . getfrom ( ) = = null ; <nl> + if ( ! hasdatabases ( ) | | ! hasresources ( ) ) { <nl> + return new noresourceshowexecutor ( sqlstatement ) ; <nl> + } <nl> + string drivertype = proxycontext . getinstance ( ) . getcontextmanager ( ) . getmetadatacontexts ( ) . getprops ( ) . getvalue ( configurationpropertykey . proxy_backend_driver_type ) ; <nl> if ( isnotuseschema ) { <nl> - if ( ! hasdatabases ( ) | | ! hasresources ( ) ) { <nl> - return new noresourceshowexecutor ( sqlstatement ) ; <nl> - } else { <nl> - <nl> - string drivertype = proxycontext . getinstance ( ) . getcontextmanager ( ) . getmetadatacontexts ( ) . getprops ( ) . getvalue ( configurationpropertykey . proxy_backend_driver_type ) ; <nl> - return " experimentalvertx " . equals ( drivertype ) ? null : new unicastresourceshowexecutor ( sqlstatement , sql ) ; <nl> - } <nl> + return " experimentalvertx " . equals ( drivertype ) ? null : new unicastresourceshowexecutor ( sqlstatement , sql ) ; <nl> } <nl> return null ; <nl> }
public final class shadownondmlstatementroutingenginetest { <nl>  <nl> @ test <nl> public void assertroute ( ) { <nl> - shadowrouteengine . route ( createroutecontext ( ) , new shadowrule ( createalgorithmprovidedshadowruleconfiguration ( ) ) ) ; <nl> - <nl> + routecontext routecontext = createroutecontext ( ) ; <nl> + shadowrouteengine . route ( routecontext , new shadowrule ( createalgorithmprovidedshadowruleconfiguration ( ) ) ) ; <nl> + collection < routeunit > routeunits = routecontext . getrouteunits ( ) ; <nl> + routemapper datasourcemapper = routeunits . iterator ( ) . next ( ) . getdatasourcemapper ( ) ; <nl> + assertthat ( datasourcemapper . getlogicname ( ) , is ( " logic_db " ) ) ; <nl> + assertthat ( datasourcemapper . getactualname ( ) , is ( " ds_shadow " ) ) ; <nl> } <nl>  <nl> private routecontext createroutecontext ( ) { <nl> - routecontext result = mock ( routecontext . class ) ; <nl> - when ( result . getrouteunits ( ) ) . thenreturn ( <nl> - collections . singleton ( new routeunit ( new routemapper ( " ds " , " ds " ) , collections . singleton ( new routemapper ( " t_order " , " t_order " ) ) ) ) ) ; <nl> + routecontext result = new routecontext ( ) ; <nl> + collection < routeunit > routeunits = result . getrouteunits ( ) ; <nl> + routeunits . add ( createrouteunit ( ) ) ; <nl> return result ; <nl> } <nl>  <nl> + private routeunit createrouteunit ( ) { <nl> + return new routeunit ( new routemapper ( " logic_db " , " shadow - data - source " ) , collections . singleton ( new routemapper ( " t_order " , " t_order " ) ) ) ; <nl> + } <nl> + <nl> private algorithmprovidedshadowruleconfiguration createalgorithmprovidedshadowruleconfiguration ( ) { <nl> algorithmprovidedshadowruleconfiguration result = new algorithmprovidedshadowruleconfiguration ( ) ; <nl> result . setdatasources ( collections . singletonmap ( " shadow - data - source " , new shadowdatasourceconfiguration ( " ds " , " ds_shadow " ) ) ) ;
import org . apache . shardingsphere . shadow . api . shadow . hint . hintshadowalgorithm ; <nl> import org . apache . shardingsphere . shadow . api . shadow . hint . precisehintshadowvalue ; <nl>  <nl> import java . util . collection ; <nl> - import java . util . objects ; <nl> + import java . util . hashmap ; <nl> + import java . util . map ; <nl> + import java . util . map . entry ; <nl> import java . util . properties ; <nl> + import java . util . set ; <nl>  <nl> / * * <nl> * simple hint shadow algorithm . <nl> * / <nl> public final class simplehintshadowalgorithm implements hintshadowalgorithm < string > { <nl>  <nl> - <nl> @ getter <nl> @ setter <nl> private properties props ; <nl>  <nl> + private map < string , string > simplehint ; <nl> + <nl> @ override <nl> public void init ( final properties props ) { <nl> checkpropssize ( props ) ; <nl> - this . props = props ; <nl> + simplehint = initsimplehint ( props ) ; <nl> + } <nl> + <nl> + private map < string , string > initsimplehint ( final properties props ) { <nl> + map < string , string > result = new hashmap < > ( props . size ( ) , num . 0f ) ; <nl> + set < string > strings = props . stringpropertynames ( ) ; <nl> + for ( string each : strings ) { <nl> + result . put ( each , props . getproperty ( each ) ) ; <nl> + } <nl> + return result ; <nl> } <nl>  <nl> private void checkpropssize ( final properties props ) { <nl>
public interface examplegenerator { <nl> string resources_path = " src / main / resources " ; <nl>  <nl> default void generate ( final configuration templateconfig , final yamlexampleconfiguration configuration ) throws ioexception , templateexception { <nl> - for ( string eachframework : configuration . getframeworks ( ) ) { <nl> - for ( string eachfeature : generateutil . generatecombination ( configuration . getfeatures ( ) ) ) { <nl> - generate ( templateconfig , builddatamodel ( configuration , eachframework , eachfeature ) , eachframework , eachfeature ) ; <nl> + for ( string eachmode : configuration . getmodes ( ) ) { <nl> + for ( string eachtransaction : configuration . gettransactions ( ) ) { <nl> + for ( string eachframework : configuration . getframeworks ( ) ) { <nl> + for ( string eachfeature : generateutil . generatecombination ( configuration . getfeatures ( ) ) ) { <nl> + generate ( templateconfig , builddatamodel ( configuration . getprops ( ) , eachmode , eachtransaction , eachframework , eachfeature ) , eachframework , eachfeature ) ; <nl> + } <nl> + } <nl> } <nl> } <nl> } <nl> - <nl> - default map < string , string > builddatamodel ( final yamlexampleconfiguration configuration , final string framework , final string feature ) { <nl> + <nl> + default map < string , string > builddatamodel ( final properties props , final string mode , final string transaction , final string framework , final string feature ) { <nl> map < string , string > result = new linkedhashmap < > ( ) ; <nl> - configuration . getprops ( ) . foreach ( ( key , value ) - > result . put ( key . tostring ( ) , value . tostring ( ) ) ) ; <nl> + props . foreach ( ( key , value ) - > result . put ( key . tostring ( ) , value . tostring ( ) ) ) ; <nl> result . put ( " product " , gettype ( ) ) ; <nl> - <nl> - result . put ( " mode " , configuration . getmodes ( ) . size ( ) > num ? configuration . getmodes ( ) . get ( 0 ) : " " ) ; <nl> - result . put ( " transaction " , configuration . gettransactions ( ) . size ( ) > num ? configuration . gettransactions ( ) . get ( 0 ) : " " ) ; <nl> + result . put ( " mode " , mode ) ; <nl> + result . put ( " transaction " , transaction ) ; <nl> result . put ( " feature " , feature ) ; <nl> result . put ( " framework " , framework ) ; <nl> result . put ( " shardingsphereversion " , shardingsphereversion . version ) ;
public final class governancerepositoryapiimpltest { <nl> asserttrue ( actual . contains ( " 1 " ) ) ; <nl> } <nl>  <nl> - <nl> - / / @ test <nl> + @ test <nl> public void assertwatch ( ) throws interruptedexception { <nl> atomicreference < datachangedevent > eventreference = new atomicreference < > ( ) ; <nl> countdownlatch countdownlatch = new countdownlatch ( 1 ) ;
<nl> < artifactid > vertx - mysql - client < / artifactid > <nl> < / dependency > <nl> < / dependencies > <nl> - <nl> - < profiles > <nl> - < profile > <nl> - < id > jdk12 + < / id > <nl> - < activation > <nl> - < jdk > [ 12 , ) < / jdk > <nl> - < / activation > <nl> - < build > <nl> - < plugins > <nl> - < plugin > <nl> - < artifactid > maven - surefire - plugin < / artifactid > <nl> - < configuration > <nl> - < excludes > <nl> - < ! - - <nl> - < exclude > org . apache . shardingsphere . infra . executor . sql . log . sqlloggertest < / exclude > <nl> - < / excludes > <nl> - < / configuration > <nl> - < / plugin > <nl> - < / plugins > <nl> - < / build > <nl> - < / profile > <nl> - < / profiles > <nl> < / project > <nl> mmm a / shardingsphere - infra / shardingsphere - infra - executor / src / test / java / org / apache / shardingsphere / infra / executor / sql / log / sqlloggertest . java <nl> ppp b / shardingsphere - infra / shardingsphere - infra - executor / src / test / java / org / apache / shardingsphere / infra / executor / sql / log / sqlloggertest . java <nl>
<nl> < artifactid > antlr4 - runtime < / artifactid > <nl> < / dependency > <nl> < / dependencies > <nl> - <nl> - < profiles > <nl> - < profile > <nl> - < id > jdk12 + < / id > <nl> - < activation > <nl> - < jdk > [ 12 , ) < / jdk > <nl> - < / activation > <nl> - < build > <nl> - < plugins > <nl> - < plugin > <nl> - < artifactid > maven - surefire - plugin < / artifactid > <nl> - < configuration > <nl> - < excludes > <nl> - < ! - - <nl> - < exclude > org . apache . shardingsphere . sql . parser . api . sqlparserenginetest < / exclude > <nl> - < / excludes > <nl> - < / configuration > <nl> - < / plugin > <nl> - < / plugins > <nl> - < / build > <nl> - < / profile > <nl> - < / profiles > <nl> < / project > <nl> mmm a / shardingsphere - sql - parser / shardingsphere - sql - parser - engine / src / test / java / org / apache / shardingsphere / sql / parser / api / sqlparserenginetest . java <nl> ppp b / shardingsphere - sql - parser / shardingsphere - sql - parser - engine / src / test / java / org / apache / shardingsphere / sql / parser / api / sqlparserenginetest . java <nl>
<nl> < version > $ { project . version } < / version > <nl> < / dependency > <nl> < / dependencies > <nl> - <nl> - < profiles > <nl> - < profile > <nl> - < id > jdk12 + < / id > <nl> - < activation > <nl> - < jdk > [ 12 , ) < / jdk > <nl> - < / activation > <nl> - < build > <nl> - < plugins > <nl> - < plugin > <nl> - < artifactid > maven - surefire - plugin < / artifactid > <nl> - < configuration > <nl> - < excludes > <nl> - < ! - - <nl> - < exclude > org . apache . shardingsphere . proxy . frontend . opengauss . opengaussfrontendenginetest < / exclude > <nl> - < / excludes > <nl> - < / configuration > <nl> - < / plugin > <nl> - < / plugins > <nl> - < / build > <nl> - < / profile > <nl> - < / profiles > <nl> < / project > <nl> mmm a / shardingsphere - proxy / shardingsphere - proxy - frontend / shardingsphere - proxy - frontend - opengauss / src / test / java / org / apache / shardingsphere / proxy / frontend / opengauss / opengaussfrontendenginetest . java <nl> ppp b / shardingsphere - proxy / shardingsphere - proxy - frontend / shardingsphere - proxy - frontend - opengauss / src / test / java / org / apache / shardingsphere / proxy / frontend / opengauss / opengaussfrontendenginetest . java <nl>
<nl> < ! - - < destroy - sql sql = " drop resource rdl_test_0 ; " / > - - > <nl> < ! - - < / assertion > - - > <nl> < ! - - < / test - case > - - > <nl> - <nl> - < ! - - <nl> + <nl> + < ! - - fixme # 16005 need to be redesigned : <nl> num . the sql of case should be rdl , not rql ; <nl> num . should not change current rules , which are used to ral and rql , it is better to create / alter / drop new rule for assertion . <nl> - - >
public final class showinstancemodeexecutor extends abstractshowexecutor { <nl> } <nl>  <nl> private collection < list < object > > buildrows ( ) { <nl> - <nl> instancecontext instancecontext = proxycontext . getinstance ( ) . getcontextmanager ( ) . getinstancecontext ( ) ; <nl> persistrepositoryconfiguration repositoryconfiguration = instancecontext . getmodeconfiguration ( ) . getrepository ( ) ; <nl> return collections . singleton ( arrays . aslist ( instancecontext . getinstance ( ) . getinstancedefinition ( ) . getinstanceid ( ) . getid ( ) , instancecontext . getmodeconfiguration ( ) . gettype ( ) , <nl> - null = = repositoryconfiguration ? " " : repositoryconfiguration . gettype ( ) , <nl> - null = = repositoryconfiguration ? " " : propertiesconverter . convert ( repositoryconfiguration . getprops ( ) ) ) ) ; <nl> + null = = repositoryconfiguration ? " " : repositoryconfiguration . gettype ( ) , null = = repositoryconfiguration ? " " : propertiesconverter . convert ( repositoryconfiguration . getprops ( ) ) , <nl> + string . valueof ( instancecontext . getmodeconfiguration ( ) . isoverwrite ( ) ) ) ) ; <nl> } <nl> } <nl> mmm a / shardingsphere - proxy / shardingsphere - proxy - backend / src / test / java / org / apache / shardingsphere / proxy / backend / text / distsql / ral / common / show / showinstancemodeexecutortest . java <nl> ppp b / shardingsphere - proxy / shardingsphere - proxy - backend / src / test / java / org / apache / shardingsphere / proxy / backend / text / distsql / ral / common / show / showinstancemodeexecutortest . java <nl>
public final class inventorytask extends abstractlifecycleexecutor implements pi <nl>  <nl> private void instancechannel ( final importer importer ) { <nl> pipelinechannel channel = pipelinechannelfactory . createpipelinechannel ( 1 , records - > { <nl> - <nl> - optional < record > record = records . stream ( ) . filter ( each - > ! ( each . getposition ( ) instanceof placeholderposition ) ) . reduce ( ( a , b ) - > b ) ; <nl> - record . ifpresent ( value - > position = value . getposition ( ) ) ; <nl> + record lastnormalrecord = getlastnormalrecord ( records ) ; <nl> + if ( null ! = lastnormalrecord ) { <nl> + position = lastnormalrecord . getposition ( ) ; <nl> + } <nl> } ) ; <nl> dumper . setchannel ( channel ) ; <nl> importer . setchannel ( channel ) ; <nl> } <nl>  <nl> + private record getlastnormalrecord ( final list < record > records ) { <nl> + for ( int <nl> + record record = records . get ( index ) ; <nl> + if ( record . getposition ( ) instanceof placeholderposition ) { <nl> + continue ; <nl> + } <nl> + return record ; <nl> + } <nl> + return null ; <nl> + } <nl> + <nl> private void waitforresult ( final future < ? > future ) { <nl> try { <nl> future . get ( ) ;
public final class authoritychecker implements sqlchecker < authorityrule > { <nl> if ( ! privileges . filter ( optional - > optional . hasprivileges ( currentschema ) ) . ispresent ( ) ) { <nl> return new sqlcheckresult ( false , string . format ( " unknown database ' % s ' " , currentschema ) ) ; <nl> } <nl> - <nl> - return privileges . map ( optional - > new sqlcheckresult ( optional . hasprivileges ( collections . singletonlist ( getprivilege ( sqlstatement ) ) ) , <nl> - string . format ( " access denied for operation % s " , getprivilege ( sqlstatement ) . name ( ) ) ) ) . orelseget ( ( ) - > new sqlcheckresult ( false , " " ) ) ; <nl> + privilegetype privilegetype = getprivilege ( sqlstatement ) ; <nl> + string errormessage = objects . isnull ( privilegetype ) ? " " : string . format ( " access denied for operation % s " , privilegetype . name ( ) ) ; <nl> + return privileges . map ( optional - > new sqlcheckresult ( optional . hasprivileges ( collections . singletonlist ( privilegetype ) ) , errormessage ) ) . orelseget ( ( ) - > new sqlcheckresult ( false , " " ) ) ; <nl> } <nl>  <nl> @ override
public final class setreadwritesplittingstatusexecutor implements setstatementex <nl> string resourcename = sqlstatement . getresourcename ( ) ; <nl> collection < string > notexistedresources = proxycontext . getinstance ( ) . getmetadata ( schemaname ) . getresource ( ) . getnotexistedresources ( collections . singleton ( resourcename ) ) ; <nl> distsqlexception . predictionthrow ( notexistedresources . isempty ( ) , new requiredresourcemissedexception ( schemaname , collections . singleton ( resourcename ) ) ) ; <nl> - optional < metadatapersistservice > persistservice = proxycontext . getinstance ( ) . getcontextmanager ( ) . getmetadatacontexts ( ) . getmetadatapersistservice ( ) ; <nl> - <nl> + shardingsphereeventbus . getinstance ( ) . post ( new datasourcedisabledevent ( schemaname , resourcename , " disable " . equals ( sqlstatement . getstatus ( ) ) ) ) ; <nl> return new updateresponseheader ( sqlstatement ) ; <nl> } <nl> }
public final class translatableoptimizercontextfactory { <nl> * / <nl> public static translatableoptimizercontext create ( final string schemaname , final schema logicschema , final filterableoptimizercontext filterableoptimizercontext ) { <nl> calciteconnectionconfig connectionconfig = new calciteconnectionconfigimpl ( filterableoptimizercontext . getprops ( ) ) ; <nl> - <nl> - config parserconfig = sqlparser . config ( ) <nl> - . withlex ( connectionconfig . lex ( ) ) <nl> - . withidentifiermaxlength ( sqlparser . default_identifier_max_length ) <nl> - . withconformance ( connectionconfig . conformance ( ) ) <nl> - . withparserfactory ( sqlparserimpl . factory ) ; <nl> reldatatypefactory reldatatypefactory = new javatypefactoryimpl ( ) ; <nl> calcitecatalogreader catalogreader = createcatalogreader ( schemaname , logicschema , reldatatypefactory , connectionconfig ) ; <nl> sqlvalidator validator = createvalidator ( catalogreader , reldatatypefactory , connectionconfig ) ; <nl> sqltorelconverter relconverter = createrelconverter ( catalogreader , validator , reldatatypefactory ) ; <nl> - return new translatableoptimizercontext ( filterableoptimizercontext , schemaname , logicschema , parserconfig , validator , relconverter ) ; <nl> + return new translatableoptimizercontext ( filterableoptimizercontext , schemaname , logicschema , validator , relconverter ) ; <nl> } <nl>  <nl> private static calcitecatalogreader createcatalogreader ( final string schemaname ,
public final class proxyinfocollector extends collector { <nl> return result ; <nl> } <nl> optional < gaugemetricfamily > proxyinfo = factory . creategaugemetricfamily ( metricids . proxy_info ) ; <nl> - <nl> - / / proxyinfo . ifpresent ( m - > <nl> - / / m . addmetric ( collections . singletonlist ( proxy_state ) , proxycontext . getinstance ( ) . getstatecontext ( ) . getcurrentstate ( ) . ordinal ( ) ) ) ; <nl> - proxyinfo . ifpresent ( optional - > optional . addmetric ( collections . singletonlist ( proxy_state ) , num ) ) ; <nl> + string currentstate = proxycontext . getinstance ( ) . getstatecontext ( ) . getcurrentstate ( ) ; <nl> + proxyinfo . ifpresent ( m - > <nl> + m . addmetric ( collections . singletonlist ( proxy_state ) , proxy_state_map . get ( currentstate ) ) ) ; <nl> proxyinfo . ifpresent ( result : : add ) ; <nl> return result ; <nl> }
the following code of conduct is based on full compliance with [ asf code of cond <nl> - use english in all the logs and javadoc . <nl> - include javadoc , <nl> - only ` public ` classes and methods need javadoc , other methods , classes and override methods do not need javadoc . <nl> + - conditional operator ( < expression1 > ? < expression2 > : < expression3 > ) ` nested use ` is forbidden . <nl>  <nl> # # contributor covenant unit test of conduct
public final class standalonebootstrapinitializer extends abstractbootstrapiniti <nl> @ override <nl> protected proxyconfiguration getproxyconfiguration ( final yamlproxyconfiguration yamlconfig ) { <nl> persistconfigurations ( yamlconfig , isoverwrite ) ; <nl> - <nl> - proxyconfiguration result = loadproxyconfiguration ( ) ; <nl> - return ( result . getschemadatasources ( ) . isempty ( ) ) ? new yamlproxyconfigurationswapper ( ) . swap ( yamlconfig ) : result ; <nl> + return loadproxyconfiguration ( ) ; <nl> } <nl>  <nl> @ override
public final class proxyconfigurationloader { <nl> yamlproxyserverconfiguration serverconfig = loadserverconfiguration ( getresourcefile ( string . join ( " / " , path , server_config_file ) ) ) ; <nl> file configpath = getresourcefile ( path ) ; <nl> collection < yamlproxyruleconfiguration > ruleconfigs = loadruleconfigurations ( configpath ) ; <nl> - <nl> - boolean containsgovernance = serverconfig . getrules ( ) . stream ( ) . anymatch ( each - > each instanceof yamlgovernanceconfiguration ) ; <nl> - preconditions . checkstate ( ! ruleconfigs . isempty ( ) | | containsgovernance , " can not find any valid rule configurations file in path ` % s ` . " , configpath . getpath ( ) ) ; <nl> return new yamlproxyconfiguration ( serverconfig , ruleconfigs . stream ( ) . collect ( collectors . tomap ( <nl> yamlproxyruleconfiguration : : getschemaname , each - > each , ( oldvalue , currentvalue ) - > oldvalue , linkedhashmap : : new ) ) ) ; <nl> }
public final class yamlshardingspheredatasourcefactory { <nl> * @ throws ioexception io exception <nl> * / <nl> public static datasource createdatasource ( final datasource datasource , final byte [ ] yamlbytes ) throws sqlexception , ioexception { <nl> - <nl> yamlrootruleconfigurations configs = yamlengine . unmarshal ( yamlbytes , yamlrootruleconfigurations . class ) ; <nl> map < string , datasource > datasourcemap = new hashmap < > ( 1 , num ) ; <nl> datasourcemap . put ( strings . isnullorempty ( configs . getschemaname ( ) ) ? defaultschema . logic_name : configs . getschemaname ( ) , datasource ) ; <nl> - return createdatasource ( datasourcemap , yamlbytes ) ; <nl> + return createdatasource ( datasourcemap , configs ) ; <nl> + } <nl> + <nl> + private static datasource createdatasource ( final map < string , datasource > datasourcemap , final yamlrootruleconfigurations configs ) throws sqlexception { <nl> + return shardingspheredatasourcefactory . createdatasource ( configs . getschemaname ( ) , datasourcemap , swapper_engine . swaptoruleconfigurations ( configs . getrules ( ) ) , configs . getprops ( ) ) ; <nl> } <nl> }
import static org . mockito . mockito . mock ; <nl> public final class standardbootstrapinitializertest extends abstractbootstrapinitializertest { <nl>  <nl> @ test <nl> - @ ignore <nl> - <nl> public void assertgetproxyconfiguration ( ) { <nl> yamlproxyconfiguration yamlconfig = makeproxyconfiguration ( ) ; <nl> proxyconfiguration actual = getinitializer ( ) . getproxyconfiguration ( yamlconfig ) ; <nl> mmm / dev / null <nl> ppp b / shardingsphere - proxy / shardingsphere - proxy - bootstrap / src / test / resources / meta - inf / services / org . apache . shardingsphere . infra . rule . checker . ruleconfigurationchecker <nl>
public final class localdistmetadatapersistrepository implements distmetadataper <nl>  <nl> @ override <nl> public void delete ( final string key ) { <nl> - boolean isdeleted = new file ( path , key ) . delete ( ) ; <nl> - if ( ! isdeleted ) { <nl> - <nl> - log . error ( " delete local dist meta data key : { } failed " , key ) ; <nl> + try { <nl> + files . walkfiletree ( paths . get ( path , key ) , new localdistmetadatadeletevisitor ( ) ) ; <nl> + } catch ( final ioexception ex ) { <nl> + log . error ( " delete local dist meta data key : { } failed " , key , ex ) ; <nl> } <nl> }
public final class governancemetadatacontexts implements metadatacontexts { <nl> configcenter . getdatasourceservice ( ) . load ( schemaname ) ) ) ; <nl> metadatacontextsbuilder metadatacontextsbuilder = new metadatacontextsbuilder ( datasourcesmap , <nl> collections . singletonmap ( schemaname , configcenter . getschemaruleservice ( ) . load ( schemaname ) ) , <nl> - <nl> configcenter . getglobalruleservice ( ) . load ( ) , <nl> metadatacontexts . getprops ( ) . getprops ( ) ) ; <nl> return metadatacontextsbuilder . build ( configcenter ) . getmetadatamap ( ) . get ( schemaname ) ; <nl>
public final class governancemetadatacontexts implements metadatacontexts { <nl> } <nl>  <nl> private shardingspheremetadata getchangedmetadata ( final shardingspheremetadata oldmetadata , final collection < ruleconfiguration > ruleconfigs ) throws sqlexception { <nl> - <nl> metadatacontextsbuilder builder = new metadatacontextsbuilder ( collections . singletonmap ( oldmetadata . getname ( ) , oldmetadata . getresource ( ) . getdatasources ( ) ) , <nl> - collections . singletonmap ( oldmetadata . getname ( ) , ruleconfigs ) , new linkedlist < > ( ) , metadatacontexts . getprops ( ) . getprops ( ) ) ; <nl> + collections . singletonmap ( oldmetadata . getname ( ) , ruleconfigs ) , configcenter . getglobalruleservice ( ) . load ( ) , metadatacontexts . getprops ( ) . getprops ( ) ) ; <nl> return builder . build ( configcenter ) . getmetadatamap ( ) . values ( ) . iterator ( ) . next ( ) ; <nl> } <nl>  <nl>
public final class governancemetadatacontexts implements metadatacontexts { <nl> oldmetadata . getresource ( ) . close ( modifieddatasources . keyset ( ) ) ; <nl> map < string , map < string , datasource > > datasourcesmap = collections . singletonmap ( oldmetadata . getname ( ) , <nl> getnewdatasources ( oldmetadata . getresource ( ) . getdatasources ( ) , getaddeddatasources ( oldmetadata , newdatasourceconfigs ) , modifieddatasources , deleteddatasources ) ) ; <nl> - <nl> - return new metadatacontextsbuilder ( datasourcesmap , collections . singletonmap ( oldmetadata . getname ( ) , oldmetadata . getrulemetadata ( ) . getconfigurations ( ) ) , new linkedlist < > ( ) , <nl> + return new metadatacontextsbuilder ( datasourcesmap , collections . singletonmap ( oldmetadata . getname ( ) , <nl> + oldmetadata . getrulemetadata ( ) . getconfigurations ( ) ) , configcenter . getglobalruleservice ( ) . load ( ) , <nl> metadatacontexts . getprops ( ) . getprops ( ) ) . build ( configcenter ) . getmetadatamap ( ) . get ( oldmetadata . getname ( ) ) ; <nl> }
public final class shardingsphererulesbuilder { <nl> } <nl>  <nl> @ suppresswarnings ( " rawtypes " ) <nl> - private static void appenddefaultkernelschemaruleconfigurationbuilder ( final map < ruleconfiguration , schemarulebuilder > builders ) { <nl> + private static map < ruleconfiguration , schemarulebuilder > appenddefaultkernelschemaruleconfigurationbuilder ( final map < ruleconfiguration , schemarulebuilder > builders ) { <nl> map < schemarulebuilder , defaultkernelruleconfigurationbuilder > defaultbuilders = <nl> orderedspiregistry . getregisteredservices ( getmissedkernelschemarulebuilders ( builders . values ( ) ) , defaultkernelruleconfigurationbuilder . class ) ; <nl> - <nl> + map < ruleconfiguration , schemarulebuilder > result = new linkedhashmap < > ( builders . size ( ) + defaultbuilders . size ( ) , num ) ; <nl> + result . putall ( builders ) ; <nl> for ( entry < schemarulebuilder , defaultkernelruleconfigurationbuilder > entry : defaultbuilders . entryset ( ) ) { <nl> - builders . put ( entry . getvalue ( ) . build ( ) , entry . getkey ( ) ) ; <nl> + result . put ( entry . getvalue ( ) . build ( ) , entry . getkey ( ) ) ; <nl> } <nl> + return result ; <nl> } <nl>  <nl> @ suppresswarnings ( { " unchecked " , " rawtypes " } )
public final class commandexecutortask implements runnable { <nl> } <nl> } finally { <nl> commandexecutor . close ( ) ; <nl> - <nl> - sqlstatementschemaholder . remove ( ) ; <nl> } <nl> return databaseprotocolfrontendengine . getfrontendcontext ( ) . isflushforpercommandpacket ( ) ; <nl> }
public final class processregistrysubscriber { <nl> * / <nl> @ subscribe <nl> public void reportexecuteprocessunit ( final executeprocessunitreportevent event ) { <nl> - <nl> - string executionpath = processnode . getexecutionpath ( event . getexecutionid ( ) ) ; <nl> - yamlexecuteprocesscontext yamlexecuteprocesscontext = yamlengine . unmarshal ( repository . get ( executionpath ) , yamlexecuteprocesscontext . class ) ; <nl> - executeprocessunit executeprocessunit = event . getexecuteprocessunit ( ) ; <nl> - for ( yamlexecuteprocessunit unit : yamlexecuteprocesscontext . getunitstatuses ( ) ) { <nl> - if ( unit . getunitid ( ) . equals ( executeprocessunit . getunitid ( ) ) ) { <nl> - unit . setstatus ( executeprocessunit . getstatus ( ) ) ; <nl> + string executionid = event . getexecutionid ( ) ; <nl> + synchronized ( executionid ) { <nl> + string executionpath = processnode . getexecutionpath ( executionid ) ; <nl> + yamlexecuteprocesscontext yamlexecuteprocesscontext = yamlengine . unmarshal ( repository . get ( executionpath ) , yamlexecuteprocesscontext . class ) ; <nl> + executeprocessunit executeprocessunit = event . getexecuteprocessunit ( ) ; <nl> + for ( yamlexecuteprocessunit unit : yamlexecuteprocesscontext . getunitstatuses ( ) ) { <nl> + if ( unit . getunitid ( ) . equals ( executeprocessunit . getunitid ( ) ) ) { <nl> + unit . setstatus ( executeprocessunit . getstatus ( ) ) ; <nl> + } <nl> } <nl> + repository . persist ( executionpath , yamlengine . marshal ( yamlexecuteprocesscontext ) ) ; <nl> } <nl> - repository . persist ( executionpath , yamlengine . marshal ( yamlexecuteprocesscontext ) ) ; <nl> } <nl>  <nl> / * * <nl> mmm a / shardingsphere - infra / shardingsphere - infra - executor / src / main / java / org / apache / shardingsphere / infra / executor / sql / process / executeprocessstrategyevaluator . java <nl> ppp b / shardingsphere - infra / shardingsphere - infra - executor / src / main / java / org / apache / shardingsphere / infra / executor / sql / process / executeprocessstrategyevaluator . java <nl>
public final class executeprocessstrategyevaluator { <nl> * @ return submit or not <nl> * / <nl> public static boolean evaluate ( final sqlstatementcontext < ? > context , final executiongroupcontext < ? extends sqlexecutionunit > executiongroupcontext , final configurationproperties props ) { <nl> - <nl> boolean showprocesslistenabled = props . getvalue ( configurationpropertykey . show_process_list_enabled ) ; <nl> - return showprocesslistenabled & & context . getsqlstatement ( ) instanceof ddlstatement ; <nl> + sqlstatement statement = context . getsqlstatement ( ) ; <nl> + boolean statementenabled = statement instanceof ddlstatement | | statement instanceof dmlstatement ; <nl> + return showprocesslistenabled & & statementenabled ; <nl> } <nl> }
public final class columnmetadataloader { <nl> } <nl> } <nl> try ( statement statement = connection . createstatement ( ) ; resultset resultset = statement . executequery ( generateemptyresultsql ( tablenamepattern , databasetype ) ) ) { <nl> - for ( string each : columnnames ) { <nl> - iscasesensitives . add ( resultset . getmetadata ( ) . iscasesensitive ( resultset . findcolumn ( each ) ) ) ; <nl> + for ( int i = num ; i < columnnames . size ( ) ; i + + ) { <nl> + iscasesensitives . add ( resultset . getmetadata ( ) . iscasesensitive ( resultset . findcolumn ( columnnames . get ( i ) ) ) ) ; <nl> + result . add ( new columnmetadata ( columnnames . get ( i ) , columntypes . get ( i ) , isprimarykeys . get ( i ) , <nl> + resultset . getmetadata ( ) . isautoincrement ( i + num ) , iscasesensitives . get ( i ) ) ) ; <nl> } <nl> } <nl> - for ( int i = num ; i < columnnames . size ( ) ; i + + ) { <nl> - <nl> - result . add ( new columnmetadata ( columnnames . get ( i ) , columntypes . get ( i ) , isprimarykeys . get ( i ) , false , iscasesensitives . get ( i ) ) ) ; <nl> - } <nl> return result ; <nl> } <nl>  <nl> mmm a / shardingsphere - jdbc / shardingsphere - jdbc - core / src / test / java / org / apache / shardingsphere / driver / jdbc / core / statement / encryptpreparedstatementtest . java <nl> ppp b / shardingsphere - jdbc / shardingsphere - jdbc - core / src / test / java / org / apache / shardingsphere / driver / jdbc / core / statement / encryptpreparedstatementtest . java <nl>
public final class datasourcestatusregistryservicetest { <nl> verify ( registrycenterrepository ) . getchildrenkeys ( anystring ( ) ) ; <nl> verify ( registrycenterrepository ) . get ( anystring ( ) ) ; <nl> } <nl> - <nl> - <nl> + <nl> + @ test <nl> + public void assertupdatedatasourcedisabledstate ( ) { <nl> + assertupdatedatasourcestate ( true , registrycenternodestatus . disabled . tostring ( ) ) ; <nl> + } <nl> + <nl> + @ test <nl> + public void assertupdatedatasourceenabledstate ( ) { <nl> + assertupdatedatasourcestate ( false , " " ) ; <nl> + } <nl> + <nl> + private void assertupdatedatasourcestate ( final boolean isdisabled , final string value ) { <nl> + string schemaname = " replica_query_db " ; <nl> + string datasourcename = " replica_ds_0 " ; <nl> + datasourcedisabledevent datasourcedisabledevent = new datasourcedisabledevent ( schemaname , datasourcename , isdisabled ) ; <nl> + datasourcestatusregistryservice . update ( datasourcedisabledevent ) ; <nl> + verify ( registrycenterrepository ) . persist ( new registrycenternode ( ) . getdatasourcepath ( schemaname , datasourcename ) , value ) ; <nl> + } <nl> + <nl> + @ test <nl> + public void assertupdateprimarydatasourcestate ( ) { <nl> + string schemaname = " replica_query_db " ; <nl> + string groupname = " group1 " ; <nl> + string datasourcename = " replica_ds_0 " ; <nl> + primarydatasourceevent primarydatasourceevent = new primarydatasourceevent ( schemaname , groupname , datasourcename ) ; <nl> + datasourcestatusregistryservice . update ( primarydatasourceevent ) ; <nl> + verify ( registrycenterrepository ) . persist ( new registrycenternode ( ) . getprimarydatasourcepath ( schemaname , groupname ) , datasourcename ) ; <nl> + } <nl> }
public final class governancefacadetest { <nl> governanceconfiguration config = new governanceconfiguration ( " test_name " , new registrycenterconfiguration ( " test " , " 127 . 0 . 0 . 1 " , new properties ( ) ) , false ) ; <nl> governancefacade . init ( config , arrays . aslist ( " schema_0 " , " schema_1 " ) ) ; <nl> assertnotnull ( governancefacade . getregistrycenter ( ) ) ; <nl> - <nl> + assertthat ( getfield ( governancefacade , " isoverwrite " ) , instanceof ( boolean . class ) ) ; <nl> + assertfalse ( ( boolean ) getfield ( governancefacade , " isoverwrite " ) ) ; <nl> + assertthat ( getfield ( governancefacade , " registrycenterrepository " ) , instanceof ( registrycenterrepository . class ) ) ; <nl> + registrycenterrepository registrycenterrepository = ( registrycenterrepository ) getfield ( governancefacade , " registrycenterrepository " ) ; <nl> + assertequals ( registrycenterrepository . gettype ( ) , " test " ) ; <nl> + assertthat ( getfield ( governancefacade , " listenermanager " ) , instanceof ( governancelistenermanager . class ) ) ; <nl> + governancelistenermanager listenermanager = ( governancelistenermanager ) getfield ( governancefacade , " listenermanager " ) ; <nl> + assertthat ( getfield ( listenermanager , " registrycenterrepository " ) , is ( registrycenterrepository ) ) ; <nl> + assertthat ( getfield ( listenermanager , " schemanames " ) , is ( arrays . aslist ( " schema_0 " , " schema_1 " ) ) ) ; <nl> } <nl>  <nl> @ test <nl>
public final class postgresqlerrpacketfactory { <nl> return createerrorresponsepacket ( ( ( psqlexception ) cause ) . getservererrormessage ( ) ) ; <nl> } <nl> if ( cause instanceof sqlexception ) { <nl> - <nl> - return postgresqlerrorresponsepacket . newbuilder ( postgresqlmessageseveritylevel . error , ( ( sqlexception ) cause ) . getsqlstate ( ) , cause . getmessage ( ) ) . build ( ) ; <nl> + return createerrorresponsepacket ( ( sqlexception ) cause ) ; <nl> } <nl> if ( cause instanceof invalidauthorizationspecificationexception ) { <nl> return postgresqlerrorresponsepacket . newbuilder ( postgresqlmessageseveritylevel . fatal , postgresqlerrorcode . invalid_authorization_specification , cause . getmessage ( ) ) . build ( ) ; <nl>
<nl> < assertion expected - data - file = " select_in_or_encrypt . xml " / > <nl> < / test - case > <nl>  <nl> - < ! - - <nl> - < ! - - < test - case sql = " select * from t_user u inner join t_user_item m on u . user_id = m . user_id " scenario - types = " encrypt , dbtbl_with_replica_query_and_encrypt " > - - > <nl> - < ! - - < assertion expected - data - file = " select_join_encrypt . xml " / > - - > <nl> - < ! - - < / test - case > - - > <nl> + < test - case sql = " select * from t_user u inner join t_user_item m on u . user_id = m . user_id " scenario - types = " encrypt , dbtbl_with_replica_query_and_encrypt " > <nl> + < assertion expected - data - file = " select_join_encrypt . xml " / > <nl> + < / test - case > <nl> < / integration - test - cases >
public final class integrationtestcaseassertion { <nl> collection < sqlvalue > result = new linkedlist < > ( ) ; <nl> int count = num ; <nl> for ( string each : splitter . on ( " , " ) . trimresults ( ) . splittolist ( parameters ) ) { <nl> - <nl> - if ( each . startswith ( " ' " ) ) { <nl> - string value = each . substring ( each . indexof ( ' \ ' ' ) + num , each . lastindexof ( ' \ ' ' ) ) ; <nl> - result . add ( new sqlvalue ( value , " json " , + + count ) ) ; <nl> - continue ; <nl> - } <nl> list < string > parameterpair = splitter . on ( " : " ) . trimresults ( ) . splittolist ( each ) ; <nl> result . add ( new sqlvalue ( parameterpair . get ( 0 ) , parameterpair . get ( 1 ) , + + count ) ) ; <nl> } <nl> mmm a / shardingsphere - test / shardingsphere - integration - test / shardingsphere - integration - test - suite / src / test / java / org / apache / shardingsphere / test / integration / cases / value / sqlvalue . java <nl> ppp b / shardingsphere - test / shardingsphere - integration - test / shardingsphere - integration - test - suite / src / test / java / org / apache / shardingsphere / test / integration / cases / value / sqlvalue . java <nl>
public final class unicastdatabasebackendhandler implements databasebackendhandl <nl>  <nl> @ override <nl> public responseheader execute ( ) throws sqlexception { <nl> - if ( null = = backendconnection . getschemaname ( ) ) { <nl> - <nl> - backendconnection . setcurrentschema ( getfirstschemaname ( ) ) ; <nl> - } <nl> - if ( ! proxycontext . getinstance ( ) . getmetadata ( backendconnection . getschemaname ( ) ) . iscomplete ( ) ) { <nl> + string schemaname = null = = backendconnection . getschemaname ( ) ? getfirstschemaname ( ) : backendconnection . getschemaname ( ) ; <nl> + if ( ! proxycontext . getinstance ( ) . getmetadata ( schemaname ) . iscomplete ( ) ) { <nl> throw new rulenotexistsexception ( ) ; <nl> } <nl> databasecommunicationengine = databasecommunicationenginefactory . newtextprotocolinstance ( sqlstatement , sql , backendconnection ) ; <nl> mmm a / shardingsphere - test / shardingsphere - integration - agent - test / shardingsphere - integration - agent - test - plugins / shardingsphere - integration - agent - test - metrics / src / test / resources / env / engine - env . properties <nl> ppp b / shardingsphere - test / shardingsphere - integration - agent - test / shardingsphere - integration - agent - test - plugins / shardingsphere - integration - agent - test - metrics / src / test / resources / env / engine - env . properties <nl>
public final class databasemetadatadialecthandlertest { <nl> public void assertgetschema ( ) throws sqlexception { <nl> when ( connection . getmetadata ( ) ) . thenreturn ( databasemetadata ) ; <nl> when ( databasemetadata . getusername ( ) ) . thenreturn ( user_name ) ; <nl> - string schema = getschema ( new oracledatabasetype ( ) ) ; <nl> - assertthat ( schema , is ( user_name . touppercase ( ) ) ) ; <nl> + <nl> + string oracleschema = getschema ( new oracledatabasetype ( ) ) ; <nl> + assertthat ( oracleschema , is ( user_name . touppercase ( ) ) ) ; <nl> + <nl> when ( connection . getschema ( ) ) . thenreturn ( user_name ) ; <nl> - string schemamysql = getschema ( new mysqldatabasetype ( ) ) ; <nl> - assertthat ( schemamysql , is ( user_name ) ) ; <nl> - <nl> + string mysqlschema = getschema ( new mysqldatabasetype ( ) ) ; <nl> + assertthat ( mysqlschema , is ( user_name ) ) ; <nl> + <nl> + string h2schema = getschema ( new h2databasetype ( ) ) ; <nl> + assertthat ( h2schema , is ( user_name ) ) ; <nl> + <nl> + string mariadbschema = getschema ( new mariadbdatabasetype ( ) ) ; <nl> + assertthat ( mariadbschema , is ( user_name ) ) ; <nl> + <nl> + string postgresqlschema = getschema ( new postgresqldatabasetype ( ) ) ; <nl> + assertthat ( postgresqlschema , is ( user_name ) ) ; <nl> + <nl> + string sqlserverschema = getschema ( new sqlserverdatabasetype ( ) ) ; <nl> + assertthat ( sqlserverschema , is ( user_name ) ) ; <nl> + <nl> + string sql92schema = getschema ( new sql92databasetype ( ) ) ; <nl> + assertthat ( sql92schema , is ( user_name ) ) ; <nl> } <nl>  <nl> @ test
public final class databasemetadatadialecthandlertest { <nl> assertthat ( oracletablenamepattern , is ( table_name_pattern . touppercase ( ) ) ) ; <nl> string mysqltablenamepattern = gettablenamepattern ( new mysqldatabasetype ( ) ) ; <nl> assertthat ( mysqltablenamepattern , is ( table_name_pattern ) ) ; <nl> - <nl> + string h2tablenamepattern = gettablenamepattern ( new h2databasetype ( ) ) ; <nl> + assertthat ( h2tablenamepattern , is ( table_name_pattern ) ) ; <nl> + string mariadbtablenamepattern = gettablenamepattern ( new mariadbdatabasetype ( ) ) ; <nl> + assertthat ( mariadbtablenamepattern , is ( table_name_pattern ) ) ; <nl> + string postgresqltablenamepattern = gettablenamepattern ( new postgresqldatabasetype ( ) ) ; <nl> + assertthat ( postgresqltablenamepattern , is ( table_name_pattern ) ) ; <nl> + string sqlservertablenamepattern = gettablenamepattern ( new sqlserverdatabasetype ( ) ) ; <nl> + assertthat ( sqlservertablenamepattern , is ( table_name_pattern ) ) ; <nl> + string sql92tablenamepattern = gettablenamepattern ( new sql92databasetype ( ) ) ; <nl> + assertthat ( sql92tablenamepattern , is ( table_name_pattern ) ) ; <nl> } <nl>  <nl> @ test
public final class datasourceconverter { <nl> result . getprops ( ) . put ( " readonly " , datasourceparameter . isreadonly ( ) ) ; <nl> return result ; <nl> } <nl> - <nl> - / * * <nl> - * get data source parameter . <nl> - * <nl> - * @ param datasource data source <nl> - * @ return data source parameter <nl> - * / <nl> - public static datasourceparameter getdatasourceparameter ( final datasource datasource ) { <nl> - datasourceparameter result = new datasourceparameter ( ) ; <nl> - hikaridatasource hikaridatasource = ( hikaridatasource ) datasource ; <nl> - result . seturl ( hikaridatasource . getjdbcurl ( ) ) ; <nl> - result . setusername ( hikaridatasource . getusername ( ) ) ; <nl> - result . setpassword ( hikaridatasource . getpassword ( ) ) ; <nl> - result . setconnectiontimeoutmilliseconds ( hikaridatasource . getconnectiontimeout ( ) ) ; <nl> - result . setidletimeoutmilliseconds ( hikaridatasource . getidletimeout ( ) ) ; <nl> - result . setmaxlifetimemilliseconds ( hikaridatasource . getmaxlifetime ( ) ) ; <nl> - result . setmaxpoolsize ( hikaridatasource . getmaximumpoolsize ( ) ) ; <nl> - result . setminpoolsize ( hikaridatasource . getminimumidle ( ) ) ; <nl> - <nl> - result . setreadonly ( hikaridatasource . isreadonly ( ) ) ; <nl> - return result ; <nl> - } <nl> } <nl> mmm a / shardingsphere - proxy / shardingsphere - proxy - common / src / test / java / org / apache / shardingsphere / proxy / config / util / datasourceconvertertest . java <nl> ppp b / shardingsphere - proxy / shardingsphere - proxy - common / src / test / java / org / apache / shardingsphere / proxy / config / util / datasourceconvertertest . java <nl>
public final class userexecutorgroup implements autocloseable { <nl> public static userexecutorgroup getinstance ( ) { <nl> return instance ; <nl> } <nl> - <nl> - <nl> - @ override <nl> - public void close ( ) { <nl> - shardingsphereexecutorservice . close ( ) ; <nl> - } <nl> }
public final class frontendchannelinboundhandler extends channelinboundhandlerad <nl> / / checkstyle : off <nl> } catch ( final exception ex ) { <nl> / / checkstyle : on <nl> - <nl> log . error ( " exception occur : " , ex ) ; <nl> context . write ( databaseprotocolfrontendengine . getcommandexecuteengine ( ) . geterrorpacket ( ex ) ) ; <nl> }
public final class orchestrationshardingspheredatasource extends abstractunsuppo <nl> this . datasourceconfigurations . putall ( datasourceconfigurations ) ; <nl> } <nl>  <nl> - <nl> private void disabledatasources ( ) { <nl> collection < string > disableddatasources = orchestrationfacade . getregistrycenter ( ) . loaddisableddatasources ( ) ; <nl> - if ( ! disableddatasources . isempty ( ) ) { <nl> - datasource . getschemacontexts ( ) . getschemacontexts ( ) . foreach ( ( key , value ) <nl> - - > value . getschema ( ) . getrules ( ) . stream ( ) . filter ( each - > each instanceof masterslaverule ) . foreach ( each - > disabledatasources ( ( masterslaverule ) each , disableddatasources , key ) ) ) ; <nl> + if ( disableddatasources . isempty ( ) ) { <nl> + return ; <nl> } <nl> + datasource . getschemacontexts ( ) . getschemacontexts ( ) . foreach ( ( key , value ) <nl> + - > value . getschema ( ) . getrules ( ) . stream ( ) . filter ( each - > each instanceof statuscontainedrule ) . foreach ( each - > disabledatasources ( ( statuscontainedrule ) each , disableddatasources , key ) ) ) ; <nl> } <nl>  <nl> - private void disabledatasources ( final masterslaverule masterslaverule , final collection < string > disableddatasources , final string schemaname ) { <nl> - masterslaverule . getsingledatasourcerule ( ) . getslavedatasourcenames ( ) . foreach ( each - > { <nl> - if ( disableddatasources . contains ( joiner . on ( " . " ) . join ( schemaname , each ) ) ) { <nl> - masterslaverule . updaterulestatus ( new datasourcenamedisabledevent ( each , true ) ) ; <nl> - } <nl> - } ) ; <nl> + private void disabledatasources ( final statuscontainedrule statuscontainedrule , final collection < string > disableddatasources , final string schemaname ) { <nl> + disableddatasources . stream ( ) . filter ( each - > each . startswith ( schemaname ) ) . map ( this : : getdatasourcename ) . foreach ( each - > <nl> + statuscontainedrule . updaterulestatus ( new datasourcenamedisabledevent ( each , true ) ) <nl> + ) ; <nl> + } <nl> + <nl> + private string getdatasourcename ( final string disabledatasource ) { <nl> + return new orchestrationschema ( disabledatasource ) . getdatasourcename ( ) ; <nl> } <nl>  <nl> private void persistmetadata ( final ruleschemametadata metadata ) {
public final class selectstatementcontext extends commonsqlstatementcontext < sele <nl> private collection < simpletablesegment > gettablefromselect ( final selectstatement selectstatement ) { <nl> collection < simpletablesegment > result = new linkedlist < > ( ) ; <nl> collection < tablesegment > realtables = new linkedlist < > ( ) ; <nl> - <nl> - collection < tablesegment > tmp = new linkedlist < > ( ) ; <nl> + collection < tablesegment > alltables = new linkedlist < > ( ) ; <nl> for ( tablereferencesegment each : selectstatement . gettablereferences ( ) ) { <nl> - tmp . addall ( gettablesfromtablereference ( each ) ) ; <nl> + alltables . addall ( gettablesfromtablereference ( each ) ) ; <nl> realtables . addall ( getrealtablesfromtablereference ( each ) ) ; <nl> } <nl> if ( selectstatement . getwhere ( ) . ispresent ( ) ) { <nl> - tmp . addall ( getalltablesfromwhere ( selectstatement . getwhere ( ) . get ( ) , realtables ) ) ; <nl> + alltables . addall ( getalltablesfromwhere ( selectstatement . getwhere ( ) . get ( ) , realtables ) ) ; <nl> } <nl> result . addall ( getalltablesfromprojections ( selectstatement . getprojections ( ) , realtables ) ) ; <nl> if ( getsqlstatement ( ) . getgroupby ( ) . ispresent ( ) ) { <nl>
public final class selectstatementcontext extends commonsqlstatementcontext < sele <nl> if ( null ! = tablefactorsegment . gettable ( ) & & tablefactorsegment . gettable ( ) instanceof simpletablesegment ) { <nl> result . add ( tablefactorsegment . gettable ( ) ) ; <nl> } <nl> - <nl> if ( null ! = tablefactorsegment . gettable ( ) & & tablefactorsegment . gettable ( ) instanceof subquerytablesegment ) { <nl> result . add ( tablefactorsegment . gettable ( ) ) ; <nl> } <nl>
public final class selectstatementcontext extends commonsqlstatementcontext < sele <nl> if ( null ! = tablefactorsegment . gettable ( ) & & tablefactorsegment . gettable ( ) instanceof simpletablesegment ) { <nl> result . add ( tablefactorsegment . gettable ( ) ) ; <nl> } <nl> - <nl> if ( null ! = tablefactorsegment . gettable ( ) & & tablefactorsegment . gettable ( ) instanceof subquerytablesegment ) { <nl> result . add ( tablefactorsegment . gettable ( ) ) ; <nl> } <nl>
public final class autointervalshardingalgorithm implements standardshardingalgo <nl> return each ; <nl> } <nl> } <nl> - <nl> return null ; <nl> - / / throw new shardingalgorithmexception ( " sharding failure , cannot find target name via ` % s ` " , shardingvalue ) ; <nl> } <nl>  <nl> @ override <nl> mmm a / shardingsphere - features / shardingsphere - sharding / shardingsphere - sharding - common / src / main / java / org / apache / shardingsphere / sharding / algorithm / sharding / mod / hashmodshardingalgorithm . java <nl> ppp b / shardingsphere - features / shardingsphere - sharding / shardingsphere - sharding - common / src / main / java / org / apache / shardingsphere / sharding / algorithm / sharding / mod / hashmodshardingalgorithm . java <nl>
public final class hashmodshardingalgorithm implements standardshardingalgorithm <nl> return each ; <nl> } <nl> } <nl> - <nl> return null ; <nl> - / / throw new shardingalgorithmexception ( " sharding failure , cannot find target name via ` % s ` " , shardingvalue ) ; <nl> } <nl>  <nl> @ override <nl> mmm a / shardingsphere - features / shardingsphere - sharding / shardingsphere - sharding - common / src / main / java / org / apache / shardingsphere / sharding / algorithm / sharding / mod / modshardingalgorithm . java <nl> ppp b / shardingsphere - features / shardingsphere - sharding / shardingsphere - sharding - common / src / main / java / org / apache / shardingsphere / sharding / algorithm / sharding / mod / modshardingalgorithm . java <nl>
public final class modshardingalgorithm implements standardshardingalgorithm < com <nl> return each ; <nl> } <nl> } <nl> - <nl> return null ; <nl> - / / throw new shardingalgorithmexception ( " sharding failure , cannot find target name via ` % s ` " , shardingvalue ) ; <nl> } <nl>  <nl> @ override
chapter = true <nl> # # congratulations on graduation of apache shardingsphere as a top - level project ! <nl>  <nl>  <nl> - wakefield , ma , april num , num - - the world ' s largest open source software foundation , the apache software foundation ( asf ) , announced apache shardingsphere as a top - level project ( tlp ) . <nl> + apache software foundation ( asf ) , the most popular open - source software foundation , announced apache shardingsphere as a top - level project ( tlp ) on wakefield , ma , num th april num . <nl>  <nl> - shardingsphere was submitted to the apache incubator and entered incubation in november num . afterwards , under the guidance of the mentor , the members of the incubator project management committee ( ipmc ) effectively manages the process of incubation . on march num , num , the proposal for graduation was put to the apache foundation ' s incubator for a vote and approved with num votes in favor . <nl> + shardingsphere entered into the apache incubator since num th november num . with the help of mentors and the whole community , the apache board approved its graduation proposal with num + 1 votes successfully , which ends up its num months incubator and promotes it as tlp . <nl>  <nl> - on april num , the apache software foundation ( asf ) board has passed the resolution for shardingsphere to graduate from the apache incubator to become a top - level project , ending the num - month incubation . and vice president of marketing and publicity at the apache software foundation , sally khudairi announced it on the official channels of the apache software foundation . shardingsphere is the first top - level project to graduate from apache incubator in num . <nl> + as the first project graduating from incubator in num , this cheering news was published subsequently on apache official blog with the support of sally khudairi , vice president marketing & publicity of asf . <nl>  <nl> - apache shardingsphere is an open - source ecosystem , which has num sub - projects that form the database solutions , for shardingsphere - jdbc , shardingsphere - proxy and shardingsphere - sidecar ( <nl> - <nl> - graduation as a top - level project reflects the efforts of the apache shardingsphere community over the past year and a half . since entering the apache incubator , shardingsphere has evolved from a jdbc driver for sharding into a distributed ecosystem . <nl> - <nl> - thanks to our mentors , contributors , and the apache incubator for their support , especially during the period of the coronavirus outbreak . moreover , we are very pleased to see that the community has been active and diverse , with the involvement of more than num contributors from all over the world . <nl> + apache shardingsphere was born in dangdang . com , grew up fastly in jd . com , and now becomes a famous apache distributed database middleware ecosystem . the evolvement from a light jdbc driver into an ecosystem presents the efforts and enthusiasm of the whole community in the past num months . <nl>  <nl> + special thanks for the guidance from ipmcs , mentors . many thanks for contributions from num + committers all over the world . what ' s more , we are glad to see the community still move actively during the coronavirus outbreak . <nl> \ no newline at end of file
public final class shardingmetadataloader { <nl> return actualdefaultdatasourcename . ispresent ( ) <nl> ? schemametadataloader . load ( datasourcemap . get ( actualdefaultdatasourcename . get ( ) ) , maxconnectionssizeperquery ) : new schemametadata ( collections . emptymap ( ) ) ; <nl> } <nl> - <nl> - <nl> + <nl> private void checkuniformed ( final string logictablename , final map < string , tablemetadata > actualtablemetadatamap ) { <nl> shardingtablemetadatadecorator decorator = new shardingtablemetadatadecorator ( ) ; <nl> tablemetadata sample = decorator . decorate ( actualtablemetadatamap . values ( ) . iterator ( ) . next ( ) , logictablename , shardingrule ) ; <nl> + collection < tablemetadataviolation > violations = new linkedlist < > ( ) ; <nl> for ( entry < string , tablemetadata > entry : actualtablemetadatamap . entryset ( ) ) { <nl> if ( ! sample . equals ( decorator . decorate ( entry . getvalue ( ) , logictablename , shardingrule ) ) ) { <nl> - throw new shardingsphereexception ( <nl> - " cannot get uniformed table structure for logic table ` % s ` and actual table ` % s ` . the different meta data of actual tables are as follows : \n % s\n % s . " , <nl> - logictablename , entry . getkey ( ) , sample , entry . getvalue ( ) ) ; <nl> + violations . add ( new tablemetadataviolation ( entry . getkey ( ) , entry . getvalue ( ) ) ) ; <nl> } <nl> } <nl> + throwexceptionifnecessary ( violations , logictablename ) ; <nl> + } <nl> + <nl> + private void throwexceptionifnecessary ( final collection < tablemetadataviolation > violations , final string logictablename ) { <nl> + if ( ! violations . isempty ( ) ) { <nl> + stringbuilder errormessage = new stringbuilder ( <nl> + " cannot get uniformed table structure for logic table ` % s ` , it has different meta data of actual tables are as follows : " ) . append ( line_
public final class whereclauseassert { <nl> count + + ; <nl> } <nl> } <nl> - count = num ; <nl> + } <nl> + <nl> + private static void assertliteralexpressionsegment ( final sqlcaseassertcontext assertcontext , final predicateinrightvalue actual , final expectedpredicateinrightvalue expected ) { <nl> + int count = num ; <nl> for ( expressionsegment each : actual . getsqlexpressions ( ) ) { <nl> if ( each instanceof literalexpressionsegment ) { <nl> expressionassert . assertliteralexpression ( assertcontext , ( literalexpressionsegment ) each , expected . getliteralexpressions ( ) . get ( count ) ) ; <nl> count + + ; <nl> } <nl> } <nl> - count = num ; <nl> + } <nl> + <nl> + private static void assertcommonexpressionsegment ( final sqlcaseassertcontext assertcontext , final predicateinrightvalue actual , final expectedpredicateinrightvalue expected ) { <nl> + int count = num ; <nl> for ( expressionsegment each : actual . getsqlexpressions ( ) ) { <nl> if ( each instanceof commonexpressionsegment ) { <nl> expressionassert . assertcommonexpression ( assertcontext , ( complexexpressionsegment ) each , expected . getcommonexpressions ( ) . get ( count ) ) ; <nl> count + + ; <nl> } <nl> } <nl> - count = num ; <nl> + } <nl> + <nl> + private static void assertsubqueryexpressionsegment ( final sqlcaseassertcontext assertcontext , final predicateinrightvalue actual , final expectedpredicateinrightvalue expected ) { <nl> + int count = num ; <nl> for ( expressionsegment each : actual . getsqlexpressions ( ) ) { <nl> if ( each instanceof subqueryexpressionsegment ) { <nl> expressionassert . assertsubquery ( assertcontext , ( subqueryexpressionsegment ) each , expected . getsubqueries ( ) . get ( count ) ) ; <nl> count + + ; <nl> } <nl> } <nl> - <nl> - / / sqlsegmentassert . assertis ( assertcontext , actual , expected ) ; <nl> } <nl>  <nl> private static void assertbetweenrightvalue ( final sqlcaseassertcontext assertcontext , final predicatebetweenrightvalue actual , final expectedpredicatebetweenrightvalue expected ) {
public final class assignmentvalueassert { <nl> } else if ( actual instanceof expressionprojectionsegment ) { <nl> expressionassert . assertcommonexpression ( assertcontext , ( expressionprojectionsegment ) actual , expected . getcommonexpression ( ) ) ; <nl> } <nl> - <nl> - / / sqlsegmentassert . assertis ( assertcontext , actual , expected ) ; <nl> } <nl> } <nl> mmm a / shardingsphere - sql - parser / shardingsphere - sql - parser - test / src / test / java / org / apache / shardingsphere / sql / parser / integrate / asserts / segment / orderby / orderbyitemassert . java <nl> ppp b / shardingsphere - sql - parser / shardingsphere - sql - parser - test / src / test / java / org / apache / shardingsphere / sql / parser / integrate / asserts / segment / orderby / orderbyitemassert . java <nl>
public final class orderbyitemassert { <nl> count + + ; <nl> } <nl> } <nl> - <nl> - / / sqlsegmentassert . assertis ( assertcontext , actual , expected ) ; <nl> } <nl>  <nl> private static void assertorderinfo ( final sqlcaseassertcontext assertcontext , final orderbyitemsegment actual , final expectedorderbyitem expected , final string type ) {
public final class sqlstatementassert { <nl> } <nl> } <nl>  <nl> - private void assertinsertstatement ( final insertstatement actual , final string databasetype ) { <nl> - <nl> - if ( " oracle " . equalsignorecase ( databasetype ) ) { <nl> - return ; <nl> - } <nl> + private void assertinsertstatement ( final insertstatement actual ) { <nl> insertnamesandvaluesassert . assertinsertnamesandvalues ( actual , expected . getinsertcolumnsandvalues ( ) ) ; <nl> } <nl>  <nl> mmm a / shardingsphere - sql - parser / shardingsphere - sql - parser - test / src / test / java / org / apache / shardingsphere / sql / parser / integrate / engine / sqlparserparameterizedtest . java <nl> ppp b / shardingsphere - sql - parser / shardingsphere - sql - parser - test / src / test / java / org / apache / shardingsphere / sql / parser / integrate / engine / sqlparserparameterizedtest . java <nl>
import java . sql . sqlexception ; <nl> public class examplemain { <nl>  <nl> / * * <nl> - * the example can ' t work well . <nl> - * related issue # 2884 : https : / / github . com / apache / incubator - shardingsphere / issues / 2884 <nl> + * main entrance . <nl> * <nl> + * @ param args startup arguments . <nl> * @ throws sqlexception sql exception <nl> * / <nl> @ deprecated <nl> public static void main ( final string [ ] args ) throws sqlexception { <nl> - <nl> try ( configurableapplicationcontext applicationcontext = springapplication . run ( examplemain . class , args ) ) { <nl> exampleexecutetemplate . run ( applicationcontext . getbean ( " encrypt " , exampleservice . class ) ) ; <nl> }
public final class mysqlbinlogeventpacketdecoder extends bytetomessagedecoder { <nl> } <nl> } <nl>  <nl> - private void handlechecksum ( final bytebuf in ) { <nl> - <nl> - var checksumlength = num ; <nl> - in . writerindex ( in . writerindex ( ) - num ) ; <nl> + private void removechecksum ( final short eventtype , final bytebuf in ) { <nl> + if ( 0 < binlogcontext . getchecksumlength ( ) <nl> + & & eventtypes . rotate_event ! = eventtype <nl> + & & eventtypes . format_description_event ! = eventtype ) { <nl> + in . writerindex ( in . writerindex ( ) - binlogcontext . getchecksumlength ( ) ) ; <nl> + } <nl> } <nl>  <nl> private void decoderotateevent ( final bytebuf in ) { <nl>
public final class shardingdropindexoptimizeengine implements shardingoptimizeen <nl> return new shardingdropindexoptimizedstatement ( sqlstatement , tables , gettablenames ( shardingtablemetadata , sqlstatement , tables ) ) ; <nl> } <nl>  <nl> - <nl> private collection < string > gettablenames ( final shardingtablemetadata shardingtablemetadata , final dropindexstatement sqlstatement , final tables tables ) { <nl> - if ( ! tables . isempty ( ) ) { <nl> - return collections . singletonlist ( tables . getsingletablename ( ) ) ; <nl> - } <nl> + return tables . isempty ( ) ? gettablenames ( shardingtablemetadata , sqlstatement ) : collections . singletonlist ( tables . getsingletablename ( ) ) ; <nl> + } <nl> + <nl> + private collection < string > gettablenames ( final shardingtablemetadata shardingtablemetadata , final dropindexstatement sqlstatement ) { <nl> collection < string > result = new linkedlist < > ( ) ; <nl> for ( indexsegment each : sqlstatement . getindexes ( ) ) { <nl> optional < string > tablename = shardingtablemetadata . getlogictablename ( each . getname ( ) ) ;
<nl> - / * <nl> - * licensed to the apache software foundation ( asf ) under one or more <nl> - * contributor license agreements . see the notice file distributed with <nl> - * this work for additional information regarding copyright ownership . <nl> - * the asf licenses this file to you under the apache license , version num . 0 <nl> - * ( the " license " ) ; you may not use this file except in compliance with <nl> - * the license . you may obtain a copy of the license at <nl> - * <nl> - * http : / / www . apache . org / licenses / license - 2 . 0 <nl> - * <nl> - * unless required by applicable law or agreed to in writing , software <nl> - * distributed under the license is distributed on an " as is " basis , <nl> - * without warranties or conditions of any kind , either express or implied . <nl> - * see the license for the specific language governing permissions and <nl> - * limitations under the license . <nl> - * / <nl> - <nl> - package org . apache . shardingsphere . core . parse . filler . encrypt ; <nl> - <nl> - import org . apache . shardingsphere . core . parse . filler . api . sqlsegmentfiller ; <nl> - import org . apache . shardingsphere . core . parse . sql . context . table . table ; <nl> - import org . apache . shardingsphere . core . parse . sql . segment . common . tablesegment ; <nl> - import org . apache . shardingsphere . core . parse . sql . statement . sqlstatement ; <nl> - <nl> - / * * <nl> - * table filler for encrypt . <nl> - * <nl> - * @ author duhongjun <nl> - * @ author zhangliang <nl> - * / <nl> - public final class encrypttablefiller implements sqlsegmentfiller < tablesegment > { <nl> - <nl> - @ override <nl> - public void fill ( final tablesegment sqlsegment , final sqlstatement sqlstatement ) { <nl> - <nl> - sqlstatement . gettables ( ) . add ( new table ( sqlsegment . getname ( ) , sqlsegment . getalias ( ) . ornull ( ) ) ) ; <nl> - } <nl> - }
public final class integratesupportedsqlparsingtest extends abstractbaseintegrat <nl> @ test <nl> public void assertsupportedsql ( ) { <nl> string sql = sqlcasesloader . getsupportedsql ( sqlcaseid , sqlcasetype , parserresultsetloader . getparserresult ( sqlcaseid ) . getparameters ( ) ) ; <nl> - <nl> - if ( " select_with_same_table_name_and_alias " . equals ( sqlcaseid ) ) { <nl> - return ; <nl> - } <nl> new sqlstatementassert ( new shardingsqlparseentry ( databasetypes . gettrunkdatabasetype ( databasetype ) , getshardingrule ( ) , getshardingtablemetadata ( ) , new parsingresultcache ( ) ) <nl> . parse ( sql , false ) , sqlcaseid , sqlcasetype ) . assertsqlstatement ( ) ; <nl> }
public final class encryptorpredicatefiller implements sqlsegmentfiller < orpredic <nl>  <nl> private shardingtablemetadata shardingtablemetadata ; <nl>  <nl> - @ deprecated <nl> - private shardingencryptorengine encryptorengine ; <nl> - <nl> @ override <nl> public void fill ( final orpredicatesegment sqlsegment , final sqlstatement sqlstatement ) { <nl> collection < integer > stopindexes = new hashset < > ( ) ; <nl>
public final class encryptorpredicatefiller implements sqlsegmentfiller < orpredic <nl> } <nl>  <nl> private boolean isneedencrypt ( final predicatesegment predicate , final string tablename ) { <nl> - <nl> - encryptorengine = null = = encryptorengine ? encryptrule . getencryptorengine ( ) : encryptorengine ; <nl> - return encryptorengine . getshardingencryptor ( tablename , predicate . getcolumn ( ) . getname ( ) ) . ispresent ( ) ; <nl> + return encryptrule . getencryptorengine ( ) . getshardingencryptor ( tablename , predicate . getcolumn ( ) . getname ( ) ) . ispresent ( ) ; <nl> } <nl>  <nl> private boolean isoperatorsupportedwithencrypt ( final string operator ) { <nl> mmm a / sharding - core / sharding - core - parse / sharding - core - parse - common / src / main / java / org / apache / shardingsphere / core / parse / filler / sharding / dml / shardingorpredicatefiller . java <nl> ppp b / sharding - core / sharding - core - parse / sharding - core - parse - common / src / main / java / org / apache / shardingsphere / core / parse / filler / sharding / dml / shardingorpredicatefiller . java <nl>
<nl> - / * <nl> - * licensed to the apache software foundation ( asf ) under one or more <nl> - * contributor license agreements . see the notice file distributed with <nl> - * this work for additional information regarding copyright ownership . <nl> - * the asf licenses this file to you under the apache license , version num . 0 <nl> - * ( the " license " ) ; you may not use this file except in compliance with <nl> - * the license . you may obtain a copy of the license at <nl> - * <nl> - * http : / / www . apache . org / licenses / license - 2 . 0 <nl> - * <nl> - * unless required by applicable law or agreed to in writing , software <nl> - * distributed under the license is distributed on an " as is " basis , <nl> - * without warranties or conditions of any kind , either express or implied . <nl> - * see the license for the specific language governing permissions and <nl> - * limitations under the license . <nl> - * / <nl> - <nl> - package org . apache . shardingsphere . core . parse . integrate . asserts . token ; <nl> - <nl> - import org . apache . shardingsphere . core . parse . integrate . asserts . sqlstatementassertmessage ; <nl> - import org . apache . shardingsphere . core . parse . integrate . jaxb . token . expectedtokens ; <nl> - import org . apache . shardingsphere . core . parse . sql . token . sqltoken ; <nl> - import org . apache . shardingsphere . test . sql . sqlcasetype ; <nl> - <nl> - import java . util . collection ; <nl> - <nl> - / * * <nl> - * token assert . <nl> - * <nl> - * @ author zhangliang <nl> - * / <nl> - public final class tokenassert { <nl> - <nl> - private final insertvaluestokenassert insertvaluestokenassert ; <nl> - <nl> - public tokenassert ( final sqlcasetype sqlcasetype , final sqlstatementassertmessage assertmessage ) { <nl> - insertvaluestokenassert = new insertvaluestokenassert ( assertmessage ) ; <nl> - } <nl> - <nl> - / * * <nl> - * assert tokens . <nl> - * <nl> - * @ param actual actual tokens <nl> - * @ param expected expected tokens <nl> - * / <nl> - public void asserttokens ( final collection < sqltoken > actual , final expectedtokens expected ) { <nl> - <nl> - insertvaluestokenassert . assertinsertvaluestoken ( actual , expected ) ; <nl> - } <nl> - }
public final class seataatshardingtransactionmanager implements shardingtransact <nl>  <nl> private final map < string , datasource > datasourcemap = new hashmap < > ( ) ; <nl>  <nl> + private final fileconfiguration configuration = new fileconfiguration ( " seata . conf " ) ; <nl> + <nl> @ override <nl> public void init ( final databasetype databasetype , final collection < resourcedatasource > resourcedatasources ) { <nl> - <nl> - tmclient . init ( " my_test_tx_group " , " my_test_tx_group " ) ; <nl> - rmclient . init ( " my_test_tx_group " , " my_test_tx_group " ) ; <nl> + initseatarpcclient ( ) ; <nl> for ( resourcedatasource each : resourcedatasources ) { <nl> datasourcemap . put ( each . getoriginalname ( ) , new datasourceproxy ( each . getdatasource ( ) ) ) ; <nl> } <nl> } <nl>  <nl> + private void initseatarpcclient ( ) { <nl> + string applicationid = configuration . getconfig ( " applicationid " ) ; <nl> + string transactionservicegroup = configuration . getconfig ( " transactionservicegroup " ) ; <nl> + tmclient . init ( applicationid , transactionservicegroup ) ; <nl> + rmclient . init ( applicationid , transactionservicegroup ) ; <nl> + } <nl> + <nl> @ override <nl> public transactiontype gettransactiontype ( ) { <nl> return transactiontype . base ; <nl> mmm / dev / null <nl> ppp b / sharding - transaction / sharding - transaction - base / sharding - transaction - base - seata - at / src / main / resources / seata . conf <nl>
unicodeescapes_ <nl> : ( ' u ' | ' u ' ) ampersand_ <nl> ; <nl>  <nl> - <nl> uescape_ <nl> - : uescape sq_ . sq_ <nl> + : uescape string_ <nl> ; <nl>  <nl> unreservedword_ <nl> mmm a / sharding - core / sharding - core - parse / sharding - core - parse - test / src / test / resources / antlr_parser / postgre / ddl / create . xml <nl> ppp b / sharding - core / sharding - core - parse / sharding - core - parse - test / src / test / resources / antlr_parser / postgre / ddl / create . xml <nl>
public final class parsecondition { <nl>  <nl> private list < andcondition > orconditions = new arraylist < > ( ) ; <nl>  <nl> - / * * <nl> - * add condition . <nl> - * <nl> - * @ param condition condition <nl> - * / <nl> - public void add ( final condition condition ) { <nl> - <nl> - if ( orconditions . isempty ( ) ) { <nl> - orconditions . add ( new andcondition ( ) ) ; <nl> - } <nl> - orconditions . iterator ( ) . next ( ) . getconditions ( ) . add ( condition ) ; <nl> - } <nl> - <nl> / * * <nl> * find conditions by column . <nl> *
public final class encryptorpredicatefiller implements sqlsegmentfiller < orpredic <nl> } <nl>  <nl> private void fill ( final predicatesegment predicate , final string tablename , final sqlstatement sqlstatement ) { <nl> - <nl> - if ( ! encryptrule . getencryptorengine ( ) . getshardingencryptor ( tablename , predicate . getcolumn ( ) . getname ( ) ) . ispresent ( ) ) { <nl> - return ; <nl> - } <nl> andcondition andcondition ; <nl> if ( sqlstatement . getencryptconditions ( ) . getorcondition ( ) . getandconditions ( ) . isempty ( ) ) { <nl> andcondition = new andcondition ( ) ; <nl>
columnsortclause_ <nl> : tablename alias ? columnname ( asc | desc ) ? <nl> ; <nl>  <nl> - dropindex <nl> - : drop index indexname <nl> - ; <nl>  <nl> - <nl> - alterindex <nl> - : alter index indexname ( rename to indexname ) ? <nl> - ;
final class insertvaluestokenassert { <nl> private void assertinsertvaluestoken ( final insertvaluestoken actual , final expectedinsertvaluestoken expected ) { <nl> assertthat ( assertmessage . getfullassertmessage ( " insert values token begin position assertion error : " ) , actual . getstartindex ( ) , is ( expected . getbeginposition ( ) ) ) ; <nl> assertthat ( assertmessage . getfullassertmessage ( " insert values type assertion error : " ) , actual . gettype ( ) . name ( ) , is ( expected . gettype ( ) ) ) ; <nl> - <nl> - / / assertthat ( assertmessage . getfullassertmessage ( " insert values column names assertion error : " ) , joiner . on ( " , " ) . join ( actual . getcolumnnames ( ) ) , is ( expected . getcolumnnames ( ) ) ) ; <nl> - / / for ( int i = num ; i < actual . getcolumnvalues ( ) . size ( ) ; i + + ) { <nl> - / / assertthat ( assertmessage . getfullassertmessage ( " insert column values assertion error : " ) , <nl> - / / getinsertvalues ( actual . getcolumnvalues ( ) . get ( i ) , actual . getcolumnnames ( ) . size ( ) ) , is ( expected . getinsertvalues ( ) . get ( i ) . getvalues ( ) ) ) ; <nl> - / / } <nl> - } <nl> - <nl> - private string getinsertvalues ( final insertcolumnvalue insertcolumnvalue , final int columnsize ) { <nl> - list < string > result = new linkedlist < > ( ) ; <nl> - for ( int i = num ; i < columnsize ; i + + ) { <nl> - result . add ( insertcolumnvalue . getcolumnvalue ( 0 ) . tostring ( ) ) ; <nl> - } <nl> - return joiner . on ( " , " ) . join ( result ) ; <nl> } <nl>  <nl> private optional < insertvaluestoken > getinsertvaluestoken ( final collection < sqltoken > actual ) {
import java . util . map ; <nl> * <nl> * @ author zhangliang <nl> * / <nl> - <nl> - @ requiredargsconstructor <nl> @ getter <nl> public final class shardingmetadata { <nl>  <nl>
public final class mysqlcomstmtclosepacket extends mysqlcommandpacket { <nl> * remove cached statement . <nl> * / <nl> public void removecachedstatement ( ) { <nl> - <nl> - / / mysqlbinarystatementregistry . getinstance ( ) . remove ( statementid ) ; <nl> + mysqlbinarystatementregistry . getinstance ( ) . remove ( statementid ) ; <nl> } <nl> }
public final class backendconnection implements autocloseable { <nl> if ( null = = schemaname ) { <nl> throw new shardingexception ( " please select database , then switch transaction type . " ) ; <nl> } <nl> - <nl> if ( isswitchfailed ( ) ) { <nl> throw new shardingexception ( " failed to switch transaction type , please terminate current transaction . " ) ; <nl> }
chapter = true <nl> - return values are named with ` result ` ; variables in the loop structure are named with ` each ` ; replace ` each ` with ` entry ` in map . <nl> - exceptions when catch are named with ` ex ` ; exceptions when catch but do nothing are named with ` ignored ` . <nl> - name property files with camel - case and lowercase first letters . <nl> + - split codes that need to add notes with it into small methods , which are explained with method names . <nl> - have constants on the left and variable on the right in ` = ` and ` equals ` conditional expressions ; have variable on the left and constants on the right in ` greater than ` and ` less than ` conditional expressions . <nl> - - use ` linkedlist ` in priority . use ` arraylist ` for use <nl> - - use capacity based ` collection ` such as ` arraylist ` , ` hashmap ` must indicate initial capacity to avoid recalculate capacity . <nl> - design class as ` final ` class expect abstract class for extend . <nl> - make nested loop structures a new method . <nl> - use guard clauses in priority . <nl> - minimize the access permission for classes and methods . <nl> - private method should be just next to the method in which it is used ; writing private methods should be in the same as the appearance order of private methods . <nl> - no ` null ` parameters or return values . <nl> - - split codes that need to add notes with it into small methods , which are explained with method names . <nl> - replace constructors , getters , setter methods and log variable with lombok in priority . <nl> + - use ` linkedlist ` in priority . use ` arraylist ` for use <nl> + - use capacity based ` collection ` such as ` arraylist ` , ` hashmap ` must indicate initial capacity to avoid recalculate capacity . <nl> - use english in all the logs and javadoc . <nl> - include javadoc , <nl> - only ` public ` classes and methods need javadoc , other methods , classes and override methods do not need javadoc .
<nl> - / * <nl> - * copyright num - 2018 shardingsphere . io . <nl> - * < p > <nl> - * licensed under the apache license , version num . 0 ( the " license " ) ; <nl> - * you may not use this file except in compliance with the license . <nl> - * you may obtain a copy of the license at <nl> - * <nl> - * http : / / www . apache . org / licenses / license - 2 . 0 <nl> - * <nl> - * unless required by applicable law or agreed to in writing , software <nl> - * distributed under the license is distributed on an " as is " basis , <nl> - * without warranties or conditions of any kind , either express or implied . <nl> - * see the license for the specific language governing permissions and <nl> - * limitations under the license . <nl> - * < / p > <nl> - * / <nl> - <nl> - package io . shardingsphere . core . hint ; <nl> - <nl> - import lombok . equalsandhashcode ; <nl> - import lombok . getter ; <nl> - <nl> - / * * <nl> - * sharding key . <nl> - * <nl> - * @ author zhangliang <nl> - * / <nl> - <nl> - @ equalsandhashcode <nl> - public final class shardingkey { <nl> - <nl> - / * * <nl> - * logic table name . <nl> - * / <nl> - private final string logictable ; <nl> - <nl> - / * * <nl> - * sharding column name . <nl> - * / <nl> - @ getter <nl> - private final string shardingcolumn ; <nl> - <nl> - public shardingkey ( final string logictable , final string shardingcolumn ) { <nl> - this . logictable = logictable . tolowercase ( ) ; <nl> - this . shardingcolumn = shardingcolumn . tolowercase ( ) ; <nl> - } <nl> - }
import io . shardingsphere . orchestration . reg . listener . datachangedevent . changedtype <nl> * / <nl> public final class datasourcestatechangedlistener extends postshardingorchestrationeventlistener { <nl>  <nl> - private final datasourceservice datasourceservice ; <nl> + private final statenode statenode ; <nl>  <nl> public datasourcestatechangedlistener ( final string name , final registrycenter regcenter ) { <nl> super ( regcenter , new statenode ( name ) . getdatasourcesnodefullrootpath ( ) ) ; <nl> - datasourceservice = new datasourceservice ( name , regcenter ) ; <nl> + statenode = new statenode ( name ) ; <nl> } <nl>  <nl> @ override <nl> protected disabledstatechangedevent createshardingorchestrationevent ( final datachangedevent event ) { <nl> - <nl> - return new disabledstatechangedevent ( datasourceservice . getdisabledslaveshardingschema ( event . getkey ( ) ) , isdatasourcedisabled ( event ) ) ; <nl> + return new disabledstatechangedevent ( getshardingschema ( event . getkey ( ) ) , isdatasourcedisabled ( event ) ) ; <nl> + } <nl> + <nl> + private orchestrationshardingschema getshardingschema ( final string datasourcenodefullpath ) { <nl> + return new orchestrationshardingschema ( datasourcenodefullpath . replace ( statenode . getdatasourcesnodefullrootpath ( ) + ' / ' , " " ) ) ; <nl> } <nl>  <nl> private boolean isdatasourcedisabled ( final datachangedevent event ) {
import lombok . tostring ; <nl> @ getter <nl> @ equalsandhashcode <nl> @ tostring <nl> - public final class aggregationdistinctselectitem extends distinctselectitem { <nl> + public final class aggregationdistinctselectitem extends aggregationselectitem { <nl>  <nl> - private final aggregationtype type ; <nl> + private final string distinctcolumnname ; <nl>  <nl> @ setter <nl> private int index ; <nl>  <nl> - public aggregationdistinctselectitem ( final aggregationtype type , final string columnname , final optional < string > alias ) { <nl> - / / super ( columnname , alias ) ; <nl> - super ( " user_id " , alias ) ; <nl> - this . type = type ; <nl> - <nl> - / / throw new sqlparsingunsupportedexception ( type . tostring ( ) + " ( distinct ) " ) ; <nl> + public aggregationdistinctselectitem ( final aggregationtype type , final string innerexpression , final optional < string > alias , final string distinctcolumnname ) { <nl> + super ( type , innerexpression , alias ) ; <nl> + this . distinctcolumnname = distinctcolumnname ; <nl> } <nl> }
public final class fromclauseextracthandler implements astextracthandler < collect <nl> optional < parserrulecontext > exprnode = astutils . findfirstchildnode ( jointablenode . get ( ) , rulename . expr ) ; <nl> if ( exprnode . ispresent ( ) ) { <nl> tablejoinextractresult tablejoinresult = new tablejoinextractresult ( extractresult . get ( ) ) ; <nl> - <nl> + optional < conditionextractresult > conditionresult = conditionextracthandler . extract ( exprnode . get ( ) ) ; <nl> + if ( conditionresult . ispresent ( ) ) { <nl> + tablejoinresult . getjoinconditions ( ) . getandconditions ( ) . addall ( conditionresult . get ( ) . getorcondition ( ) . getandconditions ( ) ) ; <nl> + } <nl> result . add ( tablejoinresult ) ; <nl> continue ; <nl> }
public final class globalregistry { <nl> * <nl> * @ return transaction type <nl> * / <nl> - <nl> public transactiontype gettransactiontype ( ) { <nl> - return shardingproperties . < boolean > getvalue ( shardingpropertiesconstant . proxy_transaction_enabled ) ? transactiontype . xa : transactiontype . local ; <nl> + return transactiontype . valueof ( ( string ) shardingproperties . getvalue ( shardingpropertiesconstant . proxy_transaction_type ) ) ; <nl> } <nl>  <nl> / * *
public abstract class frontendhandler extends channelinboundhandleradapter { <nl> @ override <nl> public final void channelinactive ( final channelhandlercontext context ) { <nl> context . firechannelinactive ( ) ; <nl> - <nl> - if ( null ! = backendconnection ) { <nl> - backendconnection . cancel ( ) ; <nl> - } <nl> + backendconnection . cancel ( ) ; <nl> channelthreadexecutorgroup . getinstance ( ) . unregister ( context . channel ( ) . id ( ) ) ; <nl> } <nl> }
public final class comquerypacket implements querycommandpacket { <nl> if ( ! operationtype . ispresent ( ) ) { <nl> return optional . of ( backendhandler . execute ( ) ) ; <nl> } <nl> - if ( transactiontype . local = = transactiontype ) { <nl> - switch ( operationtype . get ( ) ) { <nl> - case begin : <nl> - backendconnection . setautocommit ( false ) ; <nl> - break ; <nl> - case commit : <nl> - backendconnection . commit ( ) ; <nl> - break ; <nl> - case rollback : <nl> - backendconnection . rollback ( ) ; <nl> - break ; <nl> - default : <nl> - } <nl> - } else if ( transactiontype . xa = = transactiontype ) { <nl> - shardingtransactionhandler . dointransaction ( new xatransactionevent ( operationtype . get ( ) ) ) ; <nl> - } <nl> - <nl> + backendconnection . dointransactional ( operationtype . get ( ) ) ; <nl> return optional . of ( new commandresponsepackets ( new okpacket ( 1 ) ) ) ; <nl> }
public final class globalregistry { <nl> return shardingproperties . getvalue ( shardingpropertiesconstant . executor_size ) ; <nl> } <nl>  <nl> - / * * <nl> - * is use nio . <nl> - * <nl> - * @ return use or not <nl> - * / <nl> - <nl> - public boolean isusenio ( ) { <nl> - return false ; <nl> - } <nl> - <nl> / * * <nl> * check schema exists . <nl> *
public class logicschema { <nl> this . datasources = datasources ; <nl> backenddatasource = new jdbcbackenddatasource ( datasources ) ; <nl> } <nl> - <nl> - public logicschema ( final string name , final map < string , datasourceparameter > datasources , final shardingrule shardingrule , final masterslaverule masterslaverule ) { <nl> - this . name = name ; <nl> - <nl> - this . datasources = datasources ; <nl> - backenddatasource = new jdbcbackenddatasource ( datasources ) ; <nl> - } <nl> }
public final class shardingschema extends logicschema { <nl> metadata = getshardingmetadata ( backendexecutorcontext . getinstance ( ) . getexecuteengine ( ) ) ; <nl> } <nl>  <nl> - public shardingschema ( final string name , final map < string , datasourceparameter > datasources , final shardingrule shardingrule , final masterslaverule masterslaverule ) { <nl> - this . name = name ; <nl> - <nl> - this . datasources = datasources ; <nl> - this . shardingrule = shardingrule ; <nl> - this . masterslaverule = masterslaverule ; <nl> - backenddatasource = new jdbcbackenddatasource ( datasources ) ; <nl> - metadata = getshardingmetadata ( backendexecutorcontext . getinstance ( ) . getexecuteengine ( ) ) ; <nl> - } <nl> - <nl> private shardingrule getshardingrule ( final shardingruleconfiguration shardingrule , final boolean isusingregistry ) { <nl> return isusingregistry ? new orchestrationshardingrule ( shardingrule , datasources . keyset ( ) ) : new shardingrule ( shardingrule , datasources . keyset ( ) ) ; <nl> } <nl>  <nl> - private masterslaverule getmasterslaverule ( final masterslaveruleconfiguration masterslaverule , final boolean isusingregistry ) { <nl> - return isusingregistry ? new orchestrationmasterslaverule ( masterslaverule ) : new masterslaverule ( masterslaverule ) ; <nl> - } <nl> - <nl> private shardingmetadata getshardingmetadata ( final shardingexecuteengine executeengine ) { <nl> return new shardingmetadata ( getdatasourceurls ( datasources ) , shardingrule , <nl> databasetype . mysql , executeengine , new proxytablemetadataconnectionmanager ( backenddatasource ) , globalregistry . getinstance ( ) . getmaxconnectionssizeperquery ( ) ) ; <nl>
import java . util . map . entry ; <nl> * @ author wangkai <nl> * / <nl> @ getter <nl> - public final class shardingschema { <nl> - <nl> - private final string name ; <nl> - <nl> - private final map < string , datasourceparameter > datasources ; <nl> + public final class shardingschema extends logicschema { <nl>  <nl> private final shardingrule shardingrule ; <nl>  <nl> - private final masterslaverule masterslaverule ; <nl> - <nl> - private final jdbcbackenddatasource backenddatasource ; <nl> - <nl> private final shardingmetadata metadata ; <nl>  <nl> - public shardingschema ( final string name , final map < string , datasourceparameter > datasources , final ruleconfiguration ruleconfiguration , final boolean isusingregistry ) { <nl> - this . name = name ; <nl> - <nl> - this . datasources = datasources ; <nl> - shardingrule = ruleconfiguration instanceof shardingruleconfiguration ? getshardingrule ( ( shardingruleconfiguration ) ruleconfiguration , isusingregistry ) <nl> - : new shardingrule ( new shardingruleconfiguration ( ) , datasources . keyset ( ) ) ; <nl> - masterslaverule = ruleconfiguration instanceof masterslaveruleconfiguration ? getmasterslaverule ( ( masterslaveruleconfiguration ) ruleconfiguration , isusingregistry ) : null ; <nl> - backenddatasource = new jdbcbackenddatasource ( datasources ) ; <nl> + public shardingschema ( final string name , final map < string , datasourceparameter > datasources , final shardingruleconfiguration shardingruleconfig , final boolean isusingregistry ) { <nl> + super ( name , datasources ) ; <nl> + shardingrule = getshardingrule ( shardingruleconfig , isusingregistry ) ; <nl> metadata = getshardingmetadata ( backendexecutorcontext . getinstance ( ) . getexecuteengine ( ) ) ; <nl> }
<nl> - / * <nl> - * copyright num - 2018 shardingsphere . io . <nl> - * < p > <nl> - * licensed under the apache license , version num . 0 ( the " license " ) ; <nl> - * you may not use this file except in compliance with the license . <nl> - * you may obtain a copy of the license at <nl> - * <nl> - * http : / / www . apache . org / licenses / license - 2 . 0 <nl> - * <nl> - * unless required by applicable law or agreed to in writing , software <nl> - * distributed under the license is distributed on an " as is " basis , <nl> - * without warranties or conditions of any kind , either express or implied . <nl> - * see the license for the specific language governing permissions and <nl> - * limitations under the license . <nl> - * < / p > <nl> - * / <nl> - <nl> - package io . shardingsphere . core . yaml ; <nl> - <nl> - import io . shardingsphere . api . config . masterslaveruleconfiguration ; <nl> - import io . shardingsphere . api . config . shardingruleconfiguration ; <nl> - import lombok . getter ; <nl> - import lombok . setter ; <nl> - <nl> - / * * <nl> - * rule configuration for yaml . <nl> - * <nl> - * @ author panjuan <nl> - * / <nl> - @ getter <nl> - @ setter <nl> - @ deprecated <nl> - <nl> - public final class yamlruleconfiguration { <nl> - <nl> - private shardingruleconfiguration shardingrule ; <nl> - <nl> - private masterslaveruleconfiguration masterslaverule ; <nl> - }
public class xadatasourcewrapper { <nl> result . setuniqueresourcename ( datasourcename ) ; <nl> result . setmaxpoolsize ( datasourceparameter . getmaximumpoolsize ( ) ) ; <nl> result . settestquery ( " select num " ) ; <nl> - properties xaproperties ; <nl> - <nl> - if ( xadatasource . getclass ( ) . getname ( ) . equals ( " com . mysql . jdbc . jdbc2 . optional . mysqlxadatasource " ) ) { <nl> - xaproperties = getmysqlxaproperties ( datasourceparameter ) ; <nl> - } else { <nl> - xaproperties = new properties ( ) ; <nl> - } <nl> + properties xaproperties = xapropertyfactory . build ( xadatabasetype . find ( xadatasource . getclass ( ) . getname ( ) ) , datasourceparameter ) ; <nl> propertyutils . setproperties ( xadatasource , xaproperties ) ; <nl> result . setxadatasource ( xadatasource ) ; <nl> result . setxaproperties ( xaproperties ) ; <nl>
public class xadatasourcewrapper { <nl> result . settransactionmanager ( transactionmanager ) ; <nl> result . setmaxtotal ( datasourceparameter . getmaximumpoolsize ( ) ) ; <nl> result . setxadatasource ( xadatasource . getclass ( ) . getname ( ) ) ; <nl> - properties xaproperties ; <nl> - <nl> - if ( xadatasource . getclass ( ) . getname ( ) . equals ( " com . mysql . jdbc . jdbc2 . optional . mysqlxadatasource " ) ) { <nl> - xaproperties = getmysqlxaproperties ( datasourceparameter ) ; <nl> - } else { <nl> - xaproperties = new properties ( ) ; <nl> - } <nl> + properties xaproperties = xapropertyfactory . build ( xadatabasetype . find ( xadatasource . getclass ( ) . getname ( ) ) , datasourceparameter ) ; <nl> propertyutils . setproperties ( xadatasource , xaproperties ) ; <nl> result . setxadatasourceinstance ( xadatasource ) ; <nl> return result ; <nl> } <nl> - <nl> - private properties getmysqlxaproperties ( final datasourceparameter datasourceparameter ) { <nl> - properties result = new properties ( ) ; <nl> - result . setproperty ( " user " , datasourceparameter . getusername ( ) ) ; <nl> - result . setproperty ( " password " , optional . fromnullable ( datasourceparameter . getpassword ( ) ) . or ( " " ) ) ; <nl> - result . setproperty ( " url " , datasourceparameter . geturl ( ) ) ; <nl> - result . setproperty ( " pinglobaltxtophysicalconnection " , boolean . true . tostring ( ) ) ; <nl> - result . setproperty ( " autoreconnect " , boolean . true . tostring ( ) ) ; <nl> - result . setproperty ( " useserverprepstmts " , boolean . true . tostring ( ) ) ; <nl> - result . setproperty ( " cacheprepstmts " , boolean . true . tostring ( ) ) ; <nl> - result . setproperty ( " prepstmtcachesize " , " 250 " ) ; <nl> - result . setproperty ( " prepstmtcachesqllimit " , " 2048 " ) ; <nl> - result . setproperty ( " uselocalsessionstate " , boolean . true . tostring ( ) ) ; <nl> - result . setproperty ( " rewritebatchedstatements " , boolean . true . tostring ( ) ) ; <nl> - result . setproperty ( " cacheresultsetmetadata " , boolean . true . tostring ( ) ) ; <nl> - result . setproperty ( " cacheserverconfiguration " , boolean . true . tostring ( ) ) ; <nl> - result . setproperty ( " elidesetautocommits " , boolean . true . tostring ( ) ) ; <nl> - result . setproperty ( " maintaintimestats " , boolean . false . tostring ( ) ) ; <nl> - result . setproperty ( " nettimeoutforstreamingresults " , " 0 " ) ; <nl> - return result ; <nl> - } <nl> } <nl> mmm a / sharding - transaction / src / main / java / io / shardingsphere / transaction / manager / xa / property / xapropertyfactory . java <nl> ppp b / sharding - transaction / src / main / java / io / shardingsphere / transaction / manager / xa / property / xapropertyfactory . java <nl>
public class orchestrationspringbootconfiguration implements environmentaware { <nl> return ! strings . isnullorempty ( orchestrationproperties . getname ( ) ) ; <nl> } <nl>  <nl> - private boolean issharding ( ) { <nl> - return isvalidruleconfiguration ( ) ? isshardingbylocal ( ) : isshardingbyregistry ( ) ; <nl> + private boolean isshardingrule ( ) { <nl> + return isvalidruleconfiguration ( ) ? isshardingrulebylocal ( ) : isshardingrulebyregistry ( ) ; <nl> } <nl>  <nl> - private boolean isshardingbylocal ( ) { <nl> + private boolean isshardingrulebylocal ( ) { <nl> return ! shardingproperties . gettables ( ) . isempty ( ) ; <nl> } <nl>  <nl> - private boolean isshardingbyregistry ( ) { <nl> - <nl> + private boolean isshardingrulebyregistry ( ) { <nl> try ( orchestrationfacade orchestrationfacade = new orchestrationfacade ( orchestrationproperties . getorchestrationconfiguration ( ) ) ) { <nl> - orchestrationfacade . getconfigservice ( ) . loadshardingruleconfiguration ( ) ; <nl> - } catch ( final exception ex ) { <nl> - return false ; <nl> + return orchestrationfacade . getconfigservice ( ) . isshardingrule ( shardingconstant . logic_schema_name ) ; <nl> } <nl> - return true ; <nl> } <nl>  <nl> private datasource createshardingdatasource ( ) throws sqlexception { <nl> mmm a / sharding - orchestration / sharding - orchestration - core / src / main / java / io / shardingsphere / orchestration / internal / config / configurationservice . java <nl> ppp b / sharding - orchestration / sharding - orchestration - core / src / main / java / io / shardingsphere / orchestration / internal / config / configurationservice . java <nl>
public final class backendhandlerfactory { <nl> } <nl>  <nl> if ( sqlstatement instanceof showotherstatement ) { <nl> - <nl> - return newtextprotocolinstance ( connectionid , sequenceid , sql , backendconnection , databasetype . mysql , proxy_context . getdefaultschema ( ) ) ; <nl> + return new schemaunicastbackendhandler ( connectionid , sequenceid , sql , backendconnection , databasetype . mysql ) ; <nl> } <nl>  <nl> string schema = getschema ( sqlstatement ) . ispresent ( ) ? getschema ( sqlstatement ) . get ( ) : frontendhandler . getcurrentschema ( ) ; <nl> mmm / dev / null <nl> ppp b / sharding - proxy / src / main / java / io / shardingsphere / shardingproxy / backend / schemaunicastbackendhandler . java <nl>
<nl> < ! - - < assertion parameters = " 1 : int , num : int " expected - data - file = " insert_with_generate_key_column . xml " / > - - > <nl> < / dml - test - case > <nl>  <nl> - < ! - - <nl> < dml - test - case sql - case - id = " insert_without_generate_key_column " > <nl> < assertion parameters = " 1 : int , num : int " expected - data - file = " insert_without_generate_key_column . xml " / > <nl> < / dml - test - case >
<nl> < artifactid > sharding - core < / artifactid > <nl> < version > $ { project . version } < / version > <nl> < / dependency > <nl> - < ! - - <nl> - < dependency > <nl> - < groupid > io . shardingsphere < / groupid > <nl> - < artifactid > sharding - jdbc - core < / artifactid > <nl> - < version > $ { project . version } < / version > <nl> - < / dependency > <nl> < / dependencies > <nl> < / project >
public final class insertstatementparsertest extends abstractstatementparsertest <nl> shardingrule shardingrule = createshardingrule ( ) ; <nl> new sqlparsingengine ( databasetype . mysql , " insert all into table_xxx ( field1 ) values ( field1 ) on duplicate key update field1 = values ( field1 ) " , shardingrule , null ) . parse ( false ) ; <nl> } <nl> - <nl> - @ test <nl> - <nl> - public void parsemultipleinsertformysql ( ) { <nl> - shardingrule shardingrule = createshardingrule ( ) ; <nl> - new sqlparsingengine ( databasetype . mysql , " insert into table_xxx ( ` field1 ` , ` field2 ` ) values ( 1 , ' value_char ' ) , ( 2 , ' value_char ' ) " , shardingrule , null ) . parse ( false ) ; <nl> - } <nl> }
public final class shardingdatasourcetest { <nl> assertthat ( createshardingdatasource ( datasourcemap ) . getconnection ( ) . getconnection ( " ds " ) , is ( datasource . getconnection ( ) ) ) ; <nl> } <nl>  <nl> - @ test <nl> - public void assertrenewwithoutchangeexecutorpoolengine ( ) throws sqlexception , nosuchfieldexception , illegalaccessexception { <nl> - datasource originaldatasource = mockdatasource ( " h2 " ) ; <nl> - map < string , datasource > originaldatasourcemap = new hashmap < > ( 1 , num ) ; <nl> - originaldatasourcemap . put ( " ds " , originaldatasource ) ; <nl> - shardingdatasource shardingdatasource = createshardingdatasource ( originaldatasourcemap ) ; <nl> - shardingproperties originshardingproperties = getshardingproperties ( shardingdatasource ) ; <nl> - datasource newdatasource = mockdatasource ( " h2 " ) ; <nl> - map < string , datasource > newdatasourcemap = new hashmap < > ( 1 , num ) ; <nl> - newdatasourcemap . put ( " ds " , newdatasource ) ; <nl> - shardingdatasource . renew ( newdatasourcemap , new shardingrule ( createshardingruleconfig ( newdatasourcemap ) , <nl> - newdatasourcemap . keyset ( ) ) , new shardingproperties ( new properties ( ) ) ) ; <nl> - assertthat ( originshardingproperties , not ( getshardingproperties ( shardingdatasource ) ) ) ; <nl> - } <nl> - <nl> - @ test <nl> - public void assertrenewwithchangeexecuteenginepoolsize ( ) throws sqlexception , nosuchfieldexception , illegalaccessexception { <nl> - datasource originaldatasource = mockdatasource ( " h2 " ) ; <nl> - map < string , datasource > originaldatasourcemap = new hashmap < > ( 1 , num ) ; <nl> - originaldatasourcemap . put ( " ds " , originaldatasource ) ; <nl> - shardingdatasource shardingdatasource = createshardingdatasource ( originaldatasourcemap ) ; <nl> - final shardingproperties originshardingproperties = getshardingproperties ( shardingdatasource ) ; <nl> - datasource newdatasource = mockdatasource ( " h2 " ) ; <nl> - map < string , datasource > newdatasourcemap = new hashmap < > ( 1 , num ) ; <nl> - newdatasourcemap . put ( " ds " , newdatasource ) ; <nl> - properties props = new properties ( ) ; <nl> - props . setproperty ( shardingpropertiesconstant . executor_size . getkey ( ) , " 100 " ) ; <nl> - shardingproperties shardingproperties = new shardingproperties ( props ) ; <nl> - shardingdatasource . renew ( newdatasourcemap , new shardingrule ( createshardingruleconfig ( newdatasourcemap ) , newdatasourcemap . keyset ( ) ) , shardingproperties ) ; <nl> - assertthat ( originshardingproperties , not ( getshardingproperties ( shardingdatasource ) ) ) ; <nl> - } <nl> - <nl> - <nl> - / / @ test ( expected = illegalstateexception . class ) <nl> - @ test <nl> - public void assertrenewwithdatabasetypechanged ( ) throws sqlexception { <nl> - datasource originaldatasource = mockdatasource ( " h2 " ) ; <nl> - map < string , datasource > originaldatasourcemap = new hashmap < > ( 1 , num ) ; <nl> - originaldatasourcemap . put ( " ds " , originaldatasource ) ; <nl> - shardingdatasource shardingdatasource = createshardingdatasource ( originaldatasourcemap ) ; <nl> - datasource newdatasource = mockdatasource ( " mysql " ) ; <nl> - map < string , datasource > newdatasourcemap = new hashmap < > ( 1 , num ) ; <nl> - newdatasourcemap . put ( " ds " , newdatasource ) ; <nl> - shardingdatasource . renew ( newdatasourcemap , new shardingrule ( createshardingruleconfig ( newdatasourcemap ) , <nl> - newdatasourcemap . keyset ( ) ) , new shardingproperties ( new properties ( ) ) ) ; <nl> - } <nl> - <nl> private shardingdatasource createshardingdatasource ( final map < string , datasource > datasourcemap ) throws sqlexception { <nl> return new shardingdatasource ( datasourcemap , new shardingrule ( createshardingruleconfig ( datasourcemap ) , datasourcemap . keyset ( ) ) ) ; <nl> }
public final class columndefinition41packet implements mysqlpacket { <nl>  <nl> private final int decimals ; <nl>  <nl> - <nl> public columndefinition41packet ( final int sequenceid , final resultsetmetadata resultsetmetadata , final int columnindex ) throws sqlexception { <nl> this ( sequenceid , resultsetmetadata . getschemaname ( columnindex ) , resultsetmetadata . gettablename ( columnindex ) , resultsetmetadata . gettablename ( columnindex ) , <nl> resultsetmetadata . getcolumnlabel ( columnindex ) , resultsetmetadata . getcolumnname ( columnindex ) , resultsetmetadata . getcolumndisplaysize ( columnindex ) , <nl> - columntype . valueofjdbctype ( resultsetmetadata . getcolumntype ( columnindex ) ) , num ) ; <nl> + columntype . valueofjdbctype ( resultsetmetadata . getcolumntype ( columnindex ) ) , resultsetmetadata . getscale ( columnindex ) ) ; <nl> } <nl>  <nl> public columndefinition41packet ( final int sequenceid , final string schema , final string table , final string orgtable ,
public final class mysqlfrontendhandler extends frontendhandler { <nl>  <nl> @ override <nl> public void channelwritabilitychanged ( final channelhandlercontext context ) { <nl> - context . firechannelwritabilitychanged ( ) ; <nl> if ( context . channel ( ) . iswritable ( ) ) { <nl> - <nl> synchronized ( this ) { <nl> - system . out . println ( " notify " ) ; <nl> this . notifyall ( ) ; <nl> } <nl> } <nl>
public final class mysqlfrontendhandler extends frontendhandler { <nl> private void writemoreresults ( final querycommandpacket querycommandpacket , final int headpacketscount ) throws sqlexception { <nl> currentsequenceid = headpacketscount ; <nl> while ( querycommandpacket . next ( ) ) { <nl> - <nl> while ( ! context . channel ( ) . iswritable ( ) ) { <nl> synchronized ( mysqlfrontendhandler . this ) { <nl> try { <nl> - system . out . println ( " wait " ) ; <nl> mysqlfrontendhandler . this . wait ( ) ; <nl> } catch ( final interruptedexception ignore ) { <nl> }
public abstract class frontendhandler extends channelinboundhandleradapter { <nl> context . firechannelinactive ( ) ; <nl> channelthreadexecutorgroup . getinstance ( ) . unregister ( context . channel ( ) . id ( ) ) ; <nl> } <nl> - <nl> - @ override <nl> - public void channelwritabilitychanged ( final channelhandlercontext context ) { <nl> - context . firechannelwritabilitychanged ( ) ; <nl> - if ( context . channel ( ) . iswritable ( ) ) { <nl> - <nl> - } <nl> - } <nl> } <nl> mmm a / sharding - proxy / src / main / java / io / shardingsphere / proxy / frontend / mysql / mysqlfrontendhandler . java <nl> ppp b / sharding - proxy / src / main / java / io / shardingsphere / proxy / frontend / mysql / mysqlfrontendhandler . java <nl>
public final class showcreatetablemergedresult extends memorymergedresult { <nl> while ( each . next ( ) ) { <nl> memoryqueryresultrow memoryresultsetrow = new memoryqueryresultrow ( each ) ; <nl> string tablename = memoryresultsetrow . getcell ( 1 ) . tostring ( ) ; <nl> - optional < tablerule > tablerule = shardingrule . tryfindtablerulebyactualtable ( tablename ) ; <nl> - <nl> - if ( tablerule . ispresent ( ) ) { <nl> - string logictablename = tablerule . get ( ) . getlogictable ( ) ; <nl> - memoryresultsetrow . setcell ( 1 , logictablename ) ; <nl> - string createtableddl = memoryresultsetrow . getcell ( 2 ) . tostring ( ) ; <nl> - sqlparsingengine sqlparsingengine = new sqlparsingengine ( databasetype . mysql , createtableddl , shardingrule , null ) ; <nl> - string actualtablename = sqlparsingengine . parse ( true ) . gettables ( ) . getsingletablename ( ) ; <nl> - if ( actualtablename . startswith ( " ` " ) ) { <nl> - logictablename = " ` " + logictablename + " ` " ; <nl> - } <nl> - memoryresultsetrow . setcell ( 2 , createtableddl . replacefirst ( actualtablename , logictablename ) ) ; <nl> - result . add ( memoryresultsetrow ) ; <nl> + tablerule tablerule = shardingrule . gettablerulebyactualtablename ( tablename ) ; <nl> + string logictablename = tablerule . getlogictable ( ) ; <nl> + memoryresultsetrow . setcell ( 1 , logictablename ) ; <nl> + string createtableddl = memoryresultsetrow . getcell ( 2 ) . tostring ( ) ; <nl> + sqlparsingengine sqlparsingengine = new sqlparsingengine ( databasetype . mysql , createtableddl , shardingrule , null ) ; <nl> + string actualtablename = sqlparsingengine . parse ( true ) . gettables ( ) . getsingletablename ( ) ; <nl> + if ( actualtablename . startswith ( " ` " ) ) { <nl> + logictablename = " ` " + logictablename + " ` " ; <nl> } <nl> + memoryresultsetrow . setcell ( 2 , createtableddl . replacefirst ( actualtablename , logictablename ) ) ; <nl> + result . add ( memoryresultsetrow ) ; <nl> } <nl> } <nl> if ( ! result . isempty ( ) ) {
public final class executeupdateresponse implements executeresponse { <nl> long lastinsertid = num ; <nl> for ( okpacket each : packets ) { <nl> affectedrows + = each . getaffectedrows ( ) ; <nl> - <nl> - lastinsertid = each . getlastinsertid ( ) ; <nl> + if ( each . getlastinsertid ( ) > lastinsertid ) { <nl> + lastinsertid = each . getlastinsertid ( ) ; <nl> + } <nl> } <nl> return new commandresponsepackets ( new okpacket ( 1 , affectedrows , lastinsertid ) ) ; <nl> }
public class shardingdatasourcemetadata { <nl> } <nl>  <nl> private map < string , datasourcemetadata > getdatasourcemetadatamap ( final map < string , string > datasourceurls , final shardingrule shardingrule , final databasetype databasetype ) { <nl> - map < string , datasourcemetadata > datasourcemetadatamap = new linkedhashmap < > ( datasourceurls . size ( ) , num ) ; <nl> + map < string , datasourcemetadata > result = new linkedhashmap < > ( datasourceurls . size ( ) , num ) ; <nl> for ( entry < string , string > entry : datasourceurls . entryset ( ) ) { <nl> - datasourcemetadatamap . put ( entry . getkey ( ) , datasourcemetadatafactory . newinstance ( databasetype , entry . getvalue ( ) ) ) ; <nl> + result . put ( entry . getkey ( ) , datasourcemetadatafactory . newinstance ( databasetype , entry . getvalue ( ) ) ) ; <nl> } <nl> - return handlemasterslavedatasources ( shardingrule , datasourcemetadatamap ) ; <nl> + handlemasterslavedatasources ( shardingrule , result ) ; <nl> + return result ; <nl> } <nl>  <nl> - private map < string , datasourcemetadata > handlemasterslavedatasources ( final shardingrule shardingrule , final map < string , datasourcemetadata > datasourcemetadatamap ) { <nl> - map < string , datasourcemetadata > result = new linkedhashmap < > ( ) ; <nl> + private void handlemasterslavedatasources ( final shardingrule shardingrule , final map < string , datasourcemetadata > datasourcemetadatamap ) { <nl> if ( shardingrule . getmasterslaverules ( ) . isempty ( ) ) { <nl> - return datasourcemetadatamap ; <nl> + return ; <nl> } <nl> + collection < string > toremovedkeys = new linkedlist < > ( ) ; <nl> for ( entry < string , datasourcemetadata > entry : datasourcemetadatamap . entryset ( ) ) { <nl> - optional < masterslaverule > masterslaverule = shardingrule . findmasterslaverule ( entry . getkey ( ) ) ; <nl> - <nl> + final optional < masterslaverule > masterslaverule = shardingrule . findmasterslaverule ( entry . getkey ( ) ) ; <nl> if ( masterslaverule . ispresent ( ) & & masterslaverule . get ( ) . getmasterdatasourcename ( ) . equals ( entry . getkey ( ) ) ) { <nl> - result . put ( masterslaverule . get ( ) . getname ( ) , entry . getvalue ( ) ) ; <nl> + toremovedkeys . add ( masterslaverule . get ( ) . getmasterdatasourcename ( ) ) ; <nl> + toremovedkeys . addall ( masterslaverule . get ( ) . getslavedatasourcenames ( ) ) ; <nl> + datasourcemetadatamap . put ( masterslaverule . get ( ) . getname ( ) , entry . getvalue ( ) ) ; <nl> } <nl> } <nl> - return result ; <nl> + removedatasourcemetadata ( datasourcemetadatamap , toremovedkeys ) ; <nl> + } <nl> + <nl> + private void removedatasourcemetadata ( final map < string , datasourcemetadata > datasourcemetadatamap , final collection < string > toremovedkeys ) { <nl> + for ( string each : toremovedkeys ) { <nl> + datasourcemetadatamap . remove ( each ) ; <nl> + } <nl> } <nl>  <nl> / * *
public final class preparedstatementregistry { <nl> * @ param sql sql <nl> * @ return statement id <nl> * / <nl> - <nl> public int register ( final string sql ) { <nl> - integer result = sqltostatementidmap . get ( sql ) ; <nl> - if ( null ! = result ) { <nl> - return result ; <nl> - } <nl> int statementid = sequence . incrementandget ( ) ; <nl> - statementidtosqlmap . putifabsent ( statementid , sql ) ; <nl> - sqltostatementidmap . putifabsent ( sql , statementid ) ; <nl> + integer previousstatementid = sqltostatementidmap . putifabsent ( sql , statementid ) ; <nl> + if ( null = = previousstatementid ) { <nl> + statementidtosqlmap . putifabsent ( statementid , sql ) ; <nl> + } else { <nl> + return previousstatementid ; <nl> + } <nl> return statementid ; <nl> }
public abstract class baseddlintegratetest extends singleintegratetest { <nl> } <nl>  <nl> protected void assertmetadata ( final connection connection ) throws ioexception , jaxbexception , sqlexception { <nl> - <nl> if ( null = = assertion . getexpecteddatafile ( ) ) { <nl> + log . warn ( " have empty expecteddatafile ` { } ` " , super . getsql ( ) ) ; <nl> return ; <nl> } <nl> dataset expected ;
public final class pathtree { <nl> if ( realpath . equals ( rootnode . get ( ) . getkey ( ) ) ) { <nl> return rootnode . get ( ) ; <nl> } <nl> - <nl> - iterator < string > iterator = keyiterator ( realpath ) ; <nl> - if ( iterator . hasnext ( ) ) { <nl> - return rootnode . get ( ) . get ( iterator ) ; <nl> + <nl> + pathresolve pathresolve = new pathresolve ( realpath ) ; <nl> + pathresolve . next ( ) ; <nl> + if ( pathresolve . isend ( ) ) { <nl> + log . info ( " path node get ( ) hit root ! " ) ; <nl> + return rootnode . get ( ) ; <nl> } <nl> - log . debug ( " { } not exist " , realpath ) ; <nl> - return null ; <nl> + return rootnode . get ( ) . get ( pathresolve ) ; <nl> } <nl>  <nl> / * *
<nl> package io . shardingsphere . transaction . xa ; <nl>  <nl> import com . atomikos . icatch . jta . usertransactionmanager ; <nl> + import lombok . accesslevel ; <nl> + import lombok . noargsconstructor ; <nl>  <nl> / * * <nl> * hold singleton atomikos usertransaction . <nl> * <nl> * @ author zhaojun <nl> * / <nl> + @ noargsconstructor ( access = accesslevel . private ) <nl> public final class atomikosusertransaction { <nl>  <nl> - <nl> - private static volatile usertransactionmanager transactionmanager ; <nl> + private static final usertransactionmanager transaction_manager = new usertransactionmanager ( ) ; <nl>  <nl> / * * <nl> - * get singleton { @ code usertransactionmanager } lazily . <nl> + * get singleton of { @ code usertransactionmanager } . <nl> * <nl> * @ return { @ code usertransactionmanager } <nl> * / <nl> public static usertransactionmanager getinstance ( ) { <nl> - if ( null = = transactionmanager ) { <nl> - synchronized ( atomikosusertransaction . class ) { <nl> - if ( null = = transactionmanager ) { <nl> - transactionmanager = new usertransactionmanager ( ) ; <nl> - } <nl> - } <nl> - } <nl> - return transactionmanager ; <nl> + return transaction_manager ; <nl> } <nl> }
public final class comfieldlistpacket implements querycommandpacket , commandpack <nl> public commandresponsepackets execute ( ) { <nl> log . debug ( " table name received for sharding - proxy : { } " , table ) ; <nl> log . debug ( " field wildcard received for sharding - proxy : { } " , fieldwildcard ) ; <nl> - <nl> databasepacket headpacket = backendhandler . execute ( ) . getheadpacket ( ) ; <nl> return headpacket instanceof errpacket ? new commandresponsepackets ( headpacket ) : new commandresponsepackets ( new dummypacket ( ) ) ; <nl> } <nl>
public abstract class jdbcexecuteworker implements callable < commandresponsepacke <nl> return execute ( ) ; <nl> } catch ( final sqlexception ex ) { <nl> return new commandresponsepackets ( new errpacket ( 1 , ex ) ) ; <nl> - } finally { <nl> - <nl> - mastervisitedmanager . clear ( ) ; <nl> } <nl> } <nl>  <nl>
public abstract class jdbcexecuteworker implements callable < commandresponsepacke <nl> resultlist . add ( resultset . getobject ( columnindex ) ) ; <nl> } <nl> } <nl> - <nl> - resultlist . setiterator ( resultlist . getresultlist ( ) . iterator ( ) ) ; <nl> + resultlist . iterator ( ) ; <nl> jdbcbackendhandler . getresultlists ( ) . add ( resultlist ) ; <nl> } <nl> return getheaderpackets ( resultset . getmetadata ( ) ) ; <nl> } <nl>  <nl> - protected abstract boolean executesql ( ) throws sqlexception ; <nl> + protected abstract boolean executesql ( boolean isreturngeneratedkeys ) throws sqlexception ; <nl>  <nl> private commandresponsepackets getheaderpackets ( final resultsetmetadata resultsetmetadata ) throws sqlexception { <nl> int currentsequenceid = num ; <nl> mmm a / sharding - proxy / src / main / java / io / shardingsphere / proxy / backend / common / jdbc / statement / jdbcstatementexecuteworker . java <nl> ppp b / sharding - proxy / src / main / java / io / shardingsphere / proxy / backend / common / jdbc / statement / jdbcstatementexecuteworker . java <nl>
import java . util . logging . logger ; <nl> public abstract class abstractdatasourceadapter extends abstractunsupportedoperationdatasource { <nl>  <nl> static { <nl> - <nl> + transactionloader . load ( ) ; <nl> } <nl>  <nl> @ getter
public final class schemaenvironmentmanager { <nl> connection connection = datasource . getconnection ( ) ; <nl> stringreader stringreader = new stringreader ( joiner . on ( " ; \n " ) . skipnulls ( ) . join ( generatecreatedatabasesqls ( each , databaseinitialization . getdatabases ( ) ) ) ) ) { <nl> runscript . execute ( connection , stringreader ) ; <nl> - } catch ( final sqlexception ex ) { <nl> - <nl> } <nl> } <nl> } <nl>
public final class schemaenvironmentmanager { <nl> * @ param shardingruletype sharding rule type <nl> * @ throws jaxbexception jaxb exception <nl> * @ throws ioexception io exception <nl> + * @ throws sqlexception sql exception <nl> * / <nl> - public static void createtable ( final string shardingruletype ) throws jaxbexception , ioexception { <nl> + public static void createtable ( final string shardingruletype ) throws jaxbexception , ioexception , sqlexception { <nl> for ( databasetype each : integratetestenvironment . getinstance ( ) . getdatabasetypes ( ) ) { <nl> schemaenvironment databaseenvironmentschema = unmarshal ( environmentpath . getdatabaseenvironmentresourcefile ( shardingruletype ) ) ; <nl> createtable ( databaseenvironmentschema , each ) ; <nl> } <nl> } <nl>  <nl> - private static void createtable ( final schemaenvironment databaseenvironmentschema , final databasetype databasetype ) { <nl> + private static void createtable ( final schemaenvironment databaseenvironmentschema , final databasetype databasetype ) throws sqlexception { <nl> for ( string each : databaseenvironmentschema . getdatabases ( ) ) { <nl> datasource datasource = datasourceutil . createdatasource ( databasetype , each ) ; <nl> try ( connection connection = datasource . getconnection ( ) ; <nl> stringreader stringreader = new stringreader ( stringutils . join ( databaseenvironmentschema . gettablecreatesqls ( ) , " ; \n " ) ) ) { <nl> runscript . execute ( connection , stringreader ) ; <nl> - } catch ( final sqlexception ex ) { <nl> - <nl> } <nl> } <nl> } <nl> mmm a / sharding - jdbc / src / test / resources / asserts / env / masterslave / schema . xml <nl> ppp b / sharding - jdbc / src / test / resources / asserts / env / masterslave / schema . xml <nl>
public final class starttest { <nl> } <nl>  <nl> @ beforeclass <nl> - <nl> public static void createdatabasesandtables ( ) throws jaxbexception , ioexception { <nl> if ( isinitialized ) { <nl> isinitialized = false ; <nl>
public final class starttest { <nl> } <nl>  <nl> @ afterclass <nl> - <nl> public static void dropdatabases ( ) throws jaxbexception , ioexception { <nl> if ( iscleaned ) { <nl> for ( string each : datasetassertloader . getshardingruletypes ( ) ) { <nl>
public final class starttest { <nl> } <nl>  <nl> @ test <nl> - <nl> - public void test ( ) throws jaxbexception , saxexception , parseexception , ioexception , xpathexpressionexception , sqlexception , parserconfigurationexception { <nl> + public void test ( ) throws jaxbexception , parseexception , ioexception , sqlexception { <nl> if ( ! databasetypeenvironment . isenabled ( ) ) { <nl> return ; <nl> }
public final class databaseutil { <nl> throw new unsupportedoperationexception ( string . format ( " cannot support type : ' % s ' " , sqlvalue . getvalue ( ) . getclass ( ) ) ) ; <nl> } <nl>  <nl> - <nl> - private static void setparameter ( final preparedstatement preparedstatement , final int index , final string value , final string type ) throws sqlexception , parseexception { <nl> - if ( null = = type | | " varchar " . equals ( type ) | | " char " . equals ( type ) | | " string " . equals ( type ) ) { <nl> - preparedstatement . setstring ( index , value ) ; <nl> - return ; <nl> - } <nl> - if ( " int " . equals ( type ) ) { <nl> - preparedstatement . setint ( index , integer . valueof ( value ) ) ; <nl> - return ; <nl> - } <nl> - if ( " numeric " . equals ( type ) & & ! value . contains ( " / / . " ) ) { <nl> - preparedstatement . setlong ( index , long . valueof ( value ) ) ; <nl> - return ; <nl> - } <nl> - if ( " numeric " . equals ( type ) & & value . contains ( " / / . " ) ) { <nl> - preparedstatement . setdouble ( index , double . valueof ( value ) ) ; <nl> - return ; <nl> - } <nl> - if ( " datetime " . equals ( type ) ) { <nl> - preparedstatement . setdate ( index , new date ( new simpledateformat ( " yyyy - mm - dd " ) . parse ( value ) . gettime ( ) ) ) ; <nl> - return ; <nl> - } <nl> - throw new unsupportedoperationexception ( string . format ( " cannot support type : ' % s ' " , type ) ) ; <nl> - } <nl> - <nl> / * * <nl> * use statement test data update . <nl> * <nl>
<nl>  <nl> package io . shardingjdbc . proxy . backend . common ; <nl>  <nl> - import com . sun . xml . internal . bind . v2 . <nl> import io . netty . channel . channel ; <nl> import io . shardingjdbc . core . constant . databasetype ; <nl> import io . shardingjdbc . core . parsing . parser . sql . sqlstatement ; <nl>
public class usualclient extends baseclient { <nl> list < string > nodes = pathutil . getpathordernodes ( rootnode , key ) ; <nl> nodes . remove ( rootnode ) ; <nl> for ( int i = num ; i < nodes . size ( ) ; i + + ) { <nl> - <nl> - if ( checkexists ( nodes . get ( i ) ) ) { <nl> + try { <nl> + if ( i = = nodes . size ( ) - num ) { <nl> + this . createcurrentonly ( nodes . get ( i ) , value , createmode ) ; <nl> + } else { <nl> + / / this . deleteallchildren ( nodes . get ( i ) ) ; <nl> + this . createcurrentonly ( nodes . get ( i ) , constants . nothing_value , createmode ) ; <nl> + } <nl> + system . out . println ( " not exist and create : " + nodes . get ( i ) ) ; <nl> + } catch ( keeperexception . nodeexistsexception ee ) { <nl> system . out . println ( " exist : " + nodes . get ( i ) ) ; <nl> continue ; <nl> } <nl> - system . out . println ( " not exist : " + nodes . get ( i ) ) ; <nl> - if ( i = = nodes . size ( ) - num ) { <nl> - createcurrentonly ( nodes . get ( i ) , value , createmode ) ; <nl> - } else { <nl> - createcurrentonly ( nodes . get ( i ) , constants . nothing_value , createmode ) ; <nl> - } <nl> } <nl> } <nl>  <nl> mmm a / src / test / java / com / saaavsaaa / client / zookeeper / usualclienttest . java <nl> ppp b / src / test / java / com / saaavsaaa / client / zookeeper / usualclienttest . java <nl>
public class zookeeperclient { <nl> return zookeeper . getchildren ( pathutil . getrealpath ( rootnode , key ) , false ) ; <nl> } <nl>  <nl> - public void create ( string path , byte [ ] data , createmode createmode ) throws keeperexception , interruptedexception { <nl> - <nl> - if ( path . indexof ( " / " ) > - 1 ) { <nl> - system . out . println ( " exist / need op . . = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = " ) ; <nl> - } <nl> - this . zookeeper . create ( path , data , authorities , createmode ) ; <nl> + public void createcurrentpathonly ( string path , byte [ ] data , createmode createmode ) throws keeperexception , interruptedexception { <nl> + zookeeper . create ( pathutil . getrealpath ( rootnode , path ) , data , authorities , createmode ) ; <nl> } <nl>  <nl> - private void createrootnode ( ) throws keeperexception , interruptedexception { <nl> - if ( checkexists ( rootnode ) ) { <nl> + public void createallneedpath ( string path , byte [ ] data , createmode createmode ) throws keeperexception , interruptedexception { <nl> + if ( path . indexof ( " / " ) < - 1 ) { <nl> + this . createcurrentpathonly ( path , data , createmode ) ; <nl> return ; <nl> } <nl> - this . zookeeper . create ( rootnode , new byte [ 0 ] , authorities , createmode . persistent ) ; <nl> + transaction transaction = zookeeper . transaction ( ) ; <nl> + / / sync cache <nl> + stack < string > pathstack = pathutil . getpathnodes ( path ) ; <nl> + while ( ! pathstack . empty ( ) ) { <nl> + string node = pathstack . pop ( ) ; <nl> + / / contrast cache <nl> + if ( ! checkexists ( node ) ) { <nl> + createintransaction ( path , data , createmode , transaction ) ; <nl> + } <nl> + } <nl> + transaction . commit ( ) ; <nl> + } <nl> + <nl> + private transaction createintransaction ( string path , byte [ ] data , createmode createmode , transaction transaction ) { <nl> + return transaction . create ( pathutil . getrealpath ( rootnode , path ) , data , authorities , createmode ) ; <nl> } <nl>  <nl> public void update ( string key , byte [ ] data ) throws keeperexception , interruptedexception { <nl> - this . zookeeper . transaction ( ) . setdata ( pathutil . getrealpath ( rootnode , key ) , data , - 1 ) . commit ( ) ; <nl> + zookeeper . transaction ( ) . setdata ( pathutil . getrealpath ( rootnode , key ) , data , - 1 ) . commit ( ) ; <nl> } <nl>  <nl> public void setrootnode ( string rootnode ) { <nl>
public enum columntype { <nl> throw new illegalargumentexception ( string . format ( " cannot find jdbc type ' % s ' in column type " , jdbctype ) ) ; <nl> } <nl> } <nl> - <nl> - / * * <nl> - * value of description . <nl> - * <nl> - * @ param description description <nl> - * @ return column type enum <nl> - * / <nl> - <nl> - public static columntype valueofdescription ( final string description ) { <nl> - switch ( description ) { <nl> - case " bit " : <nl> - return mysql_type_bit ; <nl> - case " tiny " : <nl> - return mysql_type_tiny ; <nl> - case " int " : <nl> - return mysql_type_int24 ; <nl> - case " bigint " : <nl> - return mysql_type_long ; <nl> - case " decimal " : <nl> - return mysql_type_double ; <nl> - case " char " : <nl> - return mysql_type_string ; <nl> - case " varchar " : <nl> - return mysql_type_varchar ; <nl> - case " date " : <nl> - return mysql_type_date ; <nl> - case " time " : <nl> - return mysql_type_time ; <nl> - case " timestamp " : <nl> - return mysql_type_timestamp ; <nl> - case " blob " : <nl> - return mysql_type_blob ; <nl> - default : <nl> - throw new illegalargumentexception ( string . format ( " cannot find description ' % s ' in column type " , description ) ) ; <nl> - } <nl> - } <nl> }
<nl> < / conditions > <nl> < / parser - result > <nl>  <nl> - < ! - - <nl> < parser - result sql - case - id = " assertupdatewithgeoinpostgresql " parameters = " ' 2017 - 06 - 07 ' num num ' { & quot ; rule2 & quot ; : & quot ; null2 & quot ; } ' num num num num " > <nl> < tables > <nl> < table name = " t_place " / > <nl>
public final class integratesupportedsqlparsingtest extends abstractbaseintegrat <nl> assertgeneratedkeytoken ( actual , expected ) ; <nl> assertmultipleinsertvaluestoken ( actual , expected ) ; <nl> assertorderbytoken ( actual , expected ) ; <nl> - <nl> - / / assertoffsettoken ( actual , expected ) ; <nl> - / / assertrowcounttoken ( actual , expected ) ; <nl> + assertoffsettoken ( actual , expected ) ; <nl> + assertrowcounttoken ( actual , expected ) ; <nl> } <nl>  <nl> private void asserttabletokens ( final list < sqltoken > actual , final sqltokenasserts expected ) { <nl>
public final class conditions { <nl> } <nl> } <nl>  <nl> - <nl> - @ deprecated <nl> - public void add ( final condition condition ) { <nl> - conditions . put ( condition . getcolumn ( ) , condition ) ; <nl> - } <nl> - <nl> / * * <nl> * adjust condition is empty or not . <nl> *
chapter = true <nl> - commit allow javadoc , <nl> - give a meaningful variable name . the name of return value is result ; the name of unit value is each in for each sentence , instead of entry for map iterator . <nl> - name of properties file is camel - case , first letter is lowercase . <nl> - - constant on left and variable on right in conditional statement . <nl> + - constant on left and variable on right in conditional expression . <nl> - the nested loop should extract to a new private method . <nl> - replace nested conditional with guard clauses . <nl> - access permissions for classes and methods should minimal as possible .
chapter = true <nl> - commit allow javadoc , <nl> - give a meaningful variable name . the name of return value is result ; the name of unit value is each in for each sentence , instead of entry for map iterator . <nl> - name of properties file is camel - case , first letter is lowercase . <nl> + - constant on left and variable on right in conditional statement . <nl> - the nested loop should extract to a new private method . <nl> - replace nested conditional with guard clauses . <nl> - access permissions for classes and methods should minimal as possible .
chapter = true <nl> - no unnecessary blank line . <nl> - all logs and java docs are in english . <nl> - commit allow javadoc , <nl> - - static import is forbidden . <nl> - give a meaningful variable name . the name of return value is result ; the name of unit value is each in for each sentence , instead of entry for map iterator . <nl> - name of properties file is camel - case , first letter is lowercase . <nl> - the nested loop should extract to a new private method . <nl>
the project consists of five distinct codebases : jdbc driver , proxy , opentracing <nl>  <nl> * https : / / github . com / shardingjdbc / sharding - jdbc <nl>  <nl> - * https : <nl> - <nl> * https : / / github . com / shardingjdbc / sharding - opentracing <nl>  <nl> * https : / / github . com / shardingjdbc / sharding - example <nl>
use jdbc connect databases without redirect cost for java application , best perf <nl> database router . deploy as a stateless server , support mysql protocol for now . <nl>  <nl> * use standard mysql protocol , application do not care about whether proxy or real mysql . <nl> - * any mysql command line and ui workbench supported in theoretically . ( <nl> + * any mysql command line and ui workbench supported in theoretically . mysql workbench are fully compatible right now . <nl>  <nl> ! [ sharding - jdbc - server architecture ] ( http : / / ovfotjrsi . bkt . clouddn . com / server_architecture_en . png )
public final class comquerypacket extends abstractcommandpacket { <nl> public list < abstractmysqlsentpacket > execute ( ) { <nl> list < abstractmysqlsentpacket > result = new linkedlist < > ( ) ; <nl> int currentsequenceid = getsequenceid ( ) ; <nl> - <nl> - datasource datasource ; <nl> - try { <nl> - datasource = shardingdatasourcefactory . createdatasource ( new file ( comquerypacket . class . getresource ( " / meta - inf / sharding - config . yaml " ) . getfile ( ) ) ) ; <nl> - } catch ( final ioexception | sqlexception ex ) { <nl> - throw new shardingjdbcexception ( ex ) ; <nl> - } <nl> try ( <nl> - connection conn = datasource . getconnection ( ) ; <nl> + connection conn = datasourcemanager . getinstance ( ) . getdatasource ( ) . getconnection ( ) ; <nl> statement statement = conn . createstatement ( ) ) { <nl> statement . execute ( sql ) ; <nl> resultset resultset = statement . getresultset ( ) ;
<nl> < data parameter = " 1 , 9 , 1000 , 1909 " expected = " select_aggregate / selectcountwithbindingtable_1 . xml " / > <nl> < / sharding - rule > <nl> < / sql > <nl> - < ! - - <nl> - < ! - - <nl> < sql id = " assertselectaliaswithkeyword " > <nl> < sharding - rule value = " tbl " > <nl> < data parameter = " 100000 " expected = " select / selectaliaswithkeyword . xml " / > <nl> < / sharding - rule > <nl> < / sql > <nl> - - - > <nl> < / sqls > <nl> mmm a / sharding - jdbc - core / src / test / resources / parser / select . xml <nl> ppp b / sharding - jdbc - core / src / test / resources / parser / select . xml <nl>
<nl> < aggregation - select - item inner - expression = " ( * ) " aggregation - type = " count " alias = " items_count " / > <nl> < / aggregation - select - items > <nl> < / assert > <nl> - < ! - - <nl> - < ! - - <nl> < assert id = " assertselectaliaswithkeyword " parameters = " 1 " > <nl> < tables > <nl> - < table name = " t_order_item " / > <nl> + < table name = " t_order_item " alias = " item " / > <nl> < / tables > <nl> < table - tokens > <nl> - < table - token begin - position = " 14 " original - literals = " t_order_item " / > <nl> + < table - token begin - position = " 34 " original - literals = " t_order_item " / > <nl> < / table - tokens > <nl> - < order - by - columns > <nl> - < order - by - column name = " item_id " order - by - type = " asc " / > <nl> - < / order - by - columns > <nl> + < conditions > <nl> + < condition column - name = " item_id " table - name = " t_order_item " operator = " equal " > <nl> + < value index = " 0 " literal = " 1 " type = " int " / > <nl> + < / condition > <nl> + < / conditions > <nl> < / assert > <nl> - - - > <nl> < / asserts >
public final class sqlrewriteengine { <nl> } <nl>  <nl> private void appendtabletoken ( final sqlbuilder sqlbuilder , final tabletoken tabletoken , final int count , final list < sqltoken > sqltokens ) { <nl> - <nl> - string tablename = <nl> - sqlutil . getoriginalvalue ( sqlstatement . gettables ( ) . gettablenames ( ) . contains ( tabletoken . gettablename ( ) ) ? tabletoken . gettablename ( ) : tabletoken . getoriginalliterals ( ) , databasetype ) ; <nl> - / / string tablename = tabletoken . gettablename ( ) ; <nl> - sqlbuilder . appendtable ( tablename ) ; <nl> + sqlbuilder . appendtable ( tabletoken . gettablename ( ) ) ; <nl> int beginposition = tabletoken . getbeginposition ( ) + tabletoken . getoriginalliterals ( ) . length ( ) ; <nl> appendrest ( sqlbuilder , count , sqltokens , beginposition ) ; <nl> }
public class shardingdatasource extends abstractdatasourceadapter implements aut <nl> * @ throws sqlexception sql exception <nl> * / <nl> public void renew ( final shardingrule newshardingrule , final properties newprops ) throws sqlexception { <nl> - <nl> - / / preconditions . checkstate ( getdatabasetype ( ) = = getdatabasetype ( newshardingrule . getdatasourcemap ( ) . values ( ) ) , " cannot change database type dynamically . " ) ; <nl> shardingproperties newshardingproperties = new shardingproperties ( null = = newprops ? new properties ( ) : newprops ) ; <nl> int originalexecutorsize = shardingproperties . getvalue ( shardingpropertiesconstant . executor_size ) ; <nl> int newexecutorsize = newshardingproperties . getvalue ( shardingpropertiesconstant . executor_size ) ;
public class shardingdatasource extends abstractdatasourceadapter implements aut <nl> * @ throws sqlexception sql exception <nl> * / <nl> public void renew ( final shardingrule newshardingrule , final properties newprops ) throws sqlexception { <nl> - <nl> - / / preconditions . checkstate ( getdatabasetype ( ) = = getdatabasetype ( newshardingrule . getdatasourcemap ( ) . values ( ) ) , " cannot change database type dynamically . " ) ; <nl> + if ( databasetype . circuitbreaker ! = getdatabasetype ( ) ) { <nl> + preconditions . checkstate ( getdatabasetype ( ) = = getdatabasetype ( newshardingrule . getdatasourcemap ( ) . values ( ) ) , " cannot change database type dynamically . " ) ; <nl> + } <nl> shardingproperties newshardingproperties = new shardingproperties ( null = = newprops ? new properties ( ) : newprops ) ; <nl> int originalexecutorsize = shardingproperties . getvalue ( shardingpropertiesconstant . executor_size ) ; <nl> int newexecutorsize = newshardingproperties . getvalue ( shardingpropertiesconstant . executor_size ) ;
public class springmasterslavedatasource extends masterslavedatasource implement <nl>  <nl> @ override <nl> public void renew ( final masterslaverule masterslaverule ) throws sqlexception { <nl> - <nl> datasourcebeanutil . createdatasourcebean ( applicationcontext , masterslaverule . getmasterdatasourcename ( ) , masterslaverule . getmasterdatasource ( ) ) ; <nl> for ( entry < string , datasource > entry : masterslaverule . getslavedatasourcemap ( ) . entryset ( ) ) { <nl> datasourcebeanutil . createdatasourcebean ( applicationcontext , entry . getkey ( ) , entry . getvalue ( ) ) ; <nl> mmm a / sharding - jdbc - spring / sharding - jdbc - spring - namespace / src / main / java / io / shardingjdbc / spring / datasource / springshardingdatasource . java <nl> ppp b / sharding - jdbc - spring / sharding - jdbc - spring - namespace / src / main / java / io / shardingjdbc / spring / datasource / springshardingdatasource . java <nl>
public class springshardingdatasource extends shardingdatasource implements appl <nl>  <nl> @ override <nl> public void renew ( final shardingrule newshardingrule , final properties newprops ) throws sqlexception { <nl> - <nl> for ( entry < string , datasource > entry : newshardingrule . getdatasourcemap ( ) . entryset ( ) ) { <nl> if ( entry . getvalue ( ) instanceof masterslavedatasource ) { <nl> for ( entry < string , datasource > masterslaveentry : ( ( masterslavedatasource ) entry . getvalue ( ) ) . getalldatasources ( ) . entryset ( ) ) {
public class shardingruleconfiguration { <nl> * @ return sharding rule <nl> * / <nl> public shardingrule build ( final map < string , datasource > datasourcemap ) throws sqlexception { <nl> - <nl> - / / preconditions . checknotnull ( datasources , " datasources cannot be null . " ) ; <nl> + preconditions . checknotnull ( datasourcemap , " datasources cannot be null . " ) ; <nl> + preconditions . checkargument ( ! datasourcemap . isempty ( ) , " datasources cannot be null . " ) ; <nl> collection < tablerule > tablerules = new linkedlist < > ( ) ; <nl> for ( tableruleconfiguration each : tableruleconfigs ) { <nl> tablerules . add ( each . build ( datasourcemap ) ) ;
public class shardingjdbcdatasourcebeandefinitionparser extends abstractbeandefi <nl> factory . addpropertyvalue ( " datasources " , parsedatasources ( shardingruleelement , parsercontext ) ) ; <nl> parsedefaultdatasource ( factory , shardingruleelement ) ; <nl> factory . addpropertyvalue ( " tableruleconfigs " , parsetablerulesconfig ( shardingruleelement ) ) ; <nl> - <nl> - / / factory . addpropertyvalue ( " bindingtables " , parsebindingtablesconfig ( shardingruleelement ) ) ; <nl> - factory . addpropertyvalue ( " defaulttableshardingstrategyconfig " , parsedefaultdatabasestrategyconfig ( shardingruleelement ) ) ; <nl> + factory . addpropertyvalue ( " bindingtablegroups " , parsebindingtablesconfig ( shardingruleelement ) ) ; <nl> + factory . addpropertyvalue ( " defaultdatabaseshardingstrategyconfig " , parsedefaultdatabasestrategyconfig ( shardingruleelement ) ) ; <nl> factory . addpropertyvalue ( " defaulttableshardingstrategyconfig " , parsedefaulttablestrategyconfig ( shardingruleelement ) ) ; <nl> parsekeygenerator ( factory , shardingruleelement ) ; <nl> return factory . getbeandefinition ( ) ; <nl>
public class shardingjdbcdatasourcebeandefinitionparser extends abstractbeandefi <nl> return factory . getbeandefinition ( ) ; <nl> } <nl>  <nl> - <nl> - / / private list < beandefinition > parsebindingtablesconfig ( final element element ) { <nl> - / / element bindingtableruleselement = domutils . getchildelementbytagname ( element , shardingjdbcdatasourcebeandefinitionparsertag . binding_table_rules_tag ) ; <nl> - / / if ( null = = bindingtableruleselement ) { <nl> - / / return collections . emptylist ( ) ; <nl> - / / } <nl> - / / list < element > bindingtableruleelements = domutils . getchildelementsbytagname ( bindingtableruleselement , shardingjdbcdatasourcebeandefinitionparsertag . binding_table_rule_tag ) ; <nl> - / / beandefinitionbuilder bindingtablerulefactory = beandefinitionbuilder . rootbeandefinition ( bindingtableruleconfig . class ) ; <nl> - / / list < beandefinition > result = new managedlist < > ( bindingtableruleelements . size ( ) ) ; <nl> - / / for ( element bindingtableruleelement : bindingtableruleelements ) { <nl> - / / bindingtablerulefactory . addpropertyvalue ( " tablenames " , bindingtableruleelement . getattribute ( shardingjdbcdatasourcebeandefinitionparsertag . logic_tables_attribute ) ) ; <nl> - / / result . add ( bindingtablerulefactory . getbeandefinition ( ) ) ; <nl> - / / } <nl> - / / return result ; <nl> - / / } <nl> + private list < string > parsebindingtablesconfig ( final element element ) { <nl> + element bindingtableruleselement = domutils . getchildelementbytagname ( element , shardingjdbcdatasourcebeandefinitionparsertag . binding_table_rules_tag ) ; <nl> + if ( null = = bindingtableruleselement ) { <nl> + return collections . emptylist ( ) ; <nl> + } <nl> + list < element > bindingtableruleelements = domutils . getchildelementsbytagname ( bindingtableruleselement , shardingjdbcdatasourcebeandefinitionparsertag . binding_table_rule_tag ) ; <nl> + list < string > result = new linkedlist < > ( ) ; <nl> + for ( element bindingtableruleelement : bindingtableruleelements ) { <nl> + result . add ( bindingtableruleelement . getattribute ( shardingjdbcdatasourcebeandefinitionparsertag . logic_tables_attribute ) ) ; <nl> + } <nl> + return result ; <nl> + } <nl>  <nl> private beandefinition parsedefaultdatabasestrategyconfig ( final element element ) { <nl> return parsedefaultstrategyconfig ( element , shardingjdbcdatasourcebeandefinitionparsertag . default_database_strategy_attribute ) ;
import java . util . treeset ; <nl> * <nl> * @ author zhangliang <nl> * / <nl> - @ getter <nl> public final class inlineshardingstrategy implements shardingstrategy { <nl>  <nl> private final string shardingcolumn ; <nl>  <nl> - private final closure < ? > closuretemplate ; <nl> - <nl> - <nl> - private final string logroot = " logroot " ; <nl> + private final closure < ? > closure ; <nl>  <nl> public inlineshardingstrategy ( final string shardingcolumn , final string inlineexpression ) { <nl> this . shardingcolumn = shardingcolumn ; <nl> - binding binding = new binding ( ) ; <nl> - binding . setvariable ( " log " , loggerfactory . getlogger ( logroot . trim ( ) ) ) ; <nl> - closuretemplate = ( closure ) new groovyshell ( binding ) . evaluate ( joiner . on ( " " ) . join ( " { it - > \ " " , inlineexpression . trim ( ) , " \ " } " ) ) ; <nl> + closure = ( closure ) new groovyshell ( ) . evaluate ( joiner . on ( " " ) . join ( " { it - > \ " " , inlineexpression . trim ( ) , " \ " } " ) ) ; <nl> } <nl>  <nl> @ override <nl>
<nl> < table name = " t_temp " / > <nl> < / tables > <nl> < / assert > <nl> - < ! - - <nl> - < ! - - < assert id = " assertcreatetableifnotexist " > - - > <nl> - < ! - - < tables > - - > <nl> - < ! - - < table name = " t_temp " / > - - > <nl> - < ! - - < / tables > - - > <nl> - < ! - - < / assert > - - > <nl> + < assert id = " assertcreatetableifnotexist " > <nl> + < tables > <nl> + < table name = " t_temp " / > <nl> + < / tables > <nl> + < / assert > <nl> < / asserts >
<nl> < data parameter = " 1000 " expected = " select_relation / selectwithinnerjoin . xml " / > <nl> < / sharding - rule > <nl> < / sql > <nl> - < ! - - <nl> - < ! - - < sql id = " assertselectwithjoinusing " > - - > <nl> - < ! - - < sharding - rule value = " tbl " > - - > <nl> - < ! - - < data parameter = " 1000 " expected = " select_relation / selectwithjoinusing . xml " / > - - > <nl> - < ! - - < / sharding - rule > - - > <nl> - < ! - - < / sql > - - > <nl> + < sql id = " assertselectwithjoinusing " > <nl> + < sharding - rule value = " tbl " > <nl> + < data parameter = " 1000 " expected = " select_relation / selectwithjoinusing . xml " / > <nl> + < / sharding - rule > <nl> + < / sql > <nl> < / sqls > <nl> mmm a / sharding - jdbc - core / src / test / resources / sql / dql / select_relation . xml <nl> ppp b / sharding - jdbc - core / src / test / resources / sql / dql / select_relation . xml <nl>
<nl> < order - by - column owner = " i " name = " item_id " alias = " order_by_derived_0 " order - by - type = " asc " / > <nl> < / order - by - columns > <nl> < / assert > <nl> - < ! - - <nl> - < ! - - < assert id = " assertselectcountwithexpression " > - - > <nl> - < ! - - < tables > - - > <nl> - < ! - - < table name = " t_order " alias = " o " / > - - > <nl> - < ! - - < / tables > - - > <nl> - < ! - - < / assert > - - > <nl> + < assert id = " assertselectcountwithexpression " > <nl> + < tables > <nl> + < table name = " t_order " alias = " o " / > <nl> + < / tables > <nl> + < aggregation - select - items > <nl> + < aggregation - select - item aggregation - type = " count " inner - expression = " ( o . order_id ) " / > <nl> + < / aggregation - select - items > <nl> + < / assert > <nl> < assert id = " assertselectcountwithbindingtable " parameters = " 1 , 2 , 9 , 10 " > <nl> < tables > <nl> < table name = " t_order " alias = " o " / > <nl> mmm a / sharding - jdbc - core / src / test / resources / sql / dql / select_expression . xml <nl> ppp b / sharding - jdbc - core / src / test / resources / sql / dql / select_expression . xml <nl>
<nl> < ? xml version = " 1 . 0 " encoding = " utf - 8 " ? > <nl> < asserts > <nl> - < ! - - <nl> - < ! - - < assert id = " assertselectexpressionwithsingletable " > - - > <nl> - < ! - - < tables > - - > <nl> - < ! - - < table name = " t_order " alias = " o " / > - - > <nl> - < ! - - < / tables > - - > <nl> - < ! - - < order - by - columns > - - > <nl> - < ! - - < order - by - column owner = " o " name = " order_id " order - by - type = " desc " / > - - > <nl> - < ! - - < / order - by - columns > - - > <nl> - < ! - - < / assert > - - > <nl> + < assert id = " assertselectexpressionwithsingletable " > <nl> + < tables > <nl> + < table name = " t_order " alias = " o " / > <nl> + < / tables > <nl> + < order - by - columns > <nl> + < order - by - column owner = " o " name = " order_id " alias = " order_by_derived_0 " order - by - type = " asc " / > <nl> + < / order - by - columns > <nl> + < / assert > <nl> < assert id = " assertselectdatefuncwithsingletable " > <nl> < tables > <nl> < table name = " t_order_item " alias = " i " / >
<nl> < / condition > <nl> < / conditions > <nl> < / assert > <nl> - < ! - - <nl> - < ! - - < assert id = " assertinsertwithgeneratekeycolumn " parameters = " 10000 , 1000 , 10 " > - - > <nl> - < ! - - < tables > - - > <nl> - < ! - - < table name = " t_order_item " / > - - > <nl> - < ! - - < / tables > - - > <nl> - < ! - - < conditions > - - > <nl> - < ! - - < condition column - name = " order_item_id " table - name = " t_order_item " operator = " equal " > - - > <nl> - < ! - - < value index = " 0 " literal = " 10000 " type = " int " / > - - > <nl> - < ! - - < / condition > - - > <nl> - < ! - - < condition column - name = " order_id " table - name = " t_order_item " operator = " equal " > - - > <nl> - < ! - - < value index = " 1 " literal = " 1000 " type = " int " / > - - > <nl> - < ! - - < / condition > - - > <nl> - < ! - - < condition column - name = " user_id " table - name = " t_order_item " operator = " equal " > - - > <nl> - < ! - - < value index = " 2 " literal = " 10 " type = " int " / > - - > <nl> - < ! - - < / condition > - - > <nl> - < ! - - < / conditions > - - > <nl> - < ! - - < / assert > - - > <nl> + < assert id = " assertinsertwithgeneratekeycolumn " parameters = " 10000 , 1000 , 10 " > <nl> + < tables > <nl> + < table name = " t_order_item " / > <nl> + < / tables > <nl> + < conditions > <nl> + < condition column - name = " item_id " table - name = " t_order_item " operator = " equal " > <nl> + < value index = " 0 " literal = " 10000 " type = " int " / > <nl> + < / condition > <nl> + < condition column - name = " order_id " table - name = " t_order_item " operator = " equal " > <nl> + < value index = " 1 " literal = " 1000 " type = " int " / > <nl> + < / condition > <nl> + < condition column - name = " user_id " table - name = " t_order_item " operator = " equal " > <nl> + < value index = " 2 " literal = " 10 " type = " int " / > <nl> + < / condition > <nl> + < / conditions > <nl> + < / assert > <nl> < assert id = " assertinsertwithoutgeneratekeycolumn " parameters = " 1000 , 10 " > <nl> < tables > <nl> < table name = " t_order_item " / > <nl> mmm a / sharding - jdbc - core / src / test / resources / sql / dml / insert . xml <nl> ppp b / sharding - jdbc - core / src / test / resources / sql / dml / insert . xml <nl>
<nl> < limit offset = " 4 " row - count = " 5 " offset - index = " - 1 " row - count - index = " - 1 " / > <nl> < / assert > <nl>  <nl> - < ! - - <nl> < assert id = " assertsubselectforlimit " sql = " select * from ( select * from order where num = num limit num , 4 ) " expected - sql = " select * from ( select * from [ token ( order ) ] where num = num limit num , num ) " > <nl> < tables > <nl> < table name = " order " / > <nl> < / tables > <nl> + < limit offset = " 5 " row - count = " 4 " offset - index = " - 1 " row - count - index = " - 1 " / > <nl> < / assert > <nl> - - - > <nl> < / asserts >
public class standardgifdecoder implements gifdecoder { <nl> if ( currentframe . lct ! = null & & header . bgindex = = currentframe . transindex ) { <nl> c = color_transparent_black ; <nl> } <nl> - } else if ( framepointer = = num ) { <nl> - <nl> - / / first frame isn ' t actually transparent . for now , it ' s simpler and safer to assume <nl> - / / drawing a transparent background means the gif contains transparency . <nl> - isfirstframetransparent = true ; <nl> } <nl> / / the area used by the graphic must be restored to the background color . <nl> int downsampledih = previousframe . ih / samplesize ; <nl>
class resourcecachegenerator implements datafetchergenerator , <nl> if ( file . class . equals ( helper . gettranscodeclass ( ) ) ) { <nl> return false ; <nl> } <nl> - <nl> - / / all loads to fail . without this assertion it causes loads to miss the disk cache <nl> - / / unnecessarily <nl> - / / throw new illegalstateexception ( <nl> - / / " failed to find any load path from " + helper . getmodelclass ( ) + " to " <nl> - / / + helper . gettranscodeclass ( ) ) ; <nl> + throw new illegalstateexception ( <nl> + " failed to find any load path from " + helper . getmodelclass ( ) + " to " <nl> + + helper . gettranscodeclass ( ) ) ; <nl> } <nl> while ( modelloaders = = null | | ! hasnextmodelloader ( ) ) { <nl> resourceclassindex + + ;
import java . util . treemap ; <nl> public class sizeconfigstrategy implements lrupoolstrategy { <nl> private static final int max_size_multiple = num ; <nl>  <nl> - <nl> - / / yet tested argb_8888 / rgba_f16 re - use thoroughly yet . <nl> - private static final bitmap . config [ ] rgba_f16_in_configs ; <nl> + private static final bitmap . config [ ] argb_8888_in_configs ; <nl> static { <nl> + bitmap . config [ ] result = <nl> + new bitmap . config [ ] { <nl> + bitmap . config . argb_8888 , <nl> + / / the value returned by bitmaps with the hidden bitmap config . <nl> + null , <nl> + } ; <nl> if ( build . version . sdk_int > = build . version_codes . o ) { <nl> - rgba_f16_in_configs = new bitmap . config [ ] { bitmap . config . rgba_f16 } ; <nl> - } else { <nl> - / / this will never be used pre o . <nl> - rgba_f16_in_configs = new bitmap . config [ 0 ] ; <nl> + result = arrays . copyof ( result , result . length + num ) ; <nl> + result [ result . length - num ] = config . rgba_f16 ; <nl> } <nl> + argb_8888_in_configs = result ; <nl> } <nl> + private static final bitmap . config [ ] rgba_f16_in_configs = argb_8888_in_configs ; <nl>  <nl> - private static final bitmap . config [ ] argb_8888_in_configs = <nl> - new bitmap . config [ ] { <nl> - bitmap . config . argb_8888 , <nl> - / / the value returned by bitmaps with the hidden bitmap config . <nl> - null , <nl> - } ; <nl> / / we probably could allow argb_4444 and rgb_565 to decode into each other , but argb_4444 is <nl> / / deprecated and we ' d rather be safe . <nl> private static final bitmap . config [ ] rgb_565_in_configs =
subprojects { project - > <nl> lintoptions { <nl> warningsaserrors true <nl> quiet true <nl> - <nl> - disable " gradledependency " <nl> } <nl> } <nl> } <nl> mmm a / gradle . properties <nl> ppp b / gradle . properties <nl>
env : <nl> matrix : <nl> - component = unit <nl> - component = firebase <nl> - # <nl> - # - component = instrumentation android_target = 16 <nl> - # - component = instrumentation android_target = 17 <nl> - # - component = instrumentation android_target = 18 <nl> + - component = instrumentation android_target = 16 <nl> + - component = instrumentation android_target = 17 <nl> + - component = instrumentation android_target = 18 <nl> - component = instrumentation android_target = 19 <nl> - component = instrumentation android_target = 21 <nl> - component = instrumentation android_target = 22 <nl> mmm a / scripts / travis_create_emulator . sh <nl> ppp b / scripts / travis_create_emulator . sh <nl>
public final class transformationutils { <nl> private static final int circle_crop_paint_flags = paint_flags | paint . anti_alias_flag ; <nl> private static final paint circle_crop_shape_paint = new paint ( circle_crop_paint_flags ) ; <nl> private static final paint circle_crop_bitmap_paint ; <nl> + <nl> + / / see # 738 . <nl> + private static final list < string > models_requiring_bitmap_lock = <nl> + arrays . aslist ( <nl> + " xt1097 " , <nl> + " xt1085 " ) ; <nl> / * * <nl> * https : / / github . com / bumptech / glide / issues / 738 on some devices ( moto x with android num . 1 ) bitmap <nl> * drawing is not thread safe . <nl> * this lock only locks for these specific devices . for other types of devices the lock is always <nl> * available and therefore does not impact performance <nl> * / <nl> - private static final lock bitmap_drawable_lock = " xt1097 " . equals ( build . model ) <nl> - <nl> - & & build . version . sdk_int = = num <nl> - ? new reentrantlock ( ) <nl> - : new nolock ( ) ; <nl> + private static final lock bitmap_drawable_lock = <nl> + models_requiring_bitmap_lock . contains ( build . model ) <nl> + & & build . version . sdk_int = = build . version_codes . lollipop_mr1 <nl> + ? new reentrantlock ( ) : new nolock ( ) ; <nl>  <nl> static { <nl> circle_crop_bitmap_paint = new paint ( circle_crop_paint_flags ) ;
pom_scm_dev_connection = scm : git @ github . com : bumptech / glide . git <nl> pom_developer_id = sjudd <nl> pom_developer_name = sam judd <nl> pom_developer_email = judds @ google . com <nl> - support_v4_version = 24 . 2 . 0 <nl> - support_v7_version = 24 . 2 . 0 <nl> + support_v4_version = 25 . 1 . 1 <nl> + support_v7_version = 25 . 1 . 1 <nl> volley_version = 1 . 0 . 0 <nl> ok_http_version = 3 . 0 . 1 <nl> - # <nl> - android_gradle_version = 2 . 1 . 3 <nl> + android_gradle_version = 2 . 2 . 3 <nl>  <nl> coveralls_gradle_version = 2 . 4 . 0 <nl> junit_version = 4 . 12 <nl>
public class gifheader { <nl> int bgindex ; <nl> / / pixel aspect ratio . <nl> int pixelaspect ; <nl> - <nl> int bgcolor ; <nl> int loopcount ; <nl>  <nl> mmm a / third_party / gif_decoder / src / main / java / com / bumptech / glide / gifdecoder / standardgifdecoder . java <nl> ppp b / third_party / gif_decoder / src / main / java / com / bumptech / glide / gifdecoder / standardgifdecoder . java <nl>
<nl> - package com . bumptech . glide . load . resource . bitmap ; <nl> - <nl> - import android . graphics . bitmap ; <nl> - <nl> - import com . bumptech . glide . transitionoptions ; <nl> - <nl> - / * * <nl> - * provides { @ link bitmap } specific animation options . <nl> - * <nl> - * <nl> - * / <nl> - public final class bitmaptransitionoptions extends transitionoptions < bitmaptransitionoptions , <nl> - bitmap > { <nl> - }
<nl> - / * <nl> - * copyright ( c ) num the android open source project <nl> - * <nl> - * licensed under the apache license , version num . 0 ( the " license " ) ; <nl> - * you may not use this file except in compliance with the license . <nl> - * you may obtain a copy of the license at <nl> - * <nl> - * http : / / www . apache . org / licenses / license - 2 . 0 <nl> - * <nl> - * unless required by applicable law or agreed to in writing , software <nl> - * distributed under the license is distributed on an " as is " basis , <nl> - * without warranties or conditions of any kind , either express or implied . <nl> - * see the license for the specific language governing permissions and <nl> - * limitations under the license . <nl> - * / <nl> - <nl> - package com . bumptech . glide . integration . volley ; <nl> - <nl> - import com . android . volley . request ; <nl> - import com . android . volley . response ; <nl> - import com . android . volley . volleyerror ; <nl> - <nl> - import java . util . concurrent . cancellationexception ; <nl> - import java . util . concurrent . executionexception ; <nl> - import java . util . concurrent . future ; <nl> - import java . util . concurrent . timeunit ; <nl> - import java . util . concurrent . timeoutexception ; <nl> - <nl> - / * * <nl> - * <nl> - * <nl> - * a future that represents a volley request . <nl> - * <nl> - * used by providing as your response and error listeners . for example : <nl> - * < pre > <nl> - * requestfuture & lt ; jsonobject & gt ; future = requestfuture . newfuture ( ) ; <nl> - * myrequest request = new myrequest ( url , future , future ) ; <nl> - * <nl> - * / / if you want to be able to cancel the request : <nl> - * future . setrequest ( requestqueue . add ( request ) ) ; <nl> - * <nl> - * / / otherwise : <nl> - * requestqueue . add ( request ) ; <nl> - * <nl> - * try { <nl> - * jsonobject response = future . get ( ) ; <nl> - * / / do something with response <nl> - * } catch ( interruptedexception e ) { <nl> - * / / handle the error <nl> - * } catch ( executionexception e ) { <nl> - * / / handle the error <nl> - * } <nl> - * < / pre > <nl> - * <nl> - * @ param < t > the type of parsed response this future expects . <nl> - * / <nl> - public class volleyrequestfuture < t > implements future < t > , <nl> - response . listener < t > , <nl> - response . errorlistener { <nl> - private request < ? > mrequest ; <nl> - private boolean mresultreceived = false ; <nl> - private t mresult ; <nl> - private volleyerror mexception ; <nl> - private boolean miscancelled = false ; <nl> - <nl> - public static < e > volleyrequestfuture < e > newfuture ( ) { <nl> - return new volleyrequestfuture < e > ( ) ; <nl> - } <nl> - <nl> - public synchronized void setrequest ( request < ? > request ) { <nl> - mrequest = request ; <nl> - if ( miscancelled & & mrequest ! = null ) { <nl> - mrequest . cancel ( ) ; <nl> - } <nl> - } <nl> - <nl> - @ override <nl> - public synchronized boolean cancel ( boolean mayinterruptifrunning ) { <nl> - if ( isdone ( ) ) { <nl> - return false ; <nl> - } <nl> - miscancelled = true ; <nl> - if ( mrequest ! = null ) { <nl> - mrequest . cancel ( ) ; <nl> - } <nl> - notifyall ( ) ; <nl> - <nl> - return true ; <nl> - } <nl> - <nl> - @ override <nl> - public t get ( ) throws interruptedexception , executionexception { <nl> - try { <nl> - return doget ( null ) ; <nl> - } catch ( timeoutexception e ) { <nl> - throw new assertionerror ( e ) ; <nl> - } <nl> - } <nl> - <nl> - @ override <nl> - public t get ( long timeout , timeunit unit ) <nl> - throws interruptedexception , executionexception , timeoutexception { <nl> - return doget ( timeunit . milliseconds . convert ( timeout , unit ) ) ; <nl> - } <nl> - <nl> - private synchronized t doget ( long timeoutms ) <nl> - throws interruptedexception , executionexception , timeoutexception { <nl> - if ( mexception ! = null ) { <nl> - throw new executionexception ( mexception ) ; <nl> - } <nl> - <nl> - if ( mresultreceived ) { <nl> - return mresult ; <nl> - } <nl> - <nl> - if ( iscancelled ( ) ) { <nl> - throw new cancellationexception ( ) ; <nl> - } <nl> - <nl> - if ( timeoutms = = null ) { <nl> - wait ( 0 ) ; <nl> - } else if ( timeoutms > num ) { <nl> - wait ( timeoutms ) ; <nl> - } <nl> - <nl> - if ( mexception ! = null ) { <nl> - throw new executionexception ( mexception ) ; <nl> - } <nl> - <nl> - if ( iscancelled ( ) ) { <nl> - throw new cancellationexception ( ) ; <nl> - } <nl> - <nl> - if ( ! mresultreceived ) { <nl> - throw new timeoutexception ( ) ; <nl> - } <nl> - <nl> - return mresult ; <nl> - } <nl> - <nl> - @ override <nl> - public boolean iscancelled ( ) { <nl> - return miscancelled ; <nl> - } <nl> - <nl> - @ override <nl> - public synchronized boolean isdone ( ) { <nl> - return mresultreceived | | mexception ! = null | | iscancelled ( ) ; <nl> - } <nl> - <nl> - @ override <nl> - public synchronized void onresponse ( t response ) { <nl> - mresultreceived = true ; <nl> - mresult = response ; <nl> - notifyall ( ) ; <nl> - } <nl> - <nl> - @ override <nl> - public synchronized void onerrorresponse ( volleyerror error ) { <nl> - mexception = error ; <nl> - notifyall ( ) ; <nl> - } <nl> - } <nl> -
public class okhttpstreamfetcher implements datafetcher < inputstream > { <nl>  <nl> @ override <nl> public void cancel ( ) { <nl> - <nl> + call local = call ; <nl> + if ( local ! = null ) { <nl> + local . cancel ( ) ; <nl> + } <nl> } <nl>  <nl> @ override
public class flickrsearchactivity extends actionbaractivity { <nl> backgroundthumbnailfetcher . cancel ( ) ; <nl> } <nl>  <nl> - <nl> - / / backgroundthumbnailfetcher = <nl> - / / new backgroundthumbnailfetcher ( flickrsearchactivity . this , photos ) ; <nl> - / / backgroundhandler . post ( backgroundthumbnailfetcher ) ; <nl> + backgroundthumbnailfetcher = <nl> + new backgroundthumbnailfetcher ( flickrsearchactivity . this , photos ) ; <nl> + backgroundhandler . post ( backgroundthumbnailfetcher ) ; <nl>  <nl> currentphotos = photos ; <nl> }
<nl> buildscript { <nl> repositories { <nl> jcenter ( ) <nl> - <nl> - maven { <nl> - url ' https : / / oss . sonatype . org / content / repositories / snapshots ' <nl> - } <nl> } <nl>  <nl> dependencies { <nl>
buildscript { <nl> subprojects { project - > <nl> repositories { <nl> jcenter ( ) <nl> - <nl> - maven { <nl> - url ' https : / / oss . sonatype . org / content / repositories / snapshots ' <nl> - } <nl> } <nl>  <nl> apply plugin : ' checkstyle ' <nl> mmm a / gradle . properties <nl> ppp b / gradle . properties <nl>
public class recyclablebufferedinputstream extends filterinputstream { <nl> throw new invalidmarkexception ( " mark has been invalidated " ) ; <nl> } <nl> pos = markpos ; <nl> - <nl> - / / we reset markpos to - 1 so that after reset is called , we no longer continue to allocate larger and larger <nl> - / / buffers . if we don ' t do this , we continually allocate new buffers so that the entire stream is held in memory <nl> - / / at once . we could use a fixed size buffer , but that limits our mark size . in practice requiring users to <nl> - / / call mark once per call to reset seems to work . see issue # 225 . <nl> - markpos = - 1 ; <nl> } <nl>  <nl> / * *
<nl> package com . bumptech . glide . load . resource . file ; <nl>  <nl> - import com . bumptech . glide . load . engine . resource ; <nl> + import com . bumptech . glide . load . resource . simpleresource ; <nl>  <nl> import java . io . file ; <nl>  <nl> / * * <nl> * a simple { @ link com . bumptech . glide . load . engine . resource } that wraps a { @ link file } . <nl> * / <nl> - public class fileresource implements resource < file > { <nl> - private file file ; <nl> - <nl> + public class fileresource extends simpleresource < file > { <nl> public fileresource ( file file ) { <nl> - this . file = file ; <nl> - } <nl> - <nl> - @ override <nl> - public file get ( ) { <nl> - return file ; <nl> - } <nl> - <nl> - <nl> - @ override <nl> - public int getsize ( ) { <nl> - return num ; <nl> - } <nl> - <nl> - @ override <nl> - public void recycle ( ) { <nl> - <nl> + super ( file ) ; <nl> } <nl> }
android { <nl> } <nl> } <nl>  <nl> - def getjarname ( ) { <nl> - " glide - $ { getversionname ( ) } . jar " <nl> - } <nl> - <nl> - / / build a jar , from http : / / stackoverflow . com / a / 19037807 / 1002054 . <nl> - <nl> - task clearjar ( type : delete ) { <nl> - delete " build / libs / $ { getjarname ( ) } " <nl> - } <nl> - <nl> - task makejar ( type : copy ) { <nl> - from ( ' build / intermediates / bundles / release / ' ) <nl> - into ( ' build / libs / ' ) <nl> - include ( ' classes . jar ' ) <nl> - rename ( ' classes . jar ' , getjarname ( ) ) <nl> - } <nl> - <nl> - makejar . dependson ( clearjar , build ) <nl> - <nl> apply from : " https : / / raw . githubusercontent . com / mcxiaoke / gradle - mvn - push / master / gradle - mvn - push . gradle "
public class imageviewtarget implements target { <nl> imageview . startanimation ( animation ) ; <nl> } <nl>  <nl> - / * * <nl> - * <nl> - * a jar <nl> - * / <nl> @ override <nl> public void setimagepresenter ( imagepresenter imagepresenter ) { <nl> this . imagepresenter = imagepresenter ; <nl> mmm a / library / tests / src / com / bumptech / glide / glidetest . java <nl> ppp b / library / tests / src / com / bumptech / glide / glidetest . java <nl>
public class librarymanagerui extends installerjdialog < contributedlibraryrelease <nl> } else { <nl> installer . install ( lib , this : : setprogress ) ; <nl> } <nl> - <nl> + onindexesupdated ( ) ; <nl> if ( contribtable . getcelleditor ( ) ! = null ) { <nl> contribtable . getcelleditor ( ) . stopcellediting ( ) ; <nl> } <nl> ( ( librariesindextablemodel ) contribmodel ) . update ( ) ; <nl> - onindexesupdated ( ) ; <nl> } catch ( exception e ) { <nl> throw new runtimeexception ( e ) ; <nl> } finally { <nl>
public class librarymanagerui extends installerjdialog < contributedlibraryrelease <nl> try { <nl> setprogressvisible ( true , tr ( " removing . . . " ) ) ; <nl> installer . remove ( lib , this : : setprogress ) ; <nl> - <nl> + onindexesupdated ( ) ; <nl> if ( contribtable . getcelleditor ( ) ! = null ) { <nl> contribtable . getcelleditor ( ) . stopcellediting ( ) ; <nl> } <nl> ( ( librariesindextablemodel ) contribmodel ) . update ( ) ; <nl> - onindexesupdated ( ) ; <nl> } catch ( exception e ) { <nl> throw new runtimeexception ( e ) ; <nl> } finally {
import processing . app . helpers . preferencesmap ; <nl>  <nl> public class boardport { <nl>  <nl> - private string address ; <nl> - private string protocol ; <nl> + private string address ; / / unique name for this port , used by preferences <nl> + private string protocol ; / / how to communicate , used for ports menu sections <nl> private string boardname ; <nl> - private string vid ; <nl> - private string pid ; <nl> - private string iserial ; <nl> - private string label ; <nl> - private final preferencesmap prefs ; <nl> - private boolean online ; <nl> + private string label ; / / friendly name shown in ports menu <nl> + private final preferencesmap prefs ; / / " vendorid " , " productid " , " serialnumber " <nl> + private boolean online ; / / used by serialboardslister ( during upload ? ? ) <nl>  <nl> public boardport ( ) { <nl> this . prefs = new preferencesmap ( ) ; <nl> } <nl>  <nl> public boardport ( boardport bp ) { <nl> - prefs = new preferencesmap ( ) ; <nl> - <nl> + prefs = new preferencesmap ( bp . prefs ) ; <nl> address = bp . address ; <nl> protocol = bp . protocol ; <nl> boardname = bp . boardname ; <nl> - vid = bp . vid ; <nl> - pid = bp . pid ; <nl> - iserial = bp . iserial ; <nl> label = bp . label ; <nl> + online = bp . online ; <nl> } <nl>  <nl> public string getaddress ( ) { <nl>
public class pluggablediscovery implements discovery { <nl> while ( program ! = null & & program . isalive ( ) ) { <nl> boardport port = mapper . readvalue ( parser , boardport . class ) ; <nl> if ( port ! = null ) { <nl> - system . out . println ( discoveryname + " received json " ) ; <nl> - / / <nl> - <nl> - / / <nl> - update ( port ) ; <nl> + system . out . println ( discoveryname + " : received json " ) ; <nl> + string address = port . getaddress ( ) ; <nl> + if ( address ! = null ) { <nl> + if ( address . equals ( " error : start_sync not supported " ) ) { <nl> + if ( pollingthread = = null ) { <nl> + startpolling ( ) ; <nl> + } <nl> + } else { <nl> + update ( port ) ; <nl> + } <nl> + } <nl> } <nl> } <nl> - system . out . println ( " thread exit normally " ) ; <nl> + system . out . println ( discoveryname + " : thread exit normally " ) ; <nl> } catch ( interruptedexception e ) { <nl> - system . out . println ( " thread exit by interrupt " ) ; <nl> + system . out . println ( discoveryname + " : thread exit by interrupt " ) ; <nl> e . printstacktrace ( ) ; <nl> } catch ( exception e ) { <nl> - system . out . println ( " thread exit other exception " ) ; <nl> + system . out . println ( discoveryname + " : thread exit other exception " ) ; <nl> e . printstacktrace ( ) ; <nl> } <nl> try { <nl>
import javax . swing . uimanager ; <nl> * / <nl> public class platform extends processing . app . platform { <nl>  <nl> - <nl> - / / it may even throw a weird exception at ' em for their trouble . <nl> @ override <nl> public void setlookandfeel ( ) throws exception { <nl> + super . setlookandfeel ( ) ; <nl> gtklookandfeelfixer . installgtkpopupbugworkaround ( ) ; <nl> } <nl>  <nl> mmm a / build / linux / dist / arduino <nl> ppp b / build / linux / dist / arduino <nl>
public abstract class installerjdialog < t > extends jdialog { <nl> contribtable . getcelleditor ( ) . stopcellediting ( ) ; <nl> } <nl> updateindexfilter ( filters , categoryfilter ) ; <nl> - if ( contribmodel . getrowcount ( ) = = num ) { <nl> - <nl> - / / contribtable . addrowselectioninterval ( 0 , num ) ; <nl> - } <nl> } <nl> } ;
ipaddress : : ipaddress ( const uint8_t * address ) <nl>  <nl> bool ipaddress : : fromstring ( const char * address ) <nl> { <nl> - <nl> - <nl> uint16_t acc = num ; / / accumulator <nl> uint8_t dots = num ; <nl>  <nl> mmm a / hardware / arduino / sam / cores / arduino / ipaddress . cpp <nl> ppp b / hardware / arduino / sam / cores / arduino / ipaddress . cpp <nl>
ipaddress : : ipaddress ( const uint8_t * address ) <nl>  <nl> bool ipaddress : : fromstring ( const char * address ) <nl> { <nl> - <nl> - <nl> uint16_t acc = num ; / / accumulator <nl> uint8_t dots = num ; <nl>  <nl> mmm a / libraries / ethernet / src / dns . cpp <nl> ppp b / libraries / ethernet / src / dns . cpp <nl>
void dnsclient : : begin ( const ipaddress & adnsserver ) <nl>  <nl> int dnsclient : : inet_aton ( const char * address , ipaddress & result ) <nl> { <nl> - <nl> - <nl> uint16_t acc = num ; / / accumulator <nl> uint8_t dots = num ;
public class editor extends jframe implements runnerlistener { <nl>  <nl> menu . addseparator ( ) ; <nl>  <nl> - <nl> - / / if some text is currently selected <nl> jmenuitem cutitem = newjmenuitem ( tr ( " cut " ) , ' x ' ) ; <nl> cutitem . addactionlistener ( new actionlistener ( ) { <nl> public void actionperformed ( actionevent e ) { <nl>
public class editorheader extends jcomponent { <nl>  <nl> if ( pieces = = null ) { <nl> pieces = new image [ status . length ] [ where . length ] ; <nl> + menubuttons = new image [ status . length ] ; <nl> for ( int i = num ; i < status . length ; i + + ) { <nl> for ( int j = num ; j < where . length ; j + + ) { <nl> string path = " tab - " + status [ i ] + " - " + where [ j ] ; <nl> - pieces [ i ] [ j ] = theme . getthemeimage ( path , this , <nl> - <nl> - j = = menu ? piece_height <nl> - : piece_width , <nl> + pieces [ i ] [ j ] = theme . getthemeimage ( path , this , piece_width , <nl> piece_height ) ; <nl> } <nl> + string path = " tab - " + status [ i ] + " - menu " ; <nl> + menubuttons [ i ] = theme . getthemeimage ( path , this , piece_height , <nl> + piece_height ) ; <nl> } <nl> } <nl>  <nl>
<nl> - package processing . app ; <nl> - <nl> - import java . awt . toolkit ; <nl> - import java . awt . event . inputevent ; <nl> - import java . awt . event . keyevent ; <nl> - import java . awt . event . keylistener ; <nl> - <nl> - import processing . app . syntax . sketchtextarea ; <nl> - <nl> - public class editorlistener implements keylistener { <nl> - <nl> - private editor editor ; <nl> - <nl> - public editorlistener ( editor editor ) { <nl> - super ( ) ; <nl> - this . editor = editor ; <nl> - } <nl> - <nl> - / * * ctrl - alt on windows and linux , cmd - alt on mac os x * / <nl> - private static final int ctrl = toolkit . getdefaulttoolkit ( ) . getmenushortcutkeymask ( ) ; <nl> - private static final int ctrl_alt = inputevent . alt_mask | ctrl ; <nl> - private static final int ctrl_shift = inputevent . shift_mask | ctrl ; <nl> - <nl> - public void keytyped ( keyevent event ) { <nl> - } <nl> - <nl> - @ override <nl> - public void keypressed ( keyevent event ) { <nl> - } <nl> - <nl> - @ override <nl> - public void keyreleased ( keyevent e ) { <nl> - <nl> - <nl> - } <nl> - <nl> - } <nl> mmm a / app / src / processing / app / syntax / sketchtextarea . java <nl> ppp b / app / src / processing / app / syntax / sketchtextarea . java <nl>
<nl> # if defined ( usbcon ) <nl> # ifdef pluggable_usb_enabled <nl>  <nl> - <nl> - # define max_ep num <nl> - <nl> extern uint8_t _initendpoints [ ] ; <nl>  <nl> pluggableusb_ pluggableusb ; <nl>
public class editor extends jframe implements runnerlistener { <nl>  <nl> item = newjmenuitem ( _ ( " find . . . " ) , ' f ' ) ; <nl> item . addactionlistener ( new actionlistener ( ) { <nl> - public void actionperformed ( actionevent e ) { <nl> - if ( find = = null ) { <nl> - find = new findreplace ( editor . this ) ; <nl> - } <nl> - if ( getselectedtext ( ) ! = null ) find . setfindtext ( getselectedtext ( ) ) ; <nl> - / / new findreplace ( editor . this ) . show ( ) ; <nl> - find . setlocationrelativeto ( editor . this ) ; <nl> - find . setvisible ( true ) ; <nl> - / / find . setvisible ( true ) ; <nl> + public void actionperformed ( actionevent e ) { <nl> + if ( find = = null ) { <nl> + find = new findreplace ( editor . this ) ; <nl> } <nl> - } ) ; <nl> + if ( ! osutils . ismacos ( ) & & getselectedtext ( ) ! = null ) { <nl> + find . setfindtext ( getselectedtext ( ) ) ; <nl> + } <nl> + find . setlocationrelativeto ( editor . this ) ; <nl> + find . setvisible ( true ) ; <nl> + } <nl> + } ) ; <nl> menu . add ( item ) ; <nl>  <nl> - <nl> - / / search has actually taken place <nl> item = newjmenuitem ( _ ( " find next " ) , ' g ' ) ; <nl> item . addactionlistener ( new actionlistener ( ) { <nl> - public void actionperformed ( actionevent e ) { <nl> - if ( find ! = null ) { <nl> - find . findnext ( ) ; <nl> - } <nl> + public void actionperformed ( actionevent e ) { <nl> + if ( find ! = null ) { <nl> + find . findnext ( ) ; <nl> } <nl> - } ) ; <nl> + } <nl> + } ) ; <nl> menu . add ( item ) ; <nl>  <nl> item = newjmenuitemshift ( _ ( " find previous " ) , ' g ' ) ; <nl> item . addactionlistener ( new actionlistener ( ) { <nl> + public void actionperformed ( actionevent e ) { <nl> + if ( find ! = null ) { <nl> + find . findprevious ( ) ; <nl> + } <nl> + } <nl> + } ) ; <nl> + menu . add ( item ) ; <nl> + <nl> + if ( osutils . ismacos ( ) ) { <nl> + item = newjmenuitem ( _ ( " use selection for find " ) , ' e ' ) ; <nl> + item . addactionlistener ( new actionlistener ( ) { <nl> public void actionperformed ( actionevent e ) { <nl> - if ( find ! = null ) { <nl> - find . findprevious ( ) ; <nl> + if ( find = = null ) { <nl> + find = new findreplace ( editor . this ) ; <nl> } <nl> + if ( getselectedtext ( ) ! = null ) { <nl> + find . setfindtext ( getselectedtext ( ) ) ; <nl> + } <nl> + find . setlocationrelativeto ( editor . this ) ; <nl> + find . setvisible ( true ) ; <nl> } <nl> } ) ; <nl> - menu . add ( item ) ; <nl> + menu . add ( item ) ; <nl> + } <nl>  <nl> return menu ; <nl> }
public class versioncomparator implements comparator < string > { <nl> if ( b = = null ) <nl> return num ; <nl>  <nl> - <nl> - return a . compareto ( b ) ; <nl> + version versiona = valueof ( a ) ; <nl> + version versionb = valueof ( b ) ; <nl> + <nl> + return versiona . compareto ( versionb ) ; <nl> + } <nl> + <nl> + private version valueof ( string ver ) { <nl> + string [ ] verparts = ver . split ( " \ \ . " ) ; <nl> + if ( verparts . length < num ) { <nl> + if ( verparts . length = = num ) { <nl> + return version . forintegers ( integer . valueof ( verparts [ 0 ] ) , integer . valueof ( verparts [ 1 ] ) ) ; <nl> + } else { <nl> + return version . forintegers ( integer . valueof ( verparts [ 0 ] ) ) ; <nl> + } <nl> + } else { <nl> + return version . valueof ( ver ) ; <nl> + } <nl> } <nl>  <nl> }
public class basenogui { <nl> if ( ! indexfile . isfile ( ) ) { <nl> file distfile = finddefaultpackagefile ( ) ; <nl> if ( distfile ! = null ) { <nl> - / / if present , unpack distribution file into preferences folder <nl> archiveextractor . extract ( distfile , basenogui . getsettingsfolder ( ) , num ) ; <nl> - <nl> - <nl> } else { <nl> / / otherwise create an empty packages index <nl> fileoutputstream out = null ;
typedef unsigned int word ; <nl>  <nl> # define bit ( b ) ( 1ul < < ( b ) ) <nl>  <nl> - <nl> - typedef uint8_t boolean ; <nl> + typedef bool boolean ; <nl> typedef uint8_t byte ; <nl>  <nl> - <nl> # ifdef __cplusplus <nl> } / / extern " c " <nl> # endif / / __cplusplus
public : <nl> void begin ( ) ; <nl> yunclient accept ( ) ; <nl>  <nl> - virtual size_t write ( uint8_t c ) { / * <nl> + virtual size_t write ( uint8_t c ) ; <nl>  <nl> void listenonlocalhost ( ) { uselocalhost = true ; } <nl> void nolistenonlocalhost ( ) { uselocalhost = false ; }
void bridgeclass : : begin ( ) { <nl> return ; <nl> started = true ; <nl>  <nl> - <nl> - <nl> / / wait for atheros bootloader to finish startup <nl> do { <nl> dropall ( ) ; <nl>
void bridgeclass : : begin ( ) { <nl> } <nl>  <nl> uint8_t bridgeclass : : runcommand ( string & command ) { <nl> - <nl> - string cmd = " r " + command ; <nl> + uint8_t cmd [ ] = { ' r ' } ; <nl> uint8_t res [ 1 ] ; <nl> - transfer ( ( uint8_t * ) cmd . c_str ( ) , cmd . length ( ) , res , num ) ; <nl> + transfer ( cmd , num , ( uint8_t * ) command . c_str ( ) , command . length ( ) , res , num ) ; <nl> return res [ 0 ] ; <nl> } <nl>  <nl>
unsigned int bridgeclass : : readcommandoutput ( uint8_t handle , <nl>  <nl> void bridgeclass : : writecommandinput ( uint8_t handle , <nl> const uint8_t * buff , unsigned int size ) { <nl> - <nl> - uint8_t * tmp = new uint8_t [ size + 2 ] ; <nl> - tmp [ 0 ] = ' i ' ; <nl> - tmp [ 1 ] = handle ; <nl> - memcpy ( tmp + 2 , buff , size ) ; <nl> - transfer ( tmp , size + 2 ) ; <nl> - delete [ ] tmp ; <nl> + uint8_t cmd [ ] = { ' i ' , handle } ; <nl> + transfer ( cmd , num , buff , size , null , num ) ; <nl> } <nl>  <nl> unsigned int bridgeclass : : readmessage ( uint8_t * buff , unsigned int size ) { <nl>
unsigned int bridgeclass : : readmessage ( uint8_t * buff , unsigned int size ) { <nl> } <nl>  <nl> void bridgeclass : : writemessage ( const uint8_t * buff , unsigned int size ) { <nl> - <nl> - uint8_t * tmp = new uint8_t [ size + 1 ] ; <nl> - tmp [ 0 ] = ' m ' ; <nl> - memcpy ( tmp + 1 , buff , size ) ; <nl> - transfer ( tmp , size + 1 ) ; <nl> - delete [ ] tmp ; <nl> + uint8_t cmd [ ] = { ' m ' } ; <nl> + transfer ( cmd , num , buff , size , null , num ) ; <nl> } <nl>  <nl> unsigned int bridgeclass : : messageavailable ( ) { <nl> - uint8_t tmp [ ] = { ' n ' } ; <nl> + uint8_t tmp [ ] = { ' n ' } ; <nl> uint8_t res [ 2 ] ; <nl> transfer ( tmp , num , res , num ) ; <nl> return ( res [ 0 ] < < num ) + res [ 1 ] ; <nl>
void bridgeclass : : put ( const char * key , const char * value ) { <nl> } <nl>  <nl> unsigned int bridgeclass : : get ( const char * key , uint8_t * value , unsigned int maxlen ) { <nl> - <nl> - unsigned int l = strlen ( key ) ; <nl> - uint8_t * tmp = new uint8_t [ l + 1 ] ; <nl> - tmp [ 0 ] = ' d ' ; <nl> - memcpy ( tmp + 1 , key , strlen ( key ) ) ; <nl> - l = transfer ( tmp , l + 1 , value , maxlen ) ; <nl> - if ( l < maxlen ) <nl> + uint8_t cmd [ ] = { ' d ' } ; <nl> + unsigned int l = transfer ( cmd , num , ( uint8_t * ) key , strlen ( key ) , value , maxlen ) ; <nl> + if ( l < maxlen ) <nl> value [ l ] = num ; / / zero - terminate string <nl> - delete [ ] tmp ; <nl> return l ; <nl> } <nl>  <nl>
<nl> < ! - - - - - - - - - - - - > <nl> < target name = " revision - check " > <nl> < ! - - figure out the revision number - - > <nl> - < loadfile srcfile = " . . / <nl> + < loadfile srcfile = " shared / revisions . txt " property = " revision " > <nl> < filterchain > <nl> - < headfilter lines = " 1 " / > <nl> - < tokenfilter > <nl> - < stringtokenizer suppressdelims = " true " / > <nl> - < ! - - grab the thing from the first line that ' s num digits - - > <nl> - < containsregex pattern = " ( \ d \ d \ d \ d ) " / > <nl> - < / tokenfilter > <nl> + < ignoreblank / > <nl> + < headfilter lines = " 1 " / > <nl> + < tokenfilter > <nl> + < linetokenizer includedelims = " false " / > <nl> + < ! - - grab the thing from the first line that ' s num digits - - > <nl> + < containsregex pattern = " arduino ( . * ) " / > <nl> + < replaceregex pattern = " arduino ( [ ^ ] * ) . * " replace = " \ 1 " / > <nl> + < / tokenfilter > <nl> + < tokenfilter > <nl> + < stringtokenizer suppressdelims = " true " / > <nl> + < / tokenfilter > <nl> < / filterchain > <nl> < / loadfile > <nl> - < ! - - < echo message = " revision is $ { revision } . " / > - - > <nl> + < echo message = " latest revision detected in shared / revision . txt is : $ { revision } " / > <nl>  <nl> < ! - - figure out the revision number in base . java - - > <nl> < loadfile srcfile = " . . / app / src / processing / app / base . java " <nl> property = " revision . base " > <nl> < filterchain > <nl> - < tokenfilter > <nl> - < linetokenizer / > <nl> - < containsregex pattern = " string version_name = " / > <nl> - < replaceregex pattern = " [ ^ 0 - 9 ] * " flags = " g " replace = " " / > <nl> - < / tokenfilter > <nl> + < tokenfilter > <nl> + < linetokenizer / > <nl> + < containsregex pattern = " string version_name = " / > <nl> + < replaceregex pattern = " [ ^ 0 - 9 ] * " flags = " g " replace = " " / > <nl> + < / tokenfilter > <nl> < / filterchain > <nl> < / loadfile > <nl> - < ! - - < echo message = " base revision is $ { revision . base } . " / > - - > <nl> - <nl> - < condition property = " revision . correct " > <nl> - < ! - - using contains because i can ' t figure out how to get rid of the <nl> - lf in revision . base . please file a bug if you have a fix . - - > <nl> - < contains string = " $ { revision . base } " substring = " $ { revision } " / > <nl> - < / condition > <nl> - <nl> - < ! - - the revision . base property won ' t be set <nl> - if $ revision wasn ' t found . . . - - > <nl> - < fail unless = " revision . correct " <nl> - message = " fix revision number in base . java " / > <nl> + < echo message = " revision in base . java is : $ { revision . base } " / > <nl> < / target > <nl>  <nl> < ! - - - - - - - - - - - > <nl> mmm a / build / shared / revisions . txt <nl> ppp b / build / shared / revisions . txt <nl>
int wificlient : : read ( uint8_t * buf , size_t size ) { <nl> } <nl>  <nl> int wificlient : : peek ( ) { <nl> - <nl> - return num ; <nl> + uint8_t b ; <nl> + if ( ! available ( ) ) <nl> + return - 1 ; <nl> + <nl> + serverdrv : : getdata ( _sock , & b , num ) ; <nl> + return b ; <nl> } <nl>  <nl> void wificlient : : flush ( ) { <nl>
wificlient : : wificlient ( uint8_t sock ) : _sock ( sock ) { <nl> } <nl>  <nl> int wificlient : : connect ( const char * host , uint16_t port ) { <nl> - / * <nl> - # if num <nl> - / / look up the host first <nl> - int ret = num ; <nl> - dnsclient dns ; <nl> - ipaddress remote_addr ; <nl> - <nl> - dns . begin ( ethernet . dnsserverip ( ) ) ; <nl> - ret = dns . gethostbyname ( host , remote_addr ) ; <nl> - if ( ret = = num ) { <nl> - return connect ( remote_addr , port ) ; <nl> - } else { <nl> - return ret ; <nl> - } <nl> - # endif <nl> - return num ; <nl> + ipaddress remote_addr ; <nl> + if ( wifi . hostbyname ( host , remote_addr ) ) <nl> + { <nl> + return connect ( remote_addr , port ) ; <nl> + } <nl> + return num ; <nl> } <nl>  <nl> int wificlient : : connect ( ipaddress ip , uint16_t port ) { <nl> mmm a / wifi / utility / wifi_drv . cpp <nl> ppp b / wifi / utility / wifi_drv . cpp <nl>
<nl> # if defined ( usbcon ) <nl> # ifdef cdc_enabled <nl>  <nl> - <nl> - / / not currently working for a non - obvious reason <nl> - <nl> - typedef void ( * appptr_t ) ( void ) __attribute__ ( ( noreturn ) ) ; <nl> - appptr_t bootloader = ( appptr_t ) ( 30 * 1024 ) ; <nl> - <nl> void reboot ( ) <nl> { <nl> usb . detach ( ) ; <nl> cli ( ) ; <nl> - bootloader ( ) ; <nl> - / / wdt_enable ( wdto_15ms ) ; <nl> - / / while ( 1 ) ; / / reboot <nl> + asm volatile ( " jmp num x7800 " ) ; / / jump to bootloader - diskloader takes up last num kb <nl> } <nl>  <nl> typedef struct
<nl> # include " udp . h " <nl>  <nl> / * start udp socket , listening at local port port * / <nl> - void udpclass : : begin ( uint16_t port ) { <nl> + uint8_t udpclass : : begin ( uint16_t port ) { <nl> + if ( _sock ! = max_sock_num ) <nl> + return num ; <nl> + <nl> + for ( int i = num ; i < max_sock_num ; i + + ) { <nl> + uint8_t s = w5100 . readsnsr ( i ) ; <nl> + if ( s = = snsr : : closed | | s = = snsr : : fin_wait ) { <nl> + _sock = i ; <nl> + break ; <nl> + } <nl> + } <nl> + <nl> + if ( _sock = = max_sock_num ) <nl> + return num ; <nl> + <nl> _port = port ; <nl> - _sock = num ; <nl> socket ( _sock , snmr : : udp , _port , num ) ; <nl> + <nl> + return num ; <nl> } <nl>  <nl> / * send packet contained in buf of length len to peer at specified ip , and port * / <nl>
boolean callback_remove ( sdfile & parentdir , char * filepathcomponent , <nl>  <nl>  <nl>  <nl> - void sdclass : : begin ( uint8_t cspin ) { <nl> + boolean sdclass : : begin ( uint8_t cspin ) { <nl> / * <nl>  <nl> performs the initialisation required by the sdfatlib library . <nl>  <nl> - does not return if initialisation fails . <nl> + return true if initialization succeeds , false otherwise . <nl>  <nl> * / <nl> - <nl> - if ( ! ( card . init ( spi_half_speed , cspin ) <nl> - & & volume . init ( card ) & & root . openroot ( volume ) ) ) { <nl> - while ( true ) { <nl> - / / bail <nl> - } <nl> - } <nl> + return card . init ( spi_half_speed , cspin ) & & <nl> + volume . init ( card ) & & <nl> + root . openroot ( volume ) ; <nl> } <nl>  <nl>  <nl> mmm a / libraries / sd / sd . h <nl> ppp b / libraries / sd / sd . h <nl>
boolean sdclass : : open ( char * filepath , <nl> fileopenmode = oflag ; <nl> walkpath ( filepath , root , callback_openpath , this ) ; <nl>  <nl> - <nl> + return file ( ) ; <nl>  <nl> } <nl>  <nl>  <nl> - boolean sdclass : : close ( ) { <nl> - / * <nl> - <nl> - closes the file opened by the ` open ` method . <nl> - <nl> - * / <nl> - file . close ( ) ; <nl> - } <nl> + / / boolean sdclass : : close ( ) { <nl> + / / / * <nl> + / / <nl> + / / closes the file opened by the ` open ` method . <nl> + / / <nl> + / / * / <nl> + / / file . close ( ) ; <nl> + / / } <nl>  <nl>  <nl> boolean sdclass : : exists ( char * filepath ) { <nl>
public abstract class limitedcache < k , v > extends cache < k , v > { <nl> int sizelimit = getsizelimit ( ) ; <nl> / / add to hard cache <nl> if ( valuesize < sizelimit ) { <nl> - while ( getmapsize ( ) + valuesize > sizelimit ) { <nl> - hardcache . removelast ( ) ; <nl> + while ( cachesize + valuesize > sizelimit ) { <nl> + cachesize - = getsize ( hardcache . removelast ( ) ) ; <nl> } <nl> hardcache . addfirst ( value ) ; <nl> + cachesize + = valuesize ; <nl> } <nl> / / add to soft cache <nl> super . put ( key , value ) ; <nl> } <nl>  <nl> - <nl> - private int getmapsize ( ) { <nl> - int size = num ; <nl> - for ( v v : hardcache ) { <nl> - size + = getsize ( v ) ; <nl> - } <nl> - return size ; <nl> - } <nl> - <nl> public void clear ( ) { <nl> hardcache . clear ( ) ; <nl> + cachesize = num ; <nl> super . clear ( ) ; <nl> }
public observerreadproxyprovider ( <nl> observer_probe_retry_period_key , <nl> observer_probe_retry_period_default , timeunit . milliseconds ) ; <nl>  <nl> - <nl> if ( wrappedproxy instanceof clientprotocol ) { <nl> this . observerreadenabled = true ; <nl> } else {
private void reportdiffsortedinner ( <nl> / / if the block is an out - of - date generation stamp or state , <nl> / / but we ' re the standby , we shouldn ' t treat it as corrupt , <nl> / / but instead just queue it for later processing . <nl> - <nl> - / / since we should be postponing the info of the reported block , not <nl> - / / the stored block . see hdfs - 6289 for more context . <nl> - queuereportedblock ( storageinfo , storedblock , reportedstate , <nl> + / / storing the reported block for later processing , as that is what <nl> + / / comes from the ibr / fbr and hence what we should use to compare <nl> + / / against the memory state . <nl> + / / see hdfs - 6289 and hdfs - 15422 for more context . <nl> + queuereportedblock ( storageinfo , replica , reportedstate , <nl> queue_reason_corrupt_state ) ; <nl> } else { <nl> tocorrupt . add ( c ) ; <nl>
private boolean processandhandlereportedblock ( <nl> / / if the block is an out - of - date generation stamp or state , <nl> / / but we ' re the standby , we shouldn ' t treat it as corrupt , <nl> / / but instead just queue it for later processing . <nl> - <nl> - / / since we should be postponing the info of the reported block , not <nl> - / / the stored block . see hdfs - 6289 for more context . <nl> - queuereportedblock ( storageinfo , storedblock , reportedstate , <nl> + / / storing the reported block for later processing , as that is what <nl> + / / comes from the ibr / fbr and hence what we should use to compare <nl> + / / against the memory state . <nl> + / / see hdfs - 6289 and hdfs - 15422 for more context . <nl> + queuereportedblock ( storageinfo , block , reportedstate , <nl> queue_reason_corrupt_state ) ; <nl> } else { <nl> markblockascorrupt ( c , storageinfo , node ) ;
public final boolean isinlatestsnapshot ( final int latestsnapshotid ) { <nl> / / if parent is a reference node , parent must be a renamed node . we can <nl> / / stop the check at the reference node . <nl> if ( parent ! = null & & parent . isreference ( ) ) { <nl> - <nl> - / / some ancestor nodes may not be in the latest snapshot . <nl> return true ; <nl> } <nl> final inodedirectory parentdir = getparent ( ) ;
public containersafemoderule ( string rulename , eventqueue eventqueue , <nl> " value should be > = num . 0 and < = num . 0 " ) ; <nl>  <nl> containermap = new concurrenthashmap < > ( ) ; <nl> - if ( containers ! = null ) { <nl> - containers . foreach ( c - > { <nl> - <nl> - / / created by the client . we are not considering these containers for <nl> - / / now . these containers can be handled by tracking pipelines . <nl> - if ( c ! = null & & c . getstate ( ) ! = null & & <nl> - ! c . getstate ( ) . equals ( hddsprotos . lifecyclestate . open ) ) { <nl> - containermap . put ( c . getcontainerid ( ) , c ) ; <nl> - } <nl> - } ) ; <nl> - maxcontainer = containermap . size ( ) ; <nl> - } <nl> - <nl> + containers . foreach ( container - > { <nl> + / / there can be containers in open / closing state which were never <nl> + / / created by the client . we are not considering these containers for <nl> + / / now . these containers can be handled by tracking pipelines . <nl> + <nl> + optional . ofnullable ( container . getstate ( ) ) <nl> + . filter ( state - > state ! = hddsprotos . lifecyclestate . open ) <nl> + . filter ( state - > state ! = hddsprotos . lifecyclestate . closing ) <nl> + . ifpresent ( s - > containermap . put ( container . getcontainerid ( ) , <nl> + container ) ) ; <nl> + } ) ; <nl> + maxcontainer = containermap . size ( ) ; <nl> long cutoff = ( long ) math . ceil ( maxcontainer * safemodecutoff ) ; <nl> getsafemodemetrics ( ) . setnumcontainerwithonereplicareportedthreshold ( cutoff ) ; <nl> } <nl> mmm a / hadoop - hdds / server - scm / src / test / java / org / apache / hadoop / hdds / scm / safemode / testscmsafemodemanager . java <nl> ppp b / hadoop - hdds / server - scm / src / test / java / org / apache / hadoop / hdds / scm / safemode / testscmsafemodemanager . java <nl>
public static void main ( string [ ] args ) throws exception { <nl> } <nl> } else { <nl> printhelp ( ) ; <nl> - throw new illegalargumentexception ( " bad parameters < <nl> + throw new illegalargumentexception ( " unrecognized option : " + args [ 0 ] ) ; <nl> } <nl> } <nl> }
<nl> public abstract class noderesourceupdaterplugin { <nl> / * * <nl> * update configured resource for the given component . <nl> - * @ param res resource passed in by external mododule ( such as <nl> + * @ param res resource passed in by external module ( such as <nl> * { @ link org . apache . hadoop . yarn . server . nodemanager . nodestatusupdater } <nl> * @ throws yarnexception when any issue happens . <nl> * / <nl> public abstract void updateconfiguredresource ( resource res ) <nl> throws yarnexception ; <nl>  <nl> - / * * <nl> - * this method will be called when the node ' s resource is loaded from <nl> - * dynamic - resources . xml in resourcemanager . <nl> - * <nl> - * @ param newresource newresource reported by rm <nl> - * @ throws yarnexception when any mismatch between nm / rm <nl> - * / <nl> - public void handleupdatedresourcefromrm ( resource newresource ) throws <nl> - yarnexception { <nl> - / / by default do nothing , subclass should implement this method when any <nl> - / / special activities required upon new resource reported by rm . <nl> - } <nl> - <nl> - <nl> } <nl> \ no newline at end of file
public xceiverclientreply watchforcommit ( long index , long timeout ) <nl> return clientreply ; <nl> } <nl> log . debug ( " commit <nl> - / / create a new raftclient instance for watch request <nl> - if ( watchclient = = null ) { <nl> - watchclient = <nl> - ratishelper . newraftclient ( rpctype , getpipeline ( ) , retrypolicy , <nl> - maxoutstandingrequests , tlsconfig , clientrequesttimeout ) ; <nl> - } <nl> - completablefuture < raftclientreply > replyfuture = watchclient <nl> + completablefuture < raftclientreply > replyfuture = getclient ( ) <nl> . sendwatchasync ( index , raftprotos . replicationlevel . all_committed ) ; <nl> raftclientreply reply ; <nl> try { <nl> replyfuture . get ( timeout , timeunit . milliseconds ) ; <nl> } catch ( timeoutexception toe ) { <nl> log . warn ( " 3 way commit failed " , toe ) ; <nl> - <nl> - closeraftclient ( watchclient ) ; <nl> - / / generate a new raft client instance again so that next watch request <nl> - / / does not get blocked for the previous one <nl> - <nl> - <nl> - / / here once the watch request bypassing sliding window in raft client <nl> - / / gets fixed . <nl> - watchclient = <nl> - ratishelper . newraftclient ( rpctype , getpipeline ( ) , retrypolicy , <nl> - maxoutstandingrequests , tlsconfig , clientrequesttimeout ) ; <nl> - reply = watchclient <nl> + reply = getclient ( ) <nl> . sendwatchasync ( index , raftprotos . replicationlevel . majority_committed ) <nl> . get ( timeout , timeunit . milliseconds ) ; <nl> list < raftprotos . commitinfoproto > commitinfoprotolist =
public void persistcontainerset ( outputstream out ) throws ioexception { <nl> public long takesnapshot ( ) throws ioexception { <nl> termindex ti = getlastappliedtermindex ( ) ; <nl> log . info ( " taking snapshot at termindex : " + ti ) ; <nl> - if ( ti ! = null ) { <nl> + if ( ti ! = null & & ti . getindex ( ) ! = raftserverconstants . invalid_log_index ) { <nl> final file snapshotfile = <nl> storage . getsnapshotfile ( ti . getterm ( ) , ti . getindex ( ) ) ; <nl> log . info ( " taking a snapshot to file { } " , snapshotfile ) ; <nl> - try { <nl> - <nl> - boolean created = snapshotfile . createnewfile ( ) ; <nl> - if ( ! created ) { <nl> - throw new ioexception ( " failed to create ratis snapshot file " ) ; <nl> - } <nl> - try ( fileoutputstream fos = new fileoutputstream ( snapshotfile ) ) { <nl> - persistcontainerset ( fos ) ; <nl> - } <nl> - } catch ( ioexception ioe ) { <nl> + try ( fileoutputstream fos = new fileoutputstream ( snapshotfile ) ) { <nl> + persistcontainerset ( fos ) ; <nl> + } catch ( ioexception ioe ) { <nl> log . warn ( " failed to write snapshot file \ " " + snapshotfile <nl> + " \ " , last applied index = " + ti ) ; <nl> throw ioe ;
public void testsecureominitializationsuccess ( ) throws exception { <nl> * @ throws exception <nl> * / <nl> @ test <nl> - @ ignore ( " <nl> public void testdelegationtoken ( ) throws exception { <nl>  <nl> / / capture logs for assertions <nl>
private void generatekeypair ( ozoneconfiguration config ) throws exception { <nl> * @ throws exception <nl> * / <nl> @ test <nl> - @ ignore ( " <nl> public void testdelegationtokenrenewal ( ) throws exception { <nl> generictestutils <nl> . setloglevel ( loggerfactory . getlogger ( server . class . getname ( ) ) , info ) ; <nl>
public void start ( ) throws ioexception { <nl> defaultmetricssystem . initialize ( " ozonemanager " ) ; <nl>  <nl> metadatamanager . start ( configuration ) ; <nl> - <nl> - / / startsecretmanagerifnecessary ( ) ; <nl> + startsecretmanagerifnecessary ( ) ; <nl>  <nl> / / set metrics and start metrics back ground thread <nl> metrics . setnumvolumes ( metadatamanager . countrowsintable ( metadatamanager
public list < privilegedoperation > bootstrap ( configuration configuration ) <nl> } <nl> / / add device set . here we trust the plugin ' s return value <nl> devicemappingmanager . adddeviceset ( resourcename , availabledevices ) ; <nl> - <nl> - <nl> + / / init cgroups <nl> + this . cgroupshandler . initializecgroupcontroller ( <nl> + cgroupshandler . cgroupcontroller . devices ) ; <nl> return null ; <nl> } <nl>  <nl> mmm a / hadoop - yarn - project / hadoop - yarn / hadoop - yarn - server / hadoop - yarn - server - nodemanager / src / test / java / org / apache / hadoop / yarn / server / nodemanager / containermanager / resourceplugin / deviceframework / testdevicepluginadapter . java <nl> ppp b / hadoop - yarn - project / hadoop - yarn / hadoop - yarn - server / hadoop - yarn - server - nodemanager / src / test / java / org / apache / hadoop / yarn / server / nodemanager / containermanager / resourceplugin / deviceframework / testdevicepluginadapter . java <nl>
<nl> < / dependencymanagement > <nl> < / profile > <nl> < profile > <nl> - < ! - - <nl> - < id > javadoc - html - version < / id > <nl> + < id > jdk11 < / id > <nl> < activation > <nl> < jdk > [ 11 , ) < / jdk > <nl> < / activation > <nl>
public static string replacepatternsinlaunchcommand ( string specifiedcli , <nl> return newcli ; <nl> } <nl>  <nl> - <nl> private static map < string , long > parseresourcesstring ( string resourcesstr ) { <nl> map < string , long > resources = new hashmap < > ( ) ; <nl> - <nl> - / / ignore the grouping " [ ] " <nl> - if ( resourcesstr . startswith ( " [ " ) ) { <nl> - resourcesstr = resourcesstr . substring ( 1 ) ; <nl> - } <nl> - if ( resourcesstr . endswith ( " ] " ) ) { <nl> - resourcesstr = resourcesstr . substring ( 0 , resourcesstr . length ( ) - num ) ; <nl> - } <nl> - <nl> - for ( string resource : resourcesstr . trim ( ) . split ( " , " ) ) { <nl> + string [ ] pairs = resourcesstr . trim ( ) . split ( " , " ) ; <nl> + for ( string resource : pairs ) { <nl> resource = resource . trim ( ) ; <nl> if ( ! resource . matches ( res_pattern ) ) { <nl> throw new illegalargumentexception ( " \ " " + resource + " \ " is not a " <nl>
<nl> / * * <nl> * handler for keyvalue container type . <nl> * / <nl> - @ singleton <nl> public class keyvaluehandler extends handler { <nl>  <nl> private static final logger log = loggerfactory . getlogger ( <nl> keyvaluehandler . class ) ; <nl>  <nl> - private static volatile keyvaluehandler instance = null ; / / singleton class <nl> - <nl> private final containertype containertype ; <nl> private final keymanager keymanager ; <nl> private final chunkmanager chunkmanager ; <nl> private volumechoosingpolicy volumechoosingpolicy ; <nl> private final int maxcontainersizegb ; <nl>  <nl> - <nl> - <nl> - public static keyvaluehandler getinstance ( configuration config , <nl> - containerset contset , <nl> - volumeset volset , <nl> - containermetrics metrics ) { <nl> - if ( instance = = null ) { <nl> - instance = new keyvaluehandler ( config , contset , volset , metrics ) ; <nl> - } <nl> - return instance ; <nl> - } <nl>  <nl> - private keyvaluehandler ( configuration config , containerset contset , <nl> + public keyvaluehandler ( configuration config , containerset contset , <nl> volumeset volset , containermetrics metrics ) { <nl> super ( config , contset , volset , metrics ) ; <nl> containertype = containertype . keyvaluecontainer ; <nl>
public void testnothingtokill ( ) throws exception { <nl>  <nl> / * * <nl> * test that node manager can exit listening . <nl> - * this is done by running a long running listener for num seconds . <nl> + * this is done by running a long running listener for num seconds . <nl> * then we wait for num seconds and stop listening . <nl> + * we do not use a script this time to avoid leaking the child process . <nl> * @ throws exception exception occurred <nl> * / <nl> @ test ( timeout = num ) <nl> public void testnormalexit ( ) throws exception { <nl> - <nl> - assumemacos ( ) ; <nl> conf . set ( yarnconfiguration . nm_elastic_memory_control_oom_listener_path , <nl> - script . getabsolutepath ( ) ) ; <nl> + " sleep " ) ; <nl> executorservice service = executors . newfixedthreadpool ( 1 ) ; <nl> try { <nl> - fileutils . writestringtofile ( script , <nl> - " # ! / bin / bash\nsleep num ; " , <nl> - charset . defaultcharset ( ) , false ) ; <nl> - asserttrue ( " could not set executable " , <nl> - script . setexecutable ( true ) ) ; <nl> - <nl> cgroupshandler cgroups = mock ( cgroupshandler . class ) ; <nl> - when ( cgroups . getpathforcgroup ( any ( ) , any ( ) ) ) . thenreturn ( " " ) ; <nl> + / / this will be passed to sleep as an argument <nl> + when ( cgroups . getpathforcgroup ( any ( ) , any ( ) ) ) . thenreturn ( " 10000 " ) ; <nl> when ( cgroups . getcgroupparam ( any ( ) , any ( ) , any ( ) ) ) <nl> . thenreturn ( " under_oom num " ) ; <nl>  <nl>
public void handle ( rmappattemptevent event ) { <nl> } catch ( invalidstatetransitionexception e ) { <nl> log . error ( " app attempt : " + appattemptid <nl> + " can ' t handle this event at current state " , e ) ; <nl> - / * <nl> + oninvalidtranstion ( event . gettype ( ) , oldstate ) ; <nl> } <nl>  <nl> / / log at info if we ' re not recovering or not in a terminal state . <nl>
public void handle ( rmappevent event ) { <nl> } catch ( invalidstatetransitionexception e ) { <nl> log . error ( " app : " + appid <nl> + " can ' t handle this event at current state " , e ) ; <nl> - / * <nl> + oninvalidstatetransition ( event . gettype ( ) , oldstate ) ; <nl> } <nl>  <nl> / / log at info if we ' re not recovering or not in a terminal state . <nl>
public void initializechannels ( configuration conf ) throws exception { <nl>  <nl> log . info ( " opening tcp and udp channels on { } port { } " , addr , port ) ; <nl> addnioudp ( addr , port ) ; <nl> - <nl> - / / addniotcp ( addr , port ) ; <nl> + addniotcp ( addr , port ) ; <nl> } <nl>  <nl> / * * <nl>
public void testmultipledatanodefailurerandomlength ( ) throws exception { <nl>  <nl> @ test ( timeout = 240000 ) <nl> public void testblocktokenexpired ( ) throws exception { <nl> - <nl> - assumetrue ( " test has been temporarily disabled . see hdfs - 12417 . " , false ) ; <nl> final int length = datablocks * ( blocksize - cellsize ) ; <nl> final hdfsconfiguration conf = newhdfsconfiguration ( ) ; <nl>  <nl>
public class datanodemanager { <nl> this . namesystem = namesystem ; <nl> this . blockmanager = blockmanager ; <nl>  <nl> - <nl> - / / testings / validations . <nl> this . usedfsnetworktopology = conf . getboolean ( <nl> dfsconfigkeys . dfs_use_dfs_network_topology_key , <nl> dfsconfigkeys . dfs_use_dfs_network_topology_default ) ;
public void testfakedirectorydeletion ( ) throws throwable { <nl> new metricdiff ( fs , statistic . directories_created ) ; <nl>  <nl> path srcdir = new path ( srcbasedir , " 1 / 2 / 3 / 4 / 5 / 6 " ) ; <nl> - path srcfilepath = new path ( srcdir , " source . txt " ) ; <nl> int srcdirdepth = directoriesinpath ( srcdir ) ; <nl> / / one dir created , one removed <nl> mkdirs ( srcdir ) ; <nl> string state = " after mkdir ( srcdir ) " ; <nl> directoriescreated . assertdiffequals ( state , num ) ; <nl> - / * <nl> deleterequests . assertdiffequals ( state , num ) ; <nl> directoriesdeleted . assertdiffequals ( state , num ) ; <nl> - fakedirectoriesdeleted . assertdiffequals ( state , srcdirdepth ) ; <nl> - * / <nl> + / / hadoop - 14255 deletes unnecessary fake directory objects in mkdirs ( ) <nl> + fakedirectoriesdeleted . assertdiffequals ( state , srcdirdepth - num ) ; <nl> reset ( deleterequests , directoriescreated , directoriesdeleted , <nl> fakedirectoriesdeleted ) ; <nl>  <nl> / / creating a file should trigger demise of the src dir <nl> + final path srcfilepath = new path ( srcdir , " source . txt " ) ; <nl> touch ( fs , srcfilepath ) ; <nl> state = " after touch ( fs , srcfilepath ) " ; <nl> deleterequests . assertdiffequals ( state , num ) ; <nl>
public void testfakedirectorydeletion ( ) throws throwable { <nl>  <nl> int destdirdepth = directoriesinpath ( destdir ) ; <nl> directoriescreated . assertdiffequals ( state , num ) ; <nl> - / * <nl> - is in <nl> - deleterequests . assertdiffequals ( state , 1 ) ; <nl> - directoriesdeleted . assertdiffequals ( state , 0 ) ; <nl> - fakedirectoriesdeleted . assertdiffequals ( state , destdirdepth ) ; <nl> - * / <nl> + deleterequests . assertdiffequals ( state , num ) ; <nl> + directoriesdeleted . assertdiffequals ( state , num ) ; <nl> + fakedirectoriesdeleted . assertdiffequals ( state , destdirdepth - num ) ; <nl> reset ( deleterequests , directoriescreated , directoriesdeleted , <nl> fakedirectoriesdeleted ) ;
public boolean mkdirs ( path path , fspermission permission ) throws ioexception , <nl> * @ throws ioexception other io problems <nl> * @ throws amazonclientexception on failures inside the aws sdk <nl> * / <nl> - <nl> - / / mkdirs for / foo / bar / baz / roo what happens to the empty file / foo / bar / ? <nl> private boolean innermkdirs ( path f , fspermission permission ) <nl> throws ioexception , filealreadyexistsexception , amazonclientexception { <nl> log . debug ( " making directory : { } " , f ) ; <nl>
private path getremotenodetmplogfileforapp ( ) { <nl> ( remotenodelogfileforapp . getname ( ) + logaggregationutils . tmp_file_suffix ) ) ; <nl> } <nl>  <nl> - <nl> - / / is not always true . <nl> private boolean shoulduploadlogs ( containerlogcontext logcontext ) { <nl> return logaggpolicy . shoulddologaggregation ( logcontext ) ; <nl> }
public void settimes ( path p , long mtime , long atime ) throws ioexception { <nl> pathtofile ( p ) . topath ( ) , basicfileattributeview . class ) ; <nl> filetime fmtime = ( mtime > = num ) ? filetime . frommillis ( mtime ) : null ; <nl> filetime fatime = ( atime > = num ) ? filetime . frommillis ( atime ) : null ; <nl> - <nl> - / / on some macos environment , basicfileattributeview . settimes <nl> - / / does not set times correctly when the argument of accesstime is null . <nl> - <nl> - if ( fatime = = null & & shell . mac ) { <nl> - filestatus f = getfilestatus ( p ) ; <nl> - fatime = filetime . frommillis ( f . getaccesstime ( ) ) ; <nl> - } <nl> - <nl> view . settimes ( fmtime , fatime , null ) ; <nl> } catch ( nosuchfileexception e ) { <nl> throw new filenotfoundexception ( " file " + p + " does not exist " ) ; <nl> mmm a / hadoop - hdfs - project / hadoop - hdfs / src / main / java / org / apache / hadoop / hdfs / server / datanode / directoryscanner . java <nl> ppp b / hadoop - hdfs - project / hadoop - hdfs / src / main / java / org / apache / hadoop / hdfs / server / datanode / directoryscanner . java <nl>
public void run ( ) { <nl> } ; <nl> } . start ( ) ; <nl>  <nl> - while ( ! jhsstarted ) { <nl> - log . info ( " waiting for historyserver to start . . . " ) ; <nl> - thread . sleep ( 1500 ) ; <nl> - } <nl> - <nl> + generictestutils . waitfor ( ( ) - > jhsstarted , num , num _000 ) ; <nl> + <nl> if ( historyserver . getservicestate ( ) ! = state . started ) { <nl> throw new ioexception ( " historyserver failed to start " ) ; <nl> }
private locatedblock createlocatedblock ( final blockinfo blk , final long pos ) <nl> final byte [ ] blockindices = blk . isstriped ( ) ? new byte [ nummachines ] : null ; <nl> int j = num , i = num ; <nl> if ( nummachines > num ) { <nl> + final boolean nocorrupt = ( numcorruptreplicas = = num ) ; <nl> for ( datanodestorageinfo storage : blocksmap . getstorages ( blk ) ) { <nl> - final datanodedescriptor d = storage . getdatanodedescriptor ( ) ; <nl> - final boolean replicacorrupt = corruptreplicas . isreplicacorrupt ( blk , d ) ; <nl> - if ( ( iscorrupt | | ( ! replicacorrupt ) ) & & <nl> - storage . getstate ( ) ! = state . failed ) { <nl> - machines [ j + + ] = storage ; <nl> - <nl> - if ( blockindices ! = null ) { <nl> - byte <nl> - assert <nl> - blockindices [ i + + ] = index ; <nl> + if ( storage . getstate ( ) ! = state . failed ) { <nl> + if ( nocorrupt ) { <nl> + machines [ j + + ] = storage ; <nl> + i = setblockindices ( blk , blockindices , i , storage ) ; <nl> + } else { <nl> + final datanodedescriptor d = storage . getdatanodedescriptor ( ) ; <nl> + final boolean replicacorrupt = isreplicacorrupt ( blk , d ) ; <nl> + if ( iscorrupt | | ! replicacorrupt ) { <nl> + machines [ j + + ] = storage ; <nl> + i = setblockindices ( blk , blockindices , i , storage ) ; <nl> + } <nl> } <nl> } <nl> } <nl>
private void amrestarttests ( boolean keeprunningcontainers ) <nl> assert . assertfalse ( attempt2 . getappattemptid ( ) <nl> . equals ( am0 . getapplicationattemptid ( ) ) ) ; <nl>  <nl> - / / launch the new am <nl> - <nl> - thread . sleep ( 1000 ) ; <nl> + rm . waitforstate ( attempt2 . getappattemptid ( ) , rmappattemptstate . scheduled ) ; <nl> nm . nodeheartbeat ( true ) ; <nl> mockam am1 = rm . sendamlaunched ( attempt2 . getappattemptid ( ) ) ; <nl> am1 . registerappattempt ( ) ; <nl> - <nl> + rm . waitforstate ( am1 . getapplicationattemptid ( ) , rmappattemptstate . running ) ; <nl> / / allocate num_containers containers <nl> am1 . allocate ( " 127 . 0 . 0 . 1 " , num , num_containers , <nl> new arraylist < containerid > ( ) ) ; <nl>
private void savenamespacewithinjectedfault ( fault fault ) throws exception { <nl> break ; <nl> case write_storage_all : <nl> / / the spy throws an exception before writing any version files <nl> - dothrow ( new runtimeexception ( " injected " ) ) <nl> - . when ( spystorage ) . writeall ( ) ; <nl> + doanswer ( new faultywriteproperties ( fault . write_storage_all ) ) <nl> + . when ( spystorage ) . writeproperties ( ( storagedirectory ) anyobject ( ) ) ; <nl> shouldfail = true ; <nl> break ; <nl> case write_storage_one : <nl> / / the spy throws on exception on one particular storage directory <nl> - doanswer ( new faultysaveimage ( true ) ) <nl> + doanswer ( new faultywriteproperties ( fault . write_storage_one ) ) <nl> . when ( spystorage ) . writeproperties ( ( storagedirectory ) anyobject ( ) ) ; <nl> - <nl> - / / see hdfs - 2173 . <nl> - shouldfail = true ; <nl> + shouldfail = false ; <nl> break ; <nl> }
private int invalidateworkforonenode ( datanodeinfo dn ) { <nl> return toinvalidate . size ( ) ; <nl> } <nl>  <nl> - <nl> boolean blockhasenoughracks ( blockinfo storedblock , int expectedstoragenum ) { <nl> if ( ! this . shouldcheckforenoughracks ) { <nl> return true ; <nl> } <nl> - boolean enoughracks = false ; <nl> collection < datanodedescriptor > corruptnodes = <nl> corruptreplicas . getnodes ( storedblock ) ; <nl> + <nl> + if ( storedblock . isstriped ( ) ) { <nl> + return blockhasenoughracksstriped ( storedblock , corruptnodes ) ; <nl> + } else { <nl> + return blockhashenoughrackscontiguous ( storedblock , expectedstoragenum , <nl> + corruptnodes ) ; <nl> + } <nl> + } <nl> + <nl> + / * * <nl> + * verify whether given striped block is distributed through enough racks . <nl> + * as dicussed in hdfs - 7613 , ec file requires racks at least as many as <nl> + * the number of data block number . <nl> + * / <nl> + boolean blockhasenoughracksstriped ( blockinfo storedblock , <nl> + collection < datanodedescriptor > corruptnodes ) { <nl> + if ( ! datanodemanager . hasclustereverbeenmultirack ( ) ) { <nl> + return true ; <nl> + } <nl> + boolean enoughracks = false ; <nl> + set < string > racknameset = new hashset < > ( ) ; <nl> + int datablocknum = ( ( blockinfostriped ) storedblock ) . getrealdatablocknum ( ) ; <nl> + for ( datanodestorageinfo storage : blocksmap . getstorages ( storedblock ) ) { <nl> + final datanodedescriptor cur = storage . getdatanodedescriptor ( ) ; <nl> + if ( ! cur . isdecommissioninprogress ( ) & & ! cur . isdecommissioned ( ) ) { <nl> + if ( ( corruptnodes = = null ) | | ! corruptnodes . contains ( cur ) ) { <nl> + string racknamenew = cur . getnetworklocation ( ) ; <nl> + racknameset . add ( racknamenew ) ; <nl> + if ( racknameset . size ( ) > = datablocknum ) { <nl> + enoughracks = true ; <nl> + break ; <nl> + } <nl> + } <nl> + } <nl> + } <nl> + return enoughracks ; <nl> + } <nl> + <nl> + boolean blockhashenoughrackscontiguous ( blockinfo storedblock , <nl> + int expectedstoragenum , collection < datanodedescriptor > corruptnodes ) { <nl> + boolean enoughracks = false ; <nl> string rackname = null ; <nl> for ( datanodestorageinfo storage : blocksmap . getstorages ( storedblock ) ) { <nl> final datanodedescriptor cur = storage . getdatanodedescriptor ( ) ;
public void dumptreerecursively ( printwriter out , stringbuilder prefix , <nl> out . print ( " , filesize = " + computefilesize ( snapshotid ) ) ; <nl> / / only compare the first block <nl> out . print ( " , blocks = " ) ; <nl> - out . print ( blocks = = null | | blocks . length = = num ? null : blocks [ 0 ] ) ; <nl> - <nl> + blockinfo [ ] blks = getblocks ( ) ; <nl> + out . print ( blks = = null | | blks . length = = num ? null : blks [ 0 ] ) ; <nl> out . println ( ) ; <nl> }
localizerheartbeatresponse processheartbeat ( <nl> try { <nl> req = new localresourcerequest ( rsrc ) ; <nl> } catch ( urisyntaxexception e ) { <nl> - <nl> + log . error ( <nl> + " got exception in parsing url of localresource : " <nl> + + rsrc . getresource ( ) , e ) ; <nl> } <nl> localizerresourcerequestevent assoc = scheduled . get ( req ) ; <nl> if ( assoc = = null ) { <nl>
localizerheartbeatresponse processheartbeat ( <nl> log . error ( " inorrect path for private localization . " <nl> + next . getresource ( ) . getfile ( ) , e ) ; <nl> } catch ( urisyntaxexception e ) { <nl> - <nl> + log . error ( <nl> + " got exception in parsing url of localresource : " <nl> + + next . getresource ( ) , e ) ; <nl> } <nl> }
public void run ( ) { <nl> applicationstatedata . newinstance ( 111 , num , " user " , null , <nl> rmappstate . accepted , " diagnostics " , num ) ) ; <nl> } catch ( exception e ) { <nl> - <nl> - / / that separately . <nl> - if ( ! e . getmessage ( ) . contains ( " could only be replicated " + <nl> - " to num nodes instead of minreplication ( = 1 ) " ) ) { <nl> - assertionfailedinthread . set ( true ) ; <nl> - } <nl> + assertionfailedinthread . set ( true ) ; <nl> e . printstacktrace ( ) ; <nl> } <nl> }
protected void serviceinit ( configuration conf ) throws exception { <nl> string auth = conf . gettrimmed ( key_registry_client_auth , <nl> registry_client_auth_anonymous ) ; <nl>  <nl> - <nl> - if ( registry_client_auth_kerberos . equals ( auth ) ) { <nl> + switch ( auth ) { <nl> + case registry_client_auth_kerberos : <nl> access = accesspolicy . sasl ; <nl> - } else if ( registry_client_auth_digest . equals ( auth ) ) { <nl> + break ; <nl> + case registry_client_auth_digest : <nl> access = accesspolicy . digest ; <nl> - } else if ( registry_client_auth_anonymous . equals ( auth ) ) { <nl> + break ; <nl> + case registry_client_auth_anonymous : <nl> access = accesspolicy . anon ; <nl> - } else { <nl> + break ; <nl> + default : <nl> throw new servicestateexception ( e_unknown_authentication_mechanism <nl> + " \ " " + auth + " \ " " ) ; <nl> }
public void startlocalizer ( path nmprivatecontainertokens , <nl> createusercachedirs ( localdirs , user ) ; <nl> createappdirs ( localdirs , user , appid ) ; <nl> createapplogdirs ( appid , logdirs , user ) ; <nl> - <nl> - <nl> - path appstoragedir = getfirstapplicationdir ( localdirs , user , appid ) ; <nl> + <nl> + path appstoragedir = getworkingdir ( localdirs , user , appid ) ; <nl>  <nl> string tokenfn = string . format ( containerlocalizer . token_file_name_fmt , locid ) ; <nl> path tokendst = new path ( appstoragedir , tokenfn ) ;
private void createencryptionzoneint ( final string srcarg , string keyid , <nl> / * * <nl> * create a new key on the keyprovider for an encryption zone . <nl> * <nl> - * @ param keyid id of the key <nl> + * @ param keyidarg id of the key <nl> * @ param src path of the encryption zone . <nl> * @ return keyversion of the created key <nl> * @ throws ioexception <nl> * / <nl> - private keyversion createnewkey ( string keyid , string src ) <nl> + private keyversion createnewkey ( string keyidarg , string src ) <nl> throws ioexception { <nl> - preconditions . checknotnull ( keyid ) ; <nl> + preconditions . checknotnull ( keyidarg ) ; <nl> preconditions . checknotnull ( src ) ; <nl> - <nl> - provideroptions . setdescription ( src ) ; <nl> + final stringbuilder sb = new stringbuilder ( " hdfs : / / " ) ; <nl> + if ( nameserviceid ! = null ) { <nl> + sb . append ( nameserviceid ) ; <nl> + } <nl> + sb . append ( src ) ; <nl> + if ( ! src . endswith ( " / " ) ) { <nl> + sb . append ( ' / ' ) ; <nl> + } <nl> + sb . append ( keyidarg ) ; <nl> + final string keyid = sb . tostring ( ) ; <nl> + provideroptions . setdescription ( keyid ) ; <nl> provideroptions . setbitlength ( codec . getciphersuite ( ) <nl> . getalgorithmblocksize ( ) * 8 ) ; <nl> keyversion version = null ; <nl> try { <nl> - version = provider . createkey ( keyid , provideroptions ) ; <nl> + version = provider . createkey ( keyidarg , provideroptions ) ; <nl> } catch ( nosuchalgorithmexception e ) { <nl> throw new ioexception ( e ) ; <nl> }
protected applicationhistorymanager createapplicationhistorymanager ( <nl>  <nl> protected applicationtimelinestore createapplicationtimelinestore ( <nl> configuration conf ) { <nl> - <nl> - / / leveldb implementation <nl> return reflectionutils . newinstance ( conf . getclass ( <nl> - yarnconfiguration . ats_store , memoryapplicationtimelinestore . class , <nl> + yarnconfiguration . ats_store , leveldbapplicationtimelinestore . class , <nl> applicationtimelinestore . class ) , conf ) ; <nl> }
public void testappshelpcommand ( ) throws exception { <nl> int result = spycli . run ( new string [ ] { " - help " } ) ; <nl> assert . asserttrue ( result = = num ) ; <nl> verify ( spycli ) . printusage ( any ( options . class ) ) ; <nl> - system . err . println ( sysoutstream . tostring ( ) ) ; <nl> assert . assertequals ( createapplicationclihelpmessage ( ) , <nl> sysoutstream . tostring ( ) ) ;
public void startlocalizer ( path nmprivatecontainertokenspath , <nl> } <nl> string [ ] commandarray = command . toarray ( new string [ command . size ( ) ] ) ; <nl> shellcommandexecutor shexec = new shellcommandexecutor ( commandarray ) ; <nl> - <nl> - log . info ( " initapplication : " + arrays . tostring ( commandarray ) ) ; <nl> if ( log . isdebugenabled ( ) ) { <nl> log . debug ( " initapplication : " + arrays . tostring ( commandarray ) ) ; <nl> } <nl>
class datastreamer extends daemon { <nl> private datainputstream blockreplystream ; <nl> private responseprocessor response = null ; <nl> private volatile datanodeinfo [ ] nodes = null ; / / list of targets for current block <nl> - <nl> private volatile string [ ] storageids = null ; <nl> private loadingcache < datanodeinfo , datanodeinfo > excludednodes = <nl> cachebuilder . newbuilder ( ) <nl>
private void deletecgroup ( string controller , string groupname ) { <nl> * next three functions operate on all the resources we are enforcing . <nl> * / <nl>  <nl> - / * <nl> - * <nl> - * ( or equivalent ) to multiply the weight by the number of requested cpus . <nl> - * / <nl> private void setuplimits ( containerid containerid , <nl> resource containerresource ) throws ioexception { <nl> string containername = containerid . tostring ( ) ; <nl>  <nl> if ( iscpuweightenabled ( ) ) { <nl> createcgroup ( controller_cpu , containername ) ; <nl> + int cpushares = cpu_default_weight * containerresource . getvirtualcores ( ) ; <nl> updatecgroup ( controller_cpu , containername , " shares " , <nl> - string . valueof ( cpu_default_weight ) ) ; <nl> + string . valueof ( cpushares ) ) ; <nl> } <nl> }
private amrmprotocol submitandregisterapplication ( <nl> unsupportedfilesystemexception , yarnremoteexception , <nl> interruptedexception { <nl>  <nl> - <nl> - / / app - dirs if there are no file to download ! ! <nl> - string filename = " testfile - " + appid . tostring ( ) ; <nl> - file testfile = new file ( localdir . getabsolutepath ( ) , filename ) ; <nl> - filewriter tmpfile = new filewriter ( testfile ) ; <nl> - tmpfile . write ( " testing " ) ; <nl> - tmpfile . close ( ) ; <nl> - url testfileurl = converterutils . getyarnurlfrompath ( filecontext <nl> - . getfilecontext ( ) . makequalified ( <nl> - new path ( localdir . getabsolutepath ( ) , filename ) ) ) ; <nl> - localresource rsrc = builderutils . newlocalresource ( testfileurl , <nl> - localresourcetype . file , localresourcevisibility . private , testfile <nl> - . length ( ) , testfile . lastmodified ( ) ) ; <nl> - <nl> containerlaunchcontext amcontainer = builderutils <nl> . newcontainerlaunchcontext ( null , " testuser " , builderutils <nl> - . newresource ( 1024 ) , collections . singletonmap ( filename , rsrc ) , <nl> + . newresource ( 1024 ) , collections . < string , localresource > emptymap ( ) , <nl> new hashmap < string , string > ( ) , arrays . aslist ( " sleep " , " 100 " ) , <nl> new hashmap < string , bytebuffer > ( ) , null , <nl> new hashmap < applicationaccesstype , string > ( ) ) ;
public void progressing ( taskattemptid attemptid ) { <nl> } <nl> } <nl>  <nl> - public void pinged ( taskattemptid attemptid ) { <nl> - / / only put for the registered attempts <nl> - <nl> - reporttime time = runningattempts . get ( attemptid ) ; <nl> - if ( time ! = null ) { <nl> - time . setlastping ( clock . gettime ( ) ) ; <nl> - } <nl> - } <nl>  <nl> public void register ( taskattemptid attemptid ) { <nl> runningattempts . put ( attemptid , new reporttime ( clock . gettime ( ) ) ) ; <nl>
public void allowsnapshot ( string path ) throws safemodeexception , ioexception { <nl> } <nl> geteditlog ( ) . logsync ( ) ; <nl>  <nl> - <nl> + if ( auditlog . isinfoenabled ( ) & & isexternalinvocation ( ) ) { <nl> + logauditevent ( usergroupinformation . getcurrentuser ( ) , getremoteip ( ) , <nl> + " allowsnapshot " , path , null , null ) ; <nl> + } <nl> } <nl>  <nl> / / disallow snapshot on a directory . <nl>
public void createsnapshot ( string snapshotname , string path ) <nl> } <nl> geteditlog ( ) . logsync ( ) ; <nl>  <nl> - <nl> + if ( auditlog . isinfoenabled ( ) & & isexternalinvocation ( ) ) { <nl> + path snapshotroot = new path ( path , " . snapshot / " + snapshotname ) ; <nl> + logauditevent ( usergroupinformation . getcurrentuser ( ) , getremoteip ( ) , <nl> + " createsnapshot " , path , snapshotroot . tostring ( ) , null ) ; <nl> + } <nl> } <nl> }
protected string expandcommand ( final string cmd ) { <nl> protected result execute ( clicommand cmd ) throws exception { <nl> return cmd . getexecutor ( namenode ) . executecommand ( cmd . getcmd ( ) ) ; <nl> } <nl> - <nl> - <nl> - / / hdfs - 2038 is going to fix it . disable the test for the moment . <nl> + <nl> @ test <nl> @ override <nl> public void testall ( ) { <nl> mmm a / hadoop - hdfs - project / hadoop - hdfs / src / test / resources / testhdfsconf . xml <nl> ppp b / hadoop - hdfs - project / hadoop - hdfs / src / test / resources / testhdfsconf . xml <nl>
public abstract class zkfailovercontroller implements tool { <nl>  <nl> static final log log = logfactory . getlog ( zkfailovercontroller . class ) ; <nl>  <nl> - <nl> public static final string zk_quorum_key = " ha . zookeeper . quorum " ; <nl> private static final string zk_session_timeout_key = " ha . zookeeper . session - timeout . ms " ; <nl> private static final int zk_session_timeout_default = num * 1000 ; <nl>
protected void setadminstate ( adminstates newstate ) { <nl> @ override <nl> public void write ( dataoutput out ) throws ioexception { <nl> super . write ( out ) ; <nl> - <nl> - <nl> - out . writeshort ( ipcport ) ; <nl> - <nl> out . writelong ( capacity ) ; <nl> out . writelong ( dfsused ) ; <nl> out . writelong ( remaining ) ; <nl>
public void write ( dataoutput out ) throws ioexception { <nl> @ override <nl> public void readfields ( datainput in ) throws ioexception { <nl> super . readfields ( in ) ; <nl> - <nl> - <nl> - this . ipcport = in . readshort ( ) & num x0000ffff ; <nl> - <nl> this . capacity = in . readlong ( ) ; <nl> this . dfsused = in . readlong ( ) ; <nl> this . remaining = in . readlong ( ) ;
protected void processpath ( pathdata item ) throws ioexception { <nl>  <nl> @ override <nl> protected void processnonexistentpath ( pathdata item ) throws ioexception { <nl> - <nl> if ( ! item . fs . mkdirs ( item . path ) ) { <nl> throw new pathioexception ( item . tostring ( ) ) ; <nl> }
public int gettotalblocks ( ) { <nl>  <nl> public void removeblock ( block block ) { <nl> assert namesystem . haswritelock ( ) ; <nl> - <nl> - / / the sbn doesn ' t get block deletions until the next <nl> - / / br . . . <nl> - / / block . setnumbytes ( blockcommand . no_ack ) ; <nl> + / / no need to ack blocks that are being removed entirely <nl> + / / from the namespace , since the removal of the associated <nl> + / / file already removes them from the block map below . <nl> + block . setnumbytes ( blockcommand . no_ack ) ; <nl> addtoinvalidates ( block ) ; <nl> corruptreplicas . removefromcorruptreplicasmap ( block ) ; <nl> blocksmap . removeblock ( block ) ; <nl> mmm a / hadoop - hdfs - project / hadoop - hdfs / src / test / java / org / apache / hadoop / hdfs / server / namenode / ha / testhasafemode . java <nl> ppp b / hadoop - hdfs - project / hadoop - hdfs / src / test / java / org / apache / hadoop / hdfs / server / namenode / ha / testhasafemode . java <nl>
public static void registercommands ( commandfactory factory ) { <nl> / * * merge multiple files together * / <nl> public static class merge extends fscommand { <nl> public static final string name = " getmerge " ; <nl> - public static final string usage = " < src > < localdst > [ addnl ] " ; <nl> + public static final string usage = " [ - nl ] < src > < localdst > " ; <nl> public static final string description = <nl> " get all the files in the directories that\n " + <nl> " match the source file pattern and merge and sort them to only\n " + <nl> - " one file on local fs . < src > is kept . " ; <nl> + " one file on local fs . < src > is kept . \n " + <nl> + " - nl add a newline character at the end of each file . " ; <nl>  <nl> protected pathdata dst = null ; <nl> protected string delimiter = null ; <nl>  <nl> @ override <nl> protected void processoptions ( linkedlist < string > args ) throws ioexception { <nl> - commandformat cf = new commandformat ( 2 , num ) ; <nl> + commandformat cf = new commandformat ( 2 , num , " nl " ) ; <nl> cf . parse ( args ) ; <nl>  <nl> - <nl> - if ( ( args . size ( ) > num ) & & boolean . parseboolean ( args . removelast ( ) ) ) { <nl> - delimiter = " \n " ; <nl> - } else { <nl> - delimiter = null ; <nl> - } <nl> + delimiter = cf . getopt ( " nl " ) ? " \n " : null ; <nl>  <nl> dst = new pathdata ( new file ( args . removelast ( ) ) , getconf ( ) ) ; <nl> } <nl>
datanodecommand blockreport ( ) throws ioexception { <nl>  <nl> heartbeatresponse sendheartbeat ( ) throws ioexception { <nl> log . info ( " heartbeat : " + this ) ; <nl> - <nl> - / / same time , this one won ' t block on the other one ? <nl> return bpnamenode . sendheartbeat ( bpregistration , <nl> dn . getfsdataset ( ) . getcapacity ( ) , <nl> dn . getfsdataset ( ) . getdfsused ( ) , <nl>
<nl> import org . apache . hadoop . mapred . ifile . writer ; <nl> import org . apache . hadoop . mapred . task . combineoutputcollector ; <nl> import org . apache . hadoop . mapred . task . taskreporter ; <nl> + import org . apache . hadoop . mapreduce . mrjobconfig ; <nl> import org . junit . test ; <nl>  <nl> public class testcombineoutputcollector { <nl> private combineoutputcollector < string , integer > coc ; <nl>  <nl> counters . counter outcounter = new counters . counter ( ) { <nl> - <nl> + private long value ; <nl> @ override <nl> public void setvalue ( long value ) { <nl> - <nl> - <nl> + this . value = value ; <nl> } <nl>  <nl> @ override <nl>
public string makeescapedcompactstring ( ) { <nl>  <nl> @ override <nl> public long getcounter ( ) { <nl> - <nl> - return num ; <nl> + return value ; <nl> } <nl>  <nl> @ override <nl>
public class jobhistory extends abstractservice implements historycontext { <nl>  <nl> private static final log summary_log = logfactory . getlog ( jobsummary . class ) ; <nl>  <nl> - / * <nl> - * <nl> - * / <nl> - private static final comparator < jobid > job_id_comparator = <nl> - new comparator < jobid > ( ) { <nl> - @ override <nl> - public int compare ( jobid o1 , jobid o2 ) { <nl> - if ( o1 . getappid ( ) . getclustertimestamp ( ) > <nl> - o2 . getappid ( ) . getclustertimestamp ( ) ) { <nl> - return num ; <nl> - } else if ( o1 . getappid ( ) . getclustertimestamp ( ) < <nl> - o2 . getappid ( ) . getclustertimestamp ( ) ) { <nl> - return - 1 ; <nl> - } else { <nl> - return o1 . getid ( ) - o2 . getid ( ) ; <nl> - } <nl> - } <nl> - } ; <nl> - <nl> private static string done_before_serial_tail = <nl> jobhistoryutils . donesubdirsbeforeserialtail ( ) ; <nl>  <nl>
protected containermanager getcmproxy ( containerid containerid , <nl>  <nl> usergroupinformation user = usergroupinformation . getcurrentuser ( ) ; <nl>  <nl> - <nl> if ( usergroupinformation . issecurityenabled ( ) ) { <nl> - if ( ! ugimap . containskey ( containermanagerbindaddr ) ) { <nl> - token < containertokenidentifier > token = <nl> - new token < containertokenidentifier > ( <nl> - containertoken . getidentifier ( ) . array ( ) , <nl> - containertoken . getpassword ( ) . array ( ) , new text ( <nl> - containertoken . getkind ( ) ) , new text ( <nl> - containertoken . getservice ( ) ) ) ; <nl> - / / the user in createremoteuser in this context is not important <nl> - user = usergroupinformation . createremoteuser ( containermanagerbindaddr ) ; <nl> - user . addtoken ( token ) ; <nl> - ugimap . put ( containermanagerbindaddr , user ) ; <nl> - } else { <nl> - user = ugimap . get ( containermanagerbindaddr ) ; <nl> - } <nl> + <nl> + token < containertokenidentifier > token = new token < containertokenidentifier > ( <nl> + containertoken . getidentifier ( ) . array ( ) , containertoken <nl> + . getpassword ( ) . array ( ) , new text ( containertoken . getkind ( ) ) , <nl> + new text ( containertoken . getservice ( ) ) ) ; <nl> + / / the user in createremoteuser in this context is not important <nl> + usergroupinformation ugi = usergroupinformation <nl> + . createremoteuser ( containermanagerbindaddr ) ; <nl> + ugi . addtoken ( token ) ; <nl> + ugimap . putifabsent ( containermanagerbindaddr , ugi ) ; <nl> + <nl> + user = ugimap . get ( containermanagerbindaddr ) ; <nl> } <nl> containermanager proxy = <nl> user . doas ( new privilegedaction < containermanager > ( ) {
abstract class commandwithdestination extends fscommand { <nl> protected pathdata dst ; <nl> protected boolean overwrite = false ; <nl>  <nl> - <nl> + / * * <nl> + * <nl> + * this method is used to enable the force ( - f ) option while copying the files . <nl> + * <nl> + * @ param flag true / false <nl> + * / <nl> protected void setoverwrite ( boolean flag ) { <nl> overwrite = flag ; <nl> } <nl> mmm a / common / src / java / org / apache / hadoop / fs / shell / copycommands . java <nl> ppp b / common / src / java / org / apache / hadoop / fs / shell / copycommands . java <nl>
class butterknifeplugin : plugin < project > { <nl> when ( it ) { <nl> is featureplugin - > { <nl> project . extensions [ featureextension : : class ] . run { <nl> - applyplugin ( featurevariants ) <nl> - applyplugin ( libraryvariants ) <nl> + configurer2generation ( project , featurevariants ) <nl> + configurer2generation ( project , libraryvariants ) <nl> + } <nl> + } <nl> + is libraryplugin - > { <nl> + project . extensions [ libraryextension : : class ] . run { <nl> + configurer2generation ( project , libraryvariants ) <nl> + } <nl> + } <nl> + is appplugin - > { <nl> + project . extensions [ appextension : : class ] . run { <nl> + configurer2generation ( project , applicationvariants ) <nl> } <nl> } <nl> - is libraryplugin - > applyplugin ( project . extensions [ libraryextension : : class ] . libraryvariants ) <nl> - is appplugin - > applyplugin ( project . extensions [ appextension : : class ] . applicationvariants ) <nl> } <nl> } <nl> } <nl>  <nl> - private fun applyplugin ( variants : domainobjectset < out basevariant > ) { <nl> + private fun configurer2generation ( project : project , variants : domainobjectset < out basevariant > ) { <nl> variants . all { variant - > <nl> + val outputdir = project . builddir . resolve ( <nl> + " generated / source / r2 / $ { variant . dirname } " ) <nl> + <nl> + val task = project . tasks . create ( " generate $ { variant . name . capitalize ( ) } r2 " ) <nl> + task . outputs . dir ( outputdir ) <nl> + variant . registerjavageneratingtask ( task , outputdir ) <nl> + <nl> + val once = atomicboolean ( ) <nl> variant . outputs . all { output - > <nl> val processresources = output . processresources <nl> - <nl> - processresources . dolast { <nl> - val pathtor = processresources . packageforr . replace ( ' . ' , file . separatorchar ) <nl> + task . dependson ( processresources ) <nl> + <nl> + / / though there might be multiple outputs , their r files are all the same . thus , we only <nl> + / / need to configure the task once with the r . java input and action . <nl> + if ( once . compareandset ( false , true ) ) { <nl> + val rpackage = processresources . packageforr <nl> + val pathtor = rpackage . replace ( ' . ' , file . separatorchar ) <nl> val rfile = processresources . sourceoutputdir . resolve ( pathtor ) . resolve ( " r . java " ) <nl>  <nl> - finalrclassbuilder . brewjava ( rfile , processresources . sourceoutputdir , <nl> - processresources . packageforr , " r2 " ) <nl> + task . apply { <nl> + inputs . file ( rfile ) <nl> + <nl> + dolast { <nl> + finalrclassbuilder . brewjava ( rfile , outputdir , rpackage , " r2 " ) <nl> + } <nl> + } <nl> } <nl> } <nl> }
<nl> - package butterknife . internal ; <nl> - <nl> - / / note : this class uses single - method classes rather than interfaces as a trick to test easily . <nl> - public class listenertest { <nl> - <nl> - / / @ test public void typeswithoutonemethodareinvalid ( ) { <nl> - / / try { <nl> - / / class zeromethods { <nl> - / / } <nl> - / / <nl> - / / listener . from ( zeromethods . class ) ; <nl> - / / fail ( " one method is required . " ) ; <nl> - / / } catch ( illegalargumentexception e ) { <nl> - / / assertthat ( e ) . hasmessage ( " zeromethods is not a single - method interface " ) ; <nl> - / / } <nl> - / / <nl> - / / try { <nl> - / / @ suppresswarnings ( " unuseddeclaration " ) / / <nl> - / / class twomethods { <nl> - / / public void methodone ( ) { } <nl> - / / public void methodtwo ( ) { } <nl> - / / } <nl> - / / <nl> - / / listener . from ( twomethods . class ) ; <nl> - / / fail ( " one method is required . " ) ; <nl> - / / } catch ( illegalargumentexception e ) { <nl> - / / assertthat ( e ) . hasmessage ( " twomethods is not a single - method interface " ) ; <nl> - / / } <nl> - / / } <nl> - / / <nl> - / / @ suppresswarnings ( " unuseddeclaration " ) / / <nl> - / / interface simplecase { <nl> - / / void foo ( string foo , int bar , biginteger baz ) ; <nl> - / / } <nl> - / / <nl> - / / @ test public void simplecase ( ) { <nl> - / / listener listener = listener . from ( simplecase . class ) ; <nl> - / / <nl> - / / assertthat ( listener . getownertype ( ) ) . isequalto ( " butterknife . internal . listenertest " ) ; <nl> - / / assertthat ( listener . getsettername ( ) ) . isequalto ( " setsimplecase " ) ; <nl> - / / assertthat ( listener . gettype ( ) ) . isequalto ( " butterknife . internal . listenertest . simplecase " ) ; <nl> - / / assertthat ( listener . getmethodname ( ) ) . isequalto ( " foo " ) ; <nl> - / / assertthat ( listener . getreturntype ( ) ) . isequalto ( " void " ) ; <nl> - / / assertthat ( listener . getparametertypes ( ) ) / / <nl> - / / . containsexactly ( " string " , " int " , " java . math . biginteger " ) ; <nl> - / / } <nl> - / / <nl> - / / <nl> - / / @ suppresswarnings ( " unuseddeclaration " ) / / <nl> - / / interface genericparameter { <nl> - / / boolean foo ( adapterview < ? > adapterview ) ; <nl> - / / } <nl> - / / <nl> - / / @ test public void genericparameter ( ) { <nl> - / / listener listener = listener . from ( genericparameter . class ) ; <nl> - / / <nl> - / / assertthat ( listener . getownertype ( ) ) . isequalto ( " butterknife . internal . listenertest " ) ; <nl> - / / assertthat ( listener . getsettername ( ) ) . isequalto ( " setgenericparameter " ) ; <nl> - / / assertthat ( listener . gettype ( ) ) . isequalto ( " butterknife . internal . listenertest . genericparameter " ) ; <nl> - / / assertthat ( listener . getmethodname ( ) ) . isequalto ( " foo " ) ; <nl> - / / assertthat ( listener . getreturntype ( ) ) . isequalto ( " boolean " ) ; <nl> - / / assertthat ( listener . getparametertypes ( ) ) . containsexactly ( " android . widget . adapterview < ? > " ) ; <nl> - / / } <nl> - }
<nl> - / * * note : this file is still under development * / <nl> package com . williamfiset . algorithms . sorting ; <nl>  <nl> + / / see https : / / en . wikipedia . org / wiki / radix_sort for details on runtime and complexity <nl> + / / radix sorts operates in o ( nw ) time , where n is the number of keys , and w is the key length <nl> + / / where w is constant on primitive types like integer <nl> + / / which gives it a better performance than other compare - based sort algorithms , like i . e . quicksort <nl> + <nl> public class radixsort { <nl> - public static void radixsort ( int [ ] ar ) { <nl> - <nl> + static int getmax ( int [ ] array ) { <nl> + int max = array [ 0 ] ; <nl> + for ( int i = num ; i < array . length ; i + + ) { <nl> + if ( array [ i ] > max ) { <nl> + max = array [ i ] ; <nl> + } <nl> + } <nl> + return max ; <nl> + } <nl> + <nl> + static int calculatenumberofdigits ( int number ) { <nl> + return ( int ) math . log10 ( number ) + num ; <nl> + } <nl> + <nl> + public static void radixsort ( int numbers [ ] ) { <nl> + int maximum = getmax ( numbers ) ; <nl> + int numberofdigits = calculatenumberofdigits ( maximum ) ; <nl> + int placevalue = num ; <nl> + while ( numberofdigits - - > num ) { <nl> + countsort ( numbers , placevalue ) ; <nl> + placevalue * = num ; <nl> + } <nl> + } <nl> + <nl> + private static void countsort ( int [ ] numbers , int placevalue ) { <nl> + int range = num ; <nl> + <nl> + int [ ] frequency = new int [ range ] ; <nl> + int [ ] sortedvalues = new int [ numbers . length ] ; <nl> + <nl> + for ( int i = num ; i < numbers . length ; i + + ) { <nl> + int digit = ( numbers [ i ] / placevalue ) % range ; <nl> + frequency [ digit ] + + ; <nl> + } <nl> + <nl> + for ( int i = num ; i < range ; i + + ) { <nl> + frequency [ i ] + = frequency [ i - num ] ; <nl> + } <nl> + <nl> + for ( int i = numbers . length - num ; i > = num ; i - - ) { <nl> + int digit = ( numbers [ i ] / placevalue ) % range ; <nl> + sortedvalues [ frequency [ digit ] - num ] = numbers [ i ] ; <nl> + frequency [ digit ] - - ; <nl> + } <nl> + <nl> + system . arraycopy ( sortedvalues , num , numbers , num , numbers . length ) ; <nl> } <nl> } <nl> mmm / dev / null <nl> ppp b / src / test / java / com / williamfiset / algorithms / sorting / main . java <nl>
public class longestcommonsubstringtest { <nl> verifymultiplekvalues ( strs , answers ) ; <nl> } <nl>  <nl> + @ test <nl> + public void multiplekvaluetest5 ( ) { <nl> + string [ ] strs = { " abcde " , " f " , " ghij " , " kmlop " , " qrs " , " tu " , " v " , " wxyz " } ; <nl> + map < integer , treeset < string > > answers = new hashmap < > ( ) ; <nl> + <nl> + answers . put ( 2 , new treeset < > ( ) ) ; <nl> + answers . put ( 3 , new treeset < > ( ) ) ; <nl> + answers . put ( 4 , new treeset < > ( ) ) ; <nl> + answers . put ( 5 , new treeset < > ( ) ) ; <nl> + answers . put ( 6 , new treeset < > ( ) ) ; <nl> + answers . put ( 7 , new treeset < > ( ) ) ; <nl> + answers . put ( 8 , new treeset < > ( ) ) ; <nl> + verifymultiplekvalues ( strs , answers ) ; <nl> + } <nl> + <nl> @ test <nl> public void nolongestcommonsubstringtest ( ) { <nl> - <nl> int k = num ; <nl> string [ ] strs = { " abcd " , " efgh " } ;
public class minimumweightperfectmatching { <nl> n = cost . length ; <nl> if ( n % num ! = num ) <nl> throw new illegalargumentexception ( " matrix has an odd size , no perfect matching exists . " ) ; <nl> - <nl> + if ( n > num ) throw new illegalargumentexception ( " matrix too large ! a matrix that size for the mwpm problem with a time complexity of " + <nl> + " o ( n ^ 3 * 2 ^ n ) requires way too much computation and memory for a modern home computer . " ) ; <nl> this . cost = cost ; <nl> } <nl>  <nl> - public string pbs ( int b ) { <nl> - return string . format ( " % 1 $ 10s " , integer . tobinarystring ( b ) ) ; <nl> - } <nl> - <nl> public double getminweightcost ( ) { <nl> if ( ! solved ) solve ( ) ; <nl> return minweightcost ; <nl> } <nl>  <nl> - public void solve2 ( ) { <nl> - / / state is : number of pairs solved for ( zero based ) and the binary encoded state . <nl> + / * * <nl> + * get the minimum weight cost matching . <nl> + * the matching is returned as an array where the nodes at <nl> + * a matched pair . for example , nodes at indexes ( 0 , num ) are a pair , ( 2 , num ) are <nl> + * another pair , etc . . . <nl> + * <nl> + * how to iterate over the pairs : <nl> + * < pre > <nl> + * { @ code <nl> + * minimumweightperfectmatching mwpm = . . . <nl> + * int [ ] matching = mwpm . getminweightcostmatching ( ) ; <nl> + * for ( int i = num ; i & lt ; n / 2 ; i + = num ) { <nl> + * int node1 = matching [ 2 * i ] ; <nl> + * int node2 = matching [ 2 * i + 1 ] ; <nl> + * / / do something with the matched pair ( node1 , node2 ) <nl> + * } <nl> + * } < / pre > <nl> + * / <nl> + public int [ ] getminweightcostmatching ( ) { <nl> + if ( ! solved ) solve ( ) ; <nl> + return matching ; <nl> + } <nl> + <nl> + public void solve ( ) { <nl> double [ ] [ ] dp = new double [ n > > num ] [ 1 < < n ] ; <nl>  <nl> int numpairs = ( n * ( n + 1 ) ) / 2 ; <nl>
an indexed pq is a pq variant which allows access to key - value pairs within the <nl>  <nl> now we ' re going to look at the eager version of dijkstra ' s algorithm where we don ' t ever have duplicate keys in the pq . <nl>  <nl> - first insert the <nl> + - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - <nl>  <nl> - then visit all the neighbors of zero <nl> - . . . . . . . . . <nl> - . . . . . . . . . <nl> - <nl> - . . . . . . . . . <nl> - . . . . . . . . . <nl> + to start with , assign a distance of zero to the start node at <nl> + <nl> + then the algorithm actually starts and we look inside the pq for the first time and we discover that we should visit node num . <nl> + <nl> + from node num we can visit node num by using the edge with a cost of num . this gives us a best distance of num , so we can update our best distance from infinity to num in the ' dist ' array . also add this information to the pq . <nl> + <nl> + next we can visit node num from node num . just like the last node we can update the optimal distance to reach node num from infinity to num . additionally , add that node num is reachable with a distance of num to the pq . <nl> + <nl> + that concludes visiting all the edges for node num . to decide which node to visit next dijkstra ' s always select the next most promising node in the pq . to do this , simply poll the next best key - value pair from the pq . <nl> + <nl> + node num is the next most promising node because it has a distance of num from the start node while node num has a greater value of num . <nl> + <nl> + from node num , if we take the sideways edge to improve the best distance to node num to be num by taking the current best distance from node num , which is num , plus the edge cost of num to get the node num , for a total cost of num . <nl> + <nl> + we can also update the best distance to node num by taking the upwards edge from node num . notice that i did not insert a new key - value pair with a value of num comma num inside the pq but rather simply updated the existing value in the pq from num to num , this is the main difference between the lazy and the eager version . <nl> + <nl> + < press > <nl> + <nl> + the next most promising node is node num <nl> + <nl> + when taking the downwards edge from node num to node num we discover that node num has already been visited so we cannot improve its already best distance . <nl> + <nl> + we also cannot improve the best distance to node num by taking the diagonal downwards edge since the total cost outweighs the best distance already known for that node . <nl> + <nl> + however , we can improve the best distance to node num by taking the edge from node num to node num with a cost of num . <nl> + <nl> + i ' ll let the animation play , and as it does try and predict what the next move for the algorithm will be . <nl>  <nl> + . . . <nl>  <nl> so that ' s the eager version of dijkstra ' s algorithm which i would say is the proper way of implementing dijkstra ' s . let ' s take a look at some pseudo - code to see what needs to change .
and we ' ve made it to node num so we know it ' s possible to reach . <nl>  <nl> similarly we can update nodes num and num to have a low link value of num by the same logic . <nl>  <nl> + so in general when we look at all the directed edges we have traversed , the ones which form bridges in our undirected graph are the ones where the id of the node you started at is less than the low link of the node you ' re going to . take a moment to think about why this is true . < / pause > . let ' s look where these bridges actually occur . in each instance the id of the node where the directed edge started at is less than the low link value of the node it ' s going to . rephrasing that in another way it means there was no back edge connecting back to the starting component which is really the definition of what a bridge is . otherwise , if there was a back edge connecting backwards to the starting component the low link value of where the edge is pointing to would at least as low as the id of the node you started at . <nl>  <nl> - <nl> - <nl> - <nl> - <nl> - <nl> - <nl> + for example , if i add a back edge from node num to node num suddenly the edge from node num to node num is no longer a bridge because the low link value on node five got updated to num and our bridge property highlighted in teal no longer holds . <nl>  <nl> + let ' s take an aside and think of the time complexity of the algorithm i just presented . right now we ' re doing a dfs to label all the nodes plus v more depth first searches to find all the low link values for roughly big o of v times v plus e in the worst case if we ' re being really pessimistic and stupid with our programming . <nl> + luckily , however we can do much better than this and instead update all low - link values in one pass for a linear time complexity .
public class pkirealm extends realm implements cachingrealm { <nl> " pki_delegated_by_user " , <nl> token . getdelegateeauthentication ( ) . geteffectivesubject ( ) . getuser ( ) . principal ( ) , <nl> " pki_delegated_by_realm " , <nl> - <nl> - token . getdelegateeauthentication ( ) . getauthenticatingsubject ( ) . getrealm ( ) . getname ( ) <nl> + token . getdelegateeauthentication ( ) . geteffectivesubject ( ) . getrealm ( ) . getname ( ) <nl> ) ; <nl> } else { <nl> metadata = map . of ( " pki_dn " , token . dn ( ) ) ; <nl> mmm a / x - pack / plugin / security / src / test / java / org / elasticsearch / xpack / security / authc / pki / pkirealmtests . java <nl> ppp b / x - pack / plugin / security / src / test / java / org / elasticsearch / xpack / security / authc / pki / pkirealmtests . java <nl>
public class diskhealthindicatorservice implements healthindicatorservice { <nl> for ( string nodeid : diskhealthbynode . keyset ( ) ) { <nl> discoverynode node = clusterstate . getnodes ( ) . get ( nodeid ) ; <nl> healthstatus healthstatus = diskhealthbynode . get ( nodeid ) . healthstatus ( ) ; <nl> - <nl> - if ( mostseverestatussofar . value ( ) < healthstatus . value ( ) ) { <nl> - mostseverestatussofar = healthstatus ; <nl> - } <nl> if ( node = = null | | healthstatus . indicateshealthproblem ( ) = = false ) { <nl> continue ; <nl> } <nl> + <nl> + if ( mostseverestatussofar . value ( ) < healthstatus . value ( ) ) { <nl> + mostseverestatussofar = healthstatus ; <nl> + } <nl> affectedroles . addall ( node . getroles ( ) ) ; <nl> if ( node . cancontaindata ( ) ) { <nl> datanodes . add ( node ) ; <nl> mmm a / server / src / test / java / org / elasticsearch / health / node / diskhealthindicatorservicetests . java <nl> ppp b / server / src / test / java / org / elasticsearch / health / node / diskhealthindicatorservicetests . java <nl>
public class diskhealthindicatorservicetests extends estestcase { <nl> healthindicatorresult result = diskhealthindicatorservice . calculate ( true , healthinfo ) ; <nl> assertthat ( result . status ( ) , equalto ( expectedstatus ) ) ; <nl> } <nl> - { <nl> - healthstatus expectedstatus = healthstatus . unknown ; <nl> - healthinfo healthinfo = createhealthinfowithoneunhealthynode ( expectedstatus , discoverynodes ) ; <nl> - healthindicatorresult result = diskhealthindicatorservice . calculate ( true , healthinfo ) ; <nl> - assertthat ( result . status ( ) , equalto ( expectedstatus ) ) ; <nl> - } <nl> - { <nl> - <nl> - healthstatus expectedstatus = healthstatus . unknown ; <nl> - healthinfo healthinfo = createhealthinfowithoneunhealthynode ( expectedstatus , discoverynodes ) ; <nl> - healthindicatorresult result = diskhealthindicatorservice . calculate ( true , healthinfo ) ; <nl> - assertthat ( result . status ( ) , equalto ( expectedstatus ) ) ; <nl> - } <nl> { <nl> healthstatus expectedstatus = healthstatus . yellow ; <nl> healthinfo healthinfo = createhealthinfowithoneunhealthynode ( expectedstatus , discoverynodes ) ; <nl>
public class internalcartesiancentroidtests extends internalaggregationtestcase < <nl> protected internalcartesiancentroid createtestinstance ( string name , map < string , object > metadata ) { <nl> point point = shapetestutils . randompoint ( false ) ; <nl> cartesianpoint centroid = new cartesianpoint ( point . getx ( ) , point . gety ( ) ) ; <nl> - <nl> - <nl> + / / unlike internalgeocentroid , we do not need to encode / decode to handle hashcode test failures , <nl> + / / but we do need to treat zero values with care . see the mutate function below for details on that <nl> long count = randomintbetween ( 0 , num ) ; <nl> if ( count = = num ) { <nl> centroid = null ; <nl>
public class internalcartesiancentroidtests extends internalaggregationtestcase < <nl> assertequals ( sampled . count ( ) , samplingcontext . scaleup ( reduced . count ( ) ) , num ) ; <nl> } <nl>  <nl> - @ awaitsfix ( bugurl = " https : / / github . com / elastic / elasticsearch / issues / 90474 " ) <nl> - @ override <nl> - public void testequalsandhashcode ( ) { <nl> - <nl> - super . testequalsandhashcode ( ) ; <nl> - } <nl> - <nl> public void testreducemaxcount ( ) { <nl> internalcartesiancentroid maxvaluecentroid = new internalcartesiancentroid ( <nl> " agg " , <nl>
import java . util . map ; <nl>  <nl> import static org . hamcrest . core . is . is ; <nl>  <nl> - / / these tests are here today so they have access to a proper rest client . they cannot be in : server : integtest since the rest client needs a <nl> - / / proper transport implementation , and they cannot be rest tests today since they need to restart nodes . when # 35599 and friends land we <nl> - <nl> @ esintegtestcase . clusterscope ( scope = esintegtestcase . scope . test , numdatanodes = num , automanagemasternodes = false ) <nl> - public class zen2restapiit extends esnetty4integtestcase { <nl> + public class zen2restapiit extends esintegtestcase { <nl>  <nl> @ override <nl> protected boolean addmockhttptransport ( ) {
public class transportservice extends abstractlifecyclecomponent <nl> / / should not happen <nl> innerexception . addsuppressed ( transportexception ) ; <nl> logger . error ( " unexpected exception from handler . handleexception " , innerexception ) ; <nl> - <nl> + assert false : innerexception ; <nl> } <nl> }
public class precompiledcharmapnormalizer { <nl> / / break points from there . but , this seemed the easiest way for now <nl> / / <nl> / / keep in mind , these break points aren ' t necessarily surrogate pairs , but also codepoints that contain a combining mark <nl> + byte [ ] strbytes = str . getbytes ( standardcharsets . utf_8 ) ; <nl> + char [ ] strchars = str . tochararray ( ) ; <nl> + int [ ] strcp = str . codepoints ( ) . toarray ( ) ; <nl> breakiterator b = breakiterator . getcharacterinstance ( locale . root ) ; <nl> b . settext ( str ) ; <nl> - int start = b . first ( ) ; <nl> - / / if we knew the utf - 8 length ahead of time ( and iterated over the bytes in the appropriate chunks ) <nl> - / / we could pre - populate the known length here . <nl> + / / we iterate the whole string , so b . first ( ) is always ` 0 ` <nl> + int startiter = b . first ( ) ; <nl> + int codepointpos = num ; <nl> bytesrefbuilder strbuilder = new bytesrefbuilder ( ) ; <nl> - for ( int end = b . next ( ) ; end ! = breakiterator . done ; start = end , end = b . next ( ) ) { <nl> - <nl> - / / dramatically improved <nl> - string unicodestr = str . substring ( start , end ) ; <nl> - byte [ ] unicode = unicodestr . getbytes ( standardcharsets . utf_8 ) ; <nl> + strbuilder . grow ( strbytes . length ) ; <nl> + int bytepos = num ; <nl> + for ( int end = b . next ( ) ; end ! = breakiterator . done ; startiter = end , end = b . next ( ) ) { <nl> + int bytelen = num ; <nl> + int numcp = str . codepointcount ( startiter , end ) ; <nl> + for ( int i = codepointpos ; i < numcp + codepointpos ; i + + ) { <nl> + bytelen + = numutf8bytes ( strcp [ i ] ) ; <nl> + } <nl> + codepointpos + = numcp ; <nl> / / the trie only go up to a depth of num bytes . <nl> / / so even looking at it for graphemes ( with combining , surrogate , etc . ) that are num + bytes in length is useless . <nl> - if ( unicode . length < num ) { <nl> - optional < bytesref > substr = normalizepart ( unicode , num , unicode . length ) ; <nl> + if ( bytelen < num ) { <nl> + optional < bytesref > substr = normalizepart ( strbytes , bytepos , bytelen ) ; <nl> if ( substr . ispresent ( ) ) { <nl> strbuilder . append ( substr . get ( ) ) ; <nl> + bytepos + = bytelen ; <nl> continue ; <nl> } <nl> } <nl> - int charindex = num ; <nl> int charbyteindex = num ; <nl> - char [ ] unicodechararray = unicodestr . tochararray ( ) ; <nl> - for ( char c : unicodechararray ) { <nl> - optional < bytesref > substr = normalizepart ( unicode , charbyteindex , numutf8bytes ( c ) ) ; <nl> + for ( int i = startiter ; i < end ; i + + ) { <nl> + int utf8charbytes = numutf8bytes ( strchars [ i ] ) ; <nl> + optional < bytesref > substr = normalizepart ( strbytes , charbyteindex + bytepos , utf8charbytes ) ; <nl> if ( substr . ispresent ( ) ) { <nl> strbuilder . append ( substr . get ( ) ) ; <nl> } else { <nl> - int numbytes = unicodeutil . utf16toutf8 ( unicodechararray , charindex , num , reusablecharbytebuffer ) ; <nl> + int numbytes = unicodeutil . utf16toutf8 ( strchars , i , num , reusablecharbytebuffer ) ; <nl> strbuilder . append ( reusablecharbytebuffer , num , numbytes ) ; <nl> } <nl> - charbyteindex + = numutf8bytes ( c ) ; <nl> - + + charindex ; <nl> + charbyteindex + = utf8charbytes ; <nl> } <nl> + bytepos + = bytelen ; <nl> } <nl> return strbuilder . get ( ) . utf8tostring ( ) ; <nl> }
abstract class metricfieldproducer { <nl>  <nl> @ override <nl> void collect ( double value ) { <nl> - <nl> - this . sum + = value ; <nl> + kahansummation . add ( value ) ; <nl> } <nl>  <nl> @ override <nl> number get ( ) { <nl> - return sum ; <nl> + return kahansummation . value ( ) ; <nl> } <nl>  <nl> @ override <nl> void reset ( ) { <nl> - sum = num ; <nl> + kahansummation . reset ( 0 , num ) ; <nl> } <nl> } <nl>  <nl> mmm a / x - pack / plugin / rollup / src / test / java / org / elasticsearch / xpack / rollup / v2 / metricfieldproducertests . java <nl> ppp b / x - pack / plugin / rollup / src / test / java / org / elasticsearch / xpack / rollup / v2 / metricfieldproducertests . java <nl>
public class recoverysourcehandler { <nl> * / <nl> private engine . indexcommitref acquiresafecommit ( indexshard shard ) { <nl> final engine . indexcommitref commitref = shard . acquiresafeindexcommit ( ) ; <nl> - return new engine . indexcommitref ( commitref . getindexcommit ( ) , ( ) - > runwithgenericthreadpool ( commitref : : close ) ) ; <nl> + return new engine . indexcommitref ( commitref . getindexcommit ( ) , ( ) - > closeongenericthreadpool ( commitref ) ) ; <nl> } <nl>  <nl> - private void runwithgenericthreadpool ( checkedrunnable < exception > task ) { <nl> - final plainactionfuture < void > future = new plainactionfuture < > ( ) ; <nl> + private void closeongenericthreadpool ( closeable closeable ) { <nl> assert threadpool . generic ( ) . isshutdown ( ) = = false ; <nl> - <nl> - / / while practically unlikely at a min pool size of num we could technically block the whole pool by waiting on futures <nl> - / / below and thus make it impossible for the store release to execute which in turn would block the futures forever <nl> - threadpool . generic ( ) . execute ( actionrunnable . run ( future , task ) ) ; <nl> - futureutils . get ( future ) ; <nl> + threadpool . generic ( ) . execute ( ( ) - > { <nl> + try { <nl> + closeable . close ( ) ; <nl> + } catch ( exception e ) { <nl> + assert false : e ; <nl> + logger . warn ( new parameterizedmessage ( " exception while closing [ { } ] " , closeable ) , e ) ; <nl> + } <nl> + } ) ; <nl> } <nl>  <nl> static final class sendfileresult {
public class dosection implements executablesection { <nl> final string testpath = executioncontext . getclientyamltestcandidate ( ) ! = null <nl> ? executioncontext . getclientyamltestcandidate ( ) . gettestpath ( ) <nl> : null ; <nl> - if ( executioncontext . esversion ( ) . after ( version . v_8_1_0 ) <nl> - | | ( executioncontext . esversion ( ) . major = = version . v_7_17_0 . major & & executioncontext . esversion ( ) . after ( version . v_7_17_1 ) ) ) { <nl> - / / # 84038 and # 84089 mean that this assertion fails when running against a small number of released versions , but at time of <nl> - / / writing it ' s unclear exactly which released versions will contain the fix . <nl> - <nl> + if ( executioncontext . esversion ( ) . major = = version . v_7_17_0 . major & & executioncontext . esversion ( ) . after ( version . v_7_17_1 ) ) { <nl> + / / # 84038 and # 84089 mean that this assertion fails when running against a small number of num . 17 . x released versions <nl> checkelasticproductheader ( response . getheaders ( " x - elastic - product " ) ) ; <nl> } <nl> checkwarningheaders ( response . getwarningheaders ( ) , testpath ) ;
public final class documentparser { <nl> if ( dynamic = = objectmapper . dynamic . strict ) { <nl> throw new strictdynamicmappingexception ( parentmapper . fullpath ( ) , lastfieldname ) ; <nl> } else if ( dynamic = = objectmapper . dynamic . false ) { <nl> - <nl> - parsenondynamicarray ( context , parentmapper , lastfieldname , lastfieldname ) ; <nl> + context . parser ( ) . skipchildren ( ) ; <nl> } else { <nl> mapper objectmapperfromtemplate = dynamic . getdynamicfieldsbuilder ( ) . createobjectmapperfromtemplate ( context , lastfieldname ) ; <nl> if ( objectmapperfromtemplate = = null ) { <nl> mmm a / server / src / test / java / org / elasticsearch / index / mapper / dynamicmappingtests . java <nl> ppp b / server / src / test / java / org / elasticsearch / index / mapper / dynamicmappingtests . java <nl>
public class fullclusterrestartit extends abstractfullclusterrestarttestcase { <nl>  <nl> / / read is ok <nl> final request searchrequest = new request ( " get " , " . security / _search " ) ; <nl> - <nl> - / / configure the warning to be optional due to # 82837 , it is ok since this test is for something else <nl> - searchrequest . setoptions ( requestoptions . default . tobuilder ( ) . setwarningshandler ( warnings - > { <nl> - if ( warnings . isempty ( ) ) { <nl> - return false ; <nl> - } else if ( warnings . size ( ) = = num ) { <nl> - return false = = warnings . get ( 0 ) . startswith ( " this request accesses system indices : [ . security - 7 ] " ) ; <nl> - } else { <nl> - return true ; <nl> - } <nl> - } ) . addheader ( " authorization " , apikeyauthheader ) ) ; <nl> + searchrequest . setoptions ( <nl> + expectwarnings ( <nl> + " this request accesses system indices : [ . security - 7 ] , but in a future major " <nl> + + " version , direct access to system indices will be prevented by default " <nl> + ) . tobuilder ( ) . addheader ( " authorization " , apikeyauthheader ) <nl> + ) ; <nl> assertok ( client ( ) . performrequest ( searchrequest ) ) ; <nl>  <nl> / / write must not be allowed <nl>
public class persistedclusterstateservice { <nl> } <nl>  <nl> private boolean assertoncommit ( ) { <nl> - if ( assertoncommit ! = null / * <nl> + if ( assertoncommit ! = null & & randomness . get ( ) . nextint ( 100 ) = = num ) { <nl> / / only rarely run this assertion since reloading the whole state can be quite expensive <nl> for ( final var metadataindexwriter : metadataindexwriters ) { <nl> try ( var directoryreader = directoryreader . open ( metadataindexwriter . indexwriter ) ) {
fetch the _tsid : <nl> - match : { hits . hits . 1 . fields . ul : [ 9223372036854775807 ] } <nl>  <nl> mmm <nl> - # <nl> + # sort order is of unsigned_long fields is not the one we would expect . <nl> + # this is caused by the encoding of unsigned_long as a signed long before <nl> + # being serialized in _tsid <nl> aggregate the _tsid : <nl> - skip : <nl> version : " - num . 0 . 99 " <nl>
aggregate the _tsid : <nl> - match : { aggregations . tsids . buckets . 3 . doc_count : num } <nl>  <nl> mmm <nl> - # the time - series <nl> - # <nl> - default sort : <nl> + # sort order is of unsigned_long fields is not the one we would expect . <nl> + # this is caused by the encoding of unsigned_long as a signed long before <nl> + # being serialized in _tsid <nl> + sort by tsid : <nl> - skip : <nl> version : " - num . 0 . 99 " <nl> reason : _tsid support introduced in num . 1 . 0 <nl>
public class settingsconfig implements writeable , toxcontentobject { <nl> } else { <nl> this . aligncheckpoints = default_align_checkpoints ; <nl> } <nl> - if ( in . getversion ( ) . onorafter ( version . v_8_1_0 ) ) { <nl> + if ( in . getversion ( ) . onorafter ( version . v_7_16_1 ) ) { <nl> this . usepit = in . readoptionalint ( ) ; <nl> } else { <nl> this . usepit = default_use_pit ; <nl>
public class settingsconfig implements writeable , toxcontentobject { <nl> if ( out . getversion ( ) . onorafter ( version . v_7_15_0 ) ) { <nl> out . writeoptionalint ( aligncheckpoints ) ; <nl> } <nl> - if ( out . getversion ( ) . onorafter ( version . v_8_1_0 ) ) { <nl> + if ( out . getversion ( ) . onorafter ( version . v_7_16_1 ) ) { <nl> out . writeoptionalint ( usepit ) ; <nl> } <nl> }
public class mlscalingreason implements autoscalingdeciderresult . reason { <nl> public mlscalingreason ( streaminput in ) throws ioexception { <nl> this . waitinganalyticsjobs = in . readstringlist ( ) ; <nl> this . waitinganomalyjobs = in . readstringlist ( ) ; <nl> - <nl> - if ( in . getversion ( ) . onorafter ( version . v_8_1_0 ) ) { <nl> - this . waitingsnapshotupgrades = in . readstringlist ( ) ; <nl> - } else { <nl> - this . waitingsnapshotupgrades = list . of ( ) ; <nl> - } <nl> + this . waitingsnapshotupgrades = in . readstringlist ( ) ; <nl> if ( in . getversion ( ) . onorafter ( version . v_8_0_0 ) ) { <nl> this . waitingmodels = in . readstringlist ( ) ; <nl> } else { <nl>
public class mlscalingreason implements autoscalingdeciderresult . reason { <nl> public void writeto ( streamoutput out ) throws ioexception { <nl> out . writestringcollection ( this . waitinganalyticsjobs ) ; <nl> out . writestringcollection ( this . waitinganomalyjobs ) ; <nl> - <nl> - if ( out . getversion ( ) . onorafter ( version . v_8_1_0 ) ) { <nl> - out . writestringcollection ( this . waitingsnapshotupgrades ) ; <nl> - } <nl> + out . writestringcollection ( this . waitingsnapshotupgrades ) ; <nl> if ( out . getversion ( ) . onorafter ( version . v_8_0_0 ) ) { <nl> out . writestringcollection ( this . waitingmodels ) ; <nl> }
public class inferenceprocessor extends abstractprocessor { <nl> } else if ( configmap . containskey ( zeroshotclassificationconfig . name ) ) { <nl> checknlpsupported ( zeroshotclassificationconfig . name ) ; <nl> return zeroshotclassificationconfigupdate . frommap ( valuemap ) ; <nl> - } <nl> - <nl> - else { <nl> + } else { <nl> throw exceptionshelper . badrequestexception ( <nl> " unrecognized inference configuration type { } . supported types { } " , <nl> configmap . keyset ( ) , <nl> - arrays . aslist ( classificationconfig . name . getpreferredname ( ) , regressionconfig . name . getpreferredname ( ) ) <nl> + list . of ( <nl> + classificationconfig . name . getpreferredname ( ) , <nl> + regressionconfig . name . getpreferredname ( ) , <nl> + fillmaskconfig . name , <nl> + nerconfig . name , <nl> + passthroughconfig . name , <nl> + textclassificationconfig . name , <nl> + textembeddingconfig . name , <nl> + zeroshotclassificationconfig . name <nl> + ) <nl> ) ; <nl> } <nl> } <nl> mmm a / x - pack / plugin / ml / src / test / java / org / elasticsearch / xpack / ml / inference / ingest / inferenceprocessorfactorytests . java <nl> ppp b / x - pack / plugin / ml / src / test / java / org / elasticsearch / xpack / ml / inference / ingest / inferenceprocessorfactorytests . java <nl>
public class snapshotsservice extends abstractlifecyclecomponent implements clus <nl>  <nl> public static final version uuids_in_repo_data_version = version . v_7_12_0 ; <nl>  <nl> - <nl> - public static final version file_info_writer_uuids_in_shard_data_version = version . current ; <nl> + public static final version file_info_writer_uuids_in_shard_data_version = version . v_7_16_0 ; <nl>  <nl> public static final version old_snapshot_format = version . v_7_5_0 ;
public class reservedrolesstore implements biconsumer < set < string > , actionlistene <nl> . indices ( " . ml - annotations * " ) <nl> . privileges ( " view_index_metadata " , " read " , " write " ) <nl> . build ( ) } , <nl> - <nl> + / / this makes it completely clear to ui administrators that <nl> + / / if they grant the elasticsearch backend role to a user then <nl> + / / they cannot expect kibana privileges to stop that user from <nl> + / / accessing ml functionality - the user could switch to curl <nl> + / / or even kibana dev console and call the es endpoints directly <nl> + / / bypassing the kibana privileges layer entirely . <nl> new roledescriptor . applicationresourceprivileges [ ] { <nl> roledescriptor . applicationresourceprivileges . builder ( ) <nl> . application ( " kibana - * " ) <nl>
public class reservedrolesstore implements biconsumer < set < string > , actionlistene <nl> . indices ( " . ml - annotations * " ) <nl> . privileges ( " view_index_metadata " , " read " , " write " ) <nl> . build ( ) } , <nl> - <nl> + / / this makes it completely clear to ui administrators that <nl> + / / if they grant the elasticsearch backend role to a user then <nl> + / / they cannot expect kibana privileges to stop that user from <nl> + / / accessing ml functionality - the user could switch to curl <nl> + / / or even kibana dev console and call the es endpoints directly <nl> + / / bypassing the kibana privileges layer entirely . <nl> new roledescriptor . applicationresourceprivileges [ ] { <nl> roledescriptor . applicationresourceprivileges . builder ( ) <nl> . application ( " kibana - * " )
public class knnvectorquerybuildertests extends abstractquerytestcase < knnvectorq <nl>  <nl> @ override <nl> protected void doassertlucenequery ( knnvectorquerybuilder querybuilder , query query , searchexecutioncontext context ) { <nl> - <nl> asserttrue ( query instanceof knnvectorquery ) ; <nl> + knnvectorquery knnvectorquery = ( knnvectorquery ) query ; <nl> + <nl> + / / the field should always be resolved to the concrete field <nl> + assertthat ( knnvectorquery , equalto ( new knnvectorquery ( vector_field , <nl> + querybuilder . queryvector ( ) , <nl> + querybuilder . numcands ( ) ) ) ) ; <nl> } <nl>  <nl> public void testwrongdimension ( ) {
public class densevectorfieldmappertests extends mappertestcase { <nl> assertthat ( codec , instanceof ( perfieldmappercodec . class ) ) ; <nl> knnvectorsformat knnvectorsformat = ( ( perfieldmappercodec ) codec ) . getknnvectorsformatforfield ( " field " ) ; <nl> assertthat ( knnvectorsformat , instanceof ( lucene90hnswvectorsformat . class ) ) ; <nl> - <nl> + string expectedstring = " lucene90hnswvectorsformat ( name = lucene90hnswvectorsformat , maxconn = " + m + <nl> + " , beamwidth = " + efconstruction + " ) " ; <nl> + assertequals ( expectedstring , knnvectorsformat . tostring ( ) ) ; <nl> } <nl> }
public class eqlsearchrequest extends actionrequest implements indicesrequest . re <nl> out . writeboolean ( keeponcompletion ) ; <nl> } <nl>  <nl> - if ( out . getversion ( ) . onorafter ( version . v_7_10_0 ) ) { <nl> + if ( out . getversion ( ) . onorafter ( version . v_7_10_0 ) ) { <nl> out . writestring ( resultposition ) ; <nl> } <nl> if ( out . getversion ( ) . onorafter ( version . v_7_13_0 ) ) { <nl> mmm a / x - pack / plugin / sql / sql - action / src / main / java / org / elasticsearch / xpack / sql / action / abstractsqlqueryrequest . java <nl> ppp b / x - pack / plugin / sql / sql - action / src / main / java / org / elasticsearch / xpack / sql / action / abstractsqlqueryrequest . java <nl>
public abstract class abstractsqlqueryrequest extends abstractsqlrequest impleme <nl> query = in . readstring ( ) ; <nl> params = in . readlist ( abstractsqlqueryrequest : : readsqltypedparamvalue ) ; <nl> zoneid = in . readzoneid ( ) ; <nl> - if ( in . getversion ( ) . onorafter ( version . v_8_0_0 ) ) { <nl> + if ( in . getversion ( ) . onorafter ( version . v_7_16_0 ) ) { <nl> catalog = in . readoptionalstring ( ) ; <nl> } <nl> fetchsize = in . readvint ( ) ; <nl>
public abstract class abstractsqlqueryrequest extends abstractsqlrequest impleme <nl> writesqltypedparamvalue ( out , param ) ; <nl> } <nl> out . writezoneid ( zoneid ) ; <nl> - if ( out . getversion ( ) . onorafter ( version . v_8_0_0 ) ) { <nl> + if ( out . getversion ( ) . onorafter ( version . v_7_16_0 ) ) { <nl> out . writeoptionalstring ( catalog ) ; <nl> } <nl> out . writevint ( fetchsize ) ; <nl> mmm a / x - pack / plugin / sql / sql - action / src / main / java / org / elasticsearch / xpack / sql / action / sqlqueryrequest . java <nl> ppp b / x - pack / plugin / sql / sql - action / src / main / java / org / elasticsearch / xpack / sql / action / sqlqueryrequest . java <nl>
public class sqlqueryrequest extends abstractsqlqueryrequest { <nl> fieldmultivalueleniency = in . readboolean ( ) ; <nl> indexincludefrozen = in . readboolean ( ) ; <nl> binarycommunication = in . readoptionalboolean ( ) ; <nl> - if ( in . getversion ( ) . onorafter ( version . v_8_0_0 ) ) { <nl> + if ( in . getversion ( ) . onorafter ( version . v_7_14_0 ) ) { <nl> this . waitforcompletiontimeout = in . readoptionaltimevalue ( ) ; <nl> this . keeponcompletion = in . readboolean ( ) ; <nl> this . keepalive = in . readoptionaltimevalue ( ) ; <nl>
public class sqlqueryrequest extends abstractsqlqueryrequest { <nl> out . writeboolean ( fieldmultivalueleniency ) ; <nl> out . writeboolean ( indexincludefrozen ) ; <nl> out . writeoptionalboolean ( binarycommunication ) ; <nl> - if ( out . getversion ( ) . onorafter ( version . v_8_0_0 ) ) { <nl> + if ( out . getversion ( ) . onorafter ( version . v_7_14_0 ) ) { <nl> out . writeoptionaltimevalue ( waitforcompletiontimeout ) ; <nl> out . writeboolean ( keeponcompletion ) ; <nl> out . writeoptionaltimevalue ( keepalive ) ;
public class searchrequest extends actionrequest implements indicesrequest . repla <nl> } else { <nl> mincompatibleshardnode = null ; <nl> } <nl> - <nl> - if ( in . getversion ( ) . onorafter ( version . v_8_0_0 ) ) { <nl> + if ( in . getversion ( ) . onorafter ( version . v_7_16_0 ) ) { <nl> waitforcheckpoints = in . readmap ( streaminput : : readstring , streaminput : : readlongarray ) ; <nl> waitforcheckpointstimeout = in . readtimevalue ( ) ; <nl> } <nl>
public class searchrequest extends actionrequest implements indicesrequest . repla <nl> version . writeversion ( mincompatibleshardnode , out ) ; <nl> } <nl> } <nl> - <nl> - version waitforcheckpointsversion = version . v_8_0_0 ; <nl> - if ( out . getversion ( ) . onorafter ( version . v_8_0_0 ) ) { <nl> + version waitforcheckpointsversion = version . v_7_16_0 ; <nl> + if ( out . getversion ( ) . onorafter ( waitforcheckpointsversion ) ) { <nl> out . writemap ( waitforcheckpoints , streamoutput : : writestring , streamoutput : : writelongarray ) ; <nl> out . writetimevalue ( waitforcheckpointstimeout ) ; <nl> } else if ( waitforcheckpoints . isempty ( ) = = false ) { <nl> mmm a / server / src / main / java / org / elasticsearch / search / internal / shardsearchrequest . java <nl> ppp b / server / src / main / java / org / elasticsearch / search / internal / shardsearchrequest . java <nl>
public class shardsearchrequest extends transportrequest implements indicesreque <nl> } <nl> assert keepalive = = null | | readerid ! = null : " readerid : " + readerid + " keepalive : " + keepalive ; <nl> channelversion = version . min ( version . readversion ( in ) , in . getversion ( ) ) ; <nl> - <nl> - if ( in . getversion ( ) . onorafter ( version . v_8_0_0 ) ) { <nl> + if ( in . getversion ( ) . onorafter ( version . v_7_16_0 ) ) { <nl> waitforcheckpoint = in . readlong ( ) ; <nl> waitforcheckpointstimeout = in . readtimevalue ( ) ; <nl> } else { <nl>
public class shardsearchrequest extends transportrequest implements indicesreque <nl> out . writeoptionaltimevalue ( keepalive ) ; <nl> } <nl> version . writeversion ( channelversion , out ) ; <nl> - <nl> - version waitforcheckpointsversion = version . v_8_0_0 ; <nl> + version waitforcheckpointsversion = version . v_7_16_0 ; <nl> if ( out . getversion ( ) . onorafter ( waitforcheckpointsversion ) ) { <nl> out . writelong ( waitforcheckpoint ) ; <nl> out . writetimevalue ( waitforcheckpointstimeout ) ;
import java . util . stream . collectors ; <nl>  <nl> public class recoverysettings { <nl> public static final version snapshot_recoveries_supported_version = version . v_7_15_0 ; <nl> - <nl> - public static final version seq_no_snapshot_recoveries_supported_version = version . v_8_0_0 ; <nl> + public static final version seq_no_snapshot_recoveries_supported_version = version . v_7_16_0 ; <nl>  <nl> private static final logger logger = logmanager . getlogger ( recoverysettings . class ) ;
<nl> mmm <nl> setup : <nl> - skip : <nl> - version : " - num . 9 . 99 " <nl> - reason : <nl> + version : " - num . 15 . 0 " <nl> + reason : original indices are propagated correctly in num . 15 . 1 <nl> features : headers <nl> - do : <nl> cluster . health :
public class sqlcompatit extends baserestsqltestcase { <nl> } ) ; <nl> } <nl>  <nl> - public void testnullsorderbeforemissingordersupport ( ) throws ioexception { <nl> + public void testnullsorderbeforemissingordersupportqueryingnewnode ( ) throws ioexception { <nl> + testnullsorderbeforemissingordersupport ( newnodesclient ) ; <nl> + } <nl> + <nl> + public void testnullsorderbeforemissingordersupportqueryingoldnode ( ) throws ioexception { <nl> + testnullsorderbeforemissingordersupport ( oldnodesclient ) ; <nl> + } <nl> + <nl> + private void testnullsorderbeforemissingordersupport ( restclient client ) throws ioexception { <nl> assumetrue ( <nl> " expected some nodes without support for missing_order but got none " , <nl> bwcversion . before ( introducing_missing_order_in_composite_aggs_version ) <nl> ) ; <nl>  <nl> - for ( restclient bwcclient : arrays . aslist ( newnodesclient , oldnodesclient ) ) { <nl> - list < integer > result = runorderbynullslastquery ( bwcclient ) ; <nl> + list < integer > result = runorderbynullslastquery ( client ) ; <nl>  <nl> - assertequals ( 3 , result . size ( ) ) ; <nl> - assertnull ( result . get ( 0 ) ) ; <nl> - assertequals ( integer . valueof ( 1 ) , result . get ( 1 ) ) ; <nl> - assertequals ( integer . valueof ( 2 ) , result . get ( 2 ) ) ; <nl> - } <nl> + assertequals ( 3 , result . size ( ) ) ; <nl> + assertnull ( result . get ( 0 ) ) ; <nl> + assertequals ( integer . valueof ( 1 ) , result . get ( 1 ) ) ; <nl> + assertequals ( integer . valueof ( 2 ) , result . get ( 2 ) ) ; <nl> } <nl>  <nl> - public void testnullsorderwithmissingordersupport ( ) throws ioexception { <nl> + public void testnullsorderwithmissingordersupportqueryingnewnode ( ) throws ioexception { <nl> + testnullsorderwithmissingordersupport ( newnodesclient ) ; <nl> + } <nl> + <nl> + public void testnullsorderwithmissingordersupportqueryingoldnode ( ) throws ioexception { <nl> + testnullsorderwithmissingordersupport ( oldnodesclient ) ; <nl> + } <nl> + <nl> + private void testnullsorderwithmissingordersupport ( restclient client ) throws ioexception { <nl> assumetrue ( <nl> " expected all nodes with support for missing_order but got some without " , <nl> bwcversion . onorafter ( introducing_missing_order_in_composite_aggs_version ) <nl> ) ; <nl>  <nl> - <nl> - for ( restclient bwcclient : arrays . aslist ( newnodesclient ) ) { <nl> - list < integer > result = runorderbynullslastquery ( bwcclient ) ; <nl> + list < integer > result = runorderbynullslastquery ( client ) ; <nl>  <nl> - assertequals ( 3 , result . size ( ) ) ; <nl> - assertequals ( integer . valueof ( 1 ) , result . get ( 0 ) ) ; <nl> - assertequals ( integer . valueof ( 2 ) , result . get ( 1 ) ) ; <nl> - assertnull ( result . get ( 2 ) ) ; <nl> - } <nl> + assertequals ( 3 , result . size ( ) ) ; <nl> + assertequals ( integer . valueof ( 1 ) , result . get ( 0 ) ) ; <nl> + assertequals ( integer . valueof ( 2 ) , result . get ( 1 ) ) ; <nl> + assertnull ( result . get ( 2 ) ) ; <nl> } <nl>  <nl> @ suppresswarnings ( " unchecked " )
<nl> - / * <nl> - * copyright elasticsearch b . v . and / or licensed to elasticsearch b . v . under one <nl> - * or more contributor license agreements . licensed under the elastic license <nl> - * num . 0 and the server side public license , v num ; you may not use this file except <nl> - * in compliance with , at your election , the elastic license num . 0 or the server <nl> - * side public license , v num . <nl> - * / <nl> - <nl> - package org . apache . lucene . queryparser . classic ; <nl> - <nl> - import org . apache . lucene . analysis . analyzer ; <nl> - import org . apache . lucene . search . query ; <nl> - <nl> - / * * <nl> - * this class is just a workaround to make { @ link queryparser # handlebarefuzzy ( string , token , string ) } accessible by sub - classes . <nl> - * it is needed for { @ link queryparser } s that need to override the parsing of the slop in a fuzzy query ( e . g . word < b > ~ 2 < / b > , word < b > ~ < / b > ) . <nl> - * <nl> - * <nl> - * / <nl> - public class xqueryparser extends queryparser { <nl> - public xqueryparser ( string f , analyzer a ) { <nl> - super ( f , a ) ; <nl> - } <nl> - <nl> - @ override <nl> - protected query handlebarefuzzy ( string field , token fuzzyslop , string termimage ) throws parseexception { <nl> - return super . handlebarefuzzy ( field , fuzzyslop , termimage ) ; <nl> - } <nl> - } <nl> mmm a / server / src / main / java / org / elasticsearch / index / search / querystringqueryparser . java <nl> ppp b / server / src / main / java / org / elasticsearch / index / search / querystringqueryparser . java <nl>
<nl> [ [ snapshots - restore - snapshot ] ] <nl> = = restore a snapshot <nl>  <nl> - <nl> - / / merged . this mutes a broken docs ci . <nl> - [ [ change - index - settings - during - restore ] ] <nl> this guide shows you how to restore a snapshot . snapshots are a convenient way <nl> to store a copy of your data outside of a cluster . you can restore a snapshot <nl> to recover indices and data streams after deletion or a hardware failure . you
public class internalcomposite extends internalmultibucketaggregation < internalco <nl> formats . add ( in . readnamedwriteable ( docvalueformat . class ) ) ; <nl> } <nl> this . reversemuls = in . readintarray ( ) ; <nl> - <nl> - if ( in . getversion ( ) . onorafter ( version . v_8_0_0 ) ) { <nl> + if ( in . getversion ( ) . onorafter ( version . v_7_16_0 ) ) { <nl> this . missingorders = in . readarray ( missingorder : : readfromstream , missingorder [ ] : : new ) ; <nl> } else { <nl> this . missingorders = new missingorder [ reversemuls . length ] ; <nl>
public class internalcomposite extends internalmultibucketaggregation < internalco <nl> out . writenamedwriteable ( format ) ; <nl> } <nl> out . writeintarray ( reversemuls ) ; <nl> - <nl> - if ( out . getversion ( ) . onorafter ( version . v_8_0_0 ) ) { <nl> + if ( out . getversion ( ) . onorafter ( version . v_7_16_0 ) ) { <nl> out . writearray ( ( o , order ) - > order . writeto ( o ) , missingorders ) ; <nl> } <nl> out . writelist ( buckets ) ;
setup : <nl> mmm <nl> " simple composite aggregation with missing_order " : <nl> - skip : <nl> - # <nl> - version : " - num . 99 . 0 " <nl> + version : " - num . 15 . 99 " <nl> reason : " ` missing_order ` has been introduced in num . 16 " <nl> - do : <nl> search : <nl>
setup : <nl> mmm <nl> " missing_order with missing_bucket = false " : <nl> - skip : <nl> - # <nl> - version : " - num . 99 . 0 " <nl> + version : " - num . 15 . 99 " <nl> reason : " ` missing_order ` has been introduced in num . 16 " <nl> - do : <nl> catch : / missingorder can only be set if missingbucket is true / <nl>
setup : <nl> mmm <nl> " missing_order without missing_bucket " : <nl> - skip : <nl> - # <nl> - version : " - num . 99 . 0 " <nl> + version : " - num . 15 . 99 " <nl> reason : " ` missing_order ` has been introduced in num . 16 " <nl> - do : <nl> catch : / missingorder can only be set if missingbucket is true / <nl>
setup : <nl> mmm <nl> " nested composite aggregation with missing_order " : <nl> - skip : <nl> - # <nl> - version : " - num . 99 . 0 " <nl> + version : " - num . 15 . 99 " <nl> reason : " ` missing_order ` has been introduced in num . 16 " <nl> - do : <nl> search : <nl> mmm a / server / src / main / java / org / elasticsearch / search / aggregations / bucket / composite / compositevaluessourcebuilder . java <nl> ppp b / server / src / main / java / org / elasticsearch / search / aggregations / bucket / composite / compositevaluessourcebuilder . java <nl>
public abstract class compositevaluessourcebuilder < ab extends compositevaluessou <nl> this . uservaluetypehint = valuetype . readfromstream ( in ) ; <nl> } <nl> this . missingbucket = in . readboolean ( ) ; <nl> - <nl> - if ( in . getversion ( ) . onorafter ( version . v_8_0_0 ) ) { <nl> + if ( in . getversion ( ) . onorafter ( version . v_7_16_0 ) ) { <nl> this . missingorder = missingorder . readfromstream ( in ) ; <nl> } <nl> this . order = sortorder . readfromstream ( in ) ; <nl>
public abstract class compositevaluessourcebuilder < ab extends compositevaluessou <nl> uservaluetypehint . writeto ( out ) ; <nl> } <nl> out . writeboolean ( missingbucket ) ; <nl> - <nl> - if ( out . getversion ( ) . onorafter ( version . v_8_0_0 ) ) { <nl> + if ( out . getversion ( ) . onorafter ( version . v_7_16_0 ) ) { <nl> missingorder . writeto ( out ) ; <nl> } <nl> order . writeto ( out ) ;
<nl> mmm <nl> " test that datastream <nl> - skip : <nl> - # <nl> - version : " - num . 99 . 99 " <nl> - reason : " sorting segments was added in num . 15 " <nl> + version : " - num . 15 . 99 " <nl> + reason : " sorting segments was added in num . 16 " <nl> features : allowed_warnings <nl>  <nl> - do :
<nl> mmm <nl> " indices recovery test " : <nl> - skip : <nl> - # <nl> - version : " - num . 99 . 99 " <nl> - reason : recovery from snapshot bytes not available until num . 0 <nl> + version : " - num . 14 . 99 " <nl> + reason : recovery from snapshot bytes not available until num . 15 <nl>  <nl> - do : <nl> indices . create : <nl>
<nl> mmm <nl> " test background filter count " : <nl> - skip : <nl> - # <nl> - version : " - num . 99 . 99 " <nl> - reason : introduced in num . 15 . 0 <nl> + version : " - num . 14 . 99 " <nl> + reason : bugfix introduced in num . 15 . 0 <nl>  <nl> - do : <nl> indices . create :
import java . util . regex . pattern <nl> * dpkg - c path / to / elasticsearch . deb <nl> * / <nl>  <nl> - buildscript { <nl> - repositories { <nl> - mavencentral ( ) <nl> - maven { url ' https : / / jitpack . io ' } <nl> - } <nl> - <nl> - / / we rely on a specific version of the redline library used to build rpm packages <nl> - / / to support sha256header in our elasticsearch rpms <nl> - <nl> - configurations . all { <nl> - resolutionstrategy { <nl> - force ' org . redline - rpm : redline : 1 . 2 . 10 ' <nl> - } <nl> - } <nl> - <nl> - dependencies { <nl> - classpath " com . github . breskeby : gradle - ospackage - plugin : 98455c1 " <nl> - } <nl> + plugins { <nl> + id " nebula . ospackage - base " version " 8 . 6 . 1 " <nl> } <nl>  <nl> - apply plugin : " nebula . ospackage - base " <nl> - <nl> void addprocessfilestask ( string type , boolean oss , boolean jdk ) { <nl> string packagingfiles = " build / packaging / $ { oss ? ' oss - ' : ' ' } $ { jdk ? ' ' : ' no - jdk - ' } $ { type } "
public abstract class internalmappedterms < a extends internalterms < a , b > , b exten <nl> * / <nl> protected internalmappedterms ( streaminput in , bucket . reader < b > bucketreader ) throws ioexception { <nl> super ( in ) ; <nl> - if ( in . getversion ( ) . onorafter ( version . v_8_0_0 ) ) { <nl> + if ( in . getversion ( ) . onorafter ( version . v_7_15_0 ) ) { <nl> if ( in . readboolean ( ) ) { <nl> doccounterror = in . readzlong ( ) ; <nl> } else { <nl>
public abstract class internalmappedterms < a extends internalterms < a , b > , b exten <nl>  <nl> @ override <nl> protected final void writetermtypeinfoto ( streamoutput out ) throws ioexception { <nl> - if ( out . getversion ( ) . onorafter ( version . v_8_0_0 ) ) { <nl> + if ( out . getversion ( ) . onorafter ( version . v_7_15_0 ) ) { <nl> if ( doccounterror ! = null ) { <nl> out . writeboolean ( true ) ; <nl> out . writezlong ( doccounterror ) ;
public class settingsconfig implements writeable , toxcontentobject { <nl> } else { <nl> this . datesasepochmillis = default_dates_as_epoch_millis ; <nl> } <nl> - if ( in . getversion ( ) . onorafter ( version . current ) ) { <nl> + if ( in . getversion ( ) . onorafter ( version . v_7_15_0 ) ) { <nl> this . interimresults = in . readoptionalint ( ) ; <nl> } else { <nl> this . interimresults = default_interim_results ; <nl>
public class settingsconfig implements writeable , toxcontentobject { <nl> if ( out . getversion ( ) . onorafter ( version . v_7_11_0 ) ) { <nl> out . writeoptionalint ( datesasepochmillis ) ; <nl> } <nl> - if ( out . getversion ( ) . onorafter ( version . current ) ) { <nl> + if ( out . getversion ( ) . onorafter ( version . v_7_15_0 ) ) { <nl> out . writeoptionalint ( interimresults ) ; <nl> } <nl> } <nl> mmm a / x - pack / plugin / core / src / main / java / org / elasticsearch / xpack / core / transform / transforms / transformconfig . java <nl> ppp b / x - pack / plugin / core / src / main / java / org / elasticsearch / xpack / core / transform / transforms / transformconfig . java <nl>
public class transformconfig extends abstractdiffable < transformconfig > implement <nl> } <nl>  <nl> / / num . set interim_results to true for transforms < num . 15 to keep bwc <nl> - if ( builder . getversion ( ) ! = null & & builder . getversion ( ) . before ( version . current ) ) { <nl> + if ( builder . getversion ( ) ! = null & & builder . getversion ( ) . before ( version . v_7_15_0 ) ) { <nl> builder . setsettings ( <nl> new settingsconfig ( <nl> builder . getsettings ( ) . getmaxpagesearchsize ( ) ,
tasks . register ( " updatecibwcversions " ) { <nl> } <nl> } <nl>  <nl> - <nl> - string buildmetadatavalue = providers . environmentvariable ( ' build_metadata ' ) . orelse ( " " ) . foruseatconfigurationtime ( ) . get ( ) <nl> - map < string , string > buildmetadatamap = buildmetadatavalue . tokenize ( ' ; ' ) . collectentries { <nl> - def ( string key , string value ) = it . split ( ' = ' ) <nl> - return [ key , value ] <nl> - } <nl> - <nl> tasks . register ( " verifyversions " ) { <nl> dolast { <nl> if ( gradle . startparameter . isoffline ( ) ) { <nl>
public class indexservice extends abstractindexcomponent implements indicesclust <nl> } <nl>  <nl> if ( path = = null ) { <nl> - <nl> - / / that ' s being relocated / replicated we know how large it will become once it ' s done copying : <nl> - / / count up how many shards are currently on each data path : <nl> - map < path , integer > datapathtoshardcount = new hashmap < > ( ) ; <nl> - for ( indexshard shard : this ) { <nl> - path datapath = shard . shardpath ( ) . getrootstatepath ( ) ; <nl> - integer curcount = datapathtoshardcount . get ( datapath ) ; <nl> - if ( curcount = = null ) { <nl> - curcount = num ; <nl> - } <nl> - datapathtoshardcount . put ( datapath , curcount + num ) ; <nl> - } <nl> - path = shardpath . selectnewpathforshard ( nodeenv , shardid , this . indexsettings , <nl> - routing . getexpectedshardsize ( ) = = shardrouting . unavailable_expected_shard_size <nl> - ? getavgshardsizeinbytes ( ) : routing . getexpectedshardsize ( ) , <nl> - datapathtoshardcount ) ; <nl> + path = shardpath . selectnewpathforshard ( nodeenv , shardid , this . indexsettings ) ; <nl> logger . debug ( " { } creating using a new path [ { } ] " , shardid , path ) ; <nl> } else { <nl> logger . debug ( " { } creating using an existing path [ { } ] " , shardid , path ) ; <nl> mmm a / server / src / main / java / org / elasticsearch / index / shard / shardpath . java <nl> ppp b / server / src / main / java / org / elasticsearch / index / shard / shardpath . java <nl>
testclusters . all { <nl> setting ' xpack . license . self_generated . type ' , ' trial ' <nl> user clustercredentials <nl> } <nl> - <nl> - tasks . named ( " yamlrestcompattest " ) . configure { <nl> - systemproperty ' tests . rest . blacklist ' , [ <nl> - <nl> - ' ilm / 10_basic / test increasing phase timings validated ' <nl> - ] . join ( ' , ' ) <nl> - }
public class compression { <nl> public enum scheme { <nl> lz4 , <nl> deflate ; <nl> - <nl> - <nl> - static final version lz4_version = version . v_8_0_0 ; <nl> + <nl> + static final version lz4_version = version . v_7_14_0 ; <nl> static final int header_length = num ; <nl> private static final byte [ ] deflate_header = new byte [ ] { ' d ' , ' f ' , ' l ' , ' \ 0 ' } ; <nl> private static final byte [ ] lz4_header = new byte [ ] { ' l ' , ' z ' , ' 4 ' , ' \ 0 ' } ;
public class searchablesnapshotaction implements lifecycleaction { <nl> string policyname = lifecyclesettings . lifecycle_name_setting . get ( indexmetadata . getsettings ( ) ) ; <nl> if ( indexmetadata . getsettings ( ) . get ( lifecyclesettings . snapshot_index_name ) ! = null ) { <nl> / / the <nl> - <nl> - / / core in the future , so the settings can be used instead <nl> - / / of strings here <nl> - string repo = indexmetadata . getsettings ( ) . get ( " index . store . snapshot . repository_name " ) ; <nl> + string repo = indexmetadata . getsettings ( ) . get ( repositoriesservice . searchable_snapshots_repository_name_setting_key ) ; <nl> if ( this . snapshotrepository . equals ( repo ) = = false ) { <nl> / / okay , different repo , we need to go ahead with the searchable snapshot <nl> logger . debug ( " [ { } ] action is configured for <nl> mmm a / x - pack / plugin / ilm / qa / multi - node / src / javaresttest / java / org / elasticsearch / xpack / ilm / actions / searchablesnapshotactionit . java <nl> ppp b / x - pack / plugin / ilm / qa / multi - node / src / javaresttest / java / org / elasticsearch / xpack / ilm / actions / searchablesnapshotactionit . java <nl>
tasks . named ( " yamlrestcompattest " ) . configure { <nl> ' ml / jobs_get_stats / test get job stats after uploading data prompting the creation of some stats ' , <nl> ' ml / jobs_get_stats / test get job stats for closed job ' , <nl> ' ml / jobs_get_stats / test no exception on get job stats with missing index ' , <nl> - <nl> - ' ml / ml_standard_analyze / test num . 14 analyzer with blank lines ' , <nl> ' ml / post_data / test post data job api , flush , close and verify datacounts doc ' , <nl> ' ml / post_data / test flush with skip_time ' , <nl> ' ml / set_upgrade_mode / setting upgrade mode to disabled from enabled ' ,
tasks . named ( " yamlrestcompattest " ) . configure { <nl> ' ml / jobs_get_stats / test get job stats after uploading data prompting the creation of some stats ' , <nl> ' ml / jobs_get_stats / test get job stats for closed job ' , <nl> ' ml / jobs_get_stats / test no exception on get job stats with missing index ' , <nl> - <nl> - ' ml / ml_info / test ml info ' , <nl> ' ml / post_data / test post data job api , flush , close and verify datacounts doc ' , <nl> ' ml / post_data / test flush with skip_time ' , <nl> ' ml / set_upgrade_mode / setting upgrade mode to disabled from enabled ' ,
public class mlindextemplateregistry extends indextemplateregistry { <nl>  <nl> / * * <nl> * the version that the ml <nl> - * <nl> * / <nl> - public static final version composable_template_switch_version = version . v_8_0_0 ; <nl> + public static final version composable_template_switch_version = version . v_7_14_0 ; <nl>  <nl> private static final string root_resource_path = " / org / elasticsearch / xpack / core / ml / " ; <nl> private static final string anomaly_detection_path = root_resource_path + " anomalydetection / " ;
abstract class abstractsearchasyncaction < result extends searchphaseresult > exten <nl> } <nl>  <nl> boolean buildpointintimefromsearchresults ( ) { <nl> - <nl> - / / we can simply return the point in time of the search request . <nl> return false ; <nl> }
public class searchablesnapshotsrollingupgradeit extends abstractupgradetestcase <nl> asserthitcount ( index , equalto ( numberofdocs * num l ) ) ; <nl> deleteindex ( index ) ; <nl>  <nl> - if ( upgrade_from_version . onorafter ( version . v_8_0_0 ) ) { <nl> + if ( upgrade_from_version . onorafter ( version . v_7_13_0 ) ) { <nl> final request request = new request ( " get " , <nl> " / . snapshot - blob - cache / _settings / index . routing . allocation . include . _tier_preference " ) ; <nl> request . setoptions ( expectwarnings ( " this request accesses system indices : [ . snapshot - blob - cache ] , but in a future major " +
public class transformcontinuousit extends esresttestcase { <nl> if ( randomboolean ( ) ) { <nl> builder . field ( " codec " , " best_compression " ) ; <nl> } <nl> - <nl> - if ( false & & randomboolean ( ) ) { <nl> + if ( randomboolean ( ) ) { <nl> list < string > sortedfields = new arraylist < > ( <nl> / / note : no <nl> randomunique ( ( ) - > randomfrom ( " event " , " metric " , " run " , " timestamp " ) , randomintbetween ( 1 , num ) )
import java . util . optional ; <nl> * / <nl> public class clusterinfo implements toxcontentfragment , writeable { <nl>  <nl> - public static final version data_set_size_size_version = version . v_8_0_0 ; <nl> + public static final version data_set_size_size_version = version . v_7_13_0 ; <nl>  <nl> private final immutableopenmap < string , diskusage > leastavailablespaceusage ; <nl> private final immutableopenmap < string , diskusage > mostavailablespaceusage ;
public class transformfeaturesetusage extends usage { <nl> public transformfeaturesetusage ( streaminput in ) throws ioexception { <nl> super ( in ) ; <nl> this . transformcountbystate = in . readmap ( streaminput : : readstring , streaminput : : readlong ) ; <nl> - if ( in . getversion ( ) . onorafter ( version . v_8_0_0 ) ) { <nl> - this . transformcountbyfeature = in . readmap ( streaminput : : readstring , streaminput : : readlong ) ; <nl> - } else { <nl> - this . transformcountbyfeature = collections . emptymap ( ) ; <nl> - } <nl> + this . transformcountbyfeature = in . readmap ( streaminput : : readstring , streaminput : : readlong ) ; <nl> this . accumulatedstats = new transformindexerstats ( in ) ; <nl> } <nl>  <nl>
public class transformfeaturesetusage extends usage { <nl> public void writeto ( streamoutput out ) throws ioexception { <nl> super . writeto ( out ) ; <nl> out . writemap ( transformcountbystate , streamoutput : : writestring , streamoutput : : writelong ) ; <nl> - if ( out . getversion ( ) . onorafter ( version . v_8_0_0 ) ) { <nl> - out . writemap ( transformcountbyfeature , streamoutput : : writestring , streamoutput : : writelong ) ; <nl> - } <nl> + out . writemap ( transformcountbyfeature , streamoutput : : writestring , streamoutput : : writelong ) ; <nl> accumulatedstats . writeto ( out ) ; <nl> }
public class transportmountsearchablesnapshotaction extends transportmasternodea <nl> . put ( diskthresholddecider . setting_ignore_disk_watermarks . getkey ( ) , true ) ; <nl>  <nl> / / we cannot apply this setting during rolling upgrade . <nl> - <nl> - if ( minnodeversion . onorafter ( version . v_8_0_0 ) ) { <nl> + if ( minnodeversion . onorafter ( version . v_7_13_0 ) ) { <nl> settings . put ( shardlimitvalidator . index_setting_shard_limit_group . getkey ( ) , shardlimitvalidator . frozen_group ) ; <nl> } <nl> }
<nl> " store stats " : <nl> - skip : <nl> features : [ arbitrary_key ] <nl> - # <nl> - version : " - num . 99 . 99 " <nl> + version : " - num . 12 . 99 " <nl> reason : " total_data_set_size added in num . 13 " <nl>  <nl> - do : <nl> mmm a / server / src / main / java / org / elasticsearch / index / store / storestats . java <nl> ppp b / server / src / main / java / org / elasticsearch / index / store / storestats . java <nl>
public class storestats implements writeable , toxcontentfragment { <nl> public static final long unknown_reserved_bytes = - 1l ; <nl>  <nl> public static final version reserved_bytes_version = version . v_7_9_0 ; <nl> - public static final version total_data_set_size_size_version = version . v_8_0_0 ; <nl> + public static final version total_data_set_size_size_version = version . v_7_13_0 ; <nl>  <nl> private long sizeinbytes ; <nl> private long totaldatasetsizeinbytes ;
<nl> } else { <nl> urlbuilder + = " http : / / " ; <nl> } <nl> - urlbuilder + = attr [ " server " ] + " : " + attr [ " port " ] ; <nl> + urlbuilder + = attr [ " server " ] + " : " + attr [ " port " ] + " ? " ; <nl>  <nl> - var params = [ ] ; <nl> - params [ " user " ] = attr [ " username " ] ; <nl> - params [ " password " ] = attr [ " password " ] ; <nl> - <nl> - var formattedparams = [ ] ; <nl> - <nl> - for ( var key in params ) { <nl> - if ( params [ key ] ) { <nl> - var param = encodeuricomponent ( params [ key ] ) ; <nl> - formattedparams . push ( connectionhelper . formatkeyvaluepair ( key , param ) ) ; <nl> - } <nl> - } <nl> - <nl> - if ( formattedparams . length > num ) { <nl> - urlbuilder + = " ? " + formattedparams . join ( " & " ) <nl> - } <nl> - <nl> - / / logging visible in log . txt if - dloglevel = debug is added in tableau command line <nl> - logging . log ( " es jdbc url before adding additional parameters : " + urlbuilder ) ; <nl> - <nl> - <nl> - var additionalconnectionparameters = attr [ connectionhelper . attributewarehouse ] ; <nl> - if ( additionalconnectionparameters ! = null & & additionalconnectionparameters . trim ( ) . length > num ) { <nl> - urlbuilder + = ( formattedparams . length = = num ) ? " ? " : " & " ; <nl> - urlbuilder + = additionalconnectionparameters ; <nl> - } <nl> - <nl> - logging . log ( " es jdbc final url : " + urlbuilder ) ; <nl> return [ urlbuilder ] ; <nl> } ) <nl> mmm / dev / null <nl> ppp b / x - pack / plugin / sql / connectors / tableau / connector / connectionproperties . js <nl>
<nl> mmm <nl> " _shard_doc sort " : <nl> - skip : <nl> - version : " - num . 99 . 99 " <nl> - reason : _shard_doc sort was added in num . 0 ( <nl> + version : " - num . 11 . 99 " <nl> + reason : _shard_doc sort was added in num . 12 <nl>  <nl> - do : <nl> indices . create :
public class searchablesnapshotshardstats implements writeable , toxcontentobject <nl> } <nl> this . fileext = in . readstring ( ) ; <nl> this . numfiles = in . readvlong ( ) ; <nl> - if ( in . getversion ( ) . before ( version . v_8_0_0 ) ) { <nl> + if ( in . getversion ( ) . before ( version . v_7_13_0 ) ) { <nl> this . totalsize = new bytesizevalue ( in . readvlong ( ) ) ; <nl> this . minsize = bytesizevalue . zero ; <nl> this . maxsize = bytesizevalue . zero ; <nl>
public class searchablesnapshotshardstats implements writeable , toxcontentobject <nl> } <nl> out . writestring ( fileext ) ; <nl> out . writevlong ( numfiles ) ; <nl> - if ( out . getversion ( ) . before ( version . v_8_0_0 ) ) { <nl> + if ( out . getversion ( ) . before ( version . v_7_13_0 ) ) { <nl> out . writevlong ( totalsize . getbytes ( ) ) ; <nl> } else { <nl> totalsize . writeto ( out ) ; <nl> mmm a / x - pack / plugin / searchable - snapshots / qa / rest / src / test / resources / rest - api - spec / test / stats . yml <nl> ppp b / x - pack / plugin / searchable - snapshots / qa / rest / src / test / resources / rest - api - spec / test / stats . yml <nl>
public class transformcontinuousit extends esresttestcase { <nl> waituntiltransformsprocessednewdata ( continuoustestcase . sync_delay , run ) ; <nl> stoptransforms ( ) ; <nl>  <nl> - <nl> - refreshallindices ( ) ; <nl> - <nl> / / test the output <nl> for ( continuoustestcase testcase : transformtestcases ) { <nl> try { <nl> mmm a / x - pack / qa / multi - cluster - tests - with - security / src / test / resources / rest - api - spec / test / multi_cluster / 80_transform . yml <nl> ppp b / x - pack / qa / multi - cluster - tests - with - security / src / test / resources / rest - api - spec / test / multi_cluster / 80_transform . yml <nl>
public class transformstats implements writeable , toxcontentobject { <nl> if ( out . getversion ( ) . onorafter ( version . v_7_4_0 ) ) { <nl> out . writestring ( id ) ; <nl> / / num . 13 introduced the waiting state , in older version report the state as started <nl> - if ( out . getversion ( ) . before ( version . v_8_0_0 ) & & state . equals ( state . waiting ) ) { <nl> + if ( out . getversion ( ) . before ( version . v_7_13_0 ) & & state . equals ( state . waiting ) ) { <nl> out . writeenum ( state . started ) ; <nl> } else { <nl> out . writeenum ( state ) ; <nl> mmm a / x - pack / plugin / core / src / test / java / org / elasticsearch / xpack / core / transform / transforms / transformstatstests . java <nl> ppp b / x - pack / plugin / core / src / test / java / org / elasticsearch / xpack / core / transform / transforms / transformstatstests . java <nl>
public class transformstatstests extends abstractserializingtestcase < transformst <nl> output . setversion ( version . v_7_12_0 ) ; <nl> stats . writeto ( output ) ; <nl> try ( streaminput in = output . bytes ( ) . streaminput ( ) ) { <nl> - in . setversion ( version . v_8_0_0 ) ; <nl> + in . setversion ( version . v_7_13_0 ) ; <nl> transformstats statsfromold = new transformstats ( in ) ; <nl> assertthat ( statsfromold . getstate ( ) , equalto ( started ) ) ; <nl> }
public class frozencacheinfoaction extends actiontype < frozencacheinforesponse > { <nl>  <nl> @ override <nl> protected void doexecute ( task task , request request , actionlistener < frozencacheinforesponse > listener ) { <nl> - if ( request . discoverynode . getversion ( ) . onorafter ( version . v_8_0_0 ) ) { <nl> + if ( request . discoverynode . getversion ( ) . onorafter ( version . v_7_12_0 ) ) { <nl> transportservice . sendchildrequest ( <nl> request . discoverynode , <nl> frozencacheinfonodeaction . name , <nl>
public class frozencacheinfoaction extends actiontype < frozencacheinforesponse > { <nl> new actionlistenerresponsehandler < > ( listener , frozencacheinforesponse : : new ) <nl> ) ; <nl> } else { <nl> - / / before this is backported , be lenient with older versions . <nl> - <nl> - listener . onresponse ( new frozencacheinforesponse ( request . discoverynode . getversion ( ) . onorafter ( version . v_7_12_0 ) ) ) ; <nl> + listener . onresponse ( new frozencacheinforesponse ( false ) ) ; <nl> } <nl> }
public class bwcsetupextension { <nl>  <nl> private taskprovider < loggedexec > createrunbwcgradletask ( project project , string name , action < loggedexec > configaction ) { <nl> return project . gettasks ( ) . register ( name , loggedexec . class , loggedexec - > { <nl> - <nl> loggedexec . dependson ( " checkoutbwcbranch " ) ; <nl> loggedexec . setspooloutput ( true ) ; <nl> loggedexec . setworkingdir ( checkoutdir . get ( ) ) ; <nl> loggedexec . dofirst ( t - > { <nl> / / execution time so that the checkouts are available <nl> - string javaversionsstring = readfromfile ( new file ( checkoutdir . get ( ) , " . ci / java - versions . properties " ) ) ; <nl> - loggedexec . environment ( <nl> - " java_home " , <nl> - getjavahome ( <nl> - integer . parseint ( <nl> - javaversionsstring . lines ( ) <nl> - . filter ( l - > l . trim ( ) . startswith ( " es_build_java = " ) ) <nl> - . map ( l - > l . replace ( " es_build_java = java " , " " ) . trim ( ) ) <nl> - . map ( l - > l . replace ( " es_build_java = openjdk " , " " ) . trim ( ) ) <nl> - . collect ( collectors . joining ( " ! ! " ) ) <nl> - ) <nl> - ) <nl> - ) ; <nl> - loggedexec . environment ( <nl> - " runtime_java_home " , <nl> - getjavahome ( <nl> - integer . parseint ( <nl> - javaversionsstring . lines ( ) <nl> - . filter ( l - > l . trim ( ) . startswith ( " es_runtime_java = " ) ) <nl> - . map ( l - > l . replace ( " es_runtime_java = java " , " " ) . trim ( ) ) <nl> - . map ( l - > l . replace ( " es_runtime_java = openjdk " , " " ) . trim ( ) ) <nl> - . collect ( collectors . joining ( " ! ! " ) ) <nl> - ) <nl> - ) <nl> - ) ; <nl> + string minimumcompilerversion = readfromfile ( new file ( checkoutdir . get ( ) , minimum_compiler_version_path ) ) ; <nl> + loggedexec . environment ( " java_home " , getjavahome ( integer . parseint ( minimumcompilerversion ) ) ) ; <nl> } ) ; <nl>  <nl> if ( os . isfamily ( os . family_windows ) ) {
public class blobstorecacheservice { <nl> private static final logger logger = logmanager . getlogger ( blobstorecacheservice . class ) ; <nl>  <nl> / * * <nl> - * before num . 0 . 0 blobs were cached using a num kb or num kb maximum length . <nl> + * before num . 12 . 0 blobs were cached using a num kb or num kb maximum length . <nl> * / <nl> - private static final version old_cached_blob_size_version = version . v_8_0_0 ; <nl> + private static final version old_cached_blob_size_version = version . v_7_12_0 ; <nl>  <nl> public static final int default_cached_blob_size = bytesizeunit . kb . tointbytes ( 1 ) ; <nl> private static final cache < string , string > log_exceeding_files_cache = cachebuilder . < string , string > builder ( )
public class modelaliasmetadata implements metadata . custom { <nl>  <nl> @ override <nl> public version getminimalsupportedversion ( ) { <nl> - <nl> - return version . v_8_0_0 ; <nl> + return version . v_7_13_0 ; <nl> } <nl>  <nl> @ override
class yamlrestcompattestpluginfunctest extends abstractrestresourcesfunctest { <nl> } <nl>  <nl> when : <nl> - <nl> - result = gradlerunner ( transformtask , " - i " ) . build ( ) <nl> + result = gradlerunner ( transformtask ) . build ( ) <nl>  <nl> then : <nl> result . task ( transformtask ) . outcome = = taskoutcome . up_to_date <nl> mmm a / buildsrc / src / main / java / org / elasticsearch / gradle / internal / rest / compat / restcompattesttransformtask . java <nl> ppp b / buildsrc / src / main / java / org / elasticsearch / gradle / internal / rest / compat / restcompattesttransformtask . java <nl>
public final class schemautil { <nl> listener . onresponse ( collections . emptymap ( ) ) ; <nl> return ; <nl> } <nl> - fieldcapabilitiesrequest fieldcapabilitiesrequest = new fieldcapabilitiesrequest ( ) . indices ( index ) <nl> - . fields ( fields ) <nl> - . indicesoptions ( indicesoptions . lenient_expand_open ) ; <nl> + fieldcapabilitiesrequest fieldcapabilitiesrequest = <nl> + new fieldcapabilitiesrequest ( ) <nl> + . indices ( index ) <nl> + . fields ( fields ) <nl> + . runtimefields ( runtimemappings ) <nl> + . indicesoptions ( indicesoptions . lenient_expand_open ) ; <nl> client . execute ( <nl> fieldcapabilitiesaction . instance , <nl> fieldcapabilitiesrequest , <nl> actionlistener . wrap ( <nl> - response - > listener . onresponse ( mergesourcemappingswithruntimemappings ( extractfieldmappings ( response ) , runtimemappings ) ) , <nl> + response - > listener . onresponse ( extractfieldmappings ( response ) ) , <nl> listener : : onfailure ) <nl> ) ; <nl> } <nl>  <nl> - / * * <nl> - * <nl> - * see https : / / github . com / elastic / elasticsearch / issues / 68117 <nl> - * / <nl> - private static map < string , string > mergesourcemappingswithruntimemappings ( map < string , string > sourcemappings , <nl> - map < string , object > runtimemappings ) { <nl> - map < string , string > sourcemappingswithruntimefields = new hashmap < > ( sourcemappings ) ; <nl> - for ( map . entry < string , object > runtimemappingentry : runtimemappings . entryset ( ) ) { <nl> - if ( runtimemappingentry . getvalue ( ) instanceof map ) { <nl> - @ suppresswarnings ( " unchecked " ) <nl> - map < string , object > runtimemappingvalue = ( map < string , object > ) runtimemappingentry . getvalue ( ) ; <nl> - if ( runtimemappingvalue . containskey ( " type " ) ) { <nl> - string fieldname = runtimemappingentry . getkey ( ) ; <nl> - @ suppresswarnings ( " unchecked " ) <nl> - string type = ( string ) runtimemappingvalue . get ( " type " ) ; <nl> - sourcemappingswithruntimefields . put ( fieldname , type ) ; <nl> - } <nl> - } <nl> - } <nl> - return sourcemappingswithruntimefields ; <nl> - } <nl> - <nl> / * * <nl> * insert object mappings for fields like : <nl> * <nl> mmm a / x - pack / plugin / transform / src / test / java / org / elasticsearch / xpack / transform / transforms / pivot / schemautiltests . java <nl> ppp b / x - pack / plugin / transform / src / test / java / org / elasticsearch / xpack / transform / transforms / pivot / schemautiltests . java <nl>
public class transformconfig extends abstractdiffable < transformconfig > implement <nl> } else { <nl> settings = new settingsconfig ( ) ; <nl> } <nl> - if ( in . getversion ( ) . onorafter ( version . v_8_0_0 ) ) { <nl> + if ( in . getversion ( ) . onorafter ( version . v_7_12_0 ) ) { <nl> retentionpolicyconfig = in . readoptionalnamedwriteable ( retentionpolicyconfig . class ) ; <nl> } else { <nl> retentionpolicyconfig = null ; <nl>
public class transformconfig extends abstractdiffable < transformconfig > implement <nl> if ( out . getversion ( ) . onorafter ( version . v_7_8_0 ) ) { <nl> settings . writeto ( out ) ; <nl> } <nl> - if ( out . getversion ( ) . onorafter ( version . v_8_0_0 ) ) { <nl> + if ( out . getversion ( ) . onorafter ( version . v_7_12_0 ) ) { <nl> out . writeoptionalnamedwriteable ( retentionpolicyconfig ) ; <nl> } <nl> } <nl> mmm a / x - pack / plugin / core / src / main / java / org / elasticsearch / xpack / core / transform / transforms / transformconfigupdate . java <nl> ppp b / x - pack / plugin / core / src / main / java / org / elasticsearch / xpack / core / transform / transforms / transformconfigupdate . java <nl>
public class transformconfigupdate implements writeable { <nl> } else { <nl> settings = null ; <nl> } <nl> - if ( in . getversion ( ) . onorafter ( version . v_8_0_0 ) ) { <nl> + if ( in . getversion ( ) . onorafter ( version . v_7_12_0 ) ) { <nl> retentionpolicyconfig = in . readoptionalnamedwriteable ( retentionpolicyconfig . class ) ; <nl> } else { <nl> retentionpolicyconfig = null ; <nl>
public class transformconfigupdate implements writeable { <nl> if ( out . getversion ( ) . onorafter ( version . v_7_8_0 ) ) { <nl> out . writeoptionalwriteable ( settings ) ; <nl> } <nl> - if ( out . getversion ( ) . onorafter ( version . v_8_0_0 ) ) { <nl> + if ( out . getversion ( ) . onorafter ( version . v_7_12_0 ) ) { <nl> out . writeoptionalnamedwriteable ( retentionpolicyconfig ) ; <nl> } <nl> } <nl> mmm a / x - pack / plugin / core / src / main / java / org / elasticsearch / xpack / core / transform / transforms / transformindexerstats . java <nl> ppp b / x - pack / plugin / core / src / main / java / org / elasticsearch / xpack / core / transform / transforms / transformindexerstats . java <nl>
public class transformindexerstats extends indexerjobstats { <nl> this . expavgdocumentsindexed = in . readdouble ( ) ; <nl> this . expavgdocumentsprocessed = in . readdouble ( ) ; <nl> } <nl> - if ( in . getversion ( ) . onorafter ( version . v_8_0_0 ) ) { <nl> + if ( in . getversion ( ) . onorafter ( version . v_7_12_0 ) ) { <nl> this . numdeleteddocuments = in . readvlong ( ) ; <nl> this . deletetime = in . readvlong ( ) ; <nl> } <nl>
public class transformindexerstats extends indexerjobstats { <nl> out . writedouble ( this . expavgdocumentsindexed ) ; <nl> out . writedouble ( this . expavgdocumentsprocessed ) ; <nl> } <nl> - if ( out . getversion ( ) . onorafter ( version . v_8_0_0 ) ) { <nl> + if ( out . getversion ( ) . onorafter ( version . v_7_12_0 ) ) { <nl> out . writevlong ( numdeleteddocuments ) ; <nl> out . writevlong ( deletetime ) ; <nl> }
public class sqlsearchit extends esresttestcase { <nl> bwcnodes = new arraylist < > ( nodes . getbwcnodes ( ) ) ; <nl> bwcversion = nodes . getbwcnodes ( ) . get ( 0 ) . getversion ( ) ; <nl> newversion = nodes . getnewnodes ( ) . get ( 0 ) . getversion ( ) ; <nl> - <nl> - isbwcnodebeforefieldsapiinql = newversion = = version . v_8_0_0 | | bwcversion . before ( fields_api_ql_introduction ) ; <nl> + isbwcnodebeforefieldsapiinql = bwcversion . before ( fields_api_ql_introduction ) ; <nl> isbwcnodebeforefieldsapiines = bwcversion . before ( switch_to_fields_api_version ) ; <nl>  <nl> string mappings = readresource ( sqlsearchit . class . getresourceasstream ( " / all_field_types . json " ) ) ;
public class regressionit extends mlnativedataframeanalyticsintegtestcase { <nl> } <nl> } <nl>  <nl> - <nl> - / / empty feature importance <nl> - / / assertthat ( importancearray , hassize ( greaterthan ( 0 ) ) ) ; <nl> - / / assertthat ( <nl> - / / importancearray . stream ( ) . filter ( m - > numerical_feature_field . equals ( m . get ( " feature_name " ) ) <nl> - / / | | discrete_numerical_feature_field . equals ( m . get ( " feature_name " ) ) ) . findany ( ) , <nl> - / / ispresent ( ) ) ; <nl> + assertthat ( importancearray , hassize ( greaterthan ( 0 ) ) ) ; <nl> + assertthat ( <nl> + importancearray . stream ( ) . filter ( m - > numerical_feature_field . equals ( m . get ( " feature_name " ) ) <nl> + | | discrete_numerical_feature_field . equals ( m . get ( " feature_name " ) ) ) . findany ( ) , <nl> + ispresent ( ) ) ; <nl> } <nl>  <nl> / / if feature importance was empty for some of the docs this assertion helps us <nl>
public class transformcheckpointinginfo implements writeable , toxcontentobject { <nl> } else { <nl> changeslastdetectedat = null ; <nl> } <nl> - if ( in . getversion ( ) . onorafter ( version . v_8_0_0 ) ) { <nl> + if ( in . getversion ( ) . onorafter ( version . v_7_12_0 ) ) { <nl> lastsearchtime = in . readoptionalinstant ( ) ; <nl> } else { <nl> lastsearchtime = null ; <nl>
public class transformcheckpointinginfo implements writeable , toxcontentobject { <nl> if ( out . getversion ( ) . onorafter ( version . v_7_4_0 ) ) { <nl> out . writeoptionalinstant ( changeslastdetectedat ) ; <nl> } <nl> - if ( out . getversion ( ) . onorafter ( version . v_8_0_0 ) ) { <nl> + if ( out . getversion ( ) . onorafter ( version . v_7_12_0 ) ) { <nl> out . writeoptionalinstant ( lastsearchtime ) ; <nl> } <nl> }
public class coretestswithsearchruntimefieldsit extends esclientyamlsuitetestcas <nl> return mergemappings ( new string [ ] { " * " } ) ; <nl> } <nl> string [ ] patterns = arrays . stream ( index . split ( " , " ) ) . map ( m - > m . equals ( " _all " ) ? " * " : m ) . toarray ( string [ ] : : new ) ; <nl> - <nl> - if ( patterns . length = = num & & regex . issimplematchpattern ( patterns [ 0 ] ) ) { <nl> + if ( patterns . length = = num & & regex . issimplematchpattern ( patterns [ 0 ] ) ) { <nl> return runtimemappings . get ( patterns [ 0 ] ) ; <nl> } <nl> return mergemappings ( patterns ) ;
public class transformconfig extends abstractdiffable < transformconfig > implement <nl> } <nl> setheaders ( in . readmap ( streaminput : : readstring , streaminput : : readstring ) ) ; <nl> pivotconfig = in . readoptionalwriteable ( pivotconfig : : new ) ; <nl> - if ( in . getversion ( ) . onorafter ( version . v_8_0_0 ) ) { <nl> - latestconfig = in . readoptionalwriteable ( latestconfig : : new ) ; <nl> - } else { <nl> - latestconfig = null ; <nl> - } <nl> + latestconfig = in . readoptionalwriteable ( latestconfig : : new ) ; <nl> description = in . readoptionalstring ( ) ; <nl> if ( in . getversion ( ) . onorafter ( version . v_7_3_0 ) ) { <nl> syncconfig = in . readoptionalnamedwriteable ( syncconfig . class ) ; <nl>
public class transformconfig extends abstractdiffable < transformconfig > implement <nl> } <nl> out . writemap ( headers , streamoutput : : writestring , streamoutput : : writestring ) ; <nl> out . writeoptionalwriteable ( pivotconfig ) ; <nl> - if ( out . getversion ( ) . onorafter ( version . v_8_0_0 ) ) { <nl> - out . writeoptionalwriteable ( latestconfig ) ; <nl> - } <nl> + out . writeoptionalwriteable ( latestconfig ) ; <nl> out . writeoptionalstring ( description ) ; <nl> if ( out . getversion ( ) . onorafter ( version . v_7_3_0 ) ) { <nl> out . writeoptionalnamedwriteable ( syncconfig ) ;
<nl> " remove alias with must_exist " : <nl>  <nl> - skip : <nl> - version : " - num . 99 . 99 " # <nl> + version : " - num . 10 . 99 " <nl> reason : " must_exist does not work until num . 11 " <nl>  <nl> - do :
import java . util . regex . pattern ; <nl> * @ see mediatyperegistry <nl> * / <nl> public class parsedmediatype { <nl> - <nl> - / / sun . net . www . protocol . http . httpurlconnection sets a default accept header if it was not provided on a request . <nl> - / / for this value parsing returns null . <nl> - public static final string default_accept_string = " text / html , image / gif , image / jpeg , * ; q = . 2 , * / * ; q = . 2 " ; <nl> - <nl> private final string type ; <nl> private final string subtype ; <nl> private final map < string , string > parameters ; <nl>
public class fetchcontext { <nl> * should the response include version metadata <nl> * / <nl> public boolean version ( ) { <nl> - <nl> - / / stored fields here ? <nl> - return searchcontext . version ( ) & & <nl> - ( searchcontext . storedfieldscontext ( ) = = null | | searchcontext . storedfieldscontext ( ) . fetchfields ( ) ) ; <nl> + return searchcontext . version ( ) ; <nl> } <nl>  <nl> / * *
public abstract class esclientyamlsuitetestcase extends esresttestcase { <nl> configureclient ( builder , restclientsettings ( ) ) ; <nl> return builder ; <nl> } <nl> - <nl> - protected final boolean preservedatastreamsuponcompletion ( ) { <nl> - <nl> - / / for now don ' t automatically try to remove all data streams after each yaml test . <nl> - / / the client runners need to be adjust to remove data streams after each test too , <nl> - / / otherwise rest yaml tests using data streams succeed in elasticsearch , but may fail when clients run <nl> - / / the yaml test suite . in the mean time we should delete data streams manually after each test . <nl> - return true ; <nl> - } <nl> } <nl> mmm a / x - pack / qa / rolling - upgrade / src / test / java / org / elasticsearch / upgrades / upgradeclusterclientyamltestsuiteit . java <nl> ppp b / x - pack / qa / rolling - upgrade / src / test / java / org / elasticsearch / upgrades / upgradeclusterclientyamltestsuiteit . java <nl>
public class searchablesnapshotsblobstorecacheintegtests extends basesearchables <nl> new searchablesnapshotsstatsrequest ( ) <nl> ) . actionget ( ) . getstats ( ) ) { <nl> for ( final searchablesnapshotshardstats . cacheindexinputstats indexinputstats : shardstats . getstats ( ) ) { <nl> - final boolean mayreadmorethanheader <nl> / / we read the header of each file contained within the . cfs file , which could be anywhere <nl> - = indexinputstats . getfilename ( ) . endswith ( " . cfs " ) <nl> - / / we read a couple of longs at the end of the . fdt file ( see https : / / issues . apache . org / jira / browse / lucene - 9456 ) <nl> - <nl> - | | indexinputstats . getfilename ( ) . endswith ( " . fdt " ) ; <nl> + final boolean mayreadmorethanheader = indexinputstats . getfilename ( ) . endswith ( " . cfs " ) ; <nl> if ( indexinputstats . getfilelength ( ) < = blobstorecacheservice . default_cached_blob_size * num <nl> | | mayreadmorethanheader = = false ) { <nl> assertthat ( strings . tostring ( indexinputstats ) , indexinputstats . getblobstorebytesrequested ( ) . getcount ( ) , equalto ( 0l ) ) ;
<nl> - / * <nl> - * copyright elasticsearch b . v . and / or licensed to elasticsearch b . v . under one <nl> - * or more contributor license agreements . licensed under the elastic license ; <nl> - * you may not use this file except in compliance with the elastic license . <nl> - * / <nl> - <nl> - <nl> - / * <nl> - * only want to do because we don ' t yet have a fieldmapper implementation . <nl> - * once we have that we can move to mock scripts in unit tests and painless <nl> - * in integration tests . * / <nl> - <nl> - grant { <nl> - / / needed to generate runtime classes <nl> - permission java . lang . runtimepermission " createclassloader " ; <nl> - <nl> - / / needed to find the classloader to load whitelisted classes from <nl> - permission java . lang . runtimepermission " getclassloader " ; <nl> - } ; <nl> -
public class blobstorecacheservice extends abstractlifecyclecomponent implements <nl> } <nl>  <nl> protected void getasync ( string repository , string name , string path , long offset , actionlistener < cachedblob > listener ) { <nl> - if ( ( lifecycle . started ( ) & & ready . get ( ) ) = = false ) { <nl> - <nl> - / / we might get lucky and hit a started shard anyway . <nl> - logger . debug ( " not ready : [ { } ] " , cachedblob . generateid ( repository , name , path , offset ) ) ; <nl> - listener . onresponse ( cachedblob . cache_not_ready ) ; <nl> - return ; <nl> - } <nl> final getrequest request = new getrequest ( index ) . id ( cachedblob . generateid ( repository , name , path , offset ) ) ; <nl> client . get ( request , new actionlistener < > ( ) { <nl> @ override
public abstract class remoteconnectionstrategy implements transportconnectionlis <nl> . setcompressionenabled ( remoteclusterservice . remote_cluster_compress . getconcretesettingfornamespace ( clusteralias ) . get ( settings ) ) <nl> . setpinginterval ( remoteclusterservice . remote_cluster_ping_schedule . getconcretesettingfornamespace ( clusteralias ) . get ( settings ) ) <nl> . addconnections ( 0 , transportrequestoptions . type . bulk , transportrequestoptions . type . state , <nl> - transportrequestoptions . type . recovery ) <nl> - <nl> - . addconnections ( mode . numberofchannels , transportrequestoptions . type . reg , transportrequestoptions . type . ping ) ; <nl> + transportrequestoptions . type . recovery , transportrequestoptions . type . ping ) <nl> + . addconnections ( mode . numberofchannels , transportrequestoptions . type . reg ) ; <nl> return builder . build ( ) ; <nl> } <nl>  <nl>
public final class runtimescriptfieldmapper extends parametrizedfieldmapper { <nl> " runtime_type [ " + runtimetype . getvalue ( ) + " ] not supported for " + content_type + " field [ " + name + " ] " <nl> ) ; <nl> } <nl> - <nl> + multifields multifields = multifieldsbuilder . build ( this , context ) ; <nl> + if ( multifields . iterator ( ) . hasnext ( ) ) { <nl> + throw new illegalargumentexception ( content_type + " field does not support [ fields ] " ) ; <nl> + } <nl> + copyto copyto = this . copyto . build ( ) ; <nl> + if ( copyto . copytofields ( ) . isempty ( ) = = false ) { <nl> + throw new illegalargumentexception ( content_type + " field does not support [ copy_to ] " ) ; <nl> + } <nl> return new runtimescriptfieldmapper ( <nl> name , <nl> fieldtyperesolver . apply ( this , context ) , <nl> - multifieldsbuilder . build ( this , context ) , <nl> - copyto . build ( ) , <nl> + multifields . empty ( ) , <nl> + copyto . empty ( ) , <nl> runtimetype . getvalue ( ) , <nl> script . getvalue ( ) , <nl> scriptcompiler <nl> mmm a / x - pack / plugin / runtime - fields / src / test / java / org / elasticsearch / xpack / runtimefields / mapper / runtimescriptfieldmappertests . java <nl> ppp b / x - pack / plugin / runtime - fields / src / test / java / org / elasticsearch / xpack / runtimefields / mapper / runtimescriptfieldmappertests . java <nl>
public class indexingpressurestats implements writeable , toxcontentfragment { <nl> primaryrejections = in . readvlong ( ) ; <nl> replicarejections = in . readvlong ( ) ; <nl>  <nl> - <nl> - if ( in . getversion ( ) . onorafter ( version . v_8_0_0 ) ) { <nl> + if ( in . getversion ( ) . onorafter ( version . v_7_10_0 ) ) { <nl> memorylimit = in . readvlong ( ) ; <nl> } else { <nl> memorylimit = - 1l ; <nl>
public class indexingpressurestats implements writeable , toxcontentfragment { <nl> out . writevlong ( primaryrejections ) ; <nl> out . writevlong ( replicarejections ) ; <nl>  <nl> - <nl> - if ( out . getversion ( ) . onorafter ( version . v_8_0_0 ) ) { <nl> + if ( out . getversion ( ) . onorafter ( version . v_7_10_0 ) ) { <nl> out . writevlong ( memorylimit ) ; <nl> } <nl> }
public class movingfunctions { <nl> last_b = b ; <nl> } <nl>  <nl> - double [ ] forecastvalues = new double [ numforecasts ] ; <nl> - for ( int i = num ; i < = numforecasts ; i + + ) { <nl> - int idx = values . length - period + ( ( i - num ) % period ) ; <nl> - <nl> - <nl> - if ( multiplicative ) { <nl> - forecastvalues [ i - 1 ] = ( s + ( i * b ) ) * seasonal [ idx ] ; <nl> - } else { <nl> - forecastvalues [ i - 1 ] = s + ( i * b ) + seasonal [ idx ] ; <nl> - } <nl> + int idx = values . length - period ; <nl> + if ( multiplicative ) { <nl> + return ( s + b ) * seasonal [ idx ] ; <nl> } <nl> - <nl> - return forecastvalues ; <nl> - } <nl> - <nl> - / * * <nl> - * returns an empty set of predictions , filled with nans <nl> - * @ param numpredictions number of empty predictions to generate <nl> - * / <nl> - private static double [ ] emptypredictions ( int numpredictions ) { <nl> - double [ ] predictions = new double [ numpredictions ] ; <nl> - arrays . fill ( predictions , double . nan ) ; <nl> - return predictions ; <nl> + return s + b + seasonal [ idx ] ; <nl> } <nl> } <nl> mmm a / server / src / test / java / org / elasticsearch / search / aggregations / pipeline / movfnwhitelistedfunctiontests . java <nl> ppp b / server / src / test / java / org / elasticsearch / search / aggregations / pipeline / movfnwhitelistedfunctiontests . java <nl>
public final class scriptfieldmapper extends parametrizedfieldmapper { <nl> throw new illegalargumentexception ( " runtime_type must be specified for script field [ " + name + " ] " ) ; <nl> } <nl> } ) ; <nl> - <nl> - / / do all the shards get a consistent view ? <nl> private final parameter < script > script = new parameter < > ( <nl> " script " , <nl> true , <nl> mmm a / x - pack / plugin / src / test / resources / rest - api - spec / test / runtime_fields / 10_keyword . yml <nl> ppp b / x - pack / plugin / src / test / resources / rest - api - spec / test / runtime_fields / 10_keyword . yml <nl>
public class nodestats extends basenoderesponse implements toxcontentfragment { <nl> discoverystats = in . readoptionalwriteable ( discoverystats : : new ) ; <nl> ingeststats = in . readoptionalwriteable ( ingeststats : : new ) ; <nl> adaptiveselectionstats = in . readoptionalwriteable ( adaptiveselectionstats : : new ) ; <nl> - <nl> - if ( in . getversion ( ) . onorafter ( version . v_8_0_0 ) ) { <nl> + if ( in . getversion ( ) . onorafter ( version . v_7_9_0 ) ) { <nl> indexingpressurestats = in . readoptionalwriteable ( indexingpressurestats : : new ) ; <nl> } else { <nl> indexingpressurestats = null ; <nl>
public class nodestats extends basenoderesponse implements toxcontentfragment { <nl> out . writeoptionalwriteable ( discoverystats ) ; <nl> out . writeoptionalwriteable ( ingeststats ) ; <nl> out . writeoptionalwriteable ( adaptiveselectionstats ) ; <nl> - <nl> - if ( out . getversion ( ) . onorafter ( version . v_8_0_0 ) ) { <nl> + if ( out . getversion ( ) . onorafter ( version . v_7_9_0 ) ) { <nl> out . writeoptionalwriteable ( indexingpressurestats ) ; <nl> } <nl> }
remove - item - recurse - force \ tmp - erroraction ignore <nl> new - item - itemtype directory - path \ tmp <nl>  <nl> $ erroractionpreference = " continue " <nl> - # <nl> - & . \ gradlew . bat - g " c : \ users \ $ env : username \ . gradle " - - parallel - - no - daemon - - scan - - console = plain destructivedistrotest <nl> + & . \ gradlew . bat - g " c : \ users \ $ env : username \ . gradle " - - parallel - - no - daemon - - scan - - console = plain $ gradletasks <nl>  <nl> exit $ lastexitcode
public class globalordinalsstringtermsaggregator extends abstractstringtermsaggr <nl> protected final resultstrategy < ? , ? , ? > resultstrategy ; <nl> protected final valuessource . bytes . withordinals valuessource ; <nl>  <nl> - <nl> - / / we can ' t cache this yet in valuessource , since valuessource is reused per field for aggs during the execution . <nl> - / / if aggs with same field , but different include / exclude are defined , then the last defined one will override the <nl> - / / first defined one . <nl> - / / so currently for each instance of this aggregator the acceptedglobalvalues will be computed , this is unnecessary <nl> - / / especially if this agg is on a second layer or deeper . <nl> private final longpredicate acceptedglobalordinals ; <nl> private final long valuecount ; <nl> private final globalordlookupfunction lookupglobalord ;
public class nativeprivilegestore { <nl> public void getprivileges ( collection < string > applications , collection < string > names , <nl> actionlistener < collection < applicationprivilegedescriptor > > listener ) { <nl>  <nl> - <nl> final set < string > applicationnamescachekey = ( isempty ( applications ) | | applications . contains ( " * " ) ) ? <nl> set . of ( " * " ) : set . copyof ( applications ) ; <nl>  <nl>
public class deleteexpireddataaction extends actiontype < deleteexpireddataaction . <nl> this . requestspersecond = null ; <nl> this . timeout = null ; <nl> } <nl> - if ( in . getversion ( ) . onorafter ( version . v_8_0_0 ) ) { <nl> + if ( in . getversion ( ) . onorafter ( version . v_7_9_0 ) ) { <nl> jobid = in . readstring ( ) ; <nl> } <nl> } <nl>
public class deleteexpireddataaction extends actiontype < deleteexpireddataaction . <nl> out . writeoptionalfloat ( requestspersecond ) ; <nl> out . writeoptionaltimevalue ( timeout ) ; <nl> } <nl> - if ( out . getversion ( ) . onorafter ( version . v_8_0_0 ) ) { <nl> + if ( out . getversion ( ) . onorafter ( version . v_7_9_0 ) ) { <nl> out . writestring ( jobid ) ; <nl> } <nl> } <nl> mmm a / x - pack / plugin / core / src / test / java / org / elasticsearch / xpack / core / ml / action / deleteexpireddataactionrequesttests . java <nl> ppp b / x - pack / plugin / core / src / test / java / org / elasticsearch / xpack / core / ml / action / deleteexpireddataactionrequesttests . java <nl>
public class deleteexpireddataactionrequesttests extends abstractbwcwireserializ <nl> if ( version . before ( version . v_7_8_0 ) ) { <nl> return new request ( ) ; <nl> } <nl> - if ( version . before ( version . v_8_0_0 ) ) { <nl> + if ( version . before ( version . v_7_9_0 ) ) { <nl> request request = new request ( ) ; <nl> request . setrequestspersecond ( instance . getrequestspersecond ( ) ) ; <nl> request . settimeout ( instance . gettimeout ( ) ) ;
public final class autodatehistogramaggregatorfactory extends valuessourceaggreg <nl> throw new aggregationexecutionexception ( " registry miss - match - expected autodatehistogramaggregationsupplier , found [ " + <nl> aggregatorsupplier . getclass ( ) . tostring ( ) + " ] " ) ; <nl> } <nl> + function < rounding , rounding . prepared > roundingpreparer = <nl> + valuessource . roundingpreparer ( searchcontext . getqueryshardcontext ( ) . getindexreader ( ) ) ; <nl> return ( ( autodatehistogramaggregatorsupplier ) aggregatorsupplier ) . build ( name , factories , numbuckets , roundinginfos , <nl> - <nl> - rounding : : prepareforunknown , valuessource , config . format ( ) , searchcontext , parent , metadata ) ; <nl> + roundingpreparer , valuessource , config . format ( ) , searchcontext , parent , metadata ) ; <nl> } <nl>  <nl> @ override
public class autodatehistogramaggregatortests extends aggregatortestcase { <nl> fieldtype . sethasdocvalues ( true ) ; <nl> fieldtype . setname ( " date_field " ) ; <nl>  <nl> - testcase ( <nl> - aggregation , <nl> - default_query , <nl> + testcase ( aggregation , default_query , <nl> iw - > { } , <nl> ( consumer < internalautodatehistogram > ) histogram - > { <nl> - <nl> - assertnull ( histogram ) ; <nl> - / * <nl> assertequals ( 0 , histogram . getbuckets ( ) . size ( ) ) ; <nl> assertfalse ( aggregationinspectionhelper . hasvalue ( histogram ) ) ; <nl> - * / <nl> - } , <nl> - fieldtype <nl> - ) ; <nl> + } , fieldtype ) ; <nl> } <nl>  <nl> public void testunmappedmissing ( ) throws ioexception { <nl>
public class autodatehistogramaggregatortests extends aggregatortestcase { <nl> fieldtype . sethasdocvalues ( true ) ; <nl> fieldtype . setname ( " date_field " ) ; <nl>  <nl> - testcase ( <nl> - aggregation , <nl> - default_query , <nl> + testcase ( aggregation , default_query , <nl> iw - > { } , <nl> ( consumer < internalautodatehistogram > ) histogram - > { <nl> - <nl> - assertnull ( histogram ) ; <nl> - / * <nl> - assertequals ( 1 , histogram . getbuckets ( ) . size ( ) ) ; <nl> - asserttrue ( aggregationinspectionhelper . hasvalue ( histogram ) ) ; <nl> - * / <nl> - } , <nl> - fieldtype <nl> - ) ; <nl> + assertequals ( 0 , histogram . getbuckets ( ) . size ( ) ) ; <nl> + assertfalse ( aggregationinspectionhelper . hasvalue ( histogram ) ) ; <nl> + } , fieldtype ) ; <nl> } <nl>  <nl> - <nl> public void testintervalyear ( ) throws ioexception { <nl> final long start = localdate . of ( 2015 , num , num ) . atstartofday ( zoneoffset . utc ) . toinstant ( ) . toepochmilli ( ) ; <nl> final long end = localdate . of ( 2017 , num , num ) . atstartofday ( zoneoffset . utc ) . toinstant ( ) . toepochmilli ( ) ;
public class indexfieldmapper extends metadatafieldmapper { <nl>  <nl> @ override <nl> public valuessourcetype getvaluessourcetype ( ) { <nl> - <nl> return corevaluessourcetype . bytes ; <nl> } <nl> }
setup : <nl> mmm <nl> " no field or script " : <nl> - skip : <nl> - version : " all " # <nl> + version : " - num . 7 . 99 " <nl> reason : " exception was a deep , server exception before num . 8 " <nl> - do : <nl> catch : / required one of fields \ [ field , script \ ] , but none were specified /
public class nodeacknowledgedresponse extends acknowledgedresponse { <nl>  <nl> public nodeacknowledgedresponse ( streaminput in ) throws ioexception { <nl> super ( in ) ; <nl> - <nl> - if ( in . getversion ( ) . onorafter ( version . v_8_0_0 ) ) { <nl> - node = in . readstring ( ) ; <nl> - } else { <nl> - node = " " ; <nl> - } <nl> + node = in . readstring ( ) ; <nl> } <nl>  <nl> public string getnode ( ) { <nl>
public class nodeacknowledgedresponse extends acknowledgedresponse { <nl> @ override <nl> public void writeto ( streamoutput out ) throws ioexception { <nl> super . writeto ( out ) ; <nl> - <nl> - if ( out . getversion ( ) . onorafter ( version . v_8_0_0 ) ) { <nl> - out . writestring ( node ) ; <nl> - } <nl> + out . writestring ( node ) ; <nl> } <nl>  <nl> @ override <nl> mmm a / x - pack / plugin / core / src / test / java / org / elasticsearch / xpack / core / ml / action / nodeacknowledgedresponsetests . java <nl> ppp b / x - pack / plugin / core / src / test / java / org / elasticsearch / xpack / core / ml / action / nodeacknowledgedresponsetests . java <nl>
public class nodeacknowledgedresponsetests extends abstractbwcwireserializationt <nl> return new nodeacknowledgedresponse ( true , " " ) ; <nl> } <nl> } <nl> - <nl> - @ override <nl> - protected nodeacknowledgedresponse mutateinstanceforversion ( nodeacknowledgedresponse instance , version version ) { <nl> - <nl> - if ( version . onorafter ( version . v_8_0_0 ) ) { <nl> - return instance ; <nl> - } else { <nl> - return new nodeacknowledgedresponse ( true , " " ) ; <nl> - } <nl> - } <nl> }
public class snapshotit extends esresthighlevelclienttestcase { <nl> createsnapshotresponse response = createtestsnapshot ( request ) ; <nl> assertequals ( waitforcompletion ? reststatus . ok : reststatus . accepted , response . status ( ) ) ; <nl> if ( waitforcompletion = = false ) { <nl> - / / busy assert on the delete because a known race condition could cause the delete request to not see <nl> - / / the snapshot if delete and snapshot finalization happen at the same time <nl> - / / see https : / / github . com / elastic / elasticsearch / issues / 53509 # issuecomment - 603899620 for details <nl> - <nl> - assertbusy ( ( ) - > { <nl> - / / if we don ' t wait for the snapshot to complete we have to cancel it to not leak the snapshot task <nl> - acknowledgedresponse deleteresponse ; <nl> - try { <nl> - deleteresponse = execute ( <nl> - new deletesnapshotrequest ( repository , snapshot ) , <nl> - highlevelclient ( ) . snapshot ( ) : : delete , highlevelclient ( ) . snapshot ( ) : : deleteasync <nl> - ) ; <nl> - } catch ( exception e ) { <nl> - throw new assertionerror ( e ) ; <nl> - } <nl> - asserttrue ( deleteresponse . isacknowledged ( ) ) ; <nl> - } ) ; <nl> + / / if we don ' t wait for the snapshot to complete we have to cancel it to not leak the snapshot task <nl> + acknowledgedresponse deleteresponse = execute ( <nl> + new deletesnapshotrequest ( repository , snapshot ) , <nl> + highlevelclient ( ) . snapshot ( ) : : delete , highlevelclient ( ) . snapshot ( ) : : deleteasync <nl> + ) ; <nl> + asserttrue ( deleteresponse . isacknowledged ( ) ) ; <nl> } <nl> }
public class coordinatortests extends abstractcoordinatortestcase { <nl> } , ( source , e ) - > { } ) ; <nl> cluster . runfor ( default_cluster_state_update_delay , " committing setting update " ) ; <nl>  <nl> - leader . disconnect ( ) ; <nl> - cluster . runfor ( defaultmillis ( follower_check_timeout_setting ) + defaultmillis ( follower_check_interval_setting ) <nl> + final clusternode removednode = cluster . getanynode ( ) ; <nl> + <nl> + removednode . disconnect ( ) ; <nl> + cluster . runfor ( <nl> + math . max ( defaultmillis ( follower_check_timeout_setting ) + defaultmillis ( follower_check_interval_setting ) , <nl> + defaultmillis ( leader_check_timeout_setting ) + defaultmillis ( leader_check_interval_setting ) ) <nl> + default_cluster_state_update_delay , " detecting disconnection " ) ; <nl>  <nl> - assertthat ( leader . getlastappliedclusterstate ( ) . blocks ( ) . global ( ) , hasitem ( expectedblock ) ) ; <nl> + assertthat ( removednode . getlastappliedclusterstate ( ) . blocks ( ) . global ( ) , hasitem ( expectedblock ) ) ; <nl>  <nl> - <nl> + removednode . close ( ) ; <nl> + final clusternode restartednode = removednode . restartednode ( ) ; <nl> + cluster . clusternodes . replaceall ( cn - > cn = = removednode ? restartednode : cn ) ; <nl> + restartednode . disconnect ( ) ; <nl> + <nl> + cluster . stabilise ( ) ; <nl> + assertthat ( restartednode . getlastappliedclusterstate ( ) . blocks ( ) . global ( ) , hasitem ( expectedblock ) ) ; <nl> } <nl> }
public class coordinatortests extends abstractcoordinatortestcase { <nl> } <nl>  <nl> public void testacklistenerreceivesnacksfromfollowerinhigherterm ( ) { <nl> - <nl> - / / final cluster cluster = new cluster ( 3 ) ; <nl> - / / cluster . runrandomly ( ) ; <nl> - / / cluster . stabilise ( ) ; <nl> - / / final clusternode leader = cluster . getanyleader ( ) ; <nl> - / / final clusternode follower0 = cluster . getanynodeexcept ( leader ) ; <nl> - / / final clusternode follower1 = cluster . getanynodeexcept ( leader , follower0 ) ; <nl> - / / <nl> - / / follower0 . coordinator . joinleaderinterm ( new startjoinrequest ( follower0 . localnode , follower0 . coordinator . getcurrentterm ( ) + num ) ) ; <nl> - / / ackcollector ackcollector = leader . submitvalue ( randomlong ( ) ) ; <nl> - / / cluster . stabilise ( default_cluster_state_update_delay ) ; <nl> - / / asserttrue ( " expected ack from " + leader , ackcollector . hasackedsuccessfully ( leader ) ) ; <nl> - / / asserttrue ( " expected nack from " + follower0 , ackcollector . hasackedunsuccessfully ( follower0 ) ) ; <nl> - / / asserttrue ( " expected ack from " + follower1 , ackcollector . hasackedsuccessfully ( follower1 ) ) ; <nl> + try ( cluster cluster = new cluster ( 3 ) ) { <nl> + cluster . runrandomly ( ) ; <nl> + cluster . stabilise ( ) ; <nl> + final clusternode leader = cluster . getanyleader ( ) ; <nl> + final clusternode follower0 = cluster . getanynodeexcept ( leader ) ; <nl> + final clusternode follower1 = cluster . getanynodeexcept ( leader , follower0 ) ; <nl> + <nl> + final long originalterm = leader . coordinator . getcurrentterm ( ) ; <nl> + follower0 . coordinator . onfollowercheckrequest ( new followerschecker . followercheckrequest ( <nl> + originalterm + num , <nl> + leader . coordinator . getlocalnode ( ) <nl> + ) ) ; <nl> + <nl> + ackcollector ackcollector = leader . submitvalue ( randomlong ( ) ) ; <nl> + cluster . runfor ( default_cluster_state_update_delay , " cluster state update " ) ; <nl> + asserttrue ( " expected ack from " + leader , ackcollector . hasackedsuccessfully ( leader ) ) ; <nl> + asserttrue ( " expected nack from " + follower0 , ackcollector . hasackedunsuccessfully ( follower0 ) ) ; <nl> + asserttrue ( " expected ack from " + follower1 , ackcollector . hasackedsuccessfully ( follower1 ) ) ; <nl> + <nl> + cluster . stabilise ( ) ; <nl> + assertthat ( cluster . getanyleader ( ) . coordinator . getcurrentterm ( ) , greaterthanorequalto ( originalterm + num ) ) ; <nl> + } <nl> } <nl>  <nl> public void testsettinginitialconfigurationtriggerselection ( ) {
public class searchit extends esresthighlevelclienttestcase { <nl> countrequest countrequest = new countrequest ( ) ; <nl> countresponse countresponse = execute ( countrequest , highlevelclient ( ) : : count , highlevelclient ( ) : : countasync ) ; <nl> assertcountheader ( countresponse ) ; <nl> - / / add logging to get more info about why https : / / github . com / elastic / elasticsearch / issues / 35644 is failing <nl> - <nl> - if ( countresponse . getcount ( ) ! = num ) { <nl> - searchrequest searchrequest = new searchrequest ( ) ; <nl> - searchrequest . source ( new searchsourcebuilder ( ) . size ( 20 ) ) ; <nl> - searchresponse searchresponse = execute ( searchrequest , highlevelclient ( ) : : search , highlevelclient ( ) : : searchasync ) ; <nl> - logger . info ( " unexpected hit count , was expecting num hits but got : " + searchresponse . tostring ( ) ) ; <nl> - } <nl> assertequals ( 12 , countresponse . getcount ( ) ) ; <nl> }
public class autoscalingmetadata implements metadata . custom { <nl>  <nl> @ override <nl> public version getminimalsupportedversion ( ) { <nl> - <nl> - return version . v_8_0_0 ; <nl> + return version . v_7_8_0 ; <nl> } <nl>  <nl> @ override <nl> mmm a / x - pack / plugin / autoscaling / src / test / java / org / elasticsearch / xpack / autoscaling / autoscalingintegtestcase . java <nl> ppp b / x - pack / plugin / autoscaling / src / test / java / org / elasticsearch / xpack / autoscaling / autoscalingintegtestcase . java <nl>
public abstract class indexerjobstats implements toxcontentobject , writeable { <nl> this . indexfailures = in . readvlong ( ) ; <nl> this . searchfailures = in . readvlong ( ) ; <nl>  <nl> - if ( in . getversion ( ) . onorafter ( version . v_8_0_0 ) ) { <nl> + if ( in . getversion ( ) . onorafter ( version . v_7_7_0 ) ) { <nl> this . processingtime = in . readvlong ( ) ; <nl> this . processingtotal = in . readvlong ( ) ; <nl> } <nl>
public class indextemplatev2metadata implements metadata . custom { <nl>  <nl> @ override <nl> public version getminimalsupportedversion ( ) { <nl> - <nl> - return version . v_8_0_0 ; <nl> + return version . v_7_7_0 ; <nl> } <nl>  <nl> @ override
public class previewtransformaction extends actiontype < previewtransformaction . re <nl> for ( int i = num ; i < size ; i + + ) { <nl> this . docs . add ( in . readmap ( ) ) ; <nl> } <nl> - if ( in . getversion ( ) . onorafter ( version . v_8_0_0 ) ) { <nl> + if ( in . getversion ( ) . onorafter ( version . v_7_7_0 ) ) { <nl> this . generateddestindexsettings = new transformdestindexsettings ( in ) ; <nl> } else if ( in . getversion ( ) . onorafter ( version . v_7_3_0 ) ) { <nl> map < string , object > objectmap = in . readmap ( ) ; <nl>
public class previewtransformaction extends actiontype < previewtransformaction . re <nl> for ( map < string , object > doc : docs ) { <nl> out . writemapwithconsistentorder ( doc ) ; <nl> } <nl> - if ( out . getversion ( ) . onorafter ( version . v_8_0_0 ) ) { <nl> + if ( out . getversion ( ) . onorafter ( version . v_7_7_0 ) ) { <nl> generateddestindexsettings . writeto ( out ) ; <nl> } else if ( out . getversion ( ) . onorafter ( version . v_7_3_0 ) ) { <nl> out . writemap ( generateddestindexsettings . getmappings ( ) ) ;
<nl> mmm <nl> " test cat aliases output with a hidden <nl> - skip : <nl> - version : " - num . 99 . 99 " <nl> + version : " - num . 6 . 99 " <nl> reason : " hidden indices and aliases were added in num . 7 . 0 " <nl> - # <nl>  <nl> - do : <nl> indices . create : <nl>
<nl> mmm <nl> " test cat aliases output with a hidden <nl> - skip : <nl> - version : " - num . 99 . 99 " <nl> + version : " - num . 6 . 99 " <nl> reason : " hidden indices and aliases were added in num . 7 . 0 " <nl> - # <nl>  <nl> - do : <nl> indices . create : <nl>
<nl> mmm <nl> " test cat aliases output with a visible <nl> - skip : <nl> - version : " - num . 99 . 99 " <nl> + version : " - num . 6 . 99 " <nl> reason : " hidden indices and aliases were added in num . 7 . 0 " <nl> - # <nl>  <nl> - do : <nl> indices . create : <nl> mmm a / rest - api - spec / src / main / resources / rest - api - spec / test / cat . indices / 20_hidden . yml <nl> ppp b / rest - api - spec / src / main / resources / rest - api - spec / test / cat . indices / 20_hidden . yml <nl>
<nl> mmm <nl> " test cat indices output for hidden index " : <nl> - skip : <nl> - version : " - num . 99 . 99 " <nl> + version : " - num . 6 . 99 " <nl> reason : " hidden indices were added in num . 7 . 0 " <nl> - # <nl> - do : <nl> indices . create : <nl> index : index1 <nl>
<nl> mmm <nl> " test cat indices output for dot - hidden <nl> - skip : <nl> - version : " - num . 99 . 99 " <nl> + version : " - num . 6 . 99 " <nl> reason : " hidden indices were added in num . 7 . 0 " <nl> - # <nl> - do : <nl> indices . create : <nl> index : . index1 <nl>
<nl> mmm <nl> " test cat indices output with a hidden <nl> - skip : <nl> - version : " - num . 99 . 99 " <nl> + version : " - num . 6 . 99 " <nl> reason : " hidden indices were added in num . 7 . 0 " <nl> - # <nl>  <nl> - do : <nl> indices . create : <nl>
<nl> mmm <nl> " test cat indices output with a hidden <nl> - skip : <nl> - version : " - num . 99 . 99 " <nl> + version : " - num . 6 . 99 " <nl> reason : " hidden indices and aliases were added in num . 7 . 0 " <nl> - # <nl>  <nl> - do : <nl> indices . create : <nl>
<nl> mmm <nl> " test cat indices output with a hidden index , dot - hidden alias and dot pattern " : <nl> - skip : <nl> - version : " - num . 99 . 99 " <nl> + version : " - num . 6 . 99 " <nl> reason : " hidden indices and aliases were added in num . 7 . 0 " <nl> - # <nl>  <nl> - do : <nl> indices . create :
public class componenttemplatemetadata implements metadata . custom { <nl>  <nl> @ override <nl> public version getminimalsupportedversion ( ) { <nl> - <nl> - return version . v_8_0_0 ; <nl> + return version . v_7_7_0 ; <nl> } <nl>  <nl> @ override
public class alias implements writeable , toxcontentfragment { <nl> indexrouting = in . readoptionalstring ( ) ; <nl> searchrouting = in . readoptionalstring ( ) ; <nl> writeindex = in . readoptionalboolean ( ) ; <nl> - if ( in . getversion ( ) . onorafter ( version . v_8_0_0 ) ) { <nl> + if ( in . getversion ( ) . onorafter ( version . v_7_7_0 ) ) { <nl> ishidden = in . readoptionalboolean ( ) ; <nl> } <nl> } <nl>
public class alias implements writeable , toxcontentfragment { <nl> out . writeoptionalstring ( indexrouting ) ; <nl> out . writeoptionalstring ( searchrouting ) ; <nl> out . writeoptionalboolean ( writeindex ) ; <nl> - if ( out . getversion ( ) . onorafter ( version . v_8_0_0 ) ) { <nl> + if ( out . getversion ( ) . onorafter ( version . v_7_7_0 ) ) { <nl> out . writeoptionalboolean ( ishidden ) ; <nl> } <nl> } <nl> mmm a / server / src / main / java / org / elasticsearch / action / admin / indices / alias / indicesaliasesrequest . java <nl> ppp b / server / src / main / java / org / elasticsearch / action / admin / indices / alias / indicesaliasesrequest . java <nl>
public class indicesaliasesrequest extends acknowledgedrequest < indicesaliasesreq <nl> searchrouting = in . readoptionalstring ( ) ; <nl> indexrouting = in . readoptionalstring ( ) ; <nl> writeindex = in . readoptionalboolean ( ) ; <nl> - if ( in . getversion ( ) . onorafter ( version . v_8_0_0 ) ) { <nl> + if ( in . getversion ( ) . onorafter ( version . v_7_7_0 ) ) { <nl> ishidden = in . readoptionalboolean ( ) ; <nl> } <nl> originalaliases = in . readstringarray ( ) ; <nl>
public class indicesaliasesrequest extends acknowledgedrequest < indicesaliasesreq <nl> out . writeoptionalstring ( searchrouting ) ; <nl> out . writeoptionalstring ( indexrouting ) ; <nl> out . writeoptionalboolean ( writeindex ) ; <nl> - if ( out . getversion ( ) . onorafter ( version . v_8_0_0 ) ) { <nl> + if ( out . getversion ( ) . onorafter ( version . v_7_7_0 ) ) { <nl> out . writeoptionalboolean ( ishidden ) ; <nl> } <nl> out . writestringarray ( originalaliases ) ; <nl> mmm a / server / src / main / java / org / elasticsearch / cluster / metadata / aliasmetadata . java <nl> ppp b / server / src / main / java / org / elasticsearch / cluster / metadata / aliasmetadata . java <nl>
public class aliasmetadata extends abstractdiffable < aliasmetadata > implements to <nl> } <nl> out . writeoptionalboolean ( writeindex ( ) ) ; <nl>  <nl> - if ( out . getversion ( ) . onorafter ( version . v_8_0_0 ) ) { <nl> + if ( out . getversion ( ) . onorafter ( version . v_7_7_0 ) ) { <nl> out . writeoptionalboolean ( ishidden ) ; <nl> } <nl> } <nl>
public class aliasmetadata extends abstractdiffable < aliasmetadata > implements to <nl> } <nl> writeindex = in . readoptionalboolean ( ) ; <nl>  <nl> - if ( in . getversion ( ) . onorafter ( version . v_8_0_0 ) ) { <nl> + if ( in . getversion ( ) . onorafter ( version . v_7_7_0 ) ) { <nl> ishidden = in . readoptionalboolean ( ) ; <nl> } else { <nl> ishidden = null ;
public class boolquerybuilder extends abstractquerybuilder < boolquerybuilder > { <nl>  <nl> public static final boolean adjust_pure_negative_default = true ; <nl>  <nl> - private static final parsefield mustnot = new parsefield ( " mustnot " ) ; <nl> - private static final parsefield must_not = new parsefield ( " must_not " ) ; <nl> + private static final parsefield must_not = new parsefield ( " must_not " ) <nl> + . withdeprecation ( " mustnot " ) ; <nl> private static final parsefield filter = new parsefield ( " filter " ) ; <nl> private static final parsefield should = new parsefield ( " should " ) ; <nl> private static final parsefield must = new parsefield ( " must " ) ; <nl>
public class boolquerybuilder extends abstractquerybuilder < boolquerybuilder > { <nl> should ) ; <nl> parser . declareobjectarray ( ( builder , clauses ) - > clauses . foreach ( builder : : mustnot ) , ( p , c ) - > parseinnerquerybuilder ( p ) , <nl> must_not ) ; <nl> - parser . declareobjectarray ( ( builder , clauses ) - > clauses . foreach ( builder : : mustnot ) , ( p , c ) - > parseinnerquerybuilder ( p ) , <nl> - mustnot ) ; <nl> parser . declareobjectarray ( ( builder , clauses ) - > clauses . foreach ( builder : : filter ) , ( p , c ) - > parseinnerquerybuilder ( p ) , <nl> filter ) ; <nl> parser . declareboolean ( boolquerybuilder : : adjustpurenegative , adjust_pure_negative ) ; <nl> mmm a / server / src / test / java / org / elasticsearch / index / query / boolquerybuildertests . java <nl> ppp b / server / src / test / java / org / elasticsearch / index / query / boolquerybuildertests . java <nl>
public final class threadcontext implements writeable { <nl> } <nl>  <nl> public static list < string > readallowedsystemindices ( streaminput in ) throws ioexception { <nl> - if ( in . getversion ( ) . onorafter ( version . v_8_0_0 ) ) { <nl> + if ( in . getversion ( ) . onorafter ( version . v_7_7_0 ) ) { <nl> return in . readoptionalstringlist ( ) ; <nl> } else { <nl> return emptylist ( ) ; <nl>
public final class threadcontext implements writeable { <nl> } <nl>  <nl> out . writemap ( responseheaders , streamoutput : : writestring , streamoutput : : writestringcollection ) ; <nl> - if ( out . getversion ( ) . onorafter ( version . v_8_0_0 ) ) { <nl> + if ( out . getversion ( ) . onorafter ( version . v_7_7_0 ) ) { <nl> out . writeoptionalstringcollection ( allowedsystemindexpatterns ) ; <nl> } <nl> } <nl> mmm a / test / framework / src / main / java / org / elasticsearch / transport / abstractsimpletransporttestcase . java <nl> ppp b / test / framework / src / main / java / org / elasticsearch / transport / abstractsimpletransporttestcase . java <nl>
<nl> setup : <nl>  <nl> - skip : <nl> - version : " - num . 99 . 99 " # <nl> + version : " - num . 6 . 99 " <nl> reason : " constant_keyword was added in num . 7 " <nl>  <nl> - do :
public class indexnameexpressionresolver { <nl> return resolveemptyortrivialwildcard ( options , metadata ) ; <nl> } <nl>  <nl> - <nl> - / / internally anyway . <nl> set < string > result = innerresolve ( context , expressions , options , metadata ) ; <nl>  <nl> if ( result = = null ) { <nl> mmm a / server / src / test / java / org / elasticsearch / cluster / metadata / indexnameexpressionresolvertests . java <nl> ppp b / server / src / test / java / org / elasticsearch / cluster / metadata / indexnameexpressionresolvertests . java <nl>
public class maxsizecondition extends condition < bytesizevalue > { <nl>  <nl> @ override <nl> public void writeto ( streamoutput out ) throws ioexception { <nl> - <nl> + / / require doing the song and dance around backwards compatibility for this value . since <nl> + / / in this case the deserialized version is not displayed to a user , it ' s okay to simply use <nl> + / / bytes . <nl> out . writevlong ( value . getbytes ( ) ) ; <nl> }
public final class remoteconnectioninfo implements toxcontentfragment , writeable <nl> } <nl>  <nl> public remoteconnectioninfo ( streaminput input ) throws ioexception { <nl> - <nl> - if ( input . getversion ( ) . onorafter ( version . v_8_0_0 ) ) { <nl> + if ( input . getversion ( ) . onorafter ( version . v_7_6_0 ) ) { <nl> remoteconnectionstrategy . connectionstrategy mode = input . readenum ( remoteconnectionstrategy . connectionstrategy . class ) ; <nl> modeinfo = mode . getreader ( ) . read ( input ) ; <nl> initialconnectiontimeout = input . readtimevalue ( ) ; <nl>
public final class remoteconnectioninfo implements toxcontentfragment , writeable <nl>  <nl> @ override <nl> public void writeto ( streamoutput out ) throws ioexception { <nl> - <nl> - if ( out . getversion ( ) . onorafter ( version . v_8_0_0 ) ) { <nl> + if ( out . getversion ( ) . onorafter ( version . v_7_6_0 ) ) { <nl> out . writeenum ( modeinfo . modetype ( ) ) ; <nl> modeinfo . writeto ( out ) ; <nl> out . writetimevalue ( initialconnectiontimeout ) ;
public class maxagecondition extends condition < timevalue > { <nl>  <nl> @ override <nl> public void writeto ( streamoutput out ) throws ioexception { <nl> - <nl> + / / require doing the song and dance around backwards compatibility for this value . since <nl> + / / in this case the deserialized version is not displayed to a user , it ' s okay to simply use <nl> + / / milliseconds . it ' s possible to lose precision if someone were to say , specify num <nl> + / / nanoseconds , however , in that case , their max age is indistinguishable from num <nl> + / / milliseconds regardless . <nl> out . writelong ( value . getmillis ( ) ) ; <nl> }
public class metastateservice { <nl> if ( globalmetadata ! = null ) { <nl> metadatabuilder = metadata . builder ( globalmetadata ) ; <nl> indexgraveyard = globalmetadata . custom ( indexgraveyard . type ) ; <nl> - <nl> - / / assert version . current . major < num : " failed to find manifest file , which is mandatory staring with elasticsearch version num . 0 " ; <nl> } else { <nl> metadatabuilder = metadata . builder ( ) ; <nl> indexgraveyard = indexgraveyard . builder ( ) . build ( ) ; <nl>
public class metastateservice { <nl> tuple < indexmetadata , long > indexmetadataandgeneration = <nl> index_meta_data_format . loadlateststatewithgeneration ( logger , namedxcontentregistry , <nl> nodeenv . resolveindexfolder ( indexfoldername ) ) ; <nl> - <nl> - / / assert version . current . major < num : " failed to find manifest file , which is mandatory staring with elasticsearch version num . 0 " ; <nl> indexmetadata indexmetadata = indexmetadataandgeneration . v1 ( ) ; <nl> long generation = indexmetadataandgeneration . v2 ( ) ; <nl> if ( indexmetadata ! = null ) {
public class recoveryduringreplicationtests extends esindexlevelreplicationtestc <nl> } <nl> } <nl>  <nl> - @ awaitsfix ( bugurl = " https : / / github . com / elastic / elasticsearch / issues / 52598 " ) <nl> public void testresyncafterprimarypromotion ( ) throws exception { <nl> - <nl> string mappings = " { \ " _doc \ " : { \ " properties \ " : { \ " f \ " : { \ " type \ " : \ " keyword \ " } } } } " ; <nl> try ( replicationgroup shards = new replicationgroup ( buildindexmetadata ( 2 , mappings ) ) ) { <nl> shards . startall ( ) ; <nl>
public class modelsizestats implements toxcontentobject , writeable { <nl> totalpartitionfieldcount = in . readvlong ( ) ; <nl> bucketallocationfailurescount = in . readvlong ( ) ; <nl> memorystatus = memorystatus . readfromstream ( in ) ; <nl> - <nl> - if ( in . getversion ( ) . onorafter ( version . v_8_0_0 ) ) { <nl> + if ( in . getversion ( ) . onorafter ( version . v_7_7_0 ) ) { <nl> categorizeddoccount = in . readvlong ( ) ; <nl> totalcategorycount = in . readvlong ( ) ; <nl> frequentcategorycount = in . readvlong ( ) ; <nl>
public class modelsizestats implements toxcontentobject , writeable { <nl> out . writevlong ( totalpartitionfieldcount ) ; <nl> out . writevlong ( bucketallocationfailurescount ) ; <nl> memorystatus . writeto ( out ) ; <nl> - <nl> - if ( out . getversion ( ) . onorafter ( version . v_8_0_0 ) ) { <nl> + if ( out . getversion ( ) . onorafter ( version . v_7_7_0 ) ) { <nl> out . writevlong ( categorizeddoccount ) ; <nl> out . writevlong ( totalcategorycount ) ; <nl> out . writevlong ( frequentcategorycount ) ; <nl> mmm a / x - pack / qa / rolling - upgrade / src / test / resources / rest - api - spec / test / mixed_cluster / 30_ml_jobs_crud . yml <nl> ppp b / x - pack / qa / rolling - upgrade / src / test / resources / rest - api - spec / test / mixed_cluster / 30_ml_jobs_crud . yml <nl>
<nl> " get cluster stats returns analysis stats " : <nl>  <nl> - skip : <nl> - version : " - num . 99 . 99 " # <nl> + version : " - num . 6 . 99 " <nl> reason : " analysis stats are added for v7 . 7 . 0 " <nl>  <nl> - do : <nl> mmm a / rest - api - spec / src / main / resources / rest - api - spec / test / cluster . stats / 10_basic . yml <nl> ppp b / rest - api - spec / src / main / resources / rest - api - spec / test / cluster . stats / 10_basic . yml <nl>
<nl> " get cluster stats returns mapping stats " : <nl>  <nl> - skip : <nl> - version : " - num . 99 . 99 " # <nl> + version : " - num . 6 . 99 " <nl> reason : " mapping stats are added for v7 . 7 . 0 " <nl>  <nl> - do : <nl> mmm a / server / src / main / java / org / elasticsearch / action / admin / cluster / stats / clusterstatsresponse . java <nl> ppp b / server / src / main / java / org / elasticsearch / action / admin / cluster / stats / clusterstatsresponse . java <nl>
public class clusterstatsresponse extends basenodesresponse < clusterstatsnoderesp <nl> string clusteruuid = null ; <nl> mappingstats mappingstats = null ; <nl> analysisstats analysisstats = null ; <nl> - if ( in . getversion ( ) . onorafter ( version . v_8_0_0 ) ) { <nl> + if ( in . getversion ( ) . onorafter ( version . v_7_7_0 ) ) { <nl> clusteruuid = in . readoptionalstring ( ) ; <nl> mappingstats = in . readoptionalwriteable ( mappingstats : : new ) ; <nl> analysisstats = in . readoptionalwriteable ( analysisstats : : new ) ; <nl>
<nl> { <nl> " security . delete_privileges " : { <nl> " documentation " : { <nl> - " url " : " <nl> + " url " : " https : / / www . elastic . co / guide / en / elasticsearch / reference / current / security - api - delete - privilege . html " <nl> } , <nl> " stability " : " stable " , <nl> " url " : { <nl> mmm a / x - pack / plugin / src / test / resources / rest - api - spec / api / security . put_privileges . json <nl> ppp b / x - pack / plugin / src / test / resources / rest - api - spec / api / security . put_privileges . json <nl>
<nl> { <nl> " security . put_privileges " : { <nl> " documentation " : { <nl> - " url " : " <nl> + " url " : " https : / / www . elastic . co / guide / en / elasticsearch / reference / current / security - api - put - privileges . html " <nl> } , <nl> " stability " : " stable " , <nl> " url " : {
<nl> mmm <nl> setup : <nl> - skip : <nl> - version : " - num . 99 . 99 " # <nl> - reason : " not backported yet " <nl> + version : " - num . 6 . 99 " <nl> + reason : " start of the week monday was enabled in a backport to num . 7 pr # 50916 " <nl>  <nl> - do : <nl> indices . create :
bwcversions . forpreviousunreleased { bwcversions . unreleasedversioninfo unreleased <nl> spooloutput = true <nl> workingdir = checkoutdir <nl> dofirst { <nl> - <nl> - / / workaround for https : / / github . com / gradle / gradle / issues / 11426 <nl> - if ( gradleversion . version ( file ( " $ { checkoutdir } / buildsrc / src / main / resources / minimumgradleversion " ) . text ) ! = gradleversion . current ( ) ) { <nl> - environment = environment . findall { key , val - > key ! = ' openshift_ip ' } <nl> - } <nl> - <nl> / / execution time so that the checkouts are available <nl> list < string > lines = file ( " $ { checkoutdir } / . ci / java - versions . properties " ) . readlines ( ) <nl> environment ( <nl> binary files a / gradle / wrapper / gradle - wrapper . jar and b / gradle / wrapper / gradle - wrapper . jar differ <nl> mmm a / gradle / wrapper / gradle - wrapper . properties <nl> ppp b / gradle / wrapper / gradle - wrapper . properties <nl>
setup : <nl> mmm <nl> " test prefix " : <nl> - skip : <nl> - version : " - num . 0 . 0 " <nl> - reason : " <nl> + version : " - num . 2 . 99 " <nl> + reason : " implemented in num . 3 " <nl> - do : <nl> search : <nl> index : test <nl>
setup : <nl> mmm <nl> " test wildcard " : <nl> - skip : <nl> - version : " - num . 0 . 0 " <nl> - reason : " <nl> + version : " - num . 2 . 99 " <nl> + reason : " implemented in num . 3 " <nl> - do : <nl> search : <nl> index : test <nl>
setup : <nl> mmm <nl> " test fuzzy match " : <nl> - skip : <nl> - version : " - num . 0 . 0 " <nl> - reason : " <nl> + version : " - num . 5 . 99 " <nl> + reason : " implemented in num . 6 " <nl> - do : <nl> search : <nl> index : test <nl>
<nl> { <nl> " ml . delete_trained_model " : { <nl> " documentation " : { <nl> - " url " : " <nl> + " url " : " https : / / www . elastic . co / guide / en / elasticsearch / reference / current / delete - inference . html " <nl> } , <nl> " stability " : " experimental " , <nl> " url " : { <nl> mmm a / x - pack / plugin / src / test / resources / rest - api - spec / api / ml . get_trained_models . json <nl> ppp b / x - pack / plugin / src / test / resources / rest - api - spec / api / ml . get_trained_models . json <nl>
<nl> { <nl> " ml . get_trained_models " : { <nl> " documentation " : { <nl> - " url " : " <nl> + " url " : " https : / / www . elastic . co / guide / en / elasticsearch / reference / current / get - inference . html " <nl> } , <nl> " stability " : " experimental " , <nl> " url " : { <nl>
<nl> { <nl> " ml . get_trained_models_stats " : { <nl> " documentation " : { <nl> - " url " : " <nl> + " url " : " https : / / www . elastic . co / guide / en / elasticsearch / reference / current / get - inference - stats . html " <nl> } , <nl> " stability " : " experimental " , <nl> " url " : {
public final class machinelearningclient { <nl> * gets trained model configs <nl> * < p > <nl> * for additional info <nl> - * see < a href = " <nl> + * see < a href = " https : / / www . elastic . co / guide / en / elasticsearch / reference / current / get - inference . html " > <nl> * get trained model configs documentation < / a > <nl> * <nl> * @ param request the { @ link gettrainedmodelsrequest } <nl>
public final class machinelearningclient { <nl> * gets trained model configs asynchronously and notifies listener upon completion <nl> * < p > <nl> * for additional info <nl> - * see < a href = " <nl> + * see < a href = " https : / / www . elastic . co / guide / en / elasticsearch / reference / current / get - inference . html " > <nl> * get trained model configs documentation < / a > <nl> * <nl> * @ param request the { @ link gettrainedmodelsrequest } <nl>
public final class machinelearningclient { <nl> * gets trained model stats <nl> * < p > <nl> * for additional info <nl> - * see < a href = " <nl> + * see < a href = " https : / / www . elastic . co / guide / en / elasticsearch / reference / current / get - inference - stats . html " > <nl> * get trained model stats documentation < / a > <nl> * <nl> * @ param request the { @ link gettrainedmodelsstatsrequest } <nl>
public final class machinelearningclient { <nl> * gets trained model stats asynchronously and notifies listener upon completion <nl> * < p > <nl> * for additional info <nl> - * see < a href = " <nl> + * see < a href = " https : / / www . elastic . co / guide / en / elasticsearch / reference / current / get - inference - stats . html " > <nl> * get trained model stats documentation < / a > <nl> * <nl> * @ param request the { @ link gettrainedmodelsstatsrequest } <nl>
public final class machinelearningclient { <nl> * deletes the given trained model <nl> * < p > <nl> * for additional info <nl> - * see < a href = " <nl> + * see < a href = " https : / / www . elastic . co / guide / en / elasticsearch / reference / current / delete - inference . html " > <nl> * delete trained model documentation < / a > <nl> * <nl> * @ param request the { @ link deletetrainedmodelrequest } <nl>
public final class machinelearningclient { <nl> * deletes the given trained model asynchronously and notifies listener upon completion <nl> * < p > <nl> * for additional info <nl> - * see < a href = " <nl> + * see < a href = " https : / / www . elastic . co / guide / en / elasticsearch / reference / current / delete - inference . html " > <nl> * delete trained model documentation < / a > <nl> * <nl> * @ param request the { @ link deletetrainedmodelrequest }
import org . elasticsearch . common . io . stream . streamoutput ; <nl> import java . io . ioexception ; <nl>  <nl> public class tcpheader { <nl> - <nl> - <nl> - public static final version version_with_header_size = version . v_8_0_0 ; <nl> + <nl> + public static final version version_with_header_size = version . v_7_6_0 ; <nl>  <nl> public static final int marker_bytes_size = num ; <nl>  <nl> mmm a / test / framework / src / main / java / org / elasticsearch / transport / abstractsimpletransporttestcase . java <nl> ppp b / test / framework / src / main / java / org / elasticsearch / transport / abstractsimpletransporttestcase . java <nl>
class precommittasks { <nl> dofirst { <nl> / / we need to defer this configuration since we don ' t know the runtime java version until execution time <nl> targetcompatibility = buildparams . runtimejavaversion . majorversion <nl> - / * <nl> - <nl> if ( buildparams . runtimejavaversion > javaversion . version_13 ) { <nl> - project . logger . info ( <nl> - " forbidden apis does not support java version past num . will use the signatures from num for " , <nl> - buildparams . runtimejavaversion ` <nl> + project . logger . warn ( <nl> + " forbidden apis does not support java versions past num . will use the signatures from num for { } . " , <nl> + buildparams . runtimejavaversion <nl> ) <nl> - targetcompatibility = javaversion . version_13 . getmajorversion ( ) <nl> + targetcompatibility = javaversion . version_13 . majorversion <nl> } <nl> - * / <nl> } <nl> bundledsignatures = [ <nl> " jdk - unsafe " , " jdk - deprecated " , " jdk - non - portable " , " jdk - system - out "
public class nodesubclasstests < t extends b , b extends node < b > > extends estestcas <nl> * test { @ link node # replacechildren } implementation on { @ link # subclass } . <nl> * / <nl> public void testreplacechildren ( ) throws exception { <nl> - <nl> - assume . assumefalse ( subclass . equals ( pivot . class ) ) ; <nl> - <nl> constructor < t > ctor = longestctor ( subclass ) ; <nl> object [ ] nodectorargs = ctorargs ( ctor ) ; <nl> t node = ctor . newinstance ( nodectorargs ) ;
public class commonanalysisplugin extends plugin implements analysisplugin , scri <nl> public map < string , analysisprovider < analyzerprovider < ? extends analyzer > > > getanalyzers ( ) { <nl> map < string , analysisprovider < analyzerprovider < ? extends analyzer > > > analyzers = new treemap < > ( ) ; <nl> analyzers . put ( " fingerprint " , fingerprintanalyzerprovider : : new ) ; <nl> - <nl> - <nl> analyzers . put ( " pattern " , patternanalyzerprovider : : new ) ; <nl> analyzers . put ( " snowball " , snowballanalyzerprovider : : new ) ;
<nl> fail : true <nl> - ansicolor <nl> - timestamps <nl> - # <nl> - # - gradle - build - scan <nl> + - gradle - build - scan <nl> properties : <nl> - github : <nl> url : https : / / github . com / elastic / elasticsearch / <nl>
curl - - user rdeniro : taxidriver - xput ' localhost : 9200 / idx ' <nl> - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - <nl>  <nl> [ float ] <nl> - = = = = client libraries over http <nl> + = = = = client libraries over http <nl>  <nl> for more information about using { security - features } with the language <nl> - specific clients , refer to <nl> - https : / / github . com / elasticsearch / elasticsearch - ruby / tree / master / elasticsearch - transport # authentication [ ruby ] , <nl> - http : / / elasticsearch - py . readthedocs . org / en / master / # ssl - and - authentication [ python ] , <nl> - https : / / metacpan . org / pod / search : : elasticsearch : : cxn : : httptiny # configuration [ perl ] , <nl> - http : / / www . elastic . co / guide / en / elasticsearch / client / php - api / current / security . html [ php ] , <nl> - http : / / nest . azurewebsites . net / elasticsearch - net / security . html [ . net ] , <nl> - http : / / www . elastic . co / guide / en / elasticsearch / client / javascript - api / current / auth - reference . html [ javascript ] <nl> - <nl> - / / / / <nl> - groovy - <nl> - / / / / <nl> + specific clients , refer to : <nl> + <nl> + * { java - rest } / _basic_authentication . html [ java ] <nl> + * { jsclient - current } / auth - reference . html [ javascript ] <nl> + * https : / / www . elastic . co / guide / en / elasticsearch / client / net - api / master / configuration - options . html [ . net ] <nl> + * https : / / metacpan . org / pod / search : : elasticsearch : : cxn : : httptiny # configuration [ perl ] <nl> + * http : / / www . elastic . co / guide / en / elasticsearch / client / php - api / master / security . html [ php ] <nl> + * https : / / elasticsearch - py . readthedocs . io / en / master / # ssl - and - authentication [ python ] <nl> + * https : / / github . com / elasticsearch / elasticsearch - ruby / tree / master / elasticsearch - transport # authentication [ ruby ] <nl> \ no newline at end of file
public class geopolygonquerybuildertests extends abstractquerytestcase < geopolygo <nl>  <nl> private void assertgeopolygonquery ( string query ) throws ioexception { <nl> queryshardcontext context = createshardcontext ( ) ; <nl> - parsequery ( query ) . toquery ( context ) ; <nl> - <nl> - / / since some points can be computed from the geohash <nl> + geopolygonquerybuilder querybuilder = ( geopolygonquerybuilder ) parsequery ( query ) ; <nl> + doassertlucenequery ( querybuilder , querybuilder . toquery ( context ) , context ) ; <nl> } <nl>  <nl> public void testfromjson ( ) throws ioexception {
processtestresources { <nl> } <nl>  <nl> subprojects { project platformproject - > <nl> - <nl> - <nl> - boolean allboxes = ( project . findproperty ( ' vagrant . boxes ' ) ? : ' ' ) = = ' all ' <nl> - if ( allboxes | | [ ' centos - 7 ' , ' ubuntu - 1604 ' ] . contains ( platformproject . name ) ) { <nl> - tasks . register ( ' packagingtest ' ) { <nl> - dependson ' distrotest ' , ' batstest . oss ' , ' batstest . default ' <nl> - } <nl> + tasks . register ( ' packagingtest ' ) { <nl> + dependson ' distrotest ' , ' batstest . oss ' , ' batstest . default ' <nl> } <nl>  <nl> vagrant {
class buildplugin implements plugin < project > { <nl> ' tests . security . manager ' : ' true ' , <nl> ' jna . nosys ' : ' true ' <nl>  <nl> - <nl> - test . systemproperty ( ' java . locale . providers ' , ' spi , compat ' ) <nl>  <nl> / / ignore changing test seed when build is passed - dignore . tests . seed for cacheability experimentation <nl> if ( system . getproperty ( ' ignore . tests . seed ' ) ! = null ) { <nl> mmm a / buildsrc / src / main / groovy / org / elasticsearch / gradle / test / restintegtesttask . groovy <nl> ppp b / buildsrc / src / main / groovy / org / elasticsearch / gradle / test / restintegtesttask . groovy <nl>
public final class enrichstore { <nl> if ( name . tolowercase ( locale . root ) . equals ( name ) = = false ) { <nl> throw new illegalargumentexception ( " invalid policy name [ " + name + " ] , must be lowercase " ) ; <nl> } <nl> - <nl> + set < string > supportedpolicytypes = set . of ( enrichpolicy . supported_policy_types ) ; <nl> + if ( supportedpolicytypes . contains ( policy . gettype ( ) ) = = false ) { <nl> + throw new illegalargumentexception ( " unsupported policy type [ " + policy . gettype ( ) + <nl> + " ] , supported types are " + arrays . tostring ( enrichpolicy . supported_policy_types ) ) ; <nl> + } <nl>  <nl> final enrichpolicy finalpolicy ; <nl> if ( policy . getelasticsearchversion ( ) = = null ) { <nl> mmm a / x - pack / plugin / enrich / src / test / java / org / elasticsearch / xpack / enrich / enrichstorecrudtests . java <nl> ppp b / x - pack / plugin / enrich / src / test / java / org / elasticsearch / xpack / enrich / enrichstorecrudtests . java <nl>
public class datafeedconfig extends abstractdiffable < datafeedconfig > implements <nl> this . chunkingconfig = in . readoptionalwriteable ( chunkingconfig : : new ) ; <nl> this . headers = collections . unmodifiablemap ( in . readmap ( streaminput : : readstring , streaminput : : readstring ) ) ; <nl> delayeddatacheckconfig = in . readoptionalwriteable ( delayeddatacheckconfig : : new ) ; <nl> - <nl> - if ( in . getversion ( ) . onorafter ( version . v_8_0_0 ) ) { <nl> + if ( in . getversion ( ) . onorafter ( version . v_7_5_0 ) ) { <nl> maxemptysearches = in . readoptionalvint ( ) ; <nl> } else { <nl> maxemptysearches = null ; <nl>
public class datafeedconfig extends abstractdiffable < datafeedconfig > implements <nl> out . writeoptionalwriteable ( chunkingconfig ) ; <nl> out . writemap ( headers , streamoutput : : writestring , streamoutput : : writestring ) ; <nl> out . writeoptionalwriteable ( delayeddatacheckconfig ) ; <nl> - <nl> - if ( out . getversion ( ) . onorafter ( version . v_8_0_0 ) ) { <nl> + if ( out . getversion ( ) . onorafter ( version . v_7_5_0 ) ) { <nl> out . writeoptionalvint ( maxemptysearches ) ; <nl> } <nl> } <nl> mmm a / x - pack / plugin / core / src / main / java / org / elasticsearch / xpack / core / ml / datafeed / datafeedupdate . java <nl> ppp b / x - pack / plugin / core / src / main / java / org / elasticsearch / xpack / core / ml / datafeed / datafeedupdate . java <nl>
public class datafeedupdate implements writeable , toxcontentobject { <nl> this . scrollsize = in . readoptionalvint ( ) ; <nl> this . chunkingconfig = in . readoptionalwriteable ( chunkingconfig : : new ) ; <nl> delayeddatacheckconfig = in . readoptionalwriteable ( delayeddatacheckconfig : : new ) ; <nl> - <nl> - if ( in . getversion ( ) . onorafter ( version . v_8_0_0 ) ) { <nl> + if ( in . getversion ( ) . onorafter ( version . v_7_5_0 ) ) { <nl> maxemptysearches = in . readoptionalint ( ) ; <nl> } else { <nl> maxemptysearches = null ; <nl>
public class datafeedupdate implements writeable , toxcontentobject { <nl> out . writeoptionalvint ( scrollsize ) ; <nl> out . writeoptionalwriteable ( chunkingconfig ) ; <nl> out . writeoptionalwriteable ( delayeddatacheckconfig ) ; <nl> - <nl> - if ( out . getversion ( ) . onorafter ( version . v_8_0_0 ) ) { <nl> + if ( out . getversion ( ) . onorafter ( version . v_7_5_0 ) ) { <nl> out . writeoptionalint ( maxemptysearches ) ; <nl> } <nl> }
public final class geoshapeindexer implements abstractgeometryfieldmapper . indexe <nl>  <nl> @ override <nl> public geometry visit ( point point ) { <nl> - <nl> - return new point ( point . getx ( ) , point . gety ( ) ) ; <nl> + double [ ] latlon = new double [ ] { point . getx ( ) , point . gety ( ) } ; <nl> + normalizepoint ( latlon ) ; <nl> + return new point ( latlon [ 0 ] , latlon [ 1 ] ) ; <nl> } <nl>  <nl> @ override <nl> mmm a / server / src / test / java / org / elasticsearch / common / geo / geometryindexertests . java <nl> ppp b / server / src / test / java / org / elasticsearch / common / geo / geometryindexertests . java <nl>
final class spawner implements closeable { <nl> list < path > paths = pluginsservice . findplugindirs ( environment . modulesfile ( ) ) ; <nl> for ( final path modules : paths ) { <nl> final plugininfo info = plugininfo . readfromproperties ( modules ) ; <nl> - path spawnpath = platforms . nativecontrollerpath ( modules ) ; <nl> + final path spawnpath = platforms . nativecontrollerpath ( modules ) ; <nl> if ( ! files . isregularfile ( spawnpath ) ) { <nl> - <nl> - spawnpath = platforms . fallbacknativecontrollerpath ( modules ) ; <nl> - if ( spawnpath = = null | | files . isregularfile ( spawnpath ) = = false ) { <nl> - continue ; <nl> - } <nl> + continue ; <nl> } <nl> if ( ! info . hasnativecontroller ( ) ) { <nl> final string message = string . format ( <nl> mmm a / server / src / main / java / org / elasticsearch / plugins / platforms . java <nl> ppp b / server / src / main / java / org / elasticsearch / plugins / platforms . java <nl>
public class platforms { <nl> . resolve ( program_name ) ; <nl> } <nl>  <nl> - / * * <nl> - * the fallback path to the native controller for a plugin with native <nl> - * components to be used if no program is found using the standard path . <nl> - * this is a temporary measure to allow developers not working on this <nl> - * functionality to continue to work with c + + bundles from before or <nl> - * after the change . this code should never be in a supported release . <nl> - * <nl> - * / <nl> - public static path fallbacknativecontrollerpath ( path plugin ) { <nl> - if ( constants . mac_os_x ) { <nl> - return plugin <nl> - . resolve ( " platform " ) <nl> - . resolve ( platform_name ) <nl> - . resolve ( " bin " ) <nl> - . resolve ( program_name ) ; <nl> - } <nl> - return null ; <nl> - } <nl> - <nl> / * * <nl> * return the platform name based on the os name and architecture , for example : <nl> * - darwin - x86_64
public class restindicesaction extends abstractcataction { <nl>  <nl> @ override <nl> public void onfailure ( final exception e ) { <nl> - / / temporary logging to help debug https : / / github . com / elastic / elasticsearch / issues / 45652 <nl> - <nl> - if ( e instanceof indexnotfoundexception ) { <nl> - logger . debug ( " _cat / indices returning index_not_found_exception " , e ) ; <nl> - } <nl> listener . onfailure ( e ) ; <nl> } <nl> } ) ; <nl> mmm a / x - pack / plugin / ml / qa / native - multi - node - tests / build . gradle <nl> ppp b / x - pack / plugin / ml / qa / native - multi - node - tests / build . gradle <nl>
testclusters . integtest { <nl> setting ' xpack . security . audit . enabled ' , ' false ' <nl> setting ' xpack . license . self_generated . type ' , ' trial ' <nl> setting ' xpack . ml . min_disk_space_off_heap ' , ' 200mb ' <nl> - <nl> - setting ' logger . org . elasticsearch . rest . action . cat ' , ' debug ' <nl>  <nl> keystore ' bootstrap . password ' , ' x - pack - test - password ' <nl> keystore ' xpack . security . transport . ssl . secure_key_passphrase ' , ' testnode '
public class restindicesaction extends abstractcataction { <nl>  <nl> @ override <nl> public void onfailure ( final exception e ) { <nl> - / / temporary logging to help debug https : / / github . com / elastic / elasticsearch / issues / 45652 <nl> - <nl> - if ( e instanceof indexnotfoundexception ) { <nl> - logger . debug ( " _cat / indices returning index_not_found_exception " , e ) ; <nl> - } <nl> listener . onfailure ( e ) ; <nl> } <nl> } , size ) ;
public class elasticsearchnode implements testclusterconfiguration { <nl> / / don ' t wait for state , just start up quickly . this will also allow new and old nodes in the bwc case to become the master <nl> defaultconfig . put ( " discovery . initial_state_timeout " , " 0s " ) ; <nl>  <nl> - <nl> - defaultconfig . put ( " logger . org . elasticsearch . action . support . master . transportmasternodeaction " , " trace " ) ; <nl> - defaultconfig . put ( " logger . org . elasticsearch . cluster . metadata . metadatacreateindexservice " , " trace " ) ; <nl> - defaultconfig . put ( " logger . org . elasticsearch . cluster . service " , " debug " ) ; <nl> - defaultconfig . put ( " logger . org . elasticsearch . cluster . coordination " , " debug " ) ; <nl> - defaultconfig . put ( " logger . org . elasticsearch . gateway . metastateservice " , " trace " ) ; <nl> if ( getversion ( ) . getmajor ( ) > = num ) { <nl> defaultconfig . put ( " cluster . service . slow_task_logging_threshold " , " 5s " ) ; <nl> defaultconfig . put ( " cluster . service . slow_master_task_logging_threshold " , " 5s " ) ;
import static org . elasticsearch . index . query . abstractquerybuilder . parseinnerquery <nl> / * * <nl> * aggregation for adjacency matrices . <nl> * <nl> - * <nl> - * computation it uses a non - sparse structure ( an array of bits <nl> - * objects ) . this could be changed to a sparse structure in future . <nl> - * <nl> * / <nl> public class adjacencymatrixaggregator extends bucketsaggregator { <nl>  <nl>
public final class simulatedocumentbaseresult implements simulatedocumentresult <nl> * read from a stream . <nl> * / <nl> public simulatedocumentbaseresult ( streaminput in ) throws ioexception { <nl> - <nl> - if ( in . getversion ( ) . onorafter ( version . v_8_0_0 ) ) { <nl> + if ( in . getversion ( ) . onorafter ( version . v_7_4_0 ) ) { <nl> failure = in . readexception ( ) ; <nl> ingestdocument = in . readoptionalwriteable ( writeableingestdocument : : new ) ; <nl> } else { <nl>
public final class simulatedocumentbaseresult implements simulatedocumentresult <nl>  <nl> @ override <nl> public void writeto ( streamoutput out ) throws ioexception { <nl> - <nl> - if ( out . getversion ( ) . onorafter ( version . v_8_0_0 ) ) { <nl> + if ( out . getversion ( ) . onorafter ( version . v_7_4_0 ) ) { <nl> out . writeexception ( failure ) ; <nl> out . writeoptionalwriteable ( ingestdocument ) ; <nl> } else {
public class movfnpipelineaggregationbuilder extends abstractpipelineaggregation <nl> format = in . readoptionalstring ( ) ; <nl> gappolicy = gappolicy . readfrom ( in ) ; <nl> window = in . readint ( ) ; <nl> - if ( in . getversion ( ) . onorafter ( version . v_8_0_0 ) ) { <nl> + if ( in . getversion ( ) . onorafter ( version . v_7_4_0 ) ) { <nl> shift = in . readint ( ) ; <nl> } else { <nl> shift = num ; <nl>
public class movfnpipelineaggregationbuilder extends abstractpipelineaggregation <nl> out . writeoptionalstring ( format ) ; <nl> gappolicy . writeto ( out ) ; <nl> out . writeint ( window ) ; <nl> - if ( out . getversion ( ) . onorafter ( version . v_8_0_0 ) ) { <nl> + if ( out . getversion ( ) . onorafter ( version . v_7_4_0 ) ) { <nl> out . writeint ( shift ) ; <nl> } <nl> } <nl> mmm a / server / src / main / java / org / elasticsearch / search / aggregations / pipeline / movfnpipelineaggregator . java <nl> ppp b / server / src / main / java / org / elasticsearch / search / aggregations / pipeline / movfnpipelineaggregator . java <nl>
public class movfnpipelineaggregator extends pipelineaggregator { <nl> gappolicy = buckethelpers . gappolicy . readfrom ( in ) ; <nl> bucketspath = in . readstring ( ) ; <nl> window = in . readint ( ) ; <nl> - if ( in . getversion ( ) . onorafter ( version . v_8_0_0 ) ) { <nl> + if ( in . getversion ( ) . onorafter ( version . v_7_4_0 ) ) { <nl> shift = in . readint ( ) ; <nl> } else { <nl> shift = num ; <nl>
public class movfnpipelineaggregator extends pipelineaggregator { <nl> gappolicy . writeto ( out ) ; <nl> out . writestring ( bucketspath ) ; <nl> out . writeint ( window ) ; <nl> - if ( out . getversion ( ) . onorafter ( version . v_8_0_0 ) ) { <nl> + if ( out . getversion ( ) . onorafter ( version . v_7_4_0 ) ) { <nl> out . writeint ( shift ) ; <nl> } <nl> }
public class timingstats implements toxcontentobject , writeable { <nl> this . maxbucketprocessingtimems = in . readoptionaldouble ( ) ; <nl> this . avgbucketprocessingtimems = in . readoptionaldouble ( ) ; <nl> this . exponentialavgbucketprocessingtimems = in . readoptionaldouble ( ) ; <nl> - if ( in . getversion ( ) . onorafter ( version . current ) ) { <nl> + if ( in . getversion ( ) . onorafter ( version . v_7_4_0 ) ) { <nl> this . exponentialavgcalculationcontext = in . readoptionalwriteable ( exponentialaveragecalculationcontext : : new ) ; <nl> } else { <nl> this . exponentialavgcalculationcontext = new exponentialaveragecalculationcontext ( ) ; <nl>
public class timingstats implements toxcontentobject , writeable { <nl> out . writeoptionaldouble ( maxbucketprocessingtimems ) ; <nl> out . writeoptionaldouble ( avgbucketprocessingtimems ) ; <nl> out . writeoptionaldouble ( exponentialavgbucketprocessingtimems ) ; <nl> - if ( out . getversion ( ) . onorafter ( version . current ) ) { <nl> + if ( out . getversion ( ) . onorafter ( version . v_7_4_0 ) ) { <nl> out . writeoptionalwriteable ( exponentialavgcalculationcontext ) ; <nl> } <nl> }
public class settingsmodule implements module { <nl> } <nl> this . indexscopedsettings = new indexscopedsettings ( settings , new hashset < > ( this . indexsettings . values ( ) ) ) ; <nl> this . clustersettings = new clustersettings ( settings , new hashset < > ( this . nodesettings . values ( ) ) , clustersettingupgraders ) ; <nl> - settings indexsettings = settings . filter ( ( s ) - > ( s . startswith ( " index . " ) & & <nl> - / / special case - we want to get did you mean indices . query . bool . max_clause_count <nl> - / / which means we need to by - pass this check for this setting <nl> - <nl> - " index . query . bool . max_clause_count " . equals ( s ) = = false ) <nl> - & & clustersettings . get ( s ) = = null ) ; <nl> + settings indexsettings = settings . filter ( ( s ) - > s . startswith ( " index . " ) & & clustersettings . get ( s ) = = null ) ; <nl> if ( indexsettings . isempty ( ) = = false ) { <nl> try { <nl> string separator = intstream . range ( 0 , num ) . maptoobj ( s - > " * " ) . collect ( collectors . joining ( " " ) ) . trim ( ) ; <nl> mmm a / server / src / test / java / org / elasticsearch / common / settings / settingsmoduletests . java <nl> ppp b / server / src / test / java / org / elasticsearch / common / settings / settingsmoduletests . java <nl>
public class internalautodatehistogramtests extends internalmultibucketaggregati <nl> assertthat ( result , equalto ( 2 ) ) ; <nl> } <nl>  <nl> - <nl> - @ override <nl> - @ awaitsfix ( bugurl = " https : / / github . com / elastic / elasticsearch / issues / 39497 " ) <nl> - <nl> + <nl> public void testreducerandom ( ) { <nl> super . testreducerandom ( ) ; <nl> }
public class snapshotlifecyclemetadata implements xpackmetadatacustom { <nl>  <nl> @ override <nl> public version getminimalsupportedversion ( ) { <nl> - return version . v_8_0_0 ; <nl> + return version . v_7_4_0 ; <nl> } <nl>  <nl> @ override
public class securitycontext { <nl> try { <nl> return authentication . readfromcontext ( threadcontext ) ; <nl> } catch ( ioexception e ) { <nl> - <nl> - / / auth header , which should be be audited ? <nl> logger . error ( " failed to read authentication " , e ) ; <nl> - return null ; <nl> + throw new uncheckedioexception ( e ) ; <nl> } <nl> } <nl>  <nl> mmm a / x - pack / plugin / security / src / test / java / org / elasticsearch / xpack / security / securitycontexttests . java <nl> ppp b / x - pack / plugin / security / src / test / java / org / elasticsearch / xpack / security / securitycontexttests . java <nl>
public abstract class blobstorerepository extends abstractlifecyclecomponent imp <nl> lastsnapshotstatus . getindexversion ( ) , <nl> indexcommitpointfiles , <nl> lastsnapshotstatus . getstarttime ( ) , <nl> - / / snapshotstatus . starttime ( ) is assigned on the same machine , <nl> - / / so it ' s safe to use the relative time in millis <nl> threadpool . absolutetimeinmillis ( ) - lastsnapshotstatus . getstarttime ( ) , <nl> lastsnapshotstatus . getincrementalfilecount ( ) , <nl> lastsnapshotstatus . getincrementalsize ( ) <nl> ) ; <nl>  <nl> - <nl> logger . trace ( " [ { } ] [ { } ] writing shard snapshot file " , shardid , snapshotid ) ; <nl> try { <nl> indexshardsnapshotformat . write ( snapshot , shardcontainer , snapshotid . getuuid ( ) ) ;
<nl> setup : <nl> - skip : <nl> features : headers <nl> - version : " - num . 99 . 99 " # <nl> - reason : " dense_vector dims parameter was added from num . 0 " <nl> + version : " - num . 2 . 99 " <nl> + reason : " dense_vector functions were added from num . 3 " <nl>  <nl> - do : <nl> indices . create : <nl> mmm a / x - pack / plugin / src / test / resources / rest - api - spec / test / vectors / 20_dense_vector_special_cases . yml <nl> ppp b / x - pack / plugin / src / test / resources / rest - api - spec / test / vectors / 20_dense_vector_special_cases . yml <nl>
<nl> setup : <nl> - skip : <nl> features : headers <nl> - version : " - num . 99 . 99 " # <nl> - reason : " dense_vector dims parameter was added from num . 0 " <nl> + version : " - num . 2 . 99 " <nl> + reason : " dense_vector functions were added from num . 3 " <nl>  <nl> - do : <nl> indices . create :
public class textfieldmapper extends fieldmapper { <nl> * even if it is different from the expected one ( in case the field is nested under an object <nl> * or a multi - field ) . this way search will continue to work on old indices and new indices <nl> * will use the expected full name . <nl> - * <nl> - * <nl> * * / <nl> - string fullname = context . indexcreatedversion ( ) . before ( version . v_8_0_0 ) ? name ( ) : buildfullname ( context ) ; <nl> + string fullname = context . indexcreatedversion ( ) . before ( version . v_7_2_1 ) ? name ( ) : buildfullname ( context ) ; <nl> prefixfieldtype prefixfieldtype = <nl> new prefixfieldtype ( fullname , fullname + " . _index_prefix " , minprefixchars , maxprefixchars ) ; <nl> fieldtype ( ) . setprefixfieldtype ( prefixfieldtype ) ;
<nl> setup : <nl> - skip : <nl> - version : " - num . 0 . 0 " # <nl> + version : " - num . 2 . 99 " <nl> reason : rareterms added in num . 3 . 0 <nl> - do : <nl> indices . create : <nl> mmm a / server / src / main / java / org / elasticsearch / common / util / setbackedscalingcuckoofilter . java <nl> ppp b / server / src / main / java / org / elasticsearch / common / util / setbackedscalingcuckoofilter . java <nl>
public class startdataframeanalyticsaction extends actiontype < acknowledgedrespon <nl>  <nl> public static class taskparams implements xpackplugin . xpackpersistenttaskparams { <nl>  <nl> - <nl> - public static final version version_introduced = version . v_7_1_0 ; <nl> + public static final version version_introduced = version . v_7_3_0 ; <nl>  <nl> public static constructingobjectparser < taskparams , void > parser = new constructingobjectparser < > ( <nl> mltasks . data_frame_analytics_task_name , true , a - > new taskparams ( ( string ) a [ 0 ] ) ) ;
public class replicationtracker extends abstractindexshardcomponent implements l <nl> public synchronized void activatewithprimarycontext ( primarycontext primarycontext ) { <nl> assert invariant ( ) ; <nl> assert primarymode = = false ; <nl> - <nl> - if ( primarycontext . checkpoints . containskey ( shardallocationid ) = = false ) { <nl> - / / can happen if the old primary was on an old version <nl> - assert indexsettings . getindexversioncreated ( ) . before ( version . v_8_0_0 ) ; <nl> - throw new illegalstateexception ( " primary context [ " + primarycontext + " ] does not contain " + shardallocationid ) ; <nl> - } <nl> final runnable runafter = getmasterupdateoperationfromcurrentstate ( ) ; <nl> primarymode = true ; <nl> / / capture current state to possibly replay missed cluster state update
public class internalengine extends engine { <nl> } <nl> localcheckpointtracker . markseqnoasprocessed ( noopresult . getseqno ( ) ) ; <nl> if ( noopresult . gettransloglocation ( ) = = null ) { <nl> - / / the op is coming from the translog ( and is hence persisted already ) or it does not have a sequence number , or we failed <nl> - / / to add a tombstone doc to lucene with a non - fatal error , which would be very surprising <nl> - <nl> - assert noop . origin ( ) . isfromtranslog ( ) | | noopresult . getseqno ( ) = = sequencenumbers . unassigned_seq_no | | failure ! = null ; <nl> + / / the op is coming from the translog ( and is hence persisted already ) or it does not have a sequence number <nl> + assert noop . origin ( ) . isfromtranslog ( ) | | noopresult . getseqno ( ) = = sequencenumbers . unassigned_seq_no ; <nl> localcheckpointtracker . markseqnoaspersisted ( noopresult . getseqno ( ) ) ; <nl> } <nl> noopresult . settook ( system . nanotime ( ) - noop . starttime ( ) ) ;
public class autodatehistogramaggregationbuilder <nl> public autodatehistogramaggregationbuilder ( streaminput in ) throws ioexception { <nl> super ( in , valuessourcetype . numeric , valuetype . date ) ; <nl> numbuckets = in . readvint ( ) ; <nl> - <nl> - if ( in . getversion ( ) . onorafter ( version . v_8_0_0 ) ) { <nl> + if ( in . getversion ( ) . onorafter ( version . v_7_3_0 ) ) { <nl> minimumintervalexpression = in . readoptionalstring ( ) ; <nl> } <nl> }
public final class snapshotinfo implements comparable < snapshotinfo > , toxcontent , <nl>  <nl> public static final string context_mode_param = " context_mode " ; <nl> public static final string context_mode_snapshot = " snapshot " ; <nl> - public static final version metadata_field_introduced = version . v_8_0_0 ; <nl> + public static final version metadata_field_introduced = version . v_7_3_0 ; <nl> private static final dateformatter date_time_formatter = dateformatter . forpattern ( " strictdateoptionaltime " ) ; <nl> private static final string snapshot = " snapshot " ; <nl> private static final string uuid = " uuid " ;
public class enrichit extends esresttestcase { <nl> } <nl> } <nl>  <nl> - <nl> public void testbasicflow ( ) throws exception { <nl> / / create the policy : <nl> request putpolicyrequest = new request ( " put " , " / _enrich / policy / my_policy " ) ; <nl> - putpolicyrequest . setjsonentity ( " { \ " type \ " : \ " exact_match \ " , \ " indices \ " : [ \ " my - index * \ " ] , \ " enrich_key \ " : \ " host \ " , " + <nl> + putpolicyrequest . setjsonentity ( " { \ " type \ " : \ " exact_match \ " , \ " indices \ " : [ \ " my - source - index \ " ] , \ " enrich_key \ " : \ " host \ " , " + <nl> " \ " enrich_values \ " : [ \ " globalrank \ " , \ " tldrank \ " , \ " tld \ " ] } " ) ; <nl> assertok ( client ( ) . performrequest ( putpolicyrequest ) ) ; <nl>  <nl> - / / create <nl> - string mapping = " \ " _meta \ " : { \ " enrich_key_field \ " : \ " host \ " } " ; <nl> - createindex ( " . enrich - my_policy " , settings . empty , mapping ) ; <nl> - <nl> - / / add a single enrich document for now and then refresh : <nl> - request indexrequest = new request ( " put " , " / . enrich - my_policy / _doc / elastic . co " ) ; <nl> - xcontentbuilder document = xcontentbuilder . builder ( xcontenttype . smile . xcontent ( ) ) ; <nl> - document . startobject ( ) ; <nl> - document . field ( " host " , " elastic . co " ) ; <nl> - document . field ( " globalrank " , num ) ; <nl> - document . field ( " tldrank " , num ) ; <nl> - document . field ( " tld " , " co " ) ; <nl> - document . endobject ( ) ; <nl> - document . close ( ) ; <nl> - bytearrayoutputstream out = ( bytearrayoutputstream ) document . getoutputstream ( ) ; <nl> - indexrequest . setentity ( new bytearrayentity ( out . tobytearray ( ) , contenttype . create ( " application / smile " ) ) ) ; <nl> + / / add entry to source <nl> + request indexrequest = new request ( " put " , " / my - source - index / _doc / elastic . co " ) ; <nl> + indexrequest . setjsonentity ( " { \ " host \ " : \ " elastic . co \ " , \ " globalrank \ " : num , \ " tldrank \ " : num , \ " tld \ " : \ " co \ " } " ) ; <nl> assertok ( client ( ) . performrequest ( indexrequest ) ) ; <nl> - request refreshrequest = new request ( " post " , " / . enrich - my_policy / _refresh " ) ; <nl> + request refreshrequest = new request ( " post " , " / my - source - index / _refresh " ) ; <nl> assertok ( client ( ) . performrequest ( refreshrequest ) ) ; <nl>  <nl> + / / execute the policy : <nl> + request executepolicyrequest = new request ( " post " , " / _enrich / policy / my_policy / _execute " ) ; <nl> + assertok ( client ( ) . performrequest ( executepolicyrequest ) ) ; <nl> + <nl> / / create pipeline <nl> request putpipelinerequest = new request ( " put " , " / _ingest / pipeline / my_pipeline " ) ; <nl> putpipelinerequest . setjsonentity ( " { \ " processors \ " : [ " + <nl>
public final class resyncreplicationrequest extends replicatedwriterequest < resyn <nl> private final long maxseenautoidtimestamponprimary ; <nl>  <nl> resyncreplicationrequest ( streaminput in ) throws ioexception { <nl> - <nl> - / / assert version . current . major < = num ; <nl> super ( in ) ; <nl> trimaboveseqno = in . readzlong ( ) ; <nl> maxseenautoidtimestamponprimary = in . readzlong ( ) ;
public class rollupdatehistoupgradeit extends abstractupgradetestcase { <nl> version . fromstring ( system . getproperty ( " tests . upgrade_from_version " ) ) ; <nl>  <nl> public void testdatehistointervalupgrade ( ) throws exception { <nl> - assumetrue ( " datehisto interval changed in num . 1 " , upgrade_from_version . before ( version . v_8_0_0 ) ) ; <nl> + assumetrue ( " datehisto interval changed in num . 1 " , upgrade_from_version . before ( version . v_7_2_0 ) ) ; <nl> switch ( cluster_type ) { <nl> case old : <nl> break ;
setup : <nl> mmm <nl> " bad params " : <nl> - skip : <nl> - version : " - num . 99 . 99 " # <nl> + version : " - num . 1 . 99 " <nl> reason : " empty bodies throws exception starting in num . 2 " <nl> - do : <nl> catch : / \ [ filters \ ] cannot be empty /
integtestcluster { <nl> extraconfigfile ' hunspell / en_us / en_us . dic ' , ' . . / server / src / test / resources / indices / analyze / conf_dir / hunspell / en_us / en_us . dic ' <nl> / / whitelist reindexing from the local node so we can test it . <nl> setting ' reindex . remote . whitelist ' , ' 127 . 0 . 0 . 1 : * ' <nl> - <nl> - <nl> - systemproperty ' es . scripting . update . ctx_in_params ' , ' false ' <nl> } <nl>  <nl> / / build the cluster with all plugins
setup : <nl> mmm <nl> " missing source " : <nl> - skip : <nl> - version : " - num . 99 . 99 " # <nl> + version : " - num . 0 . 99 " <nl> reason : null / empty sources disallowed in num . 1 <nl>  <nl> - do : <nl>
setup : <nl> mmm <nl> " duplicate sources " : <nl> - skip : <nl> - version : " - num . 99 . 99 " # <nl> + version : " - num . 0 . 99 " <nl> reason : duplicate names disallowed in num . 1 <nl>  <nl> - do :
<nl> grant { <nl> - / / needed because of problems in unbound ldap library <nl> - permission java . util . propertypermission " * " , " read , write " ; <nl> - <nl> - / / required to configure the custom mailcap for watcher <nl> - permission java . lang . runtimepermission " setfactory " ; <nl> - <nl> - / / needed when sending emails for javax . activation <nl> - / / otherwise a classnotfound exception is thrown due to trying <nl> - / / to load the class with the application class loader <nl> - permission java . lang . runtimepermission " setcontextclassloader " ; <nl> - permission java . lang . runtimepermission " getclassloader " ; <nl> - <nl> - permission java . lang . runtimepermission " accessclassinpackage . com . sun . activation . registries " ; <nl> - <nl> - / / bouncy castle <nl> - permission java . security . securitypermission " putproviderproperty . bc " ; <nl> - <nl> - / / needed for x - pack security extension <nl> - permission java . security . securitypermission " createpolicy . javapolicy " ; <nl> - permission java . security . securitypermission " getpolicy " ; <nl> - permission java . security . securitypermission " setpolicy " ; <nl> - <nl> / / needed for multiple server implementations used in tests <nl> permission java . net . socketpermission " * " , " accept , connect " ; <nl> - <nl> - / / needed for windows named pipes in machine learning <nl> - permission java . io . filepermission " \ \ \ \ . \ \ pipe \ \ * " , " read , write " ; <nl> } ; <nl> - <nl> - grant codebase " $ { codebase . netty - common } " { <nl> - / / for reading the system - wide configuration for the backlog of established sockets <nl> - permission java . io . filepermission " / proc / sys / net / core / somaxconn " , " read " ; <nl> - } ; <nl> - <nl> - grant codebase " $ { codebase . netty - transport } " { <nl> - / / netty nioeventloop wants to change this , because of https : / / bugs . openjdk . java . net / browse / jdk - 6427854 <nl> - / / the bug says it only happened rarely , and that its fixed , but apparently it still happens rarely ! <nl> - permission java . util . propertypermission " sun . nio . ch . buglevel " , " write " ; <nl> - } ; <nl> - <nl> - grant codebase " $ { codebase . elasticsearch - rest - client } " { <nl> - / / rest client uses system properties which gets the default proxy <nl> - permission java . net . netpermission " getproxyselector " ; <nl> - } ; <nl> - <nl> - grant codebase " $ { codebase . httpasyncclient } " { <nl> - / / rest client uses system properties which gets the default proxy <nl> - permission java . net . netpermission " getproxyselector " ; <nl> - } ; <nl> \ no newline at end of file
class clusterformationtasks { <nl> static task configureexectask ( string name , project project , task setup , nodeinfo node , object [ ] execargs ) { <nl> return project . tasks . create ( name : name , type : loggedexec , dependson : setup ) { exec exec - > <nl> exec . workingdir node . cwd <nl> - <nl> - if ( project . isruntimejavahomeset | | node . nodeversion . before ( version . fromstring ( " 8 . 0 . 0 " ) ) | | <nl> + if ( project . isruntimejavahomeset | | node . nodeversion . before ( version . fromstring ( " 7 . 0 . 0 " ) ) | | <nl> node . config . distribution = = ' integ - test - zip ' ) { <nl> exec . environment . put ( ' java_home ' , project . runtimejavahome ) <nl> } else { <nl>
dependencies { <nl> compile " org . apache . james : apache - mime4j - dom : $ { versions . mime4j } " <nl> } <nl>  <nl> - <nl> - compilejava . options . compilerargs < < " - xlint : - deprecation " <nl> - <nl> - <nl> dependencylicenses { <nl> mapping from : / apache - mime4j - . * / , to : ' apache - mime4j ' <nl> } <nl> mmm a / plugins / ingest - attachment / src / main / java / org / elasticsearch / ingest / attachment / attachmentprocessor . java <nl> ppp b / plugins / ingest - attachment / src / main / java / org / elasticsearch / ingest / attachment / attachmentprocessor . java <nl>
esplugin { <nl> description ' the mapper size plugin allows document to record their uncompressed size at <nl> classname ' org . elasticsearch . plugin . mapper . mappersizeplugin ' <nl> } <nl> - <nl> - <nl> - compilejava . options . compilerargs < < " - xlint : - deprecation " <nl> - compiletestjava . options . compilerargs < < " - xlint : - deprecation " <nl> mmm a / plugins / transport - nio / build . gradle <nl> ppp b / plugins / transport - nio / build . gradle <nl>
setup : <nl> mmm <nl> " test use_field " : <nl> - skip : <nl> - version : " - num . 9 . 99 " # <nl> + version : " - num . 0 . 99 " <nl> reason : " implemented in num . 1 " <nl> - do : <nl> search :
<nl> { <nl> " data_frame . preview_data_frame_transform " : { <nl> - " documentation " : " <nl> + " documentation " : " https : / / www . elastic . co / guide / en / elasticsearch / reference / current / preview - data - frame - transform . html " , <nl> " methods " : [ " post " ] , <nl> " url " : { <nl> " path " : " / _data_frame / transforms / _preview " ,
<nl> setup : <nl> - skip : <nl> - version : " - num . 9 . 99 " # <nl> + version : " - num . 0 . 99 " <nl> reason : " implemented in num . 1 " <nl>  <nl> - do :
<nl> the azure classic discovery plugin uses the azure classic api to identify the <nl> addresses of seed hosts . <nl>  <nl> - <nl> - / / see issue https : / / github . com / elastic / elasticsearch / issues / 19146 <nl> - deprecated [ 5 . 0 . 0 , use coming azure arm discovery plugin instead ] <nl> + deprecated [ 5 . 0 . 0 , this plugin will be removed in the future ] <nl>  <nl> : plugin_name : discovery - azure - classic <nl> include : : install_remove . asciidoc [ ] <nl> mmm a / plugins / discovery - azure - classic / src / main / java / org / elasticsearch / plugin / discovery / azure / classic / azurediscoveryplugin . java <nl> ppp b / plugins / discovery - azure - classic / src / main / java / org / elasticsearch / plugin / discovery / azure / classic / azurediscoveryplugin . java <nl>
public final class dataframeinternalindex { <nl> / / the configurations are expected to be small <nl> . put ( indexmetadata . setting_number_of_shards , num ) <nl> . put ( indexmetadata . setting_auto_expand_replicas , " 0 - 1 " ) ) <nl> - <nl> . putmapping ( mapperservice . single_mapping_name , strings . tostring ( mappings ( ) ) ) <nl> . build ( ) ; <nl> return dataframetemplate ; <nl> mmm a / x - pack / plugin / data - frame / src / main / java / org / elasticsearch / xpack / dataframe / persistence / dataframeindex . java <nl> ppp b / x - pack / plugin / data - frame / src / main / java / org / elasticsearch / xpack / dataframe / persistence / dataframeindex . java <nl>
public class shardfollowtask extends immutablefollowparameters implements xpackp <nl> string remotecluster = in . readstring ( ) ; <nl> shardid followshardid = shardid . readshardid ( in ) ; <nl> shardid leadershardid = shardid . readshardid ( in ) ; <nl> - <nl> - int maxreadrequestoperationcount = in . readvint ( ) ; <nl> - bytesizevalue maxreadrequestsize = new bytesizevalue ( in ) ; <nl> - int maxoutstandingreadrequests = in . readvint ( ) ; <nl> - int maxwriterequestoperationcount = in . readvint ( ) ; <nl> - bytesizevalue maxwriterequestsize = new bytesizevalue ( in ) ; <nl> - int maxoutstandingwriterequests = in . readvint ( ) ; <nl> - int maxwritebuffercount = in . readvint ( ) ; <nl> - bytesizevalue maxwritebuffersize = new bytesizevalue ( in ) ; <nl> - timevalue maxretrydelay = in . readtimevalue ( ) ; <nl> - timevalue readpolltimeout = in . readtimevalue ( ) ; <nl> - map < string , string > headers = collections . unmodifiablemap ( in . readmap ( streaminput : : readstring , streaminput : : readstring ) ) ; <nl> - return new shardfollowtask ( remotecluster , followshardid , leadershardid , maxreadrequestoperationcount , <nl> - maxwriterequestoperationcount , maxoutstandingreadrequests , maxoutstandingwriterequests , maxreadrequestsize , <nl> - maxwriterequestsize , maxwritebuffercount , maxwritebuffersize , maxretrydelay , readpolltimeout , headers ) ; <nl> + return new shardfollowtask ( remotecluster , followshardid , leadershardid , in ) ; <nl> + } <nl> + <nl> + private shardfollowtask ( string remotecluster , shardid followshardid , shardid leadershardid , streaminput in ) throws ioexception { <nl> + super ( in ) ; <nl> + this . remotecluster = remotecluster ; <nl> + this . followshardid = followshardid ; <nl> + this . leadershardid = leadershardid ; <nl> + this . headers = collections . unmodifiablemap ( in . readmap ( streaminput : : readstring , streaminput : : readstring ) ) ; <nl> } <nl>  <nl> public string getremotecluster ( ) { <nl>
public class shardfollowtask extends immutablefollowparameters implements xpackp <nl> out . writestring ( remotecluster ) ; <nl> followshardid . writeto ( out ) ; <nl> leadershardid . writeto ( out ) ; <nl> - <nl> - out . writevlong ( getmaxreadrequestoperationcount ( ) ) ; <nl> - getmaxreadrequestsize ( ) . writeto ( out ) ; <nl> - out . writevint ( getmaxoutstandingreadrequests ( ) ) ; <nl> - out . writevlong ( getmaxwriterequestoperationcount ( ) ) ; <nl> - getmaxwriterequestsize ( ) . writeto ( out ) ; <nl> - out . writevint ( getmaxoutstandingwriterequests ( ) ) ; <nl> - out . writevint ( getmaxwritebuffercount ( ) ) ; <nl> - getmaxwritebuffersize ( ) . writeto ( out ) ; <nl> - out . writetimevalue ( getmaxretrydelay ( ) ) ; <nl> - out . writetimevalue ( getreadpolltimeout ( ) ) ; <nl> + super . writeto ( out ) ; <nl> out . writemap ( headers , streamoutput : : writestring , streamoutput : : writestring ) ; <nl> }
public class dataframetransform extends abstractdiffable < dataframetransform > imp <nl>  <nl> @ override <nl> public version getminimalsupportedversion ( ) { <nl> - <nl> - return version . current ; <nl> + return version . v_7_1_0 ; <nl> } <nl>  <nl> @ override
public class securityfeaturesetusage extends xpackfeatureset . usage { <nl> realmsusage = in . readmap ( ) ; <nl> rolesstoreusage = in . readmap ( ) ; <nl> sslusage = in . readmap ( ) ; <nl> - if ( in . getversion ( ) . onorafter ( version . v_8_0_0 ) ) { <nl> + if ( in . getversion ( ) . onorafter ( version . v_7_1_0 ) ) { <nl> tokenserviceusage = in . readmap ( ) ; <nl> apikeyserviceusage = in . readmap ( ) ; <nl> } <nl>
public class transportshardbulkaction extends transportwriteaction < bulkshardrequ <nl> throws ioexception { <nl> t result = toexecute . get ( ) ; <nl> if ( result . getresulttype ( ) = = engine . result . type . mapping_update_required ) { <nl> - / / try to update the mappings and try again . <nl> + / / try to update the mappings and mark the context as needing to try again . <nl> try { <nl> mappingupdater . accept ( result . getrequiredmappingupdate ( ) ) ; <nl> + context . markasrequiringmappingupdate ( ) ; <nl> } catch ( exception e ) { <nl> / / failure to update the mapping should translate to a failure of specific requests . other requests <nl> / / still need to be executed and replicated . <nl> oncomplete . accept ( exceptiontoresult . apply ( e ) ) ; <nl> return ; <nl> } <nl> - <nl> - <nl> - result = toexecute . get ( ) ; <nl> - <nl> - if ( result . getresulttype ( ) = = engine . result . type . mapping_update_required ) { <nl> - / / double mapping update . we assume that the successful mapping update wasn ' t yet processed on the node <nl> - / / and retry the entire request again . <nl> - context . markasrequiringmappingupdate ( ) ; <nl> - } else { <nl> - oncomplete . accept ( result ) ; <nl> - } <nl> } else { <nl> oncomplete . accept ( result ) ; <nl> } <nl> mmm a / server / src / test / java / org / elasticsearch / action / bulk / transportshardbulkactiontests . java <nl> ppp b / server / src / test / java / org / elasticsearch / action / bulk / transportshardbulkactiontests . java <nl>
public class authentication implements toxcontentobject { <nl> this . lookedupby = null ; <nl> } <nl> this . version = in . getversion ( ) ; <nl> - if ( in . getversion ( ) . onorafter ( version . v_7_0_0 ) ) { <nl> + if ( in . getversion ( ) . onorafter ( version . v_6_7_0 ) ) { <nl> type = authenticationtype . values ( ) [ in . readvint ( ) ] ; <nl> metadata = in . readmap ( ) ; <nl> } else { <nl>
public class authentication implements toxcontentobject { <nl> } else { <nl> out . writeboolean ( false ) ; <nl> } <nl> - if ( out . getversion ( ) . onorafter ( version . v_7_0_0 ) ) { <nl> + if ( out . getversion ( ) . onorafter ( version . v_6_7_0 ) ) { <nl> out . writevint ( type . ordinal ( ) ) ; <nl> out . writemap ( metadata ) ; <nl> } <nl> mmm a / x - pack / plugin / security / src / main / java / org / elasticsearch / xpack / security / authc / apikeyservice . java <nl> ppp b / x - pack / plugin / security / src / main / java / org / elasticsearch / xpack / security / authc / apikeyservice . java <nl>
public class apikeyservice { <nl> final instant expiration = getapikeyexpiration ( created , request ) ; <nl> final securestring apikey = uuids . randombase64uuidsecurestring ( ) ; <nl> final version version = clusterservice . state ( ) . nodes ( ) . getminnodeversion ( ) ; <nl> - if ( version . before ( version . v_7_0_0 ) ) { <nl> + if ( version . before ( version . v_6_7_0 ) ) { <nl> logger . warn ( <nl> " nodes prior to the minimum supported version for api keys { } exist in the cluster ; " <nl> + " these nodes will not be able to use api keys " , <nl> - version . v_7_0_0 ) ; <nl> + version . v_6_7_0 ) ; <nl> } <nl>  <nl> final char [ ] keyhash = hasher . hash ( apikey ) ;
public final class internaltestcluster extends testcluster { <nl> final circuitbreakerservice breakerservice = getinstancefromnode ( circuitbreakerservice . class , nodeandclient . node ) ; <nl> circuitbreaker fdbreaker = breakerservice . getbreaker ( circuitbreaker . fielddata ) ; <nl> assertthat ( " fielddata breaker not reset to num on node : " + name , fdbreaker . getused ( ) , equalto ( 0l ) ) ; <nl> - <nl> - / / see : https : / / github . com / elastic / elasticsearch / issues / 30290 <nl> - / / circuitbreaker acctbreaker = breakerservice . getbreaker ( circuitbreaker . accounting ) ; <nl> - / / assertthat ( " accounting breaker not reset to num on node : " + name , acctbreaker . getused ( ) , equalto ( 0l ) ) ; <nl> + circuitbreaker acctbreaker = breakerservice . getbreaker ( circuitbreaker . accounting ) ; <nl> + assertthat ( " accounting breaker not reset to num on node : " + name + " , are there still lucene indices around ? " , <nl> + acctbreaker . getused ( ) , equalto ( 0l ) ) ; <nl> / / anything that uses transport or http can increase the <nl> / / request breaker ( because they use bigarrays ) , because of <nl> / / that the breaker can sometimes be incremented from ping
public final class searchrequest extends actionrequest implements indicesrequest <nl> localclusteralias = in . readoptionalstring ( ) ; <nl> if ( localclusteralias ! = null ) { <nl> absolutestartmillis = in . readvlong ( ) ; <nl> + finalreduce = in . readboolean ( ) ; <nl> } else { <nl> absolutestartmillis = default_absolute_start_millis ; <nl> + finalreduce = true ; <nl> } <nl> } else { <nl> localclusteralias = null ; <nl> absolutestartmillis = default_absolute_start_millis ; <nl> - } <nl> - <nl> - if ( in . getversion ( ) . onorafter ( version . v_7_0_0 ) ) { <nl> - finalreduce = in . readboolean ( ) ; <nl> - } else { <nl> finalreduce = true ; <nl> } <nl> if ( in . getversion ( ) . onorafter ( version . v_7_0_0 ) ) { <nl>
public final class searchrequest extends actionrequest implements indicesrequest <nl> out . writeoptionalstring ( localclusteralias ) ; <nl> if ( localclusteralias ! = null ) { <nl> out . writevlong ( absolutestartmillis ) ; <nl> + out . writeboolean ( finalreduce ) ; <nl> } <nl> } <nl> - <nl> - if ( out . getversion ( ) . onorafter ( version . v_7_0_0 ) ) { <nl> - out . writeboolean ( finalreduce ) ; <nl> - } <nl> if ( out . getversion ( ) . onorafter ( version . v_7_0_0 ) ) { <nl> out . writeboolean ( ccsminimizeroundtrips ) ; <nl> } <nl> mmm a / server / src / test / java / org / elasticsearch / action / search / searchrequesttests . java <nl> ppp b / server / src / test / java / org / elasticsearch / action / search / searchrequesttests . java <nl>
public class searchrequesttests extends abstractsearchtestcase { <nl> if ( version . before ( version . v_6_7_0 ) ) { <nl> assertnull ( deserializedrequest . getlocalclusteralias ( ) ) ; <nl> assertabsolutestartmillisiscurrenttime ( deserializedrequest ) ; <nl> + asserttrue ( deserializedrequest . isfinalreduce ( ) ) ; <nl> } else { <nl> assertequals ( searchrequest . getlocalclusteralias ( ) , deserializedrequest . getlocalclusteralias ( ) ) ; <nl> assertequals ( searchrequest . getorcreateabsolutestartmillis ( ) , deserializedrequest . getorcreateabsolutestartmillis ( ) ) ; <nl> - } <nl> - <nl> - if ( version . before ( version . v_7_0_0 ) ) { <nl> - asserttrue ( deserializedrequest . isfinalreduce ( ) ) ; <nl> - } else { <nl> assertequals ( searchrequest . isfinalreduce ( ) , deserializedrequest . isfinalreduce ( ) ) ; <nl> } <nl> } <nl> mmm a / server / src / test / java / org / elasticsearch / action / search / transportsearchactionsinglenodetests . java <nl> ppp b / server / src / test / java / org / elasticsearch / action / search / transportsearchactionsinglenodetests . java <nl>
public final class putfollowaction extends action < putfollowaction . response > { <nl> super ( in ) ; <nl> remotecluster = in . readstring ( ) ; <nl> leaderindex = in . readstring ( ) ; <nl> - <nl> - if ( in . getversion ( ) . onorafter ( version . v_7_0_0 ) ) { <nl> + if ( in . getversion ( ) . onorafter ( version . v_6_7_0 ) ) { <nl> waitforactiveshards ( activeshardcount . readfrom ( in ) ) ; <nl> } <nl> followrequest = new resumefollowaction . request ( in ) ; <nl>
public final class putfollowaction extends action < putfollowaction . response > { <nl> super . writeto ( out ) ; <nl> out . writestring ( remotecluster ) ; <nl> out . writestring ( leaderindex ) ; <nl> - <nl> - if ( out . getversion ( ) . onorafter ( version . v_7_0_0 ) ) { <nl> + if ( out . getversion ( ) . onorafter ( version . v_6_7_0 ) ) { <nl> waitforactiveshards . writeto ( out ) ; <nl> } <nl> followrequest . writeto ( out ) ;
public class shardstateaction { <nl> if ( in . getversion ( ) . before ( version . v_6_3_0 ) ) { <nl> primaryterm = in . readvlong ( ) ; <nl> assert primaryterm = = unassigned_primary_term : " shard is only started by itself : primary term [ " + primaryterm + " ] " ; <nl> - } else if ( in . getversion ( ) . onorafter ( version . v_7_0_0 ) ) { <nl> + } else if ( in . getversion ( ) . onorafter ( version . v_6_7_0 ) ) { <nl> primaryterm = in . readvlong ( ) ; <nl> } else { <nl> primaryterm = unassigned_primary_term ; <nl>
public class shardstateaction { <nl> out . writestring ( allocationid ) ; <nl> if ( out . getversion ( ) . before ( version . v_6_3_0 ) ) { <nl> out . writevlong ( 0l ) ; <nl> - } else if ( out . getversion ( ) . onorafter ( version . v_7_0_0 ) ) { <nl> + } else if ( out . getversion ( ) . onorafter ( version . v_6_7_0 ) ) { <nl> out . writevlong ( primaryterm ) ; <nl> } <nl> out . writestring ( message ) ; <nl> mmm a / server / src / test / java / org / elasticsearch / cluster / action / shard / shardstateactiontests . java <nl> ppp b / server / src / test / java / org / elasticsearch / cluster / action / shard / shardstateactiontests . java <nl>
public class shardstateactiontests extends estestcase { <nl> final startedshardentry deserialized = new startedshardentry ( in ) ; <nl> assertthat ( deserialized . shardid , equalto ( shardid ) ) ; <nl> assertthat ( deserialized . allocationid , equalto ( allocationid ) ) ; <nl> - if ( version . onorafter ( version . v_7_0_0 ) ) { <nl> + if ( version . onorafter ( version . v_6_7_0 ) ) { <nl> assertthat ( deserialized . primaryterm , equalto ( primaryterm ) ) ; <nl> } else { <nl> assertthat ( deserialized . primaryterm , equalto ( 0l ) ) ;
public abstract class abstractlifecyclecomponent implements lifecyclecomponent { <nl>  <nl> protected abstractlifecyclecomponent ( ) { } <nl>  <nl> - @ deprecated <nl> - protected abstractlifecyclecomponent ( settings settings ) { <nl> - <nl> - } <nl> - <nl> @ override <nl> public lifecycle . state lifecyclestate ( ) { <nl> return this . lifecycle . state ( ) ;
public class similaritytests extends essinglenodetestcase { <nl> legacybm25similarity similarity = ( legacybm25similarity ) mapperservice . fullname ( " field1 " ) . similarity ( ) . get ( ) ; <nl> assertthat ( similarity . getk1 ( ) , equalto ( 2 . 0f ) ) ; <nl> assertthat ( similarity . getb ( ) , equalto ( 0 . 5f ) ) ; <nl> - <nl> - / / assertthat ( similarity . getdiscountoverlaps ( ) , equalto ( false ) ) ; <nl> + assertthat ( similarity . getdiscountoverlaps ( ) , equalto ( false ) ) ; <nl> } <nl>  <nl> public void testresolvesimilaritiesfrommapping_boolean ( ) throws ioexception {
public class sourceonlysnapshotit extends esintegtestcase { <nl> } <nl> } <nl>  <nl> - public void testtostopsuitefailing ( ) { <nl> - / / this is required because otherwise every test in the suite is muted <nl> - <nl> - } <nl> - <nl> - @ awaitsfix ( bugurl = " https : / / github . com / elastic / elasticsearch / issues / 36330 " ) <nl> public void testsnapshotandrestore ( ) throws exception { <nl> final string sourceidx = " test - idx " ; <nl> boolean requirerouting = randomboolean ( ) ; <nl>
public final class searchrequest extends actionrequest implements indicesrequest <nl> if ( in . getversion ( ) . onorafter ( version . v_6_3_0 ) ) { <nl> allowpartialsearchresults = in . readoptionalboolean ( ) ; <nl> } <nl> - <nl> - if ( in . getversion ( ) . onorafter ( version . v_7_0_0 ) ) { <nl> + if ( in . getversion ( ) . onorafter ( version . v_6_7_0 ) ) { <nl> localclusteralias = in . readoptionalstring ( ) ; <nl> if ( localclusteralias ! = null ) { <nl> absolutestartmillis = in . readvlong ( ) ; <nl>
public final class searchrequest extends actionrequest implements indicesrequest <nl> if ( out . getversion ( ) . onorafter ( version . v_6_3_0 ) ) { <nl> out . writeoptionalboolean ( allowpartialsearchresults ) ; <nl> } <nl> - <nl> - if ( out . getversion ( ) . onorafter ( version . v_7_0_0 ) ) { <nl> + if ( out . getversion ( ) . onorafter ( version . v_6_7_0 ) ) { <nl> out . writeoptionalstring ( localclusteralias ) ; <nl> if ( localclusteralias ! = null ) { <nl> out . writevlong ( absolutestartmillis ) ; <nl> mmm a / server / src / test / java / org / elasticsearch / action / search / searchrequesttests . java <nl> ppp b / server / src / test / java / org / elasticsearch / action / search / searchrequesttests . java <nl>
public class searchrequesttests extends abstractsearchtestcase { <nl> searchrequest searchrequest = createsearchrequest ( ) ; <nl> version version = versionutils . randomversion ( random ( ) ) ; <nl> searchrequest deserializedrequest = copywriteable ( searchrequest , namedwriteableregistry , searchrequest : : new , version ) ; <nl> - <nl> - if ( version . before ( version . v_7_0_0 ) ) { <nl> + if ( version . before ( version . v_6_7_0 ) ) { <nl> assertnull ( deserializedrequest . getlocalclusteralias ( ) ) ; <nl> assertabsolutestartmillisiscurrenttime ( deserializedrequest ) ; <nl> } else { <nl>
public class searchrequesttests extends abstractsearchtestcase { <nl> } <nl> } <nl>  <nl> - <nl> - public void testreadfrompre7_0_0 ( ) throws ioexception { <nl> + public void testreadfrompre6_7_0 ( ) throws ioexception { <nl> string msg = " aaebbwluzgv4aaaaaqacaaaa / / / / / w8aaaaaaaaa / / / / / w8aaaaaaaacaaaaaaabaamcbaubaakabacaaqiaaa = = " ; <nl> try ( streaminput in = streaminput . wrap ( base64 . getdecoder ( ) . decode ( msg ) ) ) { <nl> - in . setversion ( versionutils . randomversionbetween ( random ( ) , version . v_6_4_0 , versionutils . getpreviousversion ( version . v_7_0_0 ) ) ) ; <nl> + in . setversion ( versionutils . randomversionbetween ( random ( ) , version . v_6_4_0 , versionutils . getpreviousversion ( version . v_6_7_0 ) ) ) ; <nl> searchrequest searchrequest = new searchrequest ( in ) ; <nl> assertarrayequals ( new string [ ] { " index " } , searchrequest . indices ( ) ) ; <nl> assertnull ( searchrequest . getlocalclusteralias ( ) ) ;
public class discoverydisruptionit extends abstractdisruptiontestcase { <nl> * test cluster join with issues in cluster state publishing * <nl> * / <nl> public void testclusterjoindespiteofpublishingissues ( ) throws exception { <nl> - <nl> - string masternode = internalcluster ( ) . startmasteronlynode ( <nl> - settings . builder ( ) . put ( testzendiscovery . use_zen2 . getkey ( ) , false ) . build ( ) ) ; <nl> - string nonmasternode = internalcluster ( ) . startdataonlynode ( <nl> - settings . builder ( ) . put ( testzendiscovery . use_zen2 . getkey ( ) , false ) . build ( ) ) ; <nl> + string masternode = internalcluster ( ) . startmasteronlynode ( ) ; <nl> + string nonmasternode = internalcluster ( ) . startdataonlynode ( ) ; <nl>  <nl> discoverynodes discoverynodes = internalcluster ( ) . getinstance ( clusterservice . class , nonmasternode ) . state ( ) . nodes ( ) ;
public class gatewaymetastate implements clusterstateapplier , coordinationstate . <nl> this . clusterservice = clusterservice ; <nl> this . indicesservice = indicesservice ; <nl>  <nl> - ensureatomicmovesupported ( ) ; <nl> upgrademetadata ( metadataindexupgradeservice , metadataupgrader ) ; <nl> initializeclusterstate ( clustername . cluster_name_setting . get ( settings ) ) ; <nl> incrementalwrite = false ; <nl>
public final class searchhits implements streamable , toxcontentfragment , iterabl <nl> hits [ i ] = searchhit . readsearchhit ( in ) ; <nl> } <nl> } <nl> - <nl> - if ( in . getversion ( ) . onorafter ( version . v_7_0_0 ) ) { <nl> + if ( in . getversion ( ) . onorafter ( version . v_6_6_0 ) ) { <nl> sortfields = in . readoptionalarray ( lucene : : readsortfield , sortfield [ ] : : new ) ; <nl> collapsefield = in . readoptionalstring ( ) ; <nl> collapsevalues = in . readoptionalarray ( lucene : : readsortvalue , object [ ] : : new ) ; <nl>
public final class searchhits implements streamable , toxcontentfragment , iterabl <nl> hit . writeto ( out ) ; <nl> } <nl> } <nl> - <nl> - if ( out . getversion ( ) . onorafter ( version . v_7_0_0 ) ) { <nl> + if ( out . getversion ( ) . onorafter ( version . v_6_6_0 ) ) { <nl> out . writeoptionalarray ( lucene : : writesortfield , sortfields ) ; <nl> out . writeoptionalstring ( collapsefield ) ; <nl> out . writeoptionalarray ( lucene : : writesortvalue , collapsevalues ) ; <nl> mmm a / server / src / test / java / org / elasticsearch / search / searchhitstests . java <nl> ppp b / server / src / test / java / org / elasticsearch / search / searchhitstests . java <nl>
public class searchhitstests extends abstractstreamablexcontenttestcase < searchhi <nl> } <nl> } <nl>  <nl> - <nl> - public void testreadfrompre70 ( ) throws ioexception { <nl> + public void testreadfrompre6_6_0 ( ) throws ioexception { <nl> try ( streaminput in = streaminput . wrap ( base64 . getdecoder ( ) . decode ( " aqc / gaaaaaa = " ) ) ) { <nl> - in . setversion ( versionutils . randomversionbetween ( random ( ) , version . v_6_0_0 , versionutils . getpreviousversion ( version . v_7_0_0 ) ) ) ; <nl> + in . setversion ( versionutils . randomversionbetween ( random ( ) , version . v_6_0_0 , versionutils . getpreviousversion ( version . v_6_6_0 ) ) ) ; <nl> searchhits searchhits = new searchhits ( ) ; <nl> searchhits . readfrom ( in ) ; <nl> assertequals ( 0 , searchhits . gethits ( ) . length ) ; <nl>
public class searchhitstests extends abstractstreamablexcontenttestcase < searchhi <nl> } <nl> } <nl>  <nl> - <nl> - public void testserializationpre70 ( ) throws ioexception { <nl> - version version = versionutils . randomversionbetween ( random ( ) , version . v_6_0_0 , versionutils . getpreviousversion ( version . v_7_0_0 ) ) ; <nl> + public void testserializationpre6_6_0 ( ) throws ioexception { <nl> + version version = versionutils . randomversionbetween ( random ( ) , version . v_6_0_0 , versionutils . getpreviousversion ( version . v_6_6_0 ) ) ; <nl> searchhits original = createtestitem ( randomfrom ( xcontenttype . values ( ) ) , false , true , totalhits . relation . equal_to ) ; <nl> searchhits deserialized = copyinstance ( original , version ) ; <nl> assertarrayequals ( original . gethits ( ) , deserialized . gethits ( ) ) ;
public abstract class peerfinder { <nl> @ override <nl> public void onfailure ( exception e ) { <nl> logger . debug ( ( ) - > new parameterizedmessage ( " { } connection failed " , peer . this ) , e ) ; <nl> - removepeer ( ) ; <nl> + synchronized ( mutex ) { <nl> + peersbyaddress . remove ( transportaddress ) ; <nl> + } <nl> } <nl> } ) ; <nl> } <nl>  <nl> - void removepeer ( ) { <nl> - final peer removed = peersbyaddress . remove ( transportaddress ) ; <nl> - / / assert removed = = peer . this : removed + " ! = " + peer . this ; <nl> - / / ^ this assertion sometimes trips if we are deactivated and reactivated while a request is in flight . <nl> - <nl> - } <nl> - <nl> private void requestpeers ( ) { <nl> assert holdslock ( ) : " peerfinder mutex not held " ; <nl> assert peersrequestinflight = = false : " peersrequest already in flight " ;
public class lucene { <nl> super ( in , new subreaderwrapper ( ) { <nl> @ override <nl> public leafreader wrap ( leafreader leaf ) { <nl> - segmentreader segmentreader = segmentreader ( leaf ) ; <nl> - bits hardlivedocs = segmentreader . gethardlivedocs ( ) ; <nl> + final segmentreader segmentreader = segmentreader ( leaf ) ; <nl> + final bits hardlivedocs = segmentreader . gethardlivedocs ( ) ; <nl> if ( hardlivedocs = = null ) { <nl> return new leafreaderwithlivedocs ( leaf , null , leaf . maxdoc ( ) ) ; <nl> } <nl> - <nl> - int numdocs = num ; <nl> - for ( int i = num ; i < hardlivedocs . length ( ) ; i + + ) { <nl> - if ( hardlivedocs . get ( i ) ) { <nl> - numdocs + + ; <nl> - } <nl> - } <nl> + / / once soft - deletes is enabled , we no longer hard - update or hard - delete documents directly . <nl> + / / two scenarios that we have hard - deletes : ( 1 ) from old segments where soft - deletes was disabled , <nl> + / / ( 2 ) when indexwriter hits non - aborted exceptions . these two cases , iw flushes segmentinfos <nl> + / / before exposing the hard - deletes , thus we can use the hard - delete count of segmentinfos . <nl> + final int numdocs = segmentreader . maxdoc ( ) - segmentreader . getsegmentinfo ( ) . getdelcount ( ) ; <nl> + assert numdocs = = popcount ( hardlivedocs ) : numdocs + " ! = " + popcount ( hardlivedocs ) ; <nl> return new leafreaderwithlivedocs ( segmentreader , hardlivedocs , numdocs ) ; <nl> } <nl> } ) ; <nl>
public abstract class indexerjobstats implements toxcontentobject , writeable { <nl> this . numinputdocuments = in . readvlong ( ) ; <nl> this . numouputdocuments = in . readvlong ( ) ; <nl> this . numinvocations = in . readvlong ( ) ; <nl> - <nl> - if ( in . getversion ( ) . onorafter ( version . current ) ) { <nl> + if ( in . getversion ( ) . onorafter ( version . v_6_6_0 ) ) { <nl> this . indextime = in . readvlong ( ) ; <nl> this . searchtime = in . readvlong ( ) ; <nl> this . indextotal = in . readvlong ( ) ; <nl>
public abstract class indexerjobstats implements toxcontentobject , writeable { <nl> out . writevlong ( numinputdocuments ) ; <nl> out . writevlong ( numouputdocuments ) ; <nl> out . writevlong ( numinvocations ) ; <nl> - <nl> - if ( out . getversion ( ) . onorafter ( version . current ) ) { <nl> + if ( out . getversion ( ) . onorafter ( version . v_6_6_0 ) ) { <nl> out . writevlong ( indextime ) ; <nl> out . writevlong ( searchtime ) ; <nl> out . writevlong ( indextotal ) ;
<nl> - do : <nl> snapshot . create_repository : <nl> repository : my_repo <nl> - # <nl> verify : false <nl> body : <nl> type : url
final class documentparser { <nl> if ( idfield ! = null ) { <nl> / / we just need to store the id as indexed field , so that indexwriter # deletedocuments ( term ) can then <nl> / / delete it when the root document is deleted too . <nl> - if ( idfield . stringvalue ( ) ! = null ) { <nl> - / / backward compat with num . x <nl> - <nl> - nesteddoc . add ( new field ( idfieldmapper . name , idfield . stringvalue ( ) , idfieldmapper . defaults . nested_field_type ) ) ; <nl> - } else { <nl> - nesteddoc . add ( new field ( idfieldmapper . name , idfield . binaryvalue ( ) , idfieldmapper . defaults . nested_field_type ) ) ; <nl> - } <nl> + nesteddoc . add ( new field ( idfieldmapper . name , idfield . binaryvalue ( ) , idfieldmapper . defaults . nested_field_type ) ) ; <nl> } else { <nl> throw new illegalstateexception ( " the root document of a nested document should have an _id field " ) ; <nl> } <nl> mmm a / server / src / main / java / org / elasticsearch / index / mapper / typefieldmapper . java <nl> ppp b / server / src / main / java / org / elasticsearch / index / mapper / typefieldmapper . java <nl>
public class stoprollupjobaction extends action < stoprollupjobaction . response > { <nl> public void readfrom ( streaminput in ) throws ioexception { <nl> super . readfrom ( in ) ; <nl> id = in . readstring ( ) ; <nl> - <nl> - if ( in . getversion ( ) . onorafter ( version . current ) ) { <nl> + if ( in . getversion ( ) . onorafter ( version . v_6_6_0 ) ) { <nl> waitforcompletion = in . readboolean ( ) ; <nl> timeout = in . readtimevalue ( ) ; <nl> } <nl>
public class stoprollupjobaction extends action < stoprollupjobaction . response > { <nl> public void writeto ( streamoutput out ) throws ioexception { <nl> super . writeto ( out ) ; <nl> out . writestring ( id ) ; <nl> - <nl> - if ( out . getversion ( ) . onorafter ( version . current ) ) { <nl> + if ( out . getversion ( ) . onorafter ( version . v_6_6_0 ) ) { <nl> out . writeboolean ( waitforcompletion ) ; <nl> out . writetimevalue ( timeout ) ; <nl> } <nl> mmm a / x - pack / plugin / src / test / resources / rest - api - spec / test / rollup / stop_job . yml <nl> ppp b / x - pack / plugin / src / test / resources / rest - api - spec / test / rollup / stop_job . yml <nl>
public class rollupdocumentationit extends esresthighlevelclienttestcase { <nl> asserttrue ( latch . await ( 30l , timeunit . seconds ) ) ; <nl> } <nl>  <nl> - @ after <nl> - public void wiperollup ( ) throws exception { <nl> - <nl> - deleterollupjobs ( ) ; <nl> - waitforpendingrolluptasks ( ) ; <nl> - } <nl> - <nl> - private void deleterollupjobs ( ) throws exception { <nl> - response response = adminclient ( ) . performrequest ( new request ( " get " , " / _xpack / rollup / job / _all " ) ) ; <nl> - map < string , object > jobs = entityasmap ( response ) ; <nl> - @ suppresswarnings ( " unchecked " ) <nl> - list < map < string , object > > jobconfigs = <nl> - ( list < map < string , object > > ) xcontentmapvalues . extractvalue ( " jobs " , jobs ) ; <nl> - <nl> - if ( jobconfigs = = null ) { <nl> - return ; <nl> - } <nl> - <nl> - for ( map < string , object > jobconfig : jobconfigs ) { <nl> - @ suppresswarnings ( " unchecked " ) <nl> - string jobid = ( string ) ( ( map < string , object > ) jobconfig . get ( " config " ) ) . get ( " id " ) ; <nl> - request request = new request ( " delete " , " / _xpack / rollup / job / " + jobid ) ; <nl> - request . addparameter ( " ignore " , " 404 " ) ; / / ignore num s because they imply someone was racing us to delete this <nl> - adminclient ( ) . performrequest ( request ) ; <nl> - } <nl> - } <nl> - <nl> - private void waitforpendingrolluptasks ( ) throws exception { <nl> - assertbusy ( ( ) - > { <nl> - try { <nl> - request request = new request ( " get " , " / _cat / tasks " ) ; <nl> - request . addparameter ( " detailed " , " true " ) ; <nl> - response response = adminclient ( ) . performrequest ( request ) ; <nl> - <nl> - try ( bufferedreader responsereader = new bufferedreader ( <nl> - new inputstreamreader ( response . getentity ( ) . getcontent ( ) , standardcharsets . utf_8 ) ) ) { <nl> - int activetasks = num ; <nl> - string line ; <nl> - stringbuilder tasksliststring = new stringbuilder ( ) ; <nl> - while ( ( line = responsereader . readline ( ) ) ! = null ) { <nl> - <nl> - / / we only care about rollup jobs , otherwise this fails too easily due to unrelated tasks <nl> - if ( line . startswith ( " xpack / rollup / job " ) = = true ) { <nl> - activetasks + + ; <nl> - tasksliststring . append ( line ) . append ( ' \n ' ) ; <nl> - } <nl> - } <nl> - assertequals ( activetasks + " active tasks found : \n " + tasksliststring , num , activetasks ) ; <nl> - } <nl> - } catch ( ioexception e ) { <nl> - / / throw an assertion error so we retry <nl> - throw new assertionerror ( " error getting active tasks list " , e ) ; <nl> - } <nl> - } ) ; <nl> - } <nl> - <nl> @ suppresswarnings ( " unused " ) <nl> public void testdeleterollupjob ( ) throws exception { <nl> resthighlevelclient client = highlevelclient ( ) ; <nl> mmm a / test / framework / src / main / java / org / elasticsearch / test / rest / esresttestcase . java <nl> ppp b / test / framework / src / main / java / org / elasticsearch / test / rest / esresttestcase . java <nl>
public class sslconfigurationreloadertests extends estestcase { <nl> try ( inputstream is = files . newinputstream ( keystorepath ) ) { <nl> keystore . load ( is , keystorepass . tochararray ( ) ) ; <nl> } <nl> - <nl> - / / https : / / github . com / elastic / elasticsearch / issues / 32276 <nl> - final sslcontext sslcontext = new sslcontextbuilder ( ) . useprotocol ( " tlsv1 . 2 " ) . loadkeymaterial ( keystore , keystorepass . tochararray ( ) ) <nl> + final sslcontext sslcontext = new sslcontextbuilder ( ) . loadkeymaterial ( keystore , keystorepass . tochararray ( ) ) <nl> . build ( ) ; <nl> mockwebserver server = new mockwebserver ( sslcontext , false ) ; <nl> server . enqueue ( new mockresponse ( ) . setresponsecode ( 200 ) . setbody ( " body " ) ) ; <nl>
public class sslconfigurationreloadertests extends estestcase { <nl> keystore . load ( null , password . tochararray ( ) ) ; <nl> keystore . setkeyentry ( " testnode_ec " , pemutils . readprivatekey ( keypath , password : : tochararray ) , password . tochararray ( ) , <nl> certparsingutils . readcertificates ( collections . singletonlist ( certpath ) ) ) ; <nl> - <nl> - / / https : / / github . com / elastic / elasticsearch / issues / 32276 <nl> - final sslcontext sslcontext = new sslcontextbuilder ( ) . useprotocol ( " tlsv1 . 2 " ) . loadkeymaterial ( keystore , password . tochararray ( ) ) <nl> + final sslcontext sslcontext = new sslcontextbuilder ( ) . loadkeymaterial ( keystore , password . tochararray ( ) ) <nl> . build ( ) ; <nl> mockwebserver server = new mockwebserver ( sslcontext , false ) ; <nl> server . enqueue ( new mockresponse ( ) . setresponsecode ( 200 ) . setbody ( " body " ) ) ; <nl>
import org . elasticsearch . test . essinglenodetestcase ; <nl>  <nl> import static org . hamcrest . matchers . equalto ; <nl>  <nl> - <nl> public class documentmapperparsertests extends essinglenodetestcase { <nl> public void testtypelevel ( ) throws exception { <nl> string mapping = strings . tostring ( xcontentfactory . jsonbuilder ( ) . startobject ( ) . startobject ( " type " ) <nl> mmm a / server / src / test / java / org / elasticsearch / index / mapper / documentmappermergetests . java <nl> ppp b / server / src / test / java / org / elasticsearch / index / mapper / documentmappertests . java <nl>
public class scriptservice extends abstractcomponent implements closeable , clust <nl> options = source . getoptions ( ) ; <nl> } <nl>  <nl> - <nl> - / / special exception to prevent expressions from compiling as update or mapping scripts <nl> - boolean expression = " expression " . equals ( lang ) ; <nl> - boolean notsupported = context . name . equals ( updatescript . context . name ) ; <nl> - if ( expression & & notsupported ) { <nl> - throw new unsupportedoperationexception ( " scripts of type [ " + script . gettype ( ) + " ] , " + <nl> - " operation [ " + context . name + " ] and lang [ " + lang + " ] are not supported " ) ; <nl> - } <nl> - <nl> scriptengine scriptengine = getengine ( lang ) ; <nl>  <nl> if ( istypeenabled ( type ) = = false ) {
<nl> * specific language governing permissions and limitations <nl> * under the license . <nl> * / <nl> - <nl>  <nl> package org . elasticsearch . ingest ; <nl>  <nl> mmm a / server / src / test / java / org / elasticsearch / ingest / configurationutilstests . java <nl> ppp b / server / src / test / java / org / elasticsearch / ingest / configurationutilstests . java <nl>
public class configurationutilstests extends estestcase { <nl> } <nl> } <nl>  <nl> - <nl> - public void testoptional_invalidtype ( ) { <nl> - list < string > val = configurationutils . readlist ( null , null , config , " int " ) ; <nl> - assertthat ( val , equalto ( collections . singletonlist ( 2 ) ) ) ; <nl> - } <nl> - <nl> public void testreadstringorintproperty ( ) { <nl> string val1 = configurationutils . readstringorintproperty ( null , null , config , " foo " , null ) ; <nl> string val2 = configurationutils . readstringorintproperty ( null , null , config , " num " , null ) ; <nl> mmm a / server / src / test / java / org / elasticsearch / ingest / ingestclientit . java <nl> ppp b / server / src / test / java / org / elasticsearch / ingest / ingestclientit . java <nl>
public class ingestclientit extends esintegtestcase { <nl>  <nl> @ override <nl> protected settings nodesettings ( int nodeordinal ) { <nl> - <nl> if ( nodeordinal % num = = num ) { <nl> return settings . builder ( ) . put ( " node . ingest " , false ) . put ( super . nodesettings ( nodeordinal ) ) . build ( ) ; <nl> }
public class commonanalysisplugin extends plugin implements analysisplugin , scri <nl> } <nl>  <nl> @ override <nl> - @ suppresswarnings ( " rawtypes " ) <nl> - public list < scriptcontext > getcontexts ( ) { <nl> + public list < scriptcontext < ? > > getcontexts ( ) { <nl> return collections . singletonlist ( analysispredicatescript . context ) ; <nl> } <nl>  <nl> mmm a / modules / lang - painless / src / main / java / org / elasticsearch / painless / painlessplugin . java <nl> ppp b / modules / lang - painless / src / main / java / org / elasticsearch / painless / painlessplugin . java <nl>
public final class createtokenresponse extends actionresponse implements toxcont <nl> out . writestring ( tokenstring ) ; <nl> out . writetimevalue ( expiresin ) ; <nl> out . writeoptionalstring ( scope ) ; <nl> - if ( out . getversion ( ) . onorafter ( version . v_7_0_0_alpha1 ) ) { <nl> + if ( out . getversion ( ) . onorafter ( version . v_6_5_0 ) ) { <nl> out . writeoptionalstring ( refreshtoken ) ; <nl> } else if ( out . getversion ( ) . onorafter ( version . v_6_2_0 ) ) { <nl> if ( refreshtoken = = null ) { <nl>
public final class createtokenresponse extends actionresponse implements toxcont <nl> tokenstring = in . readstring ( ) ; <nl> expiresin = in . readtimevalue ( ) ; <nl> scope = in . readoptionalstring ( ) ; <nl> - if ( in . getversion ( ) . onorafter ( version . v_7_0_0_alpha1 ) ) { <nl> + if ( in . getversion ( ) . onorafter ( version . v_6_5_0 ) ) { <nl> refreshtoken = in . readoptionalstring ( ) ; <nl> } else if ( in . getversion ( ) . onorafter ( version . v_6_2_0 ) ) { <nl> refreshtoken = in . readstring ( ) ;
public class rollupjobstatus implements task . status , persistenttaskstate { <nl> public rollupjobstatus ( streaminput in ) throws ioexception { <nl> state = indexerstate . fromstream ( in ) ; <nl> currentposition = in . readboolean ( ) ? new treemap < > ( in . readmap ( ) ) : null ; <nl> - if ( in . getversion ( ) . onorafter ( version . v_7_0_0_alpha1 ) ) { <nl> + if ( in . getversion ( ) . onorafter ( version . v_6_4_0 ) ) { <nl> upgradeddocumentid = in . readboolean ( ) ; <nl> } else { <nl> / / if we ' re getting this job from a pre - 6 . 4 . 0 node , <nl>
public class rollupjobstatus implements task . status , persistenttaskstate { <nl> if ( currentposition ! = null ) { <nl> out . writemap ( currentposition ) ; <nl> } <nl> - if ( out . getversion ( ) . onorafter ( version . v_7_0_0_alpha1 ) ) { <nl> + if ( out . getversion ( ) . onorafter ( version . v_6_4_0 ) ) { <nl> out . writeboolean ( upgradeddocumentid ) ; <nl> } <nl> } <nl> mmm a / x - pack / qa / full - cluster - restart / src / test / java / org / elasticsearch / xpack / restart / fullclusterrestartit . java <nl> ppp b / x - pack / qa / full - cluster - restart / src / test / java / org / elasticsearch / xpack / restart / fullclusterrestartit . java <nl>
if ( iseclipse = = false | | project . path = = " : server - tests " ) { <nl> integtest . mustrunafter test <nl> } <nl>  <nl> - <nl> - additionaltest ( ' testscriptdocvaluesmissingv6behaviour ' ) { <nl> - include ' * * / scriptdocvaluesmissingv6behaviourtests . class ' <nl> - systemproperty ' es . scripting . exception_for_missing_value ' , ' false ' <nl> - } <nl> - test { <nl> - / / these are tested explicitly in separate test tasks <nl> - exclude ' * * / * scriptdocvaluesmissingv6behaviourtests . class ' <nl> - }
post _xpack / ml / anomaly_detectors / _validate / detector <nl> } <nl> - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - <nl> / / console <nl> - <nl>  <nl> when the validation completes , you receive the following results : <nl> [ source , js ] <nl>
post _xpack / ml / anomaly_detectors / _validate <nl> } <nl> - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - <nl> / / console <nl> - <nl>  <nl> when the validation is complete , you receive the following results : <nl> [ source , js ] <nl>
public class geodistancesortbuilder extends sortbuilder < geodistancesortbuilder > <nl> nestedsort = in . readoptionalwriteable ( nestedsortbuilder : : new ) ; <nl> } <nl> validation = geovalidationmethod . readfromstream ( in ) ; <nl> - <nl> - if ( in . getversion ( ) . onorafter ( version . v_7_0_0_alpha1 ) ) { <nl> + if ( in . getversion ( ) . onorafter ( version . v_6_4_0 ) ) { <nl> ignoreunmapped = in . readboolean ( ) ; <nl> } <nl> } <nl>
public class geodistancesortbuilder extends sortbuilder < geodistancesortbuilder > <nl> out . writeoptionalwriteable ( nestedsort ) ; <nl> } <nl> validation . writeto ( out ) ; <nl> - <nl> - if ( out . getversion ( ) . onorafter ( version . v_7_0_0_alpha1 ) ) { <nl> + if ( out . getversion ( ) . onorafter ( version . v_6_4_0 ) ) { <nl> out . writeboolean ( ignoreunmapped ) ; <nl> } <nl> }
public class verifiererrormessagestests extends estestcase { <nl> assertequals ( " 1 : 32 : currently , only a single expression can be used with group by ; please select one of [ bool , keyword ] " , <nl> verify ( " select bool from test group by bool , keyword " ) ) ; <nl> } <nl> - <nl> - / / <nl> - <nl> - / / <nl> - / / regarding resolution <nl> - / / public void testgroupbyorderbykeyalias ( ) { <nl> - / / assertequals ( " 1 : 8 : cannot use field [ unsupported ] type [ ip_range ] as is unsupported " , <nl> - / / verify ( " select int i from test group by int order by i " ) ) ; <nl> - / / } <nl> - / / <nl> - / / public void testgroupbyalias ( ) { <nl> - / / assertequals ( " 1 : 8 : cannot use field [ unsupported ] type [ ip_range ] as is unsupported " , <nl> - / / verify ( " select int i from test group by i order by int " ) ) ; <nl> - / / } <nl> }
public class datatypeconversiontests extends estestcase { <nl> conversion conversion = datatypeconversion . conversionfor ( datatype . keyword , to ) ; <nl> assertnull ( conversion . convert ( null ) ) ; <nl>  <nl> - <nl> assertequals ( new datetime ( 1000l , datetimezone . utc ) , conversion . convert ( " 1970 - 01 - 01t00 : 00 : 01z " ) ) ; <nl> assertequals ( new datetime ( 1483228800000l , datetimezone . utc ) , conversion . convert ( " 2017 - 01 - 01t00 : 00 : 00z " ) ) ; <nl> assertequals ( new datetime ( 18000000l , datetimezone . utc ) , conversion . convert ( " 1970 - 01 - 01t00 : 00 : 00 - 05 : 00 " ) ) ; <nl> + <nl> + / / double check back and forth conversion <nl> + datetime dt = datetime . now ( datetimezone . utc ) ; <nl> + conversion forward = datatypeconversion . conversionfor ( datatype . date , datatype . keyword ) ; <nl> + conversion back = datatypeconversion . conversionfor ( datatype . keyword , datatype . date ) ; <nl> + assertequals ( dt , back . convert ( forward . convert ( dt ) ) ) ; <nl> exception e = expectthrows ( sqlillegalargumentexception . class , ( ) - > conversion . convert ( " 0xff " ) ) ; <nl> assertequals ( " cannot cast [ 0xff ] to [ date ] : invalid format : \ " 0xff \ " is malformed at \ " xff \ " " , e . getmessage ( ) ) ; <nl> }
public class smoketestwatchertestsuiteit extends esresttestcase { <nl> assertthat ( templateexistsresponse . getstatusline ( ) . getstatuscode ( ) , is ( 200 ) ) ; <nl> } <nl> } ) ; <nl> - <nl> - <nl> - assertok ( adminclient ( ) . performrequest ( " put " , " . watches " ) ) ; <nl> } <nl>  <nl> @ after
public class poststarttrialrequest extends masternoderequest < poststarttrialreque <nl>  <nl> @ override <nl> public void writeto ( streamoutput out ) throws ioexception { <nl> - <nl> - version version = version . v_7_0_0_alpha1 ; <nl> + version version = version . v_6_3_0 ; <nl> if ( out . getversion ( ) . onorafter ( version ) ) { <nl> super . writeto ( out ) ; <nl> out . writestring ( type ) ; <nl> mmm a / x - pack / plugin / core / src / main / java / org / elasticsearch / license / poststarttrialresponse . java <nl> ppp b / x - pack / plugin / core / src / main / java / org / elasticsearch / license / poststarttrialresponse . java <nl>
class poststarttrialresponse extends actionresponse { <nl> @ override <nl> public void readfrom ( streaminput in ) throws ioexception { <nl> status = in . readenum ( status . class ) ; <nl> - <nl> - if ( in . getversion ( ) . onorafter ( version . v_7_0_0_alpha1 ) ) { <nl> + if ( in . getversion ( ) . onorafter ( version . v_6_3_0 ) ) { <nl> acknowledgemessage = in . readoptionalstring ( ) ; <nl> int size = in . readvint ( ) ; <nl> map < string , string [ ] > acknowledgemessages = new hashmap < > ( size ) ; <nl>
class poststarttrialresponse extends actionresponse { <nl>  <nl> @ override <nl> public void writeto ( streamoutput out ) throws ioexception { <nl> - <nl> - version version = version . v_7_0_0_alpha1 ; <nl> + version version = version . v_6_3_0 ; <nl> if ( out . getversion ( ) . onorafter ( version ) ) { <nl> out . writeenum ( status ) ; <nl> out . writeoptionalstring ( acknowledgemessage ) ;
<nl> mmm <nl> setup : <nl> - skip : <nl> - version : " - num . 99 . 99 " # <nl> + version : " - num . 3 . 99 " <nl> reason : _ignored was added in num . 4 . 0 <nl>  <nl> - do :
public class transportbulkshardoperationsaction <nl> final bulkshardoperationsrequest request , final indexshard shard , final engine . operation . origin origin ) throws ioexception { <nl> translog . location location = null ; <nl> for ( final translog . operation operation : request . getoperations ( ) ) { <nl> - final engine . result result = shard . applytranslogoperation ( operation , origin , m - > { <nl> - <nl> - throw new mapperexception ( " dynamic mapping updates are not allowed in follow shards [ " + operation + " ] " ) ; <nl> - } ) ; <nl> + final engine . result result = shard . applytranslogoperation ( operation , origin ) ; <nl> assert result . getseqno ( ) = = operation . seqno ( ) ; <nl> - assert result . hasfailure ( ) = = false ; <nl> + assert result . getresulttype ( ) = = engine . result . type . success ; <nl> location = locationtosync ( location , result . gettransloglocation ( ) ) ; <nl> } <nl> assert request . getoperations ( ) . length = = num | | location ! = null ;
public class poststarttrialrequest extends masternoderequest < poststarttrialreque <nl> @ override <nl> public void readfrom ( streaminput in ) throws ioexception { <nl> super . readfrom ( in ) ; <nl> - <nl> - if ( in . getversion ( ) . onorafter ( version . v_7_0_0_alpha1 ) ) { <nl> + if ( in . getversion ( ) . onorafter ( version . v_6_3_0 ) ) { <nl> type = in . readstring ( ) ; <nl> } else { <nl> type = " trial " ; <nl>
public class poststarttrialrequest extends masternoderequest < poststarttrialreque <nl> @ override <nl> public void writeto ( streamoutput out ) throws ioexception { <nl> super . writeto ( out ) ; <nl> - <nl> - version version = version . v_7_0_0_alpha1 ; <nl> + version version = version . v_6_3_0 ; <nl> if ( out . getversion ( ) . onorafter ( version ) ) { <nl> out . writestring ( type ) ; <nl> } else {
public abstract class streaminput extends inputstream { <nl> switch ( key ) { <nl> case num : <nl> final int ord = readvint ( ) ; <nl> - <nl> - assert version . current . major < num ; <nl> - if ( ord = = num ) { <nl> - final elasticsearchexception ex = new elasticsearchexception ( this ) ; <nl> - final boolean isexecutorshutdown = readboolean ( ) ; <nl> - return ( t ) new esrejectedexecutionexception ( ex . getmessage ( ) , isexecutorshutdown ) ; <nl> - } <nl> return ( t ) elasticsearchexception . readexception ( this , ord ) ; <nl> case num : <nl> string msg1 = readoptionalstring ( ) ; <nl> mmm a / server / src / main / java / org / elasticsearch / common / io / stream / streamoutput . java <nl> ppp b / server / src / main / java / org / elasticsearch / common / io / stream / streamoutput . java <nl>
public abstract class streamoutput extends outputstream { <nl> } else if ( throwable instanceof ioexception ) { <nl> writevint ( 17 ) ; <nl> } else if ( throwable instanceof esrejectedexecutionexception ) { <nl> - <nl> - assert version . current . major < num ; <nl> - if ( version . before ( version . v_7_0_0_alpha1 ) ) { <nl> - / * <nl> - * this is a backwards compatibility layer when speaking to nodes that still treated esrejectedexceutionexception as an <nl> - * instance of elasticsearchexception . as such , we serialize this in a way that the receiving node would read this as an <nl> - * esrejectedexecutionexception . <nl> - * / <nl> - final elasticsearchexception ex = new elasticsearchexception ( throwable . getmessage ( ) ) ; <nl> - writevint ( 0 ) ; <nl> - writevint ( 59 ) ; <nl> - ex . writeto ( this ) ; <nl> - writeboolean ( ( ( esrejectedexecutionexception ) throwable ) . isexecutorshutdown ( ) ) ; <nl> - return ; <nl> - } else { <nl> - writevint ( 18 ) ; <nl> - writeboolean ( ( ( esrejectedexecutionexception ) throwable ) . isexecutorshutdown ( ) ) ; <nl> - writecause = false ; <nl> - } <nl> + writevint ( 18 ) ; <nl> + writeboolean ( ( ( esrejectedexecutionexception ) throwable ) . isexecutorshutdown ( ) ) ; <nl> + writecause = false ; <nl> } else { <nl> final elasticsearchexception ex ; <nl> if ( throwable instanceof elasticsearchexception & & elasticsearchexception . isregistered ( throwable . getclass ( ) , version ) ) {
public class indexauditupgradeit extends abstractupgradetestcase { <nl> assumetrue ( " only runs against old cluster " , clustertype = = cluster_type . old ) ; <nl> assertbusy ( ( ) - > { <nl> assertauditdocsexist ( ) ; <nl> - assertnumuniquenodenamebuckets ( 0 ) ; <nl> + assertnumuniquenodenamebuckets ( 2 ) ; <nl> } ) ; <nl> } <nl>  <nl>
public class indexauditupgradeit extends abstractupgradetestcase { <nl> assumetrue ( " only runs against mixed cluster " , clustertype = = cluster_type . mixed ) ; <nl> assertbusy ( ( ) - > { <nl> assertauditdocsexist ( ) ; <nl> - <nl> - assertnumuniquenodenamebuckets ( 0 ) ; <nl> + assertnumuniquenodenamebuckets ( 2 ) ; <nl> } ) ; <nl> } <nl>  <nl>
public class indexauditupgradeit extends abstractupgradetestcase { <nl> assumetrue ( " only runs against upgraded cluster " , clustertype = = cluster_type . upgraded ) ; <nl> assertbusy ( ( ) - > { <nl> assertauditdocsexist ( ) ; <nl> - <nl> - assertnumuniquenodenamebuckets ( 2 ) ; <nl> + assertnumuniquenodenamebuckets ( 4 ) ; <nl> } ) ; <nl> }
opened again before analyzing further data . <nl>  <nl> you must have ` manage_ml ` , or ` manage ` cluster privileges to use this api . <nl> for more information , see { xpack - ref } / security - privileges . html [ security privileges ] . <nl> - / / < < privileges - list - cluster > > . <nl>  <nl>  <nl> = = = = examples <nl>  <nl> - the following example flushes the ` farequote ` job : <nl> + the following example flushes the ` total - requests ` job : <nl>  <nl> [ source , js ] <nl> - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - <nl> - post _xpack / ml / anomaly_detectors / farequote / _flush <nl> + post _xpack / ml / anomaly_detectors / total - requests / _flush <nl> { <nl> " calc_interim " : true <nl> } <nl> - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - <nl> / / console <nl> - <nl> + <nl> + when the operation succeeds , you receive the following results : <nl> + [ source , js ] <nl> + - - - - <nl> + { <nl> + " flushed " : true , <nl> + " last_finalized_bucket_end " : num <nl> + } <nl> + - - - - <nl> + / / testresponse [ s / " last_finalized_bucket_end " : num / " last_finalized_bucket_end " : $ body . last_finalized_bucket_end / ] <nl> + <nl> + the ` last_finalized_bucket_end ` provides the timestamp ( in <nl> + milliseconds - since - the - epoch ) of the end of the last bucket that was processed . <nl> + <nl> + if you want to flush the job to a specific timestamp , you can use the <nl> + ` advance_time ` or ` skip_time ` parameters . for example , to advance to num am gmt <nl> + on january num , num : <nl> + <nl> + [ source , js ] <nl> + - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - <nl> + post _xpack / ml / anomaly_detectors / total - requests / _flush <nl> + { <nl> + " advance_time " : " 1514804400 " <nl> + } <nl> + - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - <nl> + / / console <nl> + / / test [ setup : server_metrics_openjob ] <nl>  <nl> when the operation succeeds , you receive the following results : <nl> [ source , js ] <nl> - - - - <nl> { <nl> - " flushed " : true <nl> + " flushed " : true , <nl> + " last_finalized_bucket_end " : num <nl> } <nl> - - - - <nl> + / / testresponse
task verifyversions { <nl> * after the backport of the backcompat code is complete . <nl> * / <nl> allprojects { <nl> - <nl> - ext . bwc_tests_enabled = false <nl> + ext . bwc_tests_enabled = true <nl> } <nl>  <nl> task verifybwctestsenabled {
sourcesets . test . java { <nl> srcdir ' . . / . . / license - tools / src / main / java ' <nl> } <nl>  <nl> - <nl> - / / assemble the api jar for the transport - client and extension authors ; this jar is the core jar by another name <nl> - project . afterevaluate { <nl> - task apijar { <nl> - dependson ( ' generatepomfileforapijarpublication ' , project . jar ) <nl> - dofirst { <nl> - path jarfile = project . jar . outputs . files . singlefile . topath ( ) <nl> - string apifilename = jarfile . filename . tostring ( ) . replace ( " core - $ { project . version } " , " api - $ { project . version } " ) <nl> - files . copy ( jarfile , jarfile . resolvesibling ( apifilename ) , standardcopyoption . replace_existing ) <nl> - <nl> - string pomfilename = jarfile . filename . tostring ( ) . replace ( ' . jar ' , ' . pom ' ) <nl> - string apipomfilename = apifilename . replace ( ' . jar ' , ' . pom ' ) <nl> - files . copy ( jarfile . resolvesibling ( pomfilename ) , jarfile . resolvesibling ( apipomfilename ) , <nl> - standardcopyoption . replace_existing ) <nl> - } <nl> - } <nl> - assemble . dependson ( apijar ) <nl> - project . publishing { <nl> - publications { <nl> - apijar ( mavenpublication ) { <nl> - from project . components . java <nl> - artifactid = ' x - pack - api ' <nl> - pom . withxml { xmlprovider xml - > <nl> - node root = xml . asnode ( ) <nl> - root . appendnode ( ' name ' , project . pluginproperties . extension . name ) <nl> - root . appendnode ( ' description ' , project . pluginproperties . extension . description ) <nl> - } <nl> - } <nl> - } <nl> - } <nl> - } <nl> - <nl> test { <nl> / * <nl> * we have to disable setting the number of available processors as tests in the same jvm randomize processors and will step on each <nl> mmm a / transport - client / build . gradle <nl> ppp b / transport - client / build . gradle <nl>
case $ key in <nl> " - dtests . badapples = true " <nl> ) <nl> ; ; <nl> - smoketestsql ) # <nl> - gradle_cli_args = ( <nl> - " - - info " <nl> - " - pplugin / sql " <nl> - " check " <nl> - " : x - pack - elasticsearch : plugin : precommit " <nl> - " : x - pack - elasticsearch : qa : sql : check " <nl> - " : x - pack - elasticsearch : qa : sql : multinode : check " <nl> - " : x - pack - elasticsearch : qa : sql : no - security : check " <nl> - " : x - pack - elasticsearch : qa : sql : security : check " <nl> - " : x - pack - elasticsearch : qa : sql : security : no - ssl : check " <nl> - " : x - pack - elasticsearch : qa : sql : security : ssl : check " <nl> - ) <nl> - ; ; <nl> releasetest ) <nl> gradle_cli_args = ( <nl> " - - info " <nl>
public class ccr extends plugin implements actionplugin , persistenttaskplugin , e <nl> this . enabled = ccr_enabled_setting . get ( settings ) ; <nl> } <nl>  <nl> - <nl> - / / persistenttaskplugin # getpersistenttasksexecutor ( . . . ) signature . <nl> - @ override <nl> - public collection < object > createcomponents ( client client , clusterservice clusterservice , threadpool threadpool , <nl> - resourcewatcherservice resourcewatcherservice , scriptservice scriptservice , <nl> - namedxcontentregistry xcontentregistry , environment environment , <nl> - nodeenvironment nodeenvironment , namedwriteableregistry namedwriteableregistry ) { <nl> - this . client = client ; <nl> - this . threadpool = threadpool ; <nl> - return super . createcomponents ( client , clusterservice , threadpool , resourcewatcherservice , scriptservice , <nl> - xcontentregistry , environment , nodeenvironment , namedwriteableregistry ) ; <nl> - } <nl> - <nl> @ override <nl> - public list < persistenttasksexecutor < ? > > getpersistenttasksexecutor ( clusterservice clusterservice ) { <nl> + public list < persistenttasksexecutor < ? > > getpersistenttasksexecutor ( clusterservice clusterservice , <nl> + threadpool threadpool , client client ) { <nl> return collections . singletonlist ( new shardfollowtasksexecutor ( settings , client , threadpool ) ) ; <nl> }
esplugin { <nl> noticefile project ( ' : x - pack - elasticsearch ' ) . file ( ' notice . txt ' ) <nl> } <nl>  <nl> + configurations { <nl> + / / bundles the sql - cli . jar into the distribution <nl> + bin <nl> + } <nl> + <nl> archivesbasename = ' x - pack - sql ' <nl>  <nl> - <nl> integtest . enabled = false <nl>  <nl> dependencies { <nl>
dependencies { <nl> provided project ( path : ' : plugins : transport - nio ' , configuration : ' runtime ' ) <nl>  <nl> testcompile project ( path : xpackmodule ( ' monitoring ' ) ) <nl> - <nl> - testcompile project ( path : ' : x - pack - elasticsearch : plugin : sql : sql - proto ' ) <nl> + testcompile project ( path : xpackmodule ( ' sql : sql - proto ' ) ) <nl>  <nl> testcompile project ( path : xpackmodule ( ' core ' ) , configuration : ' testartifacts ' )
compiletestjava . options . compilerargs < < " - xlint : - cast , - deprecation , - rawtypes , - tr <nl> * configuration options based on their name . <nl> * / <nl> subprojects { <nl> - <nl> - ext . bwc_tests_enabled = false <nl> matcher m = project . name = ~ / with ( out ) ? - system - key / <nl> if ( false = = m . matches ( ) ) { <nl> throw new invaliduserdataexception ( " invalid project name [ $ { project . name } ] " ) <nl> mmm a / qa / rolling - upgrade / src / test / java / org / elasticsearch / upgrades / tokenbackwardscompatibilityit . java <nl> ppp b / qa / rolling - upgrade / src / test / java / org / elasticsearch / upgrades / tokenbackwardscompatibilityit . java <nl>
esplugin { <nl> } <nl> archivesbasename = ' x - pack - ccr ' <nl>  <nl> - <nl> licenseheaders . enabled = false <nl>  <nl> integtest . enabled = false <nl>
esplugin { <nl> } <nl> archivesbasename = ' x - pack - deprecation ' <nl>  <nl> - <nl> licenseheaders . enabled = false <nl>  <nl> integtest . enabled = false <nl> mmm a / plugin / graph / build . gradle <nl> ppp b / plugin / graph / build . gradle <nl>
esplugin { <nl> } <nl> archivesbasename = ' x - pack - graph ' <nl>  <nl> - <nl> licenseheaders . enabled = false <nl>  <nl> integtest . enabled = false <nl> mmm a / plugin / logstash / build . gradle <nl> ppp b / plugin / logstash / build . gradle <nl>
esplugin { <nl> } <nl> archivesbasename = ' x - pack - logstash ' <nl>  <nl> - <nl> licenseheaders . enabled = false <nl>  <nl> integtest . enabled = false <nl> mmm a / plugin / ml / build . gradle <nl> ppp b / plugin / ml / build . gradle <nl>
esplugin { <nl> } <nl> archivesbasename = ' x - pack - ml ' <nl>  <nl> - <nl> licenseheaders . enabled = false <nl>  <nl> integtest . enabled = false <nl> mmm a / plugin / monitoring / build . gradle <nl> ppp b / plugin / monitoring / build . gradle <nl>
esplugin { <nl> } <nl> archivesbasename = ' x - pack - monitoring ' <nl>  <nl> - <nl> licenseheaders . enabled = false <nl>  <nl> integtest . enabled = false <nl> mmm a / plugin / security / build . gradle <nl> ppp b / plugin / security / build . gradle <nl>
esplugin { <nl>  <nl> archivesbasename = ' x - pack - security ' <nl>  <nl> - <nl> licenseheaders . enabled = false <nl>  <nl> integtest . enabled = false <nl> mmm a / plugin / upgrade / build . gradle <nl> ppp b / plugin / upgrade / build . gradle <nl>
esplugin { <nl> } <nl>  <nl> archivesbasename = ' x - pack - upgrade ' <nl> - <nl> test . enabled = false <nl> licenseheaders . enabled = false <nl>  <nl> mmm a / plugin / watcher / build . gradle <nl> ppp b / plugin / watcher / build . gradle <nl>
esplugin { <nl>  <nl> archivesbasename = ' x - pack - watcher ' <nl>  <nl> - <nl> licenseheaders . enabled = false <nl>  <nl> integtest . enabled = false
task downloadmachinelearningsnapshot { <nl> } <nl> dofirst { <nl> snapshotzip . parentfile . mkdirs ( ) <nl> - s3object zip = getzip ( ) <nl> - <nl> - inputstream zipstream = zip . getobjectcontent ( ) <nl> - try { <nl> - project . delete ( snapshotzip ) <nl> - files . copy ( zipstream , snapshotzip . topath ( ) ) <nl> - } finally { <nl> - zipstream . close ( ) <nl> - } <nl> + getzip ( snapshotzip ) <nl> } <nl> }
public class analysisconfig implements toxcontentobject , writeable { <nl> bucketspan = new timevalue ( in ) ; <nl> categorizationfieldname = in . readoptionalstring ( ) ; <nl> categorizationfilters = in . readboolean ( ) ? in . readlist ( streaminput : : readstring ) : null ; <nl> - <nl> - if ( in . getversion ( ) . onorafter ( version . v_7_0_0_alpha1 ) ) { <nl> + if ( in . getversion ( ) . onorafter ( version . v_6_2_0 ) ) { <nl> categorizationanalyzerconfig = in . readoptionalwriteable ( categorizationanalyzerconfig : : new ) ; <nl> } else { <nl> categorizationanalyzerconfig = null ; <nl>
public class analysisconfig implements toxcontentobject , writeable { <nl> } else { <nl> out . writeboolean ( false ) ; <nl> } <nl> - <nl> - if ( out . getversion ( ) . onorafter ( version . v_7_0_0_alpha1 ) ) { <nl> + if ( out . getversion ( ) . onorafter ( version . v_6_2_0 ) ) { <nl> out . writeoptionalwriteable ( categorizationanalyzerconfig ) ; <nl> } <nl> out . writeoptionalwriteable ( latency ) ;
task verifyversions { <nl> * after the backport of the backcompat code is complete . <nl> * / <nl> allprojects { <nl> - <nl> - ext . bwc_tests_enabled = false <nl> + ext . bwc_tests_enabled = true <nl> } <nl>  <nl> task verifybwctestsenabled {
public abstract class estestcase extends lucenetestcase { <nl>  <nl> @ beforeclass <nl> public static void setusenio ( ) throws exception { <nl> - / / usenio = randomboolean ( ) ; <nl> - <nl> - usenio = false ; <nl> + usenio = randomboolean ( ) ; <nl> } <nl>  <nl> public static string gettesttransporttype ( ) {
<nl> " type " : " boolean " , <nl> " description " : " specify whether the operation should only expunge deleted documents " <nl> } , <nl> - " operation_threading " : { <nl> - " description " : " <nl> - } , <nl> " wait_for_merge " : { <nl> " type " : " boolean " , <nl> " description " : " specify whether the request should block until the merge process is finished ( default : true ) " <nl> mmm a / rest - api - spec / src / main / resources / rest - api - spec / api / indices . segments . json <nl> ppp b / rest - api - spec / src / main / resources / rest - api - spec / api / indices . segments . json <nl>
<nl> " default " : " open " , <nl> " description " : " whether to expand wildcard expression to concrete indices that are open , closed or both . " <nl> } , <nl> - " operation_threading " : { <nl> - " description " : " <nl> - } , <nl> " verbose " : { <nl> " type " : " boolean " , <nl> " description " : " includes detailed memory usage by lucene . " , <nl> mmm a / rest - api - spec / src / main / resources / rest - api - spec / api / indices . shard_stores . json <nl> ppp b / rest - api - spec / src / main / resources / rest - api - spec / api / indices . shard_stores . json <nl>
<nl> " options " : [ " open " , " closed " , " none " , " all " ] , <nl> " default " : " open " , <nl> " description " : " whether to expand wildcard expression to concrete indices that are open , closed or both . " <nl> - } , <nl> - " operation_threading " : { <nl> - " description " : " <nl> } <nl> } <nl> } , <nl> mmm a / rest - api - spec / src / main / resources / rest - api - spec / api / indices . validate_query . json <nl> ppp b / rest - api - spec / src / main / resources / rest - api - spec / api / indices . validate_query . json <nl>
<nl> " default " : " open " , <nl> " description " : " whether to expand wildcard expression to concrete indices that are open , closed or both . " <nl> } , <nl> - " operation_threading " : { <nl> - " description " : " <nl> - } , <nl> " q " : { <nl> " type " : " string " , <nl> " description " : " query in the lucene query string syntax "
<nl> - / * <nl> - * licensed to elasticsearch under one or more contributor <nl> - * license agreements . see the notice file distributed with <nl> - * this work for additional information regarding copyright <nl> - * ownership . elasticsearch licenses this file to you under <nl> - * the apache license , version num . 0 ( the " license " ) ; you may <nl> - * not use this file except in compliance with the license . <nl> - * you may obtain a copy of the license at <nl> - * <nl> - * http : / / www . apache . org / licenses / license - 2 . 0 <nl> - * <nl> - * unless required by applicable law or agreed to in writing , <nl> - * software distributed under the license is distributed on an <nl> - * " as is " basis , without warranties or conditions of any <nl> - * kind , either express or implied . see the license for the <nl> - * specific language governing permissions and limitations <nl> - * under the license . <nl> - * / <nl> - package org . elasticsearch . indices . analysis ; <nl> - <nl> - import org . apache . lucene . analysis . lowercasefilter ; <nl> - import org . apache . lucene . analysis . tokenstream ; <nl> - import org . elasticsearch . version ; <nl> - import org . elasticsearch . index . analysis . multitermawarecomponent ; <nl> - import org . elasticsearch . index . analysis . tokenfilterfactory ; <nl> - import org . elasticsearch . indices . analysis . prebuiltcachefactory . cachingstrategy ; <nl> - <nl> - import java . util . locale ; <nl> - <nl> - public enum prebuilttokenfilters { <nl> - <nl> - lowercase ( cachingstrategy . lucene ) { <nl> - @ override <nl> - public tokenstream create ( tokenstream tokenstream , version version ) { <nl> - return new lowercasefilter ( tokenstream ) ; <nl> - } <nl> - @ override <nl> - protected boolean ismultitermaware ( ) { <nl> - return true ; <nl> - } <nl> - } ; <nl> - <nl> - protected boolean ismultitermaware ( ) { <nl> - return false ; <nl> - } <nl> - <nl> - public abstract tokenstream create ( tokenstream tokenstream , version version ) ; <nl> - <nl> - protected final prebuiltcachefactory . prebuiltcache < tokenfilterfactory > cache ; <nl> - <nl> - <nl> - private final cachingstrategy cachingstrategy ; <nl> - prebuilttokenfilters ( cachingstrategy cachingstrategy ) { <nl> - this . cachingstrategy = cachingstrategy ; <nl> - cache = prebuiltcachefactory . getcache ( cachingstrategy ) ; <nl> - } <nl> - <nl> - public cachingstrategy getcachingstrategy ( ) { <nl> - return cachingstrategy ; <nl> - } <nl> - <nl> - private interface multitermawaretokenfilterfactory extends tokenfilterfactory , multitermawarecomponent { } <nl> - <nl> - public synchronized tokenfilterfactory gettokenfilterfactory ( final version version ) { <nl> - tokenfilterfactory factory = cache . get ( version ) ; <nl> - if ( factory = = null ) { <nl> - final string finalname = name ( ) . tolowercase ( locale . root ) ; <nl> - if ( ismultitermaware ( ) ) { <nl> - factory = new multitermawaretokenfilterfactory ( ) { <nl> - @ override <nl> - public string name ( ) { <nl> - return finalname ; <nl> - } <nl> - <nl> - @ override <nl> - public tokenstream create ( tokenstream tokenstream ) { <nl> - return prebuilttokenfilters . this . create ( tokenstream , version ) ; <nl> - } <nl> - <nl> - @ override <nl> - public object getmultitermcomponent ( ) { <nl> - return this ; <nl> - } <nl> - } ; <nl> - } else { <nl> - factory = new tokenfilterfactory ( ) { <nl> - @ override <nl> - public string name ( ) { <nl> - return finalname ; <nl> - } <nl> - <nl> - @ override <nl> - public tokenstream create ( tokenstream tokenstream ) { <nl> - return prebuilttokenfilters . this . create ( tokenstream , version ) ; <nl> - } <nl> - } ; <nl> - } <nl> - cache . put ( version , factory ) ; <nl> - } <nl> - <nl> - return factory ; <nl> - } <nl> - }
case $ key in <nl> " - dtests . badapples = true " <nl> ) <nl> ; ; <nl> - smoketestsql ) # <nl> - gradle_cli_args = ( <nl> - " - - info " <nl> - " - psql " <nl> - " check " <nl> - " : x - pack - elasticsearch : plugin : precommit " <nl> - " : x - pack - elasticsearch : qa : sql : check " <nl> - " : x - pack - elasticsearch : qa : sql : multinode : check " <nl> - " : x - pack - elasticsearch : qa : sql : no - security : check " <nl> - " : x - pack - elasticsearch : qa : sql : security : check " <nl> - " : x - pack - elasticsearch : qa : sql : security : no - ssl : check " <nl> - " : x - pack - elasticsearch : qa : sql : security : ssl : check " <nl> - ) <nl> - ; ; <nl> releasetest ) <nl> gradle_cli_args = ( <nl> " - - info " <nl>
include : : { es - repo - dir } / reference / index - shared3 . asciidoc [ ] <nl> : edit_url ! : <nl> include : : sql / index . asciidoc [ ] <nl> include : : monitoring / index . asciidoc [ ] <nl> - include : : rest - api / index . asciidoc [ ] <nl>  <nl> - # <nl> - # tracked by https : / / github . com / elastic / x - pack - elasticsearch / issues / 3084 <nl> + : edit_url ! : <nl> + include : : rest - api / index . asciidoc [ ] <nl>  <nl> + : edit_url ! : <nl> include : : commands / index . asciidoc [ ] <nl>  <nl> : edit_url :
public class geoshapequerybuilder extends abstractquerybuilder < geoshapequerybuil <nl> } else { <nl> throw new queryshardexception ( context , " failed to find geo_shape field [ " + fieldname + " ] " ) ; <nl> } <nl> - } <nl> - <nl> - <nl> - if ( ! ( fieldtype instanceof geoshapefieldmapper . geoshapefieldtype ) ) { <nl> - throw new queryshardexception ( context , " field [ " + fieldname + " ] is not a geo_shape " ) ; <nl> + } else if ( fieldtype . typename ( ) . equals ( geoshapefieldmapper . content_type ) = = false ) { <nl> + throw new queryshardexception ( context , <nl> + " field [ " + fieldname + " ] is not of type [ geo_shape ] but of type [ " + fieldtype . typename ( ) + " ] " ) ; <nl> } <nl>  <nl> final geoshapefieldmapper . geoshapefieldtype shapefieldtype = ( geoshapefieldmapper . geoshapefieldtype ) fieldtype ; <nl> mmm a / core / src / test / java / org / elasticsearch / index / query / geoshapequerybuildertests . java <nl> ppp b / core / src / test / java / org / elasticsearch / index / query / geoshapequerybuildertests . java <nl>
create table mock ( <nl> is_autoincrement varchar , <nl> is_generatedcolumn varchar <nl> ) as <nl> - select ' ' , ' test1 ' , ' name ' , num , ' varchar ' , num , null , null , <nl> - num , - - <nl> + select ' ' , ' test1 ' , ' name ' , num , ' varchar ' , num , null , null , null , <nl> num , - - columnnullable <nl> null , null , null , null , null , num , ' yes ' , null , null , null , null , ' ' , ' ' <nl> from dual <nl> union all <nl> - select ' ' , ' test2 ' , ' date ' , num , ' timestamp ' , num , null , null , <nl> - num , <nl> + select ' ' , ' test2 ' , ' date ' , num , ' timestamp ' , num , null , null , null , <nl> num , - - columnnullable <nl> null , null , null , null , null , num , ' yes ' , null , null , null , null , ' ' , ' ' <nl> from dual <nl> union all <nl> - select ' ' , ' test2 ' , ' number ' , - 5 , ' bigint ' , num , null , null , <nl> - num , <nl> + select ' ' , ' test2 ' , ' float ' , num , ' real ' , num , null , null , num , <nl> num , - - columnnullable <nl> null , null , null , null , null , num , ' yes ' , null , null , null , null , ' ' , ' ' <nl> from dual <nl> + union all <nl> + select ' ' , ' test2 ' , ' number ' , - 5 , ' bigint ' , num , null , null , num , <nl> + num , - - columnnullable <nl> + null , null , null , null , null , num , ' yes ' , null , null , null , null , ' ' , ' ' <nl> + from dual <nl> ; <nl> mmm a / sql / jdbc / src / main / java / org / elasticsearch / xpack / sql / jdbc / jdbc / jdbcdatabasemetadata . java <nl> ppp b / sql / jdbc / src / main / java / org / elasticsearch / xpack / sql / jdbc / jdbc / jdbcdatabasemetadata . java <nl>
the job is ready to resume its analysis from where it left off , once new data is <nl> you must have ` manage_ml ` , or ` manage ` cluster privileges to use this api . <nl> for more information , see <nl> { xpack - ref } / security - privileges . html [ security privileges ] . <nl> - / / < < privileges - list - cluster > > . <nl>  <nl>  <nl> = = = = examples <nl>  <nl> - the following example opens the ` event_rate ` job and sets an optional property : <nl> + the following example opens the ` total - requests ` job and sets an optional <nl> + property : <nl>  <nl> [ source , js ] <nl> - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - <nl> - post _xpack / ml / anomaly_detectors / event_rate / _open <nl> + post _xpack / ml / anomaly_detectors / total - requests / _open <nl> { <nl> " timeout " : " 35m " <nl> } <nl> - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - <nl> / / console <nl> - <nl>  <nl> when the job opens , you receive the following results : <nl> [ source , js ] <nl>
the following example starts the ` datafeed - it - ops - kpi ` { dfeed } : <nl>  <nl> [ source , js ] <nl> - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - <nl> - post _xpack / ml / datafeeds / datafeed - it - ops - kpi / _start <nl> + post _xpack / ml / datafeeds / datafeed - total - requests / _start <nl> { <nl> " start " : " 2017 - 04 - 07t18 : 22 : 16z " <nl> } <nl> - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - <nl> / / console <nl> - <nl>  <nl> when the { dfeed } starts , you receive the following results : <nl> [ source , js ] <nl>
for more information , see <nl>  <nl> = = = = examples <nl>  <nl> - the following example stops the ` datafeed - it - ops - kpi ` { dfeed } : <nl> + the following example stops the ` datafeed - total - requests ` { dfeed } : <nl>  <nl> [ source , js ] <nl> - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - <nl> - post _xpack / ml / datafeeds / datafeed - it - ops - kpi / _stop <nl> + post _xpack / ml / datafeeds / datafeed - total - requests / _stop <nl> { <nl> " timeout " : " 30s " <nl> } <nl> - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - <nl> / / console <nl> - <nl>  <nl> when the { dfeed } stops , you receive the following results : <nl> [ source , js ] <nl>
class combineddeletionpolicy extends indexdeletionpolicy { <nl> } <nl>  <nl> private void setlastcommittedtransloggeneration ( list < ? extends indexcommit > commits ) throws ioexception { <nl> - / / we need to keep translog since the smallest translog generation of un - deleted commits . <nl> - / / however , there are commits that are not deleted just because they are being snapshotted ( rather than being kept by the policy ) . <nl> - <nl> - long minrequiredgen = long . max_value ; <nl> - for ( indexcommit indexcommit : commits ) { <nl> - if ( indexcommit . isdeleted ( ) = = false ) { <nl> - long transloggen = long . parselong ( indexcommit . getuserdata ( ) . get ( translog . translog_generation_key ) ) ; <nl> - minrequiredgen = math . min ( transloggen , minrequiredgen ) ; <nl> - } <nl> - } <nl> - assert minrequiredgen ! = long . max_value : " all commits are deleted " ; <nl> - translogdeletionpolicy . setmintransloggenerationforrecovery ( minrequiredgen ) ; <nl> + / / when opening an existing lucene index , we currently always open the last commit . <nl> + / / we therefore use the translog gen as the one that will be required for recovery <nl> + final indexcommit indexcommit = commits . get ( commits . size ( ) - num ) ; <nl> + assert indexcommit . isdeleted ( ) = = false : " last commit is deleted " ; <nl> + long mingen = long . parselong ( indexcommit . getuserdata ( ) . get ( translog . translog_generation_key ) ) ; <nl> + translogdeletionpolicy . setmintransloggenerationforrecovery ( mingen ) ; <nl> } <nl>  <nl> public snapshotdeletionpolicy getindexdeletionpolicy ( ) { <nl> mmm a / core / src / test / java / org / elasticsearch / index / engine / combineddeletionpolicytests . java <nl> ppp b / core / src / test / java / org / elasticsearch / index / engine / combineddeletionpolicytests . java <nl>
public class job extends abstractdiffable < job > implements writeable , toxcontento <nl> createtime = new date ( in . readvlong ( ) ) ; <nl> finishedtime = in . readboolean ( ) ? new date ( in . readvlong ( ) ) : null ; <nl> lastdatatime = in . readboolean ( ) ? new date ( in . readvlong ( ) ) : null ; <nl> - <nl> - if ( in . getversion ( ) . onorafter ( version . v_7_0_0_alpha1 ) ) { <nl> + if ( in . getversion ( ) . onorafter ( version . v_6_1_0 ) ) { <nl> establishedmodelmemory = in . readoptionallong ( ) ; <nl> } else { <nl> establishedmodelmemory = null ; <nl>
public class job extends abstractdiffable < job > implements writeable , toxcontento <nl> } else { <nl> out . writeboolean ( false ) ; <nl> } <nl> - <nl> - if ( out . getversion ( ) . onorafter ( version . v_7_0_0_alpha1 ) ) { <nl> + if ( out . getversion ( ) . onorafter ( version . v_6_1_0 ) ) { <nl> out . writeoptionallong ( establishedmodelmemory ) ; <nl> } <nl> analysisconfig . writeto ( out ) ; <nl>
public class job extends abstractdiffable < job > implements writeable , toxcontento <nl> createtime = in . readboolean ( ) ? new date ( in . readvlong ( ) ) : null ; <nl> finishedtime = in . readboolean ( ) ? new date ( in . readvlong ( ) ) : null ; <nl> lastdatatime = in . readboolean ( ) ? new date ( in . readvlong ( ) ) : null ; <nl> - <nl> - if ( in . getversion ( ) . onorafter ( version . v_7_0_0_alpha1 ) ) { <nl> + if ( in . getversion ( ) . onorafter ( version . v_6_1_0 ) ) { <nl> establishedmodelmemory = in . readoptionallong ( ) ; <nl> } <nl> analysisconfig = in . readoptionalwriteable ( analysisconfig : : new ) ; <nl>
public class job extends abstractdiffable < job > implements writeable , toxcontento <nl> } else { <nl> out . writeboolean ( false ) ; <nl> } <nl> - <nl> - if ( out . getversion ( ) . onorafter ( version . v_7_0_0_alpha1 ) ) { <nl> + if ( out . getversion ( ) . onorafter ( version . v_6_1_0 ) ) { <nl> out . writeoptionallong ( establishedmodelmemory ) ; <nl> } <nl> out . writeoptionalwriteable ( analysisconfig ) ; <nl> mmm a / plugin / src / main / java / org / elasticsearch / xpack / ml / job / config / jobupdate . java <nl> ppp b / plugin / src / main / java / org / elasticsearch / xpack / ml / job / config / jobupdate . java <nl>
public class jobupdate implements writeable , toxcontentobject { <nl> } <nl> customsettings = in . readmap ( ) ; <nl> modelsnapshotid = in . readoptionalstring ( ) ; <nl> - <nl> - if ( in . getversion ( ) . onorafter ( version . v_7_0_0_alpha1 ) ) { <nl> + if ( in . getversion ( ) . onorafter ( version . v_6_1_0 ) ) { <nl> establishedmodelmemory = in . readoptionallong ( ) ; <nl> } else { <nl> establishedmodelmemory = null ; <nl>
public class jobupdate implements writeable , toxcontentobject { <nl> } <nl> out . writemap ( customsettings ) ; <nl> out . writeoptionalstring ( modelsnapshotid ) ; <nl> - <nl> - if ( out . getversion ( ) . onorafter ( version . v_7_0_0_alpha1 ) ) { <nl> + if ( out . getversion ( ) . onorafter ( version . v_6_1_0 ) ) { <nl> out . writeoptionallong ( establishedmodelmemory ) ; <nl> } <nl> }
public class remotefailure { <nl> responsemessage = builder . tostring ( ) ; <nl> } <nl> } catch ( ioexception replayexception ) { <nl> - <nl> responsemessage = " attempted to include response but failed because [ " + replayexception . getmessage ( ) + " ] . " ; <nl> } <nl> string parserlocation = " " ; <nl> mmm a / sql / shared - client / src / test / java / org / elasticsearch / xpack / sql / client / shared / remotefailuretests . java <nl> ppp b / sql / shared - client / src / test / java / org / elasticsearch / xpack / sql / client / shared / remotefailuretests . java <nl>
public abstract class csvspectestcase extends specbaseintegrationtestcase { <nl> string header = bufferedreader . readline ( ) ; <nl> if ( ! header . contains ( " : " ) ) { <nl> / / no type information in headers , no need to parse columns - trigger auto - detection <nl> - <nl> - / / see https : / / sourceforge . net / p / csvjdbc / discussion / 56965 / thread / 6a910831 / for more info <nl> - fail ( " the autodetection of types in jdbc csv is currently broken . please specify explicit types " ) ; <nl> return new tuple < > ( expectedresults , " " ) ; <nl> } <nl> try ( stringwriter writer = new stringwriter ( ) ) {
for more information , see <nl>  <nl> = = = = examples <nl>  <nl> - the following example creates the ` datafeed - it - ops - kpi ` { dfeed } : <nl> + the following example creates the ` datafeed - total - requests ` { dfeed } : <nl>  <nl> [ source , js ] <nl> - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - <nl> - put _xpack / ml / datafeeds / datafeed - it - ops - kpi <nl> + put _xpack / ml / datafeeds / datafeed - total - requests <nl> { <nl> - " job_id " : " it - ops - kpi " , <nl> - " indices " : [ " it_ops_metrics " ] , <nl> - " types " : [ " kpi " , " network " , " sql " ] , <nl> - " query " : { <nl> - " match_all " : { <nl> - " boost " : num <nl> - } <nl> - } <nl> + " job_id " : " total - requests " , <nl> + " indices " : [ " server - metrics " ] , <nl> + " types " : [ " metric " ] , <nl> + " scroll_size " : num <nl> } <nl> - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - <nl> / / console <nl> - <nl>  <nl> when the { dfeed } is created , you receive the following results : <nl> [ source , js ] <nl> - - - - <nl> { <nl> - " datafeed_id " : " datafeed - it - ops - kpi " , <nl> - " job_id " : " it - ops - kpi " , <nl> - " query_delay " : " 1m " , <nl> + " datafeed_id " : " datafeed - total - requests " , <nl> + " job_id " : " total - requests " , <nl> + " query_delay " : " 83474ms " , <nl> " indices " : [ <nl> - " it_ops_metrics " <nl> + " server - metrics " <nl> ] , <nl> " types " : [ <nl> - " kpi " , <nl> - " network " , <nl> - " sql " <nl> + " metric " <nl> ] , <nl> " query " : { <nl> " match_all " : { <nl> - " boost " : num <nl> + " boost " : num . 0 <nl> } <nl> } , <nl> " scroll_size " : num , <nl>
import org . elasticsearch . test . estestcase ; <nl>  <nl> import static java . util . collections . singletonmap ; <nl>  <nl> - <nl> public class equalstests extends scripttestcase { <nl> public void testtypesequals ( ) { <nl> assertequals ( true , exec ( " return false = = = false ; " ) ) ; <nl>
task bwctest { <nl> group = ' verification ' <nl> } <nl>  <nl> - / / for now test against the current version : <nl> - version currentversion = version . fromstring ( versionproperties . elasticsearch . minus ( ' - snapshot ' ) ) <nl> - version [ ] versions = [ currentversion ] <nl> - <nl> - / / versions = indexcompatversions <nl> - for ( version version : versions ) { <nl> + for ( version version : indexcompatversions ) { <nl> string basename = " v $ { version } " <nl>  <nl> task oldquerybuildertest = tasks . create ( name : " $ { basename } # oldquerybuildertest " , type : restintegtesttask ) { <nl>
for ( version version : versions ) { <nl>  <nl> configure ( extensions . findbyname ( " $ { basename } # oldquerybuildertestcluster " ) ) { <nl> distribution = ' zip ' <nl> - <nl> - / / bwcversion = version <nl> - / / numbwcnodes = num <nl> + bwcversion = version <nl> + numbwcnodes = num <nl> numnodes = num <nl> clustername = ' query_builder_bwc ' <nl> setting ' http . content_type . required ' , ' true ' <nl>
public class osstats implements writeable , toxcontentfragment { <nl> cpucfsperiodmicros = in . readlong ( ) ; <nl> cpucfsquotamicros = in . readlong ( ) ; <nl> cpustat = new cpustat ( in ) ; <nl> - <nl> - if ( in . getversion ( ) . onorafter ( version . v_7_0_0_alpha1 ) ) { <nl> + if ( in . getversion ( ) . onorafter ( version . v_6_1_0 ) ) { <nl> memorycontrolgroup = in . readoptionalstring ( ) ; <nl> memorylimitinbytes = in . readoptionalstring ( ) ; <nl> memoryusageinbytes = in . readoptionalstring ( ) ; <nl>
public class osstats implements writeable , toxcontentfragment { <nl> out . writelong ( cpucfsperiodmicros ) ; <nl> out . writelong ( cpucfsquotamicros ) ; <nl> cpustat . writeto ( out ) ; <nl> - <nl> - if ( out . getversion ( ) . onorafter ( version . v_7_0_0_alpha1 ) ) { <nl> + if ( out . getversion ( ) . onorafter ( version . v_6_1_0 ) ) { <nl> out . writeoptionalstring ( memorycontrolgroup ) ; <nl> out . writeoptionalstring ( memorylimitinbytes ) ; <nl> out . writeoptionalstring ( memoryusageinbytes ) ;
class licensesmetadata extends abstractnameddiffable < metadata . custom > implements <nl> streamoutput . writeboolean ( true ) ; / / has a license <nl> license . writeto ( streamoutput ) ; <nl> } <nl> - <nl> - if ( streamoutput . getversion ( ) . onorafter ( version . v_7_0_0_alpha1 ) ) { <nl> + if ( streamoutput . getversion ( ) . onorafter ( version . v_6_1_0 ) ) { <nl> if ( trialversion = = null ) { <nl> streamoutput . writeboolean ( false ) ; <nl> } else { <nl>
class licensesmetadata extends abstractnameddiffable < metadata . custom > implements <nl> } else { <nl> license = license_tombstone ; <nl> } <nl> - <nl> - if ( streaminput . getversion ( ) . onorafter ( version . v_7_0_0_alpha1 ) ) { <nl> + if ( streaminput . getversion ( ) . onorafter ( version . v_6_1_0 ) ) { <nl> boolean hasexercisedtrial = streaminput . readboolean ( ) ; <nl> if ( hasexercisedtrial ) { <nl> this . trialversion = version . readversion ( streaminput ) ;
public class localexporter extends exporter implements clusterstatelistener , cle <nl> if ( clusterstate ! = null ) { <nl> long expirationtime = expiration . getmillis ( ) ; <nl>  <nl> - <nl> - / / get the list of monitoring <nl> - final string [ ] monitoringindexpatterns = new string [ ] { " . monitoring - * " , " . marvel - * " } ; <nl> + / / list of <nl> + final string [ ] indexpatterns = new string [ ] { " . monitoring - * " } ; <nl>  <nl> monitoringdoc monitoringdoc = new monitoringdoc ( null , null , null , null , null , <nl> system . currenttimemillis ( ) , ( monitoringdoc . node ) null ) ; <nl>
public final class completionsuggestion extends suggest . suggestion < completionsug <nl> @ override <nl> public void readfrom ( streaminput in ) throws ioexception { <nl> super . readfrom ( in ) ; <nl> - <nl> - if ( in . getversion ( ) . onorafter ( version . v_7_0_0_alpha1 ) ) { <nl> + if ( in . getversion ( ) . onorafter ( version . v_6_1_0 ) ) { <nl> skipduplicates = in . readboolean ( ) ; <nl> } <nl> } <nl>
public final class completionsuggestion extends suggest . suggestion < completionsug <nl> @ override <nl> public void writeto ( streamoutput out ) throws ioexception { <nl> super . writeto ( out ) ; <nl> - <nl> - if ( out . getversion ( ) . onorafter ( version . v_7_0_0_alpha1 ) ) { <nl> + if ( out . getversion ( ) . onorafter ( version . v_6_1_0 ) ) { <nl> out . writeboolean ( skipduplicates ) ; <nl> } <nl> } <nl> mmm a / core / src / main / java / org / elasticsearch / search / suggest / completion / completionsuggestionbuilder . java <nl> ppp b / core / src / main / java / org / elasticsearch / search / suggest / completion / completionsuggestionbuilder . java <nl>
public class completionsuggestionbuilder extends suggestionbuilder < completionsug <nl> fuzzyoptions = in . readoptionalwriteable ( fuzzyoptions : : new ) ; <nl> regexoptions = in . readoptionalwriteable ( regexoptions : : new ) ; <nl> contextbytes = in . readoptionalbytesreference ( ) ; <nl> - <nl> - if ( in . getversion ( ) . onorafter ( version . v_7_0_0_alpha1 ) ) { <nl> + if ( in . getversion ( ) . onorafter ( version . v_6_1_0 ) ) { <nl> skipduplicates = in . readboolean ( ) ; <nl> } <nl> } <nl>
public class completionsuggestionbuilder extends suggestionbuilder < completionsug <nl> out . writeoptionalwriteable ( fuzzyoptions ) ; <nl> out . writeoptionalwriteable ( regexoptions ) ; <nl> out . writeoptionalbytesreference ( contextbytes ) ; <nl> - <nl> - if ( out . getversion ( ) . onorafter ( version . v_7_0_0_alpha1 ) ) { <nl> + if ( out . getversion ( ) . onorafter ( version . v_6_1_0 ) ) { <nl> out . writeboolean ( skipduplicates ) ; <nl> } <nl> } <nl> mmm a / rest - api - spec / src / main / resources / rest - api - spec / test / suggest / 20_completion . yml <nl> ppp b / rest - api - spec / src / main / resources / rest - api - spec / test / suggest / 20_completion . yml <nl>
setup : <nl> mmm <nl> " skip duplicates should work " : <nl> - skip : <nl> - version : " - num . 99 . 99 " <nl> - reason : skip_duplicates was added in num . 0 ( <nl> + version : " - num . 0 . 99 " <nl> + reason : skip_duplicates was added in num . 1 <nl>  <nl> - do : <nl> index : <nl> mmm a / rest - api - spec / src / main / resources / rest - api - spec / test / suggest / 30_context . yml <nl> ppp b / rest - api - spec / src / main / resources / rest - api - spec / test / suggest / 30_context . yml <nl>
setup : <nl> mmm <nl> " skip duplicates with contexts should work " : <nl> - skip : <nl> - version : " - num . 99 . 99 " <nl> - reason : skip_duplicates was added in num . 0 ( <nl> + version : " - num . 0 . 99 " <nl> + reason : skip_duplicates was added in num . 1 <nl>  <nl> - do : <nl> index :
public class watchbackwardscompatibilityit extends esresttestcase { <nl> ensurewatcherstopped ( ) ; <nl>  <nl> executeagainstrandomnode ( client - > assertok ( client . performrequest ( " post " , " / _xpack / watcher / _start " ) ) ) ; <nl> - executeagainstmasternode ( client - > assertbusy ( ( ) - > { <nl> - response response = client . performrequest ( " get " , " _xpack / watcher / stats " ) ; <nl> - string responsebody = entityutils . tostring ( response . getentity ( ) , standardcharsets . utf_8 ) ; <nl> - <nl> - / / using a checkedbiconsumer , that provides info against which node the request runs <nl> - assertthat ( responsebody , not ( containsstring ( " \ " watcher_state \ " : \ " starting \ " " ) ) ) ; <nl> - assertthat ( responsebody , not ( containsstring ( " \ " watcher_state \ " : \ " stopping \ " " ) ) ) ; <nl> - assertthat ( responsebody , not ( containsstring ( " \ " watcher_state \ " : \ " stopped \ " " ) ) ) ; <nl> - } ) ) ; <nl> + ensurewatcherstarted ( ) ; <nl> } <nl>  <nl> public void testwatchcrudapis ( ) throws exception { <nl>
put _xpack / ml / anomaly_detectors / it - ops - kpi <nl> } <nl> - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - <nl> / / console <nl> - <nl>  <nl> when the job is created , you receive the following results : <nl> [ source , js ] <nl>
public class watchbackwardscompatibilityit extends esresttestcase { <nl> } <nl>  <nl> public void testwatcherrestart ( ) throws exception { <nl> - <nl> - executeagainstmasternode ( client - > { <nl> + executeagainstrandomnode ( client - > { <nl> assertok ( client . performrequest ( " post " , " / _xpack / watcher / _stop " ) ) ; <nl> assertbusy ( ( ) - > { <nl> try ( inputstream is = client . performrequest ( " get " , " _xpack / watcher / stats " ) . getentity ( ) . getcontent ( ) ) { <nl>
public class watchbackwardscompatibilityit extends esresttestcase { <nl> } ) ; <nl> } ) ; <nl>  <nl> - <nl> / / currently the triggered watches <nl> / / that has not configured the ` index . format : num ` , resulting in watcher not starting <nl> map < string , string > params = new hashmap < > ( ) ; <nl>
public class watchbackwardscompatibilityit extends esresttestcase { <nl>  <nl> executeupgradeifneeded ( ) ; <nl>  <nl> - <nl> - executeagainstmasternode ( client - > { <nl> + executeagainstrandomnode ( client - > { <nl> assertok ( client . performrequest ( " post " , " / _xpack / watcher / _start " ) ) ; <nl> assertbusy ( ( ) - > { <nl> try ( inputstream is = client . performrequest ( " get " , " _xpack / watcher / stats " ) . getentity ( ) . getcontent ( ) ) { <nl>
final class bootstrap { <nl> } <nl> } <nl>  <nl> - / * * set the system property before anything has a chance to trigger its use * / <nl> - <nl> - @ suppressforbidden ( reason = " sets logger prefix on initialization " ) <nl> - static void initloggerprefix ( ) { <nl> - system . setproperty ( " es . logger . prefix " , " " ) ; <nl> - } <nl> - <nl> / * * <nl> * this method is invoked by { @ link elasticsearch # main ( string [ ] ) } to startup elasticsearch . <nl> * / <nl>
<nl> " options " : [ " open " , " closed " , " none " , " all " ] , <nl> " default " : " open " , <nl> " description " : " whether to expand wildcard expression to concrete indices that are open , closed or both . " <nl> - } , <nl> - " force " : { <nl> - " type " : " boolean " , <nl> - " description " : " force a refresh even if not required " , <nl> - " default " : false <nl> - } , <nl> - " operation_threading " : { <nl> - " description " : " <nl> } <nl> } <nl> } ,
public class searchtransportservice extends abstractcomponent { <nl> public void sendexecutequery ( transport . connection connection , final shardsearchtransportrequest request , searchtask task , <nl> final searchactionlistener < searchphaseresult > listener ) { <nl> / / we optimize this and expect a queryfetchsearchresult if we only have a single shard in the search request <nl> - / / this used to be the query_and_fetch which doesn ' t exists anymore . <nl> + / / this used to be the query_and_fetch which doesn ' t exist anymore . <nl> final boolean fetchdocuments = request . numberofshards ( ) = = num ; <nl> supplier < searchphaseresult > supplier = fetchdocuments ? queryfetchsearchresult : : new : querysearchresult : : new ; <nl> - if ( connection . getversion ( ) . before ( version . v_5_3_0 ) & & fetchdocuments ) { <nl> - / / this is a bwc layer for pre num . 3 indices <nl> - if ( request . scroll ( ) ! = null ) { <nl> - / * * <nl> - * this is needed for nodes pre num . 3 when the single shard optimization is used . <nl> - * these nodes will set the last emitted doc only if the removed ` query_and_fetch ` search type is set <nl> - * in the request . see { @ link searchtype } . <nl> - * / <nl> - request . searchtype ( searchtype . query_and_fetch ) ; <nl> - } <nl> - <nl> - transportservice . sendchildrequest ( connection , query_fetch_action_name , request , task , <nl> - new actionlistenerresponsehandler < > ( listener , supplier ) ) ; <nl> - } else { <nl> - transportservice . sendchildrequest ( connection , query_action_name , request , task , <nl> - new actionlistenerresponsehandler < > ( listener , supplier ) ) ; <nl> - } <nl> + transportservice . sendchildrequest ( connection , query_action_name , request , task , <nl> + new actionlistenerresponsehandler < > ( listener , supplier ) ) ; <nl> } <nl>  <nl> public void sendexecutequery ( transport . connection connection , final querysearchrequest request , searchtask task , <nl>
when you use ` summary_count_field_name ` , the { ml } features expect the input <nl> data to be pre - aggregated . the value of the ` summary_count_field_name ` field <nl> must contain the count of raw events that were summarized . in { kib } , use the <nl> * * summary_count_field_name * * in advanced jobs . analyzing aggregated input data <nl> - provides a significant boost in performance . <nl> - <nl> - / / / / <nl> - <nl> - / / / / <nl> + provides a significant boost in performance . for more information , see <nl> + < < ml - configuring - aggregation > > . <nl>  <nl> if your data is sparse , there may be gaps in the data which means you might have <nl> empty buckets . you might want to treat these as anomalies or you might want these
allprojects { <nl> } <nl> } <nl>  <nl> - task ( ' verifyversions ' ) { <nl> - description ' verifies that all released versions that are indexed compatible are listed in version . java . ' <nl> - group ' verification ' <nl> - enabled = false = = gradle . startparameter . isoffline ( ) <nl> + task verifyversions { <nl> dolast { <nl> + if ( gradle . startparameter . isoffline ( ) ) { <nl> + throw new gradleexception ( " must run in online mode to verify versions " ) <nl> + } <nl> / / read the list from maven central <nl> node xml <nl> new url ( ' https : / / repo1 . maven . org / maven2 / org / elasticsearch / elasticsearch / maven - metadata . xml ' ) . openstream ( ) . withstream { s - > <nl> xml = new xmlparser ( ) . parse ( s ) <nl> } <nl> - set < string > knownversions = new treeset < > ( xml . versioning . versions . version . collect { it . text ( ) } . findall { it = = ~ / \ d \ . \ d \ . \ d / } ) <nl> + set < version > knownversions = new treeset < > ( xml . versioning . versions . version . collect { it . text ( ) } . findall { it = = ~ / \ d \ . \ d \ . \ d / } . collect { version . fromstring ( it ) } ) <nl>  <nl> - / / limit the known versions to those that should be <nl> - knownversions = knownversions . findall { integer . parseint ( it . split ( ' \ \ . ' ) [ 0 ] ) > = prevmajor } <nl> + / / limit the known versions to those that should be <nl> + knownversions = knownversions . findall { it . major > = prevmajor & & it . before ( versionproperties . elasticsearch ) } <nl>  <nl> / * limit the listed versions to those that have been marked as released . <nl> * versions not marked as released don ' t get the same testing and we want <nl> * to make sure that we flip all unreleased versions to released as soon <nl> * as possible after release . * / <nl> - set < string > actualversions = new treeset < > ( <nl> - indexcompatversions <nl> - . findall { false = = it . snapshot } <nl> - . collect { it . tostring ( ) } ) <nl> - <nl> - <nl> + set < version > actualversions = new treeset < > ( indexcompatversions . findall { false = = it . snapshot } ) <nl>  <nl> / / finally , compare ! <nl> - if ( ! knownversions . equals ( actualversions ) ) { <nl> - throw new gradleexception ( " out - of - date released versions\nactual : " + <nl> - actualversions + " \nexpected : " + knownversions + <nl> - " \nupdate version . java . note that version . current doesn ' t count " + <nl> - " because it is not released . " ) <nl> + if ( knownversions . equals ( actualversions ) = = false ) { <nl> + throw new gradleexception ( " out - of - date released versions\nactual : " + actualversions + " \nexpected : " + knownversions + <nl> + " \nupdate version . java . note that version . current doesn ' t count because it is not released . " ) <nl> } <nl> } <nl> } <nl> - task ( ' precommit ' ) { <nl> - dependson ( verifyversions ) <nl> + <nl> + task branchconsistency { <nl> + description ' ensures this branch is internally consistent . for example , that versions constants match released versions . ' <nl> + group ' verification ' <nl> + dependson verifyversions <nl> } <nl>  <nl> subprojects { <nl> mmm a / buildsrc / src / main / groovy / org / elasticsearch / gradle / version . groovy <nl> ppp b / buildsrc / src / main / groovy / org / elasticsearch / gradle / version . groovy <nl>
public class machinelearningtemplateregistry extends abstractcomponent implemen <nl> / / pick up default mappings and be used in queries <nl> . put ( mapperservice . index_mapper_dynamic_setting . getkey ( ) , true ) <nl> / / set the default all search field <nl> - . put ( indexsettings . default_field_setting . getkey ( ) , elasticsearchmappings . all_field_values ) <nl> - <nl> - . put ( " index . mapping . single_type " , false ) ; <nl> + . put ( indexsettings . default_field_setting . getkey ( ) , elasticsearchmappings . all_field_values ) ; <nl> } <nl>  <nl> / * * <nl>
public class machinelearningtemplateregistry extends abstractcomponent implemen <nl> / / sacrifice durability for performance : in the event of power <nl> / / failure we can lose the last num seconds of changes , but it ' s <nl> / / much faster <nl> - . put ( indexsettings . index_translog_durability_setting . getkey ( ) , async ) <nl> - <nl> - . put ( " index . mapping . single_type " , false ) ; <nl> + . put ( indexsettings . index_translog_durability_setting . getkey ( ) , async ) ; <nl> } <nl>  <nl> public static boolean alltemplatesinstalled ( metadata metadata ) { <nl> mmm a / plugin / src / test / java / org / elasticsearch / xpack / ml / machinelearningtemplateregistrytests . java <nl> ppp b / plugin / src / test / java / org / elasticsearch / xpack / ml / machinelearningtemplateregistrytests . java <nl>
setup : <nl> " field collapsing and multiple inner_hits " : <nl>  <nl> - skip : <nl> - version : " - num . 99 . 99 " <nl> - reason : <nl> + version : " - num . 4 . 99 " <nl> + reason : multiple inner_hits is a new feature added in num . 5 <nl>  <nl> - do : <nl> search :
public abstract class parsedaggregation implements aggregation , toxcontent { <nl> return metadata ; <nl> } <nl>  <nl> - / * * <nl> - * returns a string representing the type of the aggregation . this type is added to <nl> - * the aggregation name in the response , so that it can later be used by rest clients <nl> - * to determine the internal type of the aggregation . <nl> - * / <nl> - <nl> - public abstract string gettype ( ) ; <nl> - <nl> @ override <nl> public xcontentbuilder toxcontent ( xcontentbuilder builder , toxcontent . params params ) throws ioexception { <nl> / / concatenates the type and the name of the aggregation ( ex : top_hits # foo ) <nl> mmm a / core / src / test / java / org / elasticsearch / search / aggregations / internalmultibucketaggregationtestcase . java <nl> ppp b / core / src / test / java / org / elasticsearch / search / aggregations / internalmultibucketaggregationtestcase . java <nl>
closure waitwithauth = { nodeinfo node , antbuilder ant - > <nl>  <nl> string outputdir = " generated - resources / $ { project . name } " <nl>  <nl> - task oldclustertest ( type : restintegtesttask ) { <nl> - mustrunafter ( precommit ) <nl> + / / this is a top level task which we will add dependencies to below . <nl> + / / it is a single task that can be used to backcompat tests against all versions . <nl> + task bwctest { <nl> + description = ' runs backwards compatibility tests . ' <nl> + group = ' verification ' <nl> } <nl>  <nl> - oldclustertestcluster { <nl> + for ( version version : wirecompatversions ) { <nl> + string basename = " v $ { version } " <nl> + <nl> + task oldclustertest = tasks . create ( name : " $ { basename } # oldclustertest " , type : restintegtesttask ) { <nl> + mustrunafter ( precommit ) <nl> + } <nl> + <nl> + object extension = extensions . findbyname ( " $ { basename } # oldclustertestcluster " ) <nl> + configure ( extensions . findbyname ( " $ { basename } # oldclustertestcluster " ) ) { <nl> plugin ' : x - pack - elasticsearch : plugin ' <nl> distribution = ' zip ' <nl> - bwcversion = project . wirecompatversions [ - 1 ] <nl> + bwcversion = version <nl> numbwcnodes = num <nl> numnodes = num <nl> clustername = ' rolling - upgrade ' <nl>
public class mapperservice extends abstractindexcomponent implements closeable { <nl> public static final setting < boolean > index_mapping_single_type_setting ; <nl> static { <nl> function < settings , string > defvalue = settings - > { <nl> - <nl> - / * boolean singletype = true ; <nl> + boolean singletype = true ; <nl> if ( settings . getasversion ( indexmetadata . setting_version_created , null ) ! = null ) { <nl> singletype = version . indexcreated ( settings ) . onorafter ( version . v_6_0_0_alpha1_unreleased ) ; <nl> - } * / <nl> - boolean singletype = false ; <nl> + } <nl> return boolean . valueof ( singletype ) . tostring ( ) ; <nl> } ; <nl> index_mapping_single_type_setting = setting . boolsetting ( " index . mapping . single_type " , defvalue , property . indexscope , property . final ) ; <nl> mmm a / core / src / test / java / org / elasticsearch / index / mapper / mapperservicetests . java <nl> ppp b / core / src / test / java / org / elasticsearch / index / mapper / mapperservicetests . java <nl>
class installplugincommand extends environmentawarecommand { <nl> if ( pluginid = = null ) { <nl> throw new userexception ( exitcodes . usage , " plugin id is required " ) ; <nl> } <nl> - <nl> - if ( files . exists ( env . pluginsfile ( ) ) = = false ) { <nl> - terminal . println ( " plugins directory [ " + env . pluginsfile ( ) + " ] does not exist . creating . . . " ) ; <nl> - files . createdirectory ( env . pluginsfile ( ) ) ; <nl> - } <nl>  <nl> path pluginzip = download ( terminal , pluginid , env . tmpfile ( ) ) ; <nl> path extractedzip = unzip ( pluginzip , env . pluginsfile ( ) ) ; <nl> mmm a / qa / evil - tests / src / test / java / org / elasticsearch / plugins / installplugincommandtests . java <nl> ppp b / qa / evil - tests / src / test / java / org / elasticsearch / plugins / installplugincommandtests . java <nl>
class buildplugin implements plugin < project > { <nl> / * * <nl> * returns a closure which can be used with a mavenpom for fixing problems with gradle generated poms . <nl> * <nl> - * < ul > <nl> - * < li > remove transitive dependencies . we currently exclude all artifacts explicitly instead of using wildcards <nl> - * as ivy incorrectly translates poms with * excludes to ivy xml with * excludes which results in the main artifact <nl> - * being excluded as well ( see https : / / issues . apache . org / jira / browse / ivy - 1531 ) . note that gradle num . 14 + automatically <nl> - * translates non - transitive dependencies to * excludes . we should revisit this when upgrading gradle . < / li > <nl> - * < li > set compile time deps back to compile from runtime ( known issue with maven - publish plugin ) < / li > <nl> - * < / ul > <nl> + * the current fixup is to set compile time deps back to compile from runtime ( known issue with maven - publish plugin ) . <nl> * / <nl> private static closure fixupdependencies ( project project ) { <nl> - <nl> return { xmlprovider xml - > <nl> / / first find if we have dependencies at all , and grab the node <nl> nodelist depsnodes = xml . asnode ( ) . get ( ' dependencies ' )
import java . util . map ; <nl> * / <nl> public abstract class parsedaggregation implements aggregation , toxcontent { <nl>  <nl> - <nl> protected static void declarecommonfields ( objectparser < ? extends parsedaggregation , void > objectparser ) { <nl> objectparser . declareobject ( ( parsedagg , metadata ) - > parsedagg . metadata = collections . unmodifiablemap ( metadata ) , <nl> ( parser , context ) - > parser . map ( ) , internalaggregation . commonfields . meta ) ; <nl>
public class parsedaggregationtests extends estestcase { <nl>  <nl> @ override <nl> protected namedxcontentregistry xcontentregistry ( ) { <nl> - <nl> namedxcontentregistry . entry entry = new namedxcontentregistry . entry ( aggregation . class , new parsefield ( " type " ) , <nl> ( parser , name ) - > testparsedaggregation . fromxcontent ( parser , ( string ) name ) ) ; <nl> return new namedxcontentregistry ( collections . singletonlist ( entry ) ) ;
public class singlenodediscoveryit extends esintegtestcase { <nl> . builder ( ) <nl> . put ( super . nodesettings ( nodeordinal ) ) <nl> . put ( " discovery . type " , " single - node " ) <nl> - <nl> - . put ( " transport . tcp . port " , " 49152 - 49156 " ) <nl> + . put ( " transport . tcp . port " , " 0 " ) <nl> . build ( ) ; <nl> } <nl>  <nl>
public class singlenodediscoveryit extends esintegtestcase { <nl> * we align the port ranges of the two as then with zen discovery these two <nl> * nodes would find each other . <nl> * / <nl> - <nl> - . put ( " transport . tcp . port " , " 49152 - 49156 " ) <nl> + . put ( " transport . tcp . port " , port + " - " + ( port + num - num ) ) <nl> . build ( ) ; <nl> } <nl> } ;
subprojects { <nl> " org . elasticsearch . client : transport : $ { version } " : ' : client : transport ' , <nl> " org . elasticsearch . test : framework : $ { version } " : ' : test : framework ' , <nl> " org . elasticsearch . distribution . integ - test - zip : elasticsearch : $ { version } " : ' : distribution : integ - test - zip ' , <nl> - <nl> " org . elasticsearch . distribution . zip : elasticsearch : $ { bwcversion } " : ' : distribution : bwc - zip ' , <nl> " org . elasticsearch . distribution . zip : elasticsearch : $ { version } " : ' : distribution : zip ' , <nl> " org . elasticsearch . distribution . tar : elasticsearch : $ { version } " : ' : distribution : tar ' ,
import org . elasticsearch . gradle . loggedexec <nl>  <nl> apply plugin : ' distribution ' <nl>  <nl> - <nl> - string bwc_version = " 5 . 4 . 0 - snapshot " <nl> - <nl> string checkoutdir = " $ { builddir } / bwc / checkout - 5 . x " <nl> task createclone ( type : loggedexec ) { <nl> onlyif { new file ( checkoutdir ) . exists ( ) = = false } <nl>
public class cpplogmessagehandler implements closeable { <nl> } else { <nl> logger . log ( level , " [ { } / { } ] [ { } @ { } ] { } " , msg . getlogger ( ) , latestpid , msg . getfile ( ) , msg . getline ( ) , latestmessage ) ; <nl> } <nl> - <nl> } catch ( ioexception e ) { <nl> if ( jobid ! = null ) { <nl> logger . warn ( new parameterizedmessage ( " [ { } ] failed to parse c + + log message : { } " ,
public class smoketestclientit extends essmokeclienttestcase { <nl> * create an <nl> * / <nl> public void testputdocument ( ) { <nl> - <nl> - assumefalse ( " jdk is jdk num " , constants . jre_is_minimum_java9 ) ; <nl> client client = getclient ( ) ; <nl>  <nl> / / start snippet : java - doc - index - doc - simple
integtest { <nl> dependson copymlresttests <nl> } <nl>  <nl> - / / remove tests that are expected to throw an exception , because we cannot then <nl> - / / know whether to expect an authorization exception or a validation exception <nl> integtestrunner { <nl> systemproperty ' tests . rest . blacklist ' , [ <nl> - <nl> - ' ml / jobs_crud / test close job ' , <nl> + / / remove tests that need privileges beyond those in the standard ml roles - in <nl> + / / particular , these two tests need cluster : admin / persistent / remove to directly <nl> + / / remove persistent tasks <nl> ' ml / jobs_crud / test force close job ' , <nl> ' ml / start_stop_datafeed / test force stop datafeed ' , <nl> - / / non - temporary <nl> + / / remove tests that are expected to throw an exception , because we cannot then <nl> + / / know whether to expect an authorization exception or a validation exception <nl> ' ml / datafeeds_crud / test delete datafeed with missing id ' , <nl> ' ml / datafeeds_crud / test put datafeed referring to missing job_id ' , <nl> ' ml / datafeeds_crud / test put datafeed with invalid query ' , <nl> mmm a / qa / smoke - test - ml - with - security / roles . yml <nl> ppp b / qa / smoke - test - ml - with - security / roles . yml <nl>
public class jobstoragedeletiontask extends task { <nl>  <nl> / / step num . dbq done , delete the state <nl> / / - - - - - - - <nl> - <nl> actionlistener < bulkbyscrollresponse > dbqhandler = actionlistener . wrap ( bulkbyscrollresponse - > { <nl> if ( bulkbyscrollresponse . istimedout ( ) ) { <nl> logger . warn ( " deletebyquery for indices [ " + indexname + " , " + indexpattern + " ] timed out . " ) ;
def provision ( config , <nl> rm - rf / tmp / gradle . zip <nl> ln - s / opt / gradle - 3 . 3 / bin / gradle / usr / bin / gradle <nl> # make nfs mounted gradle home dir writeable <nl> - # <nl> - chown vagrant / home / vagrant / . gradle <nl> + chown vagrant : vagrant / home / vagrant / . gradle <nl> }
public class jobresultspersister extends abstractcomponent { <nl> this . jobid = jobid ; <nl> this . object = object ; <nl> this . type = type ; <nl> - <nl> - this . id = id ! = null ? id : uuids . base64uuid ( ) ; <nl> + this . id = id ; <nl> } <nl>  <nl> boolean persist ( string indexname ) { <nl> mmm a / plugin / src / main / java / org / elasticsearch / xpack / ml / notifications / auditor . java <nl> ppp b / plugin / src / main / java / org / elasticsearch / xpack / ml / notifications / auditor . java <nl>
public class auditor { <nl> } <nl>  <nl> private void indexdoc ( string type , toxcontent toxcontent ) { <nl> - <nl> - client . prepareindex ( notifications_index , type , uuids . base64uuid ( ) ) <nl> + client . prepareindex ( notifications_index , type ) <nl> . setsource ( toxcontentbuilder ( toxcontent ) ) <nl> . execute ( new actionlistener < indexresponse > ( ) { <nl> @ override <nl> mmm a / plugin / src / test / java / org / elasticsearch / xpack / ml / notifications / auditortests . java <nl> ppp b / plugin / src / test / java / org / elasticsearch / xpack / ml / notifications / auditortests . java <nl>
public class monitoringbulkdoc extends monitoringdoc { <nl> type = in . readoptionalstring ( ) ; <nl> id = in . readoptionalstring ( ) ; <nl> source = in . readbytesreference ( ) ; <nl> - if ( source ! = bytesarray . empty & & in . getversion ( ) . after ( version . v_5_3_0_unreleased ) ) { <nl> + if ( source ! = bytesarray . empty & & in . getversion ( ) . onorafter ( version . v_5_3_0_unreleased ) ) { <nl> xcontenttype = xcontenttype . readfrom ( in ) ; <nl> } else { <nl> xcontenttype = xcontentfactory . xcontenttype ( source ) ; <nl>
public class monitoringbulkdoc extends monitoringdoc { <nl> out . writeoptionalstring ( type ) ; <nl> out . writeoptionalstring ( id ) ; <nl> out . writebytesreference ( source ) ; <nl> - if ( source ! = null & & source ! = bytesarray . empty & & out . getversion ( ) . after ( version . v_5_3_0_unreleased ) ) { <nl> - / / onorafter after backporting <nl> + if ( source ! = null & & source ! = bytesarray . empty & & out . getversion ( ) . onorafter ( version . v_5_3_0_unreleased ) ) { <nl> xcontenttype . writeto ( out ) ; <nl> } <nl> } <nl> mmm a / plugin / src / main / java / org / elasticsearch / xpack / watcher / transport / actions / execute / executewatchrequest . java <nl> ppp b / plugin / src / main / java / org / elasticsearch / xpack / watcher / transport / actions / execute / executewatchrequest . java <nl>
public class executewatchrequest extends masternodereadrequest < executewatchreque <nl> } <nl> if ( in . readboolean ( ) ) { <nl> watchsource = in . readbytesreference ( ) ; <nl> - if ( in . getversion ( ) . after ( version . v_5_3_0_unreleased ) ) { <nl> + if ( in . getversion ( ) . onorafter ( version . v_5_3_0_unreleased ) ) { <nl> xcontenttype = xcontenttype . readfrom ( in ) ; <nl> } else { <nl> xcontenttype = xcontentfactory . xcontenttype ( watchsource ) ; <nl>
public class executewatchrequest extends masternodereadrequest < executewatchreque <nl> out . writeboolean ( watchsource ! = null ) ; <nl> if ( watchsource ! = null ) { <nl> out . writebytesreference ( watchsource ) ; <nl> - if ( out . getversion ( ) . after ( version . v_5_3_0_unreleased ) ) { <nl> + if ( out . getversion ( ) . onorafter ( version . v_5_3_0_unreleased ) ) { <nl> xcontenttype . writeto ( out ) ; <nl> } <nl> } <nl> mmm a / plugin / src / main / java / org / elasticsearch / xpack / watcher / transport / actions / put / putwatchrequest . java <nl> ppp b / plugin / src / main / java / org / elasticsearch / xpack / watcher / transport / actions / put / putwatchrequest . java <nl>
public class putwatchrequest extends masternoderequest < putwatchrequest > { <nl> id = in . readstring ( ) ; <nl> source = in . readbytesreference ( ) ; <nl> active = in . readboolean ( ) ; <nl> - if ( in . getversion ( ) . after ( version . v_5_3_0_unreleased ) ) { <nl> + if ( in . getversion ( ) . onorafter ( version . v_5_3_0_unreleased ) ) { <nl> xcontenttype = xcontenttype . readfrom ( in ) ; <nl> } else { <nl> xcontenttype = xcontentfactory . xcontenttype ( source ) ; <nl>
public class putwatchrequest extends masternoderequest < putwatchrequest > { <nl> out . writestring ( id ) ; <nl> out . writebytesreference ( source ) ; <nl> out . writeboolean ( active ) ; <nl> - if ( out . getversion ( ) . after ( version . v_5_3_0_unreleased ) ) { <nl> + if ( out . getversion ( ) . onorafter ( version . v_5_3_0_unreleased ) ) { <nl> xcontenttype . writeto ( out ) ; <nl> } <nl> }
import java . util . concurrent . timeoutexception ; <nl> public class nativecontroller { <nl> private static final logger logger = loggers . getlogger ( nativecontroller . class ) ; <nl>  <nl> - <nl> - / / at the moment it has to be started manually , which could take a while <nl> - private static final duration controller_connect_timeout = duration . ofminutes ( 1 ) ; <nl> + / / the controller process should already be running by the time this class tries to connect to it , so the timeout can be short <nl> + private static final duration controller_connect_timeout = duration . ofseconds ( 2 ) ; <nl>  <nl> private static final string start_command = " start " ;
public class elasticsearchexception extends runtimeexception implements toxconte <nl> super ( in . readoptionalstring ( ) , in . readexception ( ) ) ; <nl> readstacktrace ( this , in ) ; <nl> headers . putall ( in . readmapoflists ( streaminput : : readstring , streaminput : : readstring ) ) ; <nl> - <nl> - if ( in . getversion ( ) . after ( version . v_5_3_0_unreleased ) ) { <nl> + if ( in . getversion ( ) . onorafter ( version . v_5_3_0_unreleased ) ) { <nl> metadata . putall ( in . readmapoflists ( streaminput : : readstring , streaminput : : readstring ) ) ; <nl> } else { <nl> for ( iterator < map . entry < string , list < string > > > iterator = headers . entryset ( ) . iterator ( ) ; iterator . hasnext ( ) ; ) { <nl>
public class elasticsearchexception extends runtimeexception implements toxconte <nl> out . writeoptionalstring ( this . getmessage ( ) ) ; <nl> out . writeexception ( this . getcause ( ) ) ; <nl> writestacktraces ( this , out ) ; <nl> - <nl> - if ( out . getversion ( ) . after ( version . v_5_3_0_unreleased ) ) { <nl> + if ( out . getversion ( ) . onorafter ( version . v_5_3_0_unreleased ) ) { <nl> out . writemapoflists ( headers , streamoutput : : writestring , streamoutput : : writestring ) ; <nl> out . writemapoflists ( metadata , streamoutput : : writestring , streamoutput : : writestring ) ; <nl> } else {
public class prebuiltxpacktransportclienttests extends randomizedtest { <nl>  <nl> @ test <nl> public void testplugininstalled ( ) { <nl> - <nl> - assumefalse ( constants . jre_is_minimum_java9 ) ; <nl> try ( transportclient client = new prebuiltxpacktransportclient ( settings . empty ) ) { <nl> settings settings = client . settings ( ) ; <nl> assertequals ( security . name4 , networkmodule . transport_type_setting . get ( settings ) ) ;
public final class remoteclusterservice extends abstractcomponent implements clo <nl> } <nl>  <nl> static void validateremoteclustersseeds ( settings settings ) { <nl> - <nl> for ( string clustername : settings . names ( ) ) { <nl> string [ ] remotehosts = settings . getasarray ( clustername ) ; <nl> if ( remotehosts . length = = num ) {
public class watchsourcebuilder implements toxcontent { <nl> return builder . endobject ( ) ; <nl> } <nl>  <nl> - public bytesreference buildasbytes ( xcontenttype contenttype ) { <nl> - try { <nl> - xcontentbuilder builder = xcontentfactory . contentbuilder ( contenttype ) ; <nl> - toxcontent ( builder , toxcontent . empty_params ) ; <nl> - return builder . bytes ( ) ; <nl> - } catch ( ioexception ioe ) { <nl> - <nl> - throw new elasticsearchexception ( " failed to render watch source as bytes " , ioe ) ; <nl> - } <nl> - } <nl> - <nl> static class transformedaction implements toxcontent { <nl>  <nl> private final string id ; <nl> mmm a / elasticsearch / src / test / java / org / elasticsearch / xpack / watcher / transport / action / put / putwatchtests . java <nl> ppp b / elasticsearch / src / test / java / org / elasticsearch / xpack / watcher / transport / action / put / putwatchtests . java <nl>
public abstract class abstractoldxpackindicesbackwardscompatibilitytestcase exte <nl> } <nl> } <nl>  <nl> - <nl> - @ awaitsfix ( bugurl = " we need to fix bwc first " ) <nl> public void testoldindexes ( ) throws exception { <nl> collections . shuffle ( datafiles , random ( ) ) ; <nl> for ( string datafile : datafiles ) { <nl> mmm a / elasticsearch / src / test / java / org / elasticsearch / xpack / security / authc / esnative / esnativemigratetooltests . java <nl> ppp b / elasticsearch / src / test / java / org / elasticsearch / xpack / security / authc / esnative / esnativemigratetooltests . java <nl>
public class esnativemigratetooltests extends nativerealmintegtestcase { <nl> return internalcluster ( ) . getinstances ( environment . class ) . iterator ( ) . next ( ) ; <nl> } <nl>  <nl> - <nl> - @ awaitsfix ( bugurl = " we need to fix bwc first " ) <nl> public void testretrieveusers ( ) throws exception { <nl> final environment nodeenvironment = nodeenvironment ( ) ; <nl> string home = environment . path_home_setting . get ( nodeenvironment . settings ( ) ) ; <nl>
public class esnativemigratetooltests extends nativerealmintegtestcase { <nl> } <nl> } <nl>  <nl> - <nl> - @ awaitsfix ( bugurl = " we need to fix bwc first " ) <nl> public void testretrieveroles ( ) throws exception { <nl> final environment nodeenvironment = nodeenvironment ( ) ; <nl> string home = environment . path_home_setting . get ( nodeenvironment . settings ( ) ) ;
public class dynamictemplate implements toxcontent { <nl> try { <nl> xcontentfieldtype = xcontentfieldtype . fromstring ( matchmappingtype ) ; <nl> } catch ( illegalargumentexception e ) { <nl> - <nl> - / * if ( indexversioncreated . onorafter ( version . v_6_0_0 ) ) { <nl> + if ( indexversioncreated . onorafter ( version . v_6_0_0_alpha1_unreleased ) ) { <nl> throw e ; <nl> - } * / <nl> - <nl> - deprecation_logger . deprecated ( " ignoring unrecognized match_mapping_type : [ " + matchmappingtype + " ] " ) ; <nl> - / / this template is on an unknown type so it will never match anything <nl> - / / null indicates that the template should be ignored <nl> - return null ; <nl> + } else { <nl> + / / this template is on an unknown type so it will never match anything <nl> + / / null indicates that the template should be ignored <nl> + return null ; <nl> + } <nl> } <nl> } <nl> return new dynamictemplate ( name , pathmatch , pathunmatch , match , unmatch , xcontentfieldtype , matchtype . fromstring ( matchpattern ) , mapping ) ; <nl> mmm a / core / src / test / java / org / elasticsearch / index / mapper / dynamictemplatetests . java <nl> ppp b / core / src / test / java / org / elasticsearch / index / mapper / dynamictemplatetests . java <nl>
public class transportsearchaction extends handledtransportaction < searchrequest , <nl> / / pure paranoia if time goes backwards we are at least positive <nl> final long starttimeinmillis = math . max ( 0 , system . currenttimemillis ( ) ) ; <nl>  <nl> - <nl> - / / e . g . we could skip the remote logic if no remote clusters are registered . also don ' t go remotely if the prefix is not <nl> - / / a registered cluster rather than throwing an error ? <nl> - final list < string > localindiceslist = new arraylist < > ( ) ; <nl> + final string [ ] localindices ; <nl> final map < string , list < string > > remoteindicesbycluster = new hashmap < > ( ) ; <nl> - for ( string <nl> - int i = index . indexof ( remote_cluster_index_
<nl> mmm <nl> " shrink <nl> - - skip : <nl> - version : " - num . 0 . 0 " <nl> - reason : this doesn ' t work yet with bwc tests since the master is from the old verion <nl> - # <nl> - # today if we run bwc tests and we select the master as a _shrink node but since primaries are allocated <nl> - # on the newer version nodes this fails . . . <nl> - # creates an <nl> - # relocates all it ' s shards to one node <nl> - # shrinks it into a new <nl> + # creates an <nl> + # and shrinks it into a new <nl> + # we don ' t do the relocation to a single node after the <nl> + # here since in a mixed version cluster we can ' t identify <nl> + # which node is the one with the highest version and that is the only one that can safely <nl> + # be used to shrink the index . <nl> + - do : <nl> + cluster . state : { } <nl> + # get master node id <nl> + <nl> + - set : { master_node : master } <nl> + <nl> - do : <nl> indices . create : <nl> index : source <nl> wait_for_active_shards : num <nl> body : <nl> settings : <nl> - number_of_replicas : " 0 " <nl> + # ensure everything is allocated on a single node <nl> + index . routing . allocation . include . _id : $ master <nl> + number_of_replicas : num <nl> - do : <nl> index : <nl> index : source <nl>
import org . elasticsearch . repositories . s3 . s3repository ; <nl> * / <nl> public class s3repositoryplugin extends plugin implements repositoryplugin { <nl>  <nl> - / / clientconfiguration clinit has some classloader problems <nl> - <nl> static { <nl> securitymanager sm = system . getsecuritymanager ( ) ; <nl> if ( sm ! = null ) { <nl>
public class ec2discoveryplugin extends plugin implements discoveryplugin , close <nl>  <nl> public static final string ec2 = " ec2 " ; <nl>  <nl> - / / clientconfiguration clinit has some classloader problems <nl> - <nl> static { <nl> securitymanager sm = system . getsecuritymanager ( ) ; <nl> if ( sm ! = null ) { <nl>
public class queryspectests extends estestcase { <nl> testitem . toxcontent ( builder , toxcontent . empty_params ) ; <nl> xcontentbuilder shuffled = shufflexcontent ( builder ) ; <nl> xcontentparser itemparser = xcontenthelper . createparser ( shuffled . bytes ( ) ) ; <nl> - itemparser . nexttoken ( ) ; <nl> + itemparser . nexttoken ( ) ; <nl>  <nl> queryparsecontext querycontext = new queryparsecontext ( searchrequestparsers . queryparsers , itemparser , parsefieldmatcher . strict ) ; <nl> rankevalcontext rankcontext = new rankevalcontext ( parsefieldmatcher . strict , querycontext ,
public class discountedcumulativegainat extends rankedlistqualitymetric < discount <nl>  <nl> / * * <nl> * @ param position number of top results to check against a given set of relevant results . must be positive . <nl> - * <nl> * @ param normalize if set to true , dcg will be normalized ( ndcg ) <nl> * see https : / / en . wikipedia . org / wiki / discounted_cumulative_gain <nl> * @ param unknowndocrating the rating for docs the user hasn ' t supplied an explicit rating for <nl> * * / <nl> public discountedcumulativegainat ( int position , boolean normalize , integer unknowndocrating ) { <nl> - this . position = position ; <nl> + this ( position ) ; <nl> this . normalize = normalize ; <nl> this . unknowndocrating = unknowndocrating ; <nl> } <nl>  <nl> + public discountedcumulativegainat ( streaminput in ) throws ioexception { <nl> + this ( in . readint ( ) ) ; <nl> + normalize = in . readboolean ( ) ; <nl> + unknowndocrating = in . readoptionalvint ( ) ; <nl> + } <nl> + <nl> + @ override <nl> + public void writeto ( streamoutput out ) throws ioexception { <nl> + out . writeint ( position ) ; <nl> + out . writeboolean ( normalize ) ; <nl> + out . writeoptionalvint ( unknowndocrating ) ; <nl> + } <nl> + <nl> + @ override <nl> + public string getwriteablename ( ) { <nl> + return name ; <nl> + } <nl> + <nl> / * * <nl> * return number of search results to check for quality metric . <nl> * / <nl>
public abstract class blobstorerepository extends abstractlifecyclecomponent imp <nl> stream = new ratelimitinginputstream ( partslicestream , restoreratelimiter , restoreratelimitingtimeinnanos : : inc ) ; <nl> } <nl>  <nl> - <nl> - / / it ' s not cleaned up yet , the restore process tries to reuse files <nl> + / / a restore could possibly overwrite existing segment files due to any number of reasons , <nl> + / / for example if the primary was snapshotted and then the replica was promoted to primary <nl> + / / with different segment files . in this case , the goal of the restore is to forget about <nl> + / / what is currently in the <nl> + / / hence , we are deleting files here if they already exist before writing to them . a better <nl> + / / long term solution would be to use recovery for restoring , so we have more robust restoring <nl> + / / of files ( copying to temporary files first and then moving them over ) . <nl> ioutils . deletefilesignoringexceptions ( store . directory ( ) , fileinfo . physicalname ( ) ) ; <nl>  <nl> try ( final indexoutput indexoutput = store . createverifyingoutput ( fileinfo . physicalname ( ) , fileinfo . metadata ( ) , iocontext . default ) ) {
public class transportrankevalaction extends handledtransportaction < rankevalrequ <nl> this . searchtransportservice = searchtransportservice ; <nl> this . clusterservice = clusterservice ; <nl> this . actionfilters = actionfilters ; <nl> - <nl> - <nl> - namedwriteableregistry . register ( rankedlistqualitymetric . class , precisionatn . name , precisionatn : : new ) ; <nl> } <nl>  <nl> @ override <nl> mmm a / modules / rank - eval / src / test / java / org / elasticsearch / index / rankeval / queryspectests . java <nl> ppp b / modules / rank - eval / src / test / java / org / elasticsearch / index / rankeval / queryspectests . java <nl>
public class reststatustoxcontentlistener < response extends statustoxcontent > ext <nl> * build an instance that doesn ' t support responses with the status { @ code num created } . <nl> * / <nl> public reststatustoxcontentlistener ( restchannel channel ) { <nl> - <nl> - this ( channel , r - > null ) ; <nl> + this ( channel , r - > { <nl> + assert false : " returned a num created but not set up to support a location header " ; <nl> + return null ; <nl> + } ) ; <nl> } <nl>  <nl> / * *
public class azurestorageserviceimpl extends abstractcomponent implements azures <nl> public void removecontainer ( string account , locationmode mode , string container ) throws urisyntaxexception , storageexception { <nl> cloudblobclient client = this . getselectedclient ( account , mode ) ; <nl> cloudblobcontainer blobcontainer = client . getcontainerreference ( container ) ; <nl> - <nl> - / * <nl> - blobrequestoptions options = new blobrequestoptions ( ) ; <nl> - options . settimeoutintervalinms ( 1000 ) ; <nl> - options . setretrypolicyfactory ( new retrynoretry ( ) ) ; <nl> - blobcontainer . deleteifexists ( options , null ) ; <nl> - * / <nl> logger . trace ( " removing container [ { } ] " , container ) ; <nl> blobcontainer . deleteifexists ( ) ; <nl> }
public class stash implements toxcontent { <nl> } <nl> } <nl>  <nl> - public void stashresponse ( resttestresponse response ) throws ioexception { <nl> - <nl> - stashvalue ( " body " , response . getbody ( ) ) ; <nl> - this . response = response ; <nl> - } <nl> - <nl> / * * <nl> * clears the previously stashed values <nl> * / <nl>
public interface queryparser < qb extends querybuilder > { <nl> * @ return the new querybuilder <nl> * / <nl> optional < qb > fromxcontent ( queryparsecontext parsecontext ) throws ioexception ; <nl> - <nl> - / * * <nl> - * @ return an empty { @ link querybuilder } instance for this parser that can be used for deserialization <nl> - * / <nl> - default qb getbuilderprototype ( ) { <nl> - throw new unsupportedoperationexception ( ) ; <nl> - } <nl> }
dependencies { <nl> } <nl> compile " org . openjdk . jmh : jmh - core : $ versions . jmh " <nl> compile " org . openjdk . jmh : jmh - generator - annprocess : $ versions . jmh " <nl> - <nl> runtime ' net . sf . jopt - simple : jopt - simple : 4 . 6 ' <nl> runtime ' org . apache . commons : commons - math3 : 3 . 2 ' <nl> } <nl> mmm a / benchmarks / src / main / java / org / elasticsearch / benchmark / datebenchmark . java <nl> ppp / dev / null <nl>
public final class restclient implements closeable { <nl> } <nl>  <nl> list < httphost > rotatedhosts = new arraylist < > ( filteredhosts ) ; <nl> - <nl> collections . rotate ( rotatedhosts , rotatedhosts . size ( ) - lasthostindex . getandincrement ( ) ) ; <nl> return rotatedhosts ; <nl> }
forbiddenapismain { <nl> } <nl>  <nl> forbiddenapistest { <nl> - / / we are excluding jdk - non - portable to allow for com . sun . net . httpserver . * usage <nl> - <nl> - bundledsignatures = [ ' jdk - unsafe ' , ' jdk - deprecated ' , ' jdk - system - out ' ] <nl> + / / we are using jdk - internal instead of jdk - non - portable to allow for com . sun . net . httpserver . * usage <nl> + bundledsignatures - = ' jdk - non - portable ' <nl> + bundledsignatures + = ' jdk - internal ' <nl> / / client does not depend on core , so only jdk signatures should be checked <nl> signaturesurls = [ precommittasks . getresource ( ' / forbidden / jdk - signatures . txt ' ) ] <nl> } <nl> mmm a / client / build . gradle <nl> ppp b / client / build . gradle <nl>
forbiddenapismain { <nl> } <nl>  <nl> forbiddenapistest { <nl> - / / we are excluding jdk - non - portable to allow for com . sun . net . httpserver . * usage <nl> - <nl> - bundledsignatures = [ ' jdk - unsafe ' , ' jdk - deprecated ' , ' jdk - system - out ' ] <nl> + / / we are using jdk - internal instead of jdk - non - portable to allow for com . sun . net . httpserver . * usage <nl> + bundledsignatures - = ' jdk - non - portable ' <nl> + bundledsignatures + = ' jdk - internal ' <nl> / / client does not depend on core , so only jdk signatures should be checked <nl> signaturesurls = [ precommittasks . getresource ( ' / forbidden / jdk - signatures . txt ' ) ] <nl> }
dependencies { <nl> testcompile " org . apache . lucene : lucene - core : $ { versions . lucene } " <nl> testcompile " org . apache . lucene : lucene - codecs : $ { versions . lucene } " <nl> testcompile " org . elasticsearch : securemock : $ { versions . securemock } " <nl> + signature " org . codehaus . mojo . signature : java17 : 1 . 0 @ signature " <nl> } <nl>  <nl> - <nl> compilejava . options . compilerargs < < ' - target ' < < ' 1 . 7 ' < < ' - source ' < < ' 1 . 7 ' < < ' - xlint : all , - path , - serial , - options ' <nl> compiletestjava . options . compilerargs < < ' - target ' < < ' 1 . 7 ' < < ' - source ' < < ' 1 . 7 ' <nl>  <nl>
dependencies { <nl> testcompile " org . apache . lucene : lucene - core : $ { versions . lucene } " <nl> testcompile " org . apache . lucene : lucene - codecs : $ { versions . lucene } " <nl> testcompile " org . elasticsearch : securemock : $ { versions . securemock } " <nl> + signature " org . codehaus . mojo . signature : java17 : 1 . 0 @ signature " <nl> } <nl>  <nl> - <nl> compilejava . options . compilerargs < < ' - target ' < < ' 1 . 7 ' < < ' - source ' < < ' 1 . 7 ' < < ' - xlint : all , - path , - serial , - options ' <nl> compiletestjava . options . compilerargs < < ' - target ' < < ' 1 . 7 ' < < ' - source ' < < ' 1 . 7 ' <nl>  <nl>
jarhell . enabled = false <nl> / / namingconventioncheck is part of test - framework , which we don ' t want to pull in as it depends on es core <nl> namingconventions . enabled = false <nl>  <nl> - <nl> - dependencylicenses . enabled = false <nl> + dependencylicenses { <nl> + dependencies = project . configurations . runtime . filecollection { <nl> + it . group . startswith ( ' org . elasticsearch ' ) = = false <nl> + } <nl> + } <nl>  <nl> thirdpartyaudit . excludes = [ <nl> / / commons - logging optional dependencies
import java . util . list ; <nl> import java . util . map ; <nl>  <nl> / * * <nl> - * class responsible for sniffing the http hosts from elasticsearch through the nodes info api and returning them back <nl> + * class responsible for sniffing the http hosts from elasticsearch through the nodes info api and returning them back . <nl> + * compatible with elasticsearch num . x and num . x . <nl> * / <nl> - <nl> public class hostssniffer { <nl>  <nl> private static final log logger = logfactory . getlog ( hostssniffer . class ) ; <nl> mmm a / client - sniffer / src / test / java / org / elasticsearch / client / sniff / hostssniffertests . java <nl> ppp b / client - sniffer / src / test / java / org / elasticsearch / client / sniff / hostssniffertests . java <nl>
public final class def { <nl> } else if ( receiverclass . isarray ( ) ) { <nl> return arrayiteratorhelper . newiterator ( receiverclass ) ; <nl> } else { <nl> - <nl> throw new illegalargumentexception ( " cannot iterate over [ " + receiverclass . getcanonicalname ( ) + " ] " ) ; <nl> } <nl> }
<nl> import org . elasticsearch . gradle . precommit . precommittasks <nl> import org . gradle . api . javaversion <nl>  <nl> - group = ' org . elasticsearch . client ' <nl> apply plugin : ' elasticsearch . build ' <nl>  <nl> targetcompatibility = javaversion . version_1_7 <nl> sourcecompatibility = javaversion . version_1_7 <nl>  <nl> dependencies { <nl> - <nl> - compile " org . apache . httpcomponents : httpclient : 4 . 5 . 2 " <nl> - compile " org . apache . httpcomponents : httpcore : 4 . 4 . 4 " <nl> - / / compile " org . apache . httpcomponents : httpcore - nio : 4 . 4 . 4 " <nl> - / / compile " org . apache . httpcomponents : httpasyncclient : 4 . 1 . 1 " <nl> - compile " commons - codec : commons - codec : 1 . 9 " <nl> - compile " commons - logging : commons - logging : 1 . 2 " <nl> + compile " org . apache . httpcomponents : httpclient : $ { versions . httpclient } " <nl> + compile " org . apache . httpcomponents : httpcore : $ { versions . httpcore } " <nl> + compile " commons - codec : commons - codec : $ { versions . commonscodec } " <nl> + compile " commons - logging : commons - logging : $ { versions . commonslogging } " <nl> / / jackson is only needed in the sniff package <nl> - compile " com . fasterxml . jackson . core : jackson - core : 2 . 7 . 3 " <nl> + compile " com . fasterxml . jackson . core : jackson - core : $ { versions . jackson } " <nl>  <nl> testcompile " com . carrotsearch . randomizedtesting : randomizedtesting - runner : $ { versions . randomizedrunner } " <nl> testcompile " junit : junit : $ { versions . junit } "
package org . apache . log4j ; <nl> import org . apache . log4j . helpers . threadlocalmap ; <nl>  <nl> / * * <nl> - * <nl> + * log4j num . 2 mdc breaks because it parses java . version incorrectly ( does not handle new java9 versioning ) . <nl> + * <nl> + * this hack fixes up the pkg private members as if it had detected the java version correctly . <nl> * / <nl> public class java9hack { <nl>  <nl> public static void fixlog4j ( ) { <nl> - system . out . println ( " fixing log4j " ) ; <nl> if ( mdc . mdc . tlm = = null ) { <nl> - system . out . println ( " for real " ) ; <nl> + mdc . mdc . java1 = false ; <nl> mdc . mdc . tlm = new threadlocalmap ( ) ; <nl> } <nl> }
final class documentparser { <nl> context . path ( ) . remove ( ) ; <nl> } else { <nl>  <nl> - <nl> - final string [ ] paths = strings . splitstringtoarray ( currentfieldname , ' . ' ) ; <nl> + final string [ ] paths = currentfieldname . split ( " \ \ . " ) ; <nl> currentfieldname = paths [ paths . length - num ] ; <nl> tuple < integer , objectmapper > parentmappertuple = getdynamicparentmapper ( context , paths , mapper ) ; <nl> objectmapper parentmapper = parentmappertuple . v2 ( ) ; <nl>
final class documentparser { <nl> } <nl> } else { <nl>  <nl> - <nl> - final string [ ] paths = strings . splitstringtoarray ( arrayfieldname , ' . ' ) ; <nl> + final string [ ] paths = arrayfieldname . split ( " \ \ . " ) ; <nl> arrayfieldname = paths [ paths . length - num ] ; <nl> lastfieldname = arrayfieldname ; <nl> tuple < integer , objectmapper > parentmappertuple = getdynamicparentmapper ( context , paths , parentmapper ) ; <nl>
final class documentparser { <nl> parseobjectorfield ( context , mapper ) ; <nl> } else { <nl>  <nl> - <nl> - final string [ ] paths = strings . splitstringtoarray ( currentfieldname , ' . ' ) ; <nl> + final string [ ] paths = currentfieldname . split ( " \ \ . " ) ; <nl> currentfieldname = paths [ paths . length - num ] ; <nl> tuple < integer , objectmapper > parentmappertuple = getdynamicparentmapper ( context , paths , parentmapper ) ; <nl> parentmapper = parentmappertuple . v2 ( ) ;
class writerexternal { <nl> / / first parameter is the receiver , we never know its type : always object <nl> signature . append ( writerconstants . object_type . getdescriptor ( ) ) ; <nl>  <nl> - <nl> - / / it can avoid some unnecessary boxing etc . <nl> for ( int i = num ; i < arguments . size ( ) ; i + + ) { <nl> - signature . append ( writerconstants . object_type . getdescriptor ( ) ) ; <nl> + expressionmetadata arg = metadata . getexpressionmetadata ( arguments . get ( i ) ) ; <nl> + / / disable any implicit casts / conversion for arguments , let invokedynamic take care <nl> + arg . to = arg . from ; <nl> + arg . cast = new cast ( arg . from , arg . from ) ; <nl> + signature . append ( arg . from . type . getdescriptor ( ) ) ; <nl> writer . visit ( arguments . get ( i ) ) ; <nl> } <nl> signature . append ( ' ) ' ) ; <nl> - / / return value <nl> + / / return value : currently always object . making this better may be tricky . . . <nl> signature . append ( writerconstants . object_type . getdescriptor ( ) ) ; <nl> execute . visitinvokedynamicinsn ( ( string ) sourceenmd . target , signature . tostring ( ) , <nl> writerconstants . def_bootstrap_handle , new object [ ] { dynamiccallsite . method_call } ) ; <nl> mmm a / modules / lang - painless / src / test / java / org / elasticsearch / painless / whenthingsgowrongtests . java <nl> ppp b / modules / lang - painless / src / test / java / org / elasticsearch / painless / whenthingsgowrongtests . java <nl>
dependencies { <nl>  <nl>  <nl> / * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * <nl> - * bootstrap repositories and ide setup * <nl> + * bootstrap repositories * <nl> * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * / <nl> / / this will only happen when buildsrc is built on its own during build init <nl> if ( project = = rootproject ) { <nl>  <nl> - <nl> - apply plugin : ' idea ' <nl> - apply plugin : ' eclipse ' <nl> - <nl> repositories { <nl> mavencentral ( ) <nl> maven { <nl>
public class matchquery { <nl> } <nl>  <nl> protected query zerotermsquery ( ) { <nl> - <nl> - / / why are we then having this if clause in here ? <nl> return zerotermsquery = = default_zero_terms_query ? queries . newmatchnodocsquery ( ) : queries . newmatchallquery ( ) ; <nl> }
dependencies { <nl> / / watcher deps <nl> compile ' com . googlecode . owasp - java - html - sanitizer : owasp - java - html - sanitizer : r239 ' <nl> compile ' com . google . guava : guava : 16 . 0 . 1 ' / / needed by watcher for the html sanitizer and shield tests for jimfs <nl> - compile ' com . google . code . findbugs : jsr305 : 3 . 0 . 1 ' <nl> compile ' com . sun . mail : javax . mail : 1 . 5 . 3 ' <nl> testcompile ' org . subethamail : subethasmtp : 3 . 1 . 7 ' <nl> + / / needed for subethasmtp , has @ guardedby annotation <nl> + testcompile ' com . google . code . findbugs : jsr305 : 3 . 0 . 1 ' <nl>  <nl> / / common test deps <nl> testcompile ' org . elasticsearch : securemock : 1 . 2 ' <nl>
public interface queryparser < qb extends querybuilder < qb > > { <nl> * @ return the new querybuilder <nl> * / <nl> qb fromxcontent ( queryparsecontext parsecontext ) throws ioexception ; <nl> - <nl> - / * * <nl> - * @ return an empty { @ link querybuilder } instance for this parser that can be used for deserialization <nl> - * / <nl> - default qb getbuilderprototype ( ) { <nl> - throw new unsupportedoperationexception ( ) ; <nl> - } <nl> }
public class searchmodule extends abstractmodule { <nl> * / <nl> public < qb extends querybuilder < qb > > void registerquery ( writeable . reader < qb > reader , queryparser < qb > queryparser , <nl> parsefield queryname ) { <nl> - innerregisterqueryparser ( queryparser , queryname ) ; <nl> - namedwriteableregistry . register ( querybuilder . class , queryname . getpreferredname ( ) , reader ) ; <nl> - } <nl> - <nl> - / * * <nl> - * register a query via its parser ' s prototype . <nl> - * <nl> - * / <nl> - public void registerqueryparser ( queryparser < ? > queryparser , parsefield queryname ) { <nl> - innerregisterqueryparser ( queryparser , queryname ) ; <nl> - namedwriteableregistry . registerprototype ( querybuilder . class , queryparser . getbuilderprototype ( ) ) ; <nl> - } <nl> - <nl> - private < qb extends querybuilder < qb > > void innerregisterqueryparser ( queryparser < qb > parser , parsefield queryname ) { <nl> - tuple < parsefield , queryparser < ? > > parsefieldqueryparsertuple = new tuple < > ( queryname , parser ) ; <nl> + tuple < parsefield , queryparser < ? > > parsefieldqueryparsertuple = new tuple < > ( queryname , queryparser ) ; <nl> for ( string name : queryname . getallnamesincludeddeprecated ( ) ) { <nl> tuple < parsefield , queryparser < ? > > previousvalue = queryparsers . putifabsent ( name , parsefieldqueryparsertuple ) ; <nl> if ( previousvalue ! = null ) { <nl> throw new illegalargumentexception ( " query parser [ " + previousvalue . v2 ( ) + " ] already registered for name [ " + <nl> - name + " ] while trying to register [ " + parser + " ] " ) ; <nl> + name + " ] while trying to register [ " + queryparser + " ] " ) ; <nl> } <nl> } <nl> + <nl> + namedwriteableregistry . register ( querybuilder . class , queryname . getpreferredname ( ) , reader ) ; <nl> } <nl>  <nl> set < string > getregisteredqueries ( ) {
class installplugincommand extends command { <nl> } <nl> hasesdir = true ; <nl> path targetfile = target . resolve ( entry . getname ( ) . substring ( " elasticsearch / " . length ( ) ) ) ; <nl> - <nl> + <nl> + / / using the entry name as a path can result in an entry outside of the plugin dir , either if the <nl> + / / name starts with the root of the filesystem , or it is a relative entry like . . / whatever . <nl> + / / this check attempts to identify both cases by first normalizing the path ( which removes foo / . . ) <nl> + / / and ensuring the normalized entry is still rooted with the target plugin directory . <nl> + if ( targetfile . normalize ( ) . startswith ( target ) = = false ) { <nl> + throw new ioexception ( " zip contains entry name ' " + entry . getname ( ) + " ' resolving outside of plugin directory " ) ; <nl> + } <nl>  <nl> / / be on the safe side : do not rely on that directories are always extracted <nl> / / before their children ( although this makes sense , but is it guaranteed ? ) <nl> mmm a / qa / evil - tests / src / test / java / org / elasticsearch / plugins / installplugincommandtests . java <nl> ppp b / qa / evil - tests / src / test / java / org / elasticsearch / plugins / installplugincommandtests . java <nl>
class clusterformationtasks { <nl> ' node . testattr ' : ' test ' , <nl> ' repositories . url . allowed_urls ' : ' http : / / snapshot . test * ' <nl> ] <nl> - if ( node . config . numnodes = = num ) { <nl> - esconfig [ ' http . port ' ] = node . config . httpport <nl> - esconfig [ ' transport . tcp . port ' ] = node . config . transportport <nl> - } else { <nl> - <nl> - esconfig [ ' http . port ' ] = num + node . nodenum <nl> - esconfig [ ' transport . tcp . port ' ] = num + node . nodenum <nl> - esconfig [ ' discovery . zen . ping . unicast . hosts ' ] = ( 0 . . < node . config . numnodes ) . collect { " localhost : $ { 9500 + it } " } . join ( ' , ' ) <nl> - <nl> - } <nl> + esconfig [ ' http . port ' ] = node . config . httpport <nl> + esconfig [ ' transport . tcp . port ' ] = node . config . transportport <nl> esconfig . putall ( node . config . settings ) <nl>  <nl> task writeconfig = project . tasks . create ( name : name , type : defaulttask , dependson : setup ) <nl> writeconfig . dofirst { <nl> + if ( node . nodenum > num ) { / / multi - node cluster case , we have to wait for the seed node to startup <nl> + ant . waitfor ( maxwait : ' 20 ' , maxwaitunit : ' second ' , checkevery : ' 500 ' , checkeveryunit : ' millisecond ' ) { <nl> + resourceexists { <nl> + file ( file : node . config . seednodeportsfile . tostring ( ) ) <nl> + } <nl> + } <nl> + / / the seed node is enough to form the cluster - all subsequent nodes will get the seed node as a unicast <nl> + / / host and join the cluster via that . <nl> + esconfig [ ' discovery . zen . ping . unicast . hosts ' ] = " \ " $ { node . config . seednodetransporturi ( ) } \ " " <nl> + } <nl> file configfile = new file ( node . confdir , ' elasticsearch . yml ' ) <nl> logger . info ( " configuring $ { configfile } " ) <nl> configfile . settext ( esconfig . collect { key , value - > " $ { key } : $ { value } " } . join ( ' \n ' ) , ' utf - 8 ' )
final class documentparser implements closeable { <nl> } else if ( dynamic = = objectmapper . dynamic . true ) { <nl> mapper . builder builder = context . root ( ) . findtemplatebuilder ( context , arrayfieldname , " object " ) ; <nl> if ( builder = = null ) { <nl> - <nl> parsenondynamicarray ( context , parentmapper , lastfieldname , arrayfieldname ) ; <nl> return ; <nl> }
public class geodistancesortbuilder extends sortbuilder <nl> return this . order ; <nl> } <nl>  <nl> - / * * <nl> - * not relevant . <nl> - * <nl> - * <nl> - * / <nl> - @ override <nl> - public geodistancesortbuilder missing ( object missing ) { <nl> - return this ; <nl> - } <nl> - <nl> / * * <nl> * defines which distance to use for sorting in the case a document contains multiple geo points . <nl> * possible values : min and max <nl> mmm a / core / src / main / java / org / elasticsearch / search / sort / scoresortbuilder . java <nl> ppp b / core / src / main / java / org / elasticsearch / search / sort / scoresortbuilder . java <nl>
class buildplugin implements plugin < project > { <nl> / / we use ' . / temp ' since this is per jvm and tests are forbidden from writing to cwd <nl> systemproperty ' java . io . tmpdir ' , ' . / temp ' <nl> systemproperty ' java . awt . headless ' , ' true ' <nl> - systemproperty ' tests . maven ' , ' true ' <nl> + systemproperty ' tests . gradle ' , ' true ' <nl> systemproperty ' tests . artifact ' , project . name <nl> systemproperty ' tests . task ' , path <nl> systemproperty ' tests . security . manager ' , ' true ' <nl> mmm a / test / framework / src / main / java / org / elasticsearch / bootstrap / bootstrapfortesting . java <nl> ppp b / test / framework / src / main / java / org / elasticsearch / bootstrap / bootstrapfortesting . java <nl>
public class ingestdocumentmustacheit extends abstractmustachetests { <nl> list . add ( null ) ; <nl> document . put ( " list2 " , list ) ; <nl> ingestdocument ingestdocument = new ingestdocument ( " index " , " type " , " id " , null , null , null , null , document ) ; <nl> - <nl> - ingestdocument . setfieldvalue ( templateservice . compile ( " field1 " ) , valuesource . wrap ( " 1 { { list1 } } { { list2 } } " , templateservice ) ) ; <nl> - assertthat ( ingestdocument . getfieldvalue ( " field1 " , string . class ) , equalto ( " 1 [ foo , bar , null ] [ { field = value } , null ] " ) ) ; <nl> - <nl> - ingestdocument . setfieldvalue ( templateservice . compile ( " field1 " ) , valuesource . wrap ( " 2 { { _source . list1 } } { { _source . list2 } } " , templateservice ) ) ; <nl> - assertthat ( ingestdocument . getfieldvalue ( " field1 " , string . class ) , equalto ( " 2 [ foo , bar , null ] [ { field = value } , null ] " ) ) ; <nl> + ingestdocument . setfieldvalue ( templateservice . compile ( " field1 " ) , valuesource . wrap ( " 1 { { list1 . 0 } } { { list2 . 0 } } " , templateservice ) ) ; <nl> + assertthat ( ingestdocument . getfieldvalue ( " field1 " , string . class ) , equalto ( " 1 foo { field = value } " ) ) ; <nl> } <nl>  <nl> public void testaccessingestmetadataviatemplate ( ) { <nl>
public class metadataindexupgradeservice extends abstractcomponent { <nl> public indexmetadata upgradeindexmetadata ( indexmetadata indexmetadata ) { <nl> / / throws an exception if there are too - old segments : <nl> if ( isupgraded ( indexmetadata ) ) { <nl> - return archivebrokenindexsettings ( indexmetadata ) ; <nl> + assert indexmetadata = = archivebrokenindexsettings ( indexmetadata ) : " all settings must have been upgraded before " ; <nl> + return indexmetadata ; <nl> } <nl> checksupportedversion ( indexmetadata ) ; <nl> indexmetadata newmetadata = indexmetadata ; <nl> + / / we have to run this first otherwise in we try to create indexsettings <nl> + / / with broken settings and fail in checkmappingscompatibility <nl> + newmetadata = archivebrokenindexsettings ( newmetadata ) ; <nl> + / / only run the check with the upgraded settings ! ! <nl> checkmappingscompatibility ( newmetadata ) ; <nl> - newmetadata = markasupgraded ( newmetadata ) ; <nl> - return archivebrokenindexsettings ( newmetadata ) ; <nl> + return markasupgraded ( newmetadata ) ; <nl> } <nl>  <nl>  <nl> / * * <nl> * checks if the <nl> * / <nl> - private boolean isupgraded ( indexmetadata indexmetadata ) { <nl> - return indexmetadata . getupgradedversion ( ) . onorafter ( version . v_3_0_0 ) ; <nl> + boolean isupgraded ( indexmetadata indexmetadata ) { <nl> + return indexmetadata . getupgradedversion ( ) . onorafter ( version . current ) ; <nl> } <nl>  <nl> / * * <nl> mmm a / core / src / test / java / org / elasticsearch / cluster / metadata / metadataindexupgradeservicetests . java <nl> ppp b / core / src / test / java / org / elasticsearch / cluster / metadata / metadataindexupgradeservicetests . java <nl>
final class autoexpandreplicas { <nl> / / the value we recognize in the " max " position to mean all the nodes <nl> private static final string all_nodes_value = " all " ; <nl> public static final setting < autoexpandreplicas > setting = new setting < > ( indexmetadata . setting_auto_expand_replicas , " false " , ( value ) - > { <nl> - <nl> - int min ; <nl> - int max ; <nl> + final int min ; <nl> + final int max ; <nl> if ( booleans . parseboolean ( value , true ) = = false ) { <nl> return new autoexpandreplicas ( 0 , num , false ) ; <nl> }
public class threadpool extends abstractcomponent { <nl> public static final string force_merge = " force_merge " ; <nl> public static final string fetch_shard_started = " fetch_shard_started " ; <nl> public static final string fetch_shard_store = " fetch_shard_store " ; <nl> - public static final string ingest = " ingest " ; <nl> } <nl>  <nl> public enum threadpooltype { <nl>
package org . elasticsearch . ingest ; <nl>  <nl> import org . elasticsearch . env . environment ; <nl>  <nl> + import java . util . function . bifunction ; <nl> + <nl> / * * <nl> - * the ingest framework ( pipeline , processor and processor factory ) can ' t rely on es specific code . however some <nl> - * processors rely on reading files from the config directory . we can ' t add environment as a constructor parameter , <nl> - * so we need some code that provides the physical location of the configuration directory to the processor factories <nl> - * that need this and this is what this processor factory provider does . <nl> + * functional interface that allows to create a { @ link org . elasticsearch . ingest . processor . factory } once all the needed <nl> + * components are available at a later stage , more specifically the { @ link environment } and the { @ link templateservice } <nl> + * which some processors need . <nl> * / <nl> - <nl> @ functionalinterface <nl> - public interface processorfactoryprovider { <nl> - processor . factory get ( environment environment , templateservice templateservice ) ; <nl> + public interface processorfactoryprovider extends bifunction < environment , templateservice , processor . factory > { <nl> + <nl> } <nl> mmm a / plugins / ingest / src / main / java / org / elasticsearch / plugin / ingest / pipelinestore . java <nl> ppp b / plugins / ingest / src / main / java / org / elasticsearch / plugin / ingest / pipelinestore . java <nl>
public class watchstore extends abstractcomponent { <nl>  <nl> indexrequest createindexrequest ( string id , bytesreference source , long version ) { <nl> indexrequest indexrequest = new indexrequest ( index , doc_type , id ) ; <nl> - <nl> - if ( source . hasarray ( ) ) { <nl> - indexrequest . source ( source . array ( ) , source . arrayoffset ( ) , source . length ( ) ) ; <nl> - } else { <nl> - indexrequest . source ( source . tobytes ( ) ) ; <nl> - } <nl> + indexrequest . source ( source . tobytes ( ) ) ; <nl> indexrequest . version ( version ) ; <nl> return indexrequest ; <nl> }
<nl>  <nl> package org . elasticsearch . script . expression ; <nl>  <nl> - import org . apache . lucene . expressions . js . javascriptcompiler ; <nl> - import org . elasticsearch . specialpermission ; <nl> import org . elasticsearch . plugins . plugin ; <nl> import org . elasticsearch . script . scriptmodule ; <nl>  <nl> - import java . security . accesscontroller ; <nl> - import java . security . privilegedaction ; <nl> - import java . text . parseexception ; <nl> - <nl> public class expressionplugin extends plugin { <nl>  <nl> - / / lucene expressions has crazy checks in its clinit for the functions map <nl> - / / it violates rules of classloaders to detect accessibility <nl> - <nl> - static { <nl> - securitymanager sm = system . getsecuritymanager ( ) ; <nl> - if ( sm ! = null ) { <nl> - sm . checkpermission ( new specialpermission ( ) ) ; <nl> - } <nl> - accesscontroller . doprivileged ( new privilegedaction < void > ( ) { <nl> - @ override <nl> - public void run ( ) { <nl> - try { <nl> - javascriptcompiler . compile ( " 0 " ) ; <nl> - } catch ( parseexception e ) { <nl> - throw new runtimeexception ( e ) ; <nl> - } <nl> - return null ; <nl> - } <nl> - } ) ; <nl> - } <nl> - <nl> @ override <nl> public string name ( ) { <nl> return " lang - expression " ;
dependencies { <nl> testcompile project ( path : ' : modules : lang - groovy ' , configuration : ' runtime ' ) <nl> } <nl>  <nl> - <nl> - / / into the test classpath : if it did , then things will work <nl> - test { <nl> - systemproperty ' tests . security . manager ' , ' false ' <nl> + gradle . projectsevaluated { <nl> + project groovy = project ( ' : modules : lang - groovy ' ) <nl> + sourcesets . test . resources { <nl> + srcdir groovy . pluginproperties . generatedresourcesdir <nl> + srcdir new file ( groovy . projectdir , ' src / main / plugin - metadata ' ) <nl> + } <nl> + test . dependson groovy . pluginproperties <nl> }
integtest { <nl> cluster { <nl> plugin ' license ' , project ( ' : x - plugins : license : plugin ' ) <nl> plugin ' watcher ' , project ( ' : x - plugins : watcher ' ) <nl> - <nl> - plugin ' groovy ' , project ( ' : modules : lang - groovy ' ) <nl> systemproperty ' es . script . inline ' , ' on ' <nl> } <nl> }
public class dependencylicensestask extends defaulttask { <nl>  <nl> @ taskaction <nl> public void checkdependencies ( ) { <nl> - <nl> - if ( licensesdir . exists ( ) = = false ) { <nl> - return <nl> - } <nl> - if ( licensesdir . exists ( ) = = false & & dependencies . isempty ( ) = = false ) { <nl> + if ( dependencies . isempty ( ) ) { <nl> + if ( licensesdir . exists ( ) ) { <nl> + throw new gradleexception ( " licenses dir $ { licensesdir } exists , but there are no dependencies " ) <nl> + } <nl> + return / / no dependencies to check <nl> + } else if ( licensesdir . exists ( ) = = false ) { <nl> throw new gradleexception ( " licences dir $ { licensesdir } does not exist , but there are dependencies " ) <nl> } <nl> - if ( licensesdir . exists ( ) & & dependencies . isempty ( ) ) { <nl> - throw new gradleexception ( " licenses dir $ { licensesdir } exists , but there are no dependencies " ) <nl> - } <nl> + <nl>  <nl> / / order is the same for keys and values iteration since we use a linked hashmap <nl> list < string > mapped = new arraylist < > ( mappings . values ( ) ) <nl> mmm a / test - framework / build . gradle <nl> ppp b / test - framework / build . gradle <nl>
public class routingtable implements iterable < indexroutingtable > , diffable < routi <nl> private static predicate < shardrouting > active_predicate = shardrouting - > shardrouting . active ( ) ; <nl> private static predicate < shardrouting > assigned_predicate = shardrouting - > shardrouting . assignedtonode ( ) ; <nl>  <nl> - <nl> private groupshardsiterator allsatisfyingpredicateshardsgrouped ( string [ ] indices , boolean includeempty , boolean includerelocationtargets , predicate < shardrouting > predicate ) { <nl> / / use list here since we need to maintain identity across shards <nl> arraylist < sharditerator > set = new arraylist < > ( ) ; <nl>
public class routingtable implements iterable < indexroutingtable > , diffable < routi <nl> return allshardssatisfyingpredicate ( indices , shardrouting - > true , true ) ; <nl> } <nl>  <nl> - <nl> private shardsiterator allshardssatisfyingpredicate ( string [ ] indices , predicate < shardrouting > predicate , boolean includerelocationtargets ) { <nl> / / use list here since we need to maintain identity across shards <nl> list < shardrouting > shards = new arraylist < > ( ) ;
public final class data { <nl>  <nl> @ suppresswarnings ( " unchecked " ) <nl> public < t > t getproperty ( string path ) { <nl> - <nl> - / / also xcontentmapvalues has no support to get specific values from arrays , see : https : / / github . com / elastic / elasticsearch / issues / 14324 <nl> - return ( t ) xcontentmapvalues . extractvalue ( path , document ) ; <nl> + object property = get ( path ) ; <nl> + return ( t ) property ; <nl> } <nl>  <nl> + / * * <nl> + * <nl> + * @ param path the path within the document in dot - notation <nl> + * @ return true if the document contains the property , false otherwise <nl> + * / <nl> public boolean containsproperty ( string path ) { <nl> + return getproperty ( path ) ! = null ; <nl> + } <nl> + <nl> + private object get ( string path ) { <nl> if ( path = = null | | path . length ( ) = = num ) { <nl> - return false ; <nl> + return null ; <nl> } <nl> - <nl> - boolean containsproperty = false ; <nl> string [ ] pathelements = strings . splitstringtoarray ( path , ' . ' ) ; <nl> - if ( pathelements . length = = num ) { <nl> - return false ; <nl> - } <nl> - <nl> - map < string , object > inner = document ; <nl> - <nl> - for ( int i = num ; i < pathelements . length ; i + + ) { <nl> - if ( inner = = null ) { <nl> - containsproperty = false ; <nl> - break ; <nl> - } <nl> - if ( i = = pathelements . length - num ) { <nl> - containsproperty = inner . containskey ( pathelements [ i ] ) ; <nl> - break ; <nl> - } <nl> + assert pathelements . length > num ; <nl>  <nl> - object obj = inner . get ( pathelements [ i ] ) ; <nl> + map < string , object > innermap = document ; <nl> + for ( int i = num ; i < pathelements . length - num ; i + + ) { <nl> + object obj = innermap . get ( pathelements [ i ] ) ; <nl> if ( obj instanceof map ) { <nl> - inner = ( map < string , object > ) obj ; <nl> + @ suppresswarnings ( " unchecked " ) <nl> + map < string , object > stringobjectmap = ( map < string , object > ) obj ; <nl> + innermap = stringobjectmap ; <nl> } else { <nl> - inner = null ; <nl> + return null ; <nl> } <nl> } <nl>  <nl> - return containsproperty ; <nl> + string leafkey = pathelements [ pathelements . length - num ] ; <nl> + return innermap . get ( leafkey ) ; <nl> } <nl>  <nl> / * * <nl> - * add ` value ` to path in document . if path does not exist , <nl> + * adds the provided value to path in document . if path does not exist , <nl> * nested maps will be put in as parent key values until <nl> * leaf key name in path is reached . <nl> * <nl>
public class geodistancerangequerytests extends abstractquerytestcase < geodistanc <nl> } <nl> } <nl> geopoint point = builder . point ( ) ; <nl> - <nl> - final double disttopole = sloppymath . haversin ( point . lat ( ) , point . lon ( ) , ( point . lat ( ) < 0 ) ? - 90 . 0 : num . 0 , point . lon ( ) ) ; <nl> - final double maxradius = geoutils . maxradialdistance ( point , disttopole ) ; <nl> - <nl> + final double maxradius = geoutils . maxradialdistance ( point ) ; <nl> final int fromvaluemeters = randomint ( ( int ) ( maxradius * 0 . 5 ) ) ; <nl> final int tovaluemeters = randomintbetween ( fromvaluemeters + num , ( int ) maxradius ) ; <nl> distanceunit fromtounits = randomfrom ( distanceunit . values ( ) ) ;
public class ingestmodule extends abstractmodule { <nl> protected void configure ( ) { <nl> binder ( ) . bind ( ingestrestfilter . class ) . aseagersingleton ( ) ; <nl> binder ( ) . bind ( pipelineexecutionservice . class ) . aseagersingleton ( ) ; <nl> - <nl> binder ( ) . bind ( pipelinestore . class ) . aseagersingleton ( ) ; <nl> binder ( ) . bind ( pipelinestoreclient . class ) . aseagersingleton ( ) ; <nl>  <nl> mmm a / plugins / ingest / src / main / java / org / elasticsearch / plugin / ingest / transport / simulate / simulatepipelineresponse . java <nl> ppp b / plugins / ingest / src / main / java / org / elasticsearch / plugin / ingest / transport / simulate / simulatepipelineresponse . java <nl>
public class shieldlicensee extends abstractlicenseecomponent < shieldlicensee > im <nl> } <nl>  <nl> @ override <nl> - protected void dostart ( ) throws elasticsearchexception { ; <nl> - if ( istribenode ) { <nl> - <nl> - this . status = new status ( operationmode . trial , licensestate . enabled ) ; <nl> - shieldlicensestate . updatestatus ( status ) ; <nl> - } else { <nl> + protected void dostart ( ) throws elasticsearchexception { <nl> + / / we rely on the initial licensee state to be enabled with trial operation mode <nl> + / / to ensure no operation is blocked due to not registering the licensee on a <nl> + / / tribe node <nl> + if ( ! istribenode ) { <nl> super . dostart ( ) ; <nl> } <nl> }
public class ingestmodule extends abstractmodule { <nl> addprocessor ( simpleprocessor . type , new simpleprocessor . factory ( ) ) ; <nl> addprocessor ( geoipprocessor . type , new geoipprocessor . factory ( ) ) ; <nl> addprocessor ( grokprocessor . type , new grokprocessor . factory ( ) ) ; <nl> - <nl> - <nl> + addprocessor ( dateprocessor . type , new dateprocessor . factory ( ) ) ; <nl>  <nl> mapbinder < string , processor . factory > mapbinder = mapbinder . newmapbinder ( binder ( ) , string . class , processor . factory . class ) ; <nl> for ( map . entry < string , processor . factory > entry : processors . entryset ( ) ) {
class clusterformationtasks { <nl> setup = project . tasks . create ( name : " $ { task . name } # configure " , type : defaulttask , dependson : setup ) < < { <nl> file configfile = new file ( home , ' config / elasticsearch . yml ' ) <nl> logger . info ( " configuring $ { configfile } " ) <nl> - map esconfig = [ <nl> - ' cluster . name ' : clustername , <nl> - ' http . port ' : config . httpport , <nl> - ' transport . tcp . port ' : config . transportport , <nl> - ' pidfile ' : pidfile , <nl> - <nl> - ' discovery . zen . ping . unicast . hosts ' : " localhost : $ { config . transportport } " , <nl> - ' path . repo ' : " $ { home } / repo " , <nl> - ' path . shared_data ' : " $ { home } / . . / " , <nl> - / / define a node attribute so we can test that it exists <nl> - ' node . testattr ' : ' test ' , <nl> - ' repositories . url . allowed_urls ' : ' http : / / snapshot . test * ' <nl> - ] <nl> configfile . settext ( esconfig . collect { key , value - > " $ { key } : $ { value } " } . join ( ' \n ' ) , ' utf - 8 ' ) <nl> } <nl> for ( map . entry < string , string > command : config . setupcommands . entryset ( ) ) { <nl>
if ( hasproperty ( ' projectsprefix ' ) = = false ) { <nl> } <nl> } <nl>  <nl> - / / ecplise configuration <nl> + / / eclipse configuration <nl> allprojects { <nl> apply plugin : ' eclipse ' <nl>  <nl> - <nl> - eclipse { <nl> - classpath { <nl> - defaultoutputdir = new file ( project . builddir , ' eclipse ' ) <nl> + plugins . withtype ( javabaseplugin ) { <nl> + eclipse . classpath . defaultoutputdir = new file ( project . builddir , ' eclipse ' ) <nl> + eclipse . classpath . file . whenmerged { classpath - > <nl> + / / give each source folder a unique corresponding output folder <nl> + int i = num ; <nl> + classpath . entries . findall { it instanceof sourcefolder } . each { folder - > <nl> + i + + ; <nl> + / / this is * not * a path or a file . <nl> + folder . output = " build / eclipse / " + i <nl> + } <nl> } <nl> } <nl> / / otherwise the eclipse merging is * super confusing * <nl> mmm a / plugins / delete - by - query / . gitignore <nl> ppp / dev / null <nl>
public final class data { <nl> this . document = document ; <nl> } <nl>  <nl> - <nl> @ suppresswarnings ( " unchecked " ) <nl> public < t > t getproperty ( string path ) { <nl> return ( t ) xcontentmapvalues . extractvalue ( path , document ) ; <nl>
public class attachmentmapper extends fieldmapper { <nl> / / set the maximum length of strings returned by the parsetostring method , - 1 sets no limit <nl> parsedcontent = tika . parsetostring ( streaminput . wrap ( content ) , metadata , indexedchars ) ; <nl> } catch ( throwable e ) { <nl> - / / it could happen that tika adds a system property ` sun . font . fontmanager ` which should not happen <nl> - <nl> - system . clearproperty ( " sun . font . fontmanager " ) ; <nl> - <nl> / / # 18 : we could ignore errors when tika does not parse data <nl> if ( ! ignoreerrors ) { <nl> logger . trace ( " exception caught " , e ) ;
governing permissions and limitations under the license . - - > <nl> < tests . rest . suite > cloud_gce < / tests . rest . suite > <nl> < tests . rest . load_packaged > false < / tests . rest . load_packaged > <nl> < xlint . options > - xlint : - rawtypes , - unchecked < / xlint . options > <nl> - < ! - - <nl> - https : / / github . com / elastic / elasticsearch / issues / 13623 - - > <nl> - < skip . unit . tests > true < / skip . unit . tests > <nl> < / properties > <nl>  <nl> < dependencies >
import java . util . concurrent . executionexception ; <nl> * <nl> * @ author jessewilson @ google . com ( jesse wilson ) <nl> * / <nl> - <nl> - @ suppressforbidden ( reason = " this uses function in it ' s method declaration somewhere " ) <nl> public abstract class failablecache < k , v > { <nl>  <nl> - private final loadingcache < k , object > delegate = cachebuilder . newbuilder ( ) . build ( new cacheloader < k , object > ( ) { <nl> - @ override <nl> - public object load ( k key ) throws exception { <nl> - errors errors = new errors ( ) ; <nl> - v result = null ; <nl> - try { <nl> - result = failablecache . this . create ( key , errors ) ; <nl> - } catch ( errorsexception e ) { <nl> - errors . merge ( e . geterrors ( ) ) ; <nl> - } <nl> - return errors . haserrors ( ) ? errors : result ; <nl> - } <nl> - } ) ; <nl> + private final concurrenthashmap < k , object > cache = new concurrenthashmap < > ( ) ; <nl>  <nl> protected abstract v create ( k key , errors errors ) throws errorsexception ; <nl>  <nl> public v get ( k key , errors errors ) throws errorsexception { <nl> - try { <nl> - object resultorerror = delegate . get ( key ) ; <nl> - if ( resultorerror instanceof errors ) { <nl> - errors . merge ( ( errors ) resultorerror ) ; <nl> - throw errors . toexception ( ) ; <nl> - } else { <nl> - @ suppresswarnings ( " unchecked " ) / / create returned a non - error result , so this is safe <nl> - v result = ( v ) resultorerror ; <nl> - return result ; <nl> + object resultorerror = cache . get ( key ) ; <nl> + if ( resultorerror = = null ) { <nl> + synchronized ( this ) { <nl> + resultorerror = load ( key ) ; <nl> + / / we can ' t use cache . computeifabsent since this might be recursively call this api <nl> + cache . putifabsent ( key , resultorerror ) ; <nl> } <nl> - } catch ( executionexception e ) { <nl> - throw new runtimeexception ( e ) ; <nl> } <nl> + if ( resultorerror instanceof errors ) { <nl> + errors . merge ( ( errors ) resultorerror ) ; <nl> + throw errors . toexception ( ) ; <nl> + } else { <nl> + @ suppresswarnings ( " unchecked " ) / / create returned a non - error result , so this is safe <nl> + v result = ( v ) resultorerror ; <nl> + return result ; <nl> + } <nl> + } <nl> + <nl> + <nl> + private object load ( k key ) { <nl> + errors errors = new errors ( ) ; <nl> + v result = null ; <nl> + try { <nl> + result = create ( key , errors ) ; <nl> + } catch ( errorsexception e ) { <nl> + errors . merge ( e . geterrors ( ) ) ; <nl> + } <nl> + return errors . haserrors ( ) ? errors : result ; <nl> } <nl> }
public class indexshard extends abstractindexshardcomponent { <nl> indexingservice . onrefreshsettings ( settings ) ; <nl> if ( change ) { <nl> engine ( ) . onsettingschanged ( ) ; <nl> - <nl> - refresh ( " apply settings " ) ; <nl> } <nl> } <nl> }
grant { <nl> / / reflection hacks : <nl> / / needed by groovy engine <nl> permission java . lang . runtimepermission " accessclassinpackage . sun . reflect " ; <nl> - <nl> - permission java . lang . runtimepermission " accessclassinpackage . sun . security . ssl " ; <nl>  <nl> / / needed by randomizedrunner <nl> permission java . lang . runtimepermission " accessdeclaredmembers " ;
public class newpathforshardtest extends estestcase { <nl> return desc ; <nl> } <nl>  <nl> - <nl> - <nl> @ override <nl> public boolean isreadonly ( ) { <nl> return false ; <nl>
public class licensesrenderer extends abstractrenderer < licensesmarveldoc > { <nl> builder . endarray ( ) ; <nl> } <nl>  <nl> - <nl> - public static string status ( license license ) { <nl> - string status = " active " ; <nl> - long now = system . currenttimemillis ( ) ; <nl> - if ( license . issuedate ( ) > now ) { <nl> - status = " invalid " ; <nl> - } else if ( license . expirydate ( ) < now ) { <nl> - status = " expired " ; <nl> - } <nl> - return status ; <nl> - } <nl> - <nl> public static string hash ( license license , string clustername ) { <nl> - return hash ( status ( license ) , license . uid ( ) , license . type ( ) , string . valueof ( license . expirydate ( ) ) , clustername ) ; <nl> + return hash ( license . status ( ) . label ( ) , license . uid ( ) , license . type ( ) , string . valueof ( license . expirydate ( ) ) , clustername ) ; <nl> } <nl>  <nl> public static string hash ( string licensestatus , string licenseuid , string licensetype , string licenseexpirydate , string clusteruuid ) { <nl> mmm a / marvel / src / test / java / org / elasticsearch / marvel / agent / renderer / licenses / licensesrendererit . java <nl> ppp b / marvel / src / test / java / org / elasticsearch / marvel / agent / renderer / licenses / licensesrendererit . java <nl>
<nl> < startup - elasticsearch / > <nl> < / target > <nl>  <nl> - < ! - - <nl> - and verify the pid is really an es process ! ( fail otherwise ) - - > <nl> < target name = " stop - external - cluster " if = " integ . pidfile . exists " > <nl> < stop - node / > <nl> < / target >
public class filtersfunctionscorequery extends query { <nl>  <nl> @ override <nl> public weight createweight ( indexsearcher searcher , boolean needsscores ) throws ioexception { <nl> - <nl> - / / if we dont need scores , just return the underlying weight ? <nl> - weight subqueryweight = subquery . createweight ( searcher , needsscores ) ; <nl> + if ( needsscores = = false ) { <nl> + return subquery . createweight ( searcher , needsscores ) ; <nl> + } <nl> + <nl> + boolean subqueryneedsscores = combinefunction ! = combinefunction . replace ; <nl> weight [ ] filterweights = new weight [ filterfunctions . length ] ; <nl> for ( int i = num ; i < filterfunctions . length ; + + i ) { <nl> + subqueryneedsscores | = filterfunctions [ i ] . function . needsscores ( ) ; <nl> filterweights [ i ] = searcher . createnormalizedweight ( filterfunctions [ i ] . filter , false ) ; <nl> } <nl> - return new customboostfactorweight ( this , subqueryweight , filterweights ) ; <nl> + weight subqueryweight = subquery . createweight ( searcher , subqueryneedsscores ) ; <nl> + return new customboostfactorweight ( this , subqueryweight , filterweights , subqueryneedsscores ) ; <nl> } <nl>  <nl> class customboostfactorweight extends weight { <nl>  <nl> final weight subqueryweight ; <nl> final weight [ ] filterweights ; <nl> + final boolean needsscores ; <nl>  <nl> - public customboostfactorweight ( query parent , weight subqueryweight , weight [ ] filterweights ) throws ioexception { <nl> + public customboostfactorweight ( query parent , weight subqueryweight , weight [ ] filterweights , boolean needsscores ) throws ioexception { <nl> super ( parent ) ; <nl> this . subqueryweight = subqueryweight ; <nl> this . filterweights = filterweights ; <nl> + this . needsscores = needsscores ; <nl> } <nl>  <nl> @ override <nl>
public class pluginmanager { <nl> plugininfo info = plugininfo . readfromproperties ( root ) ; <nl> terminal . println ( " % s " , info ) ; <nl>  <nl> - / / create list of current jars in classpath <nl> - final list < url > jars = new arraylist < > ( ) ; <nl> - classloader loader = pluginmanager . class . getclassloader ( ) ; <nl> - if ( loader instanceof urlclassloader ) { <nl> - collections . addall ( jars , ( ( urlclassloader ) loader ) . geturls ( ) ) ; <nl> - } <nl> - <nl> - <nl> - / / add plugin jars to the list <nl> - path pluginjars [ ] = filesystemutils . files ( root , " * . jar " ) ; <nl> - for ( path jar : pluginjars ) { <nl> - jars . add ( jar . touri ( ) . tourl ( ) ) ; <nl> - } <nl> - <nl> - / / check combined ( current classpath + new jars to - be - added ) <nl> - try { <nl> - jarhell . checkjarhell ( jars . toarray ( new url [ jars . size ( ) ] ) ) ; <nl> - } catch ( exception ex ) { <nl> - throw new runtimeexception ( ex ) ; <nl> + / / check for jar hell before any copying <nl> + if ( info . isjvm ( ) ) { <nl> + jarhellcheck ( root , info . isisolated ( ) ) ; <nl> } <nl>  <nl> / / install plugin <nl>
<nl> < configuration > <nl> < target > <nl> < ant antfile = " $ { elasticsearch . integ . antfile } " target = " stop - external - cluster " / > <nl> - < ! - - <nl> - < ant antfile = " $ { elasticsearch . integ . antfile } " target = " fixup - failsafe - summary " / > <nl> < / target > <nl> < / configuration > <nl> < / execution > <nl> mmm a / dev - tools / src / main / resources / ant / fixup - failsafe - summary . xslt <nl> ppp / dev / null <nl>
<nl> < delete file = " $ { integ . pidfile } " / > <nl> < / target > <nl>  <nl> - < ! - - <nl> - < target name = " fixup - failsafe - summary " unless = " $ { shouldskip } " > <nl> - < xslt in = " $ { project . build . directory } / failsafe - reports / failsafe - summary - buggy . xml " <nl> - out = " $ { project . build . directory } / failsafe - reports / failsafe - summary . xml " <nl> - style = " $ { elasticsearch . tools . directory } / ant / fixup - failsafe - summary . xslt " / > <nl> - < / target > <nl> - <nl> < / project > <nl> mmm a / plugins / pom . xml <nl> ppp b / plugins / pom . xml <nl>
<nl> < configuration > <nl> < target > <nl> < ant antfile = " $ { elasticsearch . integ . antfile } " target = " stop - external - cluster " / > <nl> - < ! - - <nl> - < ant antfile = " $ { elasticsearch . integ . antfile } " target = " fixup - failsafe - summary " / > <nl> < / target > <nl> < / configuration > <nl> < / execution > <nl> mmm a / pom . xml <nl> ppp b / pom . xml <nl>
<nl> args = " $ { integ . args } - des . path . repo = $ { integ . repo . home } " / > <nl>  <nl> < ! - - begin shield plugin mods - - > <nl> - < ! - - <nl> - < exec executable = " chmod " failonerror = " true " osfamily = " unix " > <nl> - < arg line = " - r a + r $ { integ . home } / bin / elasticsearch - shield " / > <nl> - < / exec > <nl> - <nl> < run - script dir = " $ { integ . home } " script = " bin / elasticsearch - shield / esusers " <nl> args = " useradd test_user - p changeme - r admin " / >
final class security { <nl> for ( map . entry < pattern , string > e : special_jars . entryset ( ) ) { <nl> if ( e . getkey ( ) . matcher ( url . getpath ( ) ) . matches ( ) ) { <nl> string prop = e . getvalue ( ) ; <nl> - <nl> - / / to add back this safety check ! see https : / / github . com / elastic / elasticsearch / issues / 11647 <nl> - / / if ( system . getproperty ( prop ) ! = null ) { <nl> - / / throw new illegalstateexception ( " property : " + prop + " is unexpectedly set : " + system . getproperty ( prop ) ) ; <nl> - / / } <nl> + if ( system . getproperty ( prop ) ! = null ) { <nl> + throw new illegalstateexception ( " property : " + prop + " is unexpectedly set : " + system . getproperty ( prop ) ) ; <nl> + } <nl> system . setproperty ( prop , url . tostring ( ) ) ; <nl> } <nl> }
public class licenseutils { <nl> * < code > feature < / code > accessible through { @ link # expired_feature_header } in the <nl> * exception ' s rest header <nl> * / <nl> - public static elasticsearchexception newexpirationexception ( string feature ) { <nl> - <nl> - return new elasticsearchexception . withrestheadersexception ( " license expired for feature [ " + feature + " ] " , <nl> - tuple . tuple ( expired_feature_header , new string [ ] { feature } ) ) ; <nl> + public static elasticsearchsecurityexception newexpirationexception ( string feature ) { <nl> + elasticsearchsecurityexception e = new elasticsearchsecurityexception ( " license expired for feature [ { } ] " , reststatus . unauthorized , feature ) ; <nl> + e . addheader ( expired_feature_header , feature ) ; <nl> + return e ; <nl> } <nl> }
<nl>  <nl> < dependencies > <nl> < ! - - test deps - - > <nl> - < ! - - <nl> - ordering issues with hamcrap matchers - - > <nl> - < dependency > <nl> - < groupid > org . hamcrest < / groupid > <nl> - < artifactid > hamcrest - all < / artifactid > <nl> - < scope > test < / scope > <nl> - < / dependency > <nl> < dependency > <nl> < groupid > org . apache . lucene < / groupid > <nl> < artifactid > lucene - expressions < / artifactid > <nl> < scope > test < / scope > <nl> < / dependency > <nl> - < dependency > <nl> - < groupid > com . google . guava < / groupid > <nl> - < artifactid > guava < / artifactid > <nl> - < scope > test < / scope > <nl> - < / dependency > <nl> < dependency > <nl> < groupid > org . slf4j < / groupid > <nl> < artifactid > slf4j - log4j12 < / artifactid >
grant { <nl> / / needed by jdkesloggertests <nl> permission java . util . logging . loggingpermission " control " ; <nl>  <nl> - / / needed by mockito to create mocks <nl> - <nl> - permission java . lang . runtimepermission " reflectionfactoryaccess " ; <nl> - <nl> / / needed to install sslfactories , advanced ssl configuration , etc . <nl> permission java . lang . runtimepermission " setfactory " ; <nl> } ;
public class restoreservice extends abstractcomponent implements clusterstatelis <nl> immutablelist < string > filteredindices = snapshotutils . filterindices ( snapshot . indices ( ) , request . indices ( ) , request . indicesoptions ( ) ) ; <nl> metadata metadatain = repository . readsnapshotmetadata ( snapshotid , filteredindices ) ; <nl>  <nl> - / / es num . 0 now requires units for all time and byte - sized settings , so we add the default unit if it ' s missing in this snapshot : <nl> - <nl> - final metadata metadata = metadata . adddefaultunitsifneeded ( logger , metadatain ) ; <nl> + final metadata metadata ; <nl> + if ( snapshot . version ( ) . before ( version . v_2_0_0 ) ) { <nl> + / / es num . 0 now requires units for all time and byte - sized settings , so we add the default unit if it ' s missing in this snapshot : <nl> + metadata = metadata . adddefaultunitsifneeded ( logger , metadatain ) ; <nl> + } else { <nl> + / / units are already enforced : <nl> + metadata = metadatain ; <nl> + } <nl>  <nl> / / make sure that we can restore from this snapshot <nl> validatesnapshotrestorable ( snapshotid , snapshot ) ;
public class timevalue implements serializable , streamable { <nl> } <nl> try { <nl> long millis ; <nl> - <nl> - / / s / s and h / h ) : <nl> string lowersvalue = svalue . tolowercase ( locale . root ) . trim ( ) ; <nl> if ( lowersvalue . endswith ( " ms " ) ) { <nl> millis = ( long ) ( double . parsedouble ( lowersvalue . substring ( 0 , lowersvalue . length ( ) - num ) ) ) ; <nl> mmm a / src / test / java / org / elasticsearch / cluster / settings / settingsvalidatortests . java <nl> ppp b / src / test / java / org / elasticsearch / cluster / settings / settingsvalidatortests . java <nl>
import static org . elasticsearch . index . engine . engine . operation . origin . primary ; <nl> import static org . elasticsearch . index . engine . engine . operation . origin . replica ; <nl> import static org . hamcrest . matchers . * ; <nl>  <nl> - <nl> - @ suppressfilesystems ( " * " ) <nl> public class internalenginetests extends elasticsearchtestcase { <nl>  <nl> protected final shardid shardid = new shardid ( new index ( " index " ) , num ) ; <nl>
class security { <nl> } <nl> path newconfig = processtemplate ( config , environment ) ; <nl> system . setproperty ( " java . security . policy " , newconfig . tostring ( ) ) ; <nl> + try { <nl> + policy policy = policy . getinstance ( " javapolicy " , new uriparameter ( newconfig . touri ( ) ) ) ; <nl> + system . out . println ( policy . getpermissions ( security . class . getprotectiondomain ( ) ) ) ; <nl> + } catch ( nosuchalgorithmexception e ) { <nl> + throw new runtimeexception ( ) ; <nl> + } <nl> system . setsecuritymanager ( new securitymanager ( ) ) ; <nl> - ioutils . deletefilesignoringexceptions ( newconfig ) ; <nl> + try { <nl> + / / don ' t hide securityexception here , it means java . io . tmpdir is not accessible ! <nl> + files . delete ( newconfig ) ; <nl> + } catch ( ioexception ignore ) { <nl> + / / e . g . virus scanner on windows <nl> + } <nl> } <nl>  <nl> / / package - private for testing
public class movavgreducer extends reducer { <nl> double thisbucketvalue = resolvebucketvalue ( histo , bucket , bucketspaths ( ) [ 0 ] , gappolicy ) ; <nl> currentkey = bucket . getkey ( ) ; <nl>  <nl> - if ( thisbucketvalue ! = null ) { <nl> + if ( ! ( thisbucketvalue = = null | | thisbucketvalue . equals ( double . nan ) ) ) { <nl> values . offer ( thisbucketvalue ) ; <nl>  <nl> - <nl> double movavg = model . next ( values ) ; <nl>  <nl> list < internalaggregation > aggs = new arraylist < > ( lists . transform ( bucket . getaggregations ( ) . aslist ( ) , function ) ) ;
<nl> < name > lucene snapshots < / name > <nl> < url > https : / / download . elastic . co / lucenesnapshots / 1674278 < / url > <nl> < / repository > <nl> - < ! - - <nl> - < repository > <nl> - < id > oss - sonatype < / id > <nl> - < name > temporarily situation < / name > <nl> - < url > http : / / oss . sonatype . org / content / repositories / releases < / url > <nl> - < / repository > <nl> < / repositories > <nl>  <nl> < dependencies >
public abstract class elasticsearchlucenetestcase extends lucenetestcase { <nl> public static int scaledrandomintbetween ( int min , int max ) { <nl> return randomizedtest . scaledrandomintbetween ( min , max ) ; <nl> } <nl> - <nl> - @ afterclass <nl> - public static void cleardefaultquerycache ( ) { <nl> - <nl> - indexsearcher . setdefaultquerycache ( null ) ; <nl> - } <nl> }
public class version { <nl> public static final int v_1_4_4_id = num ; <nl> public static final version v_1_4_4 = new version ( v_1_4_4_id , false , org . apache . lucene . util . version . lucene_4_10_3 ) ; <nl> public static final int v_1_4_5_id = num ; <nl> - public static final version v_1_4_5 = new version ( v_1_4_5_id , true , org . apache . lucene . util . version . lucene_4_10_3 ) ; <nl> + public static final version v_1_4_5 = new version ( v_1_4_5_id , true , org . apache . lucene . util . version . lucene_4_10_4 ) ; <nl> public static final int v_1_5_0_id = num ; <nl> - public static final version v_1_5_0 = new version ( v_1_5_0_id , false , org . apache . lucene . util . version . lucene_4_10_3 ) ; <nl> + public static final version v_1_5_0 = new version ( v_1_5_0_id , false , org . apache . lucene . util . version . lucene_4_10_4 ) ; <nl> public static final int v_1_5_1_id = num ; <nl> - public static final version v_1_5_1 = new version ( v_1_5_1_id , true , org . apache . lucene . util . version . lucene_4_10_3 ) ; <nl> + public static final version v_1_5_1 = new version ( v_1_5_1_id , true , org . apache . lucene . util . version . lucene_4_10_4 ) ; <nl> public static final int v_1_6_0_id = num ; <nl> - public static final version v_1_6_0 = new version ( v_1_6_0_id , true , org . apache . lucene . util . version . lucene_4_10_3 ) ; <nl> + public static final version v_1_6_0 = new version ( v_1_6_0_id , true , org . apache . lucene . util . version . lucene_4_10_4 ) ; <nl> public static final int v_2_0_0_id = num ; <nl> public static final version v_2_0_0 = new version ( v_2_0_0_id , true , org . apache . lucene . util . version . lucene_5_1_0 ) ;
public class alertsplugin extends abstractplugin { <nl> return settingsbuilder ( ) <nl> . put ( " threadpool . " + scheduler_thread_pool_name + " . type " , " fixed " ) <nl> . put ( " threadpool . " + scheduler_thread_pool_name + " . size " , availableprocessors * num ) <nl> - . put ( alertthreadpoolsettings ( availableprocessors , null ) ) <nl> + . put ( " threadpool . " + scheduler_thread_pool_name + " . queue_size " , num ) <nl> + . put ( " threadpool . " + name + " . type " , " fixed " ) <nl> + . put ( " threadpool . " + name + " . size " , availableprocessors * num ) <nl> + . put ( " threadpool . " + name + " . queue_size " , num ) <nl> . build ( ) ; <nl> } <nl>  <nl> - public static settings alertthreadpoolsettings ( int availableprocessors , integer queuesize ) { <nl> - / / executing an alert involves a lot of wait time for networking ( search , several <nl> - <nl> - if ( queuesize ! = null ) { <nl> - return settingsbuilder ( ) <nl> - . put ( " threadpool . " + name + " . type " , " fixed " ) <nl> - . put ( " threadpool . " + name + " . size " , availableprocessors * num ) <nl> - . put ( " threadpool . " + name + " . queue_size " , queuesize ) <nl> - . build ( ) ; <nl> - } else { <nl> - return settingsbuilder ( ) <nl> - . put ( " threadpool . " + name + " . type " , " fixed " ) <nl> - . put ( " threadpool . " + name + " . size " , availableprocessors * num ) <nl> - . build ( ) ; <nl> - } <nl> - } <nl> - <nl> }
public class indexaction extends action < indexaction . result > { <nl>  <nl> try { <nl> indexresponse response = client . index ( indexrequest ) . actionget ( ) ; <nl> - <nl> - / / return new result ( new payload . simple ( responsetodata ( response ) ) , null , true ) ; <nl> - return new result ( new payload . simple ( ) , null , response . iscreated ( ) ) ; <nl> + map < string , object > data = new hashmap < > ( ) ; <nl> + data . put ( " created " , response . iscreated ( ) ) ; <nl> + data . put ( " id " , response . getid ( ) ) ; <nl> + data . put ( " version " , response . getversion ( ) ) ; <nl> + data . put ( " type " , response . gettype ( ) ) ; <nl> + data . put ( " index " , response . getindex ( ) ) ; <nl> + return new result ( new payload . simple ( data ) , null , response . iscreated ( ) ) ; <nl> } catch ( elasticsearchexception e ) { <nl> logger . error ( " failed to <nl> return new result ( null , " failed to build <nl> mmm a / src / test / java / org / elasticsearch / alerts / bootstraptest . java <nl> ppp b / src / test / java / org / elasticsearch / alerts / bootstraptest . java <nl>
public class oldindexbackwardscompatibilitytests extends staticindexbackwardcomp <nl> ensuregreen ( " test " ) ; <nl> assertacked ( client ( ) . admin ( ) . indices ( ) . prepareupdatesettings ( " test " ) . setsettings ( immutablesettings . builder ( ) <nl> . put ( " number_of_replicas " , numreplicas ) ) . execute ( ) . actionget ( ) ) ; <nl> - ensuregreen ( " test " ) ; <nl> + ensuregreen ( timevalue . timevalueminutes ( 1 ) , " test " ) ; / / this can take a while when the number of replicas is high <nl>  <nl> assertacked ( client ( ) . admin ( ) . indices ( ) . prepareupdatesettings ( " test " ) . setsettings ( immutablesettings . builder ( ) <nl> . put ( " number_of_replicas " , num ) )
public class version implements serializable { <nl> public static final int v_1_4_3_id = / * 00 * / 1040399 ; <nl> public static final version v_1_4_3 = new version ( v_1_4_3_id , false , org . apache . lucene . util . version . lucene_4_10_2 ) ; <nl> public static final int v_1_5_0_id = / * 00 * / 1050099 ; <nl> - public static final version v_1_5_0 = new version ( v_1_5_0_id , false , org . apache . lucene . util . version . frombits ( 4 , num , num ) ) ; <nl> + public static final version v_1_5_0 = new version ( v_1_5_0_id , false , org . apache . lucene . util . version . lucene_4_10_3 ) ; <nl> public static final int v_2_0_0_id = / * 00 * / 2000099 ; <nl> public static final version v_2_0_0 = new version ( v_2_0_0_id , true , org . apache . lucene . util . version . lucene_5_0_0 ) ;
public class nomasternodetests extends abstractalertingtests { <nl>  <nl> @ test <nl> public void testmultiplefailures ( ) throws exception { <nl> - <nl> - / / it is not good enough yet : after multi a couple of kills errors occur and assertions fail . <nl> - int numberoffailures = num ; / / scaledrandomintbetween ( 2 , num ) ; <nl> + int numberoffailures = scaledrandomintbetween ( 2 , num ) ; <nl> int numberofalerts = scaledrandomintbetween ( numberoffailures , num ) ; <nl> config = new clusterdiscoveryconfiguration . unicastzen ( 2 + numberoffailures ) ; <nl> internaltestcluster ( ) . startnodesasync ( 2 ) . get ( ) ; <nl>
public class geohashgridtests extends elasticsearchintegrationtest { <nl> for ( int i = num ; i < numdocs ; i + + ) { <nl> final int numpoints = random . nextint ( 4 ) ; <nl> list < string > points = new arraylist < > ( ) ; <nl> - <nl> - / / the same geo hash , it will increase the doc_count for this geo hash by num instead of num <nl> - list < string > geohashes = new arraylist < > ( ) ; <nl> + set < string > geohashes = new hashset < > ( ) ; <nl> for ( int j = num ; j < numpoints ; + + j ) { <nl> double lat = ( 180d * random . nextdouble ( ) ) - num d ; <nl> double lng = ( 360d * random . nextdouble ( ) ) - num d ;
public class geojsonshapeparsertests extends elasticsearchtestcase { <nl> @ test <nl> public void testparse_invalidpolygon ( ) throws ioexception { <nl> / * * <nl> - * <nl> - * this test only checks number of coordinates , not the validity of the linearring <nl> + * the following num test cases ensure proper error handling of invalid polygons <nl> + * per the geojson specification <nl> * / <nl> / / test case num : create an invalid polygon with only num points <nl> string invalidpoly1 = xcontentfactory . jsonbuilder ( ) . startobject ( ) . field ( " type " , " polygon " ) <nl>
public abstract class elasticsearchbackwardscompatintegrationtest extends elasti <nl> private static file backwardscompatibilitypath ( ) { <nl> string path = system . getproperty ( tests_backwards_compatibility_path ) ; <nl> if ( path = = null | | path . isempty ( ) ) { <nl> - throw new illegalargumentexception ( " invalid backwards tests location path : " + path ) ; <nl> + throw new illegalargumentexception ( " must specify backwards test path with property " + tests_backwards_compatibility_path ) ; <nl> } <nl> string version = system . getproperty ( tests_backwards_compatibility_version ) ; <nl> if ( version = = null | | version . isempty ( ) ) { <nl> - throw new illegalargumentexception ( " invalid backwards tests version : " + version ) ; <nl> + throw new illegalargumentexception ( " must specify backwards test version with property " + tests_backwards_compatibility_version ) ; <nl> } <nl> if ( version . fromstring ( version ) . before ( version . current . minimumcompatibilityversion ( ) ) ) { <nl> throw new illegalargumentexception ( " backcompat elasticsearch version must be same major version as current . " + <nl> " backcompat : " + version + " , current : " + version . current . tostring ( ) ) ; <nl> } <nl> - file dir ; <nl> - if ( version = = null | | version . isempty ( ) ) { <nl> - / / choose a random version <nl> - <nl> - file [ ] subdirs = new file ( path ) . listfiles ( new filefilter ( ) { <nl> - @ override <nl> - public boolean accept ( file file ) { <nl> - return file . getname ( ) . startswith ( " elasticsearch - " ) & & file . isdirectory ( ) ; <nl> - } <nl> - } ) ; <nl> - if ( subdirs = = null | | subdirs . length = = num ) { <nl> - throw new illegalargumentexception ( " backwards dir " + path + " must be a directory , and contain elasticsearch releases " ) ; <nl> - } <nl> - dir = subdirs [ randomint ( subdirs . length - num ) ] ; <nl> - version = dir . getname ( ) . substring ( " elasticsearch - " . length ( ) ) ; <nl> - } else { <nl> - dir = new file ( path , " elasticsearch - " + version ) ; <nl> - if ( ! dir . exists ( ) ) { <nl> - throw new illegalargumentexception ( " backwards tests location is missing : " + dir . getabsolutepath ( ) ) ; <nl> - } <nl> - if ( ! dir . isdirectory ( ) ) { <nl> - throw new illegalargumentexception ( " backwards tests location is not a directory : " + dir . getabsolutepath ( ) ) ; <nl> - } <nl> - } <nl> - <nl> - version v = version . fromstring ( version ) ; <nl> - if ( v = = null ) { <nl> - throw new illegalargumentexception ( " backcompat elasticsearch version could not be parsed : " + version ) ; <nl> - } <nl> - if ( v . major ! = version . current . major ) { <nl> - throw new illegalargumentexception ( " backcompat elasticsearch version must be same major version as current . " + <nl> - " backcompat : " + version + " , current : " + version . current . tostring ( ) ) ; <nl> + file file = new file ( path , " elasticsearch - " + version ) ; <nl> + if ( ! file . exists ( ) ) { <nl> + throw new illegalargumentexception ( " backwards tests location is missing : " + file . getabsolutepath ( ) ) ; <nl> + } <nl> + if ( ! file . isdirectory ( ) ) { <nl> + throw new illegalargumentexception ( " backwards tests location is not a directory : " + file . getabsolutepath ( ) ) ; <nl> } <nl> - return dir ; <nl> + return file ; <nl> } <nl>  <nl> public compositetestcluster backwardscluster ( ) {
public class transportdeletelicenseaction extends transportmasternodeoperationac <nl>  <nl> @ override <nl> protected void masteroperation ( final deletelicenserequest request , clusterstate state , final actionlistener < deletelicenseresponse > listener ) throws elasticsearchexception { <nl> - metadata metadata = state . metadata ( ) ; <nl> - licensesmetadata licenses = metadata . custom ( licensesmetadata . type ) ; <nl> - / / listener . onresponse ( new deletelicenseresponse ( licenses ) ) ; <nl> - <nl> - <nl> licensesservice . unregisteredlicenses ( " delete_licenses [ ] " , request , new actionlistener < clusterstateupdateresponse > ( ) { <nl> @ override <nl> public void onresponse ( clusterstateupdateresponse clusterstateupdateresponse ) {
import java . util . arrays ; <nl> public class sslconfig { <nl>  <nl> private static final eslogger logger = loggers . getlogger ( sslconfig . class ) ; <nl> - <nl> - static final string [ ] default_ciphers = new string [ ] { " tls_rsa_with_aes_128_cbc_sha256 " , " tls_rsa_with_aes_128_cbc_sha " } ; <nl> + static final string [ ] default_ciphers = new string [ ] { " tls_rsa_with_aes_128_cbc_sha256 " , " tls_rsa_with_aes_128_cbc_sha " , " tls_dhe_rsa_with_aes_128_cbc_sha " , " tls_ecdhe_rsa_with_aes_128_cbc_sha " } ; <nl> private final boolean clientauth ; <nl>  <nl> private sslcontext sslcontext ;
public final class elasticsearchthreadfilter implements threadfilter { <nl> | | threadname . contains ( " keep - alive - timer " ) ) { <nl> return true ; <nl> } <nl> - return nodeprefix . matcher ( t . getname ( ) ) . find ( ) | | true ; <nl> + return nodeprefix . matcher ( t . getname ( ) ) . find ( ) ; <nl> } <nl> } <nl> \ no newline at end of file
public class alertscheduler extends abstractlifecyclecomponent { <nl> } <nl> searchresponse sr = srb . execute ( ) . get ( ) ; <nl> logger . warn ( " got search response hits : [ { } ] " , sr . gethits ( ) . gettotalhits ( ) ) ; <nl> - alertresult result = new alertresult ( ) ; <nl> - <nl> - result . istriggered = triggermanager . istriggered ( alertname , sr ) ; <nl> - result . searchresponse = sr ; <nl> - result . trigger = alert . trigger ( ) ; <nl> - result . query = builder ; <nl> - result . indices = indices ; <nl> + alertresult result = new alertresult ( alertname , sr , alert . trigger ( ) , triggermanager . istriggered ( alertname , sr ) , builder , indices ) ; <nl>  <nl> if ( result . istriggered ) { <nl> logger . warn ( " we have triggered " ) ;
public class attachmentmapper extends abstractfieldmapper < object > { <nl> } else if ( token = = xcontentparser . token . value_string ) { <nl> if ( " _content " . equals ( currentfieldname ) ) { <nl> content = parser . binaryvalue ( ) ; <nl> - } else if ( " content " . equals ( currentfieldname ) ) { <nl> - <nl> - logger . warn ( " ` content ` has been deprecated by _content . please update your code . will be removed in a future version . " ) ; <nl> - content = parser . binaryvalue ( ) ; <nl> } else if ( " _content_type " . equals ( currentfieldname ) ) { <nl> contenttype = parser . text ( ) ; <nl> } else if ( " _name " . equals ( currentfieldname ) ) { <nl> mmm a / src / test / java / org / elasticsearch / index / mapper / xcontent / multifieldattachmentmappertests . java <nl> ppp b / src / test / java / org / elasticsearch / index / mapper / xcontent / multifieldattachmentmappertests . java <nl>
<nl>  <nl> < properties > <nl> < lucene . version > 4 . 9 . 0 < / lucene . version > <nl> - < elasticsearch . version > 1 . 2 . 1 < / elasticsearch . version > <nl> - < ! - - <nl> - < elasticsearch . version > 1 . 3 . 0 - snapshot < / elasticsearch . version > <nl> + < elasticsearch . version > 1 . 4 . 0 - snapshot < / elasticsearch . version > <nl> < tests . jvms > auto < / tests . jvms > <nl> < tests . shuffle > true < / tests . shuffle > <nl> < tests . output > onerror < / tests . output >
public class mocktransportservice extends transportservice { <nl> * / <nl> private static class lookuptesttransport extends delegatetransport { <nl>  <nl> - final concurrentmap < discoverynode , transport > transports = concurrentcollections . newconcurrentmap ( ) ; <nl> + final concurrentmap < transportaddress , transport > transports = concurrentcollections . newconcurrentmap ( ) ; <nl>  <nl> lookuptesttransport ( transport transport ) { <nl> super ( transport ) ; <nl> } <nl>  <nl> private transport gettransport ( discoverynode node ) { <nl> - transport transport = transports . get ( node ) ; <nl> + transport transport = transports . get ( node . getaddress ( ) ) ; <nl> if ( transport ! = null ) { <nl> return transport ; <nl> } <nl> - <nl> return this . transport ; <nl> }
public class attachmentmapper implements mapper { <nl> contenttype = parser . text ( ) ; <nl> } else if ( " _name " . equals ( currentfieldname ) ) { <nl> name = parser . text ( ) ; <nl> - } else if ( " language " . equals ( currentfieldname ) ) { <nl> - <nl> - language = parser . text ( ) ; <nl> - logger . debug ( " ` language ` is now deprecated . use ` _language ` . see https : / / github . com / elasticsearch / elasticsearch - mapper - attachments / issues / 68 " ) ; <nl> } else if ( " _language " . equals ( currentfieldname ) ) { <nl> language = parser . text ( ) ; <nl> }
public class multimatchquerytests extends elasticsearchintegrationtest { <nl> } <nl>  <nl> @ test <nl> - public void testsinglefield ( ) { <nl> + public void testsinglefield ( ) throws nosuchfieldexception , illegalaccessexception { <nl> searchresponse searchresponse = client ( ) . preparesearch ( " test " ) <nl> . setquery ( randomizetype ( multimatchquery ( " 15 " , " skill " ) ) ) . get ( ) ; <nl> assertnofailures ( searchresponse ) ; <nl> assertfirsthit ( searchresponse , hasid ( " theone " ) ) ; <nl> - <nl> + string [ ] fields = { " full_name " , " first_name " , " last_name " , " last_name_phrase " , " first_name_phrase " , " category_phrase " , " category " } ; <nl> + <nl> + string [ ] query = { " marvel " , " hero " , " captain " , " america " , " 15 " , " 17 " , " 1 " , " 5 " , " ultimate " , " man " , <nl> + " marvel " , " wolferine " , " ninja " } ; <nl> + <nl> + / / check if it ' s equivalent to a match query . <nl> + int numiters = scaledrandomintbetween ( 10 , num ) ; <nl> + for ( int i = num ; i < numiters ; i + + ) { <nl> + string field = randompicks . randomfrom ( getrandom ( ) , fields ) ; <nl> + int numterms = randomintbetween ( 1 , query . length ) ; <nl> + stringbuilder builder = new stringbuilder ( ) ; <nl> + for ( int j = num ; j < numterms ; j + + ) { <nl> + builder . append ( randompicks . randomfrom ( getrandom ( ) , query ) ) . append ( " " ) ; <nl> + } <nl> + multimatchquerybuilder multimatchquerybuilder = randomizetype ( multimatchquery ( builder . tostring ( ) , field ) ) ; <nl> + searchresponse multimatchresp = client ( ) . preparesearch ( " test " ) <nl> + . setquery ( multimatchquerybuilder ) . get ( ) ; <nl> + matchquerybuilder matchquerybuilder = querybuilders . matchquery ( field , builder . tostring ( ) ) ; <nl> + if ( gettype ( multimatchquerybuilder ) ! = null ) { <nl> + matchquerybuilder . type ( matchquerybuilder . type . valueof ( gettype ( multimatchquerybuilder ) . matchquerytype ( ) . tostring ( ) ) ) ; <nl> + } <nl> + searchresponse matchresp = client ( ) . preparesearch ( " test " ) <nl> + . setquery ( matchquerybuilder ) . get ( ) ; <nl> + assertthat ( " field : " + field + " query : " + builder . tostring ( ) , multimatchresp . gethits ( ) . gettotalhits ( ) , equalto ( matchresp . gethits ( ) . gettotalhits ( ) ) ) ; <nl> + searchhits hits = multimatchresp . gethits ( ) ; <nl> + for ( int j = num ; j < hits . hits ( ) . length ; j + + ) { <nl> + assertthat ( hits . gethits ( ) [ j ] . score ( ) , equalto ( matchresp . gethits ( ) . gethits ( ) [ j ] . score ( ) ) ) ; <nl> + assertthat ( hits . gethits ( ) [ j ] . getid ( ) , equalto ( matchresp . gethits ( ) . gethits ( ) [ j ] . getid ( ) ) ) ; <nl> + } <nl> + } <nl> + <nl> } <nl>  <nl> @ test <nl>
public abstract class aggregator implements releasable , readercontextaware { <nl> assert factories ! = null : " sub - factories provided to bucketaggregator must not be null , use aggragatorfactories . empty instead " ; <nl> this . factories = factories ; <nl> this . subaggregators = factories . createsubaggregators ( this , estimatedbucketscount ) ; <nl> - <nl> - / / phase instead of dfs like it is done today <nl> - context . searchcontext ( ) . addreleasable ( this , lifetime . context ) ; <nl> + context . searchcontext ( ) . addreleasable ( this , lifetime . phase ) ; <nl> } <nl>  <nl> / * * <nl> mmm a / src / main / java / org / elasticsearch / search / query / queryphase . java <nl> ppp b / src / main / java / org / elasticsearch / search / query / queryphase . java <nl>
public class concurrentmergeschedulerprovider extends mergeschedulerprovider { <nl> public concurrentmergeschedulerprovider ( shardid shardid , @ indexsettings settings indexsettings , threadpool threadpool ) { <nl> super ( shardid , indexsettings , threadpool ) ; <nl>  <nl> - <nl> - this . maxthreadcount = componentsettings . getasint ( " max_thread_count " , math . max ( 1 , math . min ( 3 , runtime . getruntime ( ) . availableprocessors ( ) / num ) ) ) ; <nl> - this . maxmergecount = componentsettings . getasint ( " max_merge_count " , maxthreadcount + num ) ; <nl> + this . maxthreadcount = componentsettings . getasint ( " max_thread_count " , concurrentmergescheduler . default_max_thread_count ) ; <nl> + this . maxmergecount = componentsettings . getasint ( " max_merge_count " , concurrentmergescheduler . default_max_merge_count ) ; <nl> logger . debug ( " using [ concurrent ] merge scheduler with max_thread_count [ { } ] " , maxthreadcount ) ; <nl> }
public class restspec { <nl> } <nl>  <nl> void addapi ( restapi restapi ) { <nl> - if ( " get " . equals ( restapi . getname ( ) ) ) { <nl> - <nl> - / / as get_source is already a separate api <nl> - list < string > paths = lists . newarraylist ( ) ; <nl> - for ( string path : restapi . getpaths ( ) ) { <nl> - if ( ! path . endswith ( " / _source " ) ) { <nl> - paths . add ( path ) ; <nl> - } <nl> - } <nl> - restapimap . put ( restapi . getname ( ) , new restapi ( restapi , paths ) ) ; <nl> - } else { <nl> - restapimap . put ( restapi . getname ( ) , restapi ) ; <nl> - } <nl> + restapimap . put ( restapi . getname ( ) , restapi ) ; <nl> } <nl>  <nl> public restapi getapi ( string api ) {
public class geoshapeintegrationtests extends elasticsearchintegrationtest { <nl> assertthat ( searchresponse . gethits ( ) . getat ( 0 ) . id ( ) , equalto ( " blakely " ) ) ; <nl> } <nl>  <nl> - <nl> @ test <nl> - @ awaitsfix ( bugurl = " this test causes hangs , blocking on the action get when fetching the shape for some reason " ) <nl> public void testindexedshapereference ( ) throws exception { <nl> string mapping = xcontentfactory . jsonbuilder ( ) . startobject ( ) . startobject ( " type1 " ) <nl> . startobject ( " properties " ) . startobject ( " location " )
public class localgatewaymetastate extends abstractcomponent implements clusters <nl> continue ; <nl> } <nl> if ( ! newmetadata . hasindex ( current . index ( ) ) ) { <nl> - <nl> logger . debug ( " [ { } ] deleting <nl> if ( nodeenv . hasnodefile ( ) ) { <nl> filesystemutils . deleterecursively ( nodeenv . indexlocations ( new index ( current . index ( ) ) ) ) ; <nl> mmm a / src / main / java / org / elasticsearch / gateway / none / nonegateway . java <nl> ppp b / src / main / java / org / elasticsearch / gateway / none / nonegateway . java <nl>
public class nonegateway extends abstractlifecyclecomponent < gateway > implements <nl> / / only delete indices when we already received a state ( currentmetadata ! = null ) <nl> for ( indexmetadata current : currentmetadata ) { <nl> if ( ! newmetadata . hasindex ( current . index ( ) ) ) { <nl> - <nl> logger . debug ( " [ { } ] deleting <nl> if ( nodeenv . hasnodefile ( ) ) { <nl> filesystemutils . deleterecursively ( nodeenv . indexlocations ( new index ( current . index ( ) ) ) ) ;
public class internalindicesservice extends abstractlifecyclecomponent < indicesse <nl>  <nl> for ( indexservice indexservice : indices . values ( ) ) { <nl> for ( indexshard indexshard : indexservice ) { <nl> - commonstats indexstas = new commonstats ( indexshard , flags ) ; <nl> - stats . add ( indexstas ) ; <nl> - } <nl> - } <nl> - return new nodeindicesstats ( stats ) ; <nl> - } <nl> - <nl> - <nl> - public shardstats [ ] shardstats ( commonstatsflags flags ) { <nl> - <nl> - list < shardstats > shardstats = lists . newarraylist ( ) ; <nl> - for ( string <nl> - indexservice indexservice = indexservice ( index ) ; <nl> - if ( indexservice = = null ) { <nl> - continue ; / / something changed , move along <nl> - } <nl> - for ( int shardid : indexservice . shardids ( ) ) { <nl> - indexshard indexshard = indexservice . shard ( shardid ) ; <nl> - if ( indexshard = = null ) { <nl> - continue ; <nl> + try { <nl> + stats . add ( new commonstats ( indexshard , flags ) ) ; <nl> + } catch ( illegalindexshardstateexception e ) { <nl> + / / we can safely ignore illegal state on ones that are closing for example <nl> } <nl> - shardstats . add ( new shardstats ( indexshard , flags ) ) ; <nl> } <nl> } <nl> - return shardstats . toarray ( new shardstats [ shardstats . size ( ) ] ) ; <nl> + return new nodeindicesstats ( stats ) ; <nl> } <nl>  <nl> / * *
public class searchscantests extends abstractsharedclustertest { <nl>  <nl> @ test <nl> @ slow <nl> - <nl> public void testnarrowingquery ( ) throws exception { <nl> - try { <nl> - client ( ) . admin ( ) . indices ( ) . preparedelete ( " test " ) . execute ( ) . actionget ( ) ; <nl> - } catch ( exception e ) { <nl> - / / ignore <nl> - } <nl> - client ( ) . admin ( ) . indices ( ) . preparecreate ( " test " ) . setsettings ( immutablesettings . settingsbuilder ( ) . put ( " index . number_of_shards " , num ) ) . execute ( ) . actionget ( ) ; <nl> + client ( ) . admin ( ) . indices ( ) . preparecreate ( " test " ) . setsettings ( immutablesettings . settingsbuilder ( ) . put ( " index . number_of_shards " , between ( 1 , 5 ) ) ) . execute ( ) . actionget ( ) ; <nl> client ( ) . admin ( ) . cluster ( ) . preparehealth ( ) . setwaitforevents ( priority . languid ) . setwaitforgreenstatus ( ) . execute ( ) . actionget ( ) ; <nl>  <nl> - <nl> set < string > ids = sets . newhashset ( ) ; <nl> set < string > expectedids = sets . newhashset ( ) ; <nl> - <nl> - for ( int i = num ; i < num ; i + + ) { <nl> + indexrequestbuilder [ ] builders = new indexrequestbuilder [ atleast ( 50 ) ] ; <nl> + for ( int i = num ; i < builders . length / 2 ; i + + ) { <nl> expectedids . add ( integer . tostring ( i ) ) ; <nl> - client ( ) . prepareindex ( " test " , " tweet " , integer . tostring ( i ) ) . setsource ( <nl> - jsonbuilder ( ) . startobject ( ) . field ( " user " , " kimchy1 " ) . field ( " postdate " , system . currenttimemillis ( ) ) . field ( " message " , " test " ) . endobject ( ) ) . execute ( ) . actionget ( ) ; <nl> - / / make some segments <nl> - if ( i % num = = num ) { <nl> - client ( ) . admin ( ) . indices ( ) . prepareflush ( ) . execute ( ) . actionget ( ) ; <nl> - } <nl> + builders [ i ] = client ( ) . prepareindex ( " test " , " tweet " , integer . tostring ( i ) ) . setsource ( <nl> + jsonbuilder ( ) . startobject ( ) . field ( " user " , " kimchy1 " ) . field ( " postdate " , system . currenttimemillis ( ) ) . field ( " message " , " test " ) . endobject ( ) ) ; <nl> } <nl>  <nl> - for ( int i = num ; i < num ; i + + ) { <nl> - client ( ) . prepareindex ( " test " , " tweet " , integer . tostring ( i ) ) . setsource ( <nl> - jsonbuilder ( ) . startobject ( ) . field ( " user " , " kimchy2 " ) . field ( " postdate " , system . currenttimemillis ( ) ) . field ( " message " , " test " ) . endobject ( ) ) . execute ( ) . actionget ( ) ; <nl> - / / make some segments <nl> - if ( i % num = = num ) { <nl> - client ( ) . admin ( ) . indices ( ) . prepareflush ( ) . execute ( ) . actionget ( ) ; <nl> - } <nl> + for ( int i = builders . length / 2 ; i < builders . length ; i + + ) { <nl> + builders [ i ] = client ( ) . prepareindex ( " test " , " tweet " , integer . tostring ( i ) ) . setsource ( <nl> + jsonbuilder ( ) . startobject ( ) . field ( " user " , " kimchy2 " ) . field ( " postdate " , system . currenttimemillis ( ) ) . field ( " message " , " test " ) . endobject ( ) ) ; <nl> } <nl> - <nl> - client ( ) . admin ( ) . indices ( ) . preparerefresh ( ) . execute ( ) . actionget ( ) ; <nl> + indexrandom ( true , builders ) ; <nl>  <nl> searchresponse searchresponse = client ( ) . preparesearch ( ) <nl> . setsearchtype ( searchtype . scan ) <nl>
public class updatemappingtests extends abstractsharedclustertest { <nl> @ test <nl> public void updatedefaultmappingsettings ( ) throws exception { <nl>  <nl> - <nl> - createindex ( " test " ) ; <nl> - <nl> - logger . info ( " creating _default_ mappings " ) ; <nl> - putmappingresponse putresponse = client ( ) . admin ( ) . indices ( ) . prepareputmapping ( " test " ) . settype ( mapperservice . default_mapping ) . setsource ( <nl> + logger . info ( " creating <nl> + client ( ) . admin ( ) . indices ( ) . preparecreate ( " test " ) . addmapping ( mapperservice . default_mapping , <nl> jsonxcontent . contentbuilder ( ) . startobject ( ) . startobject ( mapperservice . default_mapping ) <nl> . field ( " date_detection " , false ) <nl> . endobject ( ) . endobject ( ) <nl> ) . get ( ) ; <nl>  <nl> - assertthat ( putresponse . isacknowledged ( ) , equalto ( true ) ) ; <nl> - logger . info ( " done : creating _default_ mappings " ) ; <nl> - <nl> getmappingsresponse getresponse = client ( ) . admin ( ) . indices ( ) . preparegetmappings ( " test " ) . addtypes ( mapperservice . default_mapping ) . get ( ) ; <nl> map < string , object > defaultmapping = getresponse . getmappings ( ) . get ( " test " ) . get ( mapperservice . default_mapping ) . sourceasmap ( ) ; <nl> assertthat ( defaultmapping , haskey ( " date_detection " ) ) ; <nl>
public class namedanalyzer extends customanalyzerwrapper { <nl> public namedanalyzer ( string name , analyzerscope scope , analyzer analyzer , int positionoffsetgap ) { <nl> / / our named analyzer always wrap a non per field analyzer , so no need to have per field analyzer <nl> super ( new globalreusestrategy ( ) ) ; <nl> - <nl> - assert ! ( analyzer instanceof analyzerwrapper ) ; / / this is the only one in lucene currently that uses perfieldstrategy , make sure we don ' t wrap it <nl> this . name = name ; <nl> this . scope = scope ; <nl> this . analyzer = analyzer ;
public class simplenestedtests extends abstractsharedclustertest { <nl> assertthat ( termsstatsfacet . getentries ( ) . get ( 0 ) . getcount ( ) , equalto ( 3l ) ) ; <nl> assertthat ( termsstatsfacet . getentries ( ) . get ( 0 ) . gettotal ( ) , equalto ( 8d ) ) ; <nl>  <nl> - <nl> - refresh ( ) ; <nl> - <nl> / / test scope ones ( post based ) <nl> searchresponse = client ( ) . preparesearch ( " test " ) <nl> . setquery (
module elasticsearch <nl> < % = ' ' * @ namespace_depth % > # normalize ruby num . 8 and ruby num . 9 hash # select behaviour <nl> < % = ' ' * @ namespace_depth % > params = hash [ params ] unless params . is_a ? ( hash ) <nl> < % - end - % > <nl> - < % = ' ' * @ namespace_depth % > body = < % = @ spec [ ' body ' ] . nil ? ? ' nil ' : ' " <nl> + < % = ' ' * @ namespace_depth % > body = < % = @ spec [ ' body ' ] . nil ? ? ' nil ' : ' arguments [ : body ] ' % > <nl> < % # perform request % > <nl> < % = ' ' * @ namespace_depth % > perform_request ( method , path , params , body ) . body <nl> < % = ' ' * @ namespace_depth % > end
<nl> } , <nl> " filter_metadata " : { <nl> " type " : " boolean " , <nl> - " description " : " <nl> + " description " : " don ' t return cluster state metadata ( default : false ) " <nl> } <nl> } <nl> } ,
<nl> " description " : " the interval for the second sampling of threads " <nl> } , <nl> " snapshots " : { <nl> - " type " : " string " , <nl> - " description " : " <nl> + " type " : " number " , <nl> + " description " : " number of samples of thread stacktrace ( default : num ) " <nl> } , <nl> " threads " : { <nl> " type " : " number " ,
<nl> " type " : " number " , <nl> " description " : " include only documents with a specific ` _score ` value in the result " <nl> } , <nl> - " operation_threading " : { <nl> - " description " : " <nl> - } , <nl> " preference " : { <nl> " type " : " string " , <nl> " description " : " specify the shards the operation should be performed on ( default : random shard ) " <nl> mmm a / rest - api - spec / api / search . json <nl> ppp b / rest - api - spec / api / search . json <nl>
<nl> " type " : " boolean " , <nl> " description " : " specify whether query terms should be lowercased " <nl> } , <nl> - " operation_threading " : { <nl> - " description " : " <nl> - } , <nl> " preference " : { <nl> " type " : " string " , <nl> " description " : " specify the shards the operation should be performed on ( default : random shard ) " <nl> mmm a / rest - api - spec / api / suggest . json <nl> ppp b / rest - api - spec / api / suggest . json <nl>
<nl> " default " : " none " , <nl> " description " : " when performed on multiple indices , allows to ignore ` missing ` ones " <nl> } , <nl> - " operation_threading " : { <nl> - " description " : " <nl> - } , <nl> " preference " : { <nl> " type " : " string " , <nl> " description " : " specify the shards the operation should be performed on ( default : random shard ) "
<nl> } , <nl> " recycler " : { <nl> " type " : " boolean " , <nl> - " description " : " <nl> + " description " : " clear the recycler cache " <nl> } <nl> } <nl> } ,
public class simpleidcache extends abstractindexcomponent implements idcache , se <nl> if ( terms ! = null ) { <nl> termsenum termsenum = terms . iterator ( null ) ; <nl> docsenum docsenum = null ; <nl> - for ( bytesref term = termsenum . next ( ) ; term ! = null ; term = termsenum . next ( ) ) { <nl> + uid : for ( bytesref term = termsenum . next ( ) ; term ! = null ; term = termsenum . next ( ) ) { <nl> hashedbytesarray [ ] typeandid = uid . splituidintotypeandid ( term ) ; <nl> - <nl> if ( ! parenttypes . contains ( typeandid [ 0 ] ) ) { <nl> - continue ; <nl> + do { <nl> + hashedbytesarray nextparent = parenttypes . ceiling ( typeandid [ 0 ] ) ; <nl> + if ( nextparent = = null ) { <nl> + break uid ; <nl> + } <nl> + <nl> + termsenum . seekstatus status = termsenum . seekceil ( nextparent . tobytesref ( ) , false ) ; <nl> + if ( status = = termsenum . seekstatus . end ) { <nl> + break uid ; <nl> + } else if ( status = = termsenum . seekstatus . not_found ) { <nl> + term = termsenum . term ( ) ; <nl> + typeandid = uid . splituidintotypeandid ( term ) ; <nl> + } else if ( status = = termsenum . seekstatus . found ) { <nl> + assert false : " seek status should never be found , because we seek only the type part " ; <nl> + term = termsenum . term ( ) ; <nl> + typeandid = uid . splituidintotypeandid ( term ) ; <nl> + } <nl> + } while ( ! parenttypes . contains ( typeandid [ 0 ] ) ) ; <nl> } <nl>  <nl> string type = typeandid [ 0 ] . toutf8 ( ) ;
public class simpleindexqueryparsertests { <nl> xfilteredquery filteredquery = ( xfilteredquery ) parsedquery ; <nl> xbooleanfilter booleanfilter = ( xbooleanfilter ) filteredquery . getfilter ( ) ; <nl>  <nl> - <nl> + iterator < filterclause > iterator = booleanfilter . iterator ( ) ; <nl> + assertthat ( iterator . hasnext ( ) , equalto ( true ) ) ; <nl> + filterclause clause = iterator . next ( ) ; <nl> + assertthat ( clause . getoccur ( ) , equalto ( booleanclause . occur . must ) ) ; <nl> + assertthat ( ( ( termfilter ) clause . getfilter ( ) ) . getterm ( ) , equalto ( new term ( " name . first " , " shay1 " ) ) ) ; <nl> + <nl> + assertthat ( iterator . hasnext ( ) , equalto ( true ) ) ; <nl> + clause = iterator . next ( ) ; <nl> + assertthat ( clause . getoccur ( ) , equalto ( booleanclause . occur . must ) ) ; <nl> + assertthat ( ( ( termfilter ) clause . getfilter ( ) ) . getterm ( ) , equalto ( new term ( " name . first " , " shay4 " ) ) ) ; <nl> + <nl> + assertthat ( iterator . hasnext ( ) , equalto ( true ) ) ; <nl> + clause = iterator . next ( ) ; <nl> + assertthat ( clause . getoccur ( ) , equalto ( booleanclause . occur . must_not ) ) ; <nl> + assertthat ( ( ( termfilter ) clause . getfilter ( ) ) . getterm ( ) , equalto ( new term ( " name . first " , " shay2 " ) ) ) ; <nl> + <nl> + assertthat ( iterator . hasnext ( ) , equalto ( true ) ) ; <nl> + clause = iterator . next ( ) ; <nl> + assertthat ( clause . getoccur ( ) , equalto ( booleanclause . occur . should ) ) ; <nl> + assertthat ( ( ( termfilter ) clause . getfilter ( ) ) . getterm ( ) , equalto ( new term ( " name . first " , " shay3 " ) ) ) ; <nl> + <nl> + assertthat ( iterator . hasnext ( ) , equalto ( false ) ) ; <nl> } <nl>  <nl> @ test
public class robinengine extends abstractindexshardcomponent implements engine { <nl> if ( ! codecname . equals ( robinengine . this . codecname ) ) { <nl> logger . info ( " updating index . codec from [ { } ] to [ { } ] " , robinengine . this . codecname , codecname ) ; <nl> robinengine . this . codecname = codecname ; <nl> - <nl> requiresflushing = true ; <nl> } <nl> } finally {
public class scriptservice extends abstractcomponent { <nl>  <nl> private final concurrentmap < string , compiledscript > staticcache = concurrentcollections . newconcurrentmap ( ) ; <nl>  <nl> - <nl> - private final cache < cachekey , compiledscript > cache = cachebuilder . newbuilder ( ) . build ( ) ; <nl> + private final cache < cachekey , compiledscript > cache ; <nl>  <nl> private final boolean disabledynamic ; <nl>  <nl>
public class filteredqueryparser implements queryparser { <nl> return q ; <nl> } <nl>  <nl> - <nl> - <nl> - xfilteredquery filteredquery = new xfilteredquery ( query , filter ) ; <nl> + xfilteredquery filteredquery = new xfilteredquery ( query , filter , filterstrategy ) ; <nl> filteredquery . setboost ( boost ) ; <nl> return filteredquery ; <nl> }
import org . apache . lucene . search . constantscorequery ; <nl> import org . apache . lucene . search . filter ; <nl>  <nl> / * * <nl> - * <nl> + * we still need sometimes to exclude deletes , because we don ' t remove them always with acceptdocs on filters <nl> * / <nl> - / / lucene monitor : against constantscorequery , basically added logic in the doc iterator to take deletions into account <nl> - / / so it can basically be cached safely even with a reader that changes deletions but remain with teh same cache key <nl> - / / see more : https : / / issues . apache . org / jira / browse / lucene - 2468 <nl> - <nl> - / / lucene num upgrade : we probably don ' t need this anymore , because of acceptdocs <nl> public class deletionawareconstantscorequery extends constantscorequery { <nl>  <nl> private final filter actualfilter ; <nl> mmm a / src / main / java / org / elasticsearch / common / lucene / search / notdeletedfilter . java <nl> ppp b / src / main / java / org / elasticsearch / common / lucene / search / notdeletedfilter . java <nl>
public class transportupdateaction extends transportinstancesingleoperationactio <nl> public void onresponse ( indexresponse response ) { <nl> updateresponse update = new updateresponse ( response . index ( ) , response . type ( ) , response . id ( ) , response . version ( ) ) ; <nl> update . matches ( response . matches ( ) ) ; <nl> - <nl> - update . getresult ( null ) ; <nl> + if ( request . fields ( ) ! = null & & request . fields ( ) . length > num ) { <nl> + tuple < xcontenttype , map < string , object > > sourceandcontent = xcontenthelper . converttomap ( updatesourcebytes , true ) ; <nl> + update . getresult ( extractgetresult ( request , response . version ( ) , sourceandcontent . v2 ( ) , sourceandcontent . v1 ( ) , updatesourcebytes ) ) ; <nl> + } else { <nl> + update . getresult ( null ) ; <nl> + } <nl> listener . onresponse ( update ) ; <nl> } <nl>  <nl> mmm a / src / test / java / org / elasticsearch / test / integration / update / updatetests . java <nl> ppp b / src / test / java / org / elasticsearch / test / integration / update / updatetests . java <nl>
<nl> - / * <nl> - * licensed to elasticsearch and shay banon under one <nl> - * or more contributor license agreements . see the notice file <nl> - * distributed with this work for additional information <nl> - * regarding copyright ownership . elasticsearch licenses this <nl> - * file to you under the apache license , version num . 0 ( the <nl> - * " license " ) ; you may not use this file except in compliance <nl> - * with the license . you may obtain a copy of the license at <nl> - * <nl> - * http : / / www . apache . org / licenses / license - 2 . 0 <nl> - * <nl> - * unless required by applicable law or agreed to in writing , <nl> - * software distributed under the license is distributed on an <nl> - * " as is " basis , without warranties or conditions of any <nl> - * kind , either express or implied . see the license for the <nl> - * specific language governing permissions and limitations <nl> - * under the license . <nl> - * / <nl> - <nl> - package org . elasticsearch . plugin . mapper . attachments . tika ; <nl> - <nl> - import org . apache . tika . tika ; <nl> - import org . apache . tika . exception . tikaexception ; <nl> - import org . apache . tika . metadata . metadata ; <nl> - import org . apache . tika . parser . parsecontext ; <nl> - import org . apache . tika . parser . parser ; <nl> - import org . apache . tika . sax . bodycontenthandler ; <nl> - import org . apache . tika . sax . writeoutcontenthandler ; <nl> - import org . xml . sax . saxexception ; <nl> - <nl> - import java . io . ioexception ; <nl> - import java . io . inputstream ; <nl> - <nl> - <nl> - / * * <nl> - * extends the tika class , so as to provide a way for setting the maximumstringlength on a per parse document basis . <nl> - * / <nl> - <nl> - public class tikaextended extends tika { <nl> - <nl> - public string parsetostring ( inputstream stream , metadata metadata , int maxstringlength ) <nl> - throws ioexception , tikaexception { <nl> - writeoutcontenthandler handler = <nl> - new writeoutcontenthandler ( maxstringlength ) ; <nl> - try { <nl> - parsecontext context = new parsecontext ( ) ; <nl> - context . set ( parser . class , getparser ( ) ) ; <nl> - getparser ( ) . parse ( <nl> - stream , new bodycontenthandler ( handler ) , metadata , context ) ; <nl> - } catch ( saxexception e ) { <nl> - if ( ! handler . iswritelimitreached ( e ) ) { <nl> - / / this should never happen with bodycontenthandler . . . <nl> - throw new tikaexception ( " unexpected sax processing failure " , e ) ; <nl> - } <nl> - } finally { <nl> - stream . close ( ) ; <nl> - } <nl> - return handler . tostring ( ) ; <nl> - } <nl> - } <nl> mmm a / src / main / java / org / elasticsearch / plugin / mapper / attachments / tika / tikainstance . java <nl> ppp b / src / main / java / org / elasticsearch / plugin / mapper / attachments / tika / tikainstance . java <nl>
public enum geodistance { <nl> factor ( ) { <nl> @ override <nl> public double calculate ( double sourcelatitude , double sourcelongitude , double targetlatitude , double targetlongitude , distanceunit unit ) { <nl> - <nl> double longitudedifference = targetlongitude - sourcelongitude ; <nl> double a = math . toradians ( 90d - sourcelatitude ) ; <nl> double c = math . toradians ( 90d - targetlatitude ) ; <nl>
public enum geodistance { <nl> arc ( ) { <nl> @ override <nl> public double calculate ( double sourcelatitude , double sourcelongitude , double targetlatitude , double targetlongitude , distanceunit unit ) { <nl> - <nl> double longitudedifference = targetlongitude - sourcelongitude ; <nl> double a = math . toradians ( 90d - sourcelatitude ) ; <nl> double c = math . toradians ( 90d - targetlatitude ) ; <nl>
public enum geodistance { <nl>  <nl> @ override <nl> public double calculate ( double targetlatitude , double targetlongitude ) { <nl> - <nl> double longitudedifference = targetlongitude - sourcelongitude ; <nl> double c = math . toradians ( 90d - targetlatitude ) ; <nl> return ( cosa * math . cos ( c ) ) + ( sina * math . sin ( c ) * math . cos ( math . toradians ( longitudedifference ) ) ) ; <nl>
public enum geodistance { <nl>  <nl> @ override <nl> public double calculate ( double targetlatitude , double targetlongitude ) { <nl> - <nl> double longitudedifference = targetlongitude - sourcelongitude ; <nl> double c = math . toradians ( 90d - targetlatitude ) ; <nl> double factor = ( cosa * math . cos ( c ) ) + ( sina * math . sin ( c ) * math . cos ( math . toradians ( longitudedifference ) ) ) ;
public class getresult implements streamable , iterable < getfield > , toxcontent { <nl> public bytesholder sourceref ( ) { <nl> if ( lzf . iscompressed ( source . bytes ( ) , source . offset ( ) , source . length ( ) ) ) { <nl> try { <nl> - <nl> - this . source = new bytesholder ( lzfdecoder . decode ( source . copybytes ( ) ) ) ; <nl> + this . source = new bytesholder ( lzfdecoder . decode ( source . bytes ( ) , source . offset ( ) , source . length ( ) ) ) ; <nl> } catch ( ioexception e ) { <nl> throw new elasticsearchparseexception ( " failed to decompress source " , e ) ; <nl> } <nl>
public class couchdbriver extends abstractrivercomponent implements river { <nl> } <nl>  <nl> / / remove _attachement from doc if needed <nl> - <nl> if ( couchignoreattachements ) { <nl> if ( doc . containskey ( " _attachments " ) ) { <nl> map < string , object > _attachments = ( map < string , object > ) doc <nl>
public class couchdbriver extends abstractrivercomponent implements river { <nl> file = file + couchfilterparamsurl ; <nl> } <nl> } <nl> - <nl>  <nl> if ( lastseq ! = null ) { <nl> file = file + " & since = " + lastseq ;
public class localgatewaynodeallocation extends nodeallocation { <nl> routingnodes routingnodes = allocation . routingnodes ( ) ; <nl>  <nl> for ( indexroutingtable indexroutingtable : routingnodes . routingtable ( ) ) { <nl> - <nl> - / / manage to find a place to allocate them . . . <nl> + / / only do the allocation if there is a local " index not recovered " block <nl> + if ( ! routingnodes . blocks ( ) . hasindexblock ( indexroutingtable . index ( ) , localgateway . index_not_recovered_block ) ) { <nl> + continue ; <nl> + } <nl> + <nl> if ( indexroutingtable . allprimaryshardsunassigned ( ) ) { <nl> / / all primary are unassigned for the index , see if we can allocate it on existing nodes , if not , don ' t assign <nl> set < string > nodesids = sets . newhashset ( ) ; <nl>
public class restxcontentbuilder { <nl> if ( contenttype = = builder . contenttype ( ) ) { <nl> builder . rawfield ( " _source " , silzf ) ; <nl> } else { <nl> - <nl> - xcontentparser parser = xcontentfactory . xcontent ( builder . contenttype ( ) ) . createparser ( silzf ) ; <nl> + xcontentparser parser = xcontentfactory . xcontent ( contenttype ) . createparser ( silzf ) ; <nl> try { <nl> parser . nexttoken ( ) ; <nl> builder . field ( " _source " ) ; <nl>
public class restxcontentbuilder { <nl> } <nl> } <nl> } else { <nl> - if ( xcontentfactory . xcontenttype ( source ) = = builder . contenttype ( ) ) { <nl> + xcontenttype contenttype = xcontentfactory . xcontenttype ( source ) ; <nl> + if ( contenttype = = builder . contenttype ( ) ) { <nl> builder . rawfield ( " _source " , source ) ; <nl> } else { <nl> - <nl> - xcontentparser parser = xcontentfactory . xcontent ( builder . contenttype ( ) ) . createparser ( source ) ; <nl> + xcontentparser parser = xcontentfactory . xcontent ( contenttype ) . createparser ( source ) ; <nl> try { <nl> parser . nexttoken ( ) ; <nl> builder . field ( " _source " ) ;
public class recoverysource extends abstractcomponent { <nl> } <nl>  <nl> private int sendsnapshot ( translog . snapshot snapshot ) throws elasticsearchexception { <nl> - int translogbatchsize = num ; <nl> int counter = num ; <nl> int totaloperations = num ; <nl> list < translog . operation > operations = lists . newarraylist ( ) ; <nl>
public class internalclusterservice extends abstractlifecyclecomponent < clusterse <nl> try { <nl> transportservice . connecttonode ( node ) ; <nl> } catch ( exception e ) { <nl> - <nl> logger . warn ( " failed to connect to node [ " + node + " ] " , e ) ; <nl> } <nl> }
import org . apache . lucene . analysis . tokenattributes . termattribute ; <nl> / * * <nl> * @ author kimchy ( shay . banon ) <nl> * / <nl> - <nl> public class charsequencetermattribute implements charsequence { <nl>  <nl> private final termattribute termatt ; <nl> mmm a / plugins / analysis / icu / src / main / java / org / elasticsearch / index / analysis / icunormalizer2filter . java <nl> ppp b / plugins / analysis / icu / src / main / java / org / elasticsearch / index / analysis / icunormalizer2filter . java <nl>
import java . io . ioexception ; <nl> * @ see com . ibm . icu . text . normalizer2 <nl> * @ see com . ibm . icu . text . filterednormalizer2 <nl> * / <nl> - <nl> public class icunormalizer2filter extends tokenfilter { <nl>  <nl> private final termattribute termatt = addattribute ( termattribute . class ) ;
public class restsearchaction extends baseresthandler { <nl> } <nl> searchsourcebuilder . query ( querybuilder ) ; <nl> } <nl> - <nl> + <nl> + int from = request . paramasint ( " from " , - 1 ) ; <nl> + if ( from ! = - 1 ) { <nl> + searchsourcebuilder . from ( from ) ; <nl> + } <nl> + int size = request . paramasint ( " size " , - 1 ) ; <nl> + if ( size ! = - 1 ) { <nl> + searchsourcebuilder . size ( size ) ; <nl> + } <nl>  <nl>  <nl> searchsourcebuilder . queryparsername ( request . param ( " queryparsername " ) ) ;
public class http1xclientconnection extends http1xconnectionbase < websocketimpl > <nl> } <nl> vertxtracer tracer = context . tracer ( ) ; <nl> if ( tracer ! = null ) { <nl> - list < map . entry < string , string > > tags = new arraylist < > ( ) ; <nl> - tags . add ( new abstractmap . simpleentry < > ( " http . url " , " <nl> - tags . add ( new abstractmap . simpleentry < > ( " http . method " , request . method . name ( ) ) ) ; <nl> biconsumer < string , string > headers = ( key , val ) - > nettyrequest . headers ( ) . add ( key , val ) ; <nl> stream . trace = tracer . sendrequest ( stream . context , spankind . rpc , options . gettracingpolicy ( ) , request , request . method . name ( ) , headers , httputils . client_http_request_tag_extractor ) ; <nl> } <nl> mmm a / src / main / java / io / vertx / core / http / impl / http2serverrequest . java <nl> ppp b / src / main / java / io / vertx / core / http / impl / http2serverrequest . java <nl>
abstract class vertxhttp2stream < c extends http2connectionbase > { <nl> } else { <nl> chunk = buf ; <nl> } <nl> - if ( chunk ! = null ) { <nl> - byteswritten + = chunk . readablebytes ( ) ; <nl> - futurelistener < void > promise = handler = = null ? null : context . promise ( handler ) ; <nl> - conn . handler . writedata ( stream , chunk , end , promise ) ; <nl> - } else { <nl> - <nl> - } <nl> + byteswritten + = chunk . readablebytes ( ) ; <nl> + futurelistener < void > promise = handler = = null ? null : context . promise ( handler ) ; <nl> + conn . handler . writedata ( stream , chunk , end , promise ) ; <nl> } <nl>  <nl> final void writereset ( long code ) {
public class defaultdeliverystrategy implements deliverystrategy { <nl> peeked . complete ( selector ) ; <nl> waiters . remove ( ) ; <nl> if ( waiters . isempty ( ) ) { <nl> - <nl> + removewaiters ( context , address ) ; <nl> return ; <nl> } <nl> } else {
public class keystorehelper { <nl> keystore . setcertificateentry ( " cert - 1 " , cert ) ; <nl> trustmgrmap . put ( alias , keystore ) ; <nl> } <nl> - <nl> - if ( cert instanceof x509certificate ) { <nl> + if ( ks . iskeyentry ( alias ) & & cert instanceof x509certificate ) { <nl> x509certificate x509cert = ( x509certificate ) cert ; <nl> collection < list < ? > > ans = x509cert . getsubjectalternativenames ( ) ; <nl> list < string > domains = new arraylist < > ( ) ;
<nl> - package io . vertx . core . eventbus ; <nl> - <nl> - import io . vertx . core . handler ; <nl> - <nl> - / * * <nl> - * @ author < a href = " http : / / tfox . org " > tim fox < / a > <nl> - * / <nl> - public abstract class filteringinterceptor implements handler < sendcontext > { <nl> - <nl> - private final string startswith ; <nl> - <nl> - public filteringinterceptor ( string startswith ) { <nl> - this . startswith = startswith ; <nl> - } <nl> - <nl> - <nl> - <nl> - @ override <nl> - public void handle ( sendcontext sendcontext ) { <nl> - if ( sendcontext . message ( ) . address ( ) . startswith ( startswith ) ) { <nl> - handlecontext ( sendcontext ) ; <nl> - } else { <nl> - sendcontext . next ( ) ; <nl> - } <nl> - } <nl> - <nl> - protected abstract void handlecontext ( sendcontext sendcontext ) ; <nl> - <nl> - }
public class nettest extends vertxtestbase { <nl> await ( ) ; <nl> } <nl>  <nl> - <nl> - / / but also trustall , which turns off the whole ssl cert checking <nl> + / / this test sets hostnameverification but also trustall , it fails if hostname is <nl> + / / incorrect but does not verify the certificate validity <nl>  <nl> @ test <nl> public void testhostverificationhttpsmatching ( ) {
public class httpclientimpl implements httpclient , metricsprovider { <nl> objects . requirenonnull ( host , " no null host accepted " ) ; <nl> objects . requirenonnull ( relativeuri , " no null relativeuri accepted " ) ; <nl> checkclosed ( ) ; <nl> + string connecthost ; <nl> + int connectport ; <nl> proxyoptions proxyoptions = options . getproxyoptions ( ) ; <nl> - if ( ! options . isssl ( ) & & proxyoptions ! = null & & proxyoptions . gettype ( ) = = proxytype . http ) { <nl> - if ( headers = = null ) { <nl> - headers = multimap . caseinsensitivemultimap ( ) ; <nl> - } <nl> + final boolean useproxy = ! options . isssl ( ) & & proxyoptions ! = null & & proxyoptions . gettype ( ) = = proxytype . http ; <nl> + if ( useproxy ) { <nl> relativeuri = " http : / / " + host + ( port ! = num ? " : " + port : " " ) + relativeuri ; <nl> - host = proxyoptions . gethost ( ) ; <nl> - port = proxyoptions . getport ( ) ; <nl> - log . debug ( " changing request to proxy request " + relativeuri ) ; <nl> - log . debug ( " username " + proxyoptions . getusername ( ) + " password " + proxyoptions . getpassword ( ) ) ; <nl> + connecthost = proxyoptions . gethost ( ) ; <nl> + connectport = proxyoptions . getport ( ) ; <nl> if ( proxyoptions . getusername ( ) ! = null & & proxyoptions . getpassword ( ) ! = null ) { <nl> - log . debug ( " adding authorization header " ) ; <nl> + if ( headers = = null ) { <nl> + headers = multimap . caseinsensitivemultimap ( ) ; <nl> + } <nl> headers . add ( " proxy - authorization " , " basic " + base64 . getencoder ( ) <nl> . encodetostring ( ( proxyoptions . getusername ( ) + " : " + proxyoptions . getpassword ( ) ) . getbytes ( ) ) ) ; <nl> } <nl> - <nl> - headers . add ( " host " , host + ( port ! = num ? " : " + port : " " ) ) ; <nl> + } else { <nl> + connecthost = host ; <nl> + connectport = port ; <nl> + } <nl> + httpclientrequest req = new httpclientrequestimpl ( this , method , connecthost , connectport , options . isssl ( ) , <nl> + relativeuri , vertx ) ; <nl> + if ( useproxy ) { <nl> + req . sethost ( host + ( port ! = num ? " : " + port : " " ) ) ; <nl> } <nl> - httpclientrequest req = new httpclientrequestimpl ( this , method , host , port , options . isssl ( ) , relativeuri , vertx ) ; <nl> if ( headers ! = null ) { <nl> req . headers ( ) . setall ( headers ) ; <nl> } <nl> mmm a / src / test / java / io / vertx / test / core / connecthttpproxy . java <nl> ppp b / src / test / java / io / vertx / test / core / connecthttpproxy . java <nl>
class vertxhttp2clienthandler extends vertxhttp2connectionhandler implements htt <nl> httpversion . http_2 , <nl> this , <nl> status , <nl> - " <nl> + statusmessage , <nl> new http2headersadaptor ( headers ) <nl> ) ; <nl> req . handleresponse ( resp ) ; <nl> mmm a / src / test / java / io / vertx / test / core / http2clienttest . java <nl> ppp b / src / test / java / io / vertx / test / core / http2clienttest . java <nl>
public class http2serverresponseimpl implements httpserverresponse { <nl> @ override <nl> public httpserverresponse closehandler ( @ nullable handler < void > handler ) { <nl> checkended ( ) ; <nl> - <nl> return this ; <nl> } <nl>  <nl> mmm a / src / main / java / io / vertx / core / http / impl / vertxhttp2handler . java <nl> ppp b / src / main / java / io / vertx / core / http / impl / vertxhttp2handler . java <nl>
public class http2test extends httptestbase { <nl> when . complete ( ) ; <nl> httpserverresponse resp = ar . result ( ) ; <nl> resp . exceptionhandler ( err - > { <nl> - <nl> + assertsame ( ctx , vertx . currentcontext ( ) ) ; <nl> complete ( ) ; <nl> } ) ; <nl> resp . setchunked ( true ) . write ( " whatever " ) ; / / transition to half - closed remote <nl> } ) ; <nl> } ) ; <nl> - startserver ( ) ; ; <nl> + startserver ( ctx ) ; ; <nl> testclient client = new testclient ( ) ; <nl> channelfuture fut = client . connect ( 4043 , " localhost " , request - > { <nl> request . decoder . framelistener ( new http2eventadapter ( ) { <nl>
request . exceptionhandler ( e - > { <nl> } ) ; <nl> - - - - <nl>  <nl> - <nl> + this does not handle non _2xx_ response that need to be handled in the <nl> + ` link : . . / . . / apidocs / io / vertx / core / http / httpclientresponse . html [ httpclientresponse ] ` code : <nl>  <nl> - maybe need a catch all exception handler ? ? <nl> + [ source , java ] <nl> + - - - - <nl> + httpclientrequest request = client . post ( " some - uri " , response - > { <nl> + if ( response . statuscode ( ) = = num ) { <nl> + system . out . println ( " everything fine " ) ; <nl> + return ; <nl> + } <nl> + if ( response . statuscode ( ) = = num ) { <nl> + system . out . println ( " unexpected behavior on the server side " ) ; <nl> + return ; <nl> + } <nl> + } ) ; <nl> + request . end ( ) ; <nl> + - - - - <nl> + <nl> + important : ` xxxnow ` methods cannot receive an exception handler . <nl>  <nl> = = = = specifying a handler on the client request <nl>  <nl> mmm a / src / main / java / examples / httpexamples . java <nl> ppp b / src / main / java / examples / httpexamples . java <nl>
<nl> * <nl> * = = = = handling exceptions <nl> * <nl> - * you can handle exceptions corresponding to a request by setting an exception handler on the { @ link io . vertx . core . http . httpclientrequest } <nl> - * instance : <nl> + * you can handle exceptions corresponding to a request by setting an exception handler on the <nl> + * { @ link io . vertx . core . http . httpclientrequest } instance : <nl> * <nl> * [ source , $ lang ] <nl> * - - - - <nl> * { @ link examples . httpexamples # example42 } <nl> * - - - - <nl> * <nl> - * <nl> + * this does not handle non _2xx_ response that need to be handled in the <nl> + * { @ link io . vertx . core . http . httpclientresponse } code : <nl> * <nl> - * maybe need a catch all exception handler ? ? <nl> + * [ source , $ lang ] <nl> + * - - - - <nl> + * { @ link examples . httpexamples # statuscodehandling } <nl> + * - - - - <nl> + * <nl> + * important : ` xxxnow ` methods cannot receive an exception handler . <nl> * <nl> * = = = = specifying a handler on the client request <nl> *
public class starter { <nl> log . info ( usage ) ; <nl> } <nl>  <nl> - / * <nl> - <nl> - <nl> - vertx run < main > - vertx . cluster - host somehost - vertx . cluster - port someport - vertx . ha - enabled true - deploy . worker <nl> - false <nl> - * / <nl> }
public class repodownloadtest extends testbase { <nl> @ override <nl> protected void setup ( ) throws exception { <nl> super . setup ( ) ; <nl> - <nl> startapp ( repodownloadtestclient . class . getname ( ) ) ; <nl> - <nl> - <nl> - thread . sleep ( 1000 ) ; <nl> } <nl>  <nl> @ override <nl> mmm a / vertx - testsuite / src / test / java / vertx / tests / repodownloadtestclient . java <nl> ppp b / vertx - testsuite / src / test / java / vertx / tests / repodownloadtestclient . java <nl>
public class defaultplatformmanager implements platformmanagerinternal , modulere <nl> if ( modjson = = null ) { <nl> throw new platformmanagerexception ( " failed to find mod . json on classpath " ) ; <nl> } <nl> - file moddir = locatemodule ( modroot , null , modid ) ; <nl> list < url > cplist = new arraylist < > ( arrays . aslist ( classpath ) ) ; <nl> - if ( moddir ! = null ) { <nl> - <nl> - / / add the module directory too if found <nl> - cplist . addall ( getmoduleclasspath ( moddir ) ) ; <nl> - } <nl> deploymodulefrommodjson ( modjson , depname , modid , config , instances , null , null , cplist , modroot , false , <nl> donehandler ) ; <nl> } <nl>
public class defaultvertx implements vertxinternal { <nl> private final filesystem filesystem = getfilesystem ( ) ; <nl> private final eventbus eventbus ; <nl> private final shareddata shareddata = new shareddata ( ) ; <nl> - <nl> - private final dnsclient dnsclient ; <nl>  <nl> private executorservice backgroundpool = vertxexecutorfactory . workerpool ( " vert . x - worker - thread - " ) ; <nl> private final orderedexecutorfactory orderedfact = new orderedexecutorfactory ( backgroundpool ) ; <nl>
public class diskcacheclient implements remotecacheclient { <nl>  <nl> / / write a temporary file first , and then rename , to avoid data corruption in case of a crash . <nl> path temp = topathnosplit ( uuid . randomuuid ( ) . tostring ( ) ) ; <nl> - try ( outputstream out = temp . getoutputstream ( ) ) { <nl> + <nl> + try ( fileoutputstream out = new fileoutputstream ( temp . getpathfile ( ) ) ) { <nl> bytestreams . copy ( in , out ) ; <nl> + / / fsync temp before we rename it to avoid data loss in the case of machine <nl> + / / crashes ( the os may reorder the writes and the rename ) . <nl> + out . getfd ( ) . sync ( ) ; <nl> } <nl> - <nl> - / / crashes ( the os may reorder the writes and the rename ) . <nl> temp . renameto ( target ) ; <nl> } <nl> }
public class treeartifactvalue implements hasdigest , skyvalue { <nl>  <nl> @ override <nl> public filestatetype gettype ( ) { <nl> - <nl> - return filestatetype . regular_file ; <nl> + return filestatetype . directory ; <nl> } <nl>  <nl> @ override
public class packageoptions extends optionsbase { <nl>  <nl> @ option ( <nl> name = " incompatible_config_setting_private_default_visibility " , <nl> - <nl> - / / - - incompatible_enforce_config_setting_visibility = true . <nl> - defaultvalue = " true " , <nl> + defaultvalue = " false " , <nl> documentationcategory = optiondocumentationcategory . starlark_semantics , <nl> effecttags = { optioneffecttag . loading_and_analysis } , <nl> metadatatags = { optionmetadatatag . incompatible_change } ,
def _py_runtime_impl ( ctx ) : <nl> if ctx . attr . coverage_tool : <nl> coverage_di = ctx . attr . coverage_tool [ defaultinfo ] <nl>  <nl> - # <nl> - # instead of always flattening to a list <nl> - coverage_di_files = coverage_di . files . to_list ( ) <nl> - if len ( coverage_di_files ) = = num : <nl> - coverage_tool = coverage_di_files [ 0 ] <nl> + if _py_builtins . is_singleton_depset ( coverage_di . files ) : <nl> + coverage_tool = coverage_di . files . to_list ( ) [ 0 ] <nl> elif coverage_di . files_to_run and coverage_di . files_to_run . executable : <nl> coverage_tool = coverage_di . files_to_run . executable <nl> else :
public class remoteactionfilesystem extends delegatefilesystem { <nl> tree . putchild ( child , createremotemetadata ( remotefile ) ) ; <nl> } <nl> } ) ; <nl> - } <nl>  <nl> - <nl> - <nl> - metadatainjector . injecttree ( parent , tree . build ( ) ) ; <nl> + metadatainjector . injecttree ( parent , tree . build ( ) ) ; <nl> + } <nl> } else { <nl> remotefileinfo remotefile = <nl> remoteoutputtree . getremotefileinfo ( path , / * followsymlinks = * / true ) ;
public class packageoptions extends optionsbase { <nl>  <nl> @ option ( <nl> name = " incompatible_config_setting_private_default_visibility " , <nl> - <nl> - / / - - incompatible_enforce_config_setting_visibility = true . <nl> - defaultvalue = " true " , <nl> + defaultvalue = " false " , <nl> documentationcategory = optiondocumentationcategory . starlark_semantics , <nl> effecttags = { optioneffecttag . loading_and_analysis } , <nl> metadatatags = { optionmetadatatag . incompatible_change } ,
public class packageoptions extends optionsbase { <nl>  <nl> @ option ( <nl> name = " incompatible_enforce_config_setting_visibility " , <nl> - <nl> - / / to true , then make these no - ops , then remove . <nl> - defaultvalue = " true " , <nl> + defaultvalue = " false " , <nl> documentationcategory = optiondocumentationcategory . starlark_semantics , <nl> effecttags = { optioneffecttag . loading_and_analysis } , <nl> metadatatags = { optionmetadatatag . incompatible_change } ,
public class bazelembeddedstarlarkblackboxtest extends abstractblackboxtest { <nl> } <nl>  <nl> private builderrunner bazel ( ) { <nl> - / / on mac , set host config to use py2 because our ci mac workers don ' t have a python num runtime . <nl> - <nl> - / / workaround . <nl> - if ( system . getproperty ( " os . name " ) . tolowercase ( ) . startswith ( " mac os x " ) ) { <nl> - system . out . println ( <nl> - " setting host python to py2 to workaround unavailability of python num on mac ci " ) ; <nl> - return workspacetestutils . bazel ( context ( ) ) . withflags ( " - - host_force_python = py2 " ) ; <nl> - } else { <nl> - return workspacetestutils . bazel ( context ( ) ) ; <nl> - } <nl> + return workspacetestutils . bazel ( context ( ) ) ; <nl> } <nl>  <nl> private path decompress ( path datatarpath ) throws exception { <nl> mmm a / src / test / shell / bazel / bazel_embedded_starlark_test . sh <nl> ppp b / src / test / shell / bazel / bazel_embedded_starlark_test . sh <nl>
source " $ { current_dir } / remote_helpers . sh " \ <nl> | | { echo " remote_helpers . sh not found ! " > & 2 ; exit num ; } <nl>  <nl>  <nl> - # on mac , set host config to use py2 because our ci mac workers don ' t have a <nl> - # python num runtime . <nl> - # <nl> - # remove this workaround . <nl> - if [ [ " $ ( uname - s | tr [ : upper : ] [ : lower : ] | grep - e ' darwin . * ' ) " ] ] ; then <nl> - host_py_flag = " - - host_force_python = py2 " <nl> - echo " setting host python to py2 to workaround unavailability of python num \ <nl> - on mac ci " <nl> - else <nl> - host_py_flag = " " <nl> - fi <nl> - <nl> - <nl> test_pkg_tar ( ) { <nl> rm - rf main <nl> mkdir main <nl>
public class dynamicspawnstrategy implements spawnstrategy { <nl> throws interruptedexception { <nl> dynamicmode cancellingstrategy = cancellingbranch . getmode ( ) ; <nl> if ( cancellingbranch . iscancelled ( ) ) { <nl> - <nl> - / / cancelled . <nl> throw new dynamicinterruptedexception ( <nl> string . format ( <nl> - " execution of % s strategy stopped because it was cancelled but not interrupted " , <nl> + " execution of % s strategy was cancelled just before it could get the lock . " , <nl> cancellingstrategy ) ) ; <nl> } <nl> / / this multi - step , unlocked access to " strategythatcancelled " is valid because , for a given
eof <nl> } <nl>  <nl> function test_compiler_flag_clang ( ) { <nl> - # <nl> - # " compiler " . <nl> - [ " $ platform " ! = " darwin " ] | | return num <nl> type - p clang | | return num <nl>  <nl> cat > build . bazel < < ' eof ' <nl> mmm a / tools / osx / crosstool / cc_toolchain_config . bzl <nl> ppp b / tools / osx / crosstool / cc_toolchain_config . bzl <nl>
load ( " : a . bzl " , " a " ) <nl> a ( name = " a " ) <nl> eof <nl>  <nl> - # <nl> - bazel build / / a : a | | fail " build failed " <nl> - assert_contains " hello , world ! " bazel - bin / a / a . link / inside . txt <nl> - expect_symlink bazel - bin / a / a . link <nl> + bazel build / / a : a > & $ test_log & & fail " build succeeded " <nl> + expect_log " symlink ( ) with \ " target_file \ " directory param requires that \ " output \ " be declared as a directory " <nl>  <nl> - bazel build - - noincompatible_disallow_symlink_file_to_dir | | fail " build failed " <nl> + bazel build - - noincompatible_disallow_symlink_file_to_dir / / a : a | | fail " build failed " <nl> assert_contains " hello , world ! " bazel - bin / a / a . link / inside . txt <nl> expect_symlink bazel - bin / a / a . link
platforms : <nl> build_flags : <nl> - " - - copt = - w " <nl> - " - - host_copt = - w " <nl> - # <nl> - # - " - c " <nl> - # - " opt " <nl> + - " - c " <nl> + - " opt " <nl> build_targets : <nl> - " / / src : bazel . exe " <nl> - " / / src : bazel_nojdk . exe " <nl>
platforms : <nl> build_flags : <nl> - " - - copt = - w " <nl> - " - - host_copt = - w " <nl> - # <nl> - # - " - c " <nl> - # - " opt " <nl> + - " - c " <nl> + - " opt " <nl> - " - - cpu = x64_arm64_windows " <nl> build_targets : <nl> - " / / src : bazel . exe "
java_library_srcs ( <nl> deps = [ " : failure_details_java_proto " ] , <nl> ) <nl>  <nl> - # this new option tagging method is in flux while being applied to the options <nl> - # in the bazel code base . the visibility should not be changed to allow external <nl> - # dependencies until the interface has stabilized and can commit to maintaining <nl> - # backwards compatibility for num months ' time . <nl> - # <nl> proto_library ( <nl> name = " option_filters_proto " , <nl> srcs = [ " option_filters . proto " ] , <nl> - visibility = [ " / / visibility : private " ] , <nl> ) <nl>  <nl> java_proto_library ( <nl> name = " option_filters_java_proto " , <nl> - visibility = [ " / / src : __subpackages__ " ] , <nl> deps = [ " : option_filters_proto " ] , <nl> ) <nl>  <nl> java_library_srcs ( <nl> name = " option_filters_java_proto_srcs " , <nl> - visibility = [ " / / visibility : private " ] , <nl> deps = [ " : option_filters_java_proto " ] , <nl> ) <nl>  <nl> proto_library ( <nl> name = " command_line_proto " , <nl> srcs = [ " command_line . proto " ] , <nl> - visibility = [ " / / src / main / java / com / google / devtools / build / lib / buildeventstream / proto : __pkg__ " ] , <nl> deps = [ " : option_filters_proto " ] , <nl> ) <nl>  <nl>
eof <nl> - - platforms = @ / / target_skipping : foo1_bar1_platform \ <nl> / / target_skipping : twice_inspected_foo3_target & > " $ { test_log } " \ <nl> & & fail " bazel passed unexpectedly . " <nl> - # <nl> - expect_log ' error : target / / target_skipping : twice_inspected_foo3_target is incompatible and cannot be built , but was explicitly requested . ' <nl> - expect_log ' ^ dependency chain : $ ' <nl> - expect_log ' ^ / / target_skipping : twice_inspected_foo3_target ' <nl> - expect_log ' ^ / / target_skipping : previously_inspected_basic_target ' <nl> - expect_log ' ^ / / target_skipping : inspected_foo3_target ' <nl> - expect_log ' ^ / / target_skipping : aliased_other_basic_target ' <nl> - expect_log ' ^ / / target_skipping : other_basic_target ' <nl> - expect_log " / / target_skipping : basic_foo3_target . * < - - target platform ( / / target_skipping : foo1_bar1_platform ) didn ' t satisfy constraint / / target_skipping : foo3 : " <nl> + expect_log_once ' error : target / / target_skipping : twice_inspected_foo3_target is incompatible and cannot be built , but was explicitly requested . ' <nl> + expect_log_once ' ^ dependency chain : $ ' <nl> + expect_log_once ' ^ / / target_skipping : twice_inspected_foo3_target ' <nl> + expect_log_once ' ^ / / target_skipping : previously_inspected_basic_target ' <nl> + expect_log_once ' ^ / / target_skipping : inspected_foo3_target ' <nl> + expect_log_once ' ^ / / target_skipping : aliased_other_basic_target ' <nl> + expect_log_once ' ^ / / target_skipping : other_basic_target ' <nl> + expect_log_once " / / target_skipping : basic_foo3_target . * < - - target platform ( / / target_skipping : foo1_bar1_platform ) didn ' t satisfy constraint / / target_skipping : foo3 $ " <nl> expect_log ' failed : build did not complete successfully ' <nl> expect_not_log " $ { debug_message1 } " <nl> expect_not_log " $ { debug_message2 } "
cc_binary_attrs_with_aspects = { <nl> " _stl " : semantics . get_stl ( ) , <nl> " _cc_toolchain " : attr . label ( default = " @ " + semantics . get_repo ( ) + " / / tools / cpp : current_cc_toolchain " ) , <nl> " _cc_toolchain_type " : attr . label ( default = " @ " + semantics . get_repo ( ) + " / / tools / cpp : toolchain_type " ) , <nl> - # <nl> - " _default_copts " : attr . string_list ( ) , <nl> + " _default_copts " : attr . string_list ( default = cc_internal . default_copts_computed_default ( ) ) , <nl> " _def_parser " : semantics . get_def_parser ( ) , <nl> }
public class cppruleclasses { <nl> } <nl>  <nl> public static toolchaintyperequirement cctoolchaintyperequirement ( label cctoolchaintype ) { <nl> - <nl> - / / optional . <nl> - return toolchaintyperequirement . builder ( cctoolchaintype ) . mandatory ( true ) . build ( ) ; <nl> + / / this is an optional dependency : if a toolchain cannot be found , cpphelper will give an <nl> + / / appropriate error . <nl> + return toolchaintyperequirement . builder ( cctoolchaintype ) . mandatory ( false ) . build ( ) ; <nl> } <nl>  <nl> public static toolchaintyperequirement cctoolchaintyperequirement ( ruledefinitionenvironment env ) {
compile_action_implicit_attrs = { <nl> providers = [ java_common . javatoolchaininfo ] , <nl> ) , <nl> } <nl> - <nl> - # <nl> - compile_action = create_dep ( <nl> - compile_action , <nl> - attrs = { <nl> - " srcs " : attr . label_list ( <nl> - allow_files = [ " . java " , " . srcjar " , " . properties " ] + semantics . extra_srcs_types , <nl> - flags = [ " direct_compile_time_input " , " order_independent " ] , <nl> - ) , <nl> - " data " : attr . label_list ( <nl> - allow_files = true , <nl> - flags = [ " skip_constraints_override " ] , <nl> - ) , <nl> - " resources " : attr . label_list ( <nl> - allow_files = true , <nl> - flags = [ " skip_constraints_override " , " order_independent " ] , <nl> - ) , <nl> - " plugins " : attr . label_list ( <nl> - providers = [ javaplugininfo ] , <nl> - allow_files = true , <nl> - cfg = " exec " , <nl> - ) , <nl> - " deps " : attr . label_list ( <nl> - allow_files = [ " . jar " ] , <nl> - allow_rules = semantics . allowed_rules_in_deps + semantics . allowed_rules_in_deps_with_warning , <nl> - providers = [ <nl> - [ ccinfo ] , <nl> - [ javainfo ] , <nl> - ] , <nl> - flags = [ " skip_analysis_time_filetype_check " ] , <nl> - ) , <nl> - " runtime_deps " : attr . label_list ( <nl> - allow_files = [ " . jar " ] , <nl> - allow_rules = semantics . allowed_rules_in_deps , <nl> - providers = [ [ ccinfo ] , [ javainfo ] ] , <nl> - flags = [ " skip_analysis_time_filetype_check " ] , <nl> - ) , <nl> - " exports " : attr . label_list ( <nl> - allow_rules = semantics . allowed_rules_in_deps , <nl> - providers = [ [ javainfo ] , [ ccinfo ] ] , <nl> - ) , <nl> - " exported_plugins " : attr . label_list ( <nl> - providers = [ javaplugininfo ] , <nl> - cfg = " exec " , <nl> - ) , <nl> - " javacopts " : attr . string_list ( ) , <nl> - " neverlink " : attr . bool ( ) , <nl> - " add_exports " : attr . string_list ( ) , <nl> - " add_opens " : attr . string_list ( ) , <nl> - " _java_toolchain " : attr . label ( <nl> - default = semantics . java_toolchain_label , <nl> - providers = [ java_common . javatoolchaininfo ] , <nl> - ) , <nl> - " _java_plugins " : attr . label ( <nl> - default = semantics . java_plugins_flag_alias_label , <nl> - providers = [ javaplugininfo ] , <nl> - ) , <nl> - } , <nl> - fragments = [ " java " , " cpp " ] , <nl> - mandatory_attrs = [ " srcs " , " deps " , " resources " , " plugins " , " javacopts " , " neverlink " ] , <nl> - ) <nl> mmm a / src / main / starlark / builtins_bzl / common / java / java_common . bzl <nl> ppp b / src / main / starlark / builtins_bzl / common / java / java_common . bzl <nl>
basic_java_library_with_proguard_implicit_attrs = merge_attrs ( <nl> basic_java_library_implicit_attrs , <nl> validate_proguard_specs_implicit_attrs , <nl> ) <nl> - <nl> - # <nl> - java_common_dep = create_composite_dep ( <nl> - basic_java_library , <nl> - compile_action , <nl> - )
public interface gowrapcchelperapi < <nl> object starlarkwrapcontext , <nl> ccinfot ccinfo ) ; <nl>  <nl> - @ starlarkmethod ( <nl> - name = " go_wrap_cc_info " , <nl> - doc = " " , <nl> - documented = false , <nl> - parameters = { <nl> - @ param ( name = " ctx " , positional = false , named = true ) , <nl> - @ param ( name = " cc_info " , positional = false , named = true ) , <nl> - } ) <nl> - <nl> - public gowrapccinfoapi < filet > getgowrapccinfo ( <nl> - starlarkrulecontextt starlarkrulecontext , ccinfot ccinfo ) <nl> - throws evalexception , interruptedexception ; <nl> - <nl> @ starlarkmethod ( <nl> name = " go_cc_link_params_provider " , <nl> doc = " " , <nl> mmm a / src / main / java / com / google / devtools / build / lib / starlarkbuildapi / cpp / gowrapccinfoapi . java <nl> ppp / dev / null <nl>
public class androidconfiguration extends fragment implements androidconfigurati <nl>  <nl> @ option ( <nl> name = " use_workers_with_dexbuilder " , <nl> - <nl> - / / https : / / github . com / bazelbuild / bazel / issues / 10241 is addressed <nl> - defaultvalue = " false " , <nl> + defaultvalue = " true " , <nl> documentationcategory = optiondocumentationcategory . undocumented , <nl> effecttags = { optioneffecttag . execution } , <nl> help = " whether dexbuilder supports being run in local worker mode . " )
public final class errorproneplugin extends blazejavacompilerplugin { <nl> private errorpronetimings timings ; <nl> private final stopwatch elapsed = stopwatch . createunstarted ( ) ; <nl>  <nl> - <nl> - static class errorpronetimings { <nl> - static class < ? > clazz ; <nl> - <nl> - static { <nl> - try { <nl> - clazz = class . forname ( " com . google . errorprone . errorpronetimings " ) ; <nl> - } catch ( classnotfoundexception e ) { <nl> - / / ignored <nl> - } <nl> - } <nl> - <nl> - private final object instance ; <nl> - <nl> - public errorpronetimings ( object instance ) { <nl> - this . instance = instance ; <nl> - } <nl> - <nl> - public static errorpronetimings instance ( context context ) { <nl> - object instance = null ; <nl> - if ( clazz ! = null ) { <nl> - try { <nl> - instance = clazz . getmethod ( " instance " , context . class ) . invoke ( null , context ) ; <nl> - } catch ( reflectiveoperationexception e ) { <nl> - throw new linkageerror ( e . getmessage ( ) , e ) ; <nl> - } <nl> - } <nl> - return new errorpronetimings ( instance ) ; <nl> - } <nl> - <nl> - @ suppresswarnings ( " unchecked " ) / / reflection <nl> - public map < string , duration > timings ( ) { <nl> - if ( clazz = = null ) { <nl> - return immutablemap . of ( ) ; <nl> - } <nl> - try { <nl> - return ( map < string , duration > ) clazz . getmethod ( " timings " ) . invoke ( instance ) ; <nl> - } catch ( reflectiveoperationexception e ) { <nl> - throw new linkageerror ( e . getmessage ( ) , e ) ; <nl> - } <nl> - } <nl> - } <nl> - <nl> / * * registers our message bundle . * / <nl> public static void setupmessagebundle ( context context ) { <nl> baseerrorpronejavacompiler . setupmessagebundle ( context ) ; <nl>
public abstract class resolvedtoolchaincontext implements toolchaincontext { <nl> immutablemap < toolchaintypeinfo , toolchaininfo > toolchains = toolchainsbuilder . buildorthrow ( ) ; <nl>  <nl> / / verify that all mandatory toolchain type requirements are present . <nl> - <nl> - / * <nl> for ( toolchaintyperequirement toolchaintyperequirement : <nl> unloadedtoolchaincontext . toolchaintypes ( ) ) { <nl> if ( toolchaintyperequirement . mandatory ( ) ) { <nl>
public class resolvedtoolchaincontexttest extends toolchaintestcase { <nl> . isequalto ( " baz " ) ; <nl> } <nl>  <nl> - <nl> @ test <nl> - @ ignore ( " b / 232128775 " ) <nl> public void load_mandatory_missing ( ) throws exception { <nl> toolchaincontextkey toolchaincontextkey = <nl> toolchaincontextkey . key ( ) <nl> mmm a / src / test / shell / integration / toolchain_test . sh <nl> ppp b / src / test / shell / integration / toolchain_test . sh <nl>
eof <nl> bazel build \ <nl> - - aspects / / $ { pkg } / toolchain : aspect_use_toolchain . bzl % use_toolchain \ <nl> " / / $ { pkg } / demo : use . log " & > $ test_log | | fail " build failed " <nl> - # <nl> - # expect_log ' using toolchain in aspect : rule message : " bar from demo " , toolchain extra_str : " foo from test_toolchain " ' <nl> + expect_log ' using toolchain in aspect : rule message : " bar from demo " , toolchain extra_str : " foo from test_toolchain " ' <nl> } <nl>  <nl> function test_toolchain_use_in_aspect_non_required_toolchain {
build : macos - - macos_minimum_os = 10 . 10 <nl>  <nl> # enable bzlmod <nl> build : bzlmod - - experimental_enable_bzlmod <nl> - # <nl> - build : bzlmod - - crosstool_top = @ rules_cc . 0 . 0 . 1 . cc_configure . local_config_cc / / : toolchain <nl> - build : bzlmod - - xcode_version_config = @ rules_cc . 0 . 0 . 1 . cc_configure . local_config_xcode / / : host_xcodes <nl>  <nl> # enable java num language features ( https : / / github . com / bazelbuild / bazel / issues / 14592 ) <nl> build - - java_language_version = 11 <nl> mmm a / module . bazel <nl> ppp b / module . bazel <nl>
<nl> # see the license for the specific language governing permissions and <nl> # limitations under the license . <nl>  <nl> - " " " a starlark implementation of the java_lite_proto_library rule . <nl> - <nl> - <nl> - * return proguardspecprovider from the rule via javaprovider . <nl> - * return proto_java from the aspect . <nl> - " " " <nl> + " " " a starlark implementation of the java_lite_proto_library rule . " " " <nl>  <nl> load ( " : common / java / java_semantics . bzl " , " semantics " ) <nl> + load ( " : common / proto / proto_common . bzl " , " protolangtoolchaininfo " , proto_common = " proto_common_do_not_use " ) <nl>  <nl> proto_toolchain_attr = " _aspect_proto_toolchain_for_javalite " <nl> proto_javacopts_key = " proto " <nl> java_toolchain_attr = " _java_toolchain " <nl>  <nl> java_common = _builtins . toplevel . java_common <nl> - java_proto_common = _builtins . toplevel . java_proto_common <nl> + protoinfo = _builtins . toplevel . protoinfo <nl> javainfo = _builtins . toplevel . javainfo <nl> proguardspecprovider = _builtins . toplevel . proguardspecprovider <nl>  <nl> _javaprotoaspectinfo = provider ( " javaprotoaspectinfo " , fields = [ " jars " ] ) <nl>  <nl> def _rule_impl ( ctx ) : <nl> - runtime = java_proto_common . get_runtime ( <nl> - ctx , <nl> - proto_toolchain_attr = proto_toolchain_attr , <nl> - ) <nl> - proguard_provider_specs = [ ] <nl> + proto_toolchain_info = ctx . attr . _aspect_proto_toolchain_for_javalite [ protolangtoolchaininfo ] <nl> + runtime = proto_toolchain_info . runtime <nl> + <nl> if runtime : <nl> - proguard_provider_specs = [ runtime [ proguardspecprovider ] . specs ] <nl> + proguard_provider_specs = runtime [ proguardspecprovider ] <nl> + else : <nl> + proguard_provider_specs = proguardspecprovider ( depset ( ) ) <nl>  <nl> # merging the retrieved list of aspect providers from the dependencies and runtime javainfo providers . <nl> java_info = java_common . merge ( <nl>
final class pathlabelvisitor { <nl> if ( visitor . hasvisited ( t ) ) { <nl> arraydeque < target > result = new arraydeque < > ( ) ; <nl> target at = t ; <nl> - <nl> while ( true ) { <nl> result . addfirst ( at ) ; <nl> list < target > pred = visitor . getparents ( at ) ; <nl> - if ( pred = = null ) { <nl> + if ( pred = = null | | pred . isempty ( ) ) { <nl> break ; <nl> } <nl> at = pred . get ( 0 ) ; <nl>
public interface gowrapcchelperapi < <nl> public runfilesapi starlarkgetgorunfiles ( starlarkrulecontextt starlarkrulecontext ) <nl> throws evalexception , interruptedexception ; <nl>  <nl> - @ starlarkmethod ( <nl> - name = " get_arch_int_size " , <nl> - doc = " " , <nl> - documented = false , <nl> - parameters = { <nl> - @ param ( name = " go " , positional = false , named = true ) , <nl> - } ) <nl> - <nl> - public int getarchintsize ( goconfigurationt goconfig ) ; <nl> - <nl> @ starlarkmethod ( <nl> name = " collect_transitive_go_context_gopkg " , <nl> doc = " " ,
public final class label implements comparable < label > , starlarkvalue , skykey , co <nl> return label_interner . intern ( new label ( packageidentifier , internedname ) ) ; <nl> } <nl>  <nl> - / * * <nl> - * parses and resolves a label string relative to the given workspace - relative directory . <nl> - * <nl> - * < ul > <nl> - * < li > if the input is an absolute label , it is parsed as normal . <nl> - * < li > if the input starts with a colon or does not contain a colon , the package path is taken <nl> - * to be the working directory , and the part after the leading colon ( if present ) is taken <nl> - * to be the target . <nl> - * < li > if the input has a non - empty part before a colon , it is appended to the working directory <nl> - * to form the package path , and the part after the colon is taken as the target . <nl> - * < / ul > <nl> - * <nl> - * < p > note that this method does not support any of the special syntactic constructs otherwise <nl> - * supported on the command line , like " : all " , " / . . . " , and so on . <nl> - * <nl> - * < p > it would be cleaner to use the targetpatternevaluator for this resolution , but that is not <nl> - * possible , because it is sometimes necessary to resolve a relative label before the package path <nl> - * is setup ( maybe not anymore . . . ) <nl> - * <nl> - * @ throws labelsyntaxexception if the resulting label is not valid <nl> - * / <nl> - public static label parsecommandlinelabel ( string raw , pathfragment workspacerelativepath ) <nl> - throws labelsyntaxexception { <nl> - preconditions . checkargument ( ! workspacerelativepath . isabsolute ( ) ) ; <nl> - parts parts = parts . parse ( raw ) ; <nl> - pathfragment pathfragment ; <nl> - if ( parts . repo = = null & & ! parts . pkgisabsolute ) { <nl> - pathfragment = workspacerelativepath . getrelative ( parts . pkg ) ; <nl> - } else { <nl> - pathfragment = pathfragment . create ( parts . pkg ) ; <nl> - } <nl> - <nl> - repositoryname reponame = <nl> - parts . repo = = null ? repositoryname . main : repositoryname . createunvalidated ( parts . repo ) ; <nl> - return create ( packageidentifier . create ( reponame , pathfragment ) , parts . target ) ; <nl> - } <nl> - <nl> / * * the name and repository of the package . * / <nl> private final packageidentifier packageidentifier ; <nl>  <nl> mmm a / src / test / java / com / google / devtools / build / lib / cmdline / labeltest . java <nl> ppp b / src / test / java / com / google / devtools / build / lib / cmdline / labeltest . java <nl>
public interface gowrapcchelperapi < <nl> public runfilesapi starlarkgetgorunfiles ( starlarkrulecontextt starlarkrulecontext ) <nl> throws evalexception , interruptedexception ; <nl>  <nl> - @ starlarkmethod ( <nl> - name = " get_arch_int_size " , <nl> - doc = " " , <nl> - documented = false , <nl> - parameters = { <nl> - @ param ( name = " go " , positional = false , named = true ) , <nl> - } ) <nl> - <nl> - public int getarchintsize ( goconfigurationt goconfig ) ; <nl> - <nl> @ starlarkmethod ( <nl> name = " collect_transitive_go_context_gopkg " , <nl> doc = " " ,
sh_test ( <nl> ] , <nl> tags = [ " no_windows " ] , <nl> ) <nl> - # <nl> - for java_version in java_versions_coverage + ( " 17 " , ) <nl> + for java_version in java_versions_coverage <nl> ] <nl>  <nl> sh_test (
def basic_java_library ( <nl> _direct_source_jars = java_info . source_jars , <nl> ) <nl>  <nl> - # <nl> - # an explicit test for " host " or " tool " configuration . <nl> - if not ( ctx . configuration = = ctx . host_configuration or <nl> - ctx . bin_dir . path . find ( " - exec - " ) > = num ) and not neverlink : <nl> + if ctx . fragments . java . run_android_lint : <nl> generated_source_jars = [ <nl> output . generated_source_jar <nl> for output in java_info . java_outputs
public final class blazedirectories { <nl> } <nl>  <nl> / * * <nl> - * returns the output directory name , relative to the execroot . <nl> - * private ? <nl> + * returns the directory where bazel writes build outputs , relative to the execroot . <nl> + * <nl> + * < p > for example : { @ code " bazel - out " } . <nl> * / <nl> public static string getrelativeoutputpath ( string productname ) { <nl> return stringcanonicalizer . intern ( productname + " - out " ) ;
if [ [ - n " $ verbose_coverage " ] ] ; then <nl> set - x <nl> fi <nl>  <nl> - if [ [ - z " $ lcov_merger " ] ] ; then <nl> - # this can happen if a rule returns an instrumentedfilesinfo ( which all do <nl> - # following num b216b2 ) but does not define an _lcov_merger attribute . <nl> - # unfortunately , we cannot simply stop this script being called in this case <nl> - # due to conflicts with how things work within google . <nl> - # the file creation is required because testactionbuilder has already declared <nl> - # it . <nl> - # <nl> - touch $ coverage_output_file <nl> - # execute the test . <nl> - " $ @ " <nl> - test_status = $ ? <nl> - exit " $ test_status " <nl> - fi <nl> - <nl> function resolve_links ( ) { <nl> local name = " $ 1 " <nl>  <nl>
public final class skyframeerrorprocessor { <nl> * be ignored . <nl> * <nl> * < p > in case of - - nokeep_going : immediately throw the exception . <nl> - * <nl> - * < p > <nl> * / <nl> static errorprocessingresult processerrors ( <nl> evaluationresult < ? extends skyvalue > result , <nl>
public class objccommandlineoptions extends fragmentoptions { <nl> + " set in the crosstool are still applied . " ) <nl> public boolean incompatibleavoidhardcodedobjccompilationflags ; <nl>  <nl> - <nl> + / * * @ deprecated delete when we are sure it ' s not used anywhere . * / <nl> + @ deprecated <nl> @ option ( <nl> name = " incompatible_disable_native_apple_binary_rule " , <nl> defaultvalue = " false " , <nl> mmm a / src / test / java / com / google / devtools / build / lib / testutil / testconstants . java <nl> ppp b / src / test / java / com / google / devtools / build / lib / testutil / testconstants . java <nl>
public final class starlarkfunction implements starlarkcallable { <nl>  <nl> immutablelist < string > names = rfn . getparameternames ( ) ; <nl>  <nl> - <nl> - / / allocating . <nl> - object [ ] arguments = new object [ names . size ( ) ] ; <nl> + object [ ] locals = new object [ rfn . getlocals ( ) . size ( ) ] ; <nl>  <nl> / / nparams is the number of ordinary parameters . <nl> int nparams = <nl>
import net . starlark . java . syntax . tokenkind ; <nl>  <nl> / * * an struct - like info ( provider instance ) for providers defined in starlark . * / <nl> public final class starlarkinfo extends structimpl implements hasbinary { <nl> - <nl> - <nl> - public static final depset . elementtype type = depset . elementtype . of ( starlarkinfo . class ) ; <nl> - <nl> private final provider provider ; <nl>  <nl> / / for a n - element info , the table contains n key strings , sorted ,
public interface skyfunction { <nl> * use the { @ code statesupplier } . it ' s important that skyframe do this because { @ link restart } <nl> * indicates that work should be redone , and so it ' d be wrong to reuse work from the previous <nl> * { @ link # compute } call . <nl> - * <nl> - * < p > <nl> - * sort of optimization . <nl> * / <nl> < t extends skykeycomputestate > t getstate ( supplier < t > statesupplier ) ; <nl> }
public class packagelookupfunction implements skyfunction { <nl>  <nl> @ nullable <nl> private packagelookupvalue findpackagebybuildfile ( <nl> - environment env , pathpackagelocator pkglocator , packageidentifier packagekey ) <nl> + state state , environment env , pathpackagelocator pkglocator , packageidentifier packagekey ) <nl> throws packagelookupfunctionexception , interruptedexception { <nl> - <nl> - / / to having restart the skyfunction after every new dependency . however , if we try to batch <nl> - / / the missing value keys , more dependencies than necessary will be declared . this wart can be <nl> - / / fixed once we have nicer continuation support [ skyframe - loading ] <nl> - for ( root packagepathentry : pkglocator . getpathentries ( ) ) { <nl> - <nl> - / / this checks for the build file names in the correct precedence order . <nl> - for ( buildfilename buildfilename : buildfilesbypriority ) { <nl> + while ( state . packagepathentrypos < pkglocator . getpathentries ( ) . size ( ) ) { <nl> + while ( state . buildfilenamepos < buildfilesbypriority . size ( ) ) { <nl> + root packagepathentry = pkglocator . getpathentries ( ) . get ( state . packagepathentrypos ) ; <nl> + buildfilename buildfilename = buildfilesbypriority . get ( state . buildfilenamepos ) ; <nl> packagelookupvalue result = <nl> getpackagelookupvalue ( env , packagepathentry , packagekey , buildfilename ) ; <nl> if ( result = = null ) { <nl>
def _create_proto_compile_action ( <nl> # set ` - direct_dependencies_violation_msg = ` <nl> args . add ( ctx . label , format = semantics . strict_deps_flag_template ) <nl>  <nl> - # use exports <nl> - # <nl> + if strict_imports : <nl> + if not proto_info . public_import_sources ( ) : <nl> + # this line is necessary to trigger the check . <nl> + args . add ( " - - allowed_public_imports = " ) <nl> + else : <nl> + args . add_all ( " - - allowed_public_imports " , map_each = _get_import_path , join_with = " : " ) <nl>  <nl> args . add_all ( proto_info . direct_sources )
public class applecommandlineoptions extends fragmentoptions { <nl> + " option may be provided multiple times . " ) <nl> public list < map . entry < appleplatform . platformtype , applebitcodemode > > applebitcodemode ; <nl>  <nl> - <nl> - / / single - - platform during the transition instead of splitting on the - - * _cpus flags . <nl> + @ option ( <nl> + name = " incompatible_enable_apple_toolchain_resolution " , <nl> + defaultvalue = " false " , <nl> + documentationcategory = optiondocumentationcategory . toolchain , <nl> + effecttags = { optioneffecttag . loading_and_analysis } , <nl> + metadatatags = { optionmetadatatag . incompatible_change } , <nl> + help = <nl> + " use toolchain resolution to select the apple sdk for apple rules ( starlark and native ) " ) <nl> + public boolean incompatibleusetoolchainresolution ; <nl> + <nl> @ option ( <nl> name = " apple_platforms " , <nl> converter = labellistconverter . class , <nl>
abstract class abstractparallelevaluator { <nl> evaluatorcontext <nl> . geterrorinfomanager ( ) <nl> . fromexception ( skykey , reifiedbuilderexception , istransitivelytransient ) ; <nl> - <nl> - / / ioexceptions in them . <nl> - if ( istransitivelytransient <nl> - & & ! shouldfailfast <nl> - & & errorinfo . getexception ( ) instanceof ioexception ) { <nl> - / / this is essentially unconditionally logged , and not often . ok to evaluate eagerly . <nl> - string keystring = skykey . tostring ( ) ; <nl> - string errorstring = errorinfo . tostring ( ) ; <nl> - logger . atinfo ( ) . log ( <nl> - " got ioexception for % s ( % s ) " , <nl> - keystring . substring ( 0 , min ( 1000 , keystring . length ( ) ) ) , <nl> - errorstring . substring ( 0 , min ( 1000 , errorstring . length ( ) ) ) ) ; <nl> - } <nl> env . seterror ( state , errorinfo ) ; <nl> set < skykey > rdepstobubbleupto = env . commitandgetparents ( state ) ; <nl> if ( shouldfailfast ) {
import java . util . map ; <nl> import java . util . treemap ; <nl> import sun . reflect . reflectionfactory ; <nl>  <nl> - / * * <nl> - * a codec that serializes arbitrary types . <nl> - * <nl> - * < p > <nl> - * / <nl> - public class dynamiccodec implements objectcodec < object > { <nl> + / * * a codec that serializes arbitrary types . * / <nl> + public final class dynamiccodec implements objectcodec < object > { <nl> + <nl> private static final googlelogger logger = googlelogger . forenclosingclass ( ) ; <nl>  <nl> private final class < ? > type ; <nl>
class skyfunctionenvironment extends abstractskyfunctionenvironment { <nl> private immutablemap < skykey , skyvalue > batchprefetch ( <nl> skykey requestor , groupedlist < skykey > depkeys , set < skykey > olddeps , boolean assertdone ) <nl> throws interruptedexception , undonepreviouslyrequesteddeps { <nl> - queryablegraph . prefetchdepsrequest request = null ; <nl> - if ( prefetch_old_deps ) { <nl> - request = new queryablegraph . prefetchdepsrequest ( requestor , olddeps , depkeys ) ; <nl> - evaluatorcontext . getgraph ( ) . prefetchdeps ( request ) ; <nl> - } else if ( prefetch_and_retain_old_deps ) { <nl> - <nl> - this . olddepsentries = <nl> - immutablemap . copyof ( evaluatorcontext . getbatchvalues ( requestor , reason . prefetch , olddeps ) ) ; <nl> - } <nl> + queryablegraph . prefetchdepsrequest prefetchdepsrequest = <nl> + new queryablegraph . prefetchdepsrequest ( requestor , olddeps , depkeys ) ; <nl> + evaluatorcontext . getgraph ( ) . prefetchdeps ( prefetchdepsrequest ) ; <nl> map < skykey , ? extends nodeentry > batchmap = <nl> evaluatorcontext . getbatchvalues ( <nl> requestor , <nl> reason . prefetch , <nl> - ( request ! = null & & request . excludedkeys ! = null ) <nl> - ? request . excludedkeys <nl> + prefetchdepsrequest . excludedkeys ! = null <nl> + ? prefetchdepsrequest . excludedkeys <nl> : depkeys . getallelementsasiterable ( ) ) ; <nl> if ( batchmap . size ( ) ! = depkeys . numelements ( ) ) { <nl> set < skykey > difference = sets . difference ( depkeys . toset ( ) , batchmap . keyset ( ) ) ; <nl>
public final class buildconfigurationfunction implements skyfunction { <nl> trimmed . addfragmentoptions ( options ) ; <nl> } <nl> } <nl> - / / most fragments don ' t need starlark options , but we provide them unconditionally . <nl> - <nl> - return trimmed . addstarlarkoptions ( original . getstarlarkoptions ( ) ) . build ( ) ; <nl> + if ( fragment . requiresstarlarkoptions ( fragment ) ) { <nl> + trimmed . addstarlarkoptions ( original . getstarlarkoptions ( ) ) ; <nl> + } <nl> + return trimmed . build ( ) ; <nl> } <nl>  <nl> @ autovalue
public class buildlanguageoptions extends optionsbase implements serializable { <nl> @ option ( <nl> name = " incompatible_applicable_licenses " , <nl> defaultvalue = " false " , <nl> - <nl> documentationcategory = optiondocumentationcategory . undocumented , <nl> - effecttags = { optioneffecttag . build_file_semantics } , <nl> + effecttags = { optioneffecttag . no_op } , <nl> metadatatags = { optionmetadatatag . incompatible_change } , <nl> - help = " if set to true , enables the function ` attr . applicable_licenses ` . " ) <nl> + help = " no - op " ) <nl> public boolean incompatibleapplicablelicenses ; <nl>  <nl> @ option ( <nl>
build : ubuntu1604_java8 - - host_platform = / / : rbe_ubuntu1604_java8_platform <nl> build : ubuntu1604_java8 - - platforms = / / : rbe_ubuntu1604_java8_platform <nl> build : ubuntu1604_java8 - - config = remote_shared <nl>  <nl> - # <nl> - build : ubuntu1804_java11 - - host_javabase = @ rbe_ubuntu1804_java11 / / java : jdk <nl> - build : ubuntu1804_java11 - - javabase = @ rbe_ubuntu1804_java11 / / java : jdk <nl> - build : ubuntu1804_java11 - - host_java_toolchain = @ bazel_tools / / tools / jdk : toolchain_java9 <nl> - build : ubuntu1804_java11 - - java_toolchain = @ bazel_tools / / tools / jdk : toolchain_java9 <nl> - build : ubuntu1604_java8 - - host_javabase = @ rbe_ubuntu1604_java8 / / java : jdk <nl> - build : ubuntu1604_java8 - - javabase = @ rbe_ubuntu1604_java8 / / java : jdk <nl> - build : ubuntu1604_java8 - - host_java_toolchain = @ bazel_tools / / tools / jdk : toolchain_hostjdk8 <nl> - build : ubuntu1604_java8 - - java_toolchain = @ bazel_tools / / tools / jdk : toolchain_hostjdk8 <nl> - <nl> # alias <nl> build : remote - - config = ubuntu1604_java8
public class methodprobesmapper extends methodprobesvisitor implements ifilterou <nl>  <nl> @ override <nl> public void replacebranches ( abstractinsnnode source , set < abstractinsnnode > newtargets ) { <nl> - <nl> + branchreplacements . put ( source , newtargets ) ; <nl> } <nl>  <nl> private abstractinsnnode findrepresentative ( abstractinsnnode node ) {
public class subcommandeventtest extends buildintegrationtestcase { <nl> @ before <nl> public void stageembeddedtools ( ) throws exception { <nl> analysismock . get ( ) . setupmocktoolsrepository ( mocktoolsconfig ) ; <nl> - <nl> - write ( " embedded_tools / tools / cpp / cc_configure . bzl " , " def cc_configure ( * * kwargs ) : " , " pass " ) ; <nl> - <nl> - write ( " embedded_tools / tools / sh / build " ) ; <nl> - write ( " embedded_tools / tools / sh / sh_configure . bzl " , " def sh_configure ( * * kwargs ) : " , " pass " ) ; <nl> - write ( " embedded_tools / tools / osx / build " ) ; <nl> - write ( <nl> - " embedded_tools / tools / osx / xcode_configure . bzl " , <nl> - " def xcode_configure ( * args , * * kwargs ) : " , / / no positional arguments for xcode <nl> - " pass " ) ; <nl> - write ( " embedded_tools / bin / sh " , " def sh ( * * kwargs ) : " , " pass " ) ; <nl>  <nl> addoptions ( " - - spawn_strategy = standalone " ) ; <nl> }
public class filefunction implements skyfunction { <nl> symlinkresolutionstate . pathtounboundedancestorsymlinkexpansionchain , <nl> symlinkresolutionstate . unboundedancestorsymlinkexpansionchain , <nl> rootedpath , <nl> - <nl> filestatevaluefromancestors , <nl> realrootedpath , <nl> realfilestatevalue ) ;
public class bazelpythonsemantics implements pythonsemantics { <nl>  <nl> if ( os . getcurrent ( ) ! = os . windows ) { <nl> pathfragment shexecutable = shtoolchain . getpathorerror ( rulecontext ) ; <nl> - <nl> - / / property of the python toolchain configuration . <nl> - string pythonexecutablename = os . getcurrent ( ) = = os . openbsd ? " python3 " : " python " ; <nl> + string pythonexecutablename = " python3 " ; <nl> / / note : keep the following line intact to support nix builds <nl> string pythonshebang = " # ! / usr / bin / env " + pythonexecutablename ; <nl> rulecontext . registeraction ( <nl> mmm a / src / test / py / bazel / launcher_test . py <nl> ppp b / src / test / py / bazel / launcher_test . py <nl>
public final class javainfo extends nativeinfo <nl> return this ; <nl> } <nl>  <nl> - <nl> - / / available <nl> - public builder experimentaldisableannotationprocessing ( ) { <nl> - javaplugininfo provider = <nl> - ( javaplugininfo ) providermap . getprovider ( javaplugininfo . provider . getkey ( ) ) ; <nl> - if ( provider ! = null ) { <nl> - providermap . put ( provider . disableannotationprocessing ( ) ) ; <nl> - } <nl> - return this ; <nl> - } <nl> - <nl> public builder setlocation ( location location ) { <nl> this . creationlocation = location ; <nl> return this ; <nl> mmm a / src / main / java / com / google / devtools / build / lib / rules / java / javastarlarkcommon . java <nl> ppp b / src / main / java / com / google / devtools / build / lib / rules / java / javastarlarkcommon . java <nl>
public interface javacommonapi < <nl> enableonlywithflag = buildlanguageoptions . experimental_google_legacy_api ) <nl> sequence < string > getconstraints ( javainfot javainfo ) ; <nl>  <nl> - <nl> - @ starlarkmethod ( <nl> - name = " experimental_disable_annotation_processing " , <nl> - doc = <nl> - " returns a copy of the given javainfo with any provided annotation processors disabled . " <nl> - + " annotation processor classpaths are preserved in case they contain error prone " <nl> - + " plugins , but processor names and data are excluded . for example , it can be " <nl> - + " used to process the inputs to java_common . compile ' s deps and plugins parameters . " , <nl> - parameters = { <nl> - @ param ( <nl> - name = " java_info " , <nl> - positional = true , <nl> - named = false , <nl> - doc = " the javainfo to process . " ) <nl> - } , <nl> - enableonlywithflag = buildlanguageoptions . experimental_google_legacy_api ) <nl> - javainfot removeannotationprocessors ( javainfot javainfo ) ; <nl> - <nl> @ starlarkmethod ( <nl> name = " set_annotation_processing " , <nl> doc = " returns a copy of the given javainfo with the given annotation_processing info . " ,
final class lexer { <nl> this . start = start ; <nl> this . end = end ; <nl> this . value = null ; <nl> - this . raw = null ; <nl> } <nl>  <nl> / / setvalue sets the value associated with a string , float , int , <nl> / / identifier , or comment token , and records the raw text of the token . <nl> private void setvalue ( object value ) { <nl> this . value = value ; <nl> - <nl> - / / but raw is only used for intliteral and floatliteral . can we allocate the raw on demand <nl> - / / instead ? <nl> - this . raw = bufferslice ( start , end ) ; <nl> + } <nl> + <nl> + / * * returns the raw input text associated with the current token . * / <nl> + string getraw ( ) { <nl> + return bufferslice ( start , end ) ; <nl> } <nl>  <nl> / * * <nl> mmm a / src / main / java / net / starlark / java / syntax / parser . java <nl> ppp b / src / main / java / net / starlark / java / syntax / parser . java <nl>
final class evalutils { <nl>  <nl> private static string repeatstring ( string s , starlarkint in ) throws evalexception { <nl> int n = in . toint ( " repeat " ) ; <nl> - <nl> - return n < = num ? " " : strings . repeat ( s , n ) ; <nl> + if ( n < = num ) { <nl> + return " " ; <nl> + } else if ( ( long ) s . length ( ) * ( long ) n > integer . max_value ) { <nl> + / / would exceed max length of a java string ( and would cause an undocumented <nl> + / / arrayindexoutofboundsexception to be thrown in strings . repeat ( ) ) . <nl> + throw starlark . errorf ( " excessive repeat ( % d * % d characters ) " , s . length ( ) , n ) ; <nl> + } else { <nl> + return strings . repeat ( s , n ) ; <nl> + } <nl> } <nl>  <nl> / * * evaluates a unary operation . * / <nl> mmm a / src / test / java / net / starlark / java / eval / testdata / list . star <nl> ppp b / src / test / java / net / starlark / java / eval / testdata / list . star <nl>
public class buildrequestoptions extends optionsbase { <nl> + " https : / / github . com / bazelbuild / bazel / issues / 8651 " ) <nl> public boolean incompatibleskipgenfilessymlink ; <nl>  <nl> - <nl> - @ option ( <nl> - name = " experimental_nested_set_as_skykey_threshold " , <nl> - defaultvalue = " 1 " , <nl> - documentationcategory = optiondocumentationcategory . undocumented , <nl> - metadatatags = optionmetadatatag . experimental , <nl> - effecttags = { optioneffecttag . execution , optioneffecttag . loses_incremental_state } , <nl> - help = " no - op scheduled for removal . " ) <nl> - public int nestedsetasskykeythreshold ; <nl> - <nl> @ option ( <nl> name = " experimental_use_fork_join_pool " , <nl> defaultvalue = " false " ,
public class discoveryfunction implements skyfunction { <nl> rootmodulekey , rewritedepkeys ( root . getmodule ( ) , overrides , rootmodulekey . getname ( ) ) ) ; <nl> queue < modulekey > unexpanded = new arraydeque < > ( ) ; <nl> unexpanded . add ( rootmodulekey ) ; <nl> - <nl> - / / all at once , using ` env . getvalues ` . <nl> while ( ! unexpanded . isempty ( ) ) { <nl> - module module = depgraph . get ( unexpanded . remove ( ) ) ; <nl> - for ( modulekey depkey : module . getdeps ( ) . values ( ) ) { <nl> - if ( depgraph . containskey ( depkey ) ) { <nl> - continue ; <nl> + set < skykey > unexpandedskykeys = new hashset < > ( ) ; <nl> + while ( ! unexpanded . isempty ( ) ) { <nl> + module module = depgraph . get ( unexpanded . remove ( ) ) ; <nl> + for ( modulekey depkey : module . getdeps ( ) . values ( ) ) { <nl> + if ( depgraph . containskey ( depkey ) ) { <nl> + continue ; <nl> + } <nl> + unexpandedskykeys . add ( modulefilevalue . key ( depkey , overrides . get ( depkey . getname ( ) ) ) ) ; <nl> } <nl> - modulefilevalue dep = <nl> - ( modulefilevalue ) <nl> - env . getvalue ( modulefilevalue . key ( depkey , overrides . get ( depkey . getname ( ) ) ) ) ; <nl> - if ( dep = = null ) { <nl> + } <nl> + map < skykey , skyvalue > result = env . getvalues ( unexpandedskykeys ) ; <nl> + for ( map . entry < skykey , skyvalue > entry : result . entryset ( ) ) { <nl> + modulekey depkey = ( ( modulefilevalue . key ) entry . getkey ( ) ) . getmodulekey ( ) ; <nl> + modulefilevalue modulefilevalue = ( modulefilevalue ) entry . getvalue ( ) ; <nl> + if ( modulefilevalue = = null ) { <nl> / / don ' t return yet . try to expand any other unexpanded nodes before returning . <nl> depgraph . put ( depkey , null ) ; <nl> } else { <nl> - depgraph . put ( depkey , rewritedepkeys ( dep . getmodule ( ) , overrides , rootmodulekey . getname ( ) ) ) ; <nl> + depgraph . put ( <nl> + depkey , <nl> + rewritedepkeys ( modulefilevalue . getmodule ( ) , overrides , rootmodulekey . getname ( ) ) ) ; <nl> unexpanded . add ( depkey ) ; <nl> } <nl> } <nl> mmm a / src / main / java / com / google / devtools / build / lib / bazel / bzlmod / modulefilevalue . java <nl> ppp b / src / main / java / com / google / devtools / build / lib / bazel / bzlmod / modulefilevalue . java <nl>
public class androidconfiguration extends fragment implements androidconfigurati <nl> help = " tracking flag for when busybox workers are enabled . " ) <nl> public boolean persistentbusyboxtools ; <nl>  <nl> - <nl> @ option ( <nl> name = " incompatible_prohibit_aapt1 " , <nl> documentationcategory = optiondocumentationcategory . toolchain , <nl> - effecttags = { optioneffecttag . loses_incremental_state , optioneffecttag . affects_outputs } , <nl> + effecttags = { optioneffecttag . no_op } , <nl> metadatatags = { <nl> optionmetadatatag . incompatible_change , <nl> optionmetadatatag . triggered_by_all_incompatible_changes <nl> } , <nl> defaultvalue = " true " , <nl> - help = <nl> - " end support for aapt in android rules . " <nl> - + " to resolve issues when migrating your app to build with aapt2 , see " <nl> - + " https : / / developer . android . com / studio / command - line / aapt2 # aapt2_changes " ) <nl> - public boolean incompatibleprohibitaapt1 ; <nl> + help = " deprecated no - op . " ) <nl> + public boolean unusedincompatibleprohibitaapt1 ; <nl>  <nl> @ option ( <nl> name = " experimental_remove_r_classes_from_instrumentation_test_jar " , <nl>
public class objccommandlineoptions extends fragmentoptions { <nl> ) <nl> public boolean devicedebugentitlements ; <nl>  <nl> - <nl> - @ option ( <nl> - name = " enable_apple_binary_native_protos " , <nl> - defaultvalue = " false " , <nl> - documentationcategory = optiondocumentationcategory . undocumented , <nl> - effecttags = { optioneffecttag . no_op } , <nl> - metadatatags = { optionmetadatatag . deprecated } , <nl> - help = " this flag is a no - op and will soon be deleted . " ) <nl> - public boolean enableapplebinarynativeprotos ; <nl> - <nl> @ option ( <nl> name = " apple_sdk " , <nl> defaultvalue = " null " ,
message setvalue { <nl> / / whether to allow this policy to be overridden by user - specified values . <nl> / / when set , if the user specified a value for this flag , use the value <nl> / / from the user , otherwise use the value specified in this policy . <nl> - / / this value is redundant to behavior - - please keep it in sync with it . <nl> optional bool overridable = num ; <nl>  <nl> / / if true , and if the flag named in the policy is a repeatable flag , then <nl> / / the values listed in flag_value do not replace all the user - set or default <nl> / / values of the flag , but instead append to them . if the flag is not <nl> / / repeatable , then this has no effect . <nl> - / / this value is redundant to behavior - - please keep it in sync with it . <nl> optional bool append = num ; <nl> - <nl> - enum behavior { <nl> - undefined = num ; <nl> - / / change the flag value but allow it to be overridden by explicit settings <nl> - / / from command line / config expansion / rc files . <nl> - / / matching old flag values : append = false , overridable = true . <nl> - allow_overrides = num ; <nl> - / / append a new value for a repeatable flag , leave old values and allow <nl> - / / further overrides . <nl> - / / matching old flag values : append = true , overridable = false . <nl> - append = num ; <nl> - / / set a final value of the flag . any overrides provided by the user for <nl> - / / this flag will be ignored . <nl> - / / matching old flag values : append = false , overridable = false . <nl> - final_value_ignore_overrides = num ; <nl> - } <nl> - <nl> - / / defines how invocation policy should interact with user settings for the <nl> - / / same flag . <nl> - / / for the time being , it coexists with overridable and append with duplicate <nl> - / / semantics . please fill both of the values as we migrate to use behavior <nl> - / / only . <nl> - <nl> - / / favor of this one . <nl> - optional behavior behavior = num ; <nl> } <nl>  <nl> message usedefault {
public final class cctoolchainprovider extends nativeinfo <nl> return targetsystemname . substring ( 0 , targetsystemname . indexof ( ' - ' ) ) ; <nl> } <nl>  <nl> - public final boolean isllvmcompiler ( ) { <nl> - <nl> - / / is temporary until the crosstool configuration is modified to add fields that <nl> - / / indicate which flavor of fdo is being used . <nl> - return toolchainidentifier . contains ( " llvm " ) ; <nl> - } <nl> - <nl> / / not all of cctoolchainprovider is exposed to starlark , which makes implementing deep equality <nl> / / impossible : if java - only parts are considered , the behavior is surprising in starlark , if they <nl> / / are not , the behavior is surprising in java . thus , object identity it is . <nl> mmm a / src / test / java / com / google / devtools / build / lib / packages / util / crosstool . java <nl> ppp b / src / test / java / com / google / devtools / build / lib / packages / util / crosstool . java <nl>
sh_test ( <nl> " : test - deps " , <nl> " / / src / test / java / com / google / devtools / build / lib / worker : exampleworker_deploy . jar " , <nl> ] , <nl> - # <nl> - flaky = num , <nl> shard_count = num , <nl> tags = [ <nl> " no_windows " , <nl> mmm a / src / test / shell / integration / bazel_worker_multiplexer_test . sh <nl> ppp b / src / test / shell / integration / bazel_worker_multiplexer_test . sh <nl>
md5_cmd = " set - e - o pipefail & & % s $ ( srcs ) | % s | % s > $ @ " <nl> [ genrule ( <nl> name = " install_base_key - file " + suffix , <nl> srcs = [ <nl> + # ensure we haven ' t forgotten any package - zip items , <nl> + # otherwise bazel won ' t correctly reextract modified files . <nl> " / / src / main / java / com / google / devtools / build / lib / bazel : bazelserver_deploy . jar " , <nl> " / / src / main / java / net / starlark / java / eval : cpu_profiler " , <nl> - # <nl> - # otherwise bazel won ' t correctly reextract modified files . <nl> " / / src / main / cpp : client " , <nl> " / / src / main / tools : build - runfiles " , <nl> " / / src / main / tools : process - wrapper " , <nl> " / / src / main / tools : linux - sandbox " , <nl> " / / tools / osx : xcode - locator " , <nl> - ] + embedded_tools_target , <nl> + " : platforms_archive " , <nl> + ] + select ( { <nl> + " / / src / conditions : windows " : [ ] , <nl> + " / / conditions : default " : [ <nl> + " / / src / main / tools : daemonize " , <nl> + ] , <nl> + } ) + embedded_tools_target , <nl> outs = [ " install_base_key " + suffix ] , <nl> cmd = select ( { <nl> " / / src / conditions : darwin " : md5_cmd % ( " / sbin / md5 " , " / sbin / md5 " , " head - c num " ) , <nl>
public abstract class starlarktoolchaincontext implements toolchaincontextapi { <nl> new toolchaincontextapi ( ) { <nl> @ override <nl> public object getindex ( <nl> - starlarkthread starlarkthread , starlarksemantics semantics , object key ) { <nl> - <nl> - return starlark . none ; <nl> + starlarkthread starlarkthread , starlarksemantics semantics , object key ) <nl> + throws evalexception { <nl> + throw starlark . errorf ( " toolchains are not valid in this context " ) ; <nl> } <nl>  <nl> @ override <nl> mmm a / src / test / java / com / google / devtools / build / lib / starlark / starlarkrulecontexttest . java <nl> ppp b / src / test / java / com / google / devtools / build / lib / starlark / starlarkrulecontexttest . java <nl>
public class predefinedattributes { <nl> * list of common ( implicitly added to all rules ) attributes documentation , relative to { @ link <nl> * com . google . devtools . build . docgen } . <nl> * / <nl> - <nl> public static final immutablelist < string > common_attributes_docfiles = <nl> immutablelist . of ( <nl> " templates / attributes / common / compatible_with . html " ,
public final class crash { <nl> * creates a crash caused by the given { @ link throwable } . <nl> * <nl> * < p > the exit code is generated by { @ link crashfailuredetails # detailedexitcodeforthrowable } . <nl> + * notably , this results in a failure detail with either { @ link <nl> + * com . google . devtools . build . lib . server . failuredetails . crash . code # crash_oom } or { @ link <nl> + * com . google . devtools . build . lib . server . failuredetails . crash . code # crash_unknown } . crashes that <nl> + * deserve special handling should use { @ link # from ( throwable , detailedexitcode ) } so that they can <nl> + * specify a custom { @ link detailedexitcode } . <nl> * / <nl> public static crash from ( throwable throwable ) { <nl> return new crash ( throwable , crashfailuredetails . detailedexitcodeforthrowable ( throwable ) ) ; <nl> } <nl>  <nl> - / * * creates a crash caused by the given { @ link throwable } with a specified { @ link exitcode } . * / <nl> - <nl> - / / exitcode , crashes are assigned the generic crash_unknown . <nl> - public static crash from ( throwable throwable , exitcode exitcode ) { <nl> - return new crash ( <nl> - throwable , detailedexitcode . of ( exitcode , crashfailuredetails . forthrowable ( throwable ) ) ) ; <nl> - } <nl> - <nl> / * * <nl> * creates a crash caused by the given { @ link throwable } with a specified { @ link <nl> * detailedexitcode } .
public class compilationsupport { <nl> cppconfiguration cppconfiguration = rulecontext . getfragment ( cppconfiguration . class ) ; <nl> activatedcrosstoolselectables . addall ( cccommon . getcoveragefeatures ( cppconfiguration ) ) ; <nl>  <nl> - immutableset . builder < string > disablefeatures = immutableset . < string > builder ( ) ; <nl> - <nl> - if ( disableparseheaders | | ! cctoolchain . supportsheaderparsing ( ) ) { <nl> - disablefeatures . add ( cppruleclasses . parse_headers ) ; <nl> + immutableset . builder < string > disabledfeatures = immutableset . < string > builder ( ) ; <nl> + disabledfeatures . addall ( rulecontext . getdisabledfeatures ( ) ) ; <nl> + if ( disableparseheaders ) { <nl> + disabledfeatures . add ( cppruleclasses . parse_headers ) ; <nl> } <nl> if ( disablelayeringcheck ) { <nl> - disablefeatures . add ( cppruleclasses . layering_check ) ; <nl> + disabledfeatures . add ( cppruleclasses . layering_check ) ; <nl> } <nl> if ( forswiftmodulemap ) { <nl> activatedcrosstoolselectables <nl>
public class uioptions extends optionsbase { <nl>  <nl> @ option ( <nl> name = " isatty " , <nl> - <nl> - / / reasonable . <nl> - oldname = " is_stderr_atty " , <nl> defaultvalue = " false " , <nl> metadatatags = { optionmetadatatag . hidden } , <nl> documentationcategory = optiondocumentationcategory . undocumented ,
public class javastarlarkapitest extends buildviewtestcase { <nl> " jrule = rule ( _impl , attrs = { ' _java_runtime ' : attr . label ( default = label ( ' / / a : alias ' ) ) } ) " ) ; <nl>  <nl> useconfiguration ( " - - extra_toolchains = / / a : all " , " - - platforms = / / a : platform " ) ; <nl> - <nl> - configuredtarget genrule = gethostconfiguredtarget ( " / / a : gen " ) ; <nl> + configuredtarget genrule = getconfiguredtarget ( " / / a : gen " ) ; <nl> configuredtarget ct = getconfiguredtarget ( " / / a : r " ) ; <nl> structimpl myinfo = getmyinfofromtarget ( ct ) ; <nl> string javahomeexecpath = ( string ) myinfo . getvalue ( " java_home_exec_path " ) ; <nl> mmm a / tools / jdk / java_toolchain_alias . bzl <nl> ppp b / tools / jdk / java_toolchain_alias . bzl <nl>
public final class javainfo extends nativeinfo implements javainfoapi < artifact > <nl> return this ; <nl> } <nl>  <nl> - public builder maybetransitiveonlyruntimejarstojavainfo ( <nl> - list < ? extends transitiveinfocollection > deps , boolean shouldadd ) { <nl> - <nl> - / / to make - - trim_test_configuration work again . <nl> - if ( shouldadd ) { <nl> - deps . stream ( ) <nl> - . map ( javainfo : : getjavainfo ) <nl> - . filter ( objects : : nonnull ) <nl> - . map ( j - > j . getprovider ( javacompilationargsprovider . class ) ) <nl> - . filter ( objects : : nonnull ) <nl> - . map ( javacompilationargsprovider : : getruntimejars ) <nl> - . foreach ( this : : addtransitiveonlyruntimejars ) ; <nl> - } <nl> + public builder addtransitiveonlyruntimejars ( list < ? extends transitiveinfocollection > deps ) { <nl> + deps . stream ( ) <nl> + . map ( javainfo : : getjavainfo ) <nl> + . filter ( objects : : nonnull ) <nl> + . map ( j - > j . getprovider ( javacompilationargsprovider . class ) ) <nl> + . filter ( objects : : nonnull ) <nl> + . map ( javacompilationargsprovider : : getruntimejars ) <nl> + . foreach ( this : : addtransitiveonlyruntimejars ) ; <nl> return this ; <nl> } <nl>  <nl> mmm a / src / main / java / com / google / devtools / build / lib / rules / java / javalibrary . java <nl> ppp b / src / main / java / com / google / devtools / build / lib / rules / java / javalibrary . java <nl>
load ( " @ bazel_tools / / tools / build_defs / repo : http . bzl " , " http_archive " ) <nl> eof <nl> } <nl>  <nl> - # <nl> - # from / / workspace <nl> - function add_rules_pkg_to_workspace ( ) { <nl> - cat > > " $ 1 " < < eof <nl> - load ( " @ bazel_tools / / tools / build_defs / repo : http . bzl " , " http_archive " ) <nl> - <nl> - http_archive ( <nl> - name = " rules_pkg " , <nl> - sha256 = " <commit_id> " , <nl> - urls = [ <nl> - " https : / / mirror . bazel . build / github . com / bazelbuild / rules_pkg / rules_pkg - 0 . 2 . 0 . tar . gz " , <nl> - " https : / / github . com / bazelbuild / rules_pkg / releases / download / 0 . 2 . 0 / rules_pkg - 0 . 2 . 0 . tar . gz " , <nl> - ] , <nl> - ) <nl> - eof <nl> - } <nl> - <nl> function add_rules_proto_to_workspace ( ) { <nl> cat > > " $ 1 " < < eof <nl> load ( " @ bazel_tools / / tools / build_defs / repo : http . bzl " , " http_archive " ) <nl>
def _find_linker_path ( repository_ctx , cc , linker ) : <nl> if result . return_code ! = num : <nl> return none <nl>  <nl> + if not is_clang : <nl> + return linker <nl> + <nl> for line in result . stderr . splitlines ( ) : <nl> if line . find ( linker ) = = - 1 : <nl> continue <nl> for flag in line . split ( " " ) : <nl> if flag . find ( linker ) = = - 1 : <nl> continue <nl> - if flag . find ( " - - enable - " + linker ) > - 1 or flag . find ( " - - with - plugin - ld " ) > - 1 : <nl> - # skip build configuration options of gcc itself <nl> - # <nl> - continue <nl> - <nl> - # flag is ' - fuse - ld = gold ' for gcc or " / usr / lib / ld . gold " for clang <nl> - # strip space , single quote , and double quotes <nl> - flag = flag . strip ( " \ " ' " ) <nl>  <nl> - # remove - fuse - ld = from gcc output so we have only the flag value part <nl> - flag = flag . replace ( " - fuse - ld = " , " " ) <nl> - return flag <nl> + # flag looks like " / usr / lib / ld . gold " . <nl> + return flag . strip ( " \ " ' " ) <nl> auto_configure_warning ( <nl> " cc with - fuse - ld = " + linker + " returned num , but its - v output " + <nl> " didn ' t contain ' " + linker + " ' , falling back to the default linker . " , <nl>
public final class evaluationtest { <nl> " foo1 " ) ) ; <nl> } <nl>  <nl> - <nl> + @ test <nl> + public void testloadsbindlocally ( ) throws exception { <nl> + module a = module . create ( ) ; <nl> + starlark . execfile ( <nl> + parserinput . fromstring ( " x = num " , " a . bzl " ) , <nl> + fileoptions . default , <nl> + a , <nl> + new starlarkthread ( mutability . create ( ) , starlarksemantics . default ) ) ; <nl> + <nl> + starlarkthread bthread = new starlarkthread ( mutability . create ( ) , starlarksemantics . default ) ; <nl> + bthread . setloader ( <nl> + module - > { <nl> + assertthat ( module ) . isequalto ( " a . bzl " ) ; <nl> + return a ; <nl> + } ) ; <nl> + module b = module . create ( ) ; <nl> + starlark . execfile ( <nl> + parserinput . fromstring ( " load ( ' a . bzl ' , ' x ' ) " , " b . bzl " ) , fileoptions . default , b , bthread ) ; <nl> + <nl> + starlarkthread cthread = new starlarkthread ( mutability . create ( ) , starlarksemantics . default ) ; <nl> + cthread . setloader ( <nl> + module - > { <nl> + assertthat ( module ) . isequalto ( " b . bzl " ) ; <nl> + return b ; <nl> + } ) ; <nl> + evalexception ex = <nl> + assertthrows ( <nl> + evalexception . class , <nl> + ( ) - > <nl> + starlark . execfile ( <nl> + parserinput . fromstring ( " load ( ' b . bzl ' , ' x ' ) " , " c . bzl " ) , <nl> + fileoptions . default , <nl> + module . create ( ) , <nl> + cthread ) ) ; <nl> + assertthat ( ex ) . hasmessagethat ( ) . contains ( " file ' b . bzl ' does not contain symbol ' x ' " ) ; <nl> + } <nl>  <nl> @ test <nl> public void testtoplevelrebinding ( ) throws exception {
function test_java_tools_has_jacocoagent ( ) { <nl> expect_path_in_java_tools " third_party / asm / asm - 8 . 0 - sources . jar " <nl> } <nl>  <nl> - # <nl> function test_java_tools_has_proguard ( ) { <nl> expect_path_in_java_tools " third_party / java / proguard " <nl> - expect_path_in_java_tools " third_party / java / proguard / proguard . * " <nl> - expect_path_in_java_tools " third_party / java / proguard / proguard . * / bin " <nl> - expect_path_in_java_tools " third_party / java / proguard / proguard . * / buildscripts " <nl> - expect_path_in_java_tools " third_party / java / proguard / proguard . * / src " <nl> - expect_path_in_java_tools " third_party / java / proguard / proguard . * / src / proguard " <nl> + expect_path_in_java_tools " third_party / java / proguard / proguard6 . 2 . 2 " <nl> + expect_path_in_java_tools " third_party / java / proguard / proguard6 . 2 . 2 / bin " <nl> + expect_path_in_java_tools " third_party / java / proguard / proguard6 . 2 . 2 / buildscripts " <nl> + expect_path_in_java_tools " third_party / java / proguard / proguard6 . 2 . 2 / src " <nl> + expect_path_in_java_tools " third_party / java / proguard / proguard6 . 2 . 2 / src / proguard " <nl> } <nl>  <nl> run_suite " java tools archive tests " <nl> mmm a / src / test / shell / bazel / bazel_java_tools_test . sh <nl> ppp b / src / test / shell / bazel / bazel_java_tools_test . sh <nl>
function test_java_tools_has_jacocoagent ( ) { <nl> expect_path_in_java_tools " java_tools / third_party / java / jacoco / license " <nl> } <nl>  <nl> - # <nl> function test_java_tools_has_proguard ( ) { <nl> expect_path_in_java_tools " java_tools / third_party / java / proguard / proguard . jar " <nl> - expect_path_in_java_tools " java_tools / third_party / java / proguard / gpl . * " <nl> + expect_path_in_java_tools " java_tools / third_party / java / proguard / gpl . md " <nl> } <nl>  <nl> function test_java_tools_toolchain_builds ( ) {
message aborted { <nl> / / set to false causing the build be ended upon failure ) . <nl> incomplete = num ; <nl>  <nl> - / / the build tool ran out of memory and crashed . not yet used . ooms are <nl> - / / currently reported as internal . <nl> - <nl> out_of_memory = num ; <nl> } <nl> abortreason reason = num ;
eof <nl> bazel build - - experimental_genquery_use_graphless_query \ <nl> / / foo : q | | fail " expected success " <nl>  <nl> - # <nl> - # query currently requires the - - incompatible_prefer_unordered_output flag to <nl> - # switch to graphless . <nl> - # in addition , - - incompatible_use_lexicographical_unordered_output is used to <nl> - # switch sort the graphless output in lexicographical order . <nl> - bazel query - - incompatible_prefer_unordered_output \ <nl> - - - incompatible_use_lexicographical_unordered_output \ <nl> + # the - - incompatible_use_lexicographical_unordered_output flag is used to <nl> + # switch order_output = auto to use graphless query and output in <nl> + # lexicographical order . <nl> + bazel query - - incompatible_use_lexicographical_unordered_output \ <nl> " deps ( / / foo : b ) " | grep foo > & foo / query_output | | fail " expected success " <nl>  <nl> # the outputs of graphless query and graphless genquery should be the same .
public class legacyincludescanner implements includescanner { <nl> checkforinterrupt ( " processing " , source ) ; <nl>  <nl> collection < inclusion > inclusions ; <nl> - try { <nl> - inclusions = <nl> - fileparsecache <nl> - . computeifabsent ( <nl> - source , <nl> - file - > { <nl> - try { <nl> - return futures . immediatefuture ( <nl> - parser . extractinclusions ( <nl> - file , <nl> - actionexecutionmetadata , <nl> - actionexecutioncontext , <nl> - grepincludes , <nl> - spawnincludescannersupplier . get ( ) , <nl> - isrealoutputfile ( source . getexecpath ( ) ) ) ) ; <nl> - } catch ( ioexception e ) { <nl> - throw new ioruntimeexception ( e ) ; <nl> - } catch ( execexception e ) { <nl> - throw new execruntimeexception ( e ) ; <nl> - } catch ( interruptedexception e ) { <nl> - throw new interruptedruntimeexception ( e ) ; <nl> - } <nl> - } ) <nl> - . get ( ) ; <nl> - } catch ( executionexception ee ) { <nl> + settablefuture < collection < inclusion > > future = settablefuture . create ( ) ; <nl> + future < collection < inclusion > > previous = fileparsecache . putifabsent ( source , future ) ; <nl> + if ( previous = = null ) { <nl> + previous = future ; <nl> try { <nl> - throwables . throwifinstanceof ( ee . getcause ( ) , runtimeexception . class ) ; <nl> - throw new illegalstateexception ( ee . getcause ( ) ) ; <nl> - } catch ( ioruntimeexception e ) { <nl> - throw e . getcauseioexception ( ) ; <nl> - } catch ( execruntimeexception e ) { <nl> - throw e . getrealcause ( ) ; <nl> - } catch ( interruptedruntimeexception e ) { <nl> - throw e . getrealcause ( ) ; <nl> + future . set ( <nl> + parser . extractinclusions ( <nl> + source , <nl> + actionexecutionmetadata , <nl> + actionexecutioncontext , <nl> + grepincludes , <nl> + spawnincludescannersupplier . get ( ) , <nl> + isrealoutputfile ( source . getexecpath ( ) ) ) ) ; <nl> + } catch ( throwable t ) { <nl> + future . setexception ( t ) ; <nl> + fileparsecache . remove ( source ) ; <nl> + throw t ; <nl> } <nl> - } catch ( runtimeexception e ) { <nl> - <nl> - logger . atsevere ( ) . withcause ( e ) . log ( " uncaught exception in call to extractinclusions " ) ; <nl> - throw e ; <nl> + } <nl> + try { <nl> + inclusions = previous . get ( ) ; <nl> + } catch ( executionexception e ) { <nl> + throwables . propagateifpossible ( e . getcause ( ) , ioexception . class , interruptedexception . class ) ; <nl> + throwables . throwifinstanceof ( e . getcause ( ) , execexception . class ) ; <nl> + throw new illegalstateexception ( e . getcause ( ) ) ; <nl> } <nl> preconditions . checknotnull ( inclusions , source ) ;
bootclasspath ( <nl> target_javabase = " current_java_runtime " , <nl> ) <nl>  <nl> - default_java_toolchain ( <nl> - name = " toolchain_hostjdk8 " , <nl> - configuration = jvm8_toolchain_configuration , <nl> - source_version = " 8 " , <nl> - target_version = " 8 " , <nl> - ) <nl> - <nl> - # default to the java num language level . <nl> - # <nl> - default_java_toolchain ( <nl> - name = " legacy_toolchain " , <nl> - configuration = default_toolchain_configuration , <nl> - source_version = " 8 " , <nl> - target_version = " 8 " , <nl> - ) <nl> - <nl> default_java_toolchain ( <nl> name = " toolchain " , <nl> configuration = default_toolchain_configuration , <nl>
public final class resolver extends nodevisitor { <nl>  <nl> if ( b . parent ! = null ) { <nl> bind = lookuplexical ( name , b . parent ) ; <nl> - <nl> - / / if a local binding was found in a parent block , <nl> - / / and this block is a function , then it is a free variable <nl> - / / of this function and must be plumbed through . <nl> - / / add an implicit free binding ( a hidden parameter ) to this function , <nl> - / / and record the outer binding that will supply its value when <nl> - / / we construct the closure . <nl> - / / also , mark the outer local as a cell : a shared , indirect local . <nl> - / / ( for a comprehension block there ' s nothing to do , <nl> - / / because it ' s part of the same frame as the enclosing block . ) <nl> - / / <nl> - / / this step may occur many times if the lookuplexical <nl> - / / recursion returns through many functions . <nl> - <nl> - if ( bind ! = null <nl> - & & ( b . syntax instanceof defstatement | | b . syntax instanceof lambdaexpression ) ) { <nl> - scope scope = bind . getscope ( ) ; <nl> - if ( scope = = scope . local | | scope = = scope . free | | scope = = scope . cell ) { <nl> - if ( scope = = scope . local ) { <nl> - bind . scope = scope . cell ; <nl> + if ( bind ! = null ) { <nl> + / / if a local binding was found in a parent block , <nl> + / / and this block is a function , then it is a free variable <nl> + / / of this function and must be plumbed through . <nl> + / / add an implicit free binding ( a hidden parameter ) to this function , <nl> + / / and record the outer binding that will supply its value when <nl> + / / we construct the closure . <nl> + / / also , mark the outer local as a cell : a shared , indirect local . <nl> + / / ( for a comprehension block there ' s nothing to do , <nl> + / / because it ' s part of the same frame as the enclosing block . ) <nl> + / / <nl> + / / this step may occur many times if the lookuplexical <nl> + / / recursion returns through many functions . <nl> + if ( b . syntax instanceof defstatement | | b . syntax instanceof lambdaexpression ) { <nl> + scope scope = bind . getscope ( ) ; <nl> + if ( scope = = scope . local | | scope = = scope . free | | scope = = scope . cell ) { <nl> + if ( scope = = scope . local ) { <nl> + bind . scope = scope . cell ; <nl> + } <nl> + int <nl> + b . freevars . add ( bind ) ; <nl> + bind = new binding ( scope . free , index , bind . first ) ; <nl> } <nl> - int <nl> - b . freevars . add ( bind ) ; <nl> - bind = new binding ( scope . free , index , bind . first ) ; <nl> } <nl> - } <nl>  <nl> - / / memoize , to avoid duplicate free vars and repeated walks . <nl> - b . bindings . put ( name , bind ) ; <nl> + / / memoize , to avoid duplicate free vars and repeated walks . <nl> + b . bindings . put ( name , bind ) ; <nl> + } <nl> } <nl>  <nl> return bind ; <nl> mmm a / src / test / java / net / starlark / java / syntax / resolvertest . java <nl> ppp b / src / test / java / net / starlark / java / syntax / resolvertest . java <nl>
public final class javatoolchainrule < c extends javatoolchain > implements ruledef <nl> . add ( <nl> attr ( " java_runtime " , label ) <nl> . cfg ( executiontransitionfactory . create ( ) ) <nl> - <nl> - / / all toolchains <nl> - . value ( javasemantics . hostjdkattribute ( env ) ) <nl> + . mandatory ( ) <nl> . mandatoryproviders ( toolchaininfo . provider . id ( ) ) <nl> . allowedfiletypes ( filetypeset . any_file ) <nl> . useoutputlicenses ( ) ) <nl> mmm a / src / test / java / com / google / devtools / build / lib / analysis / mock / bazelanalysismock . java <nl> ppp b / src / test / java / com / google / devtools / build / lib / analysis / mock / bazelanalysismock . java <nl>
public class starlarkactionfactory implements starlarkactionfactoryapi { <nl> for ( runfilessupplier supplier : <nl> sequence . cast ( inputmanifestsunchecked , runfilessupplier . class , " runfiles suppliers " ) ) { <nl> builder . addrunfilessupplier ( supplier ) ; <nl> - / / normally these artifacts will be added directly to the inputs , but we ' re gentle if the <nl> - / / user fails to do so . unfortunately , because ctx . resolve_command currently flattens <nl> - <nl> - / / duplicate traversal / memory usage for this nested set if the user does add the inputs and <nl> - / / those inputs include the runfiles . <nl> - builder . addtransitiveinputs ( supplier . getartifacts ( ) ) ; <nl> } <nl> } <nl>  <nl> mmm a / src / test / shell / bazel / remote / remote_execution_test . sh <nl> ppp b / src / test / shell / bazel / remote / remote_execution_test . sh <nl>
public abstract class starlarkint implements starlarkvalue , comparable < starlarki <nl>  <nl> / / binary operators <nl>  <nl> - / / in the common case , both operands are int32 , so the operations <nl> - / / can be done using longs with minimal fuss around overflows . <nl> - / / all other combinations are promoted to biginteger . <nl> - <nl> - / / operands are int64 ; promote to big x big only upon overflow . <nl> - / / ( see the revision history for the necessary overflow checks . ) <nl> - <nl> - / * * returns a value whose signum is equal to x - y . * / <nl> + / * * returns signum ( x - y ) . * / <nl> public static int compare ( starlarkint x , starlarkint y ) { <nl> - if ( x instanceof int32 & & y instanceof int32 ) { <nl> - return integer . compare ( ( ( int32 ) x ) . v , ( ( int32 ) y ) . v ) ; <nl> - } <nl> - <nl> + / / if both arguments are big , we compare bigintegers . <nl> + / / if neither argument is big , we compare longs . <nl> + / / if only one argument is big , its magnitude is greater <nl> + / / than the other operand , so only its sign matters . <nl> + / / <nl> + / / we avoid unnecessary branches . <nl> try { <nl> - return long . compare ( x . tolongfast ( ) , y . tolongfast ( ) ) ; <nl> + long xl = x . tolongfast ( ) ; <nl> + try { <nl> + long yl = y . tolongfast ( ) ; <nl> + return long . compare ( xl , yl ) ; / / ( long , long ) <nl> + } catch ( overflow unused ) { <nl> + return - ( ( big ) y ) . v . signum ( ) ; / / ( long , big ) <nl> + } <nl> } catch ( overflow unused ) { <nl> - / * fall through * / <nl> + return y instanceof big <nl> + ? ( ( big ) x ) . v . compareto ( ( ( big ) y ) . v ) / / ( big , big ) <nl> + : ( ( big ) x ) . v . signum ( ) ; / / ( big , long ) <nl> } <nl> - <nl> - return x . tobiginteger ( ) . compareto ( y . tobiginteger ( ) ) ; <nl> } <nl>  <nl> / * * returns x + y . * /
public final class dict < k , v > <nl> named = true , <nl> doc = " a default value if the key is absent . " ) , <nl> } ) <nl> - @ suppresswarnings ( " unchecked " ) / / cast of value to v <nl> - public object setdefault ( k key , object defaultvalue ) throws evalexception { <nl> - <nl> - object value = get ( key ) ; <nl> - if ( value ! = null ) { <nl> - return value ; <nl> - } <nl> - putentry ( key , ( v ) defaultvalue ) ; <nl> - return defaultvalue ; <nl> + public v setdefault ( k key , v defaultvalue ) throws evalexception { <nl> + starlark . checkmutable ( this ) ; <nl> + starlark . checkhashable ( key ) ; <nl> + <nl> + v prev = contents . putifabsent ( key , defaultvalue ) ; / / see class doc comment <nl> + return prev ! = null ? prev : defaultvalue ; <nl> } <nl>  <nl> @ starlarkmethod ( <nl> mmm a / src / test / java / net / starlark / java / eval / testdata / dict . star <nl> ppp b / src / test / java / net / starlark / java / eval / testdata / dict . star <nl>
function test_java_tools_has_build ( ) { <nl> expect_path_in_java_tools " build " <nl> } <nl>  <nl> - # <nl> - function disable_java_tools_has_jacocoagent ( ) { <nl> + function test_java_tools_has_jacocoagent ( ) { <nl> expect_path_in_java_tools " java_tools / third_party / java / jacoco / jacocoagent - 0 . 8 . 3 . jar " <nl> expect_path_in_java_tools " java_tools / third_party / java / jacoco / org . jacoco . agent - 0 . 8 . 3 . jar " <nl> expect_path_in_java_tools " java_tools / third_party / java / jacoco / org . jacoco . core - 0 . 8 . 3 . jar " <nl>
function disable_java_tools_has_jacocoagent ( ) { <nl> expect_path_in_java_tools " java_tools / third_party / java / jacoco / license " <nl> } <nl>  <nl> - # <nl> - function disable_java_tools_has_proguard ( ) { <nl> + function test_java_tools_has_proguard ( ) { <nl> expect_path_in_java_tools " java_tools / third_party / java / proguard / proguard . jar " <nl> expect_path_in_java_tools " java_tools / third_party / java / proguard / gpl . html " <nl> }
public class javabinary implements ruleconfiguredtargetfactory { <nl> rulecontext . checksrcssamepackage ( true ) ; <nl> boolean createexecutable = rulecontext . attributes ( ) . get ( " create_executable " , type . boolean ) ; <nl>  <nl> - if ( ! createexecutable ) { <nl> - <nl> - / / and use isattributeexplicitlyspecified here <nl> - label launcherattribute = rulecontext . attributes ( ) . get ( " launcher " , buildtype . label ) ; <nl> - if ( launcherattribute ! = null & & ! javahelper . isjdklauncher ( rulecontext , launcherattribute ) ) { <nl> - rulecontext . ruleerror ( " launcher specified but create_executable is false " ) ; <nl> - } <nl> + if ( ! createexecutable <nl> + & & rulecontext . attributes ( ) . isattributevalueexplicitlyspecified ( " launcher " ) ) { <nl> + rulecontext . ruleerror ( " launcher specified but create_executable is false " ) ; <nl> } <nl>  <nl> if ( ! rulecontext . attributes ( ) . get ( " use_launcher " , type . boolean ) <nl> mmm a / src / main / java / com / google / devtools / build / lib / rules / java / javahelper . java <nl> ppp b / src / main / java / com / google / devtools / build / lib / rules / java / javahelper . java <nl>
class main { <nl> system . err . println ( " welcome to starlark ( java . starlark . net ) " ) ; <nl> string line ; <nl>  <nl> - <nl> - / / go . starlark . net repls . this requires a new grammar production , and <nl> - / / integration with the lexer so that it consumes new <nl> - / / lines only until the parse is complete . <nl> - <nl> while ( ( line = prompt ( ) ) ! = null ) { <nl> parserinput input = parserinput . fromstring ( line , " < stdin > " ) ; <nl> try {
public final class tuple extends abstractlist < object > <nl>  <nl> / * * returns a tuple that is the concatenation of two tuples . * / <nl> public static tuple concat ( tuple x , tuple y ) { <nl> - <nl> - return wrap ( objectarrays . concat ( x . elems , y . elems , object . class ) ) ; <nl> + if ( x . isempty ( ) ) { <nl> + return y ; <nl> + } else if ( y . isempty ( ) ) { <nl> + return x ; <nl> + } else { <nl> + return wrap ( objectarrays . concat ( x . elems , y . elems , object . class ) ) ; <nl> + } <nl> } <nl>  <nl> @ override <nl> mmm / dev / null <nl> ppp b / src / test / java / net / starlark / java / eval / testdata / tuple . star <nl>
alias ( <nl> actual = " @ local_jdk / / : bootclasspath " , <nl> ) <nl>  <nl> - alias ( <nl> - name = " extclasspath " , <nl> - actual = " @ local_jdk / / : extdir " , <nl> - ) <nl> - <nl> - # <nl> - alias ( <nl> - name = " extdir " , <nl> - actual = " @ local_jdk / / : extdir " , <nl> - ) <nl> - <nl> filegroup ( <nl> name = " langtools " , <nl> srcs = [ " / / third_party / java / jdk / langtools : javac_jar " ] , <nl> mmm a / tools / jdk / jdk . build <nl> ppp b / tools / jdk / jdk . build <nl>
filegroup ( <nl> deprecation = deprecation_message , <nl> ) <nl>  <nl> - # <nl> - filegroup ( <nl> - name = " extdir " , <nl> - srcs = glob ( <nl> - [ " jre / lib / ext / * . jar " ] , <nl> - allow_empty = true , <nl> - ) , <nl> - deprecation = deprecation_message , <nl> - ) <nl> - <nl> - filegroup ( <nl> - name = " extclasspath " , <nl> - srcs = glob ( <nl> - [ " jre / lib / ext / * . jar " ] , <nl> - allow_empty = true , <nl> - ) , <nl> - deprecation = deprecation_message , <nl> - ) <nl> - <nl> filegroup ( <nl> name = " jre - bin " , <nl> srcs = select ( {
public class genclassoptionsparser { <nl> case " - - output_jar " : <nl> builder . setoutputjar ( readpath ( it ) ) ; <nl> break ; <nl> - case " - - temp_dir " : <nl> - <nl> - readpath ( it ) ; <nl> - break ; <nl> default : <nl> throw new illegalargumentexception ( <nl> string . format ( " unexpected argument : ' % s ' in % s " , arg , args ) ) ;
eof <nl> expect_log ' option_value : " 666 " ' <nl> } <nl>  <nl> - # <nl> - function disabled_test_empty_tree_in_named_files ( ) { <nl> + function test_empty_tree_in_named_files ( ) { <nl> mkdir - p foo <nl> cat > foo / rule . bzl < < ' eof ' <nl> def _leaf_impl ( ctx ) :
public class genclassoptionsparser { <nl> case " - - output_jar " : <nl> builder . setoutputjar ( readpath ( it ) ) ; <nl> break ; <nl> - case " - - temp_dir " : <nl> - <nl> - readpath ( it ) ; <nl> - break ; <nl> default : <nl> throw new illegalargumentexception ( <nl> string . format ( " unexpected argument : ' % s ' in % s " , arg , args ) ) ;
<nl> - / / copyright num the bazel authors . all rights reserved . <nl> - / / <nl> - / / licensed under the apache license , version num . 0 ( the " license " ) ; <nl> - / / you may not use this file except in compliance with the license . <nl> - / / you may obtain a copy of the license at <nl> - / / <nl> - / / http : / / www . apache . org / licenses / license - 2 . 0 <nl> - / / <nl> - / / unless required by applicable law or agreed to in writing , software <nl> - / / distributed under the license is distributed on an " as is " basis , <nl> - / / without warranties or conditions of any kind , either express or implied . <nl> - / / see the license for the specific language governing permissions and <nl> - / / limitations under the license . <nl> - package net . starlark . java . eval ; <nl> - <nl> - import org . junit . test ; <nl> - import org . junit . runner . runwith ; <nl> - import org . junit . runners . junit4 ; <nl> - <nl> - / * * tests for stringmodule . * / <nl> - <nl> - @ runwith ( junit4 . class ) <nl> - public class stringmoduletest { <nl> - <nl> - private final evaluationtestcase ev = new evaluationtestcase ( ) ; <nl> - <nl> - @ test <nl> - public void testreplace ( ) throws exception { <nl> - ev . new scenario ( ) <nl> - . testeval ( " ' banana ' . replace ( ' a ' , ' o ' ) " , " ' bonono ' " ) <nl> - . testeval ( " ' banana ' . replace ( ' a ' , ' o ' , num ) " , " ' bonona ' " ) <nl> - . testeval ( " ' banana ' . replace ( ' a ' , ' o ' , num ) " , " ' banana ' " ) <nl> - . testeval ( " ' banana ' . replace ( ' a ' , ' e ' ) " , " ' benene ' " ) <nl> - . testeval ( " ' banana ' . replace ( ' a ' , ' $ ( ) ' ) " , " ' b $ ( ) n $ ( ) n $ ( ) ' " ) <nl> - . testeval ( " ' banana ' . replace ( ' a ' , ' $ ' ) " , " ' b $ n $ n $ ' " ) <nl> - . testeval ( " ' b $ ( ) n $ ( ) n $ ( ) ' . replace ( ' $ ( ) ' , ' $ ( $ ( ) ) ' ) " , " ' b $ ( $ ( ) ) n $ ( $ ( ) ) n $ ( $ ( ) ) ' " ) <nl> - . testeval ( " ' banana ' . replace ( ' a ' , ' e ' , num ) " , " ' benena ' " ) <nl> - . testeval ( " ' banana ' . replace ( ' a ' , ' e ' , num ) " , " ' banana ' " ) <nl> - . testeval ( " ' banana ' . replace ( ' ' , ' - ' ) " , " ' - b - a - n - a - n - a - ' " ) <nl> - . testeval ( " ' banana ' . replace ( ' ' , ' - ' , num ) " , " ' - b - anana ' " ) <nl> - . testeval ( " ' banana ' . replace ( ' ' , ' - ' , num ) " , " ' banana ' " ) <nl> - . testeval ( " ' banana ' . replace ( ' ' , ' ' ) " , " ' banana ' " ) <nl> - . testeval ( " ' banana ' . replace ( ' a ' , ' ' ) " , " ' bnn ' " ) <nl> - . testeval ( " ' banana ' . replace ( ' a ' , ' ' , num ) " , " ' bnna ' " ) ; <nl> - <nl> - ev . new scenario ( ) <nl> - . testeval ( " ' banana ' . replace ( ' a ' , ' o ' , - 2 ) " , " ' bonono ' " ) <nl> - . testeval ( " ' banana ' . replace ( ' a ' , ' e ' , - 1 ) " , " ' benene ' " ) <nl> - . testeval ( " ' banana ' . replace ( ' a ' , ' e ' , - 10 ) " , " ' benene ' " ) <nl> - . testeval ( " ' banana ' . replace ( ' ' , ' - ' , - 2 ) " , " ' - b - a - n - a - n - a - ' " ) ; <nl> - <nl> - ev . new scenario ( ) <nl> - . testiferrorcontains ( <nl> - " parameter ' count ' got value of type ' nonetype ' , want ' int ' " , <nl> - " ' banana ' . replace ( ' a ' , ' e ' , none ) " ) ; <nl> - } <nl> - } <nl> mmm a / src / test / java / net / starlark / java / eval / testdata / string_misc . sky <nl> ppp b / src / test / java / net / starlark / java / eval / testdata / string_misc . sky <nl>
public class genclassoptionsparser { <nl> case " - - output_jar " : <nl> builder . setoutputjar ( readpath ( it ) ) ; <nl> break ; <nl> - case " - - temp_dir " : <nl> - <nl> - readpath ( it ) ; <nl> - break ; <nl> default : <nl> throw new illegalargumentexception ( <nl> string . format ( " unexpected argument : ' % s ' in % s " , arg , args ) ) ;
def _get_escaped_xcode_cxx_inc_directories ( repository_ctx , cc , xcode_toolchains ) <nl> include_paths : a list of builtin include paths . <nl> " " " <nl>  <nl> - # <nl> - # paths shouldn ' t be unnecessary once all actions are using xcrun . <nl> - include_dirs = get_escaped_cxx_inc_directories ( repository_ctx , cc , " - xc + + " ) <nl> + include_dirs = [ ] <nl> for toolchain in xcode_toolchains : <nl> include_dirs . append ( escape_string ( toolchain . developer_dir ) ) <nl>  <nl> mmm a / tools / cpp / unix_cc_configure . bzl <nl> ppp b / tools / cpp / unix_cc_configure . bzl <nl>
final class methoddescriptor { <nl> if ( method . getreturntype ( ) . equals ( void . type ) ) { <nl> return starlark . none ; <nl> } <nl> - if ( result = = null ) { <nl> - <nl> - / / string / integer / boolean / list / map , it seems obtuse to crash instead <nl> - / / of converting null too . <nl> - if ( isallowreturnnones ( ) ) { <nl> - return starlark . none ; <nl> - } else { <nl> - throw new illegalstateexception ( <nl> - " method invocation returned null : " + getname ( ) + tuple . copyof ( arrays . aslist ( args ) ) ) ; <nl> - } <nl> + if ( result = = null & & ! isallowreturnnones ( ) ) { <nl> + throw new illegalstateexception ( <nl> + " method invocation returned null : " + getname ( ) + tuple . copyof ( arrays . aslist ( args ) ) ) ; <nl> } <nl> - <nl> return starlark . fromjava ( result , mu ) ; <nl> }
<nl> package net . starlark . java . eval ; <nl>  <nl> import java . math . biginteger ; <nl> + import net . starlark . java . annot . starlarkbuiltin ; <nl>  <nl> / * * the starlark int data type . * / <nl> - / / no starlarkbuiltin ( name = " int " ) annotation because it would cause docgen <nl> - / / to complain that two things are called int ( the type and the function ) . <nl> - <nl> + @ starlarkbuiltin ( <nl> + name = " int " , <nl> + category = " core " , <nl> + doc = <nl> + " the type of integers in starlark . starlark integers may be of any magnitude ; arithmetic " <nl> + + " is exact . examples of integer expressions : < br > " <nl> + + " < pre class = \ " language - python \ " > 153\n " <nl> + + " 0x2a # hexadecimal literal\n " <nl> + + " 0o54 # octal literal\n " <nl> + + " 23 * num + num \n " <nl> + + " 100 / - 7\n " <nl> + + " 100 % - 7 # - 5 ( unlike in some other languages ) \n " <nl> + + " int ( \ " 18 \ " ) \n " <nl> + + " < / pre > " ) <nl> public abstract class starlarkint implements starlarkvalue , comparable < starlarkint > { <nl>  <nl> / / a cache of small integers > = least_smallint .
public final class scripttest { <nl>  <nl> } catch ( syntaxerror . exception ex ) { <nl> / / parser / resolver errors <nl> + / / <nl> + / / static errors cannot be suppressed by expectations : <nl> + / / it would be dangerous because the presence of a static <nl> + / / error prevents execution of any dynamic assertions in <nl> + / / a chunk . tests of static errors belong in syntax / . <nl> for ( syntaxerror err : ex . errors ( ) ) { <nl> - <nl> - / / they should be a different test suite . it is dangerous to mix <nl> - / / them in a chunk otherwise the presence of a static error causes <nl> - / / the program not to run the dynamic assertions . <nl> - if ( ! expected ( expectations , err . message ( ) ) ) { <nl> - system . err . println ( err ) ; / / includes location <nl> - ok = false ; <nl> - } <nl> + system . err . println ( err ) ; / / includes location <nl> + ok = false ; <nl> } <nl>  <nl> } catch ( evalexception ex ) { <nl> mmm a / src / test / java / net / starlark / java / eval / testdata / string_format . sky <nl> ppp b / src / test / java / net / starlark / java / eval / testdata / string_format . sky <nl>
<nl> - / / copyright num the bazel authors . all rights reserved . <nl> - / / <nl> - / / licensed under the apache license , version num . 0 ( the " license " ) ; <nl> - / / you may not use this file except in compliance with the license . <nl> - / / you may obtain a copy of the license at <nl> - / / <nl> - / / http : / / www . apache . org / licenses / license - 2 . 0 <nl> - / / <nl> - / / unless required by applicable law or agreed to in writing , software <nl> - / / distributed under the license is distributed on an " as is " basis , <nl> - / / without warranties or conditions of any kind , either express or implied . <nl> - / / see the license for the specific language governing permissions and <nl> - / / limitations under the license . <nl> - <nl> - package net . starlark . java . annot ; <nl> - <nl> - / * * depecated helper functions for starlark annotations . * / <nl> - <nl> - @ deprecated <nl> - public class starlarkinterfaceutils { <nl> - @ deprecated <nl> - public static starlarkbuiltin getstarlarkbuiltin ( class < ? > classobj ) { <nl> - return starlarkannotations . getstarlarkbuiltin ( classobj ) ; <nl> - } <nl> - }
fi <nl> google_api_protos = " $ ( grep - o ' " . * \ . proto " ' third_party / googleapis / build . bazel | sed ' s / " / / g ' | sed ' s | ^ | third_party / googleapis / | g ' ) " <nl> proto_files = $ ( find third_party / remoteapis $ { google_api_protos } third_party / pprof src / main / protobuf src / main / java / com / google / devtools / build / lib / buildeventstream / proto src / main / java / com / google / devtools / build / skyframe src / main / java / com / google / devtools / build / lib / skyframe / proto src / main / java / com / google / devtools / build / lib / bazel / debug src / main / java / com / google / devtools / build / lib / starlarkdebug / proto - name " * . proto " ) <nl> library_jars = $ ( find $ additional_jars third_party - name ' * . jar ' | grep - fv javabuilder | grep - fv third_party / guava | grep - ve ' third_party / grpc / grpc . * jar ' | tr " \n " " " ) <nl> - grpc_java_version = 1 . 20 . 0 <nl> + grpc_java_version = 1 . 31 . 1 <nl> grpc_library_jars = $ ( find third_party / grpc - name ' * . jar ' | grep - e " . * $ { grpc_java_version } . * jar " | tr " \n " " " ) <nl> - # <nl> - if [ - z " $ { grpc_library_jars } " ] ; then <nl> - grpc_java_version = 1 . 26 . 0 <nl> - grpc_library_jars = $ ( find third_party / grpc - name ' * . jar ' | grep - e " . * $ { grpc_java_version } . * jar " | tr " \n " " " ) <nl> - fi <nl> guava_version = 25 . 1 <nl> guava_jars = $ ( find third_party / guava - name ' * . jar ' | grep - e " . * $ { guava_version } . * jar " | tr " \n " " " ) <nl> library_jars = " $ { library_jars } $ { grpc_library_jars } $ { guava_jars } "
message query { <nl> query_stdout_flush_failure = num [ ( metadata ) = { exit_code : num } ] ; <nl> analysis_query_prereq_unmet = num [ ( metadata ) = { exit_code : num } ] ; <nl> query_results_flush_failure = num [ ( metadata ) = { exit_code : num } ] ; <nl> - <nl> - unclosed_quotation_expression_error = num [ ( metadata ) = { exit_code : num } ] ; <nl> + reserved num ; <nl> variable_name_invalid = num [ ( metadata ) = { exit_code : num } ] ; <nl> variable_undefined = num [ ( metadata ) = { exit_code : num } ] ; <nl> buildfiles_and_loadfiles_cannot_use_output_location_error = num <nl>
message query { <nl> arguments_missing = num [ ( metadata ) = { exit_code : num } ] ; <nl> rbuildfiles_function_requires_skyquery = num [ ( metadata ) = { exit_code : num } ] ; <nl> full_targets_not_supported = num [ ( metadata ) = { exit_code : num } ] ; <nl> - <nl> - unexpected_token_error = num [ ( metadata ) = { exit_code : num } ] ; <nl> - integer_literal_missing = num [ ( metadata ) = { exit_code : num } ] ; <nl> - invalid_starting_character_error = num [ ( metadata ) = { exit_code : num } ] ; <nl> - premature_end_of_input_error = num [ ( metadata ) = { exit_code : num } ] ; <nl> + reserved num to num ; <nl> / / indicates the user specified invalid query syntax . <nl> syntax_error = num [ ( metadata ) = { exit_code : num } ] ; <nl> output_formatter_io_exception = num [ ( metadata ) = { exit_code : num } ] ;
public final class starlarkattrmodule implements starlarkattrmoduleapi { <nl> } <nl> builder . cfg ( new starlarkattributetransitionprovider ( starlarkdefinedtransition ) ) ; <nl> } else if ( ! trans . equals ( " target " ) ) { <nl> - <nl> - throw starlark . errorf ( " cfg must be either ' host ' or ' target ' . " ) ; <nl> + / / we don ' t actively advertise the hard - coded but exposed transitions like <nl> + / / android_split_transition because users of those transitions should already know about <nl> + / / them . <nl> + throw starlark . errorf ( <nl> + " cfg must be either ' host ' , ' target ' , ' exec ' or a starlark defined transition defined " <nl> + + " by the exec ( ) or transition ( ) functions . " ) ; <nl> } <nl> } <nl>  <nl> mmm a / src / test / java / com / google / devtools / build / lib / starlark / starlarkruleclassfunctionstest . java <nl> ppp b / src / test / java / com / google / devtools / build / lib / starlark / starlarkruleclassfunctionstest . java <nl>
class skyfunctionenvironment extends abstractskyfunctionenvironment { <nl> maybeupdatemaxchildversion ( entry . getvalue ( ) ) ; <nl> } <nl> } <nl> - try { <nl> - return depvaluesbuilder . build ( ) ; <nl> - } catch ( illegalargumentexception e ) { <nl> - <nl> - / / every other key for equality ( and hash code collisions , just to be safe ) , and then print <nl> - / / out all the data we have for better debugging . remove this as soon as bug is fixed . <nl> - list < skykey > keys = immutablelist . copyof ( batchmap . keyset ( ) ) ; <nl> - list < pair < list < object > , list < object > > > duplicateornearduplicatekeys = new arraylist < > ( ) ; <nl> - for ( int i = num ; i < keys . size ( ) ; i + + ) { <nl> - for ( int j = num ; j < keys . size ( ) ; j + + ) { <nl> - if ( i = = j ) { <nl> - continue ; <nl> - } <nl> - / / if equals ( ) is somehow non - symmetric , we ' ll catch the other direction later in loop . <nl> - skykey ikey = keys . get ( i ) ; <nl> - skykey jkey = keys . get ( j ) ; <nl> - if ( ikey . equals ( jkey ) | | ( ikey . hashcode ( ) = = jkey . hashcode ( ) ) ) { <nl> - duplicateornearduplicatekeys . add ( <nl> - pair . of ( <nl> - immutablelist . of ( ikey , i , ikey . hashcode ( ) , system . identityhashcode ( ikey ) ) , <nl> - immutablelist . of ( jkey , j , jkey . hashcode ( ) , system . identityhashcode ( jkey ) ) ) ) ; <nl> - } <nl> - } <nl> - } <nl> - throw new illegalargumentexception ( <nl> - string . format ( <nl> - " impossible error with duplicate keys for % s ( % s % s % s ) " , <nl> - skykey , <nl> - duplicateornearduplicatekeys , <nl> - keys . size ( ) , <nl> - keys . stream ( ) <nl> - . map ( <nl> - k - > immutablelist . of ( k , k . hashcode ( ) , system . identityhashcode ( k ) ) . tostring ( ) ) <nl> - . collect ( joining ( " \n " ) ) ) , <nl> - e ) ; <nl> - } <nl> + return depvaluesbuilder . build ( ) ; <nl> } <nl>  <nl> private void checkactive ( ) {
final class starlarkdocumentationcollector { <nl> * a map from the name of each starlark module to its documentation . <nl> * / <nl> static immutablemap < string , starlarkbuiltindoc > collectmodules ( iterable < class < ? > > classes ) { <nl> - / / force class loading of net . starlark . java . eval . starlark before we do any of our <nl> - / / own processing . otherwise , we ' re in trouble since net . starlark . java . eval . dict <nl> - / / happens to be the first class on our classpath that we proccess via # collectmodulemethods , <nl> - / / but that entails a logical cycle in <nl> - / / net . starlark . java . eval . callutils # getcachevalue . <nl> - <nl> - @ suppresswarnings ( " unused " ) <nl> - object forceclassloading = starlark . universe ; <nl> - <nl> map < string , starlarkbuiltindoc > modules = new treemap < > ( ) ; <nl> / / the top level module first . <nl> / / ( this is a special case of { @ link starlarkbuiltindoc } as it has no object name ) . <nl> mmm a / src / main / java / net / starlark / java / eval / callutils . java <nl> ppp b / src / main / java / net / starlark / java / eval / callutils . java <nl>
public final class objccommon { <nl>  <nl> for ( compilationartifacts artifacts : compilationartifacts . asset ( ) ) { <nl> iterable < artifact > allsources = <nl> - iterables . concat ( artifacts . getsrcs ( ) , artifacts . getnonarcsrcs ( ) ) ; <nl> - <nl> - / / them . <nl> + iterables . concat ( <nl> + artifacts . getsrcs ( ) , artifacts . getnonarcsrcs ( ) , artifacts . getprivatehdrs ( ) ) ; <nl> objcprovider <nl> . addall ( library , artifacts . getarchive ( ) . asset ( ) ) <nl> . addall ( source , allsources ) <nl> mmm a / src / main / java / com / google / devtools / build / lib / starlarkbuildapi / apple / objcproviderapi . java <nl> ppp b / src / main / java / com / google / devtools / build / lib / starlarkbuildapi / apple / objcproviderapi . java <nl>
public class singletoncodec < t > implements objectcodec < t > { <nl> @ override <nl> public void serialize ( serializationcontext context , t t , codedoutputstream codedout ) <nl> throws ioexception { <nl> - <nl> - / / want to just toss it and trust that the classifier for this value is good enough . <nl> codedout . writebytearraynotag ( mnemonic ) ; <nl> }
public final class resolver extends nodevisitor { <nl>  <nl> @ override <nl> public void visit ( comprehension node ) { <nl> + immutablelist < comprehension . clause > clauses = node . getclauses ( ) ; <nl> + <nl> + / / following python3 , the first for clause is resolved <nl> + / / outside the comprehension block . all the other loops <nl> + / / are resolved in the scope of their own bindings , <nl> + / / permitting forward references . <nl> + comprehension . for for0 = ( comprehension . for ) clauses . get ( 0 ) ; <nl> + visit ( for0 . getiterable ( ) ) ; <nl> + <nl> openblock ( scope . local ) ; <nl> - for ( comprehension . clause clause : node . getclauses ( ) ) { <nl> + for ( comprehension . clause clause : clauses ) { <nl> if ( clause instanceof comprehension . for ) { <nl> comprehension . for forclause = ( comprehension . for ) clause ; <nl> createbindings ( forclause . getvars ( ) ) ; <nl> } <nl> } <nl> - <nl> - for ( comprehension . clause clause : node . getclauses ( ) ) { <nl> + for ( int i = num ; i < clauses . size ( ) ; i + + ) { <nl> + comprehension . clause clause = clauses . get ( i ) ; <nl> if ( clause instanceof comprehension . for ) { <nl> comprehension . for forclause = ( comprehension . for ) clause ; <nl> - visit ( forclause . getiterable ( ) ) ; <nl> + if ( i > num ) { <nl> + visit ( forclause . getiterable ( ) ) ; <nl> + } <nl> assign ( forclause . getvars ( ) ) ; <nl> } else { <nl> comprehension . if ifclause = ( comprehension . if ) clause ; <nl> mmm a / src / test / java / com / google / devtools / build / lib / syntax / resolvertest . java <nl> ppp b / src / test / java / com / google / devtools / build / lib / syntax / resolvertest . java <nl>
public final class resolver extends nodevisitor { <nl>  <nl> @ override <nl> public void visit ( comprehension node ) { <nl> + immutablelist < comprehension . clause > clauses = node . getclauses ( ) ; <nl> + <nl> + / / following python3 , the first for clause is resolved <nl> + / / outside the comprehension block . all the other loops <nl> + / / are resolved in the scope of their own bindings , <nl> + / / permitting forward references . <nl> + comprehension . for for0 = ( comprehension . for ) clauses . get ( 0 ) ; <nl> + visit ( for0 . getiterable ( ) ) ; <nl> + <nl> openblock ( scope . local ) ; <nl> - for ( comprehension . clause clause : node . getclauses ( ) ) { <nl> + for ( comprehension . clause clause : clauses ) { <nl> if ( clause instanceof comprehension . for ) { <nl> comprehension . for forclause = ( comprehension . for ) clause ; <nl> createbindings ( forclause . getvars ( ) ) ; <nl> } <nl> } <nl> - <nl> - for ( comprehension . clause clause : node . getclauses ( ) ) { <nl> + for ( int i = num ; i < clauses . size ( ) ; i + + ) { <nl> + comprehension . clause clause = clauses . get ( i ) ; <nl> if ( clause instanceof comprehension . for ) { <nl> comprehension . for forclause = ( comprehension . for ) clause ; <nl> - visit ( forclause . getiterable ( ) ) ; <nl> + if ( i > num ) { <nl> + visit ( forclause . getiterable ( ) ) ; <nl> + } <nl> assign ( forclause . getvars ( ) ) ; <nl> } else { <nl> comprehension . if ifclause = ( comprehension . if ) clause ; <nl> mmm a / src / test / java / com / google / devtools / build / lib / syntax / resolvertest . java <nl> ppp b / src / test / java / com / google / devtools / build / lib / syntax / resolvertest . java <nl>
public final class listexpression extends expression { <nl> / / or num elements ( with more elements following ) . <nl> if ( buf . length ( ) > = num | | ( i = = num & & i + num < n ) ) { <nl> buf . setlength ( mark ) ; <nl> - <nl> - buf . append ( string . format ( " < % d more arguments > " , n - i ) ) ; <nl> + buf . append ( string . format ( " + % d more " , n - i ) ) ; <nl> break ; <nl> } <nl> } <nl> mmm a / src / test / java / com / google / devtools / build / lib / syntax / prettyprinttest . java <nl> ppp b / src / test / java / com / google / devtools / build / lib / syntax / nodeprintertest . java <nl>
import org . junit . test ; <nl> import org . junit . runner . runwith ; <nl> import org . junit . runners . junit4 ; <nl>  <nl> - / * * tests the { @ code tostring } and pretty printing methods for { @ link node } subclasses . * / <nl> + / * * tests { @ link node # tostring } and { @ code nodeprinter } . * / <nl> @ runwith ( junit4 . class ) <nl> - <nl> - public final class prettyprinttest { <nl> + public final class nodeprintertest { <nl>  <nl> private static starlarkfile parsefile ( string . . . lines ) throws syntaxerror . exception { <nl> parserinput input = parserinput . fromlines ( lines ) ; <nl>
public interface javasemantics { <nl> filetype jar = filetype . of ( " . jar " ) ; <nl> filetype properties = filetype . of ( " . properties " ) ; <nl> filetype source_jar = filetype . of ( " . srcjar " ) ; <nl> - <nl> - filetype coverage_metadata = filetype . of ( " . em " ) ; <nl>  <nl> / * * label to the java toolchain rule . it is resolved from a label given in the java options . * / <nl> string java_toolchain_label = " / / tools / jdk : toolchain " ;
like linking in c + + builds without over - allocating to less demanding tasks . <nl>  <nl> # # defining execution groups <nl>  <nl> - during rule definition , rule authors can declare a set of execution groups . on <nl> - each execution group , the rule author can specify everything needed to select <nl> - an execution platform for that execution group , namely any constraints via <nl> - ` exec_compatible_with ` and toolchain types via ` toolchain ` . if an execution group <nl> - is created as empty ( no specified toolchains or constraints ) it will <nl> - automatically inherit these <nl> + during rule definition , rule authors can <nl> + [ declare ] ( https : / / docs . bazel . build / versions / master / skylark / lib / globals . html # exec_group ) <nl> + a set of execution groups . on each execution group , the rule author can specify <nl> + everything needed to select an execution platform for that execution group , <nl> + namely any constraints via ` exec_compatible_with ` and toolchain types via <nl> + ` toolchain ` . if an execution group is created as empty ( no specified toolchains <nl> + or constraints ) it will automatically inherit these <nl> [ parameters ] ( https : / / docs . bazel . build / versions / master / skylark / lib / globals . html # rule ) <nl> from the rule to which the group is attached . <nl>  <nl> - <nl> - <nl> ` ` ` python <nl> # foo . bzl <nl> my_rule = rule (
public interface starlarkrulefunctionsapi < fileapit extends fileapi > { <nl> positional = false , <nl> enableonlywithflag = flagidentifier . experimental_exec_groups , <nl> valuewhendisabled = " none " , <nl> - <nl> - doc = " dictionary to declare execution groups . do not use - not function yet . " ) <nl> + doc = <nl> + " dict of execution group name ( string ) to < a " <nl> + + " href = ' globals . html # exec_group ' > < code > exec_group < / code > s < / a > . if set , " <nl> + + " allows rules to run actions on multiple execution platforms within a " <nl> + + " single target . see < a href = ' . . / . . / exec - groups . html ' > execution groups " <nl> + + " documentation < / a > for more info . " ) <nl> } , <nl> usestarlarkthread = true ) <nl> starlarkcallable rule ( <nl>
public interface starlarkrulefunctionsapi < fileapit extends fileapi > { <nl>  <nl> @ starlarkmethod ( <nl> name = " exec_group " , <nl> - <nl> - / / enableonlywithflag = flagidentifier . experimental_exec_groups , <nl> doc = <nl> - " < i > experimental < / i > creates an execution group which can be used to create " <nl> - + " actions for a specific execution platform during rule implementation . this is " <nl> - + " ongoing work and not yet functional - do not use . " , <nl> + " < i > experimental < / i > creates an < a href = ' . . / . . / exec - groups . html ' > execution group < / a > " <nl> + + " which can be used to create actions for a specific execution platform during rule " <nl> + + " implementation . " , <nl> parameters = { <nl> @ param ( <nl> name = toolchains_param ,
final class eval { <nl> throw ex . ensurelocation ( stmt . getoperatorlocation ( ) ) ; <nl> } <nl>  <nl> - } else if ( lhs instanceof listexpression ) { <nl> - <nl> - throw new evalexception ( <nl> - stmt . getoperatorlocation ( ) , " cannot perform augmented assignment on a list literal " ) ; <nl> - <nl> } else { <nl> / / not possible for resolved asts . <nl> throw new evalexception (
public abstract class bazeljavabuilder { <nl> ? new reducedclasspathjavalibrarybuilder ( ) <nl> : new simplejavalibrarybuilder ( ) ) { <nl>  <nl> - <nl> - if ( ! collections . disjoint ( <nl> - build . getjavacopts ( ) , <nl> - immutableset . of ( " - extra_checks " , " - extra_checks : on " , " - extra_checks : off " ) ) ) { <nl> - throw new invalidcommandlineexception ( <nl> - " - extra_checks is no longer supported ; " <nl> - + " use - xepdisableallchecks to disable error prone " ) ; <nl> - } <nl> - <nl> blazejavacresult result = builder . run ( build ) ; <nl> if ( result . status ( ) = = status . requires_fallback ) { <nl> return num ; <nl> mmm a / src / java_tools / buildjar / java / com / google / devtools / build / buildjar / javac / javacoptions . java <nl> ppp b / src / java_tools / buildjar / java / com / google / devtools / build / buildjar / javac / javacoptions . java <nl>
public final class javacoptions { <nl> } <nl>  <nl> private static boolean isbazelspecificflag ( string opt ) { <nl> - return opt . startswith ( " - werror : " ) <nl> - | | opt . startswith ( " - xep " ) <nl> - <nl> - | | opt . equals ( " - extra_checks " ) <nl> - | | opt . startswith ( " - extra_checks : " ) ; <nl> + return opt . startswith ( " - werror : " ) | | opt . startswith ( " - xep " ) ; <nl> } <nl>  <nl> / * *
import javax . annotation . nullable ; <nl> * a ( label , configuration key ) pair . note that this pair may be used to look up the generating <nl> * action of an artifact . <nl> * / <nl> - <nl> + @ autocodec <nl> public class configuredtargetkey implements actionlookupkey { <nl> + / * * <nl> + * cache so that the number of configuredtargetkey instances is { @ code o ( configured targets ) } and <nl> + * not { @ code o ( edges between configured targets ) } . <nl> + * / <nl> + private static final interner < configuredtargetkey > interner = blazeinterners . newweakinterner ( ) ; <nl> + <nl> private final label label ; <nl> @ nullable private final buildconfigurationvalue . key configurationkey ; <nl>  <nl>
public class cppcompileaction extends abstractaction implements includescannable <nl>  <nl> / / copy the nested sets to hash sets for fast contains checking , but do so lazily . <nl> / / avoid immutable sets here to limit memory churn . <nl> - set < pathfragment > loosehdrsdirs = null ; <nl> + set < pathfragment > loosehdrsdirs = cccompilationcontext . getloosehdrsdirs ( ) . toset ( ) ; <nl> for ( artifact input : inputsforvalidation . tolist ( ) ) { <nl> - / / only declared modules are added to an action and so they are always valid . <nl> - if ( input . isfiletype ( cppfiletypes . cpp_module ) ) { <nl> - continue ; <nl> - } <nl> - <nl> - / / local_objc_modules feature . <nl> - if ( input . isfiletype ( cppfiletypes . objc_module_map ) ) { <nl> - continue ; <nl> - } <nl> - if ( allowedincludes . contains ( input ) ) { <nl> - continue ; <nl> - } <nl> - / / ignore headers from built - in include directories . <nl> - if ( filesystemutils . startswithany ( input . getexecpath ( ) , ignoredirs ) ) { <nl> - continue ; <nl> - } <nl> - if ( loosehdrsdirs = = null ) { <nl> - loosehdrsdirs = sets . newhashset ( cccompilationcontext . getloosehdrsdirs ( ) . tolist ( ) ) ; <nl> - } <nl> - if ( ! isdeclaredin ( cppconfiguration , actionexecutioncontext , input , loosehdrsdirs ) ) { <nl> + if ( ! validateinclude ( <nl> + actionexecutioncontext , allowedincludes , loosehdrsdirs , ignoredirs , input ) ) { <nl> errors . add ( input . getexecpath ( ) . tostring ( ) ) ; <nl> } <nl> }
public final class dict < k , v > <nl> return this ; <nl> } <nl>  <nl> - / * * puts all entries of the given map into the dict , without calling { @ link # checkmutable } . * / <nl> - @ suppresswarnings ( " unchecked " ) <nl> - private < kk extends k , vv extends v > dict < k , v > putallunsafe ( map < kk , vv > m ) { <nl> - for ( map . entry < kk , vv > e : m . entryset ( ) ) { <nl> - <nl> - contents . put ( e . getkey ( ) , ( vv ) starlark . fromjava ( e . getvalue ( ) , mutability ) ) ; <nl> - } <nl> - return this ; <nl> - } <nl> - <nl> @ override <nl> public mutability mutability ( ) { <nl> return mutability ;
public final class fetchcommand implements blazecommand { <nl> lists . < string > newarraylist ( ) , <nl> threadsoption . threads , <nl> enumset . noneof ( setting . class ) , <nl> - <nl> - / * usegraphlessquery = * / false ) ; <nl> + / * usegraphlessquery = * / true ) ; <nl>  <nl> / / num . parse query : <nl> queryexpression expr ;
public class protolangtoolchain implements ruleconfiguredtargetfactory { <nl> for ( transitiveinfocollection protos : <nl> rulecontext . getprerequisites ( " blacklisted_protos " , target ) ) { <nl> protoinfo protoinfo = protos . get ( protoinfo . provider ) ; <nl> - <nl> + if ( protoinfo = = null <nl> + & & rulecontext <nl> + . getfragment ( protoconfiguration . class ) <nl> + . blacklistedprotosrequiresprotoinfo ( ) ) { <nl> + rulecontext . ruleerror ( <nl> + " ' " + rulecontext . getlabel ( ) + " ' does not have mandatory provider ' protoinfo ' . " ) ; <nl> + } <nl> if ( protoinfo ! = null ) { <nl> blacklistedprotos . addtransitive ( protoinfo . getoriginaltransitiveprotosources ( ) ) ; <nl> } else {
public class treeartifactvalue implements hasdigest , skyvalue { <nl> ! fileartifactvalue . omitted_file_marker . equals ( value ) , <nl> " cannot construct treeartifactvalue because child % s was omitted " , <nl> child ) ; <nl> - <nl> - / / once b / 70354083 is fixed . <nl> - remote = remote & & value . isremote ( ) ; <nl> + / / tolerate a tree artifact having a mix of local and remote children ( b / 152496153 # comment80 ) . <nl> + entirelyremote & = value . isremote ( ) ; <nl> digestbuilder . put ( child . getparentrelativepath ( ) . getpathstring ( ) , value ) ; <nl> } <nl> return new treeartifactvalue ( <nl> digestutils . frommetadata ( digestbuilder ) , <nl> immutablesortedmap . copyof ( childfilevalues ) , <nl> - remote ) ; <nl> + entirelyremote ) ; <nl> } <nl>  <nl> fileartifactvalue getselfdata ( ) { <nl>
public final class moduleactioncontextregistry <nl> * returns a new { @ link builder } suitable for creating instances of moduleactioncontextregistry . <nl> * / <nl> public static builder builder ( ) { <nl> - return new builderimpl ( ) ; <nl> + return new builder ( ) ; <nl> } <nl>  <nl> / * * <nl> * builder collecting the contexts and restrictions thereon for a { @ link <nl> * moduleactioncontextregistry } . <nl> * / <nl> - <nl> - / / delete asap . <nl> - public interface builder { <nl> - <nl> - / * * <nl> - * restricts the registry to only return implementations for the given type if they were <nl> - * { @ linkplain # register registered } with the provided restriction as a command - line identifier . <nl> - * <nl> - * < p > note that if no registered action context matches the requested command - line identifiers <nl> - * when it is { @ linkplain # build ( ) built } then the registry will return { @ code null } when <nl> - * queried for this identifying type . <nl> - * <nl> - * < p > this behavior can be reset by passing an empty restriction to this method which will cause <nl> - * the default behavior ( last implementation registered for the identifying type ) to be used . <nl> - * <nl> - * @ param restriction command - line identifier used during registration of the desired <nl> - * implementation or { @ code " " } to allow any implementation of the identifying type <nl> - * / <nl> - moduleactioncontextregistry . builder restrictto ( class < ? > identifyingtype , string restriction ) ; <nl> - <nl> - / * * <nl> - * registers an action context implementation identified by the given type and which can be <nl> - * { @ linkplain # restrictto restricted } by its provided command - line identifiers . <nl> - * / <nl> - < t extends actioncontext > moduleactioncontextregistry . builder register ( <nl> - class < t > identifyingtype , t context , string . . . commandlineidentifiers ) ; <nl> - <nl> - / * * constructs the registry configured by this builder . * / <nl> - moduleactioncontextregistry build ( ) throws abruptexitexception ; <nl> - } <nl> - <nl> - / * * <nl> - * builder collecting the contexts and restrictions thereon for a { @ link <nl> - * moduleactioncontextregistry } . <nl> - * / <nl> - private static final class builderimpl implements builder { <nl> + public static final class builder { <nl>  <nl> private final list < actioncontextinformation < ? > > actioncontexts = new arraylist < > ( ) ; <nl> private final map < class < ? > , string > typetorestriction = new hashmap < > ( ) ; <nl>
java_tools = [ <nl> " / / third_party / java / j2objc : embedded_tools_srcs " , <nl> " / / third_party / py / abseil : srcs " , <nl> " / / third_party / py / concurrent : srcs " , <nl> - # <nl> - # every script in @ bazel_tools was migrated to use abseil . <nl> - " / / third_party / py / gflags : srcs " , <nl> " / / third_party / py / six : srcs " , <nl> " / / src / conditions : embedded_tools " , <nl> " / / src / tools / android / java / com / google / devtools / build / android : embedded_tools " , <nl> mmm a / src / test / java / com / google / devtools / build / lib / blackbox / bazel / pythontoolssetup . java <nl> ppp b / src / test / java / com / google / devtools / build / lib / blackbox / bazel / pythontoolssetup . java <nl>
public final class actionmetadatahandler implements metadatahandler { <nl> / / avoid duplicate chmod calls . <nl> store . injectedfiles ( ) . add ( output ) ; <nl>  <nl> - <nl> return constructfileartifactvalue ( <nl> output , filestatuswithdigestadapter . adapt ( statnofollow ) , digest ) ; <nl> }
public final class actionmetadatahandler implements metadatahandler { <nl> } <nl> / / this artifact was not injected directly to the store , but it may have been injected as part <nl> / / of a tree artifact . <nl> - <nl> - if ( artifact . hasparent ( ) ) { <nl> + if ( artifact . ischildofdeclareddirectory ( ) ) { <nl> treeartifactvalue tree = store . gettreeartifactdata ( artifact . getparent ( ) ) ; <nl> if ( tree ! = null ) { <nl> value = tree . getchildvalues ( ) . get ( artifact ) ;
public final class skyframebuildview { <nl> | | cause instanceof nosuchpackageexception ; <nl> } <nl>  <nl> - / * * special flake for error cases when loading crosstool for c + + rules * / <nl> - <nl> - public static class cccrosstoolexception extends exception implements saneanalysisexception { <nl> - <nl> - public cccrosstoolexception ( string message ) { <nl> - super ( message ) ; <nl> - } <nl> - } <nl> - <nl> public artifactfactory getartifactfactory ( ) { <nl> return artifactfactory ; <nl> }
public abstract class bugreport { <nl> } <nl>  <nl> / * * <nl> - * print , log , send a bug report , and then cause the current blaze command to fail with the <nl> - * specified exit code , and then cause the jvm to terminate . <nl> + * print , log , and then cause the current blaze command to fail with the specified exit code , and <nl> + * then cause the jvm to terminate . <nl> * <nl> * < p > has no effect if another crash has already been handled by { @ link bugreport } . <nl> * / <nl> public static void handlecrashwithoutsendingbugreport ( <nl> throwable throwable , exitcode exitcode , string . . . args ) { <nl> - <nl> handlecrash ( <nl> throwable , <nl> / * sendbugreport = * / false , <nl>
public abstract class bugreport { <nl> * < p > has no effect if another crash has already been handled by { @ link bugreport } . <nl> * / <nl> public static void handlecrash ( throwable throwable , exitcode exitcode , string . . . args ) { <nl> - <nl> handlecrash ( <nl> throwable , <nl> / * sendbugreport = * / true , <nl>
public class androidconfiguration extends fragment implements androidconfigurati <nl> } <nl> } <nl>  <nl> - <nl> - / * * converter for { @ link androidaaptversion } * / <nl> - public static final class androidaaptconverter extends enumconverter < androidaaptversion > { <nl> - public androidaaptconverter ( ) { <nl> - super ( androidaaptversion . class , " android androidaaptversion " ) ; <nl> - } <nl> - } <nl> - <nl> / * * <nl> * value used to avoid multiple configurations from conflicting . <nl> * <nl>
public class androidconfiguration extends fragment implements androidconfigurati <nl> + " before the manifests of its dependencies . " ) <nl> public manifestmergerorder manifestmergerorder ; <nl>  <nl> - <nl> - @ option ( <nl> - name = " android_aapt " , <nl> - defaultvalue = " aapt2 " , <nl> - documentationcategory = optiondocumentationcategory . toolchain , <nl> - effecttags = { <nl> - optioneffecttag . affects_outputs , <nl> - optioneffecttag . loading_and_analysis , <nl> - optioneffecttag . loses_incremental_state , <nl> - } , <nl> - converter = androidaaptconverter . class , <nl> - help = <nl> - " selects the version of androidaaptversion to use for android_binary rules . " <nl> - + " flag to help the test and transition to aapt2 . " ) <nl> - public androidaaptversion androidaaptversion ; <nl> - <nl> @ option ( <nl> name = " apk_signing_method " , <nl> converter = apksigningmethodconverter . class , <nl>
public class bazelcppruleclasses { <nl> . orderindependent ( ) <nl> . direct_compile_time_input ( ) <nl> . legacyallowanyfiletype ( ) ) <nl> - <nl> + / * < ! - - # blaze_rule ( $ cc_library ) . attribute ( linkstamp ) - - > <nl> + simultaneously compiles and links the specified c + + source file into the final <nl> + binary . this trickery is required to introduce timestamp <nl> + information into binaries ; if we compiled the source file to an <nl> + object file in the usual way , the timestamp would be incorrect . <nl> + a linkstamp compilation may not include any particular set of <nl> + compiler flags and so should not depend on any particular <nl> + header , compiler option , or other build variable . <nl> + < em class = ' harmful ' > this option should only be needed in the <nl> + < code > base < / code > package . < / em > <nl> + < ! - - # end_blaze_rule . attribute - - > * / <nl> . add ( attr ( " linkstamp " , label ) . allowedfiletypes ( cpp_source , c_source ) ) <nl> . build ( ) ; <nl> }
public class artifactnestedsetkey implements skykey { <nl> * <nl> * < p > this refers to the transitive members after any inlining that might have happened at <nl> * construction of the nested set . <nl> - * <nl> - * < p > <nl> * / <nl> - iterable < object > transitivemembers ( ) { <nl> + immutablelist < object > transitivemembers ( ) { <nl> if ( ! ( rawchildren instanceof object [ ] ) ) { <nl> return immutablelist . of ( ) ; <nl> } <nl>
public class artifactnestedsetkey implements skykey { <nl> * <nl> * < p > this refers to the direct members after any inlining that might have happened at <nl> * construction of the nested set . <nl> - * <nl> - * < p > <nl> * / <nl> - iterable < skykey > directkeys ( ) { <nl> + immutablelist < skykey > directkeys ( ) { <nl> if ( ! ( rawchildren instanceof object [ ] ) ) { <nl> - return collections . singletonlist ( artifact . key ( ( artifact ) rawchildren ) ) ; <nl> + return immutablelist . of ( artifact . key ( ( artifact ) rawchildren ) ) ; <nl> } <nl> immutablelist . builder < skykey > listbuilder = new immutablelist . builder < > ( ) ; <nl> for ( object c : ( object [ ] ) rawchildren ) {
public class runcommand implements blazecommand { <nl> runfilesdir = ensurerunfilesbuilt ( env , runfilessupport , <nl> env . getskyframeexecutor ( ) . getconfiguration ( env . getreporter ( ) , <nl> targettorun . getconfigurationkey ( ) ) ) ; <nl> - } catch ( environmentalexecexception e ) { <nl> - <nl> - env . getreporter ( ) . handle ( event . error ( " error creating runfiles : " + e . getmessage ( ) ) ) ; <nl> - return blazecommandresult . exitcode ( exitcode . local_environmental_error ) ; <nl> + } catch ( runfilesexception e ) { <nl> + env . getreporter ( ) . handle ( event . error ( e . getmessage ( ) ) ) ; <nl> + return blazecommandresult . failuredetail ( e . createfailuredetail ( ) ) ; <nl> } <nl> } <nl>  <nl>
public class corelibraryinvocationrewriter extends classvisitor { <nl> } <nl> } <nl> super . visitmethodinsn ( opcode , owner , name , desc , itf ) ; <nl> - <nl> - / / compared with the constructor invocation , a factory method invocation pushes ( areturn ) the <nl> - / / constructed object reference onto the operand stack of the invoker frame , leaving the <nl> - / / operand stack in state { uninitialized num , uninitialized num , objectref } , the following <nl> - / / instructions clears the extra values on the stack . <nl> - / / <nl> - <nl> - / / { new , dup } instructions are stripped out . <nl> - if ( replaceconstructorusewithfactorymethod ) { <nl> - super . visitinsn ( opcodes . dup_x2 ) ; <nl> - super . visitinsn ( opcodes . pop ) ; <nl> - super . visitinsn ( opcodes . pop2 ) ; <nl> - } <nl> } <nl> } <nl> }
nav : docs <nl> < h3 > reference < / h3 > <nl> < ul class = " sidebar - nav " > <nl> < li > < a href = " / versions / { { current_version } } / user - manual . html " > commands and options < / a > < / li > <nl> - <nl> - < ! - - <nl> - < li > < a href = " / versions / master / glossary . html " > glossary < / a > < / li > <nl> + < li > < a href = " / versions / { { current_version } } / glossary . html " > glossary < / a > < / li > <nl> + < li > < a href = " / versions / { { current_version } } / be / overview . html " > build encyclopedia < / a > < / li > <nl> + < li > < a href = " / versions / { { current_version } } / test - encyclopedia . html " > test encyclopedia < / a > < / li > <nl> + < li > < a href = " / versions / { { current_version } } / command - line - reference . html " > command line reference < / a > < / li > <nl>  <nl> < li > <nl> < a class = " sidebar - nav - heading " data - toggle = " collapse " <nl>
public final class starlarkthread { <nl> debug . threadhook . onpushfirst ( this ) ; <nl> } <nl>  <nl> - profilertask taskkind ; <nl> if ( fn instanceof starlarkfunction ) { <nl> starlarkfunction sfn = ( starlarkfunction ) fn ; <nl> fr . locals = maps . newlinkedhashmapwithexpectedsize ( sfn . getparameternames ( ) . size ( ) ) ; <nl> - taskkind = profilertask . starlark_user_fn ; <nl> } else { <nl> / / built - in function <nl> fr . locals = immutablemap . of ( ) ; <nl> - taskkind = profilertask . starlark_builtin_fn ; <nl> } <nl>  <nl> fr . loc = fn . getlocation ( ) ; <nl>  <nl> - / / start wall - time profile span <nl> - <nl> - if ( profiler . instance ( ) . isactive ( ) ) { <nl> - fr . profilespan = profiler . instance ( ) . profile ( taskkind , fn . getname ( ) ) ; <nl> - } <nl> - <nl> / / poll for newly installed cpu profiler . <nl> if ( profiler = = null ) { <nl> this . profiler = cpuprofiler . get ( ) ; <nl>
genrule ( <nl> distrib_java_import ( <nl> name = " netty " , <nl> jars = [ " netty / netty - all - 4 . 1 . 34 . final . jar " ] , <nl> - # <nl> - # enable_distributions = [ " debian " ] , <nl> + enable_distributions = [ " debian " ] , <nl> ) <nl>  <nl> - java_import ( <nl> + distrib_java_import ( <nl> name = " netty_tcnative " , <nl> jars = [ " netty_tcnative / netty - tcnative - filtered . jar " ] , <nl> + enable_distributions = [ " debian " ] , <nl> ) <nl>  <nl> distrib_java_import ( <nl>
public class reducedclasspathjavalibrarybuilder extends simplejavalibrarybuilder <nl> javacrunner . invokejavac ( build . toblazejavacarguments ( compressedclasspath ) ) ; <nl>  <nl> / / if javac errored out because of missing entries on the classpath , give it another try . <nl> - <nl> - boolean fallback = shouldfallback ( build , result ) ; <nl> + boolean fallback = ! result . isok ( ) ; <nl> if ( fallback ) { <nl> if ( build . reduceclasspathmode ( ) = = reduceclasspathmode . bazel_reduced ) { <nl> return blazejavacresult . fallback ( ) ; <nl>
public class formatteddiagnostic implements diagnostic < javafileobject > { <nl> return diagnostic . getmessage ( locale ) ; <nl> } <nl>  <nl> - / * * returns true if the diagnostic might be caused by the reduced classpath optimizaiton . * / <nl> - public boolean maybereducedclasspatherror ( ) { <nl> - string code = getcode ( ) ; <nl> - if ( code . contains ( " doesnt . exist " ) <nl> - | | code . contains ( " cant . resolve " ) <nl> - | | code . contains ( " cant . access " ) ) { <nl> - return true ; <nl> - } <nl> - / / handle - xdoclint : reference errors , which don ' t have a diagnostic code <nl> - <nl> - if ( getformatted ( ) . contains ( " error : reference not found " ) ) { <nl> - return true ; <nl> - } <nl> - / / error prone wraps completion failures <nl> - if ( code . equals ( " compiler . err . error . prone . crash " ) <nl> - & & getformatted ( ) . contains ( " com . sun . tools . javac . code . symbol $ completionfailure " ) ) { <nl> - return true ; <nl> - } <nl> - return false ; <nl> - } <nl> - <nl> / * * a { @ link diagnosticlistener < javafileobject > } that saves { @ link formatteddiagnostic } s . * / <nl> @ trusted <nl> static class listener implements diagnosticlistener < javafileobject > { <nl>
public final class errorproneplugin extends blazejavacompilerplugin { <nl> baseerrorpronejavacompiler . setupmessagebundle ( context ) ; <nl> } <nl>  <nl> - private static final string compiling_test_only_code_arg = " - xepcompilingtestonlycode " ; <nl> - <nl> @ override <nl> public list < string > processargs ( list < string > args ) throws invalidcommandlineexception { <nl> immutablelist . builder < string > epargs = immutablelist . < string > builder ( ) . addall ( args ) ; <nl> / / allow javacopts that reference unknown error - prone checks <nl> epargs . add ( " - xepignoreunknownchecknames " ) ; <nl> - return processepoptions ( epargs . build ( ) ) <nl> - <nl> - / / on error prone doesn ' t yet know about - xepcompilingtestonlycode . <nl> - / / remove this once the num p version is recent enough . <nl> - . stream ( ) <nl> - . filter ( arg - > ! arg . equals ( compiling_test_only_code_arg ) ) <nl> - . collect ( immutablelist . toimmutablelist ( ) ) ; <nl> + return processepoptions ( epargs . build ( ) ) ; <nl> } <nl>  <nl> private list < string > processepoptions ( list < string > args ) throws invalidcommandlineexception {
package com . google . devtools . build . lib . syntax ; <nl> * default , { @ code fastcall } delegates to { @ code call } , and call throws an exception , so an <nl> * implementer may override either one . <nl> * / <nl> - <nl> public interface starlarkcallable extends starlarkvalue { <nl>  <nl> / * * <nl>
public class symlinkforesttest { <nl> outputbase . getrelative ( labelconstants . external_path_prefix ) . getrelative ( " x " ) ) ; <nl>  <nl> assertthat ( linkroot . getrelative ( " external / foo " ) . exists ( ) ) . istrue ( ) ; <nl> - <nl> + <nl> assertthat ( plantedsymlinks ) <nl> - . containsatleast ( <nl> + . containsexactly ( <nl> linkroot . getrelative ( " dir1 " ) , <nl> linkroot . getrelative ( " dir2 " ) , <nl> linkroot . getrelative ( " dir3 " ) , <nl> - linkroot . getparentdirectory ( ) . getrelative ( " x " ) ) ; <nl> + linkroot . getrelative ( " external " ) , / / symlinked to the main repo ' s top level external dir <nl> + linkroot . getparentdirectory ( ) . getrelative ( " x " ) ) ; / / symlinked to / ob / external / x <nl> } <nl>  <nl> @ test <nl>
public class symlinkforesttest { <nl> outputbase . getrelative ( labelconstants . external_path_prefix ) . getrelative ( " x " ) ) ; <nl>  <nl> assertthat ( linkroot . getrelative ( " external / foo " ) . exists ( ) ) . istrue ( ) ; <nl> - <nl> - assertthat ( plantedsymlinks ) . contains ( linkroot . getparentdirectory ( ) . getrelative ( " x " ) ) ; <nl> + <nl> + assertthat ( plantedsymlinks ) <nl> + . containsexactly ( <nl> + linkroot . getparentdirectory ( ) . getrelative ( " x " ) , <nl> + linkroot . getrelative ( " file " ) , / / created by createmainpkg test setup <nl> + linkroot . getrelative ( " external " ) / / symlink to main repo ' s top level external directory <nl> + ) ; <nl> } <nl>  <nl> @ test
public class shadowedapiadapterhelper { <nl> * no in - process label , such as " __desugar__ / " , is attached to this invocation site . <nl> * / <nl> static boolean shoulduseinlinetypeconversion ( methodinvocationsite verbatiminvocationsite ) { <nl> - / / fix for b / 153441709 : type adapter generation causes one - version violation . <nl> - <nl> - if ( verbatiminvocationsite . owner ( ) . haspackageprefix ( " android / app / usage / usagestatsmanager " ) ) { <nl> - return true ; <nl> - } <nl> return verbatiminvocationsite . isconstructorinvocation ( ) <nl> & & verbatiminvocationsite . owner ( ) . isinpackageeligiblefortypeadapter ( ) <nl> & & stream . concat (
public final class configuredtargetfunction implements skyfunction { <nl> configuredvaluecreationexception cvce = ( configuredvaluecreationexception ) e . getcause ( ) ; <nl>  <nl> / / check if this is caused by an unresolved toolchain , and report it as such . <nl> - <nl> if ( unloadedtoolchaincontexts ! = null ) { <nl> - unloadedtoolchaincontext finalunloadedtoolchaincontext = <nl> - unloadedtoolchaincontexts . getdefaulttoolchaincontext ( ) ; <nl> + immutableset < label > requiredtoolchains = <nl> + unloadedtoolchaincontexts . getresolvedtoolchains ( ) ; <nl> set < label > toolchaindependencyerrors = <nl> cvce . getrootcauses ( ) . tolist ( ) . stream ( ) <nl> . map ( cause : : getlabel ) <nl> - . filter ( l - > finalunloadedtoolchaincontext . resolvedtoolchainlabels ( ) . contains ( l ) ) <nl> + . filter ( requiredtoolchains : : contains ) <nl> . collect ( immutableset . toimmutableset ( ) ) ; <nl>  <nl> if ( ! toolchaindependencyerrors . isempty ( ) ) {
cc_binary ( <nl> name = " libcpu_profiler . so " , <nl> srcs = select ( { <nl> " / / src / conditions : darwin " : [ " cpu_profiler_posix . cc " ] , <nl> + # there is no config_setting for linux . <nl> + # see https : / / github . com / bazelbuild / bazel / issues / 11107 <nl> + " / / src / conditions : linux_aarch64 " : [ " cpu_profiler_posix . cc " ] , <nl> + " / / src / conditions : linux_ppc " : [ " cpu_profiler_posix . cc " ] , <nl> + " / / src / conditions : linux_s390x " : [ " cpu_profiler_posix . cc " ] , <nl> " / / src / conditions : linux_x86_64 " : [ " cpu_profiler_posix . cc " ] , <nl> " / / conditions : default " : [ " cpu_profiler_unimpl . cc " ] , <nl> } ) , <nl> linkshared = num , <nl> - deps = [ " : jni " ] , # <nl> - ) <nl> - <nl> - # this has been copied to @ bazel_tools / / tools / jdk : jni and will appear in the next release . <nl> - cc_library ( <nl> - name = " jni " , <nl> - hdrs = [ " @ bazel_tools / / tools / jdk : jni_header " ] + select ( { <nl> - " / / src / conditions : linux_x86_64 " : [ " @ bazel_tools / / tools / jdk : jni_md_header - linux " ] , <nl> - " / / src / conditions : linux_aarch64 " : [ " @ bazel_tools / / tools / jdk : jni_md_header - linux " ] , <nl> - " / / src / conditions : linux_ppc " : [ " @ bazel_tools / / tools / jdk : jni_md_header - linux " ] , <nl> - " / / src / conditions : darwin " : [ " @ bazel_tools / / tools / jdk : jni_md_header - darwin " ] , <nl> - " / / src / conditions : freebsd " : [ " @ bazel_tools / / tools / jdk : jni_md_header - freebsd " ] , <nl> - " / / src / conditions : openbsd " : [ " @ bazel_tools / / tools / jdk : jni_md_header - openbsd " ] , <nl> - " / / src / conditions : windows " : [ " @ bazel_tools / / tools / jdk : jni_md_header - windows " ] , <nl> - " / / conditions : default " : [ ] , <nl> - } ) , <nl> - includes = [ " . . / . . / . . / . . / . . / . . / . . / . . / . . / external / bazel_tools / tools / jdk / include " ] + select ( { <nl> - " / / src / conditions : linux_x86_64 " : [ " . . / . . / . . / . . / . . / . . / . . / . . / . . / external / bazel_tools / tools / jdk / include / linux " ] , <nl> - " / / src / conditions : linux_aarch64 " : [ " . . / . . / . . / . . / . . / . . / . . / . . / . . / external / bazel_tools / tools / jdk / include / linux " ] , <nl> - " / / src / conditions : linux_ppc " : [ " . . / . . / . . / . . / . . / . . / . . / . . / . . / external / bazel_tools / tools / jdk / include / linux " ] , <nl> - " / / src / conditions : darwin " : [ " . . / . . / . . / . . / . . / . . / . . / . . / . . / external / bazel_tools / tools / jdk / include / darwin " ] , <nl> - " / / src / conditions : freebsd " : [ " . . / . . / . . / . . / . . / . . / . . / . . / . . / external / bazel_tools / tools / jdk / include / freebsd " ] , <nl> - " / / src / conditions : openbsd " : [ " . . / . . / . . / . . / . . / . . / . . / . . / . . / external / bazel_tools / tools / jdk / include / openbsd " ] , <nl> - " / / src / conditions : windows " : [ " . . / . . / . . / . . / . . / . . / . . / . . / . . / external / bazel_tools / tools / jdk / include / win32 " ] , <nl> - " / / conditions : default " : [ ] , <nl> - } ) , <nl> + deps = [ " @ bazel_tools / / tools / jdk : jni " ] , <nl> )
common - - show_progress_rate_limit = - 1 <nl> # disable terminal - specific features . <nl> common - - color = no - - curses = no <nl>  <nl> - # <nl> - build - - incompatible_use_python_toolchains = true <nl> - <nl> # prevent sigbus during jvm actions . <nl> build - - sandbox_tmpfs_path = / tmp
public class errormessagetest { <nl>  <nl> @ test <nl> public void testerrormessagewithunreadablelogfile ( ) { <nl> - if ( os . getcurrent ( ) = = os . windows ) { <nl> - <nl> - return ; <nl> - } <nl> inmemoryfilesystem fs = new inmemoryfilesystem ( ) ; <nl> / / this file does not exist . <nl> path logfile = fs . getpath ( " / nope . txt " ) ; <nl>
java_library ( <nl> " timeutilities . java " , <nl> " userutils . java " , <nl> ] , <nl> - # <nl> - exports = [ <nl> - " : filetype " , <nl> - " : os " , <nl> - " : resource_usage " , <nl> - " : string " , <nl> - " : var_int " , <nl> - " / / src / main / java / com / google / devtools / build / lib / clock " , <nl> - " / / src / main / java / com / google / devtools / build / lib / collect " , <nl> - ] , <nl> deps = [ <nl> " : os " , <nl> " : shell_escaper " ,
java_library ( <nl> ] , <nl> ) <nl>  <nl> - # <nl> - java_library ( <nl> - name = " events " , <nl> - exports = [ <nl> - " / / src / main / java / com / google / devtools / build / lib / events " , <nl> - ] , <nl> - ) <nl> - <nl> # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # <nl> # <nl> # the " foundation " library ( concurrent , events , util , vfs , inmemoryfs , options ) <nl> mmm a / src / main / java / com / google / devtools / build / lib / buildeventservice / build <nl> ppp b / src / main / java / com / google / devtools / build / lib / buildeventservice / build <nl>
java_library ( <nl> " starlarksemanticsoptions . java " , <nl> ] , <nl> ) , <nl> - # <nl> - exports = [ <nl> - " : build_type " , <nl> - ] , <nl> deps = [ <nl> " : build_type " , <nl> " : type " ,
public final class spawnlogmodule extends blazemodule { <nl> new abruptexitexception ( <nl> " error initializing execution log " , exitcode . command_line_error , e ) ) ; <nl> } <nl> - <nl> - if ( spawnlogcontext ! = null ) { <nl> - <nl> - / / no other spawnlogcontext to distinguish from . <nl> - builder . addactioncontext ( spawnlogcontext . class , spawnlogcontext , " spawn - log " ) ; <nl> - builder . addstrategybycontext ( spawnlogcontext . class , " " ) ; <nl> - } <nl> } <nl>  <nl> @ override
java_library ( <nl> " type . java " , <nl> ] , <nl> ) , <nl> - # <nl> - exports = [ <nl> - " : type " , <nl> - ] , <nl> deps = [ <nl> " : type " , <nl> " / / src / main / java / com / google / devtools / build / lib : config - matching - provider " ,
import org . junit . runners . junit4 ; <nl> * ( configuredtargetfunction is a skyframe function ) . and the skyframe library doesn ' t know anything <nl> * about latebound attributes . so we need to place these properly under the analysis package . <nl> * / <nl> - @ testonlyinnormalexecutionmode <nl> @ testspec ( size = suite . small_tests ) <nl> @ runwith ( junit4 . class ) <nl> public class configurationsforlateboundtargetstest extends analysistestcase { <nl> mmm a / src / test / java / com / google / devtools / build / lib / testutil / build <nl> ppp b / src / test / java / com / google / devtools / build / lib / testutil / build <nl>
static bool makedirectories ( const string & path , mode_t mode , bool childmost ) { <nl> string createtempdir ( const std : : string & prefix ) { <nl> std : : string parent = dirname ( prefix ) ; <nl> / / need parent to exist first . <nl> - <nl> - if ( ! blaze_util : : makedirectories ( parent , num ) ) { <nl> + if ( ! blaze_util : : pathexists ( parent ) & & <nl> + ! blaze_util : : makedirectories ( parent , num ) ) { <nl> bazel_die ( blaze_exit_code : : internal_error ) <nl> < < " couldn ' t create ' " < < parent < < " ' : " <nl> < < blaze_util : : getlasterrorstring ( ) ; <nl>
public class streamedtestoutputtest { <nl>  <nl> @ test <nl> public void testonlyoutputscontentsafterheaderwhenpresent ( ) throws ioexception { <nl> - if ( os . getcurrent ( ) = = os . windows ) { <nl> - <nl> - return ; <nl> - } <nl> - <nl> path watchedpath = filesystem . getpath ( " / myfile " ) ; <nl> filesystemutils . writelinesas ( <nl> watchedpath , <nl>
def find_vc_path ( repository_ctx ) : <nl> auto_configure_warning_maybe ( repository_ctx , " visual c + + build tools found at % s " % vc_dir ) <nl> return vc_dir <nl>  <nl> - # num . user might have purged all environment variables . if so , look for visual c + + in registry . <nl> + # num . user might have purged all environment variables . if so , look for visual c + + in registry . <nl> # works for visual studio num and older . ( does not work for visual studio num preview . ) <nl> - # <nl> auto_configure_warning_maybe ( repository_ctx , " looking for visual c + + through registry " ) <nl> reg_binary = _get_system_root ( repository_ctx ) + " \ \ system32 \ \ reg . exe " <nl> vc_dir = none <nl>
import java . util . list ; <nl> / / this module needs to be exported to skylark so it can be passed as a mandatory host / target <nl> / / configuration fragment in aspect definitions . <nl> public class protoconfiguration extends fragment implements protoconfigurationapi { <nl> - <nl> - / / ` - - incompatible_load_proto_toolchain_for_javalite_from_com_google_protobuf ` defaults to true . <nl> - private static final label default_javalite_toolchain_old = <nl> - label . parseabsoluteunchecked ( " @ com_google_protobuf_javalite / / : javalite_toolchain " ) ; <nl> - private static final label default_javalite_toolchain_new = <nl> - label . parseabsoluteunchecked ( " @ com_google_protobuf / / : javalite_toolchain " ) ; <nl> - <nl> / * * command line options . * / <nl> public static class options extends fragmentoptions { <nl> @ option ( <nl>
public class protoconfiguration extends fragment implements protoconfigurationap <nl>  <nl> @ option ( <nl> name = " proto_toolchain_for_javalite " , <nl> - <nl> - / / ` - - incompatible_load_proto_toolchain_for_javalite_from_com_google_protobuf ` <nl> - / / defaults to true . <nl> - defaultvalue = " null " , <nl> - converter = coreoptionconverters . emptytonulllabelconverter . class , <nl> + defaultvalue = " @ com_google_protobuf / / : javalite_toolchain " , <nl> + converter = coreoptionconverters . labelconverter . class , <nl> documentationcategory = optiondocumentationcategory . uncategorized , <nl> effecttags = { optioneffecttag . affects_outputs , optioneffecttag . loading_and_analysis } , <nl> help = " label of proto_lang_toolchain ( ) which describes how to compile javalite protos " ) <nl>
<nl> layout : documentation <nl> title : user ' s guide <nl> mmm <nl> - < ! - - begin - block : internal <nl> - <nl> < h1 > a user ' s guide to bazel < / h1 >
public class packagelookupfunction implements skyfunction { <nl> + filerootedpath . aspath ( ) ) , <nl> transience . persistent ) ; <nl> } catch ( ioexception e ) { <nl> - <nl> - / / buildfilenotfoundexception . <nl> throw new packagelookupfunctionexception ( new buildfilenotfoundexception ( packageidentifier , <nl> " io errors while looking for " + basename + " file reading " <nl> + filerootedpath . aspath ( ) + " : " + e . getmessage ( ) , e ) , <nl> mmm a / src / main / java / com / google / devtools / build / lib / skyframe / skyframeexecutor . java <nl> ppp b / src / main / java / com / google / devtools / build / lib / skyframe / skyframeexecutor . java <nl>
public final class optionsparser { <nl> return bootclasspath ; <nl> } <nl>  <nl> - public list < string > getextclasspath ( ) { <nl> - <nl> - return immutablelist . of ( ) ; <nl> - } <nl> - <nl> public list < string > getsourcepath ( ) { <nl> return sourcepath ; <nl> }
else <nl> declare - r embedded_jdk = " " <nl> fi <nl>  <nl> - function test_bootstrap ( ) { <nl> - execute_bootstrap " - - host_javabase = @ local_jdk / / : jdk " <nl> - } <nl> - <nl> - # <nl> - function test_bootstrap_with_cc_rules_using_platforms ( ) { <nl> - execute_bootstrap " - - host_javabase = @ local_jdk / / : jdk " \ <nl> - " - - incompatible_enable_cc_toolchain_resolution " <nl> - } <nl> - <nl> - function execute_bootstrap ( ) { <nl> + function test_bootstrap ( ) { <nl> cd " $ ( mktemp - d $ { test_tmpdir } / bazelbootstrap . xxxxxxxx ) " <nl> export source_date_epoch = 1501234567 <nl> unzip - q " $ { distfile } " <nl>
test_suite ( <nl> " / / src / test / java / com / google / devtools / common / options : all_windows_tests " , <nl> " / / src / test / native / windows : all_windows_tests " , <nl> " / / src / test / py / bazel : all_windows_tests " , <nl> - # <nl> - # " / / src / test / res : all_windows_tests " , <nl> + " / / src / test / res : all_windows_tests " , <nl> " / / src / test / shell : all_windows_tests " , <nl> " / / src / test / shell / bazel / android : all_windows_tests " , <nl> " / / src / tools / launcher : all_windows_tests " ,
string getselfpath ( const char * argv0 ) { <nl> return blaze_util : : getcwd ( ) + " / " + argv0str ; <nl> } <nl>  <nl> - <nl> + const std : : string from_search_path = which ( argv0 ) ; <nl> + if ( ! from_search_path . empty ( ) ) { <nl> + return from_search_path ; <nl> + } <nl>  <nl> / / none of the above worked . give up . <nl> bazel_die ( blaze_exit_code : : bad_argv ) <nl> - < < " unable to determine the location of this bazel executable . " <nl> - " currently , argv [ 0 ] must be an absolute or relative path to the " <nl> - " executable . " ; <nl> + < < " unable to determine the location of this bazel executable . " ; <nl> return " " ; / / never executed . needed so compiler does not complain . <nl> # else <nl> # error this bsd is not supported <nl> mmm a / src / main / cpp / blaze_util_linux . cc <nl> ppp b / src / main / cpp / blaze_util_linux . cc <nl>
public class buildrequestoptions extends optionsbase { <nl> clean , <nl> / * * will not create or clean up any symlinks . * / <nl> ignore , <nl> - / * * <nl> + / * * will not create or clean up any symlinks , but will record the symlinks . * / <nl> log_only <nl> } <nl> }
file_test ( <nl> " / / conditions : default " : " not supported " , <nl> } ) , <nl> file = " : run_app " , <nl> - # <nl> - # https : / / github . com / bazelbuild / bazel / issues / 9104 # issuecomment - 521231693 <nl> - tags = [ " no_windows " ] , <nl> ) <nl>  <nl> test_suite ( name = " all_tests " )
final class parser { <nl> } <nl> } <nl>  <nl> - / / create an error expression <nl> private identifier makeerrorexpression ( int start , int end ) { <nl> - <nl> + / / but it is convenient for parseident to return an identifier <nl> + / / even when it fails . <nl> return setlocation ( identifier . of ( " $ error $ " ) , start , end ) ; <nl> }
eof <nl> } <nl>  <nl> function test_java_common_compile_sourcepath ( ) { <nl> - # <nl> - java_version = " 1 . $ ( bazel query - - output = build ' @ bazel_tools / / tools / jdk : remote_toolchain ' | grep source_version | cut - d ' " ' - f num ) " <nl> - if [ " $ { java_version } " = " 1 . 7 " ] ; then <nl> - return num <nl> - fi <nl> mkdir - p g <nl> cat > g / a . java < < ' eof ' <nl> package g ; <nl>
eof <nl> } <nl>  <nl> function test_java_common_compile_sourcepath_with_implicit_class ( ) { <nl> - # <nl> - java_version = " 1 . $ ( bazel query - - output = build ' @ bazel_tools / / tools / jdk : remote_toolchain ' | grep source_version | cut - d ' " ' - f num ) " <nl> - if [ " $ { java_version } " = " 1 . 7 " ] ; then <nl> - return num <nl> - fi <nl> mkdir - p g <nl> cat > g / a . java < < ' eof ' <nl> package g ; <nl>
public final class attribute implements comparable < attribute > { <nl> return allowedruleclassesforlabels . aspredicateofruleclass ( ) ; <nl> } <nl>  <nl> - / * * <nl> - * returns a predicate that evaluates to true for rule classes that are allowed labels in this <nl> - * attribute . if this is not a label or label - list attribute , the returned predicate always <nl> - * evaluates to true . <nl> - * / <nl> - <nl> - public predicate < string > getallowedruleclassnamespredicate ( ) { <nl> - return allowedruleclassesforlabels . aspredicateofruleclassname ( ) ; <nl> - } <nl> - <nl> / * * <nl> * returns a predicate that evaluates to true for rule classes that are <nl> * allowed labels in this attribute with warning . if this is not a label or label - list
public class resourcelinker { <nl> . resolve ( " filtered " ) <nl> / / make absolute paths relative so that resolve will make a new path . <nl> . resolve ( path . isabsolute ( ) ? path . subpath ( 1 , path . getnamecount ( ) ) : path ) ; <nl> - <nl> - if ( files . exists ( outpath ) ) { <nl> - return outpath ; <nl> - } <nl> files . createdirectories ( outpath . getparent ( ) ) ; <nl> try ( filechannel inchannel = filechannel . open ( path , standardopenoption . read ) ; <nl> filechannel outchannel =
class starlark { <nl> system . err . println ( ev ) ; <nl> } <nl> } catch ( evalexception ex ) { <nl> - <nl> - ex . printstacktrace ( ) ; <nl> + system . err . println ( ex . print ( ) ) ; <nl> } catch ( interruptedexception ex ) { <nl> system . err . println ( " interrupted " ) ; <nl> } <nl>
public class resourcejaractionbuilder { <nl> if ( ! classpathresources . isempty ( ) ) { <nl> command . addexecpaths ( " - - classpath_resources " , classpathresources ) ; <nl> } <nl> - paramfileinfo paramfileinfo = null ; <nl> - <nl> - / / most resource jar actions are very small and expanding the argument list for <nl> - / / paramfilehelper # getparamsfilemaybe is expensive , so avoid doing that work if <nl> - / / we definitely don ' t need a params file . <nl> - / / this heuristic could be much more aggressive , but we don ' t ever want to skip <nl> - / / the params file in situations where it is required for - - min_param_file_size . <nl> - if ( sizegreaterthanorequal ( <nl> - iterables . concat ( messages , resources . values ( ) , resourcejars , classpathresources ) , num ) <nl> - | | rulecontext . getconfiguration ( ) . getcommandlinelimits ( ) . maxlength < num ) { <nl> - paramfileinfo = paramfileinfo . builder ( parameterfiletype . shell_quoted ) . build ( ) ; <nl> - } <nl> rulecontext . registeraction ( <nl> builder <nl> . addoutput ( outputjar ) <nl>
public class androiddatacontext implements androiddatacontextapi { <nl> androidsdkprovider . fromrulecontext ( rulecontext ) , <nl> hasexemption ( rulecontext , " allow_raw_access_to_resource_paths " , false ) , <nl> hasexemption ( rulecontext , " allow_resource_name_obfuscation_opt_out " , false ) , <nl> - <nl> - / / including a semantic change . <nl> - hasexemption ( rulecontext , " allow_resource_shrinking_opt_out " , false ) , <nl> + ! hasexemption ( rulecontext , " allow_shrink_resources_attribute " , true ) , <nl> ! hasexemption ( rulecontext , " allow_proguard_apply_dictionary " , true ) , <nl> ! hasexemption ( rulecontext , " allow_proguard_apply_mapping " , true ) , <nl> ! hasexemption ( rulecontext , " allow_resource_conflicts " , true ) , <nl>
public class androiddatacontext implements androiddatacontextapi { <nl> return optoutofresourcenameobfuscation ; <nl> } <nl>  <nl> - <nl> - / / a semantic change . <nl> - public boolean optoutofresourceshrinking ( ) { <nl> - return optoutofresourceshrinking ; <nl> + public boolean throwonshrinkresources ( ) { <nl> + return throwonshrinkresources ; <nl> } <nl>  <nl> public boolean throwonproguardapplydictionary ( ) { <nl>
public class androidcompileddatadeserializer implements androiddatadeserializer <nl> resourcetype resourcetype = resourcetype . getenum ( resourceformattype . getname ( ) ) ; <nl>  <nl> for ( resources . entry resource : resourceformattype . getentrylist ( ) ) { <nl> - if ( resource . getconfigvaluelist ( ) . isempty ( ) <nl> - & & resource . getvisibility ( ) . getlevel ( ) = = level . public ) { <nl> - fullyqualifiedname fqn = <nl> - createandrecordfqn ( <nl> - packageresolver , packagename , resourcetype , resource , immutablelist . of ( ) ) ; <nl> - <nl> - / / this is a public resource definition . <nl> - int sourceindex = resource . getvisibility ( ) . getsource ( ) . getpathidx ( ) ; <nl> - string source = sourcepool . get ( sourceindex ) ; <nl> - datasource datasource = datasource . of ( dependencyinfo , paths . get ( source ) ) ; <nl> - <nl> - dataresourcexml dataresourcexml = <nl> - dataresourcexml . frompublic ( datasource , resourcetype , resource . getentryid ( ) . getid ( ) ) ; <nl> - <nl> - <nl> - consumers . combiningconsumer . accept ( fqn , dataresourcexml ) ; <nl> - } else if ( ! " android " . equals ( packagename ) ) { <nl> + if ( ! " android " . equals ( packagename ) ) { <nl> / / this means this resource is not in the android sdk , add it to the set . <nl> for ( configvalue configvalue : resource . getconfigvaluelist ( ) ) { <nl> fullyqualifiedname fqn =
public class androiddatacontext implements androiddatacontextapi { <nl> androidsdkprovider . fromrulecontext ( rulecontext ) , <nl> hasexemption ( rulecontext , " allow_raw_access_to_resource_paths " , false ) , <nl> hasexemption ( rulecontext , " allow_resource_name_obfuscation_opt_out " , false ) , <nl> - <nl> - / / including a semantic change . <nl> - hasexemption ( rulecontext , " allow_resource_shrinking_opt_out " , false ) , <nl> + ! hasexemption ( rulecontext , " allow_shrink_resources_attribute " , true ) , <nl> ! hasexemption ( rulecontext , " allow_proguard_apply_dictionary " , true ) , <nl> ! hasexemption ( rulecontext , " allow_proguard_apply_mapping " , true ) , <nl> ! hasexemption ( rulecontext , " allow_resource_conflicts " , true ) , <nl>
public class androiddatacontext implements androiddatacontextapi { <nl> return optoutofresourcenameobfuscation ; <nl> } <nl>  <nl> - <nl> - / / a semantic change . <nl> - public boolean optoutofresourceshrinking ( ) { <nl> - return optoutofresourceshrinking ; <nl> + public boolean throwonshrinkresources ( ) { <nl> + return throwonshrinkresources ; <nl> } <nl>  <nl> public boolean throwonproguardapplydictionary ( ) { <nl>
public class cpphelper { <nl> preconditions . checknotnull ( <nl> rulecontext . getconfiguration ( ) . getoptions ( ) . get ( cppoptions . class ) ) ; <nl>  <nl> - if ( cppoptions . enablecctoolchainresolution ) { <nl> - return true ; <nl> - } <nl> - <nl> - <nl> - platformconfiguration platformconfig = <nl> - preconditions . checknotnull ( rulecontext . getfragment ( platformconfiguration . class ) ) ; <nl> - return platformconfig . istoolchaintypeenabled ( gettoolchaintypefromruleclass ( rulecontext ) ) ; <nl> + return cppoptions . enablecctoolchainresolution ; <nl> } <nl>  <nl> public static immutablelist < cccompilationcontext > getcompilationcontextsfromdeps (
py_binary ( <nl> py_binary ( <nl> name = " incremental_install " , <nl> srcs = [ " incremental_install . py " ] , <nl> - # <nl> - python_version = " py2 " , <nl> + python_version = py_binary_version , <nl> deps = [ <nl> " / / third_party / py / concurrent : futures " , <nl> " / / third_party / py / abseil " , <nl>
py_binary ( <nl> py_binary ( <nl> name = " strip_resources " , <nl> srcs = [ " strip_resources . py " ] , <nl> - # <nl> - python_version = " py2 " , <nl> + python_version = py_binary_version , <nl> deps = [ <nl> " / / third_party / py / abseil " , <nl> ] , <nl>
py_binary ( <nl> srcs = [ <nl> " aar_native_libs_zip_creator . py " , <nl> ] , <nl> - # <nl> - python_version = " py2 " , <nl> + python_version = py_binary_version , <nl> deps = [ <nl> " : junction_lib " , <nl> " / / third_party / py / abseil " , <nl>
py_binary ( <nl> py_binary ( <nl> name = " stubify_manifest " , <nl> srcs = [ " stubify_manifest . py " ] , <nl> - # <nl> - python_version = " py2 " , <nl> + python_version = py_binary_version , <nl> deps = [ <nl> " / / third_party / py / abseil " , <nl> ] , <nl>
py_binary ( <nl> py_binary ( <nl> name = " aar_embedded_jars_extractor " , <nl> srcs = [ " aar_embedded_jars_extractor . py " ] , <nl> - # <nl> - python_version = " py2 " , <nl> + python_version = py_binary_version , <nl> deps = [ <nl> " : junction_lib " , <nl> " / / third_party / py / abseil " , <nl>
py_binary ( <nl> py_binary ( <nl> name = " aar_resources_extractor " , <nl> srcs = [ " aar_resources_extractor . py " ] , <nl> - # <nl> - python_version = " py2 " , <nl> + python_version = py_binary_version , <nl> deps = [ <nl> " : junction_lib " , <nl> " / / third_party / py / abseil " , <nl>
py_binary ( <nl> py_binary ( <nl> name = " resource_extractor " , <nl> srcs = [ " resource_extractor . py " ] , <nl> - # <nl> - python_version = " py2 " , <nl> + python_version = py_binary_version , <nl> ) <nl>  <nl> py_library (
genrule ( <nl> ) <nl> eof <nl>  <nl> - # <nl> - # network sandboxing works on macos . <nl> - case " $ ( uname - s ) " in <nl> - darwin ) remote_network_address = ; ; <nl> - esac <nl> - <nl> if [ [ - n " $ { remote_network_address } " ] ] ; then <nl> local hostname = " $ { remote_network_address % : * } " <nl> local remote_ip
public class skylarknativemodule implements skylarknativemoduleapi { <nl> } <nl>  <nl> / * * <nl> - * converts back to type that will work in build and skylark , such as string instead of label , <nl> - * skylarklist instead of list , returns null if we don ' t want to export the value . <nl> + * converts a target attribute value to a starlark value for return in { @ code <nl> + * native . existing_rule ( ) } or { @ code native . existing_rules ( ) } . <nl> * <nl> - * < p > all of the types returned are immutable . if we want , we can change this to immutable in the <nl> - * future , but this is the safe choice for now . <nl> + * < p > all returned values are immutable . <nl> + * <nl> + * @ return the value , or null if we don ' t want to export it to the user . <nl> + * @ throws notrepresentableexception if an unknown type is encountered . <nl> * / <nl> @ nullable <nl> private static object skylarkifyvalue ( object val , package pkg ) throws notrepresentableexception { <nl> - <nl> - / / from java native types to skylark types should be part of the type class hierarchy , <nl> if ( val = = null ) { <nl> return null ; <nl> } <nl>
sh_test ( <nl> size = " small " , <nl> srcs = [ " sha256_test . sh " ] , <nl> data = [ " sha256 " ] , <nl> - # <nl> - # https : / / github . com / bazelbuild / bazel / issues / 4460 is fixed for sh_ * <nl> - tags = [ " no_windows " ] , <nl> + deps = [ " @ bazel_tools / / tools / bash / runfiles " ] , <nl> ) <nl>  <nl> test_suite ( <nl> mmm a / tools / build_defs / hash / sha256_test . sh <nl> ppp b / tools / build_defs / hash / sha256_test . sh <nl>
public final class loadstatement extends statement { <nl> return orig ; <nl> } <nl>  <nl> - <nl> - public binding ( identifier localname , identifier originalname ) { <nl> + binding ( identifier localname , identifier originalname ) { <nl> this . local = localname ; <nl> this . orig = originalname ; <nl> } <nl>
public final class loadstatement extends statement { <nl> * < p > import statements generated this way are bound to the usual restriction that private symbols <nl> * cannot be loaded . <nl> * / <nl> - <nl> - public loadstatement ( stringliteral imp , list < binding > bindings ) { <nl> + loadstatement ( stringliteral imp , list < binding > bindings ) { <nl> this . imp = imp ; <nl> this . bindings = immutablelist . copyof ( bindings ) ; <nl> this . mayloadinternalsymbols = false ;
public final class pycommon { <nl> if ( ! rulecontext . getfragment ( pythonconfiguration . class ) . usenewpyversionsemantics ( ) ) { <nl> return false ; <nl> } <nl> - <nl> string errortemplate = <nl> " this target is being built for python % s but ( transitively ) includes python % s - only " <nl> + " sources . you can get diagnostic information about which dependencies introduce this " <nl> + " version requirement by running the ` find_requirements ` aspect . for more info see " <nl> + " the documentation for the ` srcs_version ` attribute : " <nl> - + " https : / / docs . bazel . build / versions / master / be / python . html # py_binary . srcs_version " ; <nl> + + semantics . getsrcsversiondocurl ( ) ; <nl>  <nl> string error = null ; <nl> if ( version = = pythonversion . py2 & & haspy3onlysources ) { <nl> mmm a / src / main / java / com / google / devtools / build / lib / rules / python / pythonsemantics . java <nl> ppp b / src / main / java / com / google / devtools / build / lib / rules / python / pythonsemantics . java <nl>
public interface configgloballibraryapi { <nl>  <nl> @ skylarkcallable ( <nl> name = " analysis_test_transition " , <nl> - <nl> - / / non - experimental . <nl> doc = <nl> - " < b > experimental . this type is experimental and subject to change at any time . do " <nl> - + " not depend on it . < / b > < p > creates a configuration transition to be applied on " <nl> + " < p > creates a configuration transition to be applied on " <nl> + " an analysis - test rule ' s dependencies . this transition may only be applied " <nl> - + " on attributes of rules with < code > analysis_test = true < / code > . " , <nl> + + " on attributes of rules with < code > analysis_test = true < / code > . such rules are " <nl> + + " restricted in capabilities ( for example , the size of their dependency tree is " <nl> + + " limited ) , so transitions created using this function are limited in potential " <nl> + + " scope as compared to transitions created using " <nl> + + " < a href = \ " # transition \ " > transition < / a > . " , <nl> parameters = { <nl> @ param ( <nl> name = " settings " ,
final class realsandboxfsprocess implements sandboxfsprocess { <nl> return process ! = null & & ! process . finished ( ) ; <nl> } <nl>  <nl> - / * * <nl> - * destroys a process and waits for it to exit . <nl> - * <nl> - * @ param process the process to destroy <nl> - * / <nl> - <nl> - / / of uninterruptibles . calluninterruptibly that takes a lambda instead of a callable . <nl> - private static void destroyprocess ( subprocess process ) { <nl> - process . destroyandwait ( ) ; <nl> - } <nl> - <nl> @ override <nl> public synchronized void destroy ( ) { <nl> if ( shutdownhook ! = null ) { <nl>
public class protoresourceusageanalyzer extends resourceusageanalyzer { <nl> immutablelist < string > resourceconfigs = <nl> resources . stream ( ) <nl> . filter ( resource : : iskeep ) <nl> - <nl> - . map ( r - > string . format ( " % s / % s # no_obfuscate " , r . type . getname ( ) , r . name ) ) <nl> + . map ( r - > string . format ( " % s / % s # no_collapse " , r . type . getname ( ) , r . name ) ) <nl> . collect ( toimmutablelist ( ) ) ; <nl> files . write ( resourcesconfigfile , resourceconfigs , standardcharsets . utf_8 ) ;
import java . util . list ; <nl> public interface configgloballibraryapi { <nl> @ skylarkcallable ( <nl> name = " transition " , <nl> - <nl> - / / non - experimental . <nl> doc = <nl> - " < b > experimental . this type is experimental and subject to change at any time . do " <nl> - + " not depend on it . < / b > < p > creates a configuration transition to be applied across " <nl> - + " a dependency edge . " , <nl> + " a transition that reads a set of input build settings and writes a set of output build " <nl> + + " settings . " <nl> + + " < p > example : < / p > " <nl> + + " < p > < pre class = \ " language - python \ " > \n " <nl> + + " def _transition_impl ( settings , attr ) : \n " <nl> + + " # this transition just reads the current cpu value as a demonstration . \n " <nl> + + " # a real transition could incorporate this into its followup logic . \n " <nl> + + " current_cpu = settings [ \ " / / command_line_option : cpu \ " ] \n " <nl> + + " return { \ " / / command_line_option : compilation_mode \ " : \ " dbg \ " } \n " <nl> + + " \n " <nl> + + " build_in_debug_mode = transition ( \n " <nl> + + " implementation = _transition_impl , \n " <nl> + + " inputs = [ \ " / / command_line_option : cpu \ " ] , \n " <nl> + + " outputs = [ \ " / / command_line_option : compilation_mode \ " ] , \n " <nl> + + " ) " <nl> + + " < / pre > < / p > " <nl> + + " < p > for more details see < a href = \ " . . / config . html # user - defined - transitions \ " > " <nl> + + " here < / a > . < / p > " , <nl> parameters = { <nl> @ param ( <nl> name = " implementation " ,
flavor ( <nl> ) <nl> ` ` ` <nl>  <nl> - <nl> - cases where the implementation just fowards the value . <nl> + a collection of the most common build setting rules can be found in <nl> + - - > <nl> + [ skylib ] ( https : / / github . com / bazelbuild / bazel - skylib / blob / master / rules / common_settings . bzl ) . <nl>  <nl> # # # using build settings
java_library ( <nl> ) <nl>  <nl> # the starlark evaluator <nl> - # <nl> - # <nl> - # node is the main blocker . <nl> java_library ( <nl> name = " evaluator " , <nl> - srcs = glob ( <nl> - [ " * . java " ] , <nl> - exclude = frontend_files , <nl> - ) , <nl> + srcs = [ <nl> + " basefunction . java " , <nl> + " builtincallable . java " , <nl> + " builtinfunction . java " , <nl> + " callutils . java " , <nl> + " callstack . java " , <nl> + " classobject . java " , <nl> + " concatable . java " , <nl> + " debugframe . java " , <nl> + " debugger . java " , <nl> + " eval . java " , <nl> + " evalexception . java " , <nl> + " evalexceptionwithstacktrace . java " , <nl> + " evalutils . java " , <nl> + " flagguardedvalue . java " , <nl> + " formatparser . java " , <nl> + " functionsignature . java " , <nl> + " methoddescriptor . java " , <nl> + " methodlibrary . java " , <nl> + " mutability . java " , <nl> + " paramdescriptor . java " , <nl> + " paramtypedescriptor . java " , <nl> + " printer . java " , <nl> + " rangelist . java " , <nl> + " runtime . java " , <nl> + " selectorlist . java " , <nl> + " selectorvalue . java " , <nl> + " skylarkclassobject . java " , <nl> + " skylarkdict . java " , <nl> + " skylarkindexable . java " , <nl> + " skylarklist . java " , <nl> + " skylarknestedset . java " , <nl> + " skylarkqueryable . java " , <nl> + " skylarksignatureprocessor . java " , <nl> + " skylarktype . java " , <nl> + " skylarkutils . java " , <nl> + " starlarkcallable . java " , <nl> + " starlarkfunction . java " , <nl> + " starlarkmutable . java " , <nl> + " starlarkthread . java " , <nl> + " stringmodule . java " , <nl> + ] , <nl> deps = [ <nl> " : frontend " , <nl> " / / src / main / java / com / google / devtools / build / lib : events " ,
public class testrunneraction extends abstractaction <nl> env . put ( " coverage_manifest " , getcoveragemanifest ( ) . getexecpathstring ( ) ) ; <nl> env . put ( " coverage_dir " , getcoveragedirectory ( ) . getpathstring ( ) ) ; <nl> env . put ( " coverage_output_file " , getcoveragedata ( ) . getexecpathstring ( ) ) ; <nl> - <nl> - / / between the blaze release and the lcov_merger release . <nl> - env . put ( " new_java_coverage_impl " , " released " ) ; <nl> } <nl> }
import com . google . devtools . build . lib . events . location ; <nl> / * * <nl> * a simple interface for the starlark interpreter to notify a debugger of events during execution . <nl> * / <nl> - <nl> - public interface debugserver { <nl> + public interface debugger { <nl>  <nl> / * * notify the debugger that execution is at the point immediately before { @ code loc } . * / <nl> void before ( environment env , location loc ) ; <nl> mmm a / src / main / java / com / google / devtools / build / lib / syntax / eval . java <nl> ppp b / src / main / java / com / google / devtools / build / lib / syntax / eval . java <nl>
public class androiddatacontext implements androiddatacontextapi { <nl> / / num ) - - experimental_android_resource_name_obfuscation <nl> / / num ) - c opt <nl> / / num ) resource shrinking is on <nl> - <nl> return getandroidconfig ( ) . useandroidresourcenameobfuscation ( ) <nl> & & getactionconstructioncontext ( ) . getconfiguration ( ) . getcompilationmode ( ) = = opt <nl> - & & useresourceshrinking ( ) ; <nl> + & & useresourceshrinking ( ) <nl> + & & compatibleforresourcenameobfuscation ; <nl> } <nl> }
public abstract class statement extends astnode { <nl> * can be used in a switch / case . <nl> * / <nl> public abstract kind kind ( ) ; <nl> - <nl> - / * * parses a statement . * / <nl> - <nl> - public static statement parse ( parserinputsource input , eventhandler eventhandler ) { <nl> - return parser . parsestatement ( input , eventhandler ) ; <nl> - } <nl> } <nl> mmm a / src / test / java / com / google / devtools / build / lib / syntax / util / evaluationtestcase . java <nl> ppp b / src / test / java / com / google / devtools / build / lib / syntax / util / evaluationtestcase . java <nl>
public class buildfileast extends astnode { <nl> result . stringescapeevents ) ; <nl> } <nl>  <nl> - / * * <nl> - * temporary alias for parsewithoutimports , as , maddeningly , we cannot atomically change our api <nl> - * and copybara ' s use of it . <nl> - * / <nl> - public static buildfileast parseskylarkfilewithoutimports ( <nl> - parserinputsource input , eventhandler handler ) { <nl> - return parsewithoutimports ( input , handler ) ; <nl> - } <nl> - <nl> / * * <nl> * run static checks on the syntax tree . <nl> *
final class parser { <nl> / / | def_stmt <nl> / / | for_stmt <nl> / / | if_stmt <nl> + / / | load_stmt <nl> private void parsestatement ( list < statement > list ) { <nl> - <nl> if ( token . kind = = tokenkind . def ) { <nl> - parsefunctiondefstatement ( list ) ; <nl> + list . add ( parsefunctiondefstatement ( ) ) ; <nl> } else if ( token . kind = = tokenkind . if ) { <nl> list . add ( parseifstatement ( ) ) ; <nl> } else if ( token . kind = = tokenkind . for ) { <nl> - parseforstatement ( list ) ; <nl> + list . add ( parseforstatement ( ) ) ; <nl> } else if ( token . kind = = tokenkind . load ) { <nl> - parseloadstatement ( list ) ; <nl> + parseloadstatement ( list ) ; / / may add nothing <nl> } else { <nl> parsesimplestatement ( list ) ; <nl> } <nl>
public final class commandinterruptiontest { <nl> synchronizewithcommand ( ) ; <nl> assertwithmessage ( " the command should have been finished , but it was not . " ) <nl> . that ( result . isdone ( ) ) . istrue ( ) ; <nl> - <nl> - assertthat ( result . get ( ) ) . isequalto ( exitcode . getnumericexitcode ( ) ) ; <nl> + assertthat ( futures . getdone ( result ) ) . isequalto ( exitcode . getnumericexitcode ( ) ) ; <nl> } <nl>  <nl> / * * asserts that the command has not finished yet . * /
eof <nl> function test_downloads_minimal_failure ( ) { <nl> # test that outputs of failing actions are downloaded when using <nl> # - - remote_download_minimal <nl> - if [ [ " $ platform " = = " darwin " ] ] ; then <nl> - # <nl> - # setting sdkroot and developer_dir appropriately , as is required of <nl> - # action executors in order to select the appropriate xcode toolchain . <nl> - return num <nl> - fi <nl> - <nl> mkdir - p a <nl> cat > a / build < < ' eof ' <nl> genrule ( <nl>
static void runservermode ( <nl>  <nl> bazel_log ( info ) < < " running in server mode . " ; <nl>  <nl> - <nl> if ( server - > connected ( ) ) { <nl> - server - > killrunningserver ( ) ; <nl> + bazel_die ( blaze_exit_code : : local_environmental_error ) <nl> + < < " exec - server failed , please shut down existing server pid = " <nl> + < < server - > processinfo ( ) . server_pid_ < < " and retry . " ; <nl> } <nl>  <nl> ensureserverdir ( server_dir ) ;
public class skylarkruleclassfunctions implements skylarkrulefunctionsapi < artifa <nl> hosttransition . instance , <nl> immutableset . copyof ( hostfragments . getcontents ( string . class , " host_fragments " ) ) , <nl> collecttoolchainlabels ( <nl> - toolchains . getcontents ( string . class , " toolchains " ) , <nl> - ast . getlocation ( ) , <nl> - <nl> - / / repository mapping from a context , like in rule ( ) . <nl> - immutablemap . of ( ) ) ) ; <nl> + toolchains . getcontents ( string . class , " toolchains " ) , ast . getlocation ( ) , repomapping ) ) ; <nl> } <nl>  <nl> / * * <nl> mmm a / src / main / java / com / google / devtools / build / lib / skylarkbuildapi / skylarkrulefunctionsapi . java <nl> ppp b / src / main / java / com / google / devtools / build / lib / skylarkbuildapi / skylarkrulefunctionsapi . java <nl>
import org . objectweb . asm . tree . methodnode ; <nl> * / <nl> public class defaultmethodclassfixer extends classvisitor { <nl>  <nl> - / * * don ' t expect base classes for android things apis ( preinstalled but not in android . jar ) . * / <nl> - <nl> - private static final string unavailable_baseclasses_prefix = " com / google / android / things / pio / " ; <nl> - <nl> private final boolean usegeneratedbaseclasses ; <nl> private final classreaderfactory classpath ; <nl> private final classreaderfactory bootclasspath ; <nl>
public class grpcremotecache extends abstractremoteactioncache { <nl> uploader . uploadblobs ( filestoupload , / * forceupload = * / true ) ; <nl> } <nl>  <nl> - <nl> - if ( outerr . geterrorpath ( ) . exists ( ) ) { <nl> - digest stderr = uploadfilecontents ( outerr . geterrorpath ( ) ) ; <nl> - result . setstderrdigest ( stderr ) ; <nl> + if ( manifest . getstderrdigest ( ) ! = null ) { <nl> + result . setstderrdigest ( manifest . getstderrdigest ( ) ) ; <nl> } <nl> - if ( outerr . getoutputpath ( ) . exists ( ) ) { <nl> - digest stdout = uploadfilecontents ( outerr . getoutputpath ( ) ) ; <nl> - result . setstdoutdigest ( stdout ) ; <nl> + if ( manifest . getstdoutdigest ( ) ! = null ) { <nl> + result . setstdoutdigest ( manifest . getstdoutdigest ( ) ) ; <nl> } <nl> } <nl> - <nl> - / * * <nl> - * put the file contents cache if it is not already in it . no - op if the file is already stored in <nl> - * cache . the given path must be a full absolute path . <nl> - * <nl> - * @ return the key for fetching the file contents blob from cache . <nl> - * / <nl> - private digest uploadfilecontents ( path file ) throws ioexception , interruptedexception { <nl> - digest digest = digestutil . compute ( file ) ; <nl> - immutableset < digest > missing = getmissingdigests ( immutablelist . of ( digest ) ) ; <nl> - if ( ! missing . isempty ( ) ) { <nl> - uploader . uploadblob ( <nl> - hashcode . fromstring ( digest . gethash ( ) ) , <nl> - chunker . builder ( ) . setinput ( digest . getsizebytes ( ) , file ) . build ( ) , <nl> - / * forceupload = * / true ) ; <nl> - } <nl> - return digest ; <nl> - } <nl>  <nl> / / execution cache api
public class grpcremotecache extends abstractremoteactioncache { <nl> uploader . uploadblobs ( filestoupload , / * forceupload = * / true ) ; <nl> } <nl>  <nl> - <nl> - if ( outerr . geterrorpath ( ) . exists ( ) ) { <nl> - digest stderr = uploadfilecontents ( outerr . geterrorpath ( ) ) ; <nl> - result . setstderrdigest ( stderr ) ; <nl> + if ( manifest . getstderrdigest ( ) ! = null ) { <nl> + result . setstderrdigest ( manifest . getstderrdigest ( ) ) ; <nl> } <nl> - if ( outerr . getoutputpath ( ) . exists ( ) ) { <nl> - digest stdout = uploadfilecontents ( outerr . getoutputpath ( ) ) ; <nl> - result . setstdoutdigest ( stdout ) ; <nl> + if ( manifest . getstdoutdigest ( ) ! = null ) { <nl> + result . setstdoutdigest ( manifest . getstdoutdigest ( ) ) ; <nl> } <nl> } <nl> - <nl> - / * * <nl> - * put the file contents cache if it is not already in it . no - op if the file is already stored in <nl> - * cache . the given path must be a full absolute path . <nl> - * <nl> - * @ return the key for fetching the file contents blob from cache . <nl> - * / <nl> - private digest uploadfilecontents ( path file ) throws ioexception , interruptedexception { <nl> - digest digest = digestutil . compute ( file ) ; <nl> - immutableset < digest > missing = getmissingdigests ( immutablelist . of ( digest ) ) ; <nl> - if ( ! missing . isempty ( ) ) { <nl> - uploader . uploadblob ( <nl> - hashcode . fromstring ( digest . gethash ( ) ) , <nl> - chunker . builder ( ) . setinput ( digest . getsizebytes ( ) , file ) . build ( ) , <nl> - / * forceupload = * / true ) ; <nl> - } <nl> - return digest ; <nl> - } <nl>  <nl> / / execution cache api
public class commoncommandoptions extends optionsbase { <nl> + " too large . " ) <nl> public boolean enablejsonprofilediet ; <nl>  <nl> - <nl> - @ option ( <nl> - name = " experimental_json_profile_metadata " , <nl> - defaultvalue = " true " , <nl> - documentationcategory = optiondocumentationcategory . logging , <nl> - effecttags = { optioneffecttag . affects_outputs , optioneffecttag . bazel_monitoring } , <nl> - metadatatags = { optionmetadatatag . deprecated } , <nl> - help = " deprecated no - op . " ) <nl> - public boolean enablejsonmetadata ; <nl> - <nl> @ option ( <nl> name = " profile " , <nl> defaultvalue = " null " ,
public class skydocmain { <nl> immutableset < string > symbolnames ; <nl> immutablelist < string > deproots ; <nl>  <nl> - <nl> - list < string > residualargs = parser . getresidue ( ) ; <nl> if ( strings . isnullorempty ( skydocoptions . targetfilelabel ) <nl> | | strings . isnullorempty ( skydocoptions . outputfilepath ) ) { <nl> - if ( residualargs . size ( ) < num ) { <nl> - throw new illegalargumentexception ( <nl> - " expected two or more arguments . usage : \n " <nl> - + " { skydoc_bin } { target_skylark_file_label } { output_file } [ symbol_names ] . . . " ) ; <nl> - } <nl> - <nl> - targetfilelabelstring = residualargs . get ( 0 ) ; <nl> - outputpath = residualargs . get ( 1 ) ; <nl> - symbolnames = getsymbolnames ( residualargs ) ; <nl> - deproots = immutablelist . of ( ) ; <nl> - } else { <nl> - targetfilelabelstring = skydocoptions . targetfilelabel ; <nl> - outputpath = skydocoptions . outputfilepath ; <nl> - symbolnames = immutableset . copyof ( skydocoptions . symbolnames ) ; <nl> - deproots = immutablelist . copyof ( skydocoptions . deproots ) ; <nl> + throw new illegalargumentexception ( " expected a target file label and an output file path . " ) ; <nl> } <nl>  <nl> + targetfilelabelstring = skydocoptions . targetfilelabel ; <nl> + outputpath = skydocoptions . outputfilepath ; <nl> + symbolnames = immutableset . copyof ( skydocoptions . symbolnames ) ; <nl> + deproots = immutablelist . copyof ( skydocoptions . deproots ) ; <nl> + <nl> label targetfilelabel = label . parseabsolute ( targetfilelabelstring , immutablemap . of ( ) ) ; <nl>  <nl> immutablemap . builder < string , ruleinfo > ruleinfomap = immutablemap . builder ( ) ; <nl>
class argtokenstream { <nl> class filetokenstream { <nl> public : <nl> filetokenstream ( const char * filename ) { <nl> - <nl> - / / implementations from protobuf , in order to support long paths : <nl> - / / https : / / github . com / google / protobuf / blob / <nl> - / / <commit_id> / <nl> - / / src / google / protobuf / stubs / io_win32 . cc <nl> - / / best would be to extract that library to a common location and use <nl> - / / here , in protobuf , and in bazel itself . <nl> - if ( ! ( fp_ = fopen ( filename , " r " ) ) ) { <nl> + # ifdef _win32 <nl> + std : : wstring wpath ; <nl> + std : : string error ; <nl> + if ( ! blaze_util : : asabsolutewindowspath ( filename , & wpath , & error ) ) { <nl> + diag_err ( 1 , " % s : % d : asabsolutewindowspath failed : % s " , __file__ , <nl> + __line__ , error . c_str ( ) ) ; <nl> + } <nl> + fp_ = _wfopen ( wpath . c_str ( ) , l " r " ) ; <nl> + # else <nl> + fp_ = fopen ( filename , " r " ) ; <nl> + # endif <nl> + <nl> + if ( ! fp_ ) { <nl> diag_err ( 1 , " % s " , filename ) ; <nl> } <nl> filename_ = filename ; <nl> mmm a / src / tools / singlejar / token_stream_test . cc <nl> ppp b / src / tools / singlejar / token_stream_test . cc <nl>
function test_glob_control_chars ( ) { <nl> done <nl> } <nl>  <nl> - # <nl> - function disabled_test_glob_utf8 ( ) { <nl> + function test_glob_utf8 ( ) { <nl> local - r pkg = " $ funcname " <nl> mkdir $ pkg <nl> echo " filegroup ( name = ' t ' , srcs = glob ( [ ' * ' ] ) ) " > $ pkg / build <nl> cd $ pkg <nl> - perl - cs - e ' for $ i ( 160 . . 0xd7ff ) { print chr $ i , $ i % 80 ? " " : " \n " } ' | xargs touch <nl> + # this might print error messages for individual file names on systems like <nl> + # macos that use a file system that only permits correct utf - 8 strings as file <nl> + # names . the errors can be ignored - we just test with whatever files the os <nl> + # allowed us to create . <nl> + perl - cs - e ' for $ i ( 160 . . 0xd7ff ) { print chr $ i , $ i % 20 ? " " : " \n " } ' | xargs touch | | true <nl> cd . . <nl> bazel query " / / $ pkg : * " > & $ test_log | | fail " expected success " <nl> }
public class androidconfiguration extends buildconfiguration . fragment <nl> androidaaptversion flag = datacontext . getandroidconfig ( ) . getandroidaaptversion ( ) ; <nl> androidaaptversion attribute = androidaaptversion . fromstring ( attributestring ) ; <nl>  <nl> - androidaaptversion version = flag = = androidaaptversion . auto ? attribute : flag ; <nl> + androidaaptversion version = flag = = auto ? attribute : flag ; <nl>  <nl> if ( version = = aapt2 & & ! hasaapt2 ) { <nl> throw errorconsumer . throwwithruleerror ( <nl> " aapt2 processing requested but not available on the android_sdk " ) ; <nl> } <nl>  <nl> - if ( version ! = androidaaptversion . auto ) { <nl> - return version ; <nl> + if ( version = = auto ) { <nl> + return aapt ; <nl> } <nl>  <nl> - / / at this point , the version is still auto . if the user passes <nl> - / / - - incompatible_use_aapt2_by_default explicitly or implicitly via <nl> - / / - - all_incompatible_changes , use aapt2 by default . <nl> - / / <nl> - / / we use the - - incompatible_use_aapt2_by_default flag to signal a breaking change in bazel . <nl> - / / this is required by the bazel incompatible changes policy . <nl> - / / <nl> - <nl> - / / complete and the default value of - - android_aapt is switched from ` auto ` to ` aapt2 ` . <nl> - return datacontext . getandroidconfig ( ) . incompatiblechangeuseaapt2bydefault ( ) ? aapt2 : aapt ; <nl> + return version ; <nl> } <nl> } <nl>  <nl>
int main ( int argc , const char * argv [ ] , workspacelayout * workspace_layout , <nl> const string workspace = workspace_layout - > getworkspace ( cwd ) ; <nl> parseoptionsordie ( cwd , workspace , * option_processor , argc , argv ) ; <nl> startupoptions * startup_options = option_processor - > getparsedstartupoptions ( ) ; <nl> + startup_options - > maybelogstartupoptionwarnings ( ) ; <nl>  <nl> setdebuglog ( startup_options - > client_debug ) ; <nl> / / if client_debug was false , this is ignored , so it ' s accurate . <nl> bazel_log ( info ) < < " debug logging requested , sending all client log " <nl> " statements to stderr " ; <nl> - <nl> - / / warning might get swallowed . once the bug is fixed , move this call to <nl> - / / optionprocessor : : parseoptionsordie where the order of operations is more <nl> - / / clear . <nl> - startup_options - > maybelogstartupoptionwarnings ( ) ; <nl>  <nl> if ( startup_options - > unlimit_coredumps ) { <nl> unlimitcoredumps ( ) ;
public final class objcprovider extends info implements objcproviderapi < artifact <nl> * / <nl> void addelementsfromskylark ( key < ? > key , object skylarktoadd ) throws evalexception { <nl> nestedset < ? > toadd = objcproviderskylarkconverters . converttojava ( key , skylarktoadd ) ; <nl> - <nl> - uncheckedaddall ( key , toadd . tolist ( ) , this . items ) ; <nl> + uncheckedaddtransitive ( key , toadd , this . items ) ; <nl> if ( objcprovider . keys_for_direct . contains ( key ) ) { <nl> uncheckedaddalldirect ( key , toadd , this . directitems ) ; <nl> }
public enum compilebuildvariables { <nl> buildoptions buildoptions , <nl> cppconfiguration cppconfiguration , <nl> string sourcefile , <nl> - <nl> - / / updated . <nl> string outputfile , <nl> string gcnofile , <nl> boolean isusingfission , <nl>
public enum compilebuildvariables { <nl> string fakeoutputfileorrealoutputfile = fakeoutputfile ! = null ? fakeoutputfile : outputfile ; <nl>  <nl> if ( outputfile ! = null ) { <nl> - <nl> - / / updated . <nl> - if ( ! filetype . contains ( <nl> - pathfragment . create ( outputfile ) , <nl> - cppfiletypes . assembler , <nl> - cppfiletypes . pic_assembler , <nl> - cppfiletypes . preprocessed_c , <nl> - cppfiletypes . preprocessed_cpp , <nl> - cppfiletypes . pic_preprocessed_c , <nl> - cppfiletypes . pic_preprocessed_cpp ) ) { <nl> - buildvariables . addstringvariable ( <nl> - output_object_file . getvariablename ( ) , fakeoutputfileorrealoutputfile ) ; <nl> - } <nl> - <nl> buildvariables . addstringvariable ( <nl> output_file . getvariablename ( ) , fakeoutputfileorrealoutputfile ) ; <nl> } <nl> mmm a / src / main / java / com / google / devtools / build / lib / rules / cpp / cppcompileactiontemplate . java <nl> ppp b / src / main / java / com / google / devtools / build / lib / rules / cpp / cppcompileactiontemplate . java <nl>
public final class configuredtargetfactory { <nl> preconditions . checkstate ( ! missingfragments . isempty ( ) ) ; <nl> stringbuilder result = new stringbuilder ( ) ; <nl> result . append ( " all rules of type " + ruleclass . getname ( ) + " require the presence of " ) ; <nl> - list < string > names = new arraylist < > ( ) ; <nl> - for ( class < ? > fragment : missingfragments ) { <nl> - <nl> - / / better right now . <nl> - names . add ( fragment . getsimplename ( ) ) ; <nl> - } <nl> result . append ( " all of [ " ) ; <nl> - joiner . on ( " , " ) . appendto ( result , names ) ; <nl> - result . append ( " ] , but these were all disabled " ) ; <nl> + result . append ( <nl> + missingfragments . stream ( ) . map ( class : : getsimplename ) . collect ( collectors . joining ( " , " ) ) ) ; <nl> + result . append ( " ] , but these were all disabled in configuration " ) . append ( configurationid ) ; <nl> return result . tostring ( ) ; <nl> }
<nl> mmm <nl> platforms : <nl> - ubuntu1404 : <nl> - shell_commands : <nl> - - sed - i . bak - e ' s / ^ # android_sdk_repository / android_sdk_repository / ' - e ' s / ^ # <nl> - android_ndk_repository / android_ndk_repository / ' workspace <nl> - - rm - f workspace . bak <nl> - build_targets : <nl> - - " / / src : bazel " <nl> - - " / / src : bazel_jdk_minimal " <nl> - test_flags : <nl> - - " - - test_timeout = 1200 " <nl> - test_targets : <nl> - - " - - " <nl> - - " / / scripts / . . . " <nl> - - " / / src / java_tools / . . . " <nl> - - " / / src / test / . . . " <nl> - - " / / src / tools / singlejar / . . . " <nl> - - " / / third_party / ijar / . . . " <nl> - - " / / tools / android / . . . " <nl> - - " / / tools / aquery_differ / . . . " <nl> - - " / / tools / python / . . . " <nl> - # <nl> - - " - / / src / test / shell / bazel : embedded_tools_deps_test " <nl> - # re - enable once fixed : https : / / github . com / bazelbuild / bazel / issues / 8162 <nl> - - " - / / src / java_tools / buildjar / . . . " <nl> - - " - / / src / java_tools / import_deps_checker / . . . " <nl> - include_json_profile : <nl> - - build <nl> - - test <nl> ubuntu1604 : <nl> shell_commands : <nl> - sed - i . bak - e ' s / ^ # android_sdk_repository / android_sdk_repository / ' - e ' s / ^ # <nl> mmm a / . bazelci / presubmit . yml <nl> ppp b / . bazelci / presubmit . yml <nl>
public final class cclinkinghelper { <nl> preconditions . checknotnull ( ccoutputs ) ; <nl>  <nl> / / create link actions ( only if there are object files or if explicitly requested ) . <nl> - cclinkingoutputs cclinkingoutputs = cclinkingoutputs . empty ; <nl> + / / <nl> / / on some systems , the linker gives an error message if there are no input files . even with <nl> / / the check above , this can still happen if there is a . nopic . o or . o files in srcs , but no <nl> / / other files . to fix that , we ' d have to check for each link action individually . <nl> / / <nl> / / an additional pre - existing issue is that the header check tokens are dropped if we don ' t <nl> / / generate any link actions , effectively disabling header checking in some cases . <nl> - if ( staticlinktype . linkerorarchiver ( ) = = linkerorarchiver . archiver ) { <nl> - <nl> - cclinkingoutputs = createcclinkactions ( ccoutputs ) ; <nl> - } <nl> - return cclinkingoutputs ; <nl> + return createcclinkactions ( ccoutputs ) ; <nl> } <nl>  <nl> public cclinkingcontext buildcclinkingcontextfromlibrariestolink (
public final class nestedsetbuilder < e > { <nl> public nestedsetbuilder < e > addall ( iterable < ? extends e > elements ) { <nl> preconditions . checknotnull ( elements ) ; <nl> if ( elements instanceof nestedset ) { <nl> - nestedset < ? extends e > elementsasnestedset = ( nestedset < ? extends e > ) elements ; <nl> if ( order . equals ( order . stable_order ) ) { <nl> / / if direct / transitive order doesn ' t matter , add the nested set as a transitive member to <nl> / / avoid copying its elements . <nl> - return addtransitive ( elementsasnestedset ) ; <nl> - } else { <nl> - / / direct / transitive order matters , but we might be able to save an iteration if we hit the <nl> - / / iterables . size call below with a list instead of a nested set . <nl> - <nl> - elements = elementsasnestedset . tolist ( ) ; <nl> + return addtransitive ( ( nestedset < ? extends e > ) elements ) ; <nl> } <nl> + throw new illegalargumentexception ( " nestedset should be added as a transitive member " ) ; <nl> } <nl> if ( items = = null ) { <nl> items = compacthashset . createwithexpectedsize ( iterables . size ( elements ) ) ;
public class starlarksemanticsoptions extends optionsbase implements serializabl <nl> + " debugging . " ) <nl> public boolean experimentalplatformsapi ; <nl>  <nl> - <nl> - / / function should accept two mandatory parameters , ' settings ' and ' attr ' . <nl> @ option ( <nl> name = " experimental_starlark_config_transitions " , <nl> - defaultvalue = " false " , <nl> + defaultvalue = " true " , <nl> documentationcategory = optiondocumentationcategory . starlark_semantics , <nl> effecttags = { optioneffecttag . loading_and_analysis } , <nl> metadatatags = { optionmetadatatag . experimental } , <nl> mmm a / src / main / java / com / google / devtools / build / lib / syntax / starlarksemantics . java <nl> ppp b / src / main / java / com / google / devtools / build / lib / syntax / starlarksemantics . java <nl>
public final class skylarkrulecontext implements skylarkrulecontextapi { <nl> return rulecontext . gethostconfiguration ( ) ; <nl> } <nl>  <nl> - <nl> - / / target represented by the label instead of the actual label . <nl> @ override <nl> @ nullable <nl> public object getbuildsettingvalue ( ) throws evalexception { <nl> mmm a / src / main / java / com / google / devtools / build / lib / skylarkbuildapi / skylarkrulefunctionsapi . java <nl> ppp b / src / main / java / com / google / devtools / build / lib / skylarkbuildapi / skylarkrulefunctionsapi . java <nl>
public interface skylarkrulefunctionsapi < fileapit extends fileapi > { <nl> positional = false , <nl> enableonlywithflag = flagidentifier . experimental_build_setting_api , <nl> valuewhendisabled = " none " , <nl> - <nl> doc = <nl> - " if set , describes what kind of build setting this rule is . " <nl> - + " see the < a href = ' config . html ' > < code > config < / code > < / a > module . if this is " <nl> + " if set , describes what kind of " <nl> + + " < a href = ' . . / config . $ doc_ext # user - defined - build - settings ' > < code > build " <nl> + + " setting < / code > < / a > this rule is . see the " <nl> + + " < a href = ' config . html ' > < code > config < / code > < / a > module . if this is " <nl> + " set , a mandatory attribute named \ " build_setting_default \ " is automatically " <nl> + " added to this rule , with a type corresponding to the value passed in here . " ) , <nl> @ param (
public final class blazeruntime implements bugreport . blazeruntimeinterface { <nl> return options ; <nl> } <nl>  <nl> + / * * <nl> + * returns the first module that is an instance of a given class or interface . <nl> + * <nl> + * @ param moduleclass a class or interface that we want to match to a module <nl> + * @ param < t > the type of the module ' s class <nl> + * @ return a module that is an instance of this class or interface <nl> + * / <nl> @ suppresswarnings ( " unchecked " ) <nl> - public < t extends blazemodule > t getblazemodule ( class < t > moduleclass ) { <nl> - <nl> - / / through all the modules to find an instance of the superclass . <nl> + public < t > t getblazemodule ( class < t > moduleclass ) { <nl> for ( blazemodule module : blazemodules ) { <nl> - if ( module . getclass ( ) = = moduleclass ) { <nl> + if ( moduleclass . isinstance ( module ) ) { <nl> return ( t ) module ; <nl> } <nl> } <nl> - <nl> return null ; <nl> }
public class cpplinkactiontest extends buildviewtestcase { <nl> " - - sysroot = / usr / grte / v1 " ) <nl> . inorder ( ) ; <nl> } <nl> - <nl> - @ test <nl> - @ deprecated <nl> - <nl> - public void testsplitexecutablelinkcommanddynamicwithsplitting ( ) throws exception { <nl> - rulecontext rulecontext = createdummyrulecontext ( ) ; <nl> - <nl> - featureconfiguration featureconfiguration = getmockfeatureconfiguration ( ) ; <nl> - <nl> - cpplinkaction linkaction = <nl> - createlinkbuilder ( <nl> - rulecontext , <nl> - linktargettype . dynamic_library , <nl> - " dummyrulecontext / out . so " , <nl> - immutablelist . of ( ) , <nl> - immutablelist . of ( ) , <nl> - featureconfiguration ) <nl> - . setlibraryidentifier ( " library " ) <nl> - . build ( ) ; <nl> - pair < list < string > , list < string > > result = linkaction . getlinkcommandline ( ) . splitcommandline ( ) ; <nl> - <nl> - assertthat ( <nl> - result . first . stream ( ) <nl> - . map ( x - > removeoutdirectory ( x ) ) <nl> - . collect ( immutablelist . toimmutablelist ( ) ) ) <nl> - . containsexactly ( <nl> - " crosstool / gcc_tool " , <nl> - " - shared " , <nl> - " - o " , <nl> - " / k8 - fastbuild / bin / dummyrulecontext / out . so " , <nl> - " - wl , - s " , <nl> - " - - sysroot = / usr / grte / v1 " , <nl> - " @ / k8 - fastbuild / bin / dummyrulecontext / out . so - 2 . params " ) <nl> - . inorder ( ) ; <nl> - assertthat ( result . second ) . isempty ( ) ; <nl> - } <nl> } <nl> mmm a / src / test / py / bazel / bazel_windows_cpp_test . py <nl> ppp b / src / test / py / bazel / bazel_windows_cpp_test . py <nl>
java_toolchain ( <nl> " : java_compiler_jar " , <nl> " : jdk_compiler_jar " , <nl> ] , <nl> - # <nl> - # jacocorunner = " : jacoco_coverage_runner " <nl> + jacocorunner = " : jacoco_coverage_runner " <nl> ) <nl>  <nl> filegroup (
<nl> # https : / / groups . google . com / forum / ? nomobile = true # ! topic / bazel - dev / 4ql_7edclc0 <nl> # we do lose the ability to set - o pipefail . <nl>  <nl> - # <nl> - # found / error while trying to print version <nl> - <nl> failure_header = " \ <nl> error occurred while attempting to use the default python toolchain \ <nl> ( @ bazel_tools / / tools / python : autodetecting_toolchain ) . "
genrule ( <nl>  <nl> filegroup ( <nl> name = " transitive_sources " , <nl> - srcs = glob ( [ ' * - src . jar ' ] ) + [ " license " ] + [ <nl> + srcs = glob ( [ " * - src . jar " ] ) + [ " license " ] + [ <nl> " / / third_party : asm / asm - 7 . 0 - sources . jar " , <nl> " / / third_party : asm / asm - analysis - 7 . 0 - sources . jar " , <nl> - " / / third_party : asm / asm - commons - 7 . 0 - sources . jar " <nl> + " / / third_party : asm / asm - commons - 7 . 0 - sources . jar " , <nl> ] , <nl> ) <nl>  <nl> - # <nl> - genrule ( <nl> - name = " jacoco_source_jars_zip " , <nl> - srcs = glob ( [ ' * - src . jar ' ] ) + [ " license " ] + [ <nl> - " / / third_party : asm / asm - 7 . 0 - sources . jar " , <nl> - " / / third_party : asm / asm - analysis - 7 . 0 - sources . jar " , <nl> - " / / third_party : asm / asm - commons - 7 . 0 - sources . jar " <nl> - ] , <nl> - outs = [ " jacoco_src_jars . zip " ] , <nl> - cmd = " $ ( location / / src : zip_files ) third_party / java / jacoco $ @ $ ( srcs ) " , <nl> - output_to_bindir = num , <nl> - tools = [ " / / src : zip_files " ] , <nl> - ) <nl> - <nl> java_import ( <nl> name = " agent " , <nl> jars = [ " org . jacoco . agent - 0 . 7 . 5 . 201505241946 . jar " ] , <nl> mmm a / third_party / java / proguard / build <nl> ppp b / third_party / java / proguard / build <nl>
genrule ( <nl> tools = [ " / / src : zip_files " ] , <nl> visibility = [ " / / src : __pkg__ " ] , <nl> ) <nl> - <nl> - # <nl> - genrule ( <nl> - name = " proguard_srcs_zip " , <nl> - srcs = [ " : srcs " ] , <nl> - outs = [ " proguard_srcs . zip " ] , <nl> - cmd = " $ ( location / / src : zip_files ) third_party / java / proguard $ @ $ ( srcs ) " , <nl> - tools = [ " / / src : zip_files " ] , <nl> - visibility = [ " / / src : __pkg__ " ] , <nl> - ) <nl> \ no newline at end of file
public class xcodeconfigrule implements ruledefinition { <nl> . allowedruleclasses ( " xcode_version " ) <nl> . allowedfiletypes ( ) <nl> . nonconfigurable ( " this rule determines configuration " ) ) <nl> - / * < ! - - # blaze_rule ( xcode_config ) . attribute ( version ) - - > <nl> - deprecated . this attribute has no effect . <nl> - < ! - - # end_blaze_rule . attribute - - > * / <nl> - <nl> - . add ( attr ( require_defined_versions_attr_name , boolean ) <nl> - . value ( false ) <nl> - . nonconfigurable ( " this rule determines configuration " ) ) <nl> . build ( ) ; <nl> } <nl>  <nl> mmm a / src / test / java / com / google / devtools / build / lib / rules / apple / xcodeconfigtest . java <nl> ppp b / src / test / java / com / google / devtools / build / lib / rules / apple / xcodeconfigtest . java <nl>
source " $ { current_dir } / remote_helpers . sh " \ <nl> function set_up ( ) { <nl> bazel clean - - expunge > & $ test_log <nl> repo_cache_dir = $ test_tmpdir / repository_cache <nl> - # <nl> - add_to_bazelrc " fetch - - noexperimental_ui " <nl> - add_to_bazelrc " build - - noexperimental_ui " <nl> } <nl>  <nl> function tear_down ( ) {
class actiontemptest ( test_base . testbase ) : <nl>  <nl> def _spawnstrategies ( self ) : <nl> " " " returns the list of supported - - spawn_strategy values . " " " <nl> - # <nl> exit_code , _ , stderr = self . runbazel ( [ <nl> - ' build ' , ' - - color = no ' , ' - - curses = no ' , ' - - spawn_strategy = foo ' , <nl> - ' - - noexperimental_ui ' <nl> + ' build ' , ' - - color = no ' , ' - - curses = no ' , ' - - spawn_strategy = foo ' <nl> ] ) <nl> self . assertexitcode ( exit_code , num , stderr ) <nl> pattern = re . compile ( <nl> - r ' ^ error : . * is an invalid value for . * valid values are : ( . * ) \ . $ ' ) <nl> + r ' ^ error : . * is an invalid value for . * valid values are : ( . * ) $ ' ) <nl> for line in stderr : <nl> m = pattern . match ( line ) <nl> if m : <nl>
class actiontemptest ( test_base . testbase ) : <nl> with open ( path , ' rt ' ) as f : <nl> return [ l . strip ( ) for l in f ] <nl>  <nl> - # <nl> exit_code , _ , stderr = self . runbazel ( [ <nl> ' build ' , <nl> ' - - verbose_failures ' , <nl> - ' - - noexperimental_ui ' , <nl> ' - - spawn_strategy = % s ' % strategy , <nl> ' / / foo : genrule ' , <nl> ' / / foo : skylark ' ,
eof <nl> mkfifo $ testfifo $ sleepyfifo | | fail " couldn ' t create fifos under x " <nl>  <nl> set - m <nl> - # <nl> - bazel $ startup_opt build - - noexperimental_ui \ <nl> + bazel $ startup_opt build - - experimental_ui_debug_all_events \ <nl> - - package_path . / / x : sleepy > & $ test_log & <nl> local pid = $ ! <nl>  <nl> mmm a / src / test / shell / integration / discard_analysis_cache_test . sh <nl> ppp b / src / test / shell / integration / discard_analysis_cache_test . sh <nl>
public class applecommandlineoptions extends fragmentoptions { <nl> host . tvossdkversion = tvossdkversion ; <nl> host . macossdkversion = macossdkversion ; <nl> host . applebitcodemode = applebitcodemode ; <nl> - <nl> / / the host apple platform type will always be macos , as no other apple platform type can <nl> / / currently execute build actions . if that were the case , a host_apple_platform_type flag might <nl> / / be needed . <nl>
public class applecommandlineoptions extends fragmentoptions { <nl> return host ; <nl> } <nl>  <nl> - @ override <nl> - public fragmentoptions getexec ( ) { <nl> - applecommandlineoptions exec = ( applecommandlineoptions ) super . getexec ( ) ; <nl> - <nl> - / / the exec apple platform type will always be macos , as no other apple platform type can <nl> - / / currently execute build actions . <nl> - exec . appleplatformtype = platformtype . macos ; <nl> - return exec ; <nl> - } <nl> - <nl> void serialize ( serializationcontext context , codedoutputstream out ) <nl> throws ioexception , serializationexception { <nl> context . serialize ( this , out ) ;
public class cppoptions extends fragmentoptions { <nl> return host ; <nl> } <nl>  <nl> - @ override <nl> - public fragmentoptions getexec ( ) { <nl> - cppoptions exec = ( cppoptions ) super . getexec ( ) ; <nl> - <nl> - / / the crosstool options are partially copied from the target configuration . <nl> - if ( hostcrosstooltop ! = null ) { <nl> - exec . crosstooltop = hostcrosstooltop ; <nl> - exec . cppcompiler = hostcppcompiler ; <nl> - } <nl> - <nl> - / / hostlibctop doesn ' t default to the target ' s libctop . <nl> - / / only an explicit command - line option will change it . <nl> - / / the default is whatever the host ' s crosstool ( which might have been specified <nl> - / / by - - host_crosstool_top , or - - crosstool_top as a fallback ) says it should be . <nl> - exec . libctoplabel = hostlibctoplabel ; <nl> - <nl> - exec . targetlibctoplabel = libctoplabel ; <nl> - <nl> - / / - g0 is the default , but allowmultiple options cannot have default values so we just pass <nl> - / / - g0 first and let the user options override it . <nl> - immutablelist . builder < string > coptlistbuilder = immutablelist . builder ( ) ; <nl> - immutablelist . builder < string > cxxoptlistbuilder = immutablelist . builder ( ) ; <nl> - / / don ' t add - g0 if the host platform is windows . <nl> - / / note that host platform is not necessarily the platform bazel is running on ( foundry ) <nl> - if ( os . getcurrent ( ) ! = os . windows ) { <nl> - coptlistbuilder . add ( " - g0 " ) ; <nl> - cxxoptlistbuilder . add ( " - g0 " ) ; <nl> - } <nl> - exec . coptlist = coptlistbuilder . addall ( hostcoptlist ) . build ( ) ; <nl> - exec . cxxoptlist = cxxoptlistbuilder . addall ( hostcxxoptlist ) . build ( ) ; <nl> - exec . conlyoptlist = immutablelist . copyof ( hostconlyoptlist ) ; <nl> - exec . linkoptlist = immutablelist . copyof ( hostlinkoptlist ) ; <nl> - <nl> - exec . stripbinaries = stripmode . always ; <nl> - <nl> - return exec ; <nl> - } <nl> - <nl> / * * <nl> * returns true if targets under this configuration should apply fdo . <nl> * /
public class profilegrapher { <nl> } <nl>  <nl> long maxendtime = num ; <nl> - <nl> try ( jsonreader reader = <nl> new jsonreader ( <nl> new bufferedreader ( <nl> new inputstreamreader ( <nl> maybeunzip ( new fileinputstream ( filename ) , gzipped ) , standardcharsets . utf_8 ) ) ) ) { <nl> + if ( reader . peek ( ) = = jsontoken . begin_object ) { <nl> + reader . beginobject ( ) ; <nl> + while ( reader . hasnext ( ) ) { <nl> + if ( " traceevents " . equals ( reader . nextname ( ) ) ) { <nl> + break ; <nl> + } <nl> + reader . skipvalue ( ) ; <nl> + } <nl> + } <nl> reader . beginarray ( ) ; <nl> while ( reader . hasnext ( ) ) { <nl> map < string , object > data = decodejsonobject ( reader ) ;
public class javacompileaction extends abstractaction <nl> return continuation . execute ( ) ; <nl> } <nl>  <nl> - <nl> - @ override <nl> - public actionresult execute ( actionexecutioncontext actionexecutioncontext ) <nl> - throws actionexecutionexception , interruptedexception { <nl> - actioncontinuationorresult continuation = beginexecution ( actionexecutioncontext ) ; <nl> - while ( ! continuation . isdone ( ) ) { <nl> - continuation = continuation . execute ( ) ; <nl> - } <nl> - return continuation . get ( ) ; <nl> - } <nl> - <nl> @ override <nl> protected string getrawprogressmessage ( ) { <nl> stringbuilder sb = new stringbuilder ( " building " ) ;
public class buildviewtest extends buildviewtestbase { <nl> / / regression test : " output_filter broken ( but in a different way ) " <nl> @ test <nl> public void testoutputfilterseewarning ( ) throws exception { <nl> - if ( defaultflags ( ) . contains ( flag . trimmed_configurations ) ) { <nl> - <nl> - return ; <nl> - } <nl> runanalysiswithoutputfilter ( pattern . compile ( " . * " ) ) ; <nl> assertcontainsevent ( " please do not import ' / / java / a : a . java ' " ) ; <nl> } <nl>
public class buildviewtest extends buildviewtestbase { <nl> * / <nl> @ test <nl> public void testmultibuildinvalidationrevalidation ( ) throws exception { <nl> - if ( defaultflags ( ) . contains ( flag . trimmed_configurations ) ) { <nl> - <nl> - return ; <nl> - } <nl> scratch . file ( " java / a / a . java " , " bla1 " ) ; <nl> scratch . file ( " java / a / c . java " , " bla2 " ) ; <nl> scratch . file ( " java / a / build " ,
http_file ( <nl> ] , <nl> ) <nl>  <nl> - # used by ci to test bazel on platforms without an installed system jdk . <nl> - # <nl> - http_archive ( <nl> - name = " openjdk_linux_archive " , <nl> - build_file_content = " java_runtime ( name = ' runtime ' , srcs = glob ( [ ' * * ' ] ) , visibility = [ ' / / visibility : public ' ] ) " , <nl> - sha256 = " <commit_id> " , <nl> - strip_prefix = " zulu9 . 0 . 7 . 1 - jdk9 . 0 . 7 - linux_x64 - allmodules " , <nl> - urls = [ <nl> - " https : / / mirror . bazel . build / openjdk / azul - zulu - 9 . 0 . 7 . 1 - jdk9 . 0 . 7 / zulu9 . 0 . 7 . 1 - jdk9 . 0 . 7 - linux_x64 - allmodules . tar . gz " , <nl> - ] , <nl> - ) <nl> - <nl> http_file ( <nl> name = " openjdk_macos " , <nl> downloaded_file_path = " zulu - macos . tar . gz " , <nl>
public abstract class buildeventservicemodule < besoptionst extends buildeventserv <nl>  <nl> private static final logger logger = logger . getlogger ( buildeventservicemodule . class . getname ( ) ) ; <nl> private static final googlelogger googlelogger = googlelogger . forenclosingclass ( ) ; <nl> - <nl> - private static final duration max_wait_for_previous_invocation = duration . ofseconds ( 5 ) ; <nl>  <nl> private final atomicreference < abruptexitexception > pendingabruptexitexception = <nl> new atomicreference < > ( ) ; <nl>
public abstract class starlarktransition implements configurationtransition { <nl> return buildsettingtarget ; <nl> } <nl>  <nl> - <nl> private static immutableset < label > getrelevantstarlarksettingsfromtransition ( <nl> starlarktransition transition , settings inputoroutput ) { <nl> list < string > toget = <nl> mmm a / src / main / java / com / google / devtools / build / lib / runtime / starlarkoptionsparser . java <nl> ppp b / src / main / java / com / google / devtools / build / lib / runtime / starlarkoptionsparser . java <nl>
public class starlarkoptionsparser { <nl> } <nl> parsedoptions . put ( loadedflag , value ) ; <nl> } <nl> - <nl> nativeoptionsparser . setstarlarkoptions ( parsedoptions . build ( ) ) ; <nl> }
public class cpphelper { <nl> cctoolchainprovider toolchain , <nl> cppconfiguration cppconfiguration , <nl> featureconfiguration featureconfiguration ) { <nl> - <nl> - / / bazel - team @ google . com . the feature will be removed in a later bazel release and it might <nl> - / / break you . contact us so we can find alternatives for your build . <nl> - if ( featureconfiguration . getrequestedfeatures ( ) . contains ( " coptnopic " ) ) { <nl> - return false ; <nl> - } <nl> return cppconfiguration . forcepic ( ) <nl> | | ( toolchain . usepicfordynamiclibraries ( cppconfiguration , featureconfiguration ) <nl> & & cppconfiguration . getcompilationmode ( ) ! = compilationmode . opt ) ; <nl> mmm a / src / test / java / com / google / devtools / build / lib / rules / cpp / cccommontest . java <nl> ppp b / src / test / java / com / google / devtools / build / lib / rules / cpp / cccommontest . java <nl>
<nl>  <nl> " " " experimental re - implementations of java toolchain aliases using toolchain resolution . " " " <nl>  <nl> - load ( " : toolchain_utils . bzl " , " find_java_runtime_toolchain " , " find_java_toolchain " ) <nl> - <nl> - def _copy_default_info ( info ) : <nl> - # <nl> - return defaultinfo ( <nl> - default_runfiles = info . default_runfiles , <nl> - data_runfiles = info . data_runfiles , <nl> - files = info . files , <nl> - ) <nl> - <nl> def _java_runtime_alias ( ctx ) : <nl> " " " an experimental implementation of java_runtime_alias using toolchain resolution . " " " <nl> if java_common . is_java_toolchain_resolution_enabled_do_not_use ( ctx = ctx ) : <nl>
public abstract class composingtransitionfactory < t > implements transitionfactory <nl> public boolean issplit ( ) { <nl> return transitionfactory1 ( ) . issplit ( ) | | transitionfactory2 ( ) . issplit ( ) ; <nl> } <nl> - <nl> - <nl> - / / it private . <nl> }
public class bazeljavaruleclasses { <nl> . allowedfiletypes ( filetypeset . no_file ) <nl> . allowedruleclasses ( " cc_binary " ) ) <nl> . add ( attr ( " : java_launcher " , label ) . value ( javasemantics . java_launcher ) ) / / blaze flag <nl> - . add ( <nl> - attr ( " $ no_launcher " , nodep_label_list ) <nl> - . value ( <nl> - immutablelist . of ( <nl> - <nl> - env . gettoolslabel ( " / / third_party / java / jdk : jdk_launcher " ) , <nl> - env . gettoolslabel ( " / / tools / jdk : no_launcher " ) ) ) ) <nl> . add ( <nl> attr ( " $ launcher " , label ) <nl> . cfg ( hosttransition . createfactory ( ) ) <nl> mmm a / src / main / java / com / google / devtools / build / lib / rules / java / javahelper . java <nl> ppp b / src / main / java / com / google / devtools / build / lib / rules / java / javahelper . java <nl>
import javax . annotation . nullable ; <nl> public class blazejavacresult { <nl> / * * the compilation result . * / <nl> public enum status { <nl> - ok ( 0 ) , <nl> - error ( 1 ) , <nl> - <nl> - requires_fallback ( 1 ) ; <nl> - <nl> - private final int exitcode ; <nl> - <nl> - private status ( int exitcode ) { <nl> - this . exitcode = exitcode ; <nl> - } <nl> - <nl> - public int exitcode ( ) { <nl> - return exitcode ; <nl> - } <nl> + ok , <nl> + error , <nl> + requires_fallback , <nl> } <nl>  <nl> private final status status ;
java_tools = [ <nl> " / / src / java_tools / buildjar / java / com / google / devtools / build / buildjar / jarhelper : srcs " , <nl> " / / src / tools / singlejar : embedded_tools " , <nl> " / / src / java_tools / import_deps_checker / java / com / google / devtools / build / importdeps : embedded_tools " , <nl> - # <nl> - " / / third_party / ijar : zipper " , <nl> " / / third_party / java / jacoco : srcs " , <nl> ] + select ( { <nl> " / / src / conditions : arm " : [ ] , <nl>
filegroup ( <nl> visibility = [ " / / visibility : public " ] , <nl> ) <nl>  <nl> - # <nl> - filegroup ( <nl> - name = " embed_into_java_tools " , <nl> - srcs = glob ( <nl> - [ " * * " ] , <nl> - exclude = [ " build " ] , <nl> - ) , <nl> - visibility = [ " / / visibility : public " ] , <nl> - ) <nl> - <nl> pkg_tar ( <nl> name = " ijar_with_deps_archive " , <nl> extension = " tar . gz " , <nl>
public class buildconfiguration implements buildconfigurationapi { <nl> } <nl> } <nl>  <nl> - / * * <nl> - public static class pluginoptionconverter implements converter < map . entry < string , string > > { <nl> - @ override <nl> - public map . entry < string , string > convert ( string input ) throws optionsparsingexception { <nl> - int <nl> - if ( <nl> - throw new optionsparsingexception ( " plugin option not in the plugin = option format " ) ; <nl> - } <nl> - string option = input . substring ( 0 , index ) ; <nl> - string value = input . substring ( <nl> - return maps . immutableentry ( option , value ) ; <nl> - } <nl> - <nl> - @ override <nl> - public string gettypedescription ( ) { <nl> - return " an option for a plugin " ; <nl> - } <nl> - } <nl> - <nl> / * * <nl> * values for the - - strict_ * _deps option <nl> * /
string detectbashandexportbazelsh ( ) { <nl>  <nl> uint64_t start = blaze : : getmillisecondsmonotonic ( ) ; <nl>  <nl> - bash = locatebash ( ) ; <nl> + bash = locatebashmaybe ( ) ; <nl> uint64_t end = blaze : : getmillisecondsmonotonic ( ) ; <nl> - bazel_log ( info ) < < " bazel_sh detection took " < < end - start <nl> - < < " msec , found " < < bash . c_str ( ) ; <nl> - <nl> - if ( ! bash . empty ( ) ) { <nl> + if ( bash . empty ( ) ) { <nl> + bazel_log ( info ) < < " bazel_sh detection took " < < end - start <nl> + < < " msec , not found " ; <nl> + } else { <nl> + bazel_log ( info ) < < " bazel_sh detection took " < < end - start <nl> + < < " msec , found " < < bash . c_str ( ) ; <nl> / / set process environment variable . <nl> blaze : : setenv ( " bazel_sh " , bash ) ; <nl> } <nl> - return bash ; <nl> - } <nl>  <nl> - void detectbashordie ( ) { <nl> - string bash = detectbashandexportbazelsh ( ) ; <nl> - if ( bash . empty ( ) ) { <nl> - <nl> - / / bazel_log ( error ) <nl> - printf ( <nl> - " bazel on windows requires msys2 bash , but we could not find it . \n " <nl> - " if you do not have it installed , you can install msys2 from\n " <nl> - " http : / / repo . msys2 . org / distrib / msys2 - x86_64 - latest . exe\n " <nl> - " \n " <nl> - " if you already have it installed but bazel cannot find it , \n " <nl> - " set bazel_sh environment variable to its location : \n " <nl> - " set bazel_sh = c : \ \ path \ \ to \ \ msys2 \ \ usr \ \ bin \ \ bash . exe\n " ) ; <nl> - exit ( 1 ) ; <nl> - } <nl> + return bash ; <nl> } <nl>  <nl> void ensurepythonpathoption ( std : : vector < string > * options ) {
public class packagefunction implements skyfunction { <nl> * < p > do not use this unless you know what you are doing ; bazel will be intentionally <nl> * incrementally incorrect ! <nl> * / <nl> - <nl> non_incremental <nl> } <nl>  <nl> mmm a / src / main / java / com / google / devtools / build / lib / skyframe / skyframeexecutor . java <nl> ppp b / src / main / java / com / google / devtools / build / lib / skyframe / skyframeexecutor . java <nl>
public class actionexecutionfunction implements skyfunction , completionreceiver <nl> state . inputartifactdata . putwithnodepowner ( <nl> artifactskykey . artifact ( entry . getkey ( ) ) , ( fileartifactvalue ) entry . getvalue ( ) ) ; <nl> } <nl> - <nl> - / / see the documentation on metadatahandler . artifactomitted . this works by accident <nl> - / / because markomitted is only called for remote execution , and this code only gets <nl> - / / executed for local execution . <nl> metadatahandler = <nl> new actionmetadatahandler ( <nl> state . inputartifactdata , <nl>
def _copy_default_info ( info ) : <nl> def _java_runtime_alias ( ctx ) : <nl> " " " an experimental implementation of java_runtime_alias using toolchain resolution . " " " <nl> toolchain = find_java_runtime_toolchain ( ctx , target = ctx . attr . _java_runtime ) <nl> - <nl> - # find_java_runtime_toolchain returns a configured target if toolchain resolution is disabled <nl> - # <nl> - if type ( toolchain ) = = " target " : <nl> - return [ <nl> - toolchain [ java_common . javaruntimeinfo ] , <nl> - toolchain [ platform_common . templatevariableinfo ] , <nl> - _copy_default_info ( toolchain [ defaultinfo ] ) , <nl> - ] <nl> - <nl> return [ <nl> toolchain , <nl> platform_common . templatevariableinfo ( { <nl>
public class memoizingevaluatortest { <nl> * evaluation depending on a node in error . <nl> * / <nl> @ test <nl> - @ ignore <nl> public void shutdownbuildoncachederror_done ( ) throws exception { <nl> / / errorkey will be invalidated due to its dependence on invalidatedkey , but later revalidated <nl> / / since invalidatedkey re - evaluates to the same value on a subsequent build .
public class packagefunction implements skyfunction { <nl> env . getvaluesorthrow ( globkeys , ioexception . class , buildfilenotfoundexception . class ) ; <nl>  <nl> / / for each missing glob , evaluate it asychronously via the delegate . <nl> - / / <nl> - <nl> - / / single skyframe restart after the prefetch step is probably tolerable . <nl> collection < skykey > missingkeys = getmissingkeys ( globkeys , globvaluemap ) ; <nl> list < string > includestodelegate = new arraylist < > ( missingkeys . size ( ) ) ; <nl> list < string > excludestodelegate = new arraylist < > ( missingkeys . size ( ) ) ;
def find_java_toolchain ( ctx , target ) : <nl> a javatoolchaininfo . <nl> " " " <nl>  <nl> - _ignore = [ ctx ] <nl> + if java_common . is_java_toolchain_resolution_enabled_do_not_use ( ctx = ctx ) : <nl> + return ctx . toolchains [ " @ bazel_tools / / tools / jdk : toolchain_type " ] <nl>  <nl> - # <nl> - # see https : / / github . com / bazelbuild / bazel / issues / 6521 <nl> - <nl> - return target <nl> + return target [ java_common . javatoolchaininfo ] <nl>  <nl> def find_java_runtime_toolchain ( ctx , target ) : <nl> " " " <nl>
def find_java_runtime_toolchain ( ctx , target ) : <nl> a javaruntimeinfo . <nl> " " " <nl>  <nl> - _ignore = [ ctx ] <nl> - <nl> - # <nl> - # see https : / / github . com / bazelbuild / bazel / issues / 6521 <nl> + if java_common . is_java_toolchain_resolution_enabled_do_not_use ( ctx = ctx ) : <nl> + return ctx . toolchains [ " @ bazel_tools / / tools / jdk : runtime_toolchain_type " ] <nl>  <nl> - return target <nl> + return target [ java_common . javaruntimeinfo ]
public abstract class abstractexceptionalparallelevaluator < e extends exception > <nl> } <nl>  <nl> private void replay ( valuewithmetadata valuewithmetadata ) { <nl> - <nl> - / / modes [ skyframe - core ] <nl> + / / replaying actions is done on a small number of nodes , but potentially over a large dependency <nl> + / / graph . under those conditions , using the regular nestedset flattening with . tocollection ( ) <nl> + / / is more efficient than using nestedsetvisitor ' s custom traversal logic . <nl> evaluatorcontext <nl> . getreplayingnestedsetpostablevisitor ( ) <nl> - . visit ( valuewithmetadata . gettransitivepostables ( ) ) ; <nl> + . visit ( valuewithmetadata . gettransitivepostables ( ) . tocollection ( ) ) ; <nl> evaluatorcontext <nl> . getreplayingnestedseteventvisitor ( ) <nl> - . visit ( valuewithmetadata . gettransitiveevents ( ) ) ; <nl> + . visit ( valuewithmetadata . gettransitiveevents ( ) . tocollection ( ) ) ; <nl> } <nl>  <nl> abstract < t extends skyvalue > evaluationresult < t > constructresultexceptionally (
public abstract class abstractparallelevaluator { <nl> } <nl> biginteger depfingerprint = depvalue . getvaluefingerprint ( ) ; <nl> if ( depfingerprint = = null ) { <nl> - <nl> - return null ; <nl> + depfingerprint = depentry . getversion ( ) . getfingerprint ( ) ; <nl> + if ( depfingerprint = = null ) { <nl> + return null ; <nl> + } <nl> } <nl> groupfingerprint = <nl> bigintegerfingerprintutils . composeordered ( groupfingerprint , depfingerprint ) ; <nl> mmm a / src / main / java / com / google / devtools / build / skyframe / minimalversion . java <nl> ppp b / src / main / java / com / google / devtools / build / skyframe / minimalversion . java <nl>
public final class environmentbackedrecursivepackageprovider <nl> this . env = env ; <nl> } <nl>  <nl> - <nl> - / / in more places . <nl> + / * * <nl> + * whether any of the calls to { @ link # getpackage } , { @ link # gettarget } , { @ link # bulkgetpackages } , <nl> + * or { @ link # getpackagesunderdirectory } encountered a package in error . <nl> + * <nl> + * < p > the client of { @ link environmentbackedrecursivepackageprovider } may want to check this . see <nl> + * comments in { @ link # getpackage } for details . <nl> + * / <nl> boolean encounteredpackageerrors ( ) { <nl> return encounteredpackageerrors . get ( ) ; <nl> } <nl> mmm a / src / main / java / com / google / devtools / build / lib / skyframe / preparedepsofpatternfunction . java <nl> ppp b / src / main / java / com / google / devtools / build / lib / skyframe / preparedepsofpatternfunction . java <nl>
public final class sandboxmodule extends blazemodule { <nl> if ( sandboxfsprocess ! = null ) { <nl> checknotnull ( env , " env not initialized ; was beforecommand called ? " ) ; <nl> env . getreporter ( ) . handle ( event . info ( reason ) ) ; <nl> - <nl> sandboxfsprocess . destroy ( ) ; <nl> sandboxfsprocess = null ; <nl> }
java_binary ( <nl>  <nl> filegroup ( <nl> name = " turbine_direct " , <nl> - # <nl> - srcs = select ( { <nl> - " / / src / conditions : darwin " : [ " / / third_party : turbine_direct " ] , <nl> - " / / src / conditions : darwin_x86_64 " : [ " / / third_party : turbine_direct " ] , <nl> - " / / src / conditions : linux_x86_64 " : [ " / / third_party : turbine_direct " ] , <nl> - " / / conditions : default " : [ " turbine_direct_binary_deploy . jar " ] , <nl> - } ) , <nl> + srcs = [ " turbine_direct_binary_deploy . jar " ] , <nl> visibility = [ <nl> " / / : __subpackages__ " , <nl> ] ,
public class skylarkruleclassfunctions implements skylarkrulefunctionsapi < artifa <nl> ast . getlocation ( ) , <nl> " build setting rules cannot use the ` cfg ` param to apply transitions to themselves . " ) ; <nl> } <nl> - <nl> if ( ! buildsetting . equals ( runtime . none ) ) { <nl> - if ( funcallenv . getsemantics ( ) . experimentalbuildsettingapi ( ) ) { <nl> - builder . setbuildsetting ( ( buildsetting ) buildsetting ) ; <nl> - } else { <nl> - throw new evalexception ( <nl> - ast . getlocation ( ) , <nl> - " build_setting parameter is experimental and not available for " <nl> - + " general use . it is subject to change at any time . it may be enabled by " <nl> - + " specifying - - experimental_build_setting_api " ) ; <nl> - } <nl> + builder . setbuildsetting ( ( buildsetting ) buildsetting ) ; <nl> } <nl> if ( ! cfg . equals ( runtime . none ) ) { <nl> if ( ! ( cfg instanceof starlarkdefinedconfigtransition ) ) { <nl> mmm a / src / main / java / com / google / devtools / build / lib / skylarkbuildapi / skylarkrulefunctionsapi . java <nl> ppp b / src / main / java / com / google / devtools / build / lib / skylarkbuildapi / skylarkrulefunctionsapi . java <nl>
public class defaultmethodclassfixer extends classvisitor { <nl> int slot = num ; <nl> stubmethod . visitvarinsn ( opcodes . aload , slot + + ) ; / / load the receiver <nl> type neededtype = type . gettype ( bridged ) ; <nl> - for ( type arg : neededtype . getargumenttypes ( ) ) { <nl> - <nl> + type [ ] neededargtypes = neededtype . getargumenttypes ( ) ; <nl> + type [ ] parametertypes = type . getargumenttypes ( desc ) ; <nl> + for ( int i = num ; i < neededargtypes . length ; + + i ) { <nl> + type arg = neededargtypes [ i ] ; <nl> stubmethod . visitvarinsn ( arg . getopcode ( opcodes . iload ) , slot ) ; <nl> + if ( ! arg . equals ( parametertypes [ i ] ) ) { <nl> + checkstate ( arg . getsort ( ) = = type . array | | arg . getsort ( ) = = type . object , <nl> + " can ' t cast parameter % s from in bridge for % s . % s % s to % s " , <nl> + i , stubbedinterfacename , name , desc , arg . getclassname ( ) ) ; <nl> + stubmethod . visittypeinsn ( opcodes . checkcast , arg . getinternalname ( ) ) ; <nl> + } <nl> slot + = arg . getsize ( ) ; <nl> } <nl> / / just call the bridged method directly on the visited class using invokevirtual <nl>
public class defaultmethodclassfixer extends classvisitor { <nl> @ nullable <nl> private method findbridgedmethod ( string name , string desc ) { <nl> type [ ] paramtypes = type . getargumenttypes ( desc ) ; <nl> + type returntype = type . getreturntype ( desc ) ; <nl> class < ? > itf = loadfrominternal ( stubbedinterfacename ) ; <nl> checkargument ( itf . isinterface ( ) , " should be an interface : % s " , stubbedinterfacename ) ; <nl> + <nl> + / / num . find the bridge method we ' re trying to implement <nl> + method bridge = null ; <nl> + for ( method m : itf . getdeclaredmethods ( ) ) { <nl> + if ( m . isbridge ( ) <nl> + & & m . getname ( ) . equals ( name ) <nl> + & & arrays . equals ( paramtypes , type . getargumenttypes ( m ) ) <nl> + & & returntype . equals ( type . getreturntype ( m ) ) ) { <nl> + bridge = m ; <nl> + break ; <nl> + } <nl> + } <nl> + checkstate ( bridge ! = null , " couldn ' t find bridge % s . % s % s " , stubbedinterfacename , name , desc ) ; <nl> + checkstate ( bridge . getparametercount ( ) = = paramtypes . length ) ; <nl> + <nl> + / / num . try to find the method being bridged <nl> method result = null ; <nl> + next_method : <nl> for ( method m : itf . getdeclaredmethods ( ) ) { <nl> - if ( m . isbridge ( ) ) { <nl> + if ( m . isbridge ( ) | | modifier . isstatic ( m . getmodifiers ( ) ) ) { <nl> continue ; <nl> } <nl> if ( ! m . getname ( ) . equals ( name ) ) { <nl> continue ; <nl> } <nl> - / / for now , only support specialized return types ( which don ' t require casts ) <nl> - <nl> + <nl> if ( arrays . equals ( paramtypes , type . getargumenttypes ( m ) ) ) { <nl> - checkstate ( result = = null , <nl> - " found multiple bridge target % s and % s for descriptor % s " , result , m , desc ) ; <nl> - return result = m ; <nl> + / / all argument types match , only return type will differ : this is the method we want <nl> + return m ; <nl> + } else if ( m . getparametercount ( ) = = bridge . getparametercount ( ) ) { <nl> + for ( int i = num ; i < m . getparametercount ( ) ; + + i ) { <nl> + if ( ! bridge . getparametertypes ( ) [ i ] . isassignablefrom ( m . getparametertypes ( ) [ i ] ) ) { <nl> + continue next_method ; <nl> + } <nl> + } <nl> + <nl> + / / all of m ' s parameter types are subtypes of the bridge ' s parameter types ( or primitives ) <nl> + if ( result = = null ) { <nl> + result = m ; <nl> + } else { <nl> + / / bail if we find multiple methods that could be bridged <nl> + return null ; <nl> + } <nl> } <nl> } <nl> return result ;
public final class configurationfragmentfunction implements skyfunction { <nl> buildoptions buildoptions = configurationfragmentkey . getbuildoptions ( ) ; <nl> configurationfragmentfactory factory = getfactory ( configurationfragmentkey . getfragmenttype ( ) ) ; <nl> try { <nl> - fragment fragment = factory . create ( buildoptions ) ; <nl> - <nl> - if ( env . valuesmissing ( ) ) { <nl> - return null ; <nl> - } <nl> - return new configurationfragmentvalue ( fragment ) ; <nl> + return new configurationfragmentvalue ( factory . create ( buildoptions ) ) ; <nl> } catch ( invalidconfigurationexception e ) { <nl> - <nl> - / / exception with missing skyframe dependencies . <nl> - if ( env . valuesmissing ( ) ) { <nl> - return null ; <nl> - } <nl> throw new configurationfragmentfunctionexception ( e ) ; <nl> } <nl> }
public class actionexecutionfunction implements skyfunction , completionreceiver <nl> runfilesdepowners = actioninputdepowners . empty_instance ; <nl> } <nl>  <nl> - <nl> - / / under checkcacheandexecuteifneeded . thread them through to here . <nl> + iterable < skykey > failedactiondeps = <nl> + state . discoveredinputs ! = null <nl> + ? iterables . concat ( inputdepkeys , state . discoveredinputs ) <nl> + : inputdepkeys ; <nl> rewindplan rewindplan = <nl> - actionrewindstrategy . getrewindplan ( action , inputdepkeys , e , runfilesdepowners , env ) ; <nl> + actionrewindstrategy . getrewindplan ( action , failedactiondeps , e , runfilesdepowners , env ) ; <nl> for ( action actiontorestart : rewindplan . getactionstorestart ( ) ) { <nl> skyframeactionexecutor . resetactionexecution ( actiontorestart ) ; <nl> } <nl> mmm a / src / main / java / com / google / devtools / build / lib / skyframe / actionrewindstrategy . java <nl> ppp b / src / main / java / com / google / devtools / build / lib / skyframe / actionrewindstrategy . java <nl>
public class actionrewindstrategy { <nl> * @ throws actionexecutionfunctionexception if any lost inputs are not the outputs of previously <nl> * executed actions <nl> * / <nl> - <nl> rewindplan getrewindplan ( <nl> action failedaction , <nl> iterable < skykey > failedactiondeps ,
<nl> def exercise_the_api ( ) : <nl> - # <nl> - # move this to the rule definition when the relevant parameter is set up . <nl> - _var5 = config . int ( flag = true ) <nl> _var6 = configuration_field ( " foo " , " bar " ) <nl>  <nl> exercise_the_api ( ) <nl> + <nl> + def _build_setting_impl ( ctx ) : <nl> + return [ ] <nl> + <nl> + string_flag = rule ( <nl> + implementation = _build_setting_impl , <nl> + build_setting = config . string ( flag = true ) , <nl> + ) <nl> + <nl> + int_setting = rule ( <nl> + implementation = _build_setting_impl , <nl> + build_setting = config . int ( flag = false ) , <nl> + )
public final class printactioncommand implements blazecommand { <nl> return null ; <nl> } <nl> } else { <nl> - <nl> - / / trigger this <nl> env . getreporter ( ) . handle ( event . error ( <nl> null , configuredtarget + " is not a supported target kind " ) ) ; <nl> return null ;
public final class loadingphasecompleteevent implements extendedeventhandler . pos <nl> public immutableset < label > getfilteredlabels ( ) { <nl> return filteredlabels ; <nl> } <nl> - <nl> - <nl> - public long gettimeinms ( ) { <nl> - return num ; <nl> - } <nl> }
import com . google . devtools . build . lib . actions . fileartifactvalue ; <nl> * < p > this store is intended for use with in - memory file systems , where aggressive caching would not <nl> * be worthwhile . <nl> * / <nl> - <nl> - / / call injectremotefile for anything , including children of tree artifacts . <nl> final class minimaloutputstore extends outputstore { <nl>  <nl> @ override <nl>
public class compilationsupport { <nl> this . outputgroupcollector = outputgroupcollector ; <nl> this . objectfilescollector = objectfilescollector ; <nl> this . usepch = usepch ; <nl> - <nl> - if ( rulecontext <nl> - . attributes ( ) <nl> - . has ( cctoolchain . cc_toolchain_default_attribute_name , buildtype . label ) <nl> - | | rulecontext . attributes ( ) . has ( " : j2objc_cc_toolchain " , buildtype . label ) ) { <nl> - if ( toolchain = = null ) { <nl> - toolchain = cpphelper . gettoolchainusingdefaultcctoolchainattribute ( rulecontext ) ; <nl> - } <nl> - this . toolchain = toolchain ; <nl> - } else { <nl> - / / since the rule context doesn ' t have a toolchain at all , ignore any provided override . <nl> - this . toolchain = null ; <nl> + if ( toolchain = = null & & rulecontext . attributes ( ) . has ( <nl> + cctoolchain . cc_toolchain_default_attribute_name , buildtype . label ) ) { <nl> + toolchain = cpphelper . gettoolchainusingdefaultcctoolchainattribute ( rulecontext ) ; <nl> } <nl> + <nl> + this . toolchain = toolchain ; <nl> } <nl>  <nl> / * * builder for { @ link compilationsupport } * /
class skyfunctionenvironment extends abstractskyfunctionenvironment { <nl>  <nl> @ override <nl> public void injectversionfornonhermeticfunction ( version version ) { <nl> - <nl> - preconditions . checkstate ( hermeticity ! = functionhermeticity . hermetic , skykey ) ; <nl> + preconditions . checkstate ( hermeticity = = functionhermeticity . nonhermetic , skykey ) ; <nl> injectedversion = version ; <nl> }
<nl> - - - - <nl> - platforms : <nl> - ubuntu1404 : <nl> - shell_commands : <nl> - - sed - i . bak - e ' s / ^ # android_sdk_repository / android_sdk_repository / ' - e ' s / ^ # <nl> - android_ndk_repository / android_ndk_repository / ' workspace <nl> - - rm - f workspace . bak <nl> - build_targets : <nl> - - " / / src : bazel " <nl> - test_flags : <nl> - - " - - test_timeout = 1200 " <nl> - test_targets : <nl> - - " - - " <nl> - - " / / scripts / . . . " <nl> - - " / / src / test / . . . " <nl> - - " / / third_party / ijar / . . . " <nl> - - " / / tools / android / . . . " <nl> - # disable slow tests <nl> - - " - / / src / test / shell / bazel : bazel_determinism_test " <nl> - # re - enable once fixed : https : / / github . com / bazelbuild / bazel / issues / 4663 <nl> - - " - / / src / test / shell / bazel / android : android_ndk_integration_test " <nl> - # re - enable once fixed : https : / / github . com / bazelbuild / bazel / issues / 5888 <nl> - - " - / / src / test / java / com / google / devtools / build / android / ziputils : ziputils - tests " <nl> - macos : <nl> - shell_commands : <nl> - - sed - i . bak - e ' s / ^ # android_sdk_repository / android_sdk_repository / ' - e ' s / ^ # <nl> - android_ndk_repository / android_ndk_repository / ' workspace <nl> - - rm - f workspace . bak <nl> - build_targets : <nl> - - " / / src : bazel " <nl> - test_flags : <nl> - - " - - test_timeout = 1200 " <nl> - test_targets : <nl> - - " - - " <nl> - - " / / scripts / . . . " <nl> - - " / / src / test / . . . " <nl> - - " / / third_party / ijar / . . . " <nl> - - " / / tools / android / . . . " <nl> - # re - enable once fixed : https : / / github . com / bazelbuild / bazel / issues / 4663 <nl> - - " - / / src / test / shell / bazel / android : android_ndk_integration_test " <nl> - # the below tests have been disabled because they are too slow on macos . <nl> - # re - enable once fixed : https : / / github . com / bazelbuild / bazel / issues / 4684 <nl> - - " - / / src / test / shell / bazel : bazel_determinism_test " <nl> - - " - / / src / test / shell / bazel : bazel_java_test " <nl> - - " - / / src / test / shell / bazel : bazel_bootstrap_distfile_test " <nl> - - " - / / src / test / shell / bazel / remote : remote_execution_test " <nl> - - " - / / src / test / shell / bazel / remote : remote_execution_http_test " <nl> - - " - / / src / test / shell / bazel : skylark_git_repository_test " <nl> - - " - / / src / test / shell / bazel : external_path_test " <nl> - - " - / / src / test / py / bazel : runfiles_test " <nl> - - " - / / src / test / shell / bazel : git_repository_test " <nl> - - " - / / src / test / shell / bazel / android : aar_integration_test " <nl> - - " - / / src / test / shell / bazel / android : android_integration_test " <nl> - # re - enable once fixed : https : / / github . com / bazelbuild / bazel / issues / 5888 <nl> - - " - / / src / test / java / com / google / devtools / build / android / ziputils : ziputils - tests " <nl> - windows : <nl> - build_flags : <nl> - - " - - copt = - w " <nl> - - " - - host_copt = - w " <nl> - build_targets : <nl> - - " / / src : bazel " <nl> - test_flags : <nl> - - " - - copt = - w " <nl> - - " - - host_copt = - w " <nl> - - " - - test_env = java_home " <nl> - # <nl> - # remove this when release version bazel sets systemdrive <nl> - # on windows by default . <nl> - - " - - test_env = systemdrive " <nl> - - " - - test_timeout = 1200 " <nl> - test_targets : <nl> - - " - - " <nl> - - " / / src : all_windows_tests " <nl> - # re - enable once fixed : https : / / github . com / bazelbuild / bazel / issues / 5888 <nl> - - " - / / src / test / java / com / google / devtools / build / android / ziputils : ziputils - tests "
cc_test ( <nl> " input_jar_scan_entries_test . h " , <nl> " input_jar_scan_jartool_test . cc " , <nl> ] , <nl> - # <nl> - # " . exe " extension . <nl> - copts = [ " - djar_tool_path = $ ( java ) / bin / jar " ] , <nl> + copts = [ " - djar_tool_path = \ \ \ " $ ( javabase ) / bin / jar \ \ \ " " ] , <nl> data = [ " @ bazel_tools / / tools / jdk : current_java_runtime " ] , <nl> # timing out , see https : / / github . com / bazelbuild / bazel / issues / 1555 <nl> tags = [ " manual " ] , <nl>
<nl> - / / copyright num the bazel authors . all rights reserved . <nl> - / / <nl> - / / licensed under the apache license , version num . 0 ( the " license " ) ; <nl> - / / you may not use this file except in compliance with the license . <nl> - / / you may obtain a copy of the license at <nl> - / / <nl> - / / http : / / www . apache . org / licenses / license - 2 . 0 <nl> - / / <nl> - / / unless required by applicable law or agreed to in writing , software <nl> - / / distributed under the license is distributed on an " as is " basis , <nl> - / / without warranties or conditions of any kind , either express or implied . <nl> - / / see the license for the specific language governing permissions and <nl> - / / limitations under the license . <nl> - <nl> - <nl> - / / porting work completes .
public final class skyframeactionexecutor { <nl> actionexecutionexception . class , interruptedexception . class ) ; <nl> throw new illegalstateexception ( e ) ; <nl> } finally { <nl> - if ( ! isprimaryactionforthevalue & & action . discoversinputs ( ) & & inputdiscoveryran ) { <nl> - / * * <nl> - * if this is a shared action that does input discovery , but was not executed , we need to <nl> - * remove it from the active actions pool ( it was added there by { @ link <nl> - * actionrunner # call ( ) } ) . <nl> - * / <nl> - <nl> - statusreporterref . get ( ) . remove ( action ) ; <nl> - } <nl> string message = action . getprogressmessage ( ) ; <nl> if ( message ! = null ) { <nl> / / tell the receiver that the action has completed * before * telling the reporter .
class actioninputmaphelper { <nl> artifact actioninput ) throws interruptedexception { <nl> preconditions . checkstate ( actioninput . isfileset ( ) , actioninput ) ; <nl> actionlookupkey filesetactionlookupkey = ( actionlookupkey ) actioninput . getartifactowner ( ) ; <nl> - / / index num for the fileset configuredtarget indicates the skyframefilesetmanifestaction where <nl> - / / we compute the fileset ' s outputsymlinks . <nl> - skykey filesetactionkey = actionexecutionvalue . key ( filesetactionlookupkey , num ) ; <nl> + <nl> + actionlookupvalue filesetactionlookupvalue = <nl> + ( actionlookupvalue ) env . getvalue ( filesetactionlookupkey ) ; <nl> + <nl> + actionanalysismetadata generatingaction = <nl> + filesetactionlookupvalue . getgeneratingactiondangerousreadjavadoc ( actioninput ) ; <nl> + int filesetmanifestactionindex ; <nl> + <nl> + if ( generatingaction instanceof symlinkaction ) { <nl> + artifact outputmanifest = iterables . getonlyelement ( generatingaction . getinputs ( ) ) ; <nl> + actionanalysismetadata symlinktreeaction = <nl> + filesetactionlookupvalue . getgeneratingactiondangerousreadjavadoc ( outputmanifest ) ; <nl> + artifact inputmanifest = iterables . getonlyelement ( symlinktreeaction . getinputs ( ) ) ; <nl> + filesetmanifestactionindex = filesetactionlookupvalue . getgeneratingactionindex ( inputmanifest ) ; <nl> + } else { <nl> + filesetmanifestactionindex = filesetactionlookupvalue . getgeneratingactionindex ( actioninput ) ; <nl> + } <nl> + <nl> + skykey filesetactionkey = <nl> + actionexecutionvalue . key ( filesetactionlookupkey , filesetmanifestactionindex ) ; <nl> actionexecutionvalue filesetvalue = ( actionexecutionvalue ) env . getvalue ( filesetactionkey ) ; <nl> if ( filesetvalue = = null ) { <nl> / / at this point skyframe does not guarantee that the filesetvalue will be ready , since <nl> / / the current action does not directly depend on the outputs of the <nl> / / skyframefilesetmanifestaction whose actionexecutionvalue ( filesetvalue ) is needed here . <nl> - <nl> - / / artifact , which this action depends on , so its value will be guaranteed to be present . <nl> - / / also , unify handling of fileset with artifact expansion . <nl> return null ; <nl> } <nl> return filesetvalue . getoutputsymlinks ( ) ;
public class actiongraphprotooutputformattercallback extends aquerythreadsafecal <nl> skyframeexecutor skyframeexecutor , <nl> targetaccessor < configuredtargetvalue > accessor ) { <nl> super ( reporter , options , out , skyframeexecutor , accessor ) ; <nl> - <nl> - actiongraphdump = new actiongraphdump ( / * includeactioncmdline * / false ) ; <nl> + actiongraphdump = new actiongraphdump ( options . includecommandline ) ; <nl> } <nl>  <nl> @ override <nl> mmm a / src / main / java / com / google / devtools / build / lib / query2 / actiongraphtextoutputformattercallback . java <nl> ppp b / src / main / java / com / google / devtools / build / lib / query2 / actiongraphtextoutputformattercallback . java <nl>
public class actiongraphtextoutputformattercallback extends aquerythreadsafecall <nl> . append ( " ] \n " ) ; <nl> } <nl>  <nl> - <nl> - stringbuilder <nl> - . append ( " command line : " ) <nl> - . append ( <nl> - commandfailureutils . describecommand ( <nl> - commanddescriptionform . complete , <nl> - / * prettyprintargs = * / true , <nl> - spawnaction . getarguments ( ) , <nl> - / * environment = * / null , <nl> - / * cwd = * / null ) ) <nl> - . append ( " \n " ) ; <nl> + if ( options . includecommandline ) { <nl> + stringbuilder <nl> + . append ( " command line : " ) <nl> + . append ( <nl> + commandfailureutils . describecommand ( <nl> + commanddescriptionform . complete , <nl> + / * prettyprintargs = * / true , <nl> + spawnaction . getarguments ( ) , <nl> + / * environment = * / null , <nl> + / * cwd = * / null ) ) <nl> + . append ( " \n " ) ; <nl> + } <nl> } <nl>  <nl> if ( action instanceof executioninfospecifier ) { <nl> mmm a / src / main / java / com / google / devtools / build / lib / query2 / output / aqueryoptions . java <nl> ppp b / src / main / java / com / google / devtools / build / lib / query2 / output / aqueryoptions . java <nl>
public final class cppconfiguration extends buildconfiguration . fragment <nl> return cpptoolchaininfo . gettargetcpu ( ) ; <nl> } <nl>  <nl> - / * * <nl> - * unused , for compatibility with things internal to google . <nl> - * <nl> - * < p > deprecated : use platforms . <nl> - * / <nl> - <nl> - @ deprecated <nl> - public string gettargetos ( ) { <nl> - return cpptoolchaininfo . gettargetos ( ) ; <nl> - } <nl> - <nl> / * * <nl> * returns the path fragment that is either absolute or relative to the execution root that can be <nl> * used to execute the given tool . <nl>
public final class simpleblobstoreactioncache extends abstractremoteactioncache <nl> for ( directory directory : repository . treetodirectories ( root ) ) { <nl> uploadblob ( directory . tobytearray ( ) ) ; <nl> } <nl> - <nl> for ( treenode leaf : repository . leaves ( root ) ) { <nl> uploadfilecontents ( leaf . getactioninput ( ) , execroot , repository . getinputfilecache ( ) ) ; <nl> } <nl>
eof <nl> expect_log " to kill - 9 a hummingbird " <nl> } <nl>  <nl> - # <nl> - function disabled_test_filters_deprecated_targets ( ) { <nl> + function test_filters_deprecated_targets ( ) { <nl> local - r pkg = $ funcname <nl> init_test " test that deprecated target warnings are filtered " <nl>  <nl>
public class buildtool { <nl> } <nl> } <nl> profiler . instance ( ) . markphase ( profilephase . finish ) ; <nl> - } catch ( runtimeexception e ) { <nl> - / / print an error message for unchecked runtime exceptions . this does not concern error <nl> - / / subclasses such as outofmemoryerror . <nl> - request . getouterr ( ) . printerrln ( <nl> - " unhandled exception thrown during build ; message : " + e . getmessage ( ) ) ; <nl> - catastrophe = true ; <nl> - throw e ; <nl> - } catch ( error e ) { <nl> - catastrophe = true ; <nl> - throw e ; <nl> - } catch ( invalidconfigurationexception e ) { <nl> - <nl> - / / to a single target and have to halt the entire build . once configurations are genuinely <nl> - / / created as part of the analysis phase they should report their error on the level of the <nl> - / / target ( s ) that triggered them . <nl> + } catch ( error | runtimeexception e ) { <nl> + request <nl> + . getouterr ( ) <nl> + . printerrln ( <nl> + " internal error thrown during build . printing stack trace : " <nl> + + throwables . getstacktraceasstring ( e ) ) ; <nl> catastrophe = true ; <nl> throw e ; <nl> } finally {
public class digesthashfunction { <nl> return digestlength ; <nl> } <nl>  <nl> - public boolean isvaliddigest ( byte [ ] digest ) { <nl> - <nl> - return digest ! = null & & digest . length * num = = hashfunction . bits ( ) ; <nl> - } <nl> - <nl> @ override <nl> public string tostring ( ) { <nl> return name ; <nl> mmm a / src / main / java / com / google / devtools / build / lib / vfs / filesystem . java <nl> ppp b / src / main / java / com / google / devtools / build / lib / vfs / filesystem . java <nl>
public class bytecodetypeinferencetest { <nl> private static final path jar_path = paths . get ( system . getproperty ( " jar_path " ) ) ; <nl> private static final path golden_path = paths . get ( system . getproperty ( " golden_file " ) ) ; <nl>  <nl> - @ ignore <nl> @ test <nl> public void testtypeinference ( ) throws ioexception { <nl> stringwriter stringwriter = new stringwriter ( ) ;
public class apiexporter { <nl> value . builder field = value . newbuilder ( ) ; <nl> field . setname ( meth . getname ( ) ) ; <nl> field . setdoc ( meth . getdocumentation ( ) ) ; <nl> - <nl> - if ( ! meth . getparams ( ) . isempty ( ) ) { <nl> - callable . builder callable = callable . newbuilder ( ) ; <nl> - for ( skylarkparamdoc par : meth . getparams ( ) ) { <nl> - param . builder param = param . newbuilder ( ) ; <nl> - param . setname ( par . getname ( ) ) ; <nl> - param . settype ( par . gettype ( ) ) ; <nl> - param . setdoc ( par . getdocumentation ( ) ) ; <nl> - callable . addparam ( param ) ; <nl> - } <nl> - callable . setreturntype ( meth . getreturntype ( ) ) ; <nl> - field . setcallable ( callable ) ; <nl> + callable . builder callable = callable . newbuilder ( ) ; <nl> + for ( skylarkparamdoc par : meth . getparams ( ) ) { <nl> + param . builder param = param . newbuilder ( ) ; <nl> + param . setname ( par . getname ( ) ) ; <nl> + param . settype ( par . gettype ( ) ) ; <nl> + param . setdoc ( par . getdocumentation ( ) ) ; <nl> + callable . addparam ( param ) ; <nl> } <nl> + callable . setreturntype ( meth . getreturntype ( ) ) ; <nl> + field . setcallable ( callable ) ; <nl> return field ; <nl> }
public class apiexporter { <nl> param . setdoc ( par . getdocumentation ( ) ) ; <nl> callable . addparam ( param ) ; <nl> } <nl> - <nl> + callable . setreturntype ( meth . getreturntype ( ) ) ; <nl> field . setcallable ( callable ) ; <nl> } <nl> return field ; <nl> mmm a / src / main / java / com / google / devtools / build / docgen / skylark / skylarkbuiltinmethoddoc . java <nl> ppp b / src / main / java / com / google / devtools / build / docgen / skylark / skylarkbuiltinmethoddoc . java <nl>
public class cppcompileaction extends abstractaction <nl> return additionalinputs ; <nl> } <nl>  <nl> - if ( sourcefile . isfiletype ( cppfiletypes . cpp_module ) ) { <nl> - / / if we are generating code from a module , the module is all we need . <nl> - <nl> - usedmodules = immutableset . of ( sourcefile ) ; <nl> - additionalinputs = <nl> - new immutablelist . builder < artifact > ( ) . addall ( additionalinputs ) . add ( sourcefile ) . build ( ) ; <nl> - return additionalinputs ; <nl> - } <nl> - <nl> usedmodules = <nl> cccompilationcontext . getusedmodules ( usepic , immutableset . copyof ( additionalinputs ) ) ; <nl> return iterables . concat ( additionalinputs , usedmodules ) ;
public abstract class ccbinary implements ruleconfiguredtargetfactory { <nl> cccompilationinfobuilder . setcccompilationcontext ( cccompilationcontext ) ; <nl>  <nl> cclinkinginfo . builder cclinkinginfobuilder = cclinkinginfo . builder . create ( ) ; <nl> - <nl> - / / - - experimental_enable_cc_dynlibs_for_runtime is flipped . an empty cclinkparamsstore is not <nl> - / / needed , but here we set it to avoid a null pointer exception in places where we ' re expecting <nl> - / / it . in the future cclinkparamsstore will be obligatory . <nl> - cclinkinginfobuilder . setcclinkparamsstore ( <nl> - new cclinkparamsstore ( <nl> - / * staticmodeparamsfordynamiclibrary = * / cclinkparams . empty , <nl> - / * staticmodeparamsforexecutable = * / cclinkparams . empty , <nl> - / * dynamicmodeparamsfordynamiclibrary = * / cclinkparams . empty , <nl> - / * dynamicmodeparamsforexecutable = * / cclinkparams . empty ) ) ; <nl> if ( cppconfiguration . enableccdynamiclibrariesforruntime ( ) ) { <nl> cclinkinginfobuilder . setccdynamiclibrariesforruntime ( <nl> new ccdynamiclibrariesforruntime ( <nl> mmm a / src / main / java / com / google / devtools / build / lib / rules / cpp / cclinkinginfo . java <nl> ppp b / src / main / java / com / google / devtools / build / lib / rules / cpp / cclinkinginfo . java <nl>
public abstract class workspacestatusaction extends abstractaction { <nl> public enum keytype { <nl> integer , <nl> string , <nl> - verbatim , <nl> } <nl>  <nl> - / * * <nl> - * language for keys that should be present in the build info for every language . <nl> - * / <nl> - <nl> - / / the build_username , build_hostname and build_directory keys instead of build_info . then <nl> - / / language - specific build info keys can be removed . <nl> - public static final string all_languages = " * " ; <nl> - <nl> / * * <nl> * action context required by the actions that write language - specific workspace status artifacts . <nl> * / <nl>
public class cppcompileaction extends abstractaction <nl> public extraactioninfo . builder getextraactioninfo ( actionkeycontext actionkeycontext ) { <nl> cppcompileinfo . builder info = cppcompileinfo . newbuilder ( ) ; <nl> info . settool ( compilecommandline . gettoolpath ( ) ) ; <nl> - <nl> - / / here . for shorter command lines , we ' d prefer to use toplevelmodules here , but they are not <nl> - / / computed in the codepaths leading here . <nl> - for ( string option : <nl> - compilecommandline . getcompileroptions ( getoverwrittenvariables ( getinputs ( ) ) ) ) { <nl> + <nl> + / / for actual extra actions , the shadowed action is fully executed and overwrittenvariables get <nl> + / / computed . however , this function is also used for print_action and there , the action is <nl> + / / retrieved from the cache , the modules are reconstructed via updateinputs and <nl> + / / overwrittenvariables don ' t get computed . <nl> + list < string > options = <nl> + compilecommandline . getcompileroptions ( <nl> + overwrittenvariables ! = null <nl> + ? overwrittenvariables <nl> + : getoverwrittenvariables ( getinputs ( ) ) ) ; <nl> + <nl> + for ( string option : options ) { <nl> info . addcompileroption ( option ) ; <nl> } <nl> info . setoutputfile ( outputfile . getexecpathstring ( ) ) ;
if [ [ - z " $ { wrapper_devdir } " ] ] ; then <nl> wrapper_devdir = " $ ( xcode - select - p ) " <nl> fi <nl>  <nl> - # <nl> - # for us . <nl> - wrapper_sdkroot = " $ { sdkroot : - } " <nl> - if [ [ - z " $ { wrapper_sdkroot : - } " ] ] ; then <nl> - wrapper_sdk = iphonesimulator <nl> - for arg in " $ @ " ; do <nl> - case " $ { arg } " in <nl> - armv6 | armv7 | armv7s | arm64 ) <nl> - wrapper_sdk = iphoneos <nl> - ; ; <nl> - i386 | x86_64 ) <nl> - wrapper_sdk = iphonesimulator <nl> - ; ; <nl> - esac <nl> - done <nl> - wrapper_sdkroot = " $ ( / usr / bin / xcrun - - show - sdk - path - - sdk $ { wrapper_sdk } ) " <nl> - fi <nl> - <nl> # subsitute toolkit path placeholders . <nl> updatedargs = ( ) <nl> for arg in " $ @ " ; do <nl> arg = " $ { arg / / __bazel_xcode_developer_dir__ / $ { wrapper_devdir } } " <nl> - arg = " $ { arg / / __bazel_xcode_sdkroot__ / $ { wrapper_sdkroot } } " <nl> + arg = " $ { arg / / __bazel_xcode_sdkroot__ / $ { sdkroot } } " <nl> updatedargs + = ( " $ { arg } " ) <nl> done
public @ interface skylarkcallable { <nl> * the annotated method signature must contain skylarksemantics as a parameter . see the <nl> * interface - level javadoc for details . ) <nl> * / <nl> - <nl> boolean useskylarksemantics ( ) default false ; <nl> }
public enum linkbuildvariables { <nl>  <nl> if ( librariestolink ! = null ) { <nl> buildvariables . addcustombuiltvariable ( libraries_to_link . getvariablename ( ) , librariestolink ) ; <nl> - <nl> - buildvariables . addstringvariable ( " libs_to_link_dont_emit_objects_for_archiver " , " " ) ; <nl> } <nl>  <nl> buildvariables . addstringsequencevariable (
<nl> package ( default_visibility = [ " / / visibility : public " ] ) <nl>  <nl> - # <nl> - # in a bazel release <nl> - load ( " / / tools / jdk : alias_rules . bzl " , " java_host_runtime_alias " ) <nl> load ( <nl> " / / tools / jdk : default_java_toolchain . bzl " , <nl> " default_java_toolchain " , <nl>
callsuffix = ' ( ' [ arguments [ ' , ' ] ] ' ) ' . <nl> slicesuffix = ' [ ' [ expression ] [ ' : ' test [ ' : ' test ] ] ' ] ' . <nl> ` ` ` <nl>  <nl> - <nl> - <nl> # # # identifiers <nl>  <nl> ` ` ` text <nl>
public class skydocmain { <nl> * for rules which were not exported as top level symbols <nl> * @ throws interruptedexception if evaluation is interrupted <nl> * / <nl> - <nl> public environment eval ( <nl> path path , <nl> immutablemap . builder < string , ruleinfo > ruleinfomap ,
cc_binary ( <nl> " / / conditions : default " : [ ] , <nl> } ) , <nl> linkstatic = num , <nl> - # <nl> visibility = [ " / / visibility : public " ] , <nl> deps = [ <nl> " options " , <nl>
public interface javasemantics { <nl> ruledefinitionenvironment environment ) { <nl> return labellatebounddefault . fromtargetconfiguration ( <nl> javaconfiguration . class , <nl> - <nl> - / / @ bazel_tools / / tools / defaults can not be resolved while defaultpackage exists . <nl> - label . parseabsoluteunchecked ( java_toolchain_label ) , <nl> + environment . gettoolslabel ( java_toolchain_label ) , <nl> ( attribute . latebounddefault . resolver < javaconfiguration , label > & serializable ) <nl> ( rule , attributes , javaconfig ) - > javaconfig . gettoolchainlabel ( ) ) ; <nl> }
constraint_value ( <nl> constraint_setting = " : cc_compiler " , <nl> ) <nl>  <nl> - # <nl> cc_toolchain_alias ( name = " current_cc_toolchain " ) <nl>  <nl> + cc_host_toolchain_alias ( name = " current_cc_host_toolchain " ) <nl> + <nl> + cc_libc_top_alias ( name = " current_libc_top " ) <nl> + <nl> cc_library ( <nl> name = " malloc " , <nl> ) <nl> mmm a / tools / cpp / alias_rules . bzl <nl> ppp / dev / null <nl>
public final class environment implements freezable , debuggable { <nl> this . mutability = mutability ; <nl> } <nl>  <nl> - / * * <nl> - * obsolete , doesn ' t do anything . <nl> - * <nl> - * / <nl> - public builder setskylark ( ) { <nl> - return this ; <nl> - } <nl> - <nl> / * * enables loading or workspace phase only functions in this environment . * / <nl> public builder setphase ( phase phase ) { <nl> preconditions . checkstate ( this . phase = = phase . analysis ) ;
public class bytestreamuploadertest { <nl> retryservice . shutdownnow ( ) ; <nl> } <nl>  <nl> - @ ignore <nl> - @ test ( timeout = num ) <nl> + @ test <nl> public void singleblobuploadshouldwork ( ) throws exception { <nl> context prevcontext = withemptymetadata . attach ( ) ; <nl> remoteretrier retrier = <nl>
public final class cccompilationhelper { <nl>  <nl> / * * <nl> * create { @ code cccompilationcontext } for cc compile action from generated inputs . <nl> - * <nl> - * < p > <nl> * / <nl> - public cccompilationcontext initializecccompilationcontext ( ) { <nl> + private cccompilationcontext initializecccompilationcontext ( ) { <nl> cccompilationcontext . builder cccompilationcontextbuilder = <nl> new cccompilationcontext . builder ( rulecontext ) ;
static void startserverandconnect ( const workspacelayout * workspace_layout , <nl>  <nl> blazeserverstartup * server_startup ; <nl> server_pid = startserver ( workspace_layout , & server_startup ) ; <nl> - <nl> bazel_log ( user ) < < " starting local " < < globals - > options - > product_name <nl> < < " server and connecting to it . . . " ; <nl>  <nl> / / give the server two minutes to start up . that ' s enough to connect with a <nl> / / debugger . <nl> - auto try_until_time ( std : : chrono : : system_clock : : now ( ) + <nl> - std : : chrono : : seconds ( 120 ) ) ; <nl> + const auto start_time = std : : chrono : : system_clock : : now ( ) ; <nl> + const auto try_until_time = start_time + std : : chrono : : seconds ( 120 ) ; <nl> + / / print an update at most once every num seconds if we are still trying to <nl> + / / connect . <nl> + const auto min_message_interval = std : : chrono : : seconds ( 10 ) ; <nl> + auto last_message_time = start_time ; <nl> while ( std : : chrono : : system_clock : : now ( ) < try_until_time ) { <nl> - auto next_attempt_time ( std : : chrono : : system_clock : : now ( ) + <nl> - std : : chrono : : milliseconds ( 100 ) ) ; <nl> + const auto attempt_time = std : : chrono : : system_clock : : now ( ) ; <nl> + const auto next_attempt_time = <nl> + attempt_time + std : : chrono : : milliseconds ( 100 ) ; <nl> + <nl> if ( server - > connect ( ) ) { <nl> - fputc ( ' \n ' , stderr ) ; <nl> - fflush ( stderr ) ; <nl> delete server_startup ; <nl> return ; <nl> } <nl>  <nl> - if ( ! globals - > options - > client_debug ) { <nl> - <nl> - / / there ' s something to be said about tradition , but in this case . . . <nl> - fputc ( ' . ' , stderr ) ; <nl> - fflush ( stderr ) ; <nl> + if ( attempt_time > = ( last_message_time + min_message_interval ) ) { <nl> + auto elapsed_time = std : : chrono : : duration_cast < std : : chrono : : seconds > ( <nl> + attempt_time - start_time ) ; <nl> + bazel_log ( user ) < < " . . . still trying to connect to local " <nl> + < < globals - > options - > product_name < < " server after " <nl> + < < elapsed_time . count ( ) < < " seconds . . . " ; <nl> + last_message_time = attempt_time ; <nl> } <nl>  <nl> std : : this_thread : : sleep_until ( next_attempt_time ) ; <nl> mmm a / src / test / shell / integration / bazel_command_log_test . sh <nl> ppp b / src / test / shell / integration / bazel_command_log_test . sh <nl>
sh_test ( <nl> ] , <nl> ) <nl>  <nl> - # <nl> - # we should use a custom zip version ( singlejar ? ) . <nl> - genrule ( <nl> - name = " doc - srcs " , <nl> - testonly = num , <nl> - srcs = [ <nl> - " / / src / java_tools / singlejar : srcs " , <nl> - " / / src / main / java / com / google / devtools / build / lib / actions : srcs " , <nl> - " / / src / main / java / com / google / devtools / build / lib / rules / genquery : srcs " , <nl> - " / / src / main / java / com / google / devtools / build / lib / sandbox : srcs " , <nl> - " / / src / main / java / com / google / devtools / build / lib / standalone : srcs " , <nl> - " / / src / main / java / com / google / devtools / build / lib / worker : srcs " , <nl> - " / / src / main / java / com / google / devtools / build / lib : srcs " , <nl> - " / / src / main / protobuf : srcs " , <nl> - " / / src / tools / xcode - common : srcs " , <nl> - " / / third_party : srcs " , <nl> - ] , <nl> - outs = [ " doc - srcs . zip " ] , <nl> - cmd = " echo $ ( srcs ) | tr ' ' ' \n ' | zip - q @ $ @ " , <nl> - ) <nl> - <nl> sh_test ( <nl> name = " bazel_docgen_test " , <nl> size = " large " , <nl> mmm a / src / test / shell / bazel / remote / remote_execution_http_test . sh <nl> ppp b / src / test / shell / bazel / remote / remote_execution_http_test . sh <nl>
final class actionfilesystem extends abstractfilesystemwithcustomstat <nl>  <nl> @ override <nl> public boolean delete ( path path ) throws ioexception { <nl> - <nl> - return false ; <nl> + pathfragment execpath = asexecpath ( path ) ; <nl> + outputmetadata output = outputs . getifpresent ( execpath ) ; <nl> + return output ! = null & & outputs . asmap ( ) . remove ( execpath , output ) ; <nl> } <nl>  <nl> @ override <nl>
class testbase ( unittest . testcase ) : <nl> ' bazel_sh ' : <nl> testbase . getenv ( ' bazel_sh ' , <nl> ' c : \ \ tools \ \ msys64 \ \ usr \ \ bin \ \ bash . exe ' ) , <nl> - # <nl> - # https : / / github . com / bazelbuild / bazel / issues / 3273 <nl> - ' cc_configure_debug ' : <nl> - ' 1 ' <nl> } <nl> else : <nl> env = { ' home ' : os . path . join ( self . _temp , ' home ' ) }
public final class repositoryresolvedmodule extends blazemodule { <nl> if ( resolvedfile ! = null ) { <nl> try { <nl> writer writer = files . newwriter ( new file ( resolvedfile ) , standardcharsets . utf_8 ) ; <nl> - <nl> - writer . write ( exported_name + " = " + printer . repr ( resultbuilder . build ( ) ) ) ; <nl> + writer . write ( <nl> + exported_name <nl> + + " = " <nl> + + printer . getprettyprinter ( ) . repr ( resultbuilder . build ( ) ) . tostring ( ) ) ; <nl> writer . close ( ) ; <nl> } catch ( ioexception e ) { <nl> logger . warning ( " io error writing to file " + resolvedfile + " : " + e ) ;
public final class configuredtargetfunction implements skyfunction { <nl> return no_config_conditions ; <nl> } <nl>  <nl> - / / collect the corresponding skyframe configured target values . abort early if they haven ' t <nl> - / / been computed yet . <nl> - collection < dependency > configvaluenames ; <nl> + / / collect the actual deps , hard - coded to the current configuration ( since by definition config <nl> + / / conditions evaluate over the current target ' s configuration ) . <nl> + immutablelist . builder < dependency > depsbuilder = immutablelist . builder ( ) ; <nl> try { <nl> - configvaluenames = resolver . resolverulelabels ( <nl> - ctgvalue , configlabelmap , transitiverootcauses , trimmingtransitionfactory ) ; <nl> + for ( dependency dep : resolver . resolverulelabels ( <nl> + ctgvalue , configlabelmap , transitiverootcauses , trimmingtransitionfactory ) ) { <nl> + if ( dep . hasexplicitconfiguration ( ) & & dep . getconfiguration ( ) = = null ) { <nl> + / / bazel assumes non - existent labels are source files , which have a null configuration . <nl> + / / keep those as is . otherwise configuredtargetanddata throws an exception about a <nl> + / / source file having a non - null configuration . the error checking later in this method <nl> + / / reports a proper " bad config condition " error to the user . <nl> + depsbuilder . add ( dep ) ; <nl> + } else { <nl> + depsbuilder . add ( dependency . withconfigurationandaspects ( dep . getlabel ( ) , <nl> + ctgvalue . getconfiguration ( ) , dep . getaspects ( ) ) ) ; <nl> + } <nl> + } <nl> } catch ( inconsistentaspectorderexception e ) { <nl> throw new dependencyevaluationexception ( e ) ; <nl> } <nl> if ( env . valuesmissing ( ) ) { <nl> return null ; <nl> } <nl> - <nl> - / / no need to get new configs from skyframe - config_setting rules always use the current <nl> - / / target ' s config . <nl> - <nl> - / / simply passing this through trimconfigurations . <nl> - immutablelist . builder < dependency > staticconfigs = immutablelist . builder ( ) ; <nl> - for ( dependency dep : configvaluenames ) { <nl> - staticconfigs . add ( dependency . withconfigurationandaspects ( dep . getlabel ( ) , <nl> - ctgvalue . getconfiguration ( ) , dep . getaspects ( ) ) ) ; <nl> - } <nl> - configvaluenames = staticconfigs . build ( ) ; <nl> + immutablelist < dependency > configconditiondeps = depsbuilder . build ( ) ; <nl>  <nl> map < skykey , configuredtargetanddata > configvalues = <nl> resolveconfiguredtargetdependencies ( <nl> env , <nl> ctgvalue , <nl> - configvaluenames , <nl> + configconditiondeps , <nl> transitivepackagesforpackagerootresolution , <nl> transitiverootcauses ) ; <nl> if ( configvalues = = null ) { <nl>
public class main { <nl> help = " the rule label of the current target under analysis . " ) <nl> public string rulelabel ; <nl>  <nl> - <nl> - @ option ( <nl> - name = " fail_on_errors " , <nl> - defaultvalue = " false " , <nl> - documentationcategory = optiondocumentationcategory . undocumented , <nl> - effecttags = { optioneffecttag . unknown } , <nl> - deprecationwarning = " this will be replaced with - - checking_mode . " , <nl> - help = " fail on incomplete dependencies , otherwise emit warnings . " <nl> - ) <nl> - public boolean failonerrors ; <nl> - <nl> @ option ( <nl> name = " checking_mode " , <nl> - defaultvalue = " null " , <nl> + defaultvalue = " warning " , <nl> documentationcategory = optiondocumentationcategory . undocumented , <nl> effecttags = { optioneffecttag . unknown } , <nl> converter = checkingmodeconverter . class , <nl>
public final class runtime { <nl> throw new assertionerror ( e ) ; <nl> } <nl> } <nl> - <nl> - / * * <nl> - * registers global fields with skylarksignature into the specified environment . alias for <nl> - * { @ link # setupmoduleglobals } . <nl> - * <nl> - * @ deprecated use { @ link # setupmoduleglobals } instead . <nl> - * / <nl> - @ deprecated <nl> - <nl> - public static void registermoduleglobals ( environment env , class < ? > moduleclass ) { <nl> - setupmoduleglobals ( env , moduleclass ) ; <nl> - } <nl> }
public class repositoryresolvedevent implements postable { <nl>  <nl> immutablemap . builder < string , object > origattrbuilder = immutablemap . builder ( ) ; <nl> for ( attribute attr : rule . getattributes ( ) ) { <nl> - string name = attr . getpublicname ( ) ; <nl> - if ( ! name . startswith ( " _ " ) ) { <nl> - <nl> - / / workspace file . <nl> + if ( rule . isattributevalueexplicitlyspecified ( attr ) ) { <nl> + string name = attr . getpublicname ( ) ; <nl> try { <nl> object value = attrs . getvalue ( name , object . class ) ; <nl> - / / only record explicit values , skip computed defaults <nl> - if ( ! ( value instanceof attribute . computeddefault ) ) { <nl> - origattrbuilder . put ( name , value ) ; <nl> - } <nl> + origattrbuilder . put ( name , value ) ; <nl> } catch ( evalexception e ) { <nl> / / do nothing , just ignore the value . <nl> } <nl> mmm a / src / test / shell / bazel / workspace_resolved_test . sh <nl> ppp b / src / test / shell / bazel / workspace_resolved_test . sh <nl>
public class objectcodecregistry { <nl> * < p > also checks if there are codecs for a superclass of the given type . <nl> * / <nl> private @ nullable codecdescriptor getcodecdescriptor ( class < ? > type ) { <nl> - <nl> for ( class < ? > nexttype = type ; nexttype ! = null ; nexttype = nexttype . getsuperclass ( ) ) { <nl> codecdescriptor result = classmappedcodecs . get ( nexttype ) ; <nl> if ( result ! = null ) { <nl> + if ( nexttype ! = type ) { <nl> + classmappedcodecs . put ( type , result ) ; <nl> + } <nl> return result ; <nl> } <nl> } <nl>
public class skyqueryenvironment extends abstractblazequeryenvironment < target > <nl> . collect ( toimmutableset ( ) ) ; <nl> packagesemaphore . acquireall ( pkgids ) ; <nl> try { <nl> - iterable < skyvalue > packagevalues = graph . getsuccessfulvalues ( packagekeys ) . values ( ) ; <nl> - iterable < target > buildfiletargets = getbuildfiletargetsfrompackagevalues ( packagevalues ) ; <nl> + iterable < target > buildfiletargets = <nl> + iterables . transform ( <nl> + graph . getsuccessfulvalues ( packagekeys ) . values ( ) , <nl> + skyvalue - > ( ( packagevalue ) skyvalue ) . getpackage ( ) . getbuildfile ( ) ) ; <nl> callback . process ( buildfiletargets ) ; <nl> } finally { <nl> packagesemaphore . releaseall ( pkgids ) ; <nl> } <nl> } <nl>  <nl> - protected iterable < target > getbuildfiletargetsfrompackagevalues ( <nl> - iterable < skyvalue > packagevalues ) { <nl> - <nl> - return iterables . transform ( <nl> - iterables . filter ( <nl> - iterables . transform ( packagevalues , skyvalue - > ( ( packagevalue ) skyvalue ) . getpackage ( ) ) , <nl> - pkg - > ! pkg . containserrors ( ) ) , <nl> - package : : getbuildfile ) ; <nl> - } <nl> - <nl> / * * <nl> * calculates the set of packages that transitively depend on , via load statements , the specified <nl> * paths . the emitted { @ link target } s are build file targets .
public final class locationexpander { <nl> } <nl>  <nl> private string joinpaths ( collection < string > paths ) { <nl> - return paths . stream ( ) . map ( locationfunction : : quotepath ) . collect ( joining ( " " ) ) ; <nl> - } <nl> - <nl> - private static string quotepath ( string path ) { <nl> - <nl> - if ( path . contains ( " " ) ) { <nl> - path = " ' " + path + " ' " ; <nl> - } <nl> - return path ; <nl> + return paths . stream ( ) . map ( shellescaper : : escapestring ) . collect ( joining ( " " ) ) ; <nl> } <nl>  <nl> private string functionname ( ) {
public final class cctoolchainrule implements ruledefinition { <nl> labellatebounddefault . fromtargetconfiguration ( <nl> cppconfiguration . class , <nl> null , <nl> - <nl> ( rule , attributes , cppconfig ) - > <nl> - cppconfig . shouldincludezipperintoolchain ( ) ? zipper : null ) ) ) <nl> + shouldincludezipperintoolchain ( cppconfig ) ? zipper : null ) ) ) <nl> . add ( attr ( " : libc_top " , label ) . value ( libc_top ) ) <nl> . add ( attr ( " : fdo_optimize " , label ) . singleartifact ( ) . value ( fdo_optimize_label ) ) <nl> . add ( <nl> mmm a / src / main / java / com / google / devtools / build / lib / rules / cpp / cppconfiguration . java <nl> ppp b / src / main / java / com / google / devtools / build / lib / rules / cpp / cppconfiguration . java <nl>
public final class cppconfiguration extends buildconfiguration . fragment { <nl> return cpptoolchaininfo . isllvmcompiler ( ) ; <nl> } <nl>  <nl> - / * * <nl> - * returns true if llvm fdo optimization should be applied for this configuration . <nl> - * <nl> - * < p > deprecated : use { @ link cctoolchain # isllvmoptimizedfdo ( boolean , pathfragment ) } <nl> - * / <nl> - <nl> - @ deprecated <nl> - public boolean shouldincludezipperintoolchain ( ) { <nl> - return ( cppoptions . getfdooptimize ( ) ! = null <nl> - & & ( cppfiletypes . llvm_profile . matches ( cppoptions . getfdooptimize ( ) ) <nl> - | | cppfiletypes . llvm_profile_raw . matches ( cppoptions . getfdooptimize ( ) ) <nl> - | | ( isllvmcompiler ( ) & & cppoptions . getfdooptimize ( ) . endswith ( " . zip " ) ) ) ) <nl> - | | ( cppoptions . getfdoprofilelabel ( ) ! = null ) ; <nl> - } <nl> - <nl> / * * returns true if lipo optimization is implied by the flags of this build . * / <nl> public boolean lipooptimizationisactivated ( ) { <nl> return cppoptions . islipooptimization ( ) ; <nl> mmm a / src / test / java / com / google / devtools / build / lib / rules / cpp / cctoolchaintest . java <nl> ppp b / src / test / java / com / google / devtools / build / lib / rules / cpp / cctoolchaintest . java <nl>
<nl>  <nl> package com . google . devtools . build . lib . skylarkbuildapi ; <nl>  <nl> + import com . google . devtools . build . lib . skylarkinterface . skylarkmodule ; <nl> + import com . google . devtools . build . lib . skylarkinterface . skylarkmodulecategory ; <nl> import com . google . devtools . build . lib . skylarkinterface . skylarkvalue ; <nl>  <nl> / * * the interface for skylark - defined aspects in the build api . * / <nl> - public interface skylarkaspectapi extends skylarkvalue { <nl> - <nl> - } <nl> + @ skylarkmodule ( <nl> + name = " aspect " , <nl> + category = skylarkmodulecategory . none , <nl> + doc = <nl> + " for more information about aspects , please consult the < a href = \ " globals . html # aspect \ " > " <nl> + + " documentation of the aspect function < / a > or the " <nl> + + " < a href = \ " . . / aspects . md \ " > introduction to aspects < / a > . " <nl> + ) <nl> + public interface skylarkaspectapi extends skylarkvalue { }
public final class androidbinarymobileinstall { <nl>  <nl> javatargetattributes attributes = <nl> new javatargetattributes . builder ( javasemantics ) <nl> - <nl> - . addruntimeclasspathentries ( provider . getjavacompilationargs ( ) . getruntimejars ( ) ) <nl> + . addruntimeclasspathentries ( provider . getruntimejars ( ) ) <nl> . build ( ) ; <nl>  <nl> function < artifact , artifact > desugaredjars = functions . identity ( ) ;
blaze_exit_code : : exitcode optionprocessor : : finduserblazerc ( <nl> return blaze_exit_code : : success ; <nl> } <nl>  <nl> - <nl> namespace internal { <nl>  <nl> vector < string > dedupeblazercpaths ( const vector < string > & paths ) {
py_test ( <nl> " / / src / conditions : windows " : " windows_remote_test . py " , <nl> " / / conditions : default " : " empty_test . py " , <nl> } ) , <nl> - tags = [ " manual " ] , # <nl> deps = select ( { <nl> " / / src / conditions : windows " : [ " : test_base " ] , <nl> " / / conditions : default " : [ ] ,
public class parallelskyqueryutils { <nl> } <nl> } <nl>  <nl> - / * * helper class that computes dtc in the form of { @ link skykey } via bfs . * / <nl> - <nl> - private static class transitiveclosurevisitor extends parallelvisitor < skykey , skykey > { <nl> + / * * <nl> + * helper class that computes the ttv - only dtc of some given ttv keys , via bfs following all <nl> + * ttv - > ttv dep edges . <nl> + * / <nl> + private static class transitivetraversalvaluedtcvisitor extends parallelvisitor < skykey , skykey > { <nl> private final skyqueryenvironment env ; <nl> private final uniquifier < skykey > uniquifier ; <nl>  <nl> - private transitiveclosurevisitor ( <nl> + private transitivetraversalvaluedtcvisitor ( <nl> skyqueryenvironment env , <nl> uniquifier < skykey > uniquifier , <nl> int processresultsbatchsize , <nl>
final class skylarkdocumentationcollector { <nl> skylarkmodule skylarkmodule = moduleclass . equals ( object . class ) <nl> ? gettoplevelmodule ( ) <nl> : runtime . getskylarknamespace ( moduleclass ) . getannotation ( skylarkmodule . class ) ; <nl> - if ( skylarkmodule = = null ) { <nl> - <nl> - / / structures , namely java . util . list . remove this case when we are done . <nl> - preconditions . checkstate ( ! skylarksignature . documented ( ) ) ; <nl> - preconditions . checkstate ( moduleclass = = list . class ) ; <nl> - } else { <nl> - if ( ! modules . containskey ( skylarkmodule . name ( ) ) ) { <nl> - modules . put ( skylarkmodule . name ( ) , new skylarkmoduledoc ( skylarkmodule , moduleclass ) ) ; <nl> - } <nl> - skylarkmoduledoc module = modules . get ( skylarkmodule . name ( ) ) ; <nl> - module . addmethod ( new skylarkbuiltinmethoddoc ( module , skylarksignature , field . gettype ( ) ) ) ; <nl> + preconditions . checknotnull ( skylarkmodule ) ; <nl> + if ( ! modules . containskey ( skylarkmodule . name ( ) ) ) { <nl> + modules . put ( skylarkmodule . name ( ) , new skylarkmoduledoc ( skylarkmodule , moduleclass ) ) ; <nl> } <nl> + skylarkmoduledoc module = modules . get ( skylarkmodule . name ( ) ) ; <nl> + module . addmethod ( new skylarkbuiltinmethoddoc ( module , skylarksignature , field . gettype ( ) ) ) ; <nl> } <nl> } <nl> }
public class blazejavacmain { <nl> } <nl> filemanager . setlocationfrompaths ( standardlocation . source_path , sourcepath ) ; <nl>  <nl> - <nl> collection < path > bootclasspath = arguments . bootclasspath ( ) ; <nl> if ( ! bootclasspath . isempty ( ) ) { <nl> filemanager . setlocationfrompaths ( standardlocation . platform_class_path , bootclasspath ) ; <nl> mmm a / src / java_tools / buildjar / java / com / google / devtools / build / java / turbine / javac / javacturbinecompiler . java <nl> ppp b / src / java_tools / buildjar / java / com / google / devtools / build / java / turbine / javac / javacturbinecompiler . java <nl>
jdk9_jvm_opts = [ <nl> " - - add - exports = jdk . compiler / com . sun . tools . javac . util = all - unnamed " , <nl> " - - add - opens = jdk . compiler / com . sun . tools . javac . file = all - unnamed " , <nl>  <nl> - # <nl> - # " - - patch - module = java . compiler = $ ( location / / third_party / java / jdk / langtools / blaze : java_compiler_jar ) " , <nl> - # " - - patch - module = jdk . compiler = $ ( location / / third_party / java / jdk / langtools / blaze : jdk_compiler_jar ) " , <nl> + # override the javac in the jdk . <nl> + " - - patch - module = java . compiler = $ ( location @ bazel_tools / / third_party / java / jdk / langtools : java_compiler_jar ) " , <nl> + " - - patch - module = jdk . compiler = $ ( location @ bazel_tools / / third_party / java / jdk / langtools : jdk_compiler_jar ) " , <nl> ] <nl>  <nl> default_compatible_javacopts = { <nl>
java_library ( <nl> ] , <nl> ) <nl>  <nl> - # <nl> java_test ( <nl> name = " skylarktests " , <nl> timeout = " long " , <nl> srcs = glob ( [ <nl> " * . java " , <nl> ] ) , <nl> - flaky = num , <nl> test_class = " com . google . devtools . build . lib . alltests " , <nl> deps = [ <nl> " : testutil " ,
public final class optionsparser { <nl> throw new invalidcommandlineexception ( " unknown option : ' " + arg + " ' " ) ; <nl> } <nl> } <nl> - <nl> - if ( foundlegacydependencyargument & & foundnewdependencyargument ) { <nl> - throw new invalidcommandlineexception ( <nl> - " found both new - style and old - style dependency arguments : " <nl> - + " cannot use arguments from both " <nl> - + " ( - - direct_dependencies ) and " <nl> - + " ( - - direct_dependency , - - indirect_dependency ) " <nl> - + " at the same time . " ) ; <nl> - } <nl> } <nl>  <nl> private void sourcepathfromjavacopts ( ) {
public final class dependencymodule { <nl> private static class defaultfixmessage implements fixmessage { <nl> @ override <nl> public string get ( iterable < jarowner > missing , string recipient , dependencymodule depmodule ) { <nl> - <nl> string missingtargetsstr = <nl> streams . stream ( missing ) <nl> . flatmap ( owner - > owner . label ( ) . map ( stream : : of ) . orelse ( stream . empty ( ) ) ) <nl> - . collect ( joining ( " " , " " , " " ) ) ; <nl> + . collect ( joining ( " " ) ) ; <nl> return string . format ( <nl> " % 1 $ s * * please add the following dependencies : % 2 $ s \n % 3 $ s to % 4 $ s \n " <nl> + " % 1 $ s * * you can use the following buildozer command : % 2 $ s " <nl> mmm a / src / test / shell / bazel / local_repository_test_jdk8 . sh <nl> ppp b / src / test / shell / bazel / local_repository_test_jdk8 . sh <nl>
public class dumpcommand implements blazecommand { <nl> out . println ( ) ; <nl> } <nl>  <nl> - if ( dumpoptions . dumpvfs ) { <nl> - <nl> - out . println ( " filesystem cache " ) ; <nl> - out . println ( " dump - - vfs is no longer meaningful " ) ; <nl> - out . println ( ) ; <nl> - } <nl> - <nl> if ( dumpoptions . dumpactioncache ) { <nl> success & = dumpactioncache ( env , out ) ; <nl> out . println ( ) ;
<nl> - # ! / bin / bash <nl> - <nl> - # copyright num the bazel authors . all rights reserved . <nl> - # <nl> - # licensed under the apache license , version num . 0 ( the " license " ) ; <nl> - # you may not use this file except in compliance with the license . <nl> - # you may obtain a copy of the license at <nl> - # <nl> - # http : / / www . apache . org / licenses / license - 2 . 0 <nl> - # <nl> - # unless required by applicable law or agreed to in writing , software <nl> - # distributed under the license is distributed on an " as is " basis , <nl> - # without warranties or conditions of any kind , either express or implied . <nl> - # see the license for the specific language governing permissions and <nl> - # limitations under the license . <nl> - <nl> - set - eu <nl> - <nl> - temp_dir = " $ ( mktemp - d $ { tmpdir : - / tmp } / test_temp_dir . xxxxxx ) " <nl> - trap ' rm - rf " $ { temp_dir } " ' err exit <nl> - <nl> - test_app_dir = " $ { temp_dir } / test_app_dir " <nl> - mkdir " $ { test_app_dir } " <nl> - unzip - qq - d " $ { test_app_dir } " " % ( test_app_ipa ) s " <nl> - test_app_dir = " $ { test_app_dir } / payload / % ( test_app_name ) s . app " <nl> - <nl> - xctest_app_dir = " $ { temp_dir } / xctest_app_dir " <nl> - mkdir " $ { xctest_app_dir } " <nl> - unzip - qq - d " $ { xctest_app_dir } " " % ( xctest_app_ipa ) s " <nl> - xctest_app_dir = " $ { xctest_app_dir } / payload / % ( xctest_app_name ) s . xctest " <nl> - <nl> - killall " ios simulator " > / dev / null num > / dev / null | | : <nl> - <nl> - simhome = " $ { temp_dir } / simhome " <nl> - mkdir " $ { simhome } " <nl> - <nl> - logfile = " $ { temp_dir } / logfile " <nl> - <nl> - simulator_platform = " $ ( / usr / bin / xcrun - - sdk iphonesimulator - - show - sdk - platform - path ) " <nl> - simulator_dev_library = " $ simulator_platform / developer / library " <nl> - <nl> - " % ( iossim_path ) s " \ <nl> - - u " $ { simhome } " \ <nl> - - d " % ( device_type ) s " \ <nl> - - s " % ( simulator_sdk ) s " \ <nl> - - t num \ <nl> - - e dyld_insert_libraries = " $ simulator_dev_library / privateframeworks / idebundleinjection . framework / idebundleinjection " \ <nl> - - e " xcinjectbundle = $ { test_app_dir } " \ <nl> - - e " xcinjectbundleinto = $ { xctest_app_dir } " \ <nl> - - e dyld_fallback_framework_path = " $ simulator_dev_library / frameworks " \ <nl> - " $ { xctest_app_dir } " \ <nl> - - nstreatunknownargumentsasopen no \ <nl> - - applepersistenceignorestate yes \ <nl> - - xctest all \ <nl> - " $ { test_app_dir } " \ <nl> - num > & 1 | tee " $ { logfile } " <nl> - <nl> - killall " ios simulator " > / dev / null num > / dev / null | | : <nl> - <nl> - # <nl> - if grep - q " with [ 1 - 9 ] . * failure " " $ { logfile } " ; then <nl> - exit num <nl> - fi
public final class environment implements freezable { <nl> } <nl>  <nl> / * * inherits global bindings from the given parent frame . * / <nl> - public builder setglobals ( frame parent ) { <nl> + public builder setglobals ( globalframe parent ) { <nl> preconditions . checkstate ( this . parent = = null ) ; <nl> - <nl> - this . parent = ( globalframe ) parent ; <nl> + this . parent = parent ; <nl> return this ; <nl> }
public class cpphelper { <nl> if ( rulecontext . getrule ( ) . getattributedefinition ( " : stl " ) ! = null ) { <nl> transitiveinfocollection stl = rulecontext . getprerequisite ( " : stl " , mode . target ) ; <nl> if ( stl ! = null ) { <nl> - <nl> - cccompilationinfobuilder . addsystemincludedir ( <nl> - stl . getlabel ( ) . getpackageidentifier ( ) . getpathunderexecroot ( ) . getrelative ( " gcc3 " ) ) ; <nl> cccompilationinfo provider = stl . get ( cccompilationinfo . provider ) ; <nl> if ( provider = = null ) { <nl> rulecontext . ruleerror ( " unable to merge the stl ' " + stl . getlabel ( )
public class skylarkactionfactory implements skylarkvalue { <nl> throws evalexception { <nl> context . checkmutable ( " actions . run_shell " ) ; <nl>  <nl> - <nl> skylarklist argumentlist = ( skylarklist ) arguments ; <nl> spawnaction . builder builder = new spawnaction . builder ( ) ; <nl> buildcommandline ( builder , argumentlist ) ; <nl>
public class skylarkactionfactory implements skylarkvalue { <nl> object inputmanifestsunchecked , <nl> spawnaction . builder builder ) <nl> throws evalexception { <nl> - <nl> iterable < artifact > inputartifacts ; <nl> if ( inputs instanceof skylarklist ) { <nl> inputartifacts = ( ( skylarklist ) inputs ) . getcontents ( artifact . class , " inputs " ) ; <nl> builder . addinputs ( inputartifacts ) ; <nl> } else { <nl> - inputartifacts = ( ( skylarknestedset ) inputs ) . tocollection ( artifact . class ) ; <nl> - builder . addinputs ( ( ( skylarknestedset ) inputs ) . getset ( artifact . class ) ) ; <nl> + nestedset < artifact > inputset = ( ( skylarknestedset ) inputs ) . getset ( artifact . class ) ; <nl> + builder . addtransitiveinputs ( inputset ) ; <nl> + inputartifacts = inputset ; <nl> } <nl> builder . addoutputs ( outputs . getcontents ( artifact . class , " outputs " ) ) ;
function test_universe_scope_specified ( ) { <nl> assert_not_equals $ host_config $ target_config <nl> } <nl>  <nl> - # this test ensures the known buggy behavior described at b / 71905538 i . e . nodes <nl> - # lingering from previous builds . <nl> - # <nl> - function test_ghost_nodes_bug ( ) { <nl> - write_java_library_build <nl> - <nl> - # create host - configured / / pine : plugin node in this cquery <nl> - bazel cquery " deps ( / / pine : my_java ) " | | fail " excepted success " <nl> - # this cquery should return target configured / / pine : plugin but actually returns <nl> - # the host - configured target generated above . this is the buggy behavior . <nl> - bazel cquery / / pine : dep + / / pine : plugin \ <nl> - > output num > " $ test_log " | | fail " excepted success " <nl> - <nl> - # find the lines of output for / / pine : plugin and / / pine : dep . <nl> - plugin = $ ( grep " / / pine : plugin " output ) <nl> - dep = $ ( grep " / / pine : dep " output ) <nl> - # trim to just configurations . <nl> - plugin_config = $ { plugin / " / / pine : plugin " } <nl> - dep_config = $ { dep / " / / pine : dep " } <nl> - # ensure they are are not equal ( the buggy behavior ) . <nl> - assert_not_equals $ plugin_config $ dep_config <nl> - } <nl> - <nl> function test_host_config_output ( ) { <nl> write_java_library_build
public class blazejavacmain { <nl> " compiler . warn . sun . proprietary " ) ; <nl>  <nl> private static immutablelist < formatteddiagnostic > filterdiagnostics ( <nl> - immutablelist < formatteddiagnostic > diagnostics ) { <nl> - <nl> - immutablelist . builder < formatteddiagnostic > result = immutablelist . builder ( ) ; <nl> - diagnostics <nl> + boolean ok , immutablelist < formatteddiagnostic > diagnostics ) { <nl> + return diagnostics <nl> . stream ( ) <nl> - . filter ( d - > ! ignored_diagnostic_codes . contains ( d . getcode ( ) ) ) <nl> - . foreach ( result : : add ) ; <nl> - return result . build ( ) ; <nl> + . filter ( d - > shouldreportdiagnostic ( ok , d ) ) <nl> + . collect ( toimmutablelist ( ) ) ; <nl> + } <nl> + <nl> + private static boolean shouldreportdiagnostic ( boolean ok , formatteddiagnostic diagnostic ) { <nl> + if ( ! ignored_diagnostic_codes . contains ( diagnostic . getcode ( ) ) ) { <nl> + return true ; <nl> + } <nl> + if ( ! ok & & diagnostic . getkind ( ) ! = diagnostic . kind . note ) { <nl> + / / show compiler . warn . sun . proprietary in case we ' re running with - werror <nl> + return true ; <nl> + } <nl> + return false ; <nl> } <nl>  <nl> / * * processes plugin - specific arguments and removes them from the args array . * /
static void extractdata ( const string & self_path ) { <nl> continue ; <nl> } <nl> if ( ! blaze_util : : canreadfile ( path ) ) { <nl> - <nl> - / / somebody else fixed https : / / github . com / bazelbuild / bazel / issues / 3618 . <nl> - # if num <nl> - fprintf ( stderr , <nl> - " debug : corrupt installation : file ' % s ' missing . " <nl> - " dumping debug data . \n " , <nl> - path . c_str ( ) ) ; <nl> - string p = path ; <nl> - while ( ! p . empty ( ) ) { <nl> - fprintf ( stderr , " debug : p = ( % s ) , exists = % d , isdir = % d , canread = % d\n " , <nl> - p . c_str ( ) , blaze_util : : pathexists ( p ) ? num : num , <nl> - blaze_util : : isdirectory ( p ) ? num : num , <nl> - blaze_util : : canreadfile ( p ) ? num : num ) ; <nl> - string parent = blaze_util : : dirname ( p ) ; <nl> - if ( parent = = p ) { <nl> - break ; <nl> - } else { <nl> - p = parent ; <nl> - } <nl> - } <nl> - # endif <nl> die ( blaze_exit_code : : local_environmental_error , <nl> " error : corrupt installation : file ' % s ' missing . " <nl> " please remove ' % s ' and try again . " ,
sh_test ( <nl> size = " large " , <nl> srcs = [ " toolchain_test . sh " ] , <nl> data = [ " : test - deps " ] , <nl> - # <nl> - flaky = num , <nl> shard_count = num , <nl> )
import javax . annotation . nullable ; <nl> / * * common methods shared between android related { @ link buildviewtestcase } s . * / <nl> public abstract class androidbuildviewtestcase extends buildviewtestcase { <nl>  <nl> - @ override <nl> - protected configuredruleclassprovider getruleclassprovider ( ) { <nl> - configuredruleclassprovider . builder builder = new configuredruleclassprovider . builder ( ) ; <nl> - testruleclassprovider . addstandardrules ( builder ) ; <nl> - return builder <nl> - <nl> - . addruledefinition ( new androiddevicescriptfixturerule ( ) ) <nl> - . addruledefinition ( new androidhostservicefixturerule ( ) ) <nl> - . addruledefinition ( new androidinstrumentationtestrule ( ) ) <nl> - . build ( ) ; <nl> - } <nl> - <nl> protected iterable < artifact > getnativelibrariesinapk ( configuredtarget target ) { <nl> return iterables . filter ( <nl> getgeneratingaction ( getcompressedunsignedapk ( target ) ) . getinputs ( ) ,
public class platformoptions extends fragmentoptions { <nl> ) <nl> public string hostplatformremotepropertiesoverride ; <nl>  <nl> - <nl> + @ option ( <nl> + name = " extra_execution_platforms " , <nl> + converter = labellistconverter . class , <nl> + defaultvalue = " " , <nl> + documentationcategory = optiondocumentationcategory . toolchain , <nl> + effecttags = { optioneffecttag . execution } , <nl> + help = <nl> + " the labels of platforms that are available as execution platforms to run actions . " <nl> + + " these platforms will be considered before those declared in the workspace file by " <nl> + + " register_execution_platforms ( ) . " <nl> + ) <nl> + public list < label > extraexecutionplatforms ; <nl>  <nl> @ option ( <nl> name = " platforms " , <nl> oldname = " experimental_platforms " , <nl> - converter = buildconfiguration . labellistconverter . class , <nl> + converter = labellistconverter . class , <nl> defaultvalue = " @ bazel_tools / / platforms : target_platform " , <nl> documentationcategory = optiondocumentationcategory . toolchain , <nl> effecttags = { <nl>
abstract class abstractsandboxspawnrunner implements spawnrunner { <nl> * / <nl> protected immutableset < path > getwritabledirs ( <nl> path sandboxexecroot , map < string , string > env , path tmpdir ) throws ioexception { <nl> - filesystem filesystem = sandboxexecroot . getfilesystem ( ) ; <nl> - <nl> / / we have to make the test_tmpdir directory writable if it is specified . <nl> immutableset . builder < path > writablepaths = immutableset . builder ( ) ; <nl> writablepaths . add ( sandboxexecroot ) ; <nl> - string tmpdirstring = env . get ( " test_tmpdir " ) ; <nl> - if ( tmpdirstring ! = null ) { <nl> - path p = sandboxexecroot . getrelative ( tmpdirstring ) ; <nl> - if ( p . startswith ( sandboxexecroot ) ) { <nl> - / / we add this path even though it is below sandboxexecroot ( and thus already writable as a <nl> - / / subpath ) to take advantage of the side - effect that symlinkedexecroot also creates this <nl> - / / needed directory if it doesn ' t exist yet . <nl> - writablepaths . add ( p ) ; <nl> - } else if ( p . exists ( ) ) { <nl> - / / if ` p ` itself is a symlink , then adding it to ` writablepaths ` would result in making the <nl> - / / symlink itself writable , not what it points to . therefore we need to resolve symlinks in <nl> - / / ` p ` , however for that we need ` p ` to exist . <nl> - writablepaths . add ( p . resolvesymboliclinks ( ) ) ; <nl> - } else { <nl> - throw new ioexception ( <nl> - string . format ( <nl> - " cannot resolve symlinks in test_tmpdir because it doesn ' t exist : \ " % s \ " " , <nl> - p . getpathstring ( ) ) ) ; <nl> - } <nl> + string testtmpdir = env . get ( " test_tmpdir " ) ; <nl> + if ( testtmpdir ! = null ) { <nl> + addwritablepath ( <nl> + sandboxexecroot , <nl> + writablepaths , <nl> + sandboxexecroot . getrelative ( testtmpdir ) , <nl> + " cannot resolve symlinks in test_tmpdir because it doesn ' t exist : \ " % s \ " " ) ; <nl> } <nl> + addwritablepath ( <nl> + sandboxexecroot , <nl> + writablepaths , <nl> + tmpdir , <nl> + " cannot resolve symlinks in tmpdir because it doesn ' t exist : \ " % s \ " " ) ; <nl>  <nl> - <nl> - / / using the same method . currently we don ' t resolve symlinks in tmpdir and so we might be <nl> - / / adding a symlink to the writable paths , and not what the symlink points to . <nl> - writablepaths . add ( tmpdir ) ; <nl> - <nl> + filesystem filesystem = sandboxexecroot . getfilesystem ( ) ; <nl> for ( string writablepath : sandboxoptions . sandboxwritablepath ) { <nl> path path = filesystem . getpath ( writablepath ) ; <nl> writablepaths . add ( path ) ; <nl>
public class autocodecprocessor extends abstractprocessor { <nl> list < ? extends variableelement > parameters ) { <nl> methodspec . builder constructor = methodspec . constructorbuilder ( ) ; <nl> for ( variableelement param : parameters ) { <nl> - variableelement field = getfieldbyname ( encodedtype , param . getsimplename ( ) . tostring ( ) ) ; <nl> - if ( ! env . gettypeutils ( ) . issametype ( field . astype ( ) , param . astype ( ) ) ) { <nl> + fieldvalueandclass field = getfieldbyname ( encodedtype , param . getsimplename ( ) . tostring ( ) ) ; <nl> + if ( ! env . gettypeutils ( ) . issametype ( field . value . astype ( ) , param . astype ( ) ) ) { <nl> throw new illegalargumentexception ( <nl> encodedtype . getqualifiedname ( ) <nl> + " field " <nl> - + field . getsimplename ( ) <nl> + + field . value . getsimplename ( ) <nl> + " has mismatching type . " ) ; <nl> } <nl> builder . addfield ( <nl> typename . long , param . getsimplename ( ) + " _offset " , modifier . private , modifier . final ) ; <nl> constructor . begincontrolflow ( " try " ) ; <nl> - <nl> constructor . addstatement ( <nl> " this . $ l_offset = $ t . getinstance ( ) . objectfieldoffset ( $ t . class . getdeclaredfield ( \ " $ l \ " ) ) " , <nl> param . getsimplename ( ) , <nl> unsafeprovider . class , <nl> - encodedtype . astype ( ) , <nl> + field . declaringclasstype , <nl> param . getsimplename ( ) ) ; <nl> constructor . nextcontrolflow ( " catch ( $ t e ) " , nosuchfieldexception . class ) ; <nl> constructor . addstatement ( " throw new $ t ( e ) " , illegalstateexception . class ) ; <nl>
final class queryparser { <nl> * scan and parse the specified query expression . <nl> * / <nl> static queryexpression parse ( string query , queryenvironment < ? > env ) throws queryexception { <nl> - queryparser parser = new queryparser ( lexer . scan ( query ) , env ) ; <nl> + hashmap < string , queryfunction > functions = new hashmap < > ( ) ; <nl> + for ( queryfunction queryfunction : env . getfunctions ( ) ) { <nl> + functions . put ( queryfunction . getname ( ) , queryfunction ) ; <nl> + } <nl> + return parse ( query , functions ) ; <nl> + } <nl> + <nl> + public static queryexpression parse ( string query , hashmap < string , queryfunction > functions ) <nl> + throws queryexception { <nl> + queryparser parser = new queryparser ( lexer . scan ( query ) , functions ) ; <nl> queryexpression expr = parser . parseexpression ( ) ; <nl> if ( parser . token . kind ! = tokenkind . eof ) { <nl> throw new queryexception ( " unexpected token ' " + parser . token <nl> - + " ' after query expression ' " + expr + " ' " ) ; <nl> + + " ' after query expression ' " + expr + " ' " ) ; <nl> } <nl> return expr ; <nl> } <nl>  <nl> - private queryparser ( list < lexer . token > tokens , queryenvironment < ? > env ) { <nl> - <nl> - / / queryparser # parse to instead just pass in the set of functions to make testing , among other <nl> - / / things , simpler . <nl> - this . functions = new hashmap < > ( ) ; <nl> - for ( queryfunction queryfunction : env . getfunctions ( ) ) { <nl> - this . functions . put ( queryfunction . getname ( ) , queryfunction ) ; <nl> - } <nl> + public queryparser ( list < lexer . token > tokens , hashmap < string , queryfunction > functions ) { <nl> + this . functions = functions ; <nl> this . tokens = tokens ; <nl> this . tokeniterator = tokens . iterator ( ) ; <nl> nexttoken ( ) ; <nl> mmm a / src / test / java / com / google / devtools / build / lib / analysis / util / analysistestcase . java <nl> ppp b / src / test / java / com / google / devtools / build / lib / analysis / util / analysistestcase . java <nl>
<nl> " test_tag_filters " : [ " - slow " ] , <nl> " targets " : [ ] <nl> } <nl> - } , { <nl> - " configurations " : [ <nl> - { " node " : " freebsd - 11 " } / / , <nl> - <nl> - / / { " node " : " freebsd - 12 " } <nl> - ] , <nl> - " parameters " : { <nl> - / / as configure step , we redo the uses = shebangfix of the devel / bazel <nl> - / / port . in other words , we replace every # ! - line calling bash by a <nl> - / / line containing the correct path to bash on our test machines . <nl> - " configure " : [ <nl> - " find - e . - type f - iregex ' . * ( sh | txt | _stub | stub_ . * | bazel | get_workspace_status | protobuf_support | _so ) ' \ \ " , <nl> - " - exec sed - i ' ' \ \ " , <nl> - " - e ' 1s | ^ \ \ # ! [ [ : space : ] ] * / bin / bash \ \ ( [ [ : space : ] ] \ \ ) | \ \ # ! / usr / local / bin / bash \ \ 1 | ' \ \ " , <nl> - " - e ' 1s | ^ \ \ # ! [ [ : space : ] ] * / bin / bash $ | \ \ # ! / usr / local / bin / bash | ' \ \ " , <nl> - " - e ' 1s | ^ \ \ # ! [ [ : space : ] ] * / usr / bin / env bash \ \ ( [ [ : space : ] ] \ \ ) | \ \ # ! / usr / local / bin / bash \ \ 1 | ' \ \ " , <nl> - " - e ' 1s | ^ \ \ # ! [ [ : space : ] ] * / usr / bin / env bash $ | \ \ # ! / usr / local / bin / bash | ' \ \ " , <nl> - " { } + " <nl> - ] , <nl> - " tests " : [ <nl> - " / / src / test / shell / integration / . . . " , <nl> - " let bazel = \ " / / src / test / shell / bazel / . . . \ " in $ bazel - filter ( \ " all_tests \ " , $ bazel ) - filter ( \ " jdk \ " , $ bazel ) - filter ( \ " maven \ " , $ bazel ) - filter ( \ " android \ " , $ bazel ) - filter ( \ " java \ " , $ bazel ) - filter ( \ " workspace \ " , $ bazel ) - filter ( \ " external \ " , $ bazel ) - filter ( \ " example \ " , $ bazel ) - filter ( \ " skylark_repository \ " , $ bazel ) - filter ( \ " repository_cache \ " , $ bazel ) " <nl> - ] , <nl> - " test_tag_filters " : [ " - slow " ] , <nl> - " targets " : [ ] <nl> - } <nl> } , { <nl> " node " : " darwin - x86_64 " , <nl> " parameters " : { <nl> mmm a / scripts / ci / bootstrap . json <nl> ppp b / scripts / ci / bootstrap . json <nl>
final class queryparser { <nl> * scan and parse the specified query expression . <nl> * / <nl> static queryexpression parse ( string query , queryenvironment < ? > env ) throws queryexception { <nl> - queryparser parser = new queryparser ( lexer . scan ( query ) , env ) ; <nl> + hashmap < string , queryfunction > functions = new hashmap < > ( ) ; <nl> + for ( queryfunction queryfunction : env . getfunctions ( ) ) { <nl> + functions . put ( queryfunction . getname ( ) , queryfunction ) ; <nl> + } <nl> + return parse ( query , functions ) ; <nl> + } <nl> + <nl> + public static queryexpression parse ( string query , hashmap < string , queryfunction > functions ) <nl> + throws queryexception { <nl> + queryparser parser = new queryparser ( lexer . scan ( query ) , functions ) ; <nl> queryexpression expr = parser . parseexpression ( ) ; <nl> if ( parser . token . kind ! = tokenkind . eof ) { <nl> throw new queryexception ( " unexpected token ' " + parser . token <nl> - + " ' after query expression ' " + expr + " ' " ) ; <nl> + + " ' after query expression ' " + expr + " ' " ) ; <nl> } <nl> return expr ; <nl> } <nl>  <nl> - private queryparser ( list < lexer . token > tokens , queryenvironment < ? > env ) { <nl> - <nl> - / / queryparser # parse to instead just pass in the set of functions to make testing , among other <nl> - / / things , simpler . <nl> - this . functions = new hashmap < > ( ) ; <nl> - for ( queryfunction queryfunction : env . getfunctions ( ) ) { <nl> - this . functions . put ( queryfunction . getname ( ) , queryfunction ) ; <nl> - } <nl> + public queryparser ( list < lexer . token > tokens , hashmap < string , queryfunction > functions ) { <nl> + this . functions = functions ; <nl> this . tokens = tokens ; <nl> this . tokeniterator = tokens . iterator ( ) ; <nl> nexttoken ( ) ; <nl> mmm a / src / test / java / com / google / devtools / build / lib / analysis / util / analysistestcase . java <nl> ppp b / src / test / java / com / google / devtools / build / lib / analysis / util / analysistestcase . java <nl>
public final class androidruleclasses { <nl> obfuscation . <nl> < ! - - # end_blaze_rule . attribute - - > * / <nl> . add ( attr ( " proguard_apply_dictionary " , label ) . legacyallowanyfiletype ( ) ) <nl> - <nl> - . add ( <nl> - attr ( " legacy_native_support " , tristate ) <nl> - . value ( tristate . auto ) <nl> - . undocumented ( " no - op , soon to be removed " ) ) <nl> . add ( attr ( " : extra_proguard_specs " , label_list ) . value ( javasemantics . extra_proguard_specs ) ) <nl> . add ( <nl> attr ( " : bytecode_optimizers " , label_list )
public final class packagefactory { <nl> return pkgbuilder ; <nl> } <nl>  <nl> - / * * visit all targets and expand the globs in parallel . * / <nl> - / * * <nl> - * tests a build ast to ensure that it contains no assignment statements that redefine built - in <nl> - * build rules . <nl> - * <nl> - * @ param pkgenv a package environment initialized with all of the built - in build rules <nl> - * @ param ast the build file ast to be tested <nl> - * @ param eventhandler a eventhandler where any errors should be logged <nl> - * @ return true if the build file contains no redefinitions of built - in functions <nl> - * / <nl> - <nl> - private static boolean validateassignmentstatements ( <nl> - environment pkgenv , buildfileast ast , extendedeventhandler eventhandler ) { <nl> - for ( statement stmt : ast . getstatements ( ) ) { <nl> - if ( stmt instanceof assignmentstatement ) { <nl> - expression lvalue = ( ( assignmentstatement ) stmt ) . getlvalue ( ) . getexpression ( ) ; <nl> - if ( ! ( lvalue instanceof identifier ) ) { <nl> - continue ; <nl> - } <nl> - string target = ( ( identifier ) lvalue ) . getname ( ) ; <nl> - if ( pkgenv . hasvariable ( target ) ) { <nl> - eventhandler . handle ( event . error ( stmt . getlocation ( ) , " reassignment of builtin build " <nl> - + " function ' " + target + " ' not permitted " ) ) ; <nl> - return false ; <nl> - } <nl> - } <nl> - } <nl> - return true ; <nl> - } <nl> - <nl> / / reports an error and returns false iff package identifier was illegal . <nl> private static boolean validatepackageidentifier ( <nl> packageidentifier packageid , location location , extendedeventhandler eventhandler ) { <nl> mmm a / src / test / java / com / google / devtools / build / lib / packages / packagefactorytest . java <nl> ppp b / src / test / java / com / google / devtools / build / lib / packages / packagefactorytest . java <nl>
public final class optionsparser { <nl> private static final splitter classpath_splitter = <nl> splitter . on ( file . pathseparatorchar ) . trimresults ( ) . omitemptystrings ( ) ; <nl>  <nl> - <nl> - private static void collectclasspatharguments ( collection < string > output , deque < string > args ) { <nl> - for ( string arg = args . pollfirst ( ) ; arg ! = null ; arg = args . pollfirst ( ) ) { <nl> - if ( arg . startswith ( " - " ) ) { <nl> - args . addfirst ( arg ) ; <nl> - break ; <nl> - } <nl> - iterables . addall ( output , classpath_splitter . split ( arg ) ) ; <nl> - } <nl> - } <nl> - <nl> / * * <nl> * collects the arguments for the - - processors command line flag until it finds a flag that starts <nl> * with the terminatorprefix .
filegroup ( <nl> visibility = [ " / / src / main / native : __pkg__ " ] , <nl> ) <nl>  <nl> - # <nl> - # regard to where it is used ( / / src / main / native : embedded_tools ) . <nl> - # context : https : / / github . com / bazelbuild / bazel / commit / <commit_id> <nl> filegroup ( <nl> name = " embedded_tools " , <nl> - srcs = [ " : srcs " ] , <nl> + srcs = [ <nl> + " build " , <nl> + " file . cc " , <nl> + " file . h " , <nl> + " util . cc " , <nl> + " util . h " , <nl> + ] , <nl> visibility = [ " / / src / main / native : __pkg__ " ] , <nl> )
eof <nl> expect_log " executing genrule / / : test failed : " <nl> } <nl>  <nl> - # <nl> - function disabled_test_sandbox_mount_customized_path ( ) { <nl> + function test_sandbox_mount_customized_path ( ) { <nl> + <nl> + if ! [ " $ { platform - } " = " linux " - a \ <nl> + " $ ( cat / dev / null / etc / * release | grep ' distrib_codename = ' | sed ' s / ^ . * = / / ' ) " = " trusty " ] ; then <nl> + echo " skipping test : the toolchain used in this test is only supported on trusty . " <nl> + return num <nl> + fi <nl> + <nl> # create build file <nl> cat > build < < ' eof ' <nl> package ( default_visibility = [ " / / visibility : public " ] ) <nl>
public class buildconfiguration implements buildevent { <nl>  <nl> @ option ( <nl> name = " auto_cpu_environment_group " , <nl> - <nl> - / / removed <nl> - oldname = " experimental_auto_cpu_environment_group " , <nl> converter = emptytonulllabelconverter . class , <nl> defaultvalue = " " , <nl> category = " flags " ,
public class bazelruleclassprovider { <nl> } <nl> } ; <nl>  <nl> - / * * <nl> - * set the label for windows def parser . in bazel , it should be <nl> - * @ bazel_tools / / tools / def_parser : def_parser , otherwise it should be null . <nl> - * <nl> - * < p > <nl> - * related bug b / 63658220 <nl> - * / <nl> - public static final ruleset cpp_rules = cpprules ( " @ bazel_tools / / tools / def_parser : def_parser " ) ; <nl> - <nl> - public static ruleset cpprules ( ) { <nl> - return cpprules ( null ) ; <nl> - } <nl> + public static final ruleset cpp_rules = <nl> + new ruleset ( ) { <nl> + @ override <nl> + public void init ( builder builder ) { <nl> + builder . addconfig ( <nl> + cppoptions . class , new cppconfigurationloader ( functions . < string > identity ( ) ) ) ; <nl>  <nl> - public static ruleset cpprules ( string defparserlabel ) { <nl> - return new ruleset ( ) { <nl> - @ override <nl> - public void init ( builder builder ) { <nl> - builder . addconfig ( <nl> - cppoptions . class , new cppconfigurationloader ( functions . < string > identity ( ) ) ) ; <nl> - <nl> - builder . addbuildinfofactory ( new cppbuildinfo ( ) ) ; <nl> - builder . adddynamictransitionmaps ( cppruleclasses . dynamic_transitions_map ) ; <nl> - <nl> - builder . addruledefinition ( new cctoolchainrule ( defparserlabel ) ) ; <nl> - builder . addruledefinition ( new cctoolchainsuiterule ( ) ) ; <nl> - builder . addruledefinition ( new cctoolchainalias . cctoolchainaliasrule ( ) ) ; <nl> - builder . addruledefinition ( new ccinclibraryrule ( ) ) ; <nl> - builder . addruledefinition ( new bazelcppruleclasses . cclinkingrule ( ) ) ; <nl> - builder . addruledefinition ( new bazelcppruleclasses . ccdeclrule ( ) ) ; <nl> - builder . addruledefinition ( new bazelcppruleclasses . ccbaserule ( ) ) ; <nl> - builder . addruledefinition ( new bazelcppruleclasses . ccrule ( ) ) ; <nl> - builder . addruledefinition ( new bazelcppruleclasses . ccbinarybaserule ( ) ) ; <nl> - builder . addruledefinition ( new bazelccbinaryrule ( ) ) ; <nl> - builder . addruledefinition ( new bazelcctestrule ( ) ) ; <nl> - builder . addruledefinition ( new bazelcppruleclasses . cclibrarybaserule ( ) ) ; <nl> - builder . addruledefinition ( new bazelcclibraryrule ( ) ) ; <nl> - builder . addruledefinition ( new bazelccinclibraryrule ( ) ) ; <nl> - } <nl> - <nl> - @ override <nl> - public immutablelist < ruleset > requires ( ) { <nl> - return immutablelist . of ( corerules . instance , platform_rules ) ; <nl> - } <nl> - } ; <nl> - } <nl> + builder . addbuildinfofactory ( new cppbuildinfo ( ) ) ; <nl> + builder . adddynamictransitionmaps ( cppruleclasses . dynamic_transitions_map ) ; <nl> + <nl> + builder . addruledefinition ( <nl> + new cctoolchainrule ( " @ bazel_tools / / tools / def_parser : def_parser " ) ) ; <nl> + builder . addruledefinition ( new cctoolchainsuiterule ( ) ) ; <nl> + builder . addruledefinition ( new cctoolchainalias . cctoolchainaliasrule ( ) ) ; <nl> + builder . addruledefinition ( new ccinclibraryrule ( ) ) ; <nl> + builder . addruledefinition ( new bazelcppruleclasses . cclinkingrule ( ) ) ; <nl> + builder . addruledefinition ( new bazelcppruleclasses . ccdeclrule ( ) ) ; <nl> + builder . addruledefinition ( new bazelcppruleclasses . ccbaserule ( ) ) ; <nl> + builder . addruledefinition ( new bazelcppruleclasses . ccrule ( ) ) ; <nl> + builder . addruledefinition ( new bazelcppruleclasses . ccbinarybaserule ( ) ) ; <nl> + builder . addruledefinition ( new bazelccbinaryrule ( ) ) ; <nl> + builder . addruledefinition ( new bazelcctestrule ( ) ) ; <nl> + builder . addruledefinition ( new bazelcppruleclasses . cclibrarybaserule ( ) ) ; <nl> + builder . addruledefinition ( new bazelcclibraryrule ( ) ) ; <nl> + builder . addruledefinition ( new bazelccinclibraryrule ( ) ) ; <nl> + } <nl> + <nl> + @ override <nl> + public immutablelist < ruleset > requires ( ) { <nl> + return immutablelist . of ( corerules . instance , platform_rules ) ; <nl> + } <nl> + } ; <nl>  <nl> public static final ruleset cpp_proto_rules = <nl> new ruleset ( ) {
public class j2objcaspect extends nativeaspectclass implements configuredaspectf <nl> label . parseabsoluteunchecked ( <nl> toolsrepository + " / / tools / j2objc : j2objc_proto_blacklist " ) ) ) ) <nl> . add ( attr ( " : j2objc_cc_toolchain " , label ) . value ( objcruleclasses . apple_toolchain ) ) <nl> - . add ( <nl> - / / objc builds do not use a lipo context collector , but must specify the attribute as <nl> - / / a late - bound attribute to match with the similar attribute on the cc rules . <nl> - <nl> - / / null instance . <nl> - attr ( " : lipo_context_collector " , label ) <nl> - . value ( latebounddefault . alwaysnull ( ) ) <nl> - . skipprereqvalidatorcheck ( ) ) <nl> . build ( ) ; <nl> } <nl>  <nl> mmm a / src / main / java / com / google / devtools / build / lib / rules / objc / objcruleclasses . java <nl> ppp b / src / main / java / com / google / devtools / build / lib / rules / objc / objcruleclasses . java <nl>
public class objcruleclasses { <nl> . add ( <nl> attr ( cctoolchain . cc_toolchain_type_attribute_name , label ) <nl> . value ( cppruleclasses . cctoolchaintypeattribute ( env ) ) ) <nl> - . add ( <nl> - / / objc builds do not use a lipo context collector , but must specify the attribute as <nl> - / / a late - bound attribute to match with the similar attribute on the cc rules . <nl> - <nl> - / / null instance . <nl> - attr ( " : lipo_context_collector " , label ) <nl> - . value ( latebounddefault . alwaysnull ( ) ) <nl> - . skipprereqvalidatorcheck ( ) ) <nl> . addrequiredtoolchains ( <nl> immutablelist . of ( cpphelper . getcctoolchaintype ( env . gettoolsrepository ( ) ) ) ) <nl> . build ( ) ;
) : ] . strip ( ) ) <nl> + yield code , expected_errors <nl> + <nl> + def evaluate ( self , f ) : <nl> + " " " execute skylark file , return stderr . " " " <nl> + proc = subprocess . popen ( <nl> + [ testenv . skylark_binary_path , f ] , stderr = subprocess . pipe ) <nl> + _ , stderr = proc . communicate ( ) <nl> + return stderr <nl> + <nl> + def check_output ( self , output , expected ) : <nl> + if expected and not output : <nl> + raise exception ( " expected error : " , expected ) <nl> + <nl> + if output and not expected : <nl> + raise exception ( " unexpected error : " , output ) <nl> + <nl> + for exp in expected : <nl> + if not re . search ( exp , output ) : <nl> + raise exception ( " error ` { } ` not found , got : { } " . format ( exp , output ) ) <nl>  <nl> def testsuccess ( self ) : <nl> tests = [ " int . sky " , " equality . sky " , " and_or_not . sky " ] <nl> for t in tests : <nl> - print subprocess . check_output ( <nl> - [ testenv . skylark_binary_path , <nl> - os . path . join ( testenv . skylark_testdata_path , t ) ] ) <nl> - <nl> - # <nl> + print ( " = = = " , t , " = = = " ) <nl> + f = os . path . join ( testenv . skylark_testdata_path , t ) <nl> + for chunk , expected in self . chunks ( f ) : <nl> + with tempfile . namedtemporaryfile ( suffix = " . sky " , delete = false ) as tmp : <nl> + tmp . writelines ( chunk ) <nl> + output = self . evaluate ( tmp . name ) <nl> + os . unlink ( tmp . name ) <nl> + self . check_output ( output , expected ) <nl>  <nl>  <nl> if __name__ = = " __main__ " : <nl> mmm a / src / test / skylark / testdata / int . sky <nl> ppp b / src / test / skylark / testdata / int . sky <nl>
test_suite ( <nl> " / / src / test / shell / bazel : bazel_bootstrap_distfile_test " , <nl> " / / src / test / shell / bazel : bazel_windows_example_test " , <nl> " / / src / tools / launcher : all_windows_tests " , <nl> - # <nl> - # corresponding target to the third_party package on github . <nl> - # " / / third_party / def_parser : all_windows_tests " , <nl> + " / / third_party / def_parser : all_windows_tests " , <nl> ] , <nl> )
public class androidconfiguration extends buildconfiguration . fragment { <nl> ) <nl> public boolean incrementaldexing ; <nl>  <nl> - <nl> - @ option ( <nl> - name = " host_incremental_dexing " , <nl> - defaultvalue = " false " , <nl> - metadatatags = { optionmetadatatag . hidden } , <nl> - documentationcategory = optiondocumentationcategory . undocumented , <nl> - effecttags = { optioneffecttag . unknown } , <nl> - help = <nl> - " this flag is deprecated in favor of applying - - incremental_dexing to both host " <nl> - + " and target configuration . this flag will be removed in a future release . " <nl> - ) <nl> - public boolean hostincrementaldexing ; <nl> - <nl> / / do not use on the command line . <nl> / / the idea is that this option lets us gradually turn on incremental dexing for different <nl> / / binaries . users should rely on - - noincremental_dexing to turn it off .
class remotespawnrunner implements spawnrunner { <nl> . build ( ) ; <nl> } <nl>  <nl> - private actionresult executeremotely ( action action , int numinputfiles , boolean acceptcachedresult ) <nl> - throws ioexception , interruptedexception { <nl> - <nl> - executerequest . builder request = <nl> - executerequest . newbuilder ( ) <nl> - . setinstancename ( options . remoteinstancename ) <nl> - . setaction ( action ) <nl> - . settotalinputfilecount ( numinputfiles ) <nl> - . setskipcachelookup ( ! acceptcachedresult ) ; <nl> - executeresponse reply = remoteexecutor . executeremotely ( request . build ( ) ) ; <nl> - return reply . getresult ( ) ; <nl> - } <nl> - <nl> private spawnresult execlocallyorfail ( <nl> spawn spawn , <nl> spawnexecutionpolicy policy ,
public class androidconfiguration extends buildconfiguration . fragment { <nl>  <nl> / / do not use on the command line . <nl> / / this flag is intended to be updated as we add supported flags to the incremental dexing tools <nl> - <nl> @ option ( <nl> name = " dexopts_supported_in_dexmerger " , <nl> converter = converters . commaseparatedoptionlistconverter . class , <nl> - defaultvalue = " - - no - optimize , - - no - locals , - - minimal - main - dex , - - set - max - idx - number " , <nl> + defaultvalue = " - - minimal - main - dex , - - set - max - idx - number " , <nl> metadatatags = { optionmetadatatag . hidden } , <nl> documentationcategory = optiondocumentationcategory . undocumented , <nl> effecttags = { optioneffecttag . unknown } ,
public final class mockprotosupport { <nl> * / <nl> public static void setup ( mocktoolsconfig config ) throws ioexception { <nl> createnetproto2 ( config ) ; <nl> - <nl> - createjspbplugin ( config ) ; <nl> createjavascriptclosureproto2 ( config ) ; <nl> } <nl>  <nl>
public final class buildconfiguration implements buildevent { <nl> ) <nl> public string cpu ; <nl>  <nl> - / * * <nl> - * allows a configuration to record if - - experimental_multi_cpu was used to set a cpu value . <nl> - * this is necessary to ensure that a configuration transition that sets cpu does not erase the <nl> - * difference between a pair of configurations created by - - experimental_multi_cpu , leading to a <nl> - * crash when the configurations are treated as the same . <nl> - * <nl> - * < p > <nl> - * / <nl> - @ option ( <nl> - name = " experimental multi cpu distinguisher " , <nl> - defaultvalue = " " , <nl> - documentationcategory = optiondocumentationcategory . undocumented , <nl> - effecttags = { optioneffecttag . unknown } , <nl> - metadatatags = { optionmetadatatag . internal } <nl> - ) <nl> - public string experimentalmulticpudistinguisher ; <nl> - <nl> @ option ( <nl> name = " min_param_file_size " , <nl> defaultvalue = " 32768 " , <nl> mmm a / src / main / java / com / google / devtools / build / lib / skyframe / skyframeexecutor . java <nl> ppp b / src / main / java / com / google / devtools / build / lib / skyframe / skyframeexecutor . java <nl>
shard_number = { <nl> " dbg " : num , <nl> } <nl>  <nl> - # <nl> [ <nl> [ py_test ( <nl> name = " test_cc_configure - % s - % s " % ( flavour , mode ) , <nl>
<nl> ] <nl> } <nl> } , <nl> - <nl> { <nl> " variation " : " " , <nl> " node " : " windows - x86_64 " ,
public class httpdownloader { <nl> } <nl> } <nl>  <nl> - <nl> clock clock = new javaclock ( ) ; <nl> sleeper sleeper = new javasleeper ( ) ; <nl> locale locale = locale . getdefault ( ) ;
public class java7compatibility extends classvisitor { <nl> / / initializer instead <nl> return null ; <nl> } <nl> - <nl> checkargument ( ! isinterface <nl> | | bitflags . isset ( access , opcodes . acc_abstract ) <nl> | | " < clinit > " . equals ( name ) ,
public final class objccommon { <nl>  <nl> for ( objcprovider provider : runtimedepobjcproviders ) { <nl> objcprovider . addtransitiveandpropagate ( objcprovider . dynamic_framework_file , provider ) ; <nl> - <nl> - / / no longer provided by ios_framework . <nl> objcprovider . addtransitiveandpropagate ( objcprovider . static_framework_file , provider ) ; <nl> objcprovider . addtransitiveandpropagate ( objcprovider . merge_zip , provider ) ; <nl> }
public class multiarchbinarysupport { <nl> . addnonpropagateddepobjcproviders ( nonpropagatedobjcdeps ) <nl> . setintermediateartifacts ( intermediateartifacts ) <nl> . setalwayslink ( false ) <nl> - <nl> . setlinkedbinary ( intermediateartifacts . strippedsinglearchitecturebinary ( ) ) ; <nl>  <nl> if ( objcruleclasses . objcconfiguration ( rulecontext ) . generatedsym ( ) ) {
public class xcodeversionrule implements ruledefinition { <nl> static final string default_ios_sdk_version_attr_name = " default_ios_sdk_version " ; <nl> static final string default_watchos_sdk_version_attr_name = " default_watchos_sdk_version " ; <nl> static final string default_tvos_sdk_version_attr_name = " default_tvos_sdk_version " ; <nl> - <nl> - static final string deprecated_default_macosx_sdk_version_attr_name = <nl> - " default_macosx_sdk_version " ; <nl> - static final string default_macos_sdk_version_attr_name = <nl> - " default_macos_sdk_version " ; <nl> + static final string default_macos_sdk_version_attr_name = " default_macos_sdk_version " ; <nl>  <nl> @ override <nl> public ruleclass build ( builder builder , ruledefinitionenvironment env ) { <nl>
def _swift_lib_dir ( ctx ) : <nl>  <nl> # we cannot use non xcode - packaged toolchains , and the only one non - default <nl> # toolchain known to exist ( as of xcode num . 1 ) is this one . <nl> - # <nl> if toolchain = = " com . apple . dt . toolchain . swift_2_3 " : <nl> toolchain_name = " swift_2 . 3 "
public class grpcremotecache implements remoteactioncache { <nl> repository . getdatafromdigests ( missingdigests , missingactioninputs , missingtreenodes ) ; <nl>  <nl> if ( ! missingtreenodes . isempty ( ) ) { <nl> - <nl> - batchupdateblobsrequest . builder treeblobrequest = <nl> - batchupdateblobsrequest . newbuilder ( ) . setinstancename ( options . remoteinstancename ) ; <nl> + list < chunker > toupload = new arraylist < > ( missingtreenodes . size ( ) ) ; <nl> for ( directory d : missingtreenodes ) { <nl> - byte [ ] data = d . tobytearray ( ) ; <nl> - treeblobrequest <nl> - . addrequestsbuilder ( ) <nl> - . setcontentdigest ( digests . computedigest ( data ) ) <nl> - . setdata ( bytestring . copyfrom ( data ) ) ; <nl> + toupload . add ( new chunker ( d . tobytearray ( ) ) ) ; <nl> } <nl> - retrier . execute ( <nl> - ( ) - > { <nl> - batchupdateblobsresponse response = <nl> - casblockingstub ( ) . batchupdateblobs ( treeblobrequest . build ( ) ) ; <nl> - for ( batchupdateblobsresponse . response r : response . getresponseslist ( ) ) { <nl> - if ( ! status . fromcodevalue ( r . getstatus ( ) . getcode ( ) ) . isok ( ) ) { <nl> - throw statusproto . tostatusruntimeexception ( r . getstatus ( ) ) ; <nl> - } <nl> - } <nl> - return null ; <nl> - } ) ; <nl> + uploader . uploadblobs ( toupload ) ; <nl> } <nl> uploadblob ( command . tobytearray ( ) ) ; <nl> if ( ! missingactioninputs . isempty ( ) ) {
string binarylauncherbase : : getrunfilespath ( ) const { <nl>  <nl> void binarylauncherbase : : parsemanifestfile ( manifestfilemap * manifest_file_map , <nl> const string & manifest_path ) { <nl> - <nl> - / / std : : ifstream supports long paths , but only if they are in the correct <nl> - / / format , e . g . " \ \ \ \ ? \ \ c : \ \ imagine \ \ some \ \ very \ \ long \ \ path . txt " . <nl> - ifstream manifest_file ( manifest_path . c_str ( ) ) ; <nl> + ifstream manifest_file ( asabsolutewindowspath ( manifest_path . c_str ( ) ) . c_str ( ) ) ; <nl>  <nl> if ( ! manifest_file ) { <nl> die ( " couldn ' t open manifest file : % s " , manifest_path . c_str ( ) ) ; <nl> mmm a / src / tools / launcher / util / build <nl> ppp b / src / tools / launcher / util / build <nl>
public class objcruleclasses { <nl> attr ( " runtime_deps " , label_list ) <nl> . direct_compile_time_input ( ) <nl> . allowedruleclasses ( " objc_framework " ) <nl> - <nl> - . allowedruleclasseswithwarning ( " ios_framework " ) <nl> . allowedfiletypes ( ) ) <nl> / * < ! - - # blaze_rule ( $ objc_compiling_rule ) . attribute ( non_propagated_deps ) - - > <nl> the list of targets that are required in order to build this target ,
public class legacycompilationsupport extends compilationsupport { <nl> ? strippingtype . dynamic_lib <nl> : strippingtype . default ; <nl> } catch ( commandlineexpansionexception e ) { <nl> - <nl> - / / in the analysis phase <nl> / / this can ' t actually happen , because the command lines used by this class do <nl> - / / not throw . <nl> + / / not throw . this class is slated for deletion , so throwing an assertion is good enough . <nl> throw new assertionerror ( " cannot fail to expand command line but did . " , e ) ; <nl> } <nl> }
<nl> ] , <nl> " opts " : [ <nl> " - - copt = - w " , <nl> - " - - host_copt = - w " , <nl> - <nl> - / / remove it after wrapper - less crosstool becomes default <nl> - " - - action_env = no_msvc_wrapper = 1 " <nl> + " - - host_copt = - w " <nl> ] <nl> } <nl> } <nl> mmm a / scripts / ci / windows / compile_windows . sh <nl> ppp b / scripts / ci / windows / compile_windows . sh <nl>
fi <nl> export msys_no_pathconv = 1 <nl> export msys2_arg_conv_excl = " * " <nl>  <nl> - # <nl> - export no_msvc_wrapper = 1 <nl> - <nl> echo " bootstrap_bazel version : " <nl> $ { bootstrap_bazel } - - bazelrc = $ { bazelrc : - / dev / null } - - nomaster_bazelrc version
public final class rulecontext extends targetcontext <nl> * false if it should just create the manifest . <nl> * / <nl> public boolean shouldcreaterunfilessymlinks ( ) { <nl> - <nl> - / / always use the buildconfiguration # buildrunfiles ( ) to determine <nl> - / / whether to build the runfiles . the problem is that certain build <nl> - / / steps actually consume their runfiles . these include : <nl> - / / a . par files consumes the runfiles directory <nl> - / / we should modify autopar to take a list of files instead . <nl> - / / of the runfiles directory . <nl> - / / b . host tools could potentially use data files , but currently don ' t <nl> - / / ( they ' re run from the execution root , not a runfiles tree ) . <nl> - / / currently hostconfiguration . buildrunfiles ( ) returns true . <nl> - if ( istesttarget ( ) ) { <nl> - / / tests are only executed during testing ( duh ) , <nl> - / / and their runfiles are generated lazily on local <nl> - / / execution ( see localteststrategy ) . therefore , it <nl> - / / is safe not to build their runfiles . <nl> - return getconfiguration ( ) . buildrunfiles ( ) ; <nl> - } else { <nl> - return true ; <nl> - } <nl> + return getconfiguration ( ) . buildrunfiles ( ) ; <nl> } <nl>  <nl> / * * <nl> mmm a / src / main / java / com / google / devtools / build / lib / analysis / config / buildconfiguration . java <nl> ppp b / src / main / java / com / google / devtools / build / lib / analysis / config / buildconfiguration . java <nl>
public final class validationenvironment { <nl> private class scope { <nl> private final set < string > variables = new hashset < > ( ) ; <nl> private final set < string > readonlyvariables = new hashset < > ( ) ; <nl> - / / a stack of variable - sets which are read only but can be assigned in different <nl> - / / branches of if - else statements . <nl> - <nl> - private final stack < set < string > > futurereadonlyvariables = new stack < > ( ) ; <nl> @ nullable private final scope parent ; <nl>  <nl> scope ( @ nullable scope parent ) { <nl>
sh_test ( <nl>  <nl> sh_test ( <nl> name = " skylark_flag_test " , <nl> - size = " small " , <nl> + size = " medium " , <nl> srcs = [ " skylark_flag_test . sh " ] , <nl> data = [ " : test - deps " ] , <nl> - # <nl> - tags = [ " manual " ] , <nl> ) <nl>  <nl> sh_test (
public class objccppsemantics implements cppsemantics { <nl> actionbuilder . addtransitivemandatoryinputs ( objcprovider . get ( static_framework_file ) ) ; <nl> actionbuilder . addtransitivemandatoryinputs ( objcprovider . get ( dynamic_framework_file ) ) ; <nl>  <nl> - immutableset . builder < artifact > generatedheaders = immutableset . builder ( ) ; <nl> - <nl> - <nl> - / / it here . <nl> - for ( artifact header : objcprovider . get ( header ) ) { <nl> - if ( ! header . issourceartifact ( ) ) { <nl> - generatedheaders . add ( header ) ; <nl> - } <nl> - } <nl> - actionbuilder . addmandatoryinputs ( generatedheaders . build ( ) ) ; <nl> - <nl> if ( isheaderthinningenabled ) { <nl> artifact sourcefile = actionbuilder . getsourcefile ( ) ; <nl> if ( ! sourcefile . istreeartifact ( ) <nl>
toolchain { <nl> } <nl> } <nl>  <nl> - # stop adding any flag for dotd file , bazel knows how to parse the output of / showincludes option <nl> - # <nl> - feature { <nl> - name : ' dependency_file ' <nl> - } <nl> - <nl> # tell bazel to parse the output of / showincludes <nl> feature { <nl> name : ' parse_showincludes ' <nl>
public class cppoptions extends fragmentoptions { <nl> ) <nl> public boolean skipstaticoutputs ; <nl>  <nl> - <nl> - @ option ( <nl> - name = " send_transitive_header_module_srcs " , <nl> - defaultvalue = " true " , <nl> - category = " semantics " , <nl> - documentationcategory = optiondocumentationcategory . uncategorized , <nl> - effecttags = { optioneffecttag . unknown } , <nl> - help = " obsolete . don ' t use . " <nl> - ) <nl> - public boolean sendtransitiveheadermodulesrcs ; <nl> - <nl> @ option ( <nl> name = " process_headers_in_dependencies " , <nl> defaultvalue = " false " ,
public final class androidruleclasses { <nl> these compiler options are passed to javac after the global compiler options . < / p > <nl> < ! - - # end_blaze_rule . attribute - - > * / <nl> . add ( attr ( " javacopts " , string_list ) ) <nl> - <nl> - / / like all the rest of android tools . <nl> . add ( <nl> attr ( " $ jarjar_bin " , label ) <nl> . cfg ( host ) <nl> . exec ( ) <nl> - . value ( env . gettoolslabel ( " / / third_party / java / jarjar : jarjar_bin " ) ) ) <nl> + . value ( env . gettoolslabel ( " / / tools / android : jarjar_bin " ) ) ) <nl> . add ( <nl> attr ( " $ idlclass " , label ) <nl> . cfg ( host ) <nl> mmm a / src / test / java / com / google / devtools / build / lib / analysis / mock / bazelanalysismock . java <nl> ppp b / src / test / java / com / google / devtools / build / lib / analysis / mock / bazelanalysismock . java <nl>
public final class buildconfiguration implements buildevent { <nl> * values for - - experimental_dynamic_configs . <nl> * / <nl> public enum dynamicconfigsmode { <nl> - / * * don ' t use dynamic configurations . * / <nl> - off , <nl> / * * use dynamic configurations , including only the fragments each rule needs . * / <nl> on , <nl> / * * use dynamic configurations , always including all fragments known to blaze . * / <nl> notrim , <nl> / * * <nl> - * use untrimmed dynamic configurations unless an { @ link options } fragment needs static <nl> - * configurations . this is used to exempt features that don ' t yet work with dynamic configs . <nl> + * same as notrim . <nl> + * <nl> + * < p > this used to revert certain special cases to static configurations because dynamic <nl> + * configuration didn ' t support them . but now all builds use dynamic configurations . this <nl> + * value will be removed once we know no one is setting it . <nl> + * <nl> + * @ deprecated use { @ link # notrim } instead <nl> * / <nl> - <nl> - / / configs . b / 23280991 tracks the effort ( lipo is the main culprit ) . <nl> - notrim_partial <nl> + @ deprecated <nl> + notrim_partial , <nl> + / * * <nl> + * same as notrim . <nl> + * <nl> + * < p > this used to disable dynamic configurations ( while the feature was still being <nl> + * developed ) . but now all builds use dynamic configurations . this value will be removed <nl> + * once we know no one is setting it . <nl> + * <nl> + * @ deprecated use { @ link # notrim } instead <nl> + * / <nl> + @ deprecated <nl> + off <nl> } <nl>  <nl> / * * <nl>
public class printer { <nl> this . append ( o . tostring ( ) ) ; <nl>  <nl> } else { <nl> - <nl> - this . append ( o . tostring ( ) ) ; <nl> + / / other types of objects shouldn ' t be leaked to skylark , but if happens , their <nl> + / / . tostring method shouldn ' t be used because their return values are likely to contain <nl> + / / memory addresses or other nondeterministic information . <nl> + this . append ( " < unknown object " + o . getclass ( ) . getname ( ) + " > " ) ; <nl> } <nl>  <nl> return this ; <nl> mmm a / src / test / java / com / google / devtools / build / lib / skylark / skylarkstringrepresentationstest . java <nl> ppp b / src / test / java / com / google / devtools / build / lib / skylark / skylarkstringrepresentationstest . java <nl>
final class executionserver extends executionimplbase { <nl> / / an ioexception from the underlying subprocess . factory . <nl> cmdresult = null ; <nl> } <nl> - long timeoutmillis = timeunit . minutes . tomillis ( 15 ) ; <nl> - <nl> + long timeoutmillis = <nl> + action . hastimeout ( ) <nl> + ? durations . tomillis ( action . gettimeout ( ) ) <nl> + : timeunit . minutes . tomillis ( 15 ) ; <nl> boolean wastimeout = <nl> ( cmdresult ! = null & & cmdresult . getterminationstatus ( ) . timedout ( ) ) <nl> | | wastimeout ( timeoutmillis , system . currenttimemillis ( ) - starttime ) ;
public class printer { <nl> this . append ( o . tostring ( ) ) ; <nl>  <nl> } else { <nl> - <nl> - this . append ( o . tostring ( ) ) ; <nl> + / / other types of objects shouldn ' t be leaked to skylark , but if happens , their <nl> + / / . tostring method shouldn ' t be used because their return values are likely to contain <nl> + / / memory addresses or other nondeterministic information . <nl> + this . append ( " < unknown object " + o . getclass ( ) . getname ( ) + " > " ) ; <nl> } <nl>  <nl> return this ; <nl> mmm a / src / test / java / com / google / devtools / build / lib / skylark / skylarkstringrepresentationstest . java <nl> ppp b / src / test / java / com / google / devtools / build / lib / skylark / skylarkstringrepresentationstest . java <nl>
public class artifact <nl>  <nl> @ override <nl> public void repr ( skylarkprinter printer ) { <nl> - printer . append ( tostring ( ) ) ; <nl> + if ( issourceartifact ( ) ) { <nl> + printer . append ( " < source file " + rootrelativepath + " > " ) ; <nl> + } else { <nl> + printer . append ( " < generated file " + rootrelativepath + " > " ) ; <nl> + } <nl> + } <nl> + <nl> + @ override <nl> + public void reprlegacy ( skylarkprinter printer ) { <nl> + printer . append ( tostring ( ) ) ; <nl> } <nl> } <nl> mmm a / src / test / java / com / google / devtools / build / lib / skylark / skylarkstringrepresentationstest . java <nl> ppp b / src / test / java / com / google / devtools / build / lib / skylark / skylarkstringrepresentationstest . java <nl>
final class cachedlocalspawnrunner implements spawnrunner { <nl> spawn . getoutputfiles ( ) , <nl> digests . computedigest ( command ) , <nl> repository . getmerkledigest ( inputroot ) , <nl> - <nl> - spawns . gettimeoutseconds ( spawn , num ) ) ; <nl> + spawns . gettimeoutseconds ( spawn ) ) ; <nl>  <nl> / / look up action cache , and reuse the action output if it is found . <nl> actionkey = digests . computeactionkey ( action ) ; <nl>
final class remotespawnrunner implements spawnrunner { <nl> spawn . getoutputfiles ( ) , <nl> digests . computedigest ( command ) , <nl> repository . getmerkledigest ( inputroot ) , <nl> - <nl> - spawns . gettimeoutseconds ( spawn , num ) ) ; <nl> + spawns . gettimeoutseconds ( spawn ) ) ; <nl>  <nl> actionkey actionkey = digests . computeactionkey ( action ) ; <nl> actionresult result = <nl>
final class remotespawnstrategy implements spawnactioncontext { <nl> spawn . getoutputfiles ( ) , <nl> digests . computedigest ( command ) , <nl> repository . getmerkledigest ( inputroot ) , <nl> - <nl> - spawns . gettimeoutseconds ( spawn , num ) ) ; <nl> + spawns . gettimeoutseconds ( spawn ) ) ; <nl>  <nl> / / look up action cache , and reuse the action output if it is found . <nl> actionkey = digests . computeactionkey ( action ) ;
targets : <nl> / / src : bazel <nl> / / src / tools / remote_worker <nl> / / src / test / . . . <nl> - <nl> - # <nl> - java_language_level : num <nl> -
using std : : vector ; <nl> const char kserverpidfile [ ] = " server . pid . txt " ; <nl>  <nl> string makeabsolute ( const string & path ) { <nl> - / / check if path is already absolute . <nl> - <nl> - / / not absolute ! <nl> - if ( path . empty ( ) | | blaze_util : : isabsolute ( path ) ) { <nl> + if ( path . empty ( ) ) { <nl> + return blaze_util : : getcwd ( ) ; <nl> + } <nl> + <nl> + if ( blaze_util : : isabsolute ( path ) ) { <nl> return path ; <nl> } <nl>  <nl> mmm a / src / test / cpp / blaze_util_test . cc <nl> ppp b / src / test / cpp / blaze_util_test . cc <nl>
public class platformoptions extends fragmentoptions { <nl> @ option ( <nl> name = " experimental_host_platform " , <nl> converter = buildconfiguration . labelconverter . class , <nl> - <nl> - defaultvalue = " @ bazel_tools / / platforms : default_platform " , <nl> + defaultvalue = " @ bazel_tools / / platforms : host_platform " , <nl> optionusagerestrictions = optionsparser . optionusagerestrictions . hidden , <nl> help = " declare the platform the build is started from " <nl> ) <nl>
public class platformoptions extends fragmentoptions { <nl> @ option ( <nl> name = " experimental_platforms " , <nl> converter = buildconfiguration . labellistconverter . class , <nl> - <nl> - defaultvalue = " @ bazel_tools / / platforms : default_platform " , <nl> + defaultvalue = " @ bazel_tools / / platforms : target_platform " , <nl> optionusagerestrictions = optionsparser . optionusagerestrictions . hidden , <nl> help = " declare the platforms targeted by the current build " <nl> ) <nl> mmm a / tools / platforms / platforms . build <nl> ppp b / tools / platforms / platforms . build <nl>
static void createcommandline ( cmdline * result , const string & exe , <nl> cmdline < < ' \ " ' ; <nl> } <nl>  <nl> - <nl> - / / because each time a new buffer is allocated and the old one copied , so <nl> - / / this means n allocations ( of o ( n ) size each ) and n copies . <nl> - / / if possible , get rid of the whole createcommandline method and do the <nl> - / / logic on the caller side . <nl> std : : string : : const_iterator it = s . begin ( ) ; <nl> while ( it ! = s . end ( ) ) { <nl> char ch = * it + + ; <nl>
static void createcommandline ( cmdline * result , const string & exe , <nl> } / / namespace <nl>  <nl> string getjvmversion ( const string & java_exe ) { <nl> - <nl> handle pipe_read , pipe_write ; <nl>  <nl> security_attributes sa = { sizeof ( security_attributes ) , null , true } ; <nl>
static handle createjvmoutputfile ( const wstring & path , <nl> handle handle = : : createfilew ( <nl> / * lpfilename * / path . c_str ( ) , <nl> / * dwdesiredaccess * / generic_read | generic_write , <nl> - <nl> - / / jvm . out and maybe fixes <nl> - / / https : / / github . com / bazelbuild / bazel / issues / 2326 . unfortunately <nl> - / / however if a file that we opened with file_share_delete is deleted <nl> - / / while its still open , write operations will still succeed but have no <nl> - / / effect , the file won ' t be recreated . ( i haven ' t tried what happens <nl> - / / with read operations . ) <nl> - / / <nl> - / / file_share_read : so that the file can be read while the server is <nl> - / / running <nl> - / * dwsharemode * / file_share_read , <nl> + / / share for reading and also for deletion , so ` bazel clean <nl> + / / - - expunge / - - expunge_async ` can delete this file while the jvm holds <nl> + / / an open file descriptor to it ( via stdout ) . although subsequent <nl> + / / writes would not recreate the file after it ' s deleted , this is fine <nl> + / / because - - expunge / - - expunge_async shut down the bazel server . <nl> + / * dwsharemode * / file_share_read | file_share_delete , <nl> / * lpsecurityattributes * / sa , <nl> / * dwcreationdisposition * / create_always , <nl> / * dwflagsandattributes * / file_attribute_normal ,
class optionsparserimpl { <nl>  <nl> / / look for a " no " - prefixed option name : " no < optionname > " . <nl> if ( field = = null & & name . startswith ( " no " ) ) { <nl> - / / give a nice error if someone is using the deprecated - - no_ prefix . <nl> - <nl> - / / that feature to have stopped using it . <nl> name = name . substring ( 2 ) ; <nl> - if ( name . startswith ( " _ " ) & & optionsdata . getfieldfromname ( name . substring ( 1 ) ) ! = null ) { <nl> - name = name . substring ( 1 ) ; <nl> - warnings . add ( " option ' " + name + " ' is specified using the deprecated - - no_ prefix . " <nl> - + " use - - no without the underscore instead . " ) ; <nl> - } <nl> field = optionsdata . getfieldfromname ( name ) ; <nl> booleanvalue = false ; <nl> if ( field ! = null ) { <nl> mmm a / src / test / java / com / google / devtools / common / options / optionsparsertest . java <nl> ppp b / src / test / java / com / google / devtools / common / options / optionsparsertest . java <nl>
public class androidconfiguration extends buildconfiguration . fragment { <nl> / / other settings default to empty and are set or modified via dynamic configuration . <nl> public resourcefilter resourcefilter ; <nl>  <nl> - <nl> - @ option ( <nl> - name = " use_singlejar_for_proguard_libraryjars " , <nl> - defaultvalue = " false " , <nl> - optionusagerestrictions = optionusagerestrictions . undocumented , <nl> - help = " unused flag . " <nl> - ) <nl> - public boolean usesinglejarforproguardlibraryjars ; <nl> - <nl> @ option ( <nl> name = " experimental_android_compress_java_resources " , <nl> defaultvalue = " false " ,
public final class analysistestutil { <nl>  <nl> @ override <nl> public int hashcode ( ) { <nl> - <nl> - return system . identityhashcode ( this ) ; <nl> + return key . hashcode ( ) ; <nl> } <nl> }
java_import ( <nl> ] , <nl> ) <nl>  <nl> - # <nl> - alias ( <nl> - name = " error_prone - 2 . 0 . 20 - snapshot " , <nl> - actual = " : error_prone " , <nl> - ) <nl> - <nl> java_import ( <nl> name = " error_prone " , <nl> jars = [ <nl>
filegroup ( <nl> ] , <nl> ) <nl>  <nl> - # <nl> - alias ( <nl> - name = " bootstrap_guava_and_error_prone - jars - 2 . 0 . 20 - snapshot " , <nl> - actual = " bootstrap_guava_and_error_prone - jars " , <nl> - ) <nl> - <nl> # as of guava num . 0 , guava code uses error prone annotations . this isn ' t a <nl> # problem when compiling with java num , but is a problem when compiling bazel <nl> # with java num ( the error prone jars need to be on the javac classpath ) . so , <nl> mmm a / third_party / java / jdk / langtools / build <nl> ppp b / third_party / java / jdk / langtools / build <nl>
static void startserverandconnect ( const workspacelayout * workspace_layout , <nl> " server directory ' % s ' could not be created " , server_dir . c_str ( ) ) ; <nl> } <nl>  <nl> - <nl> - / / after num - 05 - 01 ( ~ half a year from writing this comment ) . by that time old <nl> - / / bazel clients that used to write pid symlinks will probably no longer be in <nl> - / / use . <nl> - / / until then , defensively delete old pid symlinks that older clients may have <nl> - / / left behind . <nl> - string pid_symlink = blaze_util : : joinpath ( server_dir , kserverpidsymlink ) ; <nl> - remove ( pid_symlink . c_str ( ) ) ; <nl> - <nl> / / if we couldn ' t connect to the server check if there is still a pid file <nl> / / and if so , kill the server that wrote it . this can happen e . g . if the <nl> / / server is in a gc pause and therefore cannot respond to ping requests and <nl> mmm a / src / main / cpp / blaze_util . cc <nl> ppp b / src / main / cpp / blaze_util . cc <nl>
namespace blaze { <nl>  <nl> extern const char kserverpidfile [ ] ; <nl>  <nl> - <nl> - / / ( ~ half a year from writing this comment ) . by that time old bazel clients that <nl> - / / used to write pid symlinks will probably no longer be in use . <nl> - extern const char kserverpidsymlink [ ] ; <nl> - <nl> / / returns the given path in absolute form . does not change paths that are <nl> / / already absolute . <nl> / /
if [ $ do_srcs_test ] ; then <nl> | grep - v ' ^ derived ' \ <nl> | grep - ev " $ { srcs_excludes } " \ <nl> | grep - v ' ^ tools / defaults / build ' \ <nl> - # <nl> - | grep - v ' third_party / protobuf / 3 . 0 . 0 / ' \ <nl> | sort - u > " $ { output_dir } / srcs - find " <nl>  <nl> log " diffing "
public class multiarchsplittransitionprovider implements splittransitionprovider <nl> case ios : <nl> cpus = buildoptions . get ( applecommandlineoptions . class ) . iosmulticpus ; <nl> if ( cpus . isempty ( ) ) { <nl> - <nl> - / / flag values : don ' t transition unless minimum_os or is_extension is specified ! <nl> - if ( minimumosversion . ispresent ( ) | | isextension ) { <nl> - cpus = immutablelist . of ( buildoptions . get ( applecommandlineoptions . class ) . ioscpu ) ; <nl> - } <nl> + cpus = immutablelist . of ( buildoptions . get ( applecommandlineoptions . class ) . ioscpu ) ; <nl> } <nl> configurationdistinguisher = isextension <nl> ? configurationdistinguisher . applebin_ios_ext
sh_test ( <nl> " / / conditions : default " : [ " / / src / test / shell / bazel / testdata : bazel_toolchain_test_project_pkg " ] , <nl> } ) , <nl> tags = [ <nl> - " noci " , # <nl> " requires - network " , <nl> ] , <nl> ) <nl> mmm a / src / test / shell / bazel / bazel_toolchain_test . sh <nl> ppp b / src / test / shell / bazel / bazel_toolchain_test . sh <nl>
sh_test ( <nl> " / / external : android_ndk_for_testing " , <nl> " / / external : android_sdk_for_testing " , <nl> ] , <nl> - # <nl> - tags = [ " manual " ] , <nl> ) <nl>  <nl> sh_test ( <nl>
sh_test ( <nl> " / / src / test / shell / bazel : test - deps " , <nl> ] , <nl> # this test builds an android_binary with java num code . <nl> - # <nl> - tags = [ <nl> - " jdk8 " , <nl> - " manual " , <nl> - ] , <nl> + tags = [ " jdk8 " ] , <nl> )
public class javabinary implements ruleconfiguredtargetfactory { <nl> semantics . translate ( rulecontext , javaconfig , attributes . getmessages ( ) ) ) ; <nl> } <nl>  <nl> - <nl> - boolean hasresources = <nl> - ! attributes . getresources ( ) . isempty ( ) | | ! attributes . getclasspathresources ( ) . isempty ( ) ; <nl> - if ( attributes . hassources ( ) | | hasresources ) { <nl> + if ( attributes . hassources ( ) | | attributes . hasresources ( ) ) { <nl> / / we only want to add a jar to the classpath of a dependent rule if it has content . <nl> javaartifactsbuilder . addruntimejar ( classjar ) ; <nl> }
eof <nl> fi <nl> } <nl>  <nl> - # <nl> - # run_suite " test tests " <nl> + run_suite " test tests "
linkpatterns = [ <nl> ( ' - l ( . + ) ' , [ ' / libpath : $ path0 ' ] ) , <nl> ( ' - static ' , [ ] ) , <nl> ( ' - shared ' , [ ' / dll ' ] ) , <nl> - # <nl> - # / wholearchive is supported in visual stuido num update num <nl> - ( ( ' - whole - archive ' , ' ( . + ) ' ) , [ ' / wholearchive : $ path0 ' ] ) , <nl> ( ' - no - whole - archive ' , [ ] ) , <nl> ( ' - rdynamic ' , [ ] ) , <nl> ( r ' - wl , ( . + ) \ . lib ' , [ ' $ 0 . lib ' ] ) , <nl>
public final class optionsparser { <nl> postprocessors . put ( processorname , arguments ) ; <nl> } <nl>  <nl> - <nl> - private void bootclasspathfromjavacopts ( ) { <nl> - iterator < string > it = javacopts . iterator ( ) ; <nl> - while ( it . hasnext ( ) ) { <nl> - string curr = it . next ( ) ; <nl> - if ( curr . equals ( " - bootclasspath " ) & & it . hasnext ( ) ) { <nl> - it . remove ( ) ; <nl> - bootclasspath = it . next ( ) ; <nl> - it . remove ( ) ; <nl> - } <nl> - } <nl> - } <nl> - <nl> public list < string > getjavacopts ( ) { <nl> return javacopts ; <nl> }
public final class javalibrarybuildrequest { <nl> . build ( ) ; <nl> } <nl>  <nl> - <nl> - / / listing it here <nl> - list < path > getextjars ( ) { <nl> - if ( getextdir ( ) = = null ) { <nl> - return immutablelist . of ( ) ; <nl> - } <nl> - immutablelist . builder < path > jars = immutablelist . builder ( ) ; <nl> - for ( string file : splitter . on ( file . pathseparatorchar ) . split ( getextdir ( ) ) ) { <nl> - try { <nl> - path path = paths . get ( file ) ; <nl> - if ( files . isdirectory ( path ) ) { <nl> - files . list ( path ) . foreach ( jars : : add ) ; <nl> - } else { <nl> - jars . add ( path ) ; <nl> - } <nl> - } catch ( ioexception e ) { <nl> - throw new ioerror ( e ) ; <nl> - } <nl> - } <nl> - return jars . build ( ) ; <nl> - } <nl> - <nl> static immutablelist < path > topaths ( list < string > files ) { <nl> if ( files = = null ) { <nl> return immutablelist . of ( ) ;
public abstract class teststrategy implements testactioncontext { <nl> * - - test_tmpdir . this does not create the directory . <nl> * / <nl> public static path gettmproot ( path workspace , path execroot , executionoptions executionoptions ) { <nl> - if ( executionoptions . testtmpdir ! = null ) { <nl> - return workspace . getrelative ( executionoptions . testtmpdir ) . getrelative ( test_tmp_root ) ; <nl> - } <nl> - switch ( os . getcurrent ( ) ) { <nl> - case windows : <nl> - <nl> - / / hardcoding this to c : / temp isn ' t great , but if we use a longer path , we trip the max_path <nl> - / / limit of the windows api when running bazel inside shell integration tests . <nl> - return workspace . getfilesystem ( ) . getpath ( " c : / temp " ) ; <nl> - default : <nl> - return execroot . getrelative ( test_tmp_root ) ; <nl> - } <nl> + return executionoptions . testtmpdir ! = null <nl> + ? workspace . getrelative ( executionoptions . testtmpdir ) . getrelative ( test_tmp_root ) <nl> + : execroot . getrelative ( test_tmp_root ) ; <nl> } <nl>  <nl> / * *
attribute_noreturn void signalhandler : : propagatesignalorexit ( int exit_code ) { <nl> / / in case the blaze server has written a partial line . <nl> void sigprintf ( const char * format , . . . ) { <nl> # ifdef compiler_msvc <nl> - <nl> + int stderr_fileno = _fileno ( stderr ) ; <nl> # else / / not compiler_msvc <nl> + int stderr_fileno = stderr_fileno ; <nl> + # endif <nl> char buf [ 1024 ] ; <nl> va_list ap ; <nl> va_start ( ap , format ) ; <nl> int r = vsnprintf ( buf , sizeof buf , format , ap ) ; <nl> va_end ( ap ) ; <nl> - if ( write ( stderr_fileno , buf , r ) < = num ) { <nl> + if ( write ( stderr_fileno , buf , r ) < = num ) { <nl> / / we don ' t care , just placate the compiler . <nl> } <nl> - # endif / / compiler_msvc <nl> } <nl>  <nl> static void printerror ( const string & op ) {
public class aargeneratoraction { <nl> category = " output " , <nl> help = " path to write the archive . " ) <nl> public path aaroutput ; <nl> - <nl> - <nl> - @ option ( name = " strictmerge " , <nl> - defaultvalue = " true " , <nl> - category = " option " , <nl> - help = " merge strategy for resources . " ) <nl> - public boolean strictmerge ; <nl> } <nl>  <nl> public static void main ( string [ ] args ) {
function test_java ( ) { <nl> assert_binary_run_from_subdir " bazel - bin / $ { java_pkg } / hello - world foo " " hello foo " <nl> } <nl>  <nl> - # <nl> - # function test_java_test ( ) { <nl> - # setup_javatest_support <nl> - # local java_native_tests = / / examples / java - native / src / test / java / com / example / myproject <nl> - # local java_native_main = / / examples / java - native / src / main / java / com / example / myproject <nl> - <nl> - # assert_build " - - / / examples / java - native / . . . - $ { java_native_main } : hello - error - prone " <nl> - # assert_build_fails " $ { java_native_main } : hello - error - prone " \ <nl> - # " did you mean ' result = b = = - 1 ; ' ? " <nl> - # assert_test_ok " $ { java_native_tests } : hello " <nl> - # assert_test_ok " $ { java_native_tests } : custom " <nl> - # assert_test_fails " $ { java_native_tests } : fail " <nl> - # assert_test_fails " $ { java_native_tests } : resource - fail " <nl> - # } <nl> + function test_java_test ( ) { <nl> + setup_javatest_support <nl> + local java_native_tests = / / examples / java - native / src / test / java / com / example / myproject <nl> + local java_native_main = / / examples / java - native / src / main / java / com / example / myproject <nl> + <nl> + assert_build " - - / / examples / java - native / . . . - $ { java_native_main } : hello - error - prone " <nl> + assert_build_fails " $ { java_native_main } : hello - error - prone " \ <nl> + " did you mean ' result = b = = - 1 ; ' ? " <nl> + assert_test_ok " $ { java_native_tests } : hello " <nl> + assert_test_ok " $ { java_native_tests } : custom " <nl> + assert_test_fails " $ { java_native_tests } : fail " <nl> + assert_test_fails " $ { java_native_tests } : resource - fail " <nl> + } <nl>  <nl> function test_native_python ( ) { <nl> # on windows , we build a python executable zip as the python binary
bool isemacsterminal ( ) { <nl> / / environment variables ) . <nl> bool isstandardterminal ( ) { <nl> # ifdef compiler_msvc <nl> - <nl> - / / stdout and stderr are not redirected . <nl> - return false ; <nl> + for ( dword i : { std_output_handle , std_error_handle } ) { <nl> + dword mode = num ; <nl> + handle handle = : : getstdhandle ( i ) ; <nl> + / / handle may be invalid when std { out , err } is redirected <nl> + if ( handle = = invalid_handle_value | | ! : : getconsolemode ( handle , & mode ) | | <nl> + ! ( mode & enable_processed_output ) | | <nl> + ! ( mode & enable_wrap_at_eol_output ) | | <nl> + ! ( mode & enable_virtual_terminal_processing ) ) { <nl> + return false ; <nl> + } <nl> + } <nl> + return true ; <nl> # else / / not compiler_msvc <nl> string term = getenv ( " term " ) ; <nl> if ( term . empty ( ) | | term = = " dumb " | | term = = " emacs " | |
bool isemacsterminal ( ) { <nl> / / environment variables ) . <nl> bool isstandardterminal ( ) { <nl> # ifdef compiler_msvc <nl> - <nl> - / / stdout and stderr are not redirected . <nl> - return false ; <nl> + for ( dword i : { std_output_handle , std_error_handle } ) { <nl> + dword mode = num ; <nl> + handle handle = : : getstdhandle ( i ) ; <nl> + / / handle may be invalid when std { out , err } is redirected <nl> + if ( handle = = invalid_handle_value | | ! : : getconsolemode ( handle , & mode ) | | <nl> + ! ( mode & enable_processed_output ) | | <nl> + ! ( mode & enable_wrap_at_eol_output ) | | <nl> + ! ( mode & enable_virtual_terminal_processing ) ) { <nl> + return false ; <nl> + } <nl> + } <nl> + return true ; <nl> # else / / not compiler_msvc <nl> string term = getenv ( " term " ) ; <nl> if ( term . empty ( ) | | term = = " dumb " | | term = = " emacs " | |
string getjvmversion ( const string & java_exe ) { <nl> / / so , we first pretend to be a posix daemon so that msys2 knows about our <nl> / / intentions and * then * we call createprocess ( ) . life ain ' t easy . <nl> static bool daemonizeonwindows ( ) { <nl> - # ifdef compiler_msvc <nl> - <nl> - return false ; <nl> - # else / / not compiler_msvc <nl> if ( fork ( ) > num ) { <nl> / / we are the original client process . <nl> return true ; <nl>
bool readdirectorysymlink ( const string & posix_name , string * result ) { <nl> } <nl> } <nl>  <nl> - <nl> - static bool isabsolutewindowspath ( const string & p ) { <nl> - if ( p . size ( ) < num ) { <nl> - return false ; <nl> - } <nl> - <nl> - if ( p . substr ( 1 , num ) = = " : / " ) { <nl> - return true ; <nl> + bool compareabsolutepaths ( const string & a , const string & b ) { <nl> + / / ` a ` and ` b ` may not be windows - style and may not be normalized , so convert <nl> + / / them both before comparing them . <nl> + wstring a_real , b_real ; <nl> + if ( ! blaze_util : : aswindowspathwithuncprefix ( a , & a_real ) ) { <nl> + pdie ( blaze_exit_code : : local_environmental_error , <nl> + " compareabsolutepaths ( a = % s , b = % s ) " , a . c_str ( ) , b . c_str ( ) ) ; <nl> } <nl> - <nl> - if ( p . substr ( 1 , num ) = = " : \ \ " ) { <nl> - return true ; <nl> + if ( ! blaze_util : : aswindowspathwithuncprefix ( b , & b_real ) ) { <nl> + pdie ( blaze_exit_code : : local_environmental_error , <nl> + " compareabsolutepaths ( a = % s , b = % s ) " , a . c_str ( ) , b . c_str ( ) ) ; <nl> } <nl> - <nl> - return false ; <nl> - } <nl> - <nl> - bool compareabsolutepaths ( const string & a , const string & b ) { <nl> - string a_real = isabsolutewindowspath ( a ) ? convertpathtoposix ( a ) : a ; <nl> - string b_real = isabsolutewindowspath ( b ) ? convertpathtoposix ( b ) : b ; <nl> return a_real = = b_real ; <nl> } <nl>  <nl>
class desugar { <nl> system . out . printf ( " lambda classes will be written under % s % n " , dumpdirectory ) ; <nl> } <nl>  <nl> - boolean allowdefaultmethods = options . minsdkversion > = num ; <nl> - <nl> - classloader parent ; <nl> - if ( options . bootclasspath . isempty ( ) & & ! options . allowemptybootclasspath ) { <nl> - <nl> - / / bootclasspath as a fallback is iffy at best and produces wrong results at worst . <nl> - parent = classloader . getsystemclassloader ( ) ; <nl> - } else { <nl> - parent = new throwingclassloader ( ) ; <nl> - } <nl> + checkstate ( ! options . bootclasspath . isempty ( ) | | options . allowemptybootclasspath , <nl> + " bootclasspath required to desugar % s " , options . inputjar ) ; <nl>  <nl> corelibraryrewriter rewriter = <nl> new corelibraryrewriter ( options . corelibrary ? " __desugar__ / " : " " ) ; <nl>
public final class appledebugoutputsprovider extends skylarkclassobject <nl> / * * expected types of debug outputs . * / <nl> enum outputtype { <nl>  <nl> - <nl> - <nl> / * * a bitcode symbol map , per architecture . * / <nl> - bitcode_symbols ; <nl> + bitcode_symbols , <nl> + <nl> + / * * a single - architecture dwarf binary with debug symbols . * / <nl> + dsym_binary ; <nl>  <nl> @ override <nl> public string tostring ( ) {
public abstract class teststrategy implements testactioncontext { <nl> boolean enablerunfiles ) <nl> throws execexception , interruptedexception { <nl> testtargetexecutionsettings execsettings = testaction . getexecutionsettings ( ) ; <nl> + path runfilesdir = execsettings . getrunfilesdir ( ) ; <nl>  <nl> / / if the symlink farm is already created then return the existing directory . if not we <nl> / / need to explicitly build it . this can happen when - - nobuild_runfile_links is supplied <nl> / / as a flag to the build . <nl> if ( execsettings . getrunfilessymlinkscreated ( ) ) { <nl> - return execsettings . getrunfilesdir ( ) ; <nl> + return runfilesdir ; <nl> } <nl>  <nl> - <nl> - / / generating the directory ourselves ? <nl> - path program = execsettings . getexecutable ( ) . getpath ( ) ; <nl> - path runfilesdir = program . getparentdirectory ( ) . getchild ( program . getbasename ( ) + " . runfiles " ) ; <nl> - <nl> / / synchronize runfiles tree generation on the runfiles manifest artifact . <nl> / / this is necessary , because we might end up with multiple test runner actions <nl> / / trying to generate same runfiles tree in case of - - runs_per_test > num or
public class skylarkjavaliteprotolibrarytest extends buildviewtestcase { <nl> prettyjarnames ( <nl> getprovider ( javacompilationargsprovider . class , litepb2 ) <nl> . getjavacompilationargs ( ) . getruntimejars ( ) ) ; <nl> - <nl> - / / a check for proto sources in skylarkified java_lite_proto_library . <nl> - assertthat ( directjars ) . containsexactly ( <nl> - " cross / libbravo - lite . jar " , " cross / libalpha - lite . jar " , " protobuf / libjavalite_runtime . jar " ) ; <nl> + assertthat ( directjars ) <nl> + . containsexactly ( " cross / libbravo - lite . jar " , " protobuf / libjavalite_runtime . jar " ) ; <nl> } <nl>  <nl> @ test <nl>
public class skylarkjavaliteprotolibrarytest extends buildviewtestcase { <nl> * behaves as if we depend directly on the aliased proto_library . <nl> * / <nl> @ test <nl> - @ ignore <nl> - <nl> - / / java_lite_proto_library . <nl> public void jplcorrectlydefinesdirectjars_strictdepsenabled_aliasproto ( ) throws exception { <nl> scratch . file ( <nl> " x / build " ,
public final class printer { <nl> return buffer ; <nl> } <nl>  <nl> - / * * <nl> - * returns the sorted entry set of the given map <nl> - * / <nl> - private static < k , v > set < map . entry < k , v > > getsortedentryset ( map < k , v > dict ) { <nl> - if ( ! ( dict instanceof sortedmap < ? , ? > ) ) { <nl> - <nl> - / / potentially different types is not supported anymore in skylark . <nl> - map < k , v > tmp = new treemap < > ( evalutils . safe_skylark_comparator ) ; <nl> - tmp . putall ( dict ) ; <nl> - dict = tmp ; <nl> - } <nl> - <nl> - return dict . entryset ( ) ; <nl> - } <nl> - <nl> public static appendable write ( appendable buffer , object o ) { <nl> return write ( buffer , o , skylark_quotation_mark ) ; <nl> } <nl> mmm a / src / test / java / com / google / devtools / build / lib / syntax / printertest . java <nl> ppp b / src / test / java / com / google / devtools / build / lib / syntax / printertest . java <nl>
string listseparator ( ) { return " ; " ; } <nl>  <nl> string convertpath ( const string & path ) { <nl> # ifdef compiler_msvc <nl> - <nl> - pdie ( 255 , " blaze : : convertpath is not implemented on windows " ) ; <nl> - return " " ; <nl> + / / this isn ' t needed when the binary isn ' t linked against msys - 2 . 0 . dll ( when <nl> + / / we build with msvc ) : msys converts all unix paths to windows paths for such <nl> + / / binaries . <nl> + return path ; <nl> # else / / not compiler_msvc <nl> / / if the path looks like % userprofile % / foo / bar , don ' t convert . <nl> if ( path . empty ( ) | | path [ 0 ] = = ' % ' ) {
public class skylarkrepositoryfunction extends repositoryfunction { <nl> throw new repositoryfunctionexception ( e , transience . transient ) ; <nl> } <nl>  <nl> - filevalue repositoryvalue = getrepositorydirectory ( outputdirectory , env ) ; <nl> - if ( repositoryvalue = = null ) { <nl> - <nl> - / / second execution . <nl> - return null ; <nl> - } <nl> - <nl> - if ( ! repositoryvalue . isdirectory ( ) ) { <nl> + if ( ! outputdirectory . isdirectory ( ) ) { <nl> throw new repositoryfunctionexception ( <nl> new ioexception ( rule + " must create a directory " ) , transience . transient ) ; <nl> }
void unsetenv ( const string & name ) { setenv ( name , " " ) ; } <nl>  <nl> void setupstdstreams ( ) { <nl> # ifdef compiler_msvc <nl> - <nl> - pdie ( 255 , " blaze : : setupstdstreams is not implemented on windows " ) ; <nl> + static const dword stdhandles [ ] = { std_input_handle , std_output_handle , <nl> + std_error_handle } ; <nl> + for ( int i = num ; i < num ; + + i ) { <nl> + handle handle = : : getstdhandle ( stdhandles [ i ] ) ; <nl> + if ( handle = = invalid_handle_value | | handle = = null ) { <nl> + / / ensure we have open fds to each std * stream . otherwise we can end up <nl> + / / with bizarre things like stdout going to the lock file , etc . <nl> + _open ( " nul " , ( i = = num ) ? _o_rdonly : _o_wronly ) ; <nl> + } <nl> + } <nl> # else / / not compiler_msvc <nl> / / set non - buffered output mode for stderr / stdout . the server already <nl> / / line - buffers messages where it makes sense , so there ' s no need to do set
bool changedirectory ( const string & path ) { <nl> return true ; <nl> } <nl>  <nl> - # ifdef compiler_msvc <nl> void foreachdirectoryentry ( const string & path , <nl> directoryentryconsumer * consume ) { <nl> - <nl> - pdie ( 255 , " blaze_util : : foreachdirectoryentry is not implemented on windows " ) ; <nl> + wstring wpath ; <nl> + if ( path . empty ( ) | | isdevnull ( path ) ) { <nl> + return ; <nl> + } <nl> + if ( ! aswindowspath ( path , & wpath ) ) { <nl> + pdie ( blaze_exit_code : : local_environmental_error , <nl> + " foreachdirectoryentry ( % s ) : aswindowspath failed " , path . c_str ( ) ) ; <nl> + } <nl> + <nl> + static const wstring kdot ( l " . " ) ; <nl> + static const wstring kdotdot ( l " . . " ) ; <nl> + <nl> + wpath = l " \ \ \ \ ? \ \ " + wpath + l " \ \ " ; <nl> + win32_find_dataw metadata ; <nl> + windows_util : : autohandle handle ( <nl> + findfirstfilew ( ( wpath + l " * " ) . c_str ( ) , & metadata ) ) ; <nl> + if ( handle . handle = = invalid_handle_value ) { <nl> + return ; / / directory does not exist or is empty <nl> + } <nl> + <nl> + do { <nl> + if ( kdot ! = metadata . cfilename & & kdotdot ! = metadata . cfilename ) { <nl> + wstring wname = wpath + metadata . cfilename ; <nl> + string name ( wstringtocstring ( / * omit prefix * / num + wname . c_str ( ) ) . get ( ) ) ; <nl> + bool is_dir = ( metadata . dwfileattributes & file_attribute_directory ) ! = num ; <nl> + consume - > consume ( name , is_dir ) ; <nl> + } <nl> + } while ( findnextfilew ( handle . handle , & metadata ) ) ; <nl> } <nl> - # else / / not compiler_msvc <nl> - # endif / / compiler_msvc <nl>  <nl> string normalizewindowspath ( string path ) { <nl> if ( path . empty ( ) ) { <nl> mmm a / src / test / cpp / util / file_test . cc <nl> ppp b / src / test / cpp / util / file_test . cc <nl>
java_test ( <nl> " vfs / inmemoryfs / * . java " , <nl> ] , <nl> exclude = [ <nl> - # <nl> - " concurrent / multisetsemaphoretest . java " , <nl> # java_rules_skylark doesn ' t support resource loading with <nl> # qualified paths . <nl> " util / resourcefileloadertest . java " ,
def swift_module_name ( label ) : <nl>  <nl> def _swift_lib_dir ( ctx ) : <nl> " " " returns the location of swift runtime directory to link against . " " " <nl> - # <nl> - developer_dir = " __bazel_xcode_developer_dir__ " <nl> platform_str = ctx . fragments . apple . single_arch_platform . name_in_plist . lower ( ) <nl>  <nl> toolchain_name = " xcodedefault " <nl>
def swiftc_args ( ctx ) : <nl> args . extend ( framework_args ) <nl> args . extend ( clang_args ) <nl> args . extend ( define_args ) <nl> - <nl> - # <nl> - if hasattr ( ctx . fragments , " swift " ) : <nl> - args . extend ( ctx . fragments . swift . copts ( ) ) <nl> - <nl> + args . extend ( ctx . fragments . swift . copts ( ) ) <nl> args . extend ( ctx . attr . copts ) <nl>  <nl> return args
public class appleconfiguration extends buildconfiguration . fragment { <nl> public map < string , string > appletargetplatformenv ( platform platform ) { <nl> immutablemap . builder < string , string > builder = immutablemap . builder ( ) ; <nl>  <nl> - <nl> - / / evaluated for the current configuration xcode version , this would break users who build <nl> - / / cc_ * rules without specifying both xcode_version and macosx_sdk_version build options . <nl> - if ( platform ! = platform . macos_x ) { <nl> - string sdkversion = getsdkversionforplatform ( platform ) . tostringwithminimumcomponents ( 2 ) ; <nl> - builder . put ( appleconfiguration . apple_sdk_version_env_name , sdkversion ) <nl> - . put ( appleconfiguration . apple_sdk_platform_env_name , platform . getnameinplist ( ) ) ; <nl> - } <nl> + string sdkversion = getsdkversionforplatform ( platform ) . tostringwithminimumcomponents ( 2 ) ; <nl> + builder <nl> + . put ( appleconfiguration . apple_sdk_version_env_name , sdkversion ) <nl> + . put ( appleconfiguration . apple_sdk_platform_env_name , platform . getnameinplist ( ) ) ; <nl> + <nl> return builder . build ( ) ; <nl> }
public final class androidruleclasses { <nl> " cc_library " , <nl> " java_import " , <nl> " java_library " , <nl> - " proto_library " <nl> } ; <nl>  <nl> public static final boolean hasproguardspecs ( attributemap rule ) {
bool writefile ( const void * data , size_t size , const string & filename ) { <nl> return result ; <nl> } <nl>  <nl> - <nl> - / / msys , remove file_posix . cc from the ` srcs ` of <nl> - / / / / src / main / cpp / util : file when building for msys , and remove all <nl> - / / # ifndef __cygwin__ directives . <nl> - # ifndef __cygwin__ <nl> bool unlinkpath ( const string & file_path ) { <nl> return unlink ( file_path . c_str ( ) ) = = num ; <nl> } <nl> mmm a / src / main / cpp / util / file_windows . cc <nl> ppp b / src / main / cpp / util / file_windows . cc <nl>
bool readfile ( const string & filename , string * content , int max_size ) { <nl> return result ; <nl> } <nl>  <nl> - # ifdef compiler_msvc <nl> bool writefile ( const void * data , size_t size , const string & filename ) { <nl> - <nl> - pdie ( 255 , " blaze_util : : writefile is not implemented on windows " ) ; <nl> - return false ; <nl> + if ( isdevnull ( filename ) ) { <nl> + return true ; / / mimic write ( 2 ) behavior with / dev / null <nl> + } <nl> + wstring wpath ; <nl> + if ( ! aswindowspathwithuncprefix ( filename , & wpath ) ) { <nl> + return false ; <nl> + } <nl> + <nl> + unlinkpathw ( wpath ) ; / / we don ' t care about the success of this . <nl> + handle handle = createfilew ( <nl> + / * lpfilename * / wpath . c_str ( ) , <nl> + / * dwdesiredaccess * / generic_write , <nl> + / * dwsharemode * / file_share_read , <nl> + / * lpsecurityattributes * / null , <nl> + / * dwcreationdisposition * / create_always , <nl> + / * dwflagsandattributes * / file_attribute_normal , <nl> + / * htemplatefile * / null ) ; <nl> + if ( handle = = invalid_handle_value ) { <nl> + return false ; <nl> + } <nl> + <nl> + bool result = writeto ( <nl> + [ handle ] ( const void * buf , size_t bufsize ) { <nl> + dword actually_written = num ; <nl> + : : writefile ( handle , buf , bufsize , & actually_written , null ) ; <nl> + return actually_written ; <nl> + } , <nl> + data , size ) ; <nl> + closehandle ( handle ) ; <nl> + return result ; <nl> } <nl> - # else / / not compiler_msvc <nl> - # endif / / compiler_msvc <nl>  <nl> static bool unlinkpathw ( const wstring & path ) { <nl> dword attrs = : : getfileattributesw ( path . c_str ( ) ) ; <nl> mmm a / src / test / cpp / util / file_test . cc <nl> ppp b / src / test / cpp / util / file_test . cc <nl>
bool writefile ( const void * data , size_t size , const string & filename ) { <nl> # else / / not compiler_msvc <nl> # endif / / compiler_msvc <nl>  <nl> - # ifdef compiler_msvc <nl> + static bool unlinkpathw ( const wstring & path ) { <nl> + dword attrs = : : getfileattributesw ( path . c_str ( ) ) ; <nl> + if ( attrs = = invalid_file_attributes ) { <nl> + / / path does not exist . <nl> + return false ; <nl> + } <nl> + if ( attrs & file_attribute_directory ) { <nl> + if ( ! ( attrs & file_attribute_reparse_point ) ) { <nl> + / / path is a directory ; unlink ( 2 ) also cannot remove directories . <nl> + return false ; <nl> + } <nl> + / / otherwise it ' s a junction , remove using removedirectoryw . <nl> + return : : removedirectoryw ( path . c_str ( ) ) = = true ; <nl> + } else { <nl> + / / otherwise it ' s a file , remove using deletefilew . <nl> + return : : deletefilew ( path . c_str ( ) ) = = true ; <nl> + } <nl> + } <nl> + <nl> bool unlinkpath ( const string & file_path ) { <nl> - <nl> - pdie ( 255 , " blaze_util : : unlinkpath is not implemented on windows " ) ; <nl> - return false ; <nl> + wstring wpath ; <nl> + if ( ! aswindowspathwithuncprefix ( file_path , & wpath ) ) { <nl> + return false ; <nl> + } <nl> + return unlinkpathw ( wpath ) ; <nl> } <nl> - # else / / not compiler_msvc <nl> - # endif / / compiler_msvc <nl>  <nl> handle opendirectory ( const wchar * path , bool read_write ) { <nl> return : : createfilew ( <nl> mmm a / src / test / cpp / util / file_windows_test . cc <nl> ppp b / src / test / cpp / util / file_windows_test . cc <nl>
public class multiarchsplittransitionprovider implements splittransitionprovider <nl> string platformcpu = string . format ( " % s_ % s " , platformtype , cpu ) ; <nl> applecrosstooltransition . setapplecrosstooltransitionconfiguration ( buildoptions , <nl> splitoptions , platformcpu ) ; <nl> - } else { <nl> - / / if the new configuration does not use the apple crosstool , then it needs ios_cpu to be <nl> - / / to decide architecture . <nl> - <nl> - / / " else " clause . deprecate ios_cpu . <nl> - splitoptions . get ( applecommandlineoptions . class ) . ioscpu = cpu ; <nl> } <nl> splitoptions . get ( applecommandlineoptions . class ) . configurationdistinguisher = <nl> configurationdistinguisher ;
bool canaccess ( const string & path , bool read , bool write , bool exec ) { <nl> # else / / not compiler_msvc <nl> # endif / / compiler_msvc <nl>  <nl> - # ifdef compiler_msvc <nl> + static bool isdirectoryw ( const wstring & path ) { <nl> + dword attrs = : : getfileattributesw ( path . c_str ( ) ) ; <nl> + return ( attrs ! = invalid_file_attributes ) & & <nl> + ( attrs & file_attribute_directory ) & & <nl> + junctionresolver ( ) . resolve ( path . c_str ( ) , nullptr ) ; <nl> + } <nl> + <nl> bool isdirectory ( const string & path ) { <nl> - <nl> - pdie ( 255 , " blaze_util : : isdirectory is not implemented on windows " ) ; <nl> - return false ; <nl> + if ( path . empty ( ) ) { <nl> + return false ; <nl> + } <nl> + wstring wpath ; <nl> + if ( ! aswindowspathwithuncprefix ( path , & wpath ) ) { <nl> + return false ; <nl> + } <nl> + return isdirectoryw ( wpath ) ; <nl> } <nl> - # else / / not compiler_msvc <nl> - # endif / / compiler_msvc <nl>  <nl> bool isrootdirectory ( const string & path ) { <nl> return isrootorabsolute ( path , true ) ; <nl> mmm a / src / test / cpp / util / file_windows_test . cc <nl> ppp b / src / test / cpp / util / file_windows_test . cc <nl>
bool writefile ( const void * data , size_t size , const string & filename ) { <nl> # else / / not compiler_msvc <nl> # endif / / compiler_msvc <nl>  <nl> - # ifdef compiler_msvc <nl> + static bool unlinkpathw ( const wstring & path ) { <nl> + dword attrs = : : getfileattributesw ( path . c_str ( ) ) ; <nl> + if ( attrs = = invalid_file_attributes ) { <nl> + / / path does not exist . <nl> + return false ; <nl> + } <nl> + if ( attrs & file_attribute_directory ) { <nl> + if ( ! ( attrs & file_attribute_reparse_point ) ) { <nl> + / / path is a directory ; unlink ( 2 ) also cannot remove directories . <nl> + return false ; <nl> + } <nl> + / / otherwise it ' s a junction , remove using removedirectoryw . <nl> + return : : removedirectoryw ( path . c_str ( ) ) = = true ; <nl> + } else { <nl> + / / otherwise it ' s a file , remove using deletefilew . <nl> + return : : deletefilew ( path . c_str ( ) ) = = true ; <nl> + } <nl> + } <nl> + <nl> bool unlinkpath ( const string & file_path ) { <nl> - <nl> - pdie ( 255 , " blaze_util : : unlinkpath is not implemented on windows " ) ; <nl> - return false ; <nl> + wstring wpath ; <nl> + if ( ! aswindowspathwithuncprefix ( file_path , & wpath ) ) { <nl> + return false ; <nl> + } <nl> + return unlinkpathw ( wpath ) ; <nl> } <nl> - # else / / not compiler_msvc <nl> - # endif / / compiler_msvc <nl>  <nl> handle opendirectory ( const wchar * path , bool read_write ) { <nl> return : : createfilew ( <nl> mmm a / src / test / cpp / util / file_windows_test . cc <nl> ppp b / src / test / cpp / util / file_windows_test . cc <nl>
string getcwd ( ) { <nl> wstringtocstring ( cwd . get ( ) + ( hasuncprefix ( cwd . get ( ) ) ? num : num ) ) . get ( ) ) ; <nl> } <nl>  <nl> - # ifdef compiler_msvc <nl> bool changedirectory ( const string & path ) { <nl> - <nl> - pdie ( 255 , " blaze_util : : changedirectory is not implemented on windows " ) ; <nl> - return false ; <nl> + wstring wpath ; <nl> + if ( ! aswindowspathwithuncprefix ( path , & wpath ) ) { <nl> + return false ; <nl> + } <nl> + if ( ! : : setcurrentdirectoryw ( wpath . c_str ( ) ) ) { <nl> + printerror ( <nl> + " changedirectory ( % s ) : setcurrentdirectoryw ( % s ) , failed , err = % d\n " , <nl> + path . c_str ( ) , wpath . c_str ( ) , getlasterror ( ) ) ; <nl> + return false ; <nl> + } <nl> + return true ; <nl> } <nl> - # else / / not compiler_msvc <nl> - # endif / / compiler_msvc <nl>  <nl> # ifdef compiler_msvc <nl> void foreachdirectoryentry ( const string & path ,
bool readfile ( const string & filename , string * content , int max_size ) { <nl> / / could not retrieve the bazel_sh envvar . <nl> return false ; <nl> } <nl> - <nl> - if ( wfilename . size ( ) > max_path ) { <nl> - / / createfilew requires that paths longer than max_path be prefixed with <nl> - / / " \ \ ? \ " , so add that here . <nl> - <nl> - wfilename = wstring ( l " \ \ \ \ ? \ \ " ) + wfilename ; <nl> - } <nl> - <nl> + adduncprefixmaybe ( & wfilename ) ; <nl> handle handle = createfilew ( <nl> / * lpfilename * / wfilename . c_str ( ) , <nl> / * dwdesiredaccess * / generic_read , <nl>
bool makedirectories ( const string & path , unsigned int mode ) { <nl> # else / / not compiler_msvc <nl> # endif / / compiler_msvc <nl>  <nl> - # ifdef compiler_msvc <nl> + static unique_ptr < wchar [ ] > getcwdw ( ) { <nl> + dword len = : : getcurrentdirectoryw ( 0 , nullptr ) ; <nl> + unique_ptr < wchar [ ] > cwd ( new wchar [ len ] ) ; <nl> + if ( ! : : getcurrentdirectoryw ( len , cwd . get ( ) ) ) { <nl> + die ( 255 , " getcurrentdirectoryw failed , err = % d\n " , getlasterror ( ) ) ; <nl> + } <nl> + return std : : move ( cwd ) ; <nl> + } <nl> + <nl> string getcwd ( ) { <nl> - <nl> - pdie ( 255 , " blaze_util : : getcwd is not implemented on windows " ) ; <nl> - return " " ; <nl> + unique_ptr < wchar [ ] > cwd ( getcwdw ( ) ) ; <nl> + return string ( <nl> + wstringtocstring ( cwd . get ( ) + ( hasuncprefix ( cwd . get ( ) ) ? num : num ) ) . get ( ) ) ; <nl> } <nl> - # else / / not compiler_msvc <nl> - # endif / / compiler_msvc <nl>  <nl> # ifdef compiler_msvc <nl> bool changedirectory ( const string & path ) {
public final class fetchcommand implements blazecommand { <nl> / / querying for all of the dependencies of the targets has the side - effect of populating the <nl> / / skyframe graph for external targets , which requires downloading them . the jdk is required to <nl> / / build everything but isn ' t counted as a dep in the build graph so we add it manually . <nl> - javaoptions javaoptions = options . getoptions ( javaoptions . class ) ; <nl> immutablelist . builder < string > labelstoload = new immutablelist . builder < string > ( ) <nl> . addall ( options . getresidue ( ) ) ; <nl>  <nl> - <nl> - / / framework currently doesn ' t set up the jdk normally on os x , so attempting to fetch <nl> - / / tools / jdk : jdk will cause errors . <nl> - labelstoload . add ( string . valueof ( javaoptions . javatoolchain ) ) ; <nl> - <nl> string query = joiner . on ( " union " ) . join ( labelstoload . build ( ) ) ; <nl> query = " deps ( " + query + " ) " ;
void executedaemon ( const string & exe , const std : : vector < string > & args_vector , <nl> sa . binherithandle = true ; <nl> sa . lpsecuritydescriptor = null ; <nl>  <nl> - handle output_file = createfilew ( <nl> - / * lpfilename * / wdaemon_output . c_str ( ) , <nl> + handle output_file = createfilea ( <nl> + / * lpfilename * / convertpath ( daemon_output ) . c_str ( ) , <nl> / * dwdesiredaccess * / generic_read | generic_write , <nl> / / so that the file can be read while the server is running <nl> - <nl> - / / jvm . out and fixes https : / / github . com / bazelbuild / bazel / issues / 2326 ? <nl> / * dwsharemode * / file_share_read , <nl> / * lpsecurityattributes * / & sa , <nl> / * dwcreationdisposition * / create_always , <nl>
def swiftc_args ( ctx ) : <nl> objc_module_maps + = objc . module_map <nl>  <nl> framework_dirs + = _parent_dirs ( objc . framework_dir ) <nl> - # <nl> - framework_dirs + = _parent_dirs ( getattr ( objc , " dynamic_framework_dir " , [ ] ) ) <nl> + framework_dirs + = _parent_dirs ( objc . dynamic_framework_dir ) <nl>  <nl> # objc_library # copts is not propagated to its dependencies and so it is not <nl> # collected here . in theory this may lead to un - importable targets ( since
typedef struct { <nl> wchar pathbuffer [ anysize_array ] ; <nl> } reparse_mountpoint_data_buffer , * preparse_mountpoint_data_buffer ; <nl>  <nl> - <nl> - / / file_windows , as part of fixing <nl> - / / https : / / github . com / bazelbuild / bazel / issues / 2181 . <nl> - handle opendirectory ( const string & path , bool readwrite ) { <nl> - handle result = : : createfilea ( <nl> - / * lpfilename * / path . c_str ( ) , <nl> - / * dwdesiredaccess * / readwrite ? ( generic_read | generic_write ) <nl> - : generic_read , <nl> - / * dwsharemode * / num , <nl> - / * lpsecurityattributes * / null , <nl> - / * dwcreationdisposition * / open_existing , <nl> - / * dwflagsandattributes * / file_flag_open_reparse_point | <nl> - file_flag_backup_semantics , <nl> - / * htemplatefile * / null ) ; <nl> - if ( result = = invalid_handle_value ) { <nl> - printerror ( " createfile ( " + path + " ) " ) ; <nl> - } <nl> - <nl> - return result ; <nl> - } <nl> + / / defined by file_windows . cc <nl> + handle opendirectory ( const wchar * path , bool read_write ) ; <nl>  <nl> bool symlinkdirectories ( const string & posix_target , const string & posix_name ) { <nl> string target = convertpath ( posix_target ) ; <nl> string name = convertpath ( posix_name ) ; <nl> + wstring wname ; <nl> + <nl> + if ( ! blaze_util : : aswindowspath ( name , & wname ) ) { <nl> + printerror ( " symlinkdirectories : aswindowspath ( " + name + " ) " ) ; <nl> + return false ; <nl> + } <nl> + wname = wstring ( l " \ \ \ \ ? \ \ " ) + wname ; <nl>  <nl> / / junctions are directories , so create one <nl> if ( ! : : createdirectorya ( name . c_str ( ) , null ) ) { <nl>
public final class event implements serializable { <nl> * an alternative representation for message . <nl> * <nl> * < p > exactly one of message or messagebytes will be non - null . if messagebytes is non - null , then <nl> - * it contains the bytes of the message ( encoding currently unspecified ) . we do this to avoid <nl> - * converting back and forth between strings and bytes . <nl> - * <nl> - * <nl> + * it contains the utf - 8 - encoded bytes of the message . we do this to avoid converting back and <nl> + * forth between strings and bytes . <nl> * / <nl> private final byte [ ] messagebytes ; <nl>  <nl>
public final class event implements serializable { <nl> } <nl>  <nl> public string getmessage ( ) { <nl> - <nl> - return message ! = null ? message : new string ( messagebytes , charset . defaultcharset ( ) ) ; <nl> + return message ! = null ? message : new string ( messagebytes , utf_8 ) ; <nl> } <nl>  <nl> public byte [ ] getmessagebytes ( ) { <nl> - return messagebytes ! = null ? messagebytes : message . getbytes ( iso_8859_1 ) ; <nl> + return messagebytes ! = null ? messagebytes : message . getbytes ( utf_8 ) ; <nl> } <nl>  <nl> public eventkind getkind ( ) { <nl>
public class androidcommon { <nl> artifact maindexlist ) { <nl> list < string > args = new arraylist < > ( ) ; <nl> args . add ( " - - dex " ) ; <nl> - / / add - - no - locals to coverage builds . older coverage tools don ' t correctly preserve local <nl> - / / variable information in stack frame maps that are required since java num , so to avoid runtime <nl> - / / errors we just don ' t add local variable info in the first place . this may no longer be <nl> - / / necessary , however , as long as we use a coverage tool that generates stack frame maps . <nl> - if ( rulecontext . getconfiguration ( ) . iscodecoverageenabled ( ) ) { <nl> - args . add ( " - - no - locals " ) ; <nl> - } <nl>  <nl> / / multithreaded dex does not work when using - - multi - dex . <nl> if ( ! multidex ) {
public class applecommandlineoptions extends fragmentoptions { <nl> ) <nl> public label xcodeversionconfig ; <nl>  <nl> - <nl> - @ option ( <nl> - name = " experimental_disable_native_swift_rules " , <nl> - defaultvalue = " false " , <nl> - category = " undocumented " , <nl> - help = " disables swift support in native objc_ rules . " <nl> - ) <nl> - public boolean disablenativeswiftrules ; <nl> - <nl> / * * <nl> * the default label of the build - wide { @ code xcode_config } configuration rule . this can be <nl> * changed from the default using the { @ code xcode_version_config } build flag . <nl> mmm a / src / main / java / com / google / devtools / build / lib / rules / apple / appleconfiguration . java <nl> ppp b / src / main / java / com / google / devtools / build / lib / rules / apple / appleconfiguration . java <nl>
current_dir = " $ ( cd " $ ( dirname " $ { bash_source [ 0 ] } " ) " & & pwd ) " <nl> source " $ { current_dir } / . . / integration_test_setup . sh " \ <nl> | | { echo " integration_test_setup . sh not found ! " > & 2 ; exit num ; } <nl>  <nl> - # <nl> - function disabled_test_java_test_coverage ( ) { <nl> + function test_java_test_coverage ( ) { <nl>  <nl> cat < < eof > build <nl> java_test (
public class windowsfilesystem extends javaiofilesystem { <nl> * < p > this method returns true for all three types as long as their target is a directory ( even if <nl> * they are dangling ) , though only directory junctions and directory symlinks are useful . <nl> * / <nl> - <nl> - / / in windowsfileoperations . <nl> @ visiblefortesting <nl> static boolean isjunction ( file file ) throws ioexception { <nl> - if ( files . exists ( file . topath ( ) , symlinkopts ( / * followsymlinks * / false ) ) ) { <nl> - dosfileattributes attributes = getattribs ( file , / * followsymlinks * / false ) ; <nl> - <nl> - if ( attributes . isregularfile ( ) ) { <nl> - return false ; <nl> - } <nl> - <nl> - if ( attributes . isdirectory ( ) ) { <nl> - return attributes . isother ( ) ; <nl> - } else { <nl> - return attributes . issymboliclink ( ) ; <nl> - } <nl> - } <nl> - return false ; <nl> + return windowsfileoperations . isjunction ( file . getpath ( ) ) ; <nl> } <nl>  <nl> private static dosfileattributes getattribs ( file file , boolean followsymlinks )
function test_3_local_jobs ( ) { <nl> - - runs_per_test = 10 / / dir : test <nl> } <nl>  <nl> - # <nl> - function disabled_test_tmpdir ( ) { <nl> + function test_tmpdir ( ) { <nl> mkdir - p foo <nl> cat > foo / bar_test . sh < < ' eof ' <nl> # ! / bin / bash <nl>
void releaselock ( blazelock * blaze_lock ) { <nl> # endif <nl>  <nl> string getusername ( ) { <nl> - # ifdef compiler_msvc <nl> - <nl> - pdie ( 255 , " blaze : : getusername is not implemented on windows " ) ; <nl> - return " " ; <nl> - # else / / not compiler_msvc <nl> - string user = getenv ( " user " ) ; <nl> - if ( ! user . empty ( ) ) { <nl> - return user ; <nl> - } <nl> - errno = num ; <nl> - passwd * pwent = getpwuid ( getuid ( ) ) ; / / nolint ( single - threaded ) <nl> - if ( pwent = = null | | pwent - > pw_name = = null ) { <nl> + wchar buffer [ unlen + num ] ; <nl> + dword len = unlen + num ; <nl> + if ( ! getusernamew ( buffer , & len ) ) { <nl> pdie ( blaze_exit_code : : local_environmental_error , <nl> - " $ user is not set , and unable to look up name of current user " ) ; <nl> + " error : getusernamew failed , err = % d\n " , getlasterror ( ) ) ; <nl> } <nl> - return pwent - > pw_name ; <nl> - # endif / / compiler_msvc <nl> + return string ( blaze_util : : wstringtocstring ( buffer ) . get ( ) ) ; <nl> } <nl>  <nl> bool isemacsterminal ( ) {
<nl> - # copyright num the bazel authors . all rights reserved . <nl> - # <nl> - # licensed under the apache license , version num . 0 ( the " license " ) ; <nl> - # you may not use this file except in compliance with the license . <nl> - # you may obtain a copy of the license at <nl> - # <nl> - # http : / / www . apache . org / licenses / license - 2 . 0 <nl> - # <nl> - # unless required by applicable law or agreed to in writing , software <nl> - # distributed under the license is distributed on an " as is " basis , <nl> - # without warranties or conditions of any kind , either express or implied . <nl> - # see the license for the specific language governing permissions and <nl> - # limitations under the license . <nl> - <nl> - " " " calls proto_lang_toolchain ( ) , but only if it ' s already been released . " " " <nl> - <nl> - # <nl> - def proto_lang_toolchain ( * * kwargs ) : <nl> - " " " calls proto_lang_toolchain ( ) , but only if it ' s already been released . " " " <nl> - if hasattr ( native , ' proto_lang_toolchain ' ) : <nl> - native . proto_lang_toolchain ( * * kwargs ) <nl> - else : <nl> - native . filegroup ( name = kwargs [ ' name ' ] ) <nl> -
def _http_archive_impl ( ctx ) : <nl> if ctx . attr . build_file and ctx . attr . build_file_content : <nl> ctx . fail ( " only one of build_file and build_file_content can be provided . " ) <nl>  <nl> - # <nl> - if len ( ctx . attr . urls ) > num : <nl> - ctx . fail ( " multiple urls are not yet supported . " ) <nl> - url = ctx . attr . urls [ 0 ] <nl> - ctx . download_and_extract ( url , " " , ctx . attr . sha256 , ctx . attr . type , <nl> + ctx . download_and_extract ( ctx . attr . urls , " " , ctx . attr . sha256 , ctx . attr . type , <nl> ctx . attr . strip_prefix ) <nl> ctx . file ( " workspace " , " workspace ( name = \ " { name } \ " ) \n " . format ( name = ctx . name ) ) <nl> if ctx . attr . build_file : <nl> + print ( " ctx . attr . build_file % s " % str ( ctx . attr . build_file ) ) <nl> ctx . symlink ( ctx . attr . build_file , " build " ) <nl> else : <nl> ctx . file ( " build " , ctx . attr . build_file_content ) <nl>
filegroup ( <nl>  <nl> def _http_file_impl ( ctx ) : <nl> " " " implementation of the http_file rule . " " " <nl> - # <nl> - if len ( ctx . attr . urls ) > num : <nl> - ctx . fail ( " multiple urls are not yet supported . " ) <nl> - url = ctx . attr . urls [ 0 ] <nl> - ctx . download ( url , " file / downloaded " , ctx . attr . sha256 , ctx . attr . executable ) <nl> + ctx . download ( ctx . attr . urls , " file / downloaded " , ctx . attr . sha256 , <nl> + ctx . attr . executable ) <nl> ctx . file ( " workspace " , " workspace ( name = \ " { name } \ " ) " . format ( name = ctx . name ) ) <nl> ctx . file ( " file / build " , _http_file_build ) <nl>  <nl>
public class skylarkcallbackfunction { <nl> } <nl>  <nl> public immutablelist < string > getparameternames ( ) { <nl> - immutablelist < string > names = callback . signature . getsignature ( ) . getnames ( ) ; <nl> - <nl> - / / the cfg parameter ( also update googleskylarkintegrationtest ) . <nl> - int lastindex = names . size ( ) - num ; <nl> - if ( lastindex > = num & & names . get ( lastindex ) . equals ( " cfg " ) ) { <nl> - names = names . sublist ( 0 , lastindex ) ; <nl> - } <nl> - <nl> - return names ; <nl> + return callback . signature . getsignature ( ) . getnames ( ) ; <nl> } <nl>  <nl> public object call ( classobject ctx , object . . . arguments )
public final class buildconfiguration { <nl> help = " stamp binaries with the date , username , hostname , workspace information , etc . " ) <nl> public boolean stampbinaries ; <nl>  <nl> - <nl> - / / this default value is always overwritten in the case of " blaze coverage " by <nl> - / / coveragecommand . setdefaultinstrumentationfilter ( ) <nl> + / / this default value is always overwritten in the case of " bazel coverage " by <nl> + / / coveragecommand . setdefaultinstrumentationfilter ( ) . <nl> @ option ( name = " instrumentation_filter " , <nl> converter = regexfilter . regexfilterconverter . class , <nl> defaultvalue = " - / javatests [ / : ] " , <nl> mmm a / src / main / java / com / google / devtools / build / lib / rules / test / coveragereportactionfactory . java <nl> ppp b / src / main / java / com / google / devtools / build / lib / rules / test / coveragereportactionfactory . java <nl>
static void computebasedirectories ( const string & self_path ) { <nl> } <nl>  <nl> if ( globals - > options - > output_base . empty ( ) ) { <nl> - # if ! defined ( __cygwin__ ) <nl> globals - > options - > output_base = blaze : : gethashedbasedir ( <nl> globals - > options - > output_user_root , globals - > workspace ) ; <nl> - # else <nl> - / / this md5s together user name and workspace directory . <nl> - / / <nl> - <nl> - / / blaze : : getoutputroot ( https : / / github . com / bazelbuild / bazel / issues / 2096 ) . <nl> - globals - > options - > output_base = blaze : : gethashedbasedir ( <nl> - blaze : : getoutputroot ( ) + " / " + globals - > options - > product_name , <nl> - blaze : : getusername ( ) + globals - > workspace ) ; <nl> - # endif <nl> } <nl>  <nl> struct stat buf ;
class windowsrunner ( object ) : <nl> error : if path is too long <nl> " " " <nl> abspath = os . path . abspath ( path ) <nl> - long_path = abspath . replace ( ' \ \ ' , ' \ \ \ \ ' ) <nl> # we must allow for the drive letter as well , which is three characters , and <nl> # the length of any compiler option ahead of the path , <nl>  <nl> - if len ( long_path ) + max_drive_length + max_option_length < max_path : <nl> - return long_path <nl> - else : <nl> - # <nl> - # this still doesn ' t solve all the problems , because the compiler <nl> - # doesn ' t seem to support long path . <nl> - return " \ \ \ \ ? \ \ " + long_path <nl> - return none <nl> + if len ( abspath ) + max_drive_length + max_option_length > max_path : <nl> + print ( ' warning : path " ' + abspath + ' " is > than num characters ( ' + <nl> + str ( len ( abspath ) ) + ' ) ; programs may crash with long arguments ' ) <nl> + return abspath <nl>  <nl> def setupenvironment ( self ) : <nl> " " " setup proper path for running .
fi <nl> mkdir - p output / ci <nl> cp output / bazel . exe output / ci / bazel - $ ( get_full_release_name ) . exe <nl> zip - j output / ci / bazel - $ ( get_full_release_name ) . zip output / bazel . exe <nl> - <nl> - # <nl> - echo " running tests " <nl> - . / output / bazel test - k - - test_output = all - - test_tag_filters - no_windows \ <nl> - / / src / test / shell / bazel : bazel_windows_example_test \ <nl> - / / src / test / java / . . . <nl> - retcode = $ ? <nl> - <nl> - # exit for failure except for test failures ( exit code num ) . <nl> - if ( ( $ retcode ! = num ) ) ; then <nl> - echo " $ retcode " > . unstable <nl> - fi
public class cppcompileaction extends abstractaction <nl> * / <nl> public static final string clif_match = " clif - match " ; <nl>  <nl> - <nl> - / / enabled . move those two things to local fields and drop this . accessing anything other than <nl> - / / these fields can impact correctness ! <nl> - private final buildconfiguration configuration ; <nl> + private final immutablemap < string , string > localshellenvironment ; <nl> + private final boolean iscodecoverageenabled ; <nl> protected final artifact outputfile ; <nl> private final label sourcelabel ; <nl> private final artifact optionalsourcefile ; <nl>
test_f ( blazeutiltest , makedirectories ) { <nl> assert_eq ( 0750 , filestat . st_mode & num ) ; <nl>  <nl> / / srcdir shouldn ' t be writable . <nl> - <nl> - / / string srcdir = blaze_util : : joinpath ( test_src_dir , " x / y / z " ) ; <nl> - / / ok = makedirectories ( srcdir , num ) ; <nl> - / / assert_eq ( - 1 , ok ) ; <nl> - / / assert_eq ( eacces , errno ) ; <nl> + string srcdir = blaze_util : : joinpath ( test_src_dir , " x / y / z " ) ; <nl> + ok = makedirectories ( srcdir , num ) ; <nl> + assert_eq ( - 1 , ok ) ; <nl> + assert_eq ( eacces , errno ) ; <nl>  <nl> / / can ' t make a dir out of a file . <nl> string non_dir = blaze_util : : joinpath ( dir , " w " ) ; <nl>
test_f ( blazeutiltest , makedirectories ) { <nl> assert_true ( symlink ( " / " , symlink ) ) ; <nl>  <nl> / / these perms will force a chmod ( ) <nl> - <nl> - / / ok = makedirectories ( symlink , num ) ; <nl> - / / assert_eq ( - 1 , ok ) ; <nl> - / / assert_eq ( eperm , errno ) ; <nl> + ok = makedirectories ( symlink , num ) ; <nl> + assert_eq ( - 1 , ok ) ; <nl> + assert_eq ( eperm , errno ) ; <nl>  <nl> / / edge cases . <nl> assert_eq ( - 1 , makedirectories ( " " , num ) ) ; <nl>
test_f ( blazeutiltest , hammermakedirectories ) { <nl> assert_strne ( tmp_dir , null ) ; <nl>  <nl> string path = blaze_util : : joinpath ( tmp_dir , " x / y / z " ) ; <nl> - <nl> - / / assert_le ( 0 , fork ( ) ) ; <nl> - / / assert_eq ( 0 , makedirectories ( path , num ) ) ; <nl> + assert_le ( 0 , fork ( ) ) ; <nl> + assert_eq ( 0 , makedirectories ( path , num ) ) ; <nl> } <nl>  <nl> } / / namespace blaze
def _swift_lib_dir ( ctx ) : <nl> return " { 0 } / toolchains / { 1 } . xctoolchain / usr / lib / swift / { 2 } " . format ( <nl> developer_dir , toolchain_name , platform_str ) <nl>  <nl> + <nl> def _swift_linkopts ( ctx ) : <nl> " " " returns additional linker arguments for the given rule context . " " " <nl> return set ( [ " - l " + _swift_lib_dir ( ctx ) ] ) <nl>  <nl> + <nl> def _swift_xcrun_args ( ctx ) : <nl> " " " returns additional arguments that should be passed to xcrun . " " " <nl> - # <nl> - args = [ ] <nl> - if hasattr ( ctx . fragments . apple , " xcode_toolchain " ) : <nl> - if ctx . fragments . apple . xcode_toolchain : <nl> - args + = [ " - - toolchain " , ctx . fragments . apple . xcode_toolchain ] <nl> + if ctx . fragments . apple . xcode_toolchain : <nl> + return [ " - - toolchain " , ctx . fragments . apple . xcode_toolchain ] <nl>  <nl> - return args <nl> + return [ ] <nl>  <nl>  <nl> def _is_valid_swift_module_name ( string ) :
done <nl> tempdir = $ ( mktemp - d " $ { tmpdir : - / tmp } / swiftstdlibtoolzippingoutput . xxxxxx " ) <nl> trap " rm - rf \ " $ tempdir \ " " exit <nl>  <nl> - if [ - z " $ { path_inside_zip : - } " ] & & [ - z " $ { outzip : - } " ] ; then <nl> - # this is an older bazel binary , massage the arguments to accommodate . <nl> - # <nl> - path_inside_zip = " $ { cmd_args [ 1 ] } " <nl> - outzip = $ ( " $ { realpath } " " $ { cmd_args [ 0 ] } " ) <nl> - tool_args = ( " $ { tool_args [ @ ] : 2 } " ) <nl> - fi <nl> - <nl> fullpath = " $ tempdir / $ path_inside_zip " <nl>  <nl> xcrun_args = ( )
public final class bazeltestsuiterule implements ruledefinition { <nl> < / p > <nl> < ! - - # end_blaze_rule . attribute - - > * / <nl>  <nl> - <nl> - <nl> / * < ! - - # blaze_rule ( test_suite ) . attribute ( tests ) - - > <nl> a list of test suites and test targets of any language . <nl> < p > <nl>
def _swift_library_impl ( ctx ) : <nl> cpu = apple_fragment . single_arch_cpu <nl> platform = apple_fragment . single_arch_platform <nl>  <nl> - # <nl> - if hasattr ( ctx . fragments . apple , " minimum_os_for_platform_type " ) : <nl> - target_os = ctx . fragments . apple . minimum_os_for_platform_type ( <nl> - apple_common . platform_type . ios ) <nl> - else : <nl> - target_os = ctx . fragments . objc . ios_minimum_os <nl> + target_os = ctx . fragments . apple . minimum_os_for_platform_type ( <nl> + apple_common . platform_type . ios ) <nl> target = _swift_target ( cpu , platform , target_os ) <nl> apple_toolchain = apple_common . apple_toolchain ( )
import javax . annotation . nullable ; <nl> * < p > this is an ephemeral object created only for the analysis of a single configured target . after <nl> * that configured target is analyzed , this is thrown away . <nl> * / <nl> - <nl> - / / type ( ) of this class to be " mergedconfiguredtarget " instead of " target " . the dependent code <nl> - / / should be refactored , possibly by adding a field to this class that it could read instead . <nl> - @ skylarkmodule ( <nl> - name = " mergedconfiguredtarget " , <nl> - doc = " " , <nl> - documented = false <nl> - ) <nl> public final class mergedconfiguredtarget extends abstractconfiguredtarget { <nl> private final configuredtarget base ; <nl> private final transitiveinfoprovidermap providers ;
for opt in " $ { @ } " ; do <nl> prefix = " $ ( echo " $ opt " | cut - d ' = ' - f num - ) " <nl> ; ; <nl> - - bazelrc = * ) <nl> - # <nl> - # this comment . <nl> + bazelrc = " $ ( echo " $ opt " | cut - d ' = ' - f num - ) " <nl> ; ; <nl> - - bin = * ) <nl> bin = " $ ( echo " $ opt " | cut - d ' = ' - f num - ) " <nl>
namespace blaze { <nl>  <nl> using std : : vector ; <nl>  <nl> - startupoptions : : startupoptions ( ) : <nl> - startupoptions ( " bazel " ) { <nl> - init ( ) ; <nl> - } <nl> - <nl> - startupoptions : : startupoptions ( const string & product_name ) : <nl> - product_name ( product_name ) { <nl> - init ( ) ; <nl> - } <nl> + startupoptions : : startupoptions ( ) : startupoptions ( " bazel " ) { } <nl>  <nl> - startupoptions : : ~ startupoptions ( ) { <nl> - } <nl> - <nl> - <nl> - void startupoptions : : init ( ) { <nl> + startupoptions : : startupoptions ( const string & product_name ) <nl> + : product_name ( product_name ) , <nl> + deep_execroot ( true ) , <nl> + block_for_lock ( true ) , <nl> + host_jvm_debug ( false ) , <nl> + batch ( false ) , <nl> + batch_cpu_scheduling ( false ) , <nl> + io_nice_level ( - 1 ) , <nl> + oom_more_eagerly ( false ) , <nl> + oom_more_eagerly_threshold ( 100 ) , <nl> + write_command_log ( true ) , <nl> + watchfs ( false ) , <nl> + allow_configurable_attributes ( false ) , <nl> + fatal_event_bus_exceptions ( false ) , <nl> + command_port ( 0 ) , <nl> + invocation_policy ( null ) { <nl> bool testing = getenv ( " test_tmpdir " ) ! = null ; <nl> if ( testing ) { <nl> output_root = makeabsolute ( getenv ( " test_tmpdir " ) ) ; <nl> } else { <nl> - output_root = workspacelayout : : getoutputroot ( ) ; <nl> + output_root = workspacelayout : : getoutputroot ( ) ; <nl> } <nl>  <nl> string product_name_lower = product_name ; <nl> blaze_util : : tolower ( & product_name_lower ) ; <nl> output_user_root = blaze_util : : joinpath ( <nl> output_root , " _ " + product_name_lower + " _ " + getusername ( ) ) ; <nl> - deep_execroot = true ; <nl> - block_for_lock = true ; <nl> - host_jvm_debug = false ; <nl> - host_javabase = " " ; <nl> - batch = false ; <nl> - batch_cpu_scheduling = false ; <nl> - allow_configurable_attributes = false ; <nl> - fatal_event_bus_exceptions = false ; <nl> - io_nice_level = - 1 ; <nl> / / num hours ( but only num seconds if used within a test ) <nl> max_idle_secs = testing ? num : ( 3 * num ) ; <nl> - oom_more_eagerly_threshold = num ; <nl> - command_port = num ; <nl> - oom_more_eagerly = false ; <nl> - write_command_log = true ; <nl> - watchfs = false ; <nl> - invocation_policy = null ; <nl> } <nl>  <nl> + startupoptions : : ~ startupoptions ( ) { } <nl> + <nl> void startupoptions : : addextraoptions ( vector < string > * result ) const { } <nl>  <nl> blaze_exit_code : : exitcode startupoptions : : processarg ( <nl> mmm a / src / main / cpp / startup_options . h <nl> ppp b / src / main / cpp / startup_options . h <nl>
def xcrun_action ( ctx , * * kw ) : <nl> this method takes the same keyword arguments as ctx . action , however you don ' t <nl> need to specify the executable . <nl> " " " <nl> - <nl> - if ( hasattr ( ctx . fragments . apple , " single_arch_cpu " ) <nl> - and hasattr ( ctx . fragments . apple , " single_arch_platform " ) ) : <nl> - platform = ctx . fragments . apple . single_arch_platform <nl> - else : <nl> - # <nl> - # by default . <nl> - platform = ctx . fragments . apple . ios_cpu_platform ( ) <nl> + platform = ctx . fragments . apple . single_arch_platform <nl>  <nl> action_env = ctx . fragments . apple . target_apple_env ( platform ) \ <nl> + ctx . fragments . apple . apple_host_system_env ( ) <nl> mmm a / tools / build_defs / apple / swift . bzl <nl> ppp b / tools / build_defs / apple / swift . bzl <nl>
def _intersperse ( separator , iterable ) : <nl>  <nl> def _swift_target ( cpu , platform , sdk_version ) : <nl> " " " returns a target triplet for swift compiler . " " " <nl> - # <nl> - platform_string = none <nl> - if str ( platform ) . startswith ( " ios_ " ) : <nl> - platform_string = " ios " <nl> - elif str ( platform ) . startswith ( " watchos_ " ) : <nl> - platform_string = " watchos " <nl> - else : <nl> - fail ( " platform % s is not supported " ) <nl> + platform_string = str ( platform . platform_type ) <nl> + if platform_string not in [ " ios " , " watchos " ] : <nl> + fail ( " platform ' % s ' is not supported " % platform_string ) <nl>  <nl> return " % s - apple - % s % s " % ( cpu , platform_string , sdk_version ) <nl>  <nl>
static int getserverpid ( const string & server_dir ) { <nl>  <nl> / / the server writes a file , but we need to handle old servers that still <nl> / / write a symlink . <nl> - <nl> - / / server lingering around . probably safe after num . 06 . 01 . <nl> int len ; <nl> string pid_file = blaze_util : : joinpath ( server_dir , kserverpidfile ) ; <nl> string pid_symlink = blaze_util : : joinpath ( server_dir , kserverpidsymlink ) ;
for opt in " $ { @ } " ; do <nl> prefix = " $ ( echo " $ opt " | cut - d ' = ' - f num - ) " <nl> ; ; <nl> - - bazelrc = * ) <nl> - # <nl> - # this comment . <nl> + bazelrc = " $ ( echo " $ opt " | cut - d ' = ' - f num - ) " <nl> ; ; <nl> - - bin = * ) <nl> bin = " $ ( echo " $ opt " | cut - d ' = ' - f num - ) " <nl>
public abstract class infoitem { <nl>  <nl> / * * <nl> * returns the value of the info key . the return value is directly printed to stdout . <nl> - * <nl> - * @ param env <nl> * / <nl> public abstract byte [ ] get ( <nl> supplier < buildconfiguration > configurationsupplier , commandenvironment env )
void startupoptions : : init ( ) { <nl> output_root = getoutputroot ( ) ; <nl> } <nl>  <nl> - <nl> - / / product_name at construction time instead of using preprocessor <nl> - / / definitions . <nl> - product_name = product_name ; <nl> - string product_name_lower = product_name ; <nl> + string product_name_lower = product_name ; <nl> blaze_util : : tolower ( & product_name_lower ) ; <nl> output_user_root = blaze_util : : joinpath ( <nl> output_root , " _ " + product_name_lower + " _ " + getusername ( ) ) ; <nl> mmm a / src / main / cpp / startup_options . h <nl> ppp b / src / main / cpp / startup_options . h <nl>
static attribute_noreturn void sendserverrequest ( blazeserver * server ) { <nl> startserverandconnect ( server ) ; <nl> } <nl>  <nl> - / / check for deleted server cwd : <nl> + / / check for the case when the workspace directory deleted and then gets <nl> + / / recreated while the server is running <nl> + <nl> string server_cwd = getprocesscwd ( globals - > server_pid ) ; <nl> - <nl> - / / moves the server directory , the client cannot connect to the server <nl> - / / anymore . iow , the client finds the server based on the output base , <nl> - / / so if a server is found , it should be by definition at the correct output <nl> - / / base . <nl> - / / <nl> / / if server_cwd is empty , getprocesscwd failed . this notably occurs when <nl> / / running under docker because then readlink ( / proc / [ pid ] / cwd ) returns <nl> / / eperm . <nl>
public class objccommandlineoptions extends fragmentoptions { <nl> ) <nl> public label extraentitlements ; <nl>  <nl> - <nl> - @ option ( <nl> - name = " experimental_auto_top_level_union_objc_protos " , <nl> - defaultvalue = " true " , <nl> - category = " flags " , <nl> - help = " this flag is a noop and scheduled for removal . " <nl> - ) <nl> - public boolean experimentalautotoplevelunionobjcprotos ; <nl> - <nl> @ option ( <nl> name = " device_debug_entitlements " , <nl> defaultvalue = " true " ,
test_directory_expansion_in_subdir ( ) { <nl> ' build streamer2 / stuff / ' <nl> } <nl>  <nl> - # <nl> - disabled_test_target_expansion ( ) { <nl> + test_target_expansion ( ) { <nl> # ' test expansion of target names within packages ' <nl>  <nl> make_packages <nl> mmm a / src / test / shell / bazel / bazel_rules_test . sh <nl> ppp b / src / test / shell / bazel / bazel_rules_test . sh <nl>
eof <nl> expect_log " hello , world ! " <nl> } <nl>  <nl> - # <nl> - function disabled_test_genrule_default_env ( ) { <nl> + <nl> + function test_genrule_default_env ( ) { <nl> mkdir - p pkg <nl> cat < < ' eof ' > pkg / build <nl> genrule (
class rulelinkexpander { <nl> } <nl>  <nl> / / the name is not the name of a rule but is the name of a static page , such as <nl> - / / common - definitions . generate a link to that page , and append the page heading if <nl> - / / specified . for example , $ { link common - definitions . label - expansion } expands to <nl> - / / common - definitions . html # label - expansion . <nl> - <nl> if ( static_pages . contains ( name ) ) { <nl> string link = name + " . html " ; <nl> - / / the fourth capture group matches the attribute name , or page heading , e . g . <nl> - / / " label - expansion " in " common - definitions . label - expansion " . <nl> + / / for referencing headings on a static page , use the following syntax : <nl> + / / $ { link static_page_name # heading_name } , example : $ { link make - variables # gendir } <nl> string pageheading = matcher . group ( 4 ) ; <nl> if ( pageheading ! = null ) { <nl> - link = link + " # " + pageheading ; <nl> + throw new illegalargumentexception ( <nl> + " invalid link syntax for be page : " + matcher . group ( ) <nl> + + " \nuse $ { link static - page # heading } syntax instead . " ) ; <nl> } <nl> matcher . appendreplacement ( sb , matcher . quotereplacement ( link ) ) ; <nl> continue ; <nl> mmm a / src / test / java / com / google / devtools / build / docgen / rulelinkexpandertest . java <nl> ppp b / src / test / java / com / google / devtools / build / docgen / rulelinkexpandertest . java <nl>
public class manifestmergeraction { <nl>  <nl> @ option ( name = " mergeemanifests " , <nl> defaultvalue = " " , <nl> - <nl> - / / has been released . <nl> - converter = mergeemanifestsconverter . class , <nl> + converter = existingpathstringdictionaryconverter . class , <nl> category = " input " , <nl> help = " a dictionary of manifests , and originating target , to be merged into manifest . " ) <nl> public map < path , string > mergeemanifests ;
public final class androidaaptactionhelper { <nl> * / <nl> private iterable < artifact > getinputs ( ) { <nl> if ( inputs . isempty ( ) ) { <nl> - filestorunprovider toolrunner = <nl> - rulecontext . getexecutableprerequisite ( " $ android_tool_runner " , mode . host ) ; <nl> - <nl> - / / not expanded . fix by providing code to expand and use getfilestorun here . <nl> - runfilessupport aaptrunnerrunfiles = toolrunner . getrunfilessupport ( ) ; <nl> - preconditions . checkstate ( aaptrunnerrunfiles ! = null ) ; <nl> - / / note the below may be an overapproximation of the actual runfiles , due to " conditional <nl> - / / artifacts " ( see runfiles . pruningmanifest ) . <nl> - iterables . addall ( inputs , aaptrunnerrunfiles . getrunfilesartifactswithoutmiddlemen ( ) ) ; <nl> inputs . add ( androidsdkprovider . fromrulecontext ( rulecontext ) . getandroidjar ( ) ) ; <nl> inputs . add ( manifest ) ; <nl> iterables . addall ( inputs , iterables . concat ( iterables . transform ( resourcecontainers , <nl>
public class androidconfiguration extends buildconfiguration . fragment { <nl> help = " enables resource shrinking for android_binary apks that use proguard . " ) <nl> public boolean useandroidresourceshrinking ; <nl>  <nl> - <nl> - @ option ( name = " experimental_use_proguard_previous_obfuscation_map " , <nl> - defaultvalue = " false " , <nl> - category = " undocumented " , <nl> - help = " does nothing ( obsolete ) . " ) <nl> - public boolean useproguardpreviousobfuscationmap ; <nl> - <nl> @ option ( name = " android_manifest_merger " , <nl> defaultvalue = " legacy " , <nl> category = " semantics " ,
public class androidconfiguration extends buildconfiguration . fragment { <nl> help = " enables resource shrinking for android_binary apks that use proguard . " ) <nl> public boolean useandroidresourceshrinking ; <nl>  <nl> - <nl> - @ option ( name = " experimental_use_proguard_previous_obfuscation_map " , <nl> - defaultvalue = " false " , <nl> - category = " undocumented " , <nl> - help = " does nothing ( obsolete ) . " ) <nl> - public boolean useproguardpreviousobfuscationmap ; <nl> - <nl> @ option ( name = " android_manifest_merger " , <nl> defaultvalue = " legacy " , <nl> category = " semantics " ,
<nl> - # ! / bin / bash <nl> - # copyright num the bazel authors . all rights reserved . <nl> - # <nl> - # licensed under the apache license , version num . 0 ( the " license " ) ; <nl> - # you may not use this file except in compliance with the license . <nl> - # you may obtain a copy of the license at <nl> - # <nl> - # http : / / www . apache . org / licenses / license - 2 . 0 <nl> - # <nl> - # unless required by applicable law or agreed to in writing , software <nl> - # distributed under the license is distributed on an " as is " basis , <nl> - # without warranties or conditions of any kind , either express or implied . <nl> - # see the license for the specific language governing permissions and <nl> - # limitations under the license . <nl> - <nl> - # <nl> - exit num
public final class converters { <nl> @ override <nl> public fullrevision convert ( string input ) throws optionsparsingexception { <nl> try { <nl> - <nl> - / / how to properly parse build tool revisions with " - preview " , and <nl> - / / upgrading to the lastest version will take time . since we don ' t <nl> - / / currently need to distinguish between preview and non - preview build <nl> - / / tools , for now just remove the suffix . <nl> - input = input . replace ( " - preview " , " " ) ; <nl> return fullrevision . parserevision ( input ) ; <nl> } catch ( numberformatexception e ) { <nl> throw new optionsparsingexception ( e . getmessage ( ) ) ;
def _swift_library_impl ( ctx ) : <nl>  <nl> srcs_args = [ f . path for f in ctx . files . srcs ] <nl>  <nl> - # <nl> - # a shared dir and include that ? <nl> + # include each swift module ' s parent directory for imports to work . <nl> include_dirs = set ( [ x . dirname for x in dep_modules ] ) <nl>  <nl> include_args = [ " - i % s " % d for d in include_dirs + objc_includes ]
def _swift_library_impl ( ctx ) : <nl> # their module cannot be compiled by clang ) , but did not occur in practice . <nl> objc_defines + = objc . define <nl>  <nl> - # <nl> - # file , does not matter to the linker , but should be replaced with proper ar <nl> - # call . <nl> output_lib = ctx . new_file ( module_name + " . a " ) <nl> output_module = ctx . new_file ( module_name + " . swiftmodule " ) <nl> output_header = ctx . new_file ( ctx . label . name + " - swift . h " ) <nl> + output_file_map = ctx . new_file ( ctx . label . name + " . output_file_map . json " ) <nl> + <nl> + output_map = struct ( ) <nl> + output_objs = [ ] <nl> + for source in ctx . files . srcs : <nl> + obj = ctx . new_file ( source . basename + " . o " ) <nl> + output_objs . append ( obj ) <nl> + <nl> + output_map + = struct ( * * { source . path : struct ( object = obj . path ) } ) <nl> + <nl> + # write down the output file map for this compilation , to be used with <nl> + # - output - file - map flag . <nl> + # it ' s a json file that maps each source input ( . swift ) to its outputs <nl> + # ( . o , . bc , . d , . . . ) <nl> + # example : <nl> + # { ' foo . swift ' : <nl> + # { ' object ' : ' foo . o ' , ' bitcode ' : ' foo . bc ' , ' dependencies ' : ' foo . d ' } } <nl> + # there ' s currently no documentation on this option , however all of the keys <nl> + # are listed here https : / / github . com / apple / swift / blob / swift - 2 . 2 . 1 - release / include / swift / driver / types . def <nl> + ctx . file_action ( output = output_file_map , content = output_map . to_json ( ) ) <nl>  <nl> srcs_args = [ f . path for f in ctx . files . srcs ] <nl>  <nl>
public class skylarkcallbackfunction { <nl> } <nl> } <nl>  <nl> - / / for legacy reasons : these names are used in the depot to signal that the first parameter of <nl> - / / the callback function should be an attribute map . <nl> - <nl> - private static final immutableset < string > legacy_attr_map_names = <nl> - immutableset . < string > of ( " attr_map " , " attrs " , " attr " ) ; <nl> - <nl> / * * <nl> * creates a list of actual arguments that contains the given arguments and all attribute values <nl> * required from the specified context . <nl>
public class skylarkcallbackfunction { <nl> string name = names . get ( pos ) ; <nl> object value = ctx . getvalue ( name ) ; <nl> if ( value = = null ) { <nl> - if ( requiredparameters = = num & & legacy_attr_map_names . contains ( name ) ) { <nl> - / / legacy mode : some bzl files still expect the attribute map as the first parameter . <nl> - <nl> - / / is clean . <nl> - value = ctx ; <nl> - } else { <nl> throw new illegalargumentexception ( ctx . errormessage ( name ) ) ; <nl> - } <nl> } <nl> builder . add ( value ) ; <nl> }
public class skylarkruleclassfunctions { <nl> + " it is a dictionary mapping from string to a template name . " <nl> + " for example : < code > { \ " ext \ " : \ " % { name } . ext \ " } < / code > . < br > " <nl> + " the dictionary key becomes an attribute in < code > ctx . outputs < / code > . " <nl> - <nl> - + " it may also be a function ( which receives < code > ctx . attr < / code > as argument ) " <nl> - + " returning such a dictionary . " ) , <nl> + + " similar to computed dependency rule attributes , you can also specify the name of a " <nl> + + " function that returns the dictionary . this function can access all rule " <nl> + + " attributes that are listed as parameters in its function signature . " <nl> + + " for example , < code > outputs = _my_func < code > with < code > def _my_func ( srcs , deps ) : " <nl> + + " < / code > has access to the attributes ' srcs ' and ' deps ' ( if defined ) . " ) , <nl> @ param ( name = " executable " , type = boolean . class , defaultvalue = " false " , <nl> doc = " whether this rule is marked as executable or not . if true , " <nl> + " there must be an action that generates < code > ctx . outputs . executable < / code > . " ) ,
public final class compilationsupport { <nl> * / <nl> private void registergeneratemodulemapaction ( <nl> cppmodulemap modulemap , iterable < artifact > publicheaders , iterable < artifact > privateheaders ) { <nl> - / / the current clang ( clang - 600 . 0 . 57 ) on darwin doesn ' t support ' textual ' , so we can ' t have <nl> - / / ' . inc ' files in the module map ( since they ' re implictly textual ) . <nl> - <nl> - publicheaders = iterables . filter ( publicheaders , non_inc_files ) ; <nl> - privateheaders = iterables . filter ( privateheaders , non_inc_files ) ; <nl> + publicheaders = iterables . filter ( publicheaders , module_map_header ) ; <nl> + privateheaders = iterables . filter ( privateheaders , module_map_header ) ; <nl> rulecontext . registeraction ( <nl> new cppmodulemapaction ( <nl> rulecontext . getactionowner ( ) ,
abstract class skylarkdoc { <nl> } else if ( type . equals ( void . type ) | | type . equals ( nonetype . class ) ) { <nl> return " < a class = \ " anchor \ " href = \ " " + top_level_id + " . html # none \ " > none < / a > " ; <nl> } else if ( type . isannotationpresent ( skylarkmodule . class ) ) { <nl> - <nl> - / / the correct fix is to generate those types ( e . g . skylarkfiletype ) too . <nl> - string module = type . getannotation ( skylarkmodule . class ) . name ( ) ; <nl> - return " < a class = \ " anchor \ " href = \ " " + module + " . html \ " > " + module + " < / a > " ; <nl> - } else { <nl> - return evalutils . getdatatypenamefromclass ( type ) ; <nl> + skylarkmodule module = type . getannotation ( skylarkmodule . class ) ; <nl> + if ( module . documented ( ) ) { <nl> + return string . format ( " < a class = \ " anchor \ " href = \ " % 1 $ s . html \ " > % 1 $ s < / a > " , <nl> + module . name ( ) ) ; <nl> + } <nl> } <nl> + return evalutils . getdatatypenamefromclass ( type ) ; <nl> } <nl>  <nl> / / elide self parameter from parameters in class methods .
swift_library ( name = " swiftmain " , <nl> srcs = [ " app . swift " ] ) <nl>  <nl> objc_binary ( name = " bin " , <nl> - # <nl> - # uses_swift flag on objcprovider and should not be necessary . <nl> - srcs = [ ' dummy . swift ' ] , <nl> + srcs = [ " / / tools / objc : dummy . c " ] , <nl> deps = [ " : swiftmain " ] ) <nl>  <nl> ios_application ( name = " app " , <nl>
swift_library ( name = " swiftmain " , <nl> srcs = [ " main . swift " ] ) <nl>  <nl> objc_binary ( name = " bin " , <nl> - # <nl> - # uses_swift flag on objcprovider and should not be necessary . <nl> - srcs = [ ' app . m ' , ' dummy . swift ' ] , <nl> + srcs = [ ' app . m ' , ] , <nl> deps = [ " : swiftmain " ] ) <nl> eof <nl>  <nl>
swift_library ( name = " swiftmain " , <nl> srcs = [ " app . swift " ] ) <nl>  <nl> objc_binary ( name = " bin " , <nl> - # <nl> - # uses_swift flag on objcprovider and should not be necessary . <nl> - srcs = [ ' dummy . swift ' ] , <nl> + srcs = [ " / / tools / objc : dummy . c " ] , <nl> deps = [ " : swiftmain " ] ) <nl>  <nl> ios_application ( name = " app " , <nl>
docker_build_ = rule ( <nl> # # https : / / docs . docker . com / reference / builder / # maintainer <nl> # maintainer = " . . . " , <nl> # <nl> - # # <nl> # # https : / / docs . docker . com / reference / builder / # user <nl> # # note : the normal directive affects subsequent run , cmd , <nl> # # and entrypoint <nl> mmm a / tools / build_defs / docker / rewrite_json . py <nl> ppp b / tools / build_defs / docker / rewrite_json . py <nl>
public final class commandenvironment { <nl> throws invalidconfigurationexception , interruptedexception { <nl> buildoptions buildoptions = runtime . createbuildoptions ( optionsprovider ) ; <nl> boolean keepgoing = optionsprovider . getoptions ( buildview . options . class ) . keepgoing ; <nl> - boolean loadingsuccessful = <nl> - loadforconfigurations ( reporter , <nl> - immutableset . copyof ( buildoptions . getalllabels ( ) . values ( ) ) , <nl> - keepgoing ) ; <nl> - if ( ! loadingsuccessful ) { <nl> - throw new invalidconfigurationexception ( " configuration creation failed " ) ; <nl> - } <nl> return getskyframeexecutor ( ) . createconfigurations ( reporter , runtime . getconfigurationfactory ( ) , <nl> buildoptions , immutableset . < string > of ( ) , keepgoing ) ; <nl> } <nl>  <nl> - <nl> - / / implicitly trigger any necessary loading . <nl> - private boolean loadforconfigurations ( eventhandler eventhandler , <nl> - set < label > labelstoload , boolean keepgoing ) throws interruptedexception { <nl> - / / use a new label visitor here to avoid erasing the cache on the existing one . <nl> - transitivepackageloader transitivepackageloader = getpackagemanager ( ) . newtransitiveloader ( ) ; <nl> - boolean loadingsuccessful = transitivepackageloader . sync ( <nl> - eventhandler , immutableset . < target > of ( ) , <nl> - labelstoload , keepgoing , / * parallelthreads = * / 10 , <nl> - / * maxdepth = * / integer . max_value ) ; <nl> - return loadingsuccessful ; <nl> - } <nl> - <nl> / * * <nl> * hook method called by the blazecommanddispatcher right before the dispatch <nl> * of each command ends ( while its outcome can still be modified ) .
def create_android_sdk_rules ( <nl> " # ! / bin / bash - eu " , <nl> # the tools under build - tools / version require the libraries under build - tools / version / lib , <nl> # so we can ' t simply depend on them as a file like we do with aapt . <nl> - # <nl> - " sdk = $ $ { 0 } . runfiles / % s / external / % s " % ( workspace_name , name ) , <nl> + " sdk = $ $ { 0 } . runfiles / % s " % name , <nl> " exec $ $ { sdk } / build - tools / % s / % s $ $ * " % ( build_tools_directory , tool ) , <nl> " eof\n " ] ) , <nl> ) for tool in [ " aapt " , " aidl " , " zipalign " ] ]
<nl>  <nl> # installation and etc prefix can be overriden from command line <nl> install_prefix = $ { 1 : - " / usr / local " } <nl> - # <nl> - bazelrc = $ { 2 : - " / etc / bazel . bazelrc " } <nl>  <nl> progname = " $ 0 " <nl>  <nl>
<nl>  <nl> # installation and etc prefix can be overriden from command line <nl> install_prefix = $ { 1 : - " / usr / local " } <nl> - # <nl> - bazelrc = $ { 2 : - " / etc / bazel . bazelrc " } <nl>  <nl> progname = " $ 0 " <nl>  <nl>
def _swift_library_impl ( ctx ) : <nl> progress_message = ( " compiling swift module % s ( % d files ) " <nl> % ( ctx . label . name , len ( ctx . files . srcs ) ) ) ) <nl>  <nl> - struct_kw = { } <nl> - if hasattr ( apple_common , " new_objc_provider " ) : <nl> - struct_kw [ " objc " ] = apple_common . new_objc_provider ( <nl> - library = set ( [ output_lib ] + dep_libs ) , <nl> - header = set ( [ output_header ] ) ) <nl> - else : <nl> - # <nl> - struct_kw [ " objc_export " ] = struct ( library = set ( [ output_lib ] + dep_libs ) , <nl> - header = set ( [ output_header ] ) ) <nl> + objc_provider = apple_common . new_objc_provider ( <nl> + library = set ( [ output_lib ] + dep_libs ) , <nl> + header = set ( [ output_header ] ) ) <nl>  <nl> return struct ( <nl> swift = struct ( <nl> library = output_lib , <nl> module = output_module , <nl> transitive_libs = dep_libs , <nl> - transitive_modules = dep_modules ) , * * struct_kw ) <nl> + transitive_modules = dep_modules ) , <nl> + objc = objc_provider ) <nl>  <nl> swift_library = rule ( <nl> _swift_library_impl ,
public class objccommandlineoptions extends fragmentoptions { <nl> + " on the machine the simulator will be run on . " ) <nl> public string iossimulatordevice ; <nl>  <nl> - <nl> @ option ( <nl> name = " objc_generate_debug_symbols " , <nl> defaultvalue = " false " , <nl> category = " flags " , <nl> + deprecationwarning = " - g is enabled for all dbg builds . " <nl> + + " use - - apple_generate_dsym flag for dsym . " <nl> + + " use apple_generate_breakpad rule for breakpad . " , <nl> help = " specifies whether to generate debug symbol ( . dsym ) file . " <nl> ) <nl> public boolean generatedebugsymbols ;
mkdir - p " $ { tmpdir } " # mkdir does work with a path starting with ' c : / ' , wow <nl> # containing spaces seem to be passed properly . <nl> echo " bootstrapping bazel " <nl> . / compile . sh " $ * " | | exit $ ? <nl> - <nl> - # run the only windows - specific test we have . <nl> - # <nl> - echo " running tests " <nl> - retcode = 0 <nl> - . / output / bazel - - batch test / / src / test / shell / bazel : bazel_windows_cpp_test | | retcode = $ ? <nl> - # exit for failure except for test failures ( exit code num ) . <nl> - if ( ( $ retcode ! = num & & $ retcode ! = num ) ) ; then <nl> - exit $ retcode <nl> - fi
def _swift_library_impl ( ctx ) : <nl> " - module - name " , ctx . label . name , <nl> " - parse - as - library " , <nl> " - target " , target , <nl> - # <nl> - " - sdk " , " __bazel_xcode_sdkroot__ " , <nl> + " - sdk " , apple_common . apple_toolchain ( ) . sdk_dir ( ) , <nl> " - o " , output_lib . path , <nl> ] + srcs_args + include_args
public class javaoptions extends fragmentoptions { <nl> host . jvmopts = immutablelist . of ( " - client " , " - xx : errorfile = / dev / stderr " ) ; <nl>  <nl> host . javacopts = javacopts ; <nl> - <nl> - host . javatoolchain = javatoolchain ; <nl> + host . javatoolchain = hostjavatoolchain ; <nl>  <nl> / / java builds often contain complicated code generators for which <nl> / / incremental build performance is important .
class gitprogressmonitor implements progressmonitor { <nl> } <nl>  <nl> @ override <nl> - public void start ( int totaltasks ) { <nl> - this . totaltasks = totaltasks ; <nl> - this . currenttask = num ; <nl> - } <nl> + public void start ( int totaltasks ) { } <nl>  <nl> private void report ( ) { <nl> eventhandler . handle ( <nl> - event . progress ( " [ " + currenttask + " / " + totaltasks + " ] " <nl> - + message + " : " + worktitle + " ( " <nl> - + completedwork + " / " + totalwork + " ) " ) ) ; <nl> + event . progress ( message + " : " + worktitle <nl> + + " ( " + completedwork + " / " + totalwork + " ) " ) ) ; <nl> } <nl>  <nl> @ override <nl> public void begintask ( string title , int totalwork ) { <nl> - + + currenttask ; <nl> - <nl> - if ( currenttask > totaltasks ) { <nl> - totaltasks = currenttask ; <nl> - } <nl> this . totalwork = totalwork ; <nl> this . completedwork = num ; <nl> this . worktitle = title ;
public final class cppmodel { <nl> * @ return whether this target needs to generate a pic header module . <nl> * / <nl> public boolean getgeneratespicheadermodule ( ) { <nl> - <nl> - return featureconfiguration . isenabled ( cppruleclasses . header_modules ) & & ! fake <nl> - & & getgeneratepicactions ( ) ; <nl> + return shouldprovideheadermodules ( ) & & ! fake & & getgeneratepicactions ( ) ; <nl> } <nl>  <nl> / * * <nl> * @ return whether this target needs to generate a non - pic header module . <nl> * / <nl> public boolean getgeneratesnopicheadermodule ( ) { <nl> - return featureconfiguration . isenabled ( cppruleclasses . header_modules ) & & ! fake <nl> - & & getgeneratenopicactions ( ) ; <nl> + return shouldprovideheadermodules ( ) & & ! fake & & getgeneratenopicactions ( ) ; <nl> } <nl>  <nl> / * * <nl>
final class skyframelabelvisitor implements transitivepackageloader { <nl> } <nl>  <nl> private static void warnaboutloadingfailure ( label label , eventhandler eventhandler ) { <nl> - eventhandler . handle ( event . warn ( <nl> - <nl> - / / blaze . once we get rid of legacy we should be able to change to ' loading ' or <nl> - / / similar . <nl> - " errors encountered while analyzing target ' " + label + " ' : it will not be built " ) ) ; <nl> + eventhandler . handle ( event . warn ( " errors encountered while loading target ' " + label + " ' " ) ) ; <nl> } <nl>  <nl> private static set < label > getrootcausesofcycles ( label labeltoload , iterable < cycleinfo > cycles ) { <nl> mmm a / src / test / java / com / google / devtools / build / lib / analysis / buildviewtest . java <nl> ppp b / src / test / java / com / google / devtools / build / lib / analysis / buildviewtest . java <nl>
gensrcjar = rule ( <nl> outputs = { " srcjar " : " lib % { name } . srcjar " } , <nl> ) <nl>  <nl> - # <nl> - def java_proto_library ( name , src ) : <nl> - gensrcjar ( name = name + " _srcjar " , src = src ) <nl> + def cc_grpc_library ( name , src ) : <nl> + basename = src [ : - len ( " . proto " ) ] <nl> + <nl> + native . genrule ( <nl> + name = name + " _codegen " , <nl> + srcs = [ src ] , <nl> + tools = [ " / / third_party / protobuf : protoc " , " / / third_party / grpc : cpp_plugin " ] , <nl> + cmd = " \ \ \n " . join ( [ <nl> + " $ ( location / / third_party / protobuf : protoc ) " , <nl> + " - - plugin = protoc - gen - grpc = $ ( location / / third_party / grpc : cpp_plugin ) " , <nl> + " - - cpp_out = $ ( gendir ) " , <nl> + " - - grpc_out = $ ( gendir ) " , <nl> + " $ ( location " + src + " ) " ] ) , <nl> + outs = [ basename + " . grpc . pb . h " , basename + " . grpc . pb . cc " , basename + " . pb . cc " , basename + " . pb . h " ] ) <nl> + <nl> + native . cc_library ( <nl> + name = name , <nl> + srcs = [ basename + " . grpc . pb . cc " , basename + " . pb . cc " ] , <nl> + hdrs = [ basename + " . grpc . pb . h " , basename + " . pb . h " ] , <nl> + deps = [ " / / third_party / grpc : grpc + + " ] , <nl> + includes = [ " . " ] ) <nl> + <nl> + def java_proto_library ( name , src , use_grpc_plugin = false ) : <nl> + grpc_java_plugin = none <nl> + if use_grpc_plugin : <nl> + grpc_java_plugin = " / / third_party / grpc : grpc - java - plugin " <nl> + <nl> + gensrcjar ( name = name + " _srcjar " , src = src , grpc_java_plugin = grpc_java_plugin ) <nl> + deps = [ " / / third_party / protobuf " ] <nl> + if use_grpc_plugin : <nl> + deps + = [ " / / third_party / grpc : grpc - jar " , " / / third_party : guava " ] <nl> native . java_library ( <nl> name = name , <nl> srcs = [ name + " _srcjar " ] , <nl> - deps = [ " @ bazel_tools / / third_party / protobuf " ] , <nl> + deps = deps , <nl> # the generated code has lots of ' rawtypes ' warnings . <nl> javacopts = [ " - xlint : - rawtypes " ] , <nl> ) <nl> mmm a / tools / build_rules / gensrcjar . sh <nl> ppp b / tools / build_rules / gensrcjar . sh <nl>
cc_library ( <nl> " mapped_file . h " , <nl> " zip . h " , <nl> ] , <nl> - # <nl> - # we should instead use a new_local_repository once the autoconf <nl> - # mechanism is ready . <nl> - linkopts = [ " - lz " ] , <nl> + deps = [ " / / third_party / zlib " ] , <nl> ) <nl>  <nl> cc_binary ( <nl> mmm a / third_party / zlib / build <nl> ppp b / third_party / zlib / build <nl>
public class cppcompileactionbuilder { <nl> } <nl> realmandatoryinputsbuilder . addtransitive ( context . getadditionalinputs ( usepic ) ) ; <nl>  <nl> - / / add all sources of transitively found modules . although they are also embedded in the . pcm <nl> - / / files , clang currently verifies that all files specified in a cppmap do exist . <nl> - <nl> - realmandatoryinputsbuilder . addtransitive ( context . gettransitiveheadermodulesrcs ( ) ) ; <nl> + if ( cppconfiguration . sendtransitiveheadermodulesrcs ( ) ) { <nl> + realmandatoryinputsbuilder . addtransitive ( context . gettransitiveheadermodulesrcs ( ) ) ; <nl> + } <nl>  <nl> realmandatoryinputsbuilder . addtransitive ( plugininputsbuilder . build ( ) ) ; <nl> realmandatoryinputsbuilder . add ( sourcefile ) ; <nl> mmm a / src / main / java / com / google / devtools / build / lib / rules / cpp / cppconfiguration . java <nl> ppp b / src / main / java / com / google / devtools / build / lib / rules / cpp / cppconfiguration . java <nl>
public final class packageidentifier implements comparable < packageidentifier > , s <nl> } <nl> } <nl>  <nl> - / * * <nl> - * this is only used by legacy callers . actually creates the package identifier in the main <nl> - * repository , not the default one . <nl> - * / <nl> - <nl> - @ deprecated <nl> - public static packageidentifier createindefaultrepo ( string name ) { <nl> - return create ( main_repository_name , new pathfragment ( name ) ) ; <nl> - } <nl> - <nl> public static packageidentifier createinmainrepo ( string name ) { <nl> return createinmainrepo ( new pathfragment ( name ) ) ; <nl> }
public abstract class repositoryfunction { <nl> if ( value = = null ) { <nl> return null ; <nl> } <nl> - <nl> package externalpackage = value . getpackage ( ) ; <nl> if ( externalpackage . containserrors ( ) ) { <nl> + event . replayeventson ( env . getlistener ( ) , externalpackage . getevents ( ) ) ; <nl> throw new repositoryfunctionexception ( <nl> new buildfilecontainserrorsexception ( <nl> label . external_package_identifier , " could not load / / external package " ) , <nl> mmm a / src / test / java / com / google / devtools / build / lib / bazel / repository / skylark / skylarkrepositoryintegrationtest . java <nl> ppp b / src / test / java / com / google / devtools / build / lib / bazel / repository / skylark / skylarkrepositoryintegrationtest . java <nl>
public class iostestrule implements ruledefinition { <nl> } <nl> } ) <nl> . allowedfiletypes ( ) <nl> - <nl> - . allowedruleclasses ( " objc_binary " , " ios_application " ) ) <nl> + . allowedruleclasses ( " ios_application " ) ) <nl> . override ( <nl> attr ( bundlingrule . infoplist_attr , label ) <nl> . value (
public class abstractqueuevisitortest { <nl> counter . awaitquiescence ( / * interruptworkers = * / false ) ; <nl> assertsame ( 10 , counter . getcount ( ) ) ; <nl> assertsame ( 0 , counter . activeparalleltasks ( ) ) ; <nl> - <nl> - / / assertsame ( 1 , counter . getmaxrunningconcurrently ( ) ) ; <nl> } <nl>  <nl> @ test <nl>
public class skylarkexecutionresult { <nl> argsarray [ i ] = arg . tostring ( ) ; <nl> } <nl> commandresult result = new command ( argsarray ) . execute ( new byte [ ] { } , timeout , false ) ; <nl> - <nl> - / / bazel will crash . maybe we should use custom output streams that throw an appropriate <nl> - / / exception when reaching a specific size . <nl> - string stdout = new string ( result . getstdout ( ) , standardcharsets . utf_8 ) ; <nl> - string stderr = new string ( result . getstderr ( ) , standardcharsets . utf_8 ) ; <nl> - return new skylarkexecutionresult ( <nl> - result . getterminationstatus ( ) . getexitcode ( ) , stdout , stderr ) ; <nl> + return new skylarkexecutionresult ( result ) ; <nl> + } catch ( badexitstatusexception e ) { <nl> + return new skylarkexecutionresult ( e . getresult ( ) ) ; <nl> } catch ( commandexception e ) { <nl> return new skylarkexecutionresult ( 256 , " " , e . getmessage ( ) ) ; <nl> } <nl> mmm a / src / test / shell / bazel / skylark_repository_test . sh <nl> ppp b / src / test / shell / bazel / skylark_repository_test . sh <nl>
xcode_config ( <nl> name = " host_xcodes " , <nl> ) <nl>  <nl> - # <nl> - py_library ( <nl> + filegroup ( <nl> name = " j2objc_dead_code_pruner " , <nl> srcs = [ " j2objc_dead_code_pruner . py " ] , <nl> )
eval " cleanup_phasefile ( ) { <nl> } " <nl> atexit cleanup_phasefile <nl>  <nl> - function run_silent ( ) { <nl> - echo " $ { @ } " > $ { errfile } <nl> - # <nl> - # even though errexit is set . <nl> - " $ { @ } " > > $ { errfile } num > & 1 | | exit $ ? <nl> - rm $ { errfile } <nl> + # excutes a command respecting the current verbosity settings . <nl> + # <nl> + # if verbose is yes , the command itself and its output are printed . <nl> + # if verbose is no , the command ' s output is only displayed in case of failure . <nl> + # <nl> + # exits the script if the command fails . <nl> + function run ( ) { <nl> + if [ " $ { verbose } " = yes ] ; then <nl> + echo " $ { @ } " <nl> + " $ { @ } " | | exit $ ? <nl> + else <nl> + echo " $ { @ } " > " $ { errfile } " <nl> + # the exit here is needed because " set - e " on the shell does not cause <nl> + # errors in functions to exit in all cases . we should probably disable <nl> + # " set - e " altogether and add explicit error handling where necessary . <nl> + " $ { @ } " > > " $ { errfile } " num > & 1 | | exit $ ? <nl> + rm " $ { errfile } " <nl> + fi <nl> } <nl>  <nl> function fail ( ) { <nl> mmm a / scripts / bootstrap / compile . sh <nl> ppp b / scripts / bootstrap / compile . sh <nl>
def java_rule_ide_info ( target , ctx ) : <nl> else : <nl> sources = [ ] <nl> jars = [ library_artifact ( output ) for output in target . java . outputs . jars ] <nl> + ide_resolve_files = set ( [ jar <nl> + for jar in [ output . class_jar , output . ijar , output . source_jar ] <nl> + for output in target . java . outputs . jars ] ) <nl> jdeps = artifact_location ( target . java . outputs . jdeps ) <nl>  <nl> - return struct ( sources = sources , <nl> - jars = jars , <nl> - jdeps = jdeps , <nl> - ) # <nl> + return ( struct ( sources = sources , <nl> + jars = jars , <nl> + jdeps = jdeps , <nl> + ) , <nl> + ide_resolve_files ) <nl>  <nl>  <nl> def _aspect_impl ( target , ctx ) : <nl>
public final class buildviewtest extends buildviewtestbase { <nl> assertsame ( failaction . class , action . getclass ( ) ) ; <nl> } <nl>  <nl> - <nl> - / / analysis fail , this needs a proper way to inject errors / warnings <nl> @ test <nl> - @ ignore <nl> - public void disabled_testreportsanalysisrootcauses ( ) throws exception { <nl> - scratch . file ( " pkg / build " , <nl> - " genrule ( name = ' foo ' , " , <nl> - " tools = [ : missing ] , " , <nl> - " outs = [ ' foofile ' ] , " , <nl> - " cmd = ' ' ) " , <nl> - " genrule ( name = ' bar ' , " , <nl> - " srcs = [ ' foofile ' ] , " , <nl> - " outs = [ ' barfile ' ] , " , <nl> - " cmd = ' ' ) " ) ; <nl> + public void testreportsanalysisrootcauses ( ) throws exception { <nl> + scratch . file ( " private / build " , <nl> + " genrule ( " , <nl> + " name = ' private ' , " , <nl> + " outs = [ ' private . out ' ] , " , <nl> + " cmd = ' ' , " , <nl> + " visibility = [ ' / / visibility : private ' ] ) " ) ; <nl> + scratch . file ( " foo / build " , <nl> + " genrule ( " , <nl> + " name = ' foo ' , " , <nl> + " tools = [ ' : bar ' ] , " , <nl> + " outs = [ ' foo . out ' ] , " , <nl> + " cmd = ' ' ) " , <nl> + " genrule ( " , <nl> + " name = ' bar ' , " , <nl> + " tools = [ ' / / private ' ] , " , <nl> + " outs = [ ' bar . out ' ] , " , <nl> + " cmd = ' ' ) " ) ; <nl>  <nl> reporter . removehandler ( failfasthandler ) ; <nl> eventbus eventbus = new eventbus ( ) ; <nl> analysisfailurerecorder recorder = new analysisfailurerecorder ( ) ; <nl> eventbus . register ( recorder ) ; <nl> - update ( eventbus , defaultflags ( ) . with ( flag . keep_going ) , " / / pkg : bar " ) ; <nl> + update ( eventbus , defaultflags ( ) . with ( flag . keep_going ) , " / / foo " ) ; <nl> assertthat ( recorder . events ) . hassize ( 1 ) ; <nl> analysisfailureevent event = recorder . events . get ( 0 ) ; <nl> - assertequals ( " / / pkg : foo " , event . getfailurereason ( ) . tostring ( ) ) ; <nl> - assertequals ( " / / pkg : bar " , event . getfailedtarget ( ) . getlabel ( ) . tostring ( ) ) ; <nl> + assertequals ( " / / foo : bar " , event . getfailurereason ( ) . tostring ( ) ) ; <nl> + assertequals ( " / / foo : foo " , event . getfailedtarget ( ) . getlabel ( ) . tostring ( ) ) ; <nl> } <nl>  <nl> @ test
<nl> - / / copyright num the bazel authors . all rights reserved . <nl> - / / <nl> - / / licensed under the apache license , version num . 0 ( the " license " ) ; <nl> - / / you may not use this file except in compliance with the license . <nl> - / / you may obtain a copy of the license at <nl> - / / <nl> - / / http : / / www . apache . org / licenses / license - 2 . 0 <nl> - / / <nl> - / / unless required by applicable law or agreed to in writing , software <nl> - / / distributed under the license is distributed on an " as is " basis , <nl> - / / without warranties or conditions of any kind , either express or implied . <nl> - / / see the license for the specific language governing permissions and <nl> - / / limitations under the license . <nl> - package com . google . devtools . build . lib . util ; <nl> - <nl> - / * * utilities for dealing with { @ link runnable } s that may call into uncontrolled code . * / <nl> - public class runnables { <nl> - private runnables ( ) { } <nl> - <nl> - / * * <nl> - * a { @ link runnable } that terminates the jvm instead of throwing an unchecked exception in <nl> - * { @ link runnable # run } . <nl> - * <nl> - * < p > this is useful if the { @ link runnable } may be executed by code outside of our control , e . g . <nl> - * if we call into library code that silently swallows { @ link runtimeexception } s from our code . <nl> - * / <nl> - <nl> - public abstract static class abstractcrashterminatingrunnable implements runnable { <nl> - protected abstract void runimpl ( ) ; <nl> - <nl> - @ override <nl> - public final void run ( ) { <nl> - try { <nl> - runimpl ( ) ; <nl> - } catch ( throwable t ) { <nl> - runtimeutils . halt ( t ) ; <nl> - } <nl> - } <nl> - } <nl> - } <nl> mmm a / src / main / java / com / google / devtools / build / lib / util / runtimeutils . java <nl> ppp / dev / null <nl>
void blazestartupoptions : : init ( ) { <nl> block_for_lock = true ; <nl> host_jvm_debug = false ; <nl> host_javabase = " " ; <nl> - <nl> - preserve_spaces_in_host_jvm_args = true ; <nl> batch = false ; <nl> batch_cpu_scheduling = false ; <nl> blaze_cpu = false ; <nl>
public abstract class skylarklist implements iterable < object > , skylarkvalue { <nl> * returns the list object underlying this skylarklist . <nl> * mutating it ( if mutable ) will actually mutate the contents of the list . <nl> * / <nl> - <nl> - public abstract list < object > getlist ( ) ; <nl> + protected abstract list < object > getlist ( ) ; <nl>  <nl> / * * <nl> * returns an immutablelist object with the current underlying contents of this skylarklist . <nl>
public final class environment implements freezable { <nl> return lexicalframe = = null ; <nl> } <nl>  <nl> - / * * <nl> - * is the current code skylark ? <nl> - * @ return true if skylark was enabled when this code was read . <nl> - * / <nl> - <nl> - / / this function is currently used in various functions that change their behavior with respect to <nl> - / / lists depending on the skylark - ness of the code ; lists should be unified between the two modes . <nl> - @ visiblefortesting <nl> - public boolean isskylark ( ) { <nl> - return isskylark ; <nl> - } <nl> - <nl> @ override <nl> public mutability mutability ( ) { <nl> / / the mutability of the environment is that of its dynamic frame . <nl>
public class skylarkruleclassfunctions { <nl> } <nl>  <nl>  <nl> - @ skylarksignature ( <nl> - name = " aspect " , <nl> + @ skylarksignature ( name = " aspect " , doc = <nl> + " creates a new aspect . the result of this fucntion must be stored in a global value . " , <nl> returntype = skylarkaspect . class , <nl> - documented = false , <nl> - mandatorypositionals = { @ param ( name = " implementation " , type = basefunction . class ) } , <nl> + mandatorypositionals = { <nl> + @ param ( name = " implementation " , type = basefunction . class , <nl> + doc = " the function implementing this aspect . must have two parameters : " <nl> + + " < a href = \ " target . html \ " > target < / a > ( the target to which the aspect is applied ) and " <nl> + + " < a href = \ " ctx . html \ " > ctx < / a > . attributes of the target are available via ctx . rule " <nl> + + " field . the function is called during the analysis phase for each application of " <nl> + + " an aspect to a target . " <nl> + ) , <nl> + } , <nl> optionalpositionals = { <nl> - @ param ( <nl> - name = " attr_aspects " , <nl> - type = skylarklist . class , <nl> - generic1 = string . class , <nl> - defaultvalue = " [ ] " <nl> + @ param ( name = " attr_aspects " , type = skylarklist . class , generic1 = string . class , <nl> + defaultvalue = " [ ] " , <nl> + doc = " list of attribute names . the aspect propagates along dependencies specified by " <nl> + + " attributes of a target with this name " <nl> ) , <nl> - @ param ( name = " attrs " , type = map . class , noneable = true , defaultvalue = " none " ) <nl> + @ param ( name = " attrs " , type = map . class , noneable = true , defaultvalue = " none " , <nl> + doc = " dictionary to declare all the attributes of the aspect . " <nl> + + " it maps from an attribute name to an attribute object " <nl> + + " ( see < a href = \ " attr . html \ " > attr < / a > module ) . " <nl> + + " aspect attributes are available to implementation function as fields of ctx parameter . " <nl> + + " all aspect attributes must be private , so their names must start with < code > _ < / code > . " <nl> + + " all aspect attributes must be have default values , and be of type " <nl> + + " < code > label < / code > or < code > label_list < / code > " <nl> + ) <nl> } , <nl> useenvironment = true , <nl> useast = true
go_test = rule ( <nl> test = true , <nl> ) <nl>  <nl> - # <nl> def go_repositories ( ) : <nl> - native . bind ( name = " go_prefix " , <nl> - actual = " / / : go_prefix " , <nl> - ) <nl> - <nl> native . new_http_archive ( <nl> name = " golang - linux - amd64 " , <nl> url = " https : / / storage . googleapis . com / golang / go1 . 5 . 1 . linux - amd64 . tar . gz " ,
static vector < string > getargumentarray ( ) { <nl> globals - > options . host_jvm_args . end ( ) ) ; <nl> } else { <nl> for ( const auto & arg : globals - > options . host_jvm_args ) { <nl> - / / int num_segments = <nl> - blaze_util : : splitquotedstringusing ( arg , ' ' , & user_options ) ; <nl> - <nl> - / / if ( num_segments > num ) { <nl> - / / fprintf ( stderr , " warning : you are passing multiple jvm options " <nl> - / / " under a single - - host_jvm_args option : % s . this will stop <nl> - / / working " <nl> - / / " soon . instead , pass each option under its own <nl> - / / - - host_jvm_args " <nl> - / / " option . \n " , arg ) ; <nl> - / / <nl> + int num_segments = <nl> + blaze_util : : splitquotedstringusing ( arg , ' ' , & user_options ) ; <nl> + if ( num_segments > num ) { <nl> + fprintf ( <nl> + stderr , <nl> + " warning : you are passing multiple jvm options " <nl> + " under a single - - host_jvm_args option : % s . this will stop working " <nl> + " soon . instead , pass each option under its own - host_jvm_args " <nl> + " option . \n " , <nl> + arg . c_str ( ) ) ; <nl> + } <nl> } <nl> }
import com . google . common . collect . immutablelist ; <nl>  <nl> import java . util . list ; <nl>  <nl> - <nl> - / / create a chain of if - else statements for elif - s . <nl> / * * <nl> * syntax node for an if / else statement . <nl> * / <nl>
public abstract class linenumbertable implements serializable { <nl> * line number table implementation for source files that have been <nl> * preprocessed . ignores newlines and uses only # line directives . <nl> * / <nl> - <nl> @ immutable <nl> public static class hashline extends linenumbertable { <nl>  <nl> mmm a / src / test / java / com / google / devtools / build / lib / syntax / util / evaluationtestcase . java <nl> ppp b / src / test / java / com / google / devtools / build / lib / syntax / util / evaluationtestcase . java <nl>
<nl> # script for building bazel from scratch without bazel <nl>  <nl> proto_files = $ ( ls src / main / protobuf / * . proto ) <nl> - # <nl> library_jars = $ ( find third_party - name ' * . jar ' | tr " \n " " " ) <nl> dirs = $ ( echo src / { java_tools / singlejar / java / com / google / devtools / build / zip , main / java , tools / xcode - common / java / com / google / devtools / build / xcode / { common , util } } $ { output_dir } / src )
<nl> - # <nl> - # move every target of the build file into there java package . <nl> - java_library ( <nl> - name = " options " , <nl> - srcs = glob ( [ <nl> - " com / google / devtools / common / options / * . java " , <nl> - ] ) , <nl> - visibility = [ " / / visibility : public " ] , <nl> - deps = [ <nl> - " / / third_party : guava " , <nl> - " / / third_party : jsr305 " , <nl> - ] , <nl> - )
static void killrunningserver ( pid_t server_pid ) { <nl> globals - > options . getproductname ( ) . c_str ( ) , server_pid ) ; <nl> fflush ( stderr ) ; <nl> killpg ( server_pid , sigkill ) ; <nl> - if ( kill ( server_pid , num ) = = - 1 ) { / / ( probe ) <nl> - fprintf ( stderr , " could not be killed . \n " ) ; / / task state ' z ' or ' d ' ? <nl> - exit ( 1 ) ; <nl> - } else { <nl> - fprintf ( stderr , " killed . \n " ) ; <nl> + for ( int ii = num ; ii < num ; + + ii ) { / / wait up to num s <nl> + if ( kill ( server_pid , num ) = = - 1 ) { / / ( probe ) <nl> + if ( errno = = esrch ) { <nl> + / / the previous server is gone . this is what we ' re looking for ! <nl> + fprintf ( stderr , " killed . \n " ) ; <nl> + return ; <nl> + } <nl> + / / unexpected failure from kill ( ) . <nl> + pdie ( blaze_exit_code : : internal_error , " could not be killed " ) ; <nl> + } <nl> + poll ( null , num , num ) ; / / sleep num ms . ( usleep ( 3 ) is obsolete . ) <nl> } <nl> + / / process did not go away num s after sigkill . stuck in state ' z ' or ' d ' ? <nl> + pdie ( blaze_exit_code : : internal_error , " sigkill unsuccessful after num s " ) ; <nl> }
<nl> - / / copyright num the bazel authors . all rights reserved . <nl> - / / <nl> - / / licensed under the apache license , version num . 0 ( the " license " ) ; <nl> - / / you may not use this file except in compliance with the license . <nl> - / / you may obtain a copy of the license at <nl> - / / <nl> - / / http : / / www . apache . org / licenses / license - 2 . 0 <nl> - / / <nl> - / / unless required by applicable law or agreed to in writing , software <nl> - / / distributed under the license is distributed on an " as is " basis , <nl> - / / without warranties or conditions of any kind , either express or implied . <nl> - / / see the license for the specific language governing permissions and <nl> - / / limitations under the license . <nl> - <nl> - package com . google . devtools . build . lib . packages ; <nl> - <nl> - import com . google . devtools . build . lib . cmdline . packageidentifier ; <nl> - <nl> - / * * <nl> - * exception indicating that the same package ( i . e . build file ) can be loaded <nl> - * via different package paths . <nl> - * / <nl> - <nl> - / / longer a child of nosuchpackageexception . <nl> - public class duplicatepackageexception extends nosuchpackageexception { <nl> - <nl> - public duplicatepackageexception ( packageidentifier packageidentifier , string message ) { <nl> - super ( packageidentifier , message ) ; <nl> - } <nl> - <nl> - public duplicatepackageexception ( packageidentifier packageidentifier , string message , <nl> - throwable cause ) { <nl> - super ( packageidentifier , message , cause ) ; <nl> - } <nl> - }
public final class ruleclass { <nl>  <nl> private void checkattrvalnonempty ( <nl> rule rule , eventhandler eventhandler , object attributevalue , integer attrindex ) { <nl> - list < ? > list ; <nl> + <nl> + attribute attr = getattribute ( attrindex ) ; <nl> + if ( ! attr . isnonempty ( ) ) { <nl> + return ; <nl> + } <nl> + <nl> + boolean isempty = false ; <nl>  <nl> if ( attributevalue instanceof skylarklist ) { <nl> - list = ( ( skylarklist ) attributevalue ) . getlist ( ) ; <nl> + isempty = ( ( skylarklist ) attributevalue ) . isempty ( ) ; <nl> } else if ( attributevalue instanceof list < ? > ) { <nl> - list = ( list < ? > ) attributevalue ; <nl> - } else { <nl> - <nl> - return ; <nl> + isempty = ( ( list < ? > ) attributevalue ) . isempty ( ) ; <nl> + } else if ( attributevalue instanceof map < ? , ? > ) { <nl> + isempty = ( ( map < ? , ? > ) attributevalue ) . isempty ( ) ; <nl> } <nl>  <nl> - attribute attr = getattribute ( attrindex ) ; <nl> - if ( attr . isnonempty ( ) & & list . isempty ( ) ) { <nl> - rule . reporterror ( rule . getlabel ( ) + " : non empty " + " attribute ' " + attr . getname ( ) <nl> + if ( isempty ) { <nl> + rule . reporterror ( rule . getlabel ( ) + " : non empty attribute ' " + attr . getname ( ) <nl> + " ' in ' " + name + " ' rule ' " + rule . getlabel ( ) + " ' has to have at least one value " , <nl> eventhandler ) ; <nl> }
<nl> - # <nl> + package ( <nl> + default_visibility = [ " / / src : __subpackages__ " ] , <nl> + ) <nl>  <nl> filegroup ( <nl> name = " toolchain " , <nl>
def _jsonnet_to_json_impl ( ctx ) : <nl> output_json_files = [ ctx . new_file ( ctx . configuration . bin_dir , out . name ) <nl> for out in ctx . attr . outs ] <nl> outputs + = output_json_files <nl> - command + = [ " - m " , ctx . file . src . path ] <nl> - # currently , jsonnet - m creates the output files in the current working <nl> - # directory . append mv commands to move the output files into their <nl> - # correct output directories . <nl> - # <nl> - # an output directory . <nl> - for json_file in output_json_files : <nl> - command + = [ " ; mv % s % s " % ( json_file . basename , json_file . path ) ] <nl> + command + = [ " - m " , output_json_files [ 0 ] . dirname , ctx . file . src . path ] <nl> else : <nl> if len ( ctx . attr . outs ) > num : <nl> fail ( " only one file can be specified in outs if multiple_outputs is " + <nl>
public class androidconfiguration extends buildconfiguration . fragment { <nl> help = " enables sanity checks for jack and jill compilation . " ) <nl> public boolean jacksanitychecks ; <nl>  <nl> - <nl> - @ option ( <nl> - name = " treat_srcjars_as_srcs_for_strict_deps " , <nl> - defaultvalue = " true " , <nl> - category = " undocumented " , <nl> - help = " no - op . kept here for backwards compatibility . " <nl> - ) <nl> - public boolean treatsrcjarsassrcsforstrictdeps ; <nl> - <nl> @ override <nl> public void addalllabels ( multimap < string , label > labelmap ) { <nl> if ( proguard ! = null ) {
public class buildview { <nl> * / <nl> @ nullable private final coveragereportactionfactory coveragereportactionfactory ; <nl>  <nl> - / * * <nl> - * used only for testing that we clear skyframe caches correctly . <nl> - * <nl> - * / <nl> - private boolean skyframecachewasinvalidated ; <nl> - <nl> / * * <nl> * if the last build was executed with { @ code options # discard_analysis_cache } and we are not <nl> * running skyframe full , we should clear the legacy data since it is out - of - sync . <nl>
public class buildview { <nl> return skyframebuildview . getevaluatedtargetkeys ( ) . size ( ) ; <nl> } <nl>  <nl> - / * * <nl> - * returns true iff skyframe was invalidated during the analysis phase . <nl> - * <nl> - * / <nl> - @ visiblefortesting <nl> - boolean wasskyframecacheinvalidatedduringanalysis ( ) { <nl> - return skyframecachewasinvalidated ; <nl> - } <nl> - <nl> public buildview ( blazedirectories directories , <nl> configuredruleclassprovider ruleclassprovider , <nl> skyframeexecutor skyframeexecutor , <nl>
<nl> - # copyright num google inc . all rights reserved . <nl> - # <nl> - # licensed under the apache license , version num . 0 ( the " license " ) ; <nl> - # you may not use this file except in compliance with the license . <nl> - # you may obtain a copy of the license at <nl> - # <nl> - # http : / / www . apache . org / licenses / license - 2 . 0 <nl> - # <nl> - # unless required by applicable law or agreed to in writing , software <nl> - # distributed under the license is distributed on an " as is " basis , <nl> - # without warranties or conditions of any kind , either express or implied . <nl> - # see the license for the specific language governing permissions and <nl> - # limitations under the license . <nl> - <nl> - licenses ( [ " notice " ] ) # apache license num . 0 <nl> - <nl> - # <nl> - exports_files ( [ " license " ] ) <nl> - <nl> - package ( <nl> - default_visibility = [ " / / visibility : public " ] , <nl> - ) <nl> - <nl> - filegroup ( <nl> - name = " srcs " , <nl> - srcs = glob ( [ " * * " ] ) , <nl> - visibility = [ " / / third_party : __pkg__ " ] , <nl> - ) <nl> - <nl> - objc_library ( <nl> - name = " jre_emul_lib " , <nl> - sdk_dylibs = [ <nl> - " libicucore " , <nl> - " libz " , <nl> - ] , <nl> - sdk_frameworks = [ <nl> - " security " , <nl> - ] , <nl> - deps = [ " @ bazel - j2objc / / : jre_emul_archive " ] , <nl> - )
public class j2objclibrarybaserule implements ruledefinition { <nl> } <nl> } <nl>  <nl> - <nl> / * < ! - - # blaze_rule ( name = j2objc_library , type = library , family = objective - c ) - - > <nl>  <nl> $ { attribute_signature } <nl> mmm a / third_party / java / j2objc / build . remote <nl> ppp b / third_party / java / j2objc / build . remote <nl>
<nl> # see the license for the specific language governing permissions and <nl> # limitations under the license . <nl>  <nl> - # <nl> - <nl> licenses ( [ " notice " ] ) # apache license num . 0 <nl>  <nl> exports_files ( [ " license " ] ) <nl>
string blazestartupoptions : : getjvm ( ) { <nl> blaze_exit_code : : exitcode blazestartupoptions : : addjvmarguments ( <nl> const string & host_javabase , vector < string > * result , <nl> const vector < string > & user_options , string * error ) const { <nl> - <nl> - / / open - source world . <nl> + / / configure logging <nl> + const string propfile = output_base + " / javalog . properties " ; <nl> + if ( ! writefile ( <nl> + " handlers = java . util . logging . filehandler\n " <nl> + " . level = info\n " <nl> + " java . util . logging . filehandler . level = info\n " <nl> + " java . util . logging . filehandler . pattern = " <nl> + + output_base + " / java . log\n " <nl> + " java . util . logging . filehandler . limit = 50000\n " <nl> + " java . util . logging . filehandler . count = 1\n " <nl> + " java . util . logging . filehandler . formatter = " <nl> + " java . util . logging . simpleformatter\n " , <nl> + propfile ) ) { <nl> + perror ( ( " couldn ' t write logging file " + propfile ) . c_str ( ) ) ; <nl> + } else { <nl> + result - > push_back ( " - djava . util . logging . config . file = " + propfile ) ; <nl> + } <nl> return blaze_exit_code : : success ; <nl> }
public final class bazelgenrulerule implements ruledefinition { <nl> . add ( attr ( " output_to_bindir " , boolean ) . value ( false ) <nl> . nonconfigurable ( " policy decision : no reason for this to depend on the configuration " ) ) <nl>  <nl> - <nl> + / * < ! - - # blaze_rule ( genrule ) . attribute ( local ) - - > <nl> + $ { synopsis } <nl> + < p > <nl> + if set to num , this option force this < code > genrule < / code > to run with the <nl> + < code > standalone < / code > strategy , without sandboxing . <nl> + < / p > <nl> + < ! - - # end_blaze_rule . attribute - - > * / <nl> . add ( attr ( " local " , boolean ) . value ( false ) ) <nl>  <nl> / * < ! - - # blaze_rule ( genrule ) . attribute ( message ) - - >
public class objccommandlineoptions extends fragmentoptions { <nl> @ option ( name = " xcode_options " , <nl> defaultvalue = " debug " , <nl> category = " undocumented " , <nl> + deprecationwarning = " use - - compilation_mode instead . " , <nl> help = " specifies the name of the build settings to use . " ) <nl> - <nl> - / / control proto . <nl> public string xcodeoptions ; <nl>  <nl> @ option ( name = " objc_generate_debug_symbols " ,
public final class javalibraryhelper { <nl> return new cclinkparamsstore ( ) { <nl> @ override <nl> protected void collect ( builder builder , boolean linkingstatically , boolean linkshared ) { <nl> - builder . addtransitivelangtargets ( <nl> - deps , <nl> - javacclinkparamsprovider . to_link_params ) ; <nl> - builder . addtransitivetargets ( deps ) ; <nl> - <nl> - builder . addtransitivelangtargets ( <nl> - deps , <nl> - ccspecificlinkparamsprovider . to_link_params ) ; <nl> + if ( legacycollectcppandjavalinkoptions ) { <nl> + builder . addtransitivetargets ( deps , <nl> + javacclinkparamsprovider . to_link_params ) ; <nl> + builder . addtransitivetargets ( deps , <nl> + cclinkparamsprovider . to_link_params , <nl> + ccspecificlinkparamsprovider . to_link_params ) ; <nl> + } else { <nl> + builder . addtransitivetargets ( deps , <nl> + javacclinkparamsprovider . to_link_params , <nl> + cclinkparamsprovider . to_link_params , <nl> + ccspecificlinkparamsprovider . to_link_params ) ; <nl> + } <nl> } <nl> } ; <nl> }
public class linuxsandboxedstrategy implements spawnactioncontext { <nl> throws execexception { <nl> executor executor = actionexecutioncontext . getexecutor ( ) ; <nl>  <nl> - <nl> - / / maybe add an annotation to actions that they can refuse to run under certain strategies ? <nl> - if ( spawn . getowner ( ) . getlabel ( ) = = null <nl> - | | spawn . getarguments ( ) . get ( 0 ) . contains ( " build - runfiles " ) ) { <nl> + / / certain actions can ' t run remotely or in a sandbox - pass them on to the standalone strategy . <nl> + if ( ! spawn . isremotable ( ) ) { <nl> standalonestrategy . exec ( spawn , actionexecutioncontext ) ; <nl> return ; <nl> }
public final class ruleclass { <nl> * are declared , this allows access to all fragments for backwards compatibility . <nl> * / <nl> public boolean islegalconfigurationfragment ( class < ? > configurationfragment ) { <nl> - / / for now , we allow all rules that don ' t declare allowed fragments to access any fragment . <nl> - <nl> - if ( requiredconfigurationfragments . isempty ( ) & & requiredconfigurationfragmentnames . isempty ( ) ) { <nl> - return true ; <nl> - } <nl> return requiredconfigurationfragments . contains ( configurationfragment ) <nl> | | haslegalfragmentname ( configurationfragment ) ; <nl> }
public class objccommandlineoptions extends fragmentoptions { <nl> + " built with - - cpu set to \ " ios_ < - - ios_cpu > \ " for any values in - - ios_multi_cpu . " ) <nl> public boolean enableccdeps ; <nl>  <nl> - <nl> @ option ( name = " experimental_objc_fastbuild_options " , <nl> - defaultvalue = " - o0 " , <nl> + defaultvalue = " - o0 , - ddebug " , <nl> category = " undocumented " , <nl> converter = commaseparatedoptionlistconverter . class , <nl> - help = " adds these strings to fastbuild compiler options . " ) <nl> + help = " uses these strings as objc fastbuild compiler options . " ) <nl> public list < string > fastbuildoptions ; <nl>  <nl> @ option ( name = " objc_enable_binary_stripping " ,
final class compilationsupport { <nl> . addexecpath ( " - o " , objfile ) <nl> . addexecpath ( " - emit - module - path " , intermediateartifacts . swiftmodulefile ( sourcefile ) ) ; <nl>  <nl> - / / add all objc headers to the compiler , in case swift code is calling into objc <nl> - <nl> - commandline . addbeforeeachexecpath ( " - import - objc - header " , attributes . hdrs ( ) ) ; <nl> + <nl> + immutablelist . builder < artifact > inputheaders = immutablelist . builder ( ) ; <nl> + inputheaders . addall ( attributes . hdrs ( ) ) ; <nl> + <nl> + optional < artifact > bridgingheader = attributes . bridgingheader ( ) ; <nl> + if ( bridgingheader . ispresent ( ) ) { <nl> + commandline . addexecpath ( " - import - objc - header " , bridgingheader . get ( ) ) ; <nl> + inputheaders . add ( bridgingheader . get ( ) ) ; <nl> + } <nl>  <nl> rulecontext . registeraction ( objcruleclasses . spawnondarwinactionbuilder ( ) <nl> . setmnemonic ( " swiftcompile " ) <nl>
public class blazecommandeventhandler implements eventhandler { <nl> out . write ( event . getmessagebytes ( ) ) ; <nl> out . flush ( ) ; <nl> } catch ( ioexception e ) { <nl> - / / this can happen in server mode if the blaze client has exited , <nl> - / / or if output is redirected to a file and the disk is full , etc . <nl> - <nl> - string message = " failed to write event " ; <nl> - log . log ( level . warning , message , e ) ; <nl> - loggingutil . logtoremote ( level . warning , message , e ) ; <nl> + / / this can happen in server mode if the blaze client has exited , or if output is redirected <nl> + / / to a file and the disk is full , etc . may be moot in the case of full disk , or useful in <nl> + / / the case of real bug in our handling of streams . <nl> + log . log ( level . warning , " failed to write event " , e ) ; <nl> } <nl> }
public class objcconfiguration extends buildconfiguration . fragment { <nl> " - fstack - protector " , " - fstack - protector - all " , " - d_glibcxx_debug_pedantic " , " - d_glibcxx_debug " , <nl> " - d_glibcpp_concept_checks " ) ; <nl>  <nl> - <nl> - @ visiblefortesting <nl> - static final immutablelist < string > fastbuild_copts = immutablelist . of ( " - o0 " ) ; <nl> - <nl> @ visiblefortesting <nl> static final immutablelist < string > opt_copts = <nl> immutablelist . of ( <nl>
public final class cccommon { <nl> return headerscheckingmode ; <nl> } <nl>  <nl> - / * * <nl> - * expand and tokenize the copts and nocopts attributes . <nl> - * / <nl> - private immutablelist < string > initcopts ( ) { <nl> - if ( ! hasattribute ( " copts " , type . string_list ) ) { <nl> - return immutablelist . < string > of ( ) ; <nl> - } <nl> - <nl> - / / make a warning for now . <nl> - list < string > tokens = new arraylist < > ( ) ; <nl> - for ( string str : rulecontext . attributes ( ) . get ( " copts " , type . string_list ) ) { <nl> - tokens . clear ( ) ; <nl> - try { <nl> - shellutils . tokenize ( tokens , str ) ; <nl> - if ( tokens . size ( ) > num ) { <nl> - rulecontext . attributewarning ( " copts " , <nl> - " each item in the list should contain only one option " ) ; <nl> - } <nl> - } catch ( shellutils . tokenizationexception e ) { <nl> - / / ignore , the error is reported in the getattributecopts call <nl> - } <nl> - } <nl> - <nl> - pattern nocopts = getnocopts ( rulecontext ) ; <nl> - if ( nocopts ! = null & & nocopts . matcher ( " - wno - future - warnings " ) . matches ( ) ) { <nl> - rulecontext . attributewarning ( " nocopts " , <nl> - " regular expression ' " + nocopts . pattern ( ) + " ' is too general ; for example , it matches " <nl> - + " ' - wno - future - warnings ' . thus it might * re - enable * compiler warnings we wish to " <nl> - + " disable globally . to disable all compiler warnings , add ' - w ' to copts instead " ) ; <nl> - } <nl> - <nl> - return immutablelist . < string > builder ( ) <nl> - . addall ( getpackagecopts ( rulecontext ) ) <nl> - . addall ( cpphelper . getattributecopts ( rulecontext , " copts " ) ) <nl> - . build ( ) ; <nl> - } <nl> - <nl> private static immutablelist < string > getpackagecopts ( rulecontext rulecontext ) { <nl> list < string > unexpanded = rulecontext . getrule ( ) . getpackage ( ) . getdefaultcopts ( ) ; <nl> return immutablelist . copyof ( cpphelper . expandmakevariables ( rulecontext , " copts " , unexpanded ) ) ;
public class xcodeprojgeneration { <nl> } <nl> } <nl>  <nl> - <nl> - / / xcodegen pre - processed . <nl> - private static string labeltoxcodetargetname ( string label ) { <nl> - string pathfromworkspaceroot = label . replace ( " / / " , " " ) . replace ( ' : ' , ' / ' ) ; <nl> - list < string > components = splitter . on ( ' / ' ) . splittolist ( pathfromworkspaceroot ) ; <nl> - return joiner . on ( ' _ ' ) . join ( lists . reverse ( components ) ) ; <nl> - } <nl> - <nl> private static nsdictionary nonarccompilesettings ( ) { <nl> nsdictionary result = new nsdictionary ( ) ; <nl> result . put ( " compiler_flags " , " - fno - objc - arc " ) ; <nl>
public abstract class implicitoutputsfunction { <nl> public immutablemap < string , string > calculateoutputs ( attributemap map ) throws evalexception { <nl> map < string , object > attrvalues = new hashmap < > ( ) ; <nl> for ( string attrname : map . getattributenames ( ) ) { <nl> - <nl> - / / pass on to the child outputs function ? maybe implicit output functions shouldn ' t <nl> - / / have access to configurable values ( makes them too complicated ? ) . maybe they <nl> - / / should have * full * access ( gives them the most power ? ) . <nl> - object value = map . get ( attrname , map . getattributetype ( attrname ) ) ; <nl> - attrvalues . put ( attrname , value = = null ? environment . none : value ) ; <nl> + type < ? > attrtype = map . getattributetype ( attrname ) ; <nl> + / / don ' t include configurable attributes : we don ' t know which value they might take <nl> + / / since we don ' t yet have a build configuration . <nl> + if ( ! map . isconfigurable ( attrname , attrtype ) ) { <nl> + object value = map . get ( attrname , attrtype ) ; <nl> + attrvalues . put ( attrname , value = = null ? environment . none : value ) ; <nl> + } <nl> } <nl> - classobject attrs = new skylarkclassobject ( attrvalues , " no such attribute ' % s ' " ) ; <nl> + classobject attrs = new skylarkclassobject ( attrvalues , " attribute ' % s ' either doesn ' t exist " <nl> + + " or uses a select ( ) ( i . e . could have multiple values ) " ) ; <nl> try { <nl> immutablemap . builder < string , string > builder = immutablemap . builder ( ) ; <nl> for ( map . entry < string , string > entry : castmap ( callback . call ( attrs ) ,
import com . google . devtools . build . lib . packages . ruleclass . builder ; <nl> * rule definition for { @ code java_toolchain } <nl> * / <nl> public final class javatoolchainrule implements ruledefinition { <nl> - <nl> - private final immutablelist < string > defaultjavacjvmopts ; <nl> - <nl> - public javatoolchainrule ( ) { <nl> - defaultjavacjvmopts = immutablelist . < string > of ( " - client " ) ; <nl> - } <nl> - <nl> - / * * <nl> - * construct a { @ link javatoolchainrule } with a different set of default jvm options for javac . <nl> - * / <nl> - public javatoolchainrule ( immutablelist < string > defaultjavacjvmopts ) { <nl> - this . defaultjavacjvmopts = defaultjavacjvmopts ; <nl> - } <nl> - <nl> @ override <nl> public ruleclass build ( builder builder , ruledefinitionenvironment env ) { <nl> return builder . setundocumented ( ) <nl>
if [ - z " $ { travis_os_name + x } " ] ; then <nl> fi <nl>  <nl> if [ [ $ travis_os_name = ' osx ' ] ] ; then <nl> - # <nl> - true <nl> + export java_version = 1 . 7 <nl> + sed - i . bak ' s / _version = " 8 " , / _version = " 7 " , / ' tools / jdk / build <nl> + cat . travis / jdk7 . workspace > workspace <nl> + # ignore zip tests as they requires to much space and jdk8 stuff <nl> + cat < < ' eof ' > . bazelrc <nl> + build - - test_tag_filters - zip , - jdk8 <nl> + eof <nl> + export bazelrc = $ pwd / . bazelrc <nl> + . / compile . sh all <nl> else <nl> sudo apt - get update - qq <nl> sudo apt - get install - y netcat - traditional <nl> mmm a / compile . sh <nl> ppp b / compile . sh <nl>
class filesystemvaluechecker { <nl> executor . execute ( wrapper . wrap ( new runnable ( ) { <nl> @ override <nl> public void run ( ) { <nl> - if ( value = = null ) { <nl> - / / value will be null if the value is in error or part of a cycle . <nl> - <nl> - batchresult . add ( key , / * newvalue = * / null ) ; <nl> - return ; <nl> - } <nl> - dirtyresult result = checker . check ( key , value , tsgm ) ; <nl> - if ( result . isdirty ( ) ) { <nl> - batchresult . add ( key , result . getnewvalue ( ) ) ; <nl> + if ( value ! = null ) { <nl> + dirtyresult result = checker . check ( key , value , tsgm ) ; <nl> + if ( result . isdirty ( ) ) { <nl> + batchresult . add ( key , result . getnewvalue ( ) ) ; <nl> + } <nl> } <nl> } <nl> } ) ) ;
public class constraintsemantics { <nl> dep = ( ( outputfileconfiguredtarget ) dep ) . getgeneratingrule ( ) ; <nl> } <nl> / / input files don ' t support environments . we may subsequently opt them into constraint <nl> - / / checking , but for now just pass them by . otherwise , we opt in anything that ' s not <nl> - / / a host dependency . <nl> - <nl> - if ( dep . getprovider ( supportedenvironmentsprovider . class ) ! = null <nl> - & & ! verify . verifynotnull ( dep . getconfiguration ( ) ) . ishostconfiguration ( ) ) { <nl> + / / checking , but for now just pass them by . <nl> + if ( dep . getprovider ( supportedenvironmentsprovider . class ) ! = null ) { <nl> depstocheck . add ( dep ) ; <nl> } <nl> } <nl> mmm a / src / test / java / com / google / devtools / build / lib / analysis / constraints / constraintstest . java <nl> ppp b / src / test / java / com / google / devtools / build / lib / analysis / constraints / constraintstest . java <nl>
public class runfilessupplierimpl implements runfilessupplier { <nl> public iterable < artifact > getartifacts ( ) { <nl> immutableset . builder < artifact > builder = immutableset . builder ( ) ; <nl> for ( entry < pathfragment , runfiles > entry : inputrunfiles . entryset ( ) ) { <nl> - <nl> - / / the runfiles level . <nl> - builder . addall ( entry . getvalue ( ) . getallartifacts ( ) ) ; <nl> + builder . addall ( <nl> + iterables . filter ( entry . getvalue ( ) . getallartifacts ( ) , artifact . middleman_filter ) ) ; <nl> } <nl> return builder . build ( ) ; <nl> } <nl> mmm a / src / test / java / com / google / devtools / build / lib / analysis / runfilessupplierimpltest . java <nl> ppp b / src / test / java / com / google / devtools / build / lib / analysis / runfilessupplierimpltest . java <nl>
ide_output_path = " bazel - out / ide - classes " <nl>  <nl> # source roots . <nl> java_paths = " $ ( find src - name " * . java " | sed " s | / com / google / . * $ | | " | sort - u ) " <nl> - # <nl> - # if [ " $ ( uname - s | tr ' a - z ' ' a - z ' ) " ! = " darwin " ] ; then <nl> - java_paths = " $ ( echo " $ { java_paths } " | fgrep - v " / objc_tools / " ) " <nl> - # fi <nl> + if [ " $ ( uname - s | tr ' a - z ' ' a - z ' ) " ! = " darwin " ] ; then <nl> + java_paths = " $ ( echo " $ { java_paths } " | fgrep - v " / objc_tools / " ) " <nl> + fi <nl> # android doesn ' t work out of the box , but should we tell users to install the <nl> # android sdk ? <nl> java_paths = " $ ( echo " $ { java_paths } " | fgrep - v " / android / " ) "
public abstract class skylarktype { <nl> } <nl> } <nl>  <nl> - boolean isstruct ( ) { <nl> - return classobject . class . isassignablefrom ( gettype ( ) ) ; <nl> - } <nl> - <nl> - boolean islist ( ) { <nl> - return skylarklist . class . isassignablefrom ( gettype ( ) ) ; <nl> - } <nl> - <nl> - boolean isdict ( ) { <nl> - return map . class . isassignablefrom ( gettype ( ) ) ; <nl> - } <nl> - <nl> - boolean isset ( ) { <nl> - return set . class . isassignablefrom ( gettype ( ) ) ; <nl> - } <nl> - <nl> - boolean isnset ( ) { <nl> - <nl> - / / and execution time ) . that can be cleaned up once we have complete type inference . <nl> - return skylarknestedset . class . isassignablefrom ( gettype ( ) ) ; <nl> - } <nl> - <nl> private static boolean istypeallowedinskylark ( object object ) { <nl> if ( object instanceof nestedset < ? > ) { <nl> return false ;
public class namespacesandboxrunner { <nl> files . copy ( new file ( this . embeddedbinaries . getchild ( " build - runfiles " ) . getpathstring ( ) ) , <nl> new file ( bin . getchild ( " build - runfiles " ) . getpathstring ( ) ) ) ; <nl> filesystemutils . chmod ( bin . getchild ( " build - runfiles " ) . getpathstring ( ) , num ) ; <nl> - <nl> - / / some of the tools could be in inputs ; we will mount entire tools anyway so it ' s just <nl> - / / easier to remove them and remount inside sandbox <nl> - filesystemutils . rmtree ( sandboxpath . getchild ( " tools " ) . getpathstring ( ) ) ; <nl> } <nl>  <nl>  <nl>
public final class selectorlist { <nl> return ( ( selectorvalue ) value ) . gettype ( ) ; <nl> } else if ( value instanceof globlist ) { <nl> builder . add ( ( ( globlist < ? > ) value ) . delegate ( ) ) ; <nl> - <nl> - / / we verify this is the right class through test coverage . <nl> - return arraylist . class ; <nl> + return native_list_type ; <nl> } else { <nl> builder . add ( value ) ; <nl> return value . getclass ( ) ; <nl> } <nl> } <nl>  <nl> + private static boolean islisttype ( class < ? > type ) { <nl> + return type = = native_list_type | | type . getsuperclass ( ) = = skylarklist . class ; <nl> + } <nl> + <nl> + private static boolean canconcatenate ( class < ? > type1 , class < ? > type2 ) { <nl> + if ( type1 = = type2 ) { <nl> + return true ; <nl> + } else if ( islisttype ( type1 ) & & islisttype ( type2 ) ) { <nl> + return true ; <nl> + } else { <nl> + return false ; <nl> + } <nl> + } <nl> + <nl> @ override <nl> public string tostring ( ) { <nl> return joiner . on ( " + " ) . join ( elements ) ; <nl> mmm a / src / test / java / com / google / devtools / build / lib / syntax / evaluationtest . java <nl> ppp b / src / test / java / com / google / devtools / build / lib / syntax / evaluationtest . java <nl>
if [ [ " $ ( uname ) " ! = darwin ] ] ; then <nl> exit num <nl> fi <nl>  <nl> - # <nl> - readonly sdk_version = ' 8 . 1 ' <nl> - readonly sim_device = ' iphone num ' <nl> + readonly sdk_version = " % sdk_version % " <nl> + readonly sim_device = " % sim_device % " <nl> readonly app_dir = $ ( mktemp - d - t extracted_app ) <nl>  <nl> args = ( )
if [ [ " $ ( uname ) " ! = darwin ] ] ; then <nl> exit num <nl> fi <nl>  <nl> - # <nl> - readonly sdk_version = ' 8 . 1 ' <nl> - readonly sim_device = ' iphone num ' <nl> + readonly sdk_version = " % sdk_version % " <nl> + readonly sim_device = " % sim_device % " <nl> readonly app_dir = $ ( mktemp - d - t extracted_app ) <nl>  <nl> args = ( )
public final class dependencymodule { <nl>  <nl> / * * <nl> * updates { @ link # requiredclasspath } to include dependencies from the given output artifact . <nl> - * <nl> - * during the . deps migration from text to proto format , this method will try to handle both . <nl> - * blaze can thus switch the . deps artifacts independently . <nl> * / <nl> - private void collectdependenciesfromartifact ( string path ) { <nl> - / / try reading in proto format first <nl> + private void collectdependenciesfromartifact ( string path ) throws ioexception { <nl> try ( bufferedinputstream bis = new bufferedinputstream ( new fileinputstream ( path ) ) ) { <nl> deps . dependencies deps = deps . dependencies . parsefrom ( bis ) ; <nl> - / / sanity check to make sure we have a valid proto , not a text file that happened to match . <nl> + / / sanity check to make sure we have a valid proto . <nl> if ( ! deps . hasrulelabel ( ) ) { <nl> - throw new ioexception ( " text file " ) ; <nl> + throw new ioexception ( " could not parse deps . dependencies message from proto . " ) ; <nl> } <nl> for ( deps . dependency dep : deps . getdependencylist ( ) ) { <nl> if ( dep . getkind ( ) = = kind . explicit | | dep . getkind ( ) = = kind . implicit ) { <nl> requiredclasspath . add ( dep . getpath ( ) ) ; <nl> } <nl> } <nl> - } catch ( ioexception ex ) { <nl> - <nl> - try ( bufferedreader reader = new bufferedreader ( new filereader ( path ) ) ) { <nl> - for ( string dep = reader . readline ( ) ; dep ! = null ; dep = reader . readline ( ) ) { <nl> - requiredclasspath . add ( dep ) ; <nl> - } <nl> - } catch ( ioexception exc ) { <nl> - / / at this point we can give up altogether <nl> - exc . printstacktrace ( ) ; <nl> - } <nl> } <nl> }
public final class skyframeactionexecutor { <nl> actionexecutioncontext constructactionexecutioncontext ( <nl> peractionfilecache graphfilecache , metadatahandler metadatahandler , <nl> map < artifact , collection < artifact > > expandedinputmiddlemen ) { <nl> - <nl> fileouterr fileouterr = actionlogbufferpathgenerator . generate ( ) ; <nl> return new actionexecutioncontext ( <nl> executorengine , <nl> mmm a / src / main / java / com / google / devtools / build / lib / util / io / fileouterr . java <nl> ppp b / src / main / java / com / google / devtools / build / lib / util / io / fileouterr . java <nl>
function create_zip ( ) { <nl> local bazel_dir <nl> bazel_dir = bazel - $ git_hash <nl> mkdir $ bazel_dir <nl> - # <nl> - # . / compile . sh . once bazel can bootstrap itself on travis , change this to <nl> - # upload the bootstrapped binary , instead . <nl> - cp output / bazel $ bazel_dir <nl> + cp bazel - bin / src / bazel $ bazel_dir <nl> sha256sum $ bazel_dir / bazel > $ bazel_dir / sha256 . txt <nl> cat > $ bazel_dir / readme . md < < eof <nl> bazel binary built by travis ci
final class configuredtargetfunction implements skyfunction { <nl> boolean ok = ! env . valuesmissing ( ) ; <nl> string message = null ; <nl> iterable < skykey > depkeys = iterables . transform ( deps , to_keys ) ; <nl> - <nl> - / / exception here . <nl> map < skykey , valueorexception2 < nosuchtargetexception , <nl> nosuchpackageexception > > depvaluesorexceptions = env . getvaluesorthrow ( depkeys , <nl> nosuchtargetexception . class , nosuchpackageexception . class ) ;
string makeabsolute ( string path ) { <nl> return cwdbuf + separator + path ; <nl> } <nl>  <nl> - / / mkdir - p path . returns - 1 on failure , sets errno . <nl> - int makedirectories ( string path , int mode ) { <nl> - path . push_back ( ' \ 0 ' ) ; <nl> - char * buf = & path [ 0 ] ; <nl> - for ( char * slash = strchr ( buf + num , ' / ' ) ; slash ! = null ; <nl> - slash = strchr ( slash + num , ' / ' ) ) { <nl> - * slash = ' \ 0 ' ; <nl> - if ( mkdir ( buf , mode ) = = - 1 & & errno ! = eexist ) { <nl> + static int makedirectories_ ( string path , int mode , bool childmost ) { <nl> + if ( path . empty ( ) | | path = = " / " ) { <nl> + errno = eacces ; <nl> + return - 1 ; <nl> + } <nl> + <nl> + struct stat filestat = { } ; <nl> + if ( stat ( path . c_str ( ) , & filestat ) = = num ) { <nl> + if ( s_isdir ( filestat . st_mode ) ) { <nl> + / / only check permissions if this is the actual directory we ' re trying to <nl> + / / create . <nl> + if ( childmost ) { <nl> + / / if this is a symlink , run checks on the link . ( if we did lstat above <nl> + / / then it would return false for isdir ) . <nl> + struct stat linkstat = { } ; <nl> + if ( lstat ( path . c_str ( ) , & linkstat ) ! = num ) { <nl> + return - 1 ; <nl> + } <nl> + if ( linkstat . st_uid ! = geteuid ( ) ) { <nl> + / / the directory isn ' t owned by me . <nl> + errno = eacces ; <nl> + return - 1 ; <nl> + } <nl> + if ( ( filestat . st_mode & num ) ! = mode <nl> + & & chmod ( path . c_str ( ) , mode ) = = - 1 ) { <nl> + / / errno set by chmod . <nl> + return - 1 ; <nl> + } <nl> + } <nl> + return num ; <nl> + } else { <nl> + errno = enotdir ; <nl> return - 1 ; <nl> } <nl> - * slash = ' / ' ; <nl> } <nl> - <nl> - if ( mkdir ( buf , mode ) = = - 1 & & errno ! = eexist ) { <nl> - return - 1 ; <nl> + <nl> + if ( errno = = enoent ) { <nl> + / / path does not exist , attempt to create its parents , then it . <nl> + string parent = blaze_util : : dirname ( path ) ; <nl> + if ( makedirectories_ ( parent , mode , false ) = = num <nl> + & & mkdir ( path . c_str ( ) , mode ) = = num ) { <nl> + return num ; <nl> + } <nl> } <nl> - return num ; <nl> + <nl> + / / errno set by stat . <nl> + return - 1 ; <nl> + } <nl> + <nl> + / / mkdir - p path . returns num if the path was created or already exists and could <nl> + / / be chmod - ed to exactly the given permissions . if final part of the path is a <nl> + / / symlink , this ensures that the destination of the symlink has the desired <nl> + / / permissions . it also checks that the directory or symlink is owned by us . <nl> + / / on failure , this returns - 1 and sets errno . <nl> + int makedirectories ( string path , int mode ) { <nl> + return makedirectories_ ( path , mode , true ) ; <nl> } <nl>  <nl> / / replaces ' contents ' with contents of ' fd ' file descriptor .
public class skylarkruleimplementationfunctions { <nl> immutablemap . copyof ( ( map < label , iterable < artifact > > ) params . get ( " label_dict " ) ) ) ; <nl> } <nl> } ; <nl> - <nl> - / / deprecated function . <nl> - / / use the new ctx . var field , which is a dictionary . <nl> - <nl> - @ skylarkbuiltin ( name = " var " , <nl> - doc = " get the value bound to a configuration variable in the context " , <nl> - hidden = true , <nl> - objecttype = skylarkrulecontext . class , <nl> - mandatoryparams = { <nl> - @ param ( name = " name " , type = string . class , doc = " the name of the variable " ) <nl> - } , <nl> - returntype = string . class ) <nl> - private static final skylarkfunction configurationmakevariablecontext = <nl> - new simpleskylarkfunction ( " var " ) { <nl> - @ suppresswarnings ( " unchecked " ) <nl> - @ override <nl> - protected object call ( map < string , object > params , location loc ) <nl> - throws conversionexception , evalexception { <nl> - skylarkrulecontext ctx = ( skylarkrulecontext ) params . get ( " self " ) ; <nl> - string name = ( string ) params . get ( " name " ) ; <nl> - try { <nl> - return ctx . getrulecontext ( ) . getconfigurationmakevariablecontext ( ) <nl> - . lookupmakevariable ( name ) ; <nl> - } catch ( makevariableexpander . expansionexception e ) { <nl> - throw new evalexception ( loc , " configuration variable " <nl> - + shellescaper . escapestring ( name ) + " not defined " ) ; <nl> - } <nl> - } <nl> - } ; <nl> }
<nl> # ifndef macros_h__ <nl> # define macros_h__ <nl>  <nl> - <nl> + / / gcc - 4 . 7 and clang - 3 . 1 ( 2011 - 12 - 13 ) . __cplusplus was defined to num <nl> + / / in gcc before num . 7 and clang before num . 1 , but is defined according <nl> + / / to the language version in effect thereafter . <nl> + # if defined ( __gxx_experimental_cxx0x__ ) | | __cplusplus > = num l <nl> + / / when compiled with clang c + + 11 standard with warning on switch <nl> + / / fallthrough , tell the compiler not to complain when it was intended . <nl> + # if defined ( __clang__ ) & & defined ( __has_warning ) <nl> + # if __has_feature ( cxx_attributes ) & & __has_warning ( " - wimplicit - fallthrough " ) <nl> + # define fallthrough_intended [ [ clang : : fallthrough ] ] / / nolint <nl> + # endif <nl> + # endif <nl> + # endif <nl> + <nl> + <nl> + # ifndef fallthrough_intended <nl> # define fallthrough_intended do { } while ( 0 ) <nl> + # endif <nl>  <nl> # endif / / macros_h__
<nl> # only supports java . <nl>  <nl>  <nl> - # <nl> - # file . <nl> jar_filetype = filetype ( [ " . jar " ] ) <nl>  <nl> proto_filetype = filetype ( [ " . proto " ] ) <nl>  <nl> + def java_compile_command ( ctx , classdir , classpath , output ) : <nl> + java = ctx . file . _java . path <nl> + langtools = ctx . file . _java_langtools . path <nl> + javabuilder = ctx . file . _javabuilder . path <nl> + return ( " % s - xbootclasspath / p : % s - jar % s " % ( java , langtools , javabuilder ) + <nl> + " - - classdir % s - - classpath % s " % ( classdir , classpath ) + <nl> + " - - output % s " % ( output ) + <nl> + " - - javacopts - source num . 8 - target num . 8 - - compress_jar - - sources $ { java_files } " ) <nl> + <nl> def genproto_impl ( ctx ) : <nl> src = ctx . file . src <nl> proto_compiler = ctx . file . _proto_compiler <nl>
uses : <nl> * ijar is a tool to extracts the class interfaces of jars and is a third <nl> party software at ` / / third_party / ijar ` . <nl> * for objective - c / ios support <nl> - * <nl> + * actoolzip is a utility that runs os x ' s actool and zips up its output for <nl> + further processing . it is currently compiled and placed into ` tools / objc / ` <nl> + by ` compile . sh ` . <nl> + * ibtoolzip is a utility that runs os x ' s ibtool and zips up its output for <nl> + further processing . it is currently compiled and placed into ` tools / objc / ` <nl> + by ` compile . sh ` . <nl> + * momczip is a utility that runs os x ' s momc and zips up its output for <nl> + further processing . it is currently compiled and placed into ` tools / objc / ` <nl> + by ` compile . sh ` . <nl> + * bundlemerge is a tool that can construct ios bundles ( such as . ipa files or <nl> + . bndl directories ) , including plist merging and zip creation . it is currently <nl> + compiled and placed into ` tools / objc / ` by ` compile . sh ` . <nl> + * plmerge is a tool used for merging plists . it is currently compiled and <nl> + placed into ` tools / objc / ` by ` compile . sh ` . <nl> + * xcodegen is a tool that assembles an xcode project file matching bazel build <nl> + targets . it is currently compiled and placed into ` tools / objc / ` by <nl> + ` compile . sh ` . <nl> + * iossim allows us to run ios applications built by bazel on xcode ' s ios <nl> + simulator and is third party software located at ` / / third_party / iossim ` <nl>  <nl> when modifying bazel , you want to make sure that the following still works :
public class objcprotolibraryrule implements ruledefinition { <nl> $ { synopsis } <nl> < ! - - # end_blaze_rule . attribute - - > * / <nl> . add ( attr ( output_cpp_attr , boolean ) . value ( false ) ) <nl> - <nl> . add ( attr ( libprotobuf_attr , label ) . allowedruleclasses ( " objc_library " ) <nl> . value ( env . getlabel ( <nl> - " / / googlemac / thirdparty / protocolbuffers2 / objectivec : protocolbuffers_lib " ) ) ) <nl> + " / / external : objc_proto_lib " ) ) ) <nl> . add ( attr ( " $ xcodegen " , label ) . cfg ( host ) . exec ( ) <nl> . value ( env . getlabel ( " / / tools / objc : xcodegen " ) ) ) <nl> . build ( ) ; <nl> mmm a / src / test / java / com / google / devtools / build / lib / packages / util / mocktoolsconfig . java <nl> ppp b / src / test / java / com / google / devtools / build / lib / packages / util / mocktoolsconfig . java <nl>
should also hold for our open - source codebase . <nl> how can i start using bazel ? <nl> - - - - - - - - - - - - - - - - - - - - - - - - - - - - <nl>  <nl> - see our [ getting started doc ] ( getting - started . md ) <nl> - <nl> - <nl> + see our [ getting started document ] ( getting - started . md ) . <nl>  <nl>  <nl> why do i need to have a tools / directory in my source tree ? <nl>
will need to take some extra care : <nl> * avoid processes that use random numbers , in particular , dictionary <nl> traversal is randomized in many programming languages . <nl>  <nl> - <nl> - instead , or the genrule docs ? <nl> - <nl>  <nl> do you have binary releases ? <nl> - - - - - - - - - - - - - - - - - - - - - - - - - - - - <nl>
fails , and this should be enough for basic ci integration . since <nl> bazel does not need clean builds for correctness , the ci system can <nl> be configured to not clean before starting a build / test run . <nl>  <nl> - <nl> + further details on exit codes are in the [ user manual ] ( docs / bazel - user - manual . html ) . <nl>  <nl> what future features can we expect in bazel ? <nl> - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - <nl> mmm a / docs / contributing . md <nl> ppp b / docs / contributing . md <nl>
<nl> building bazel on windows <nl> = = = = = = = = = = = = = = = = = = = = = = = = = <nl>  <nl> - <nl> - <nl> warning : windows support on bazel is still at a very early stage , many things <nl> will not work .
<nl> - # bind statements go here . <nl> + workspace ( name = " bazel " )
import java . util . list ; <nl> * / <nl> public class baselinecoverageaction extends abstractfilewriteaction <nl> implements notifyonactioncachehit { <nl> - <nl> - / / instrumented files . <nl> - private static final list < string > offline_instrumentation_suffixes = immutablelist . of ( <nl> - " . c " , " . cc " , " . cpp " , " . dart " , " . go " , " . h " , " . java " , " . py " ) ; <nl> + <nl> private final iterable < artifact > instrumentedfiles ; <nl>  <nl> private baselinecoverageaction ( <nl>
public class skylarkimportlookupvalue implements skyvalue { <nl> pathfragment computedpath ; <nl> if ( filetoimport . isabsolute ( ) ) { <nl> computedpath = filetoimport . torelative ( ) ; <nl> - } else if ( filetoimport . segmentcount ( ) > num ) { <nl> - <nl> - / / for a transition period . remove this after the transition is over . <nl> - computedpath = filetoimport ; <nl> - } else { <nl> + } else if ( filetoimport . segmentcount ( ) = = num ) { <nl> computedpath = fromfile . getparentdirectory ( ) . getrelative ( filetoimport ) ; <nl> + } else { <nl> + throw new astlookupinputexception ( string . format ( loadstatement . path_error_msg , filetoimport ) ) ; <nl> } <nl> return key ( repo , computedpath ) ; <nl> } <nl> mmm a / src / main / java / com / google / devtools / build / lib / syntax / loadstatement . java <nl> ppp b / src / main / java / com / google / devtools / build / lib / syntax / loadstatement . java <nl>
public class objcruleclasses { <nl> private static final iterable < string > allowed_deps_rule_classes = immutableset . of ( <nl> " objc_library " , <nl> " objc_import " , <nl> - <nl> - <nl> - " objc_bundle " , <nl> - " objc_bundle_library " , <nl> - <nl> " objc_framework " , <nl> " objc_proto_library " , <nl> " j2objc_library " ) ;
package main <nl> import ( <nl> " fmt " <nl>  <nl> - <nl> " examples / go / lib1 / lib1 " <nl> ) <nl>  <nl> mmm a / tools / build_rules / go_rules . bzl <nl> ppp b / tools / build_rules / go_rules . bzl <nl>
public class zipkinhttpconfiguration { <nl>  <nl> / / block trace requests because https : / / github . com / openzipkin / zipkin / issues / 2286 <nl> sb . routedecorator ( ) . trace ( " prefix : / " ) <nl> - . build ( ( delegate , ctx , req ) - > { <nl> - if ( req . method ( ) = = httpmethod . trace ) { <nl> - return httpresponse . of ( httpstatus . method_not_allowed ) ; <nl> - } <nl> - return delegate . serve ( ctx , req ) ; <nl> - } ) ; <nl> + . build ( ( delegate , ctx , req ) - > httpresponse . of ( httpstatus . method_not_allowed ) ) ; <nl> } ; <nl> }
<nl> < artifactid > brave < / artifactid > <nl> < optional > true < / optional > <nl> < / dependency > <nl> - < ! - - <nl> - < dependency > <nl> - < groupid > io . zipkin . reporter2 < / groupid > <nl> - < artifactid > zipkin - reporter < / artifactid > <nl> - < version > 2 . 10 . 1 < / version > <nl> - < optional > true < / optional > <nl> - < / dependency > <nl> < dependency > <nl> < groupid > io . zipkin . brave < / groupid > <nl> < artifactid > brave - context - log4j2 < / artifactid >
public class httpcalltest { <nl> } <nl> } <nl>  <nl> - <nl> - / / in other words , find actual json <nl> + / / for simplicity , we also parse messages from aws elasticsearch , as it prevents copy / paste . <nl> @ test public void executionexception_message ( ) throws exception { <nl> map < aggregatedhttpresponse , string > responsetomessage = new linkedhashmap < > ( ) ; <nl> - responsetomessage . put ( aggregatedhttpresponse . of ( <nl> - responseheaders . of ( httpstatus . unauthorized ) , <nl> - httpdata . ofutf8 ( " { \ " message \ " : \ " rain \ " } " ) <nl> - ) , " rain " ) ; <nl> responsetomessage . put ( aggregatedhttpresponse . of ( <nl> responseheaders . of ( httpstatus . forbidden ) , <nl> - httpdata . ofutf8 ( " { \ " message \ " : \ " snow \ " } " ) / / note : case of key is different <nl> - ) , " snow " ) ; <nl> + httpdata . ofutf8 ( <nl> + " { \ " message \ " : \ " user : anonymous is not authorized to perform : es : eshttpget \ " } " ) <nl> + ) , " user : anonymous is not authorized to perform : es : eshttpget " ) ; <nl> + responsetomessage . put ( aggregatedhttpresponse . of ( <nl> + responseheaders . of ( httpstatus . forbidden ) <nl> + ) , " response for / failed : num forbidden " ) ; <nl> responsetomessage . put ( aggregatedhttpresponse . of ( <nl> responseheaders . of ( httpstatus . bad_gateway ) , <nl> httpdata . ofutf8 ( " message : sleet " ) / / note : not json
<nl> < version > $ { wire . version } < / version > <nl> < / dependency > <nl> < dependency > <nl> - < groupid > io . zipkin . proto3 < / groupid > <nl> + < groupid > org . apache . zipkin . proto3 < / groupid > <nl> < artifactid > zipkin - proto3 < / artifactid > <nl> < / dependency > <nl> - < ! - - <nl> - < dependency > <nl> - < groupid > com . google . protobuf < / groupid > <nl> - < artifactid > protobuf - java < / artifactid > <nl> - < version > 3 . 7 . 1 < / version > <nl> - < scope > test < / scope > <nl> - < exclusions > <nl> - < exclusion > <nl> - < groupid > * < / groupid > <nl> - < artifactid > * < / artifactid > <nl> - < / exclusion > <nl> - < / exclusions > <nl> - < / dependency > <nl> < / dependencies > <nl>  <nl> < build > <nl> mmm a / pom . xml <nl> ppp b / pom . xml <nl>
<nl> < goal > unpack - dependencies < / goal > <nl> < / goals > <nl> < configuration > <nl> - < ! - - <nl> - < includeartifactids > protobuf - java , zipkin - proto3 < / includeartifactids > <nl> + < includeartifactids > zipkin - proto3 < / includeartifactids > <nl> < includes > * * / * . proto < / includes > <nl> < outputdirectory > $ { unpack - proto . directory } < / outputdirectory > <nl> < / configuration > <nl>
<nl> < configuration > <nl> < protosourcedirectory > $ { unpack - proto . directory } < / protosourcedirectory > <nl> < includes > <nl> - < ! - - <nl> - < include > google . protobuf . empty < / include > <nl> < include > zipkin . proto3 . * < / include > <nl> < / includes > <nl> < / configuration > <nl> mmm a / zipkin - server / pom . xml <nl> ppp b / zipkin - server / pom . xml <nl>
<nl>  <nl> < ! - - to test the experimental grpc endpoint with the square / wire library - - > <nl> < dependency > <nl> - < groupid > io . zipkin . proto3 < / groupid > <nl> + < groupid > org . apache . zipkin . proto3 < / groupid > <nl> < artifactid > zipkin - proto3 < / artifactid > <nl> < scope > test < / scope > <nl> < / dependency > <nl> - < ! - - <nl> - < dependency > <nl> - < groupid > com . google . protobuf < / groupid > <nl> - < artifactid > protobuf - java < / artifactid > <nl> - < version > 3 . 7 . 1 < / version > <nl> - < scope > test < / scope > <nl> - < exclusions > <nl> - < exclusion > <nl> - < groupid > * < / groupid > <nl> - < artifactid > * < / artifactid > <nl> - < / exclusion > <nl> - < / exclusions > <nl> - < / dependency > <nl> < dependency > <nl> < groupid > com . squareup . wire < / groupid > <nl> < artifactid > wire - grpc - client < / artifactid > <nl> mmm a / zipkin - server / src / test / kotlin / zipkin2 / server / internal / itzipkingrpccollector . kt <nl> ppp b / zipkin - server / src / test / kotlin / zipkin2 / server / internal / itzipkingrpccollector . kt <nl>
export default component ( function spanpanel ( ) { <nl> } <nl> $ row . find ( ' td ' ) . each ( function ( ) { <nl> const $ this = $ ( this ) ; <nl> - const maybeobject = anno [ $ this . data ( ' key ' ) ] ; <nl> - / / in case someone is storing escaped json as an annotation value <nl> - <nl> - $ this . text ( $ . type ( maybeobject ) = = = ' object ' ? json . stringify ( maybeobject ) : maybeobject ) ; <nl> + const unformattedvalue = anno [ $ this . data ( ' key ' ) ] ; <nl> + const value = formatannotationvalue ( unformattedvalue ) ; <nl> + $ this . append ( value ) ; <nl> } ) ; <nl> $ annobody . append ( $ row ) ; <nl> } ) ; <nl>
export default component ( function spanpanel ( ) { <nl> } <nl> $ row . find ( ' td ' ) . each ( function ( ) { <nl> const $ this = $ ( this ) ; <nl> - const maybeobject = anno [ $ this . data ( ' key ' ) ] ; <nl> - / / in case someone is storing escaped json as binary annotation values <nl> - <nl> - const type = $ . type ( maybeobject ) ; <nl> - if ( type = = = ' object ' | | type = = = ' array ' ) { <nl> - $ this . append ( ` < pre > $ { json . stringify ( maybeobject , null , num ) } < / pre > ` ) ; <nl> - } else { <nl> - $ this . text ( maybeobject ) ; <nl> - } <nl> + const unformattedvalue = anno [ $ this . data ( ' key ' ) ] ; <nl> + const value = formatbinaryannotationvalue ( unformattedvalue ) ; <nl> + $ this . append ( value ) ; <nl> } ) ; <nl> $ binannobody . append ( $ row ) ; <nl> } ) ; <nl> mmm / dev / null <nl> ppp b / zipkin - ui / test / component_ui / spanpanel . test . js <nl>
before_install : <nl> - mysql - uroot - e ' set global innodb_file_format = barracuda ' <nl> - mysql - uroot - e ' create database if not exists zipkin ' <nl> - mysql - uroot - dzipkin < zipkin - storage / mysql / src / main / resources / mysql . sql <nl> - # <nl> - # once tag - driven automation is setup , these parameters will be used by travis . <nl> + # parameters used during a release <nl> - git config user . name " $ gh_user " <nl> - git config user . email " $ gh_user_email " <nl> # setup https authentication credentials , used by . / mvnw release : prepare <nl> mmm a / release . md <nl> ppp b / release . md <nl>
public final class tracedsession implements invocationhandler , latencytracker { <nl> return method . invoke ( target , args ) ; <nl> } <nl>  <nl> - / * * <nl> - * injects propagation info to the { @ link boundstatement # setoutgoingpayload ( map ) statement ' s <nl> - * outgoing payload } . { @ code org . apache . cassandra . tracing . tracing . newsession ( sessionid , <nl> - * custompayload ) } must be able to extract this format . <nl> - * / <nl> - void inject ( spanid spanid , boundstatement statement ) { <nl> - <nl> - } <nl> - <nl> @ override public void update ( host host , statement statement , exception e , long nanos ) { <nl> span span = null ; <nl> synchronized ( cache ) { <nl> mmm a / zipkin - server / src / main / resources / zipkin - server . yml <nl> ppp b / zipkin - server / src / main / resources / zipkin - server . yml <nl>
final class elasticsearchspanstore implements guavaspanstore { <nl> searchrequestbuilder elasticrequest = client . preparesearch ( indices ) <nl> . setindicesoptions ( indicesoptions . lenientexpandopen ( ) ) <nl> . settypes ( elasticsearchconstants . span ) <nl> - <nl> - / / need to determine whether this is enough by zipkin standards or should <nl> - / / increase it in the <nl> - . setsize ( 10000 ) <nl> + . setsize ( max_raw_spans ) <nl> . setquery ( termsquery ( " traceid " , traceidsstr ) ) ; <nl> return futures . transform ( toguava ( elasticrequest . execute ( ) ) , converttracesresponse . instance ) ; <nl> } <nl> mmm a / zipkin / src / test / java / zipkin / spanstoretest . java <nl> ppp b / zipkin / src / test / java / zipkin / spanstoretest . java <nl>
public class inmemoryscalaspanstoretest extends spanstorespec { <nl> public void clear ( ) { <nl> mem . clear ( ) ; <nl> } <nl> - <nl> - @ ignore <nl> - <nl> - @ override <nl> - public void correctsclockskew_whenspantimestampanddurationarederivedfromannotations ( ) { <nl> - } <nl> } <nl> mmm a / interop / src / test / java / zipkin / jdbc / jdbcscalaspanstoretest . java <nl> ppp b / interop / src / test / java / zipkin / jdbc / jdbcscalaspanstoretest . java <nl>
public class jdbcscalaspanstoretest extends spanstorespec { <nl> throw new assertionerror ( e ) ; <nl> } <nl> } <nl> - <nl> - @ ignore <nl> - <nl> - @ override <nl> - public void correctsclockskew_whenspantimestampanddurationarederivedfromannotations ( ) { <nl> - } <nl> }
<nl> < groupid > io . zipkin < / groupid > <nl> < artifactid > zipkin - common < / artifactid > <nl> < classifier > test < / classifier > <nl> - < ! - - <nl> - < version > 1 . 18 . 2 - snapshot < / version > <nl> + < version > $ { zipkin - scala . version } < / version > <nl> < scope > test < / scope > <nl> < / dependency > <nl>  <nl> mmm a / zipkin - java - server / dockerfile <nl> ppp b / zipkin - java - server / dockerfile <nl>
<nl> * or implied . see the license for the specific language governing permissions and limitations under <nl> * the license . <nl> * / <nl> - <nl> package io . zipkin . server . brave ; <nl>  <nl> import com . github . kristofa . brave . brave ;
public class sqlstatementparser extends sqlparser { <nl> } <nl>  <nl> public sqlstatement parsecommit ( ) { <nl> - throw new parserexception ( " <nl> + acceptidentifier ( " commit " ) ; <nl> + return new sqlcommitstatement ( ) ; <nl> } <nl>  <nl> public sqlstatement parseshow ( ) { <nl> mmm / dev / null <nl> ppp b / src / test / java / com / alibaba / druid / bvt / sql / db2 / db2resourcetest . java <nl>
public class oraclemockpreparedstatement extends mockpreparedstatement implement <nl>  <nl> } <nl>  <nl> - @ override <nl> - public void setresultsetcache ( oracleresultsetcache arg0 ) throws sqlexception { <nl> - <nl> - <nl> - } <nl> - <nl> @ override <nl> public void setrowprefetch ( int rowprefetch ) throws sqlexception { <nl> this . rowprefetch = rowprefetch ; <nl>
public class failfasttest extends testcase { <nl> try { <nl> datasource . getconnection ( ) ; <nl> } catch ( sqlexception e ) { <nl> - <nl> - e . printstacktrace ( ) ; <nl> + errorholder . set ( e ) ; <nl> } finally { <nl> connectendlatch . countdown ( ) ; <nl> }
public class mysqlexceptionsorter implements exceptionsorter { <nl>  <nl> @ override <nl> public void configfromproperties ( properties properties ) { <nl> - <nl>  <nl> } <nl>  <nl> mmm a / src / test / java / com / alibaba / druid / bvt / pool / vendor / mysqlexceptionsortertest_oceanbase . java <nl> ppp b / src / test / java / com / alibaba / druid / bvt / pool / vendor / mysqlexceptionsortertest_oceanbase . java <nl>
public class statservlet extends httpservlet { <nl> } <nl> / / find file in jar resources path <nl> returnresourcefile ( requestpath , resp ) ; <nl> - return ; <nl> - } <nl> - <nl> - private void returnresourcefile ( string filename , httpservletresponse resp ) throws servletexception , ioexception { <nl> - printwriter out = resp . getwriter ( ) ; <nl> - <nl> - out . print ( readresourcefile ( filename ) ) ; <nl> } <nl>  <nl> private jsonarray getjsondrivers ( ) { <nl>
public class oracleexprparser extends sqlexprparser { <nl> if ( lexer . stringval ( ) . equalsignorecase ( " preceding " ) ) { <nl> lexer . nexttoken ( ) ; <nl> windowing . setexpr ( new sqlidentifierexpr ( " unbounded preceding " ) ) ; <nl> - over . setwindowing ( windowing ) ; <nl> + } else { <nl> + throw new parserexception ( " syntax error " ) ; <nl> } <nl> - throw new parserexception ( " syntax error " ) ; <nl> } <nl>  <nl> - throw new parserexception ( " <nl> + over . setwindowing ( windowing ) ; <nl> } <nl> } <nl>  <nl> mmm a / src / main / java / com / alibaba / druid / sql / dialect / oracle / visitor / oracleoutputvisitor . java <nl> ppp b / src / main / java / com / alibaba / druid / sql / dialect / oracle / visitor / oracleoutputvisitor . java <nl>
public final class maps { <nl> @ canignorereturnvalue <nl> public static < k , v > immutablemap < k , v > uniqueindex ( <nl> iterable < v > values , function < ? super v , k > keyfunction ) { <nl> - <nl> + if ( values instanceof collection ) { <nl> + return uniqueindex ( <nl> + values . iterator ( ) , <nl> + keyfunction , <nl> + immutablemap . builderwithexpectedsize ( ( ( collection < ? > ) values ) . size ( ) ) ) ; <nl> + } <nl> return uniqueindex ( values . iterator ( ) , keyfunction ) ; <nl> } <nl>  <nl>
public final class maps { <nl> @ canignorereturnvalue <nl> public static < k , v > immutablemap < k , v > uniqueindex ( <nl> iterable < v > values , function < ? super v , k > keyfunction ) { <nl> - <nl> + if ( values instanceof collection ) { <nl> + return uniqueindex ( <nl> + values . iterator ( ) , <nl> + keyfunction , <nl> + immutablemap . builderwithexpectedsize ( ( ( collection < ? > ) values ) . size ( ) ) ) ; <nl> + } <nl> return uniqueindex ( values . iterator ( ) , keyfunction ) ; <nl> } <nl>  <nl>
public final class cachebuilderspec { <nl> * <nl> * @ param cachebuilderspecification the string form <nl> * / <nl> - @ canignorereturnvalue <nl> public static cachebuilderspec parse ( string cachebuilderspecification ) { <nl> cachebuilderspec spec = new cachebuilderspec ( cachebuilderspecification ) ; <nl> if ( ! cachebuilderspecification . isempty ( ) ) { <nl> mmm a / guava / src / com / google / common / cache / cachebuilderspec . java <nl> ppp b / guava / src / com / google / common / cache / cachebuilderspec . java <nl>
public final class cachebuilderspec { <nl> * <nl> * @ param cachebuilderspecification the string form <nl> * / <nl> - @ canignorereturnvalue <nl> public static cachebuilderspec parse ( string cachebuilderspecification ) { <nl> cachebuilderspec spec = new cachebuilderspec ( cachebuilderspecification ) ; <nl> if ( ! cachebuilderspecification . isempty ( ) ) {
public interface function < f extends @ nullable object , t extends @ nullable object <nl> * @ throws nullpointerexception if { @ code input } is null and this function does not accept null <nl> * arguments <nl> * / <nl> - @ canignorereturnvalue <nl> @ parametricnullness <nl> t apply ( @ parametricnullness f input ) ; <nl>  <nl> mmm a / guava / src / com / google / common / base / function . java <nl> ppp b / guava / src / com / google / common / base / function . java <nl>
import org . checkerframework . checker . nullness . qual . nullable ; <nl> public interface function < f extends @ nullable object , t extends @ nullable object > <nl> extends java . util . function . function < f , t > { <nl> @ override <nl> - @ canignorereturnvalue <nl> @ parametricnullness <nl> t apply ( @ parametricnullness f input ) ;
import javax . annotation . checkfornull ; <nl> * @ since num . 0 <nl> * / <nl> @ beta <nl> - @ canignorereturnvalue <nl> @ gwtincompatible <nl> @ elementtypesarenonnullbydefault <nl> public class cycledetectinglockfactory { <nl> mmm a / guava / src / com / google / common / util / concurrent / cycledetectinglockfactory . java <nl> ppp b / guava / src / com / google / common / util / concurrent / cycledetectinglockfactory . java <nl>
import javax . annotation . checkfornull ; <nl> * @ since num . 0 <nl> * / <nl> @ beta <nl> - @ canignorereturnvalue <nl> @ gwtincompatible <nl> @ elementtypesarenonnullbydefault <nl> public class cycledetectinglockfactory {
import org . checkerframework . checker . nullness . qual . nullable ; <nl> * @ author isaac shum <nl> * @ since num . 0 <nl> * / <nl> - @ canignorereturnvalue <nl> @ gwtincompatible <nl> @ elementtypesarenonnullbydefault <nl> public abstract class forwardinglisteningexecutorservice extends forwardingexecutorservice <nl> mmm a / guava / src / com / google / common / util / concurrent / forwardinglisteningexecutorservice . java <nl> ppp b / guava / src / com / google / common / util / concurrent / forwardinglisteningexecutorservice . java <nl>
import org . checkerframework . checker . nullness . qual . nullable ; <nl> * @ author isaac shum <nl> * @ since num . 0 <nl> * / <nl> - @ canignorereturnvalue <nl> @ gwtincompatible <nl> @ elementtypesarenonnullbydefault <nl> public abstract class forwardinglisteningexecutorservice extends forwardingexecutorservice
public abstract class abstractiterator < t extends @ nullable object > extends unmod <nl> return null ; <nl> } <nl>  <nl> - @ canignorereturnvalue <nl> @ override <nl> public final boolean hasnext ( ) { <nl> checkstate ( state ! = state . failed ) ; <nl> mmm a / guava / src / com / google / common / collect / abstractiterator . java <nl> ppp b / guava / src / com / google / common / collect / abstractiterator . java <nl>
public abstract class abstractiterator < t extends @ nullable object > extends unmod <nl> return null ; <nl> } <nl>  <nl> - @ canignorereturnvalue <nl> @ override <nl> public final boolean hasnext ( ) { <nl> checkstate ( state ! = state . failed ) ;
import org . checkerframework . checker . nullness . qual . nullable ; <nl> * @ author kurt alfred kluever <nl> * @ since num . 0 <nl> * / <nl> - @ canignorereturnvalue <nl> @ gwtincompatible <nl> @ elementtypesarenonnullbydefault <nl> public abstract class forwardingexecutorservice extends forwardingobject <nl>
import org . checkerframework . checker . nullness . qual . nullable ; <nl> * @ author kurt alfred kluever <nl> * @ since num . 0 <nl> * / <nl> - @ canignorereturnvalue <nl> @ gwtincompatible <nl> @ elementtypesarenonnullbydefault <nl> public abstract class forwardingexecutorservice extends forwardingobject <nl>
import org . checkerframework . checker . nullness . qual . nullable ; <nl> * <nl> * @ author chris nokleberg <nl> * / <nl> - @ canignorereturnvalue <nl> @ gwtincompatible <nl> @ elementtypesarenonnullbydefault <nl> abstract class wrappingexecutorservice implements executorservice { <nl>
import org . checkerframework . checker . nullness . qual . nullable ; <nl> * <nl> * @ author luke sandberg <nl> * / <nl> - @ canignorereturnvalue <nl> @ gwtincompatible <nl> @ elementtypesarenonnullbydefault <nl> abstract class wrappingscheduledexecutorservice extends wrappingexecutorservice <nl> mmm a / guava / src / com / google / common / util / concurrent / wrappingexecutorservice . java <nl> ppp b / guava / src / com / google / common / util / concurrent / wrappingexecutorservice . java <nl>
import org . checkerframework . checker . nullness . qual . nullable ; <nl> * <nl> * @ author chris nokleberg <nl> * / <nl> - @ canignorereturnvalue <nl> @ gwtincompatible <nl> @ elementtypesarenonnullbydefault <nl> abstract class wrappingexecutorservice implements executorservice { <nl>
import org . checkerframework . checker . nullness . qual . nullable ; <nl> * <nl> * @ author luke sandberg <nl> * / <nl> - @ canignorereturnvalue <nl> @ gwtincompatible <nl> @ elementtypesarenonnullbydefault <nl> abstract class wrappingscheduledexecutorservice extends wrappingexecutorservice
import org . checkerframework . checker . nullness . qual . nullable ; <nl> * @ author sven mawson <nl> * @ since num . 0 <nl> * / <nl> - @ canignorereturnvalue <nl> @ gwtcompatible <nl> @ elementtypesarenonnullbydefault <nl> public abstract class forwardingfuture < v extends @ nullable object > extends forwardingobject <nl>
import org . checkerframework . checker . nullness . qual . nullable ; <nl> * @ author sven mawson <nl> * @ since num . 0 <nl> * / <nl> - @ canignorereturnvalue <nl> @ gwtcompatible <nl> @ elementtypesarenonnullbydefault <nl> public abstract class forwardingfuture < v extends @ nullable object > extends forwardingobject <nl>
import org . checkerframework . checker . nullness . qual . nullable ; <nl> * @ author shardul deo <nl> * @ since num . 0 <nl> * / <nl> - @ canignorereturnvalue <nl> @ gwtcompatible <nl> @ elementtypesarenonnullbydefault <nl> public abstract class forwardinglistenablefuture < v extends @ nullable object > <nl> mmm a / guava / src / com / google / common / util / concurrent / forwardinglistenablefuture . java <nl> ppp b / guava / src / com / google / common / util / concurrent / forwardinglistenablefuture . java <nl>
import org . checkerframework . checker . nullness . qual . nullable ; <nl> * @ author shardul deo <nl> * @ since num . 0 <nl> * / <nl> - @ canignorereturnvalue <nl> @ gwtcompatible <nl> @ elementtypesarenonnullbydefault <nl> public abstract class forwardinglistenablefuture < v extends @ nullable object >
public abstract class ordering < t extends @ nullable object > implements comparator <nl>  <nl> / / regular instance methods <nl>  <nl> - @ canignorereturnvalue <nl> @ override <nl> public abstract int compare ( @ parametricnullness t left , @ parametricnullness t right ) ; <nl>  <nl> mmm a / guava / src / com / google / common / collect / ordering . java <nl> ppp b / guava / src / com / google / common / collect / ordering . java <nl>
public abstract class ordering < t extends @ nullable object > implements comparator <nl>  <nl> / / regular instance methods <nl>  <nl> - @ canignorereturnvalue <nl> @ override <nl> public abstract int compare ( @ parametricnullness t left , @ parametricnullness t right ) ;
public final class uninterruptibles { <nl> * invokes { @ code latch . } { @ link countdownlatch # await ( long , timeunit ) await ( timeout , unit ) } <nl> * uninterruptibly . <nl> * / <nl> - @ canignorereturnvalue <nl> @ gwtincompatible / / concurrency <nl> @ suppresswarnings ( " goodtime " ) / / should accept a java . time . duration <nl> public static boolean awaituninterruptibly ( countdownlatch latch , long timeout , timeunit unit ) { <nl> mmm a / guava / src / com / google / common / util / concurrent / uninterruptibles . java <nl> ppp b / guava / src / com / google / common / util / concurrent / uninterruptibles . java <nl>
public final class uninterruptibles { <nl> * invokes { @ code latch . } { @ link countdownlatch # await ( long , timeunit ) await ( timeout , unit ) } <nl> * uninterruptibly . <nl> * / <nl> - @ canignorereturnvalue <nl> @ gwtincompatible / / concurrency <nl> @ suppresswarnings ( " goodtime " ) / / should accept a java . time . duration <nl> public static boolean awaituninterruptibly ( countdownlatch latch , long timeout , timeunit unit ) {
public final class uninterruptibles { <nl> * <nl> * @ since num . 0 <nl> * / <nl> - @ canignorereturnvalue <nl> @ gwtincompatible / / concurrency <nl> public static boolean awaituninterruptibly ( countdownlatch latch , duration timeout ) { <nl> return awaituninterruptibly ( latch , tonanossaturated ( timeout ) , timeunit . nanoseconds ) ;
public final class throwables { <nl> * @ return an unmodifiable list containing the cause chain starting with { @ code throwable } <nl> * @ throws illegalargumentexception if there is a loop in the causal chain <nl> * / <nl> - @ beta <nl> public static list < throwable > getcausalchain ( throwable throwable ) { <nl> checknotnull ( throwable ) ; <nl> list < throwable > causes = new arraylist < > ( 4 ) ; <nl>
public final class throwables { <nl> * @ return an unmodifiable list containing the cause chain starting with { @ code throwable } <nl> * @ throws illegalargumentexception if there is a loop in the causal chain <nl> * / <nl> - @ beta <nl> public static list < throwable > getcausalchain ( throwable throwable ) { <nl> checknotnull ( throwable ) ; <nl> list < throwable > causes = new arraylist < > ( 4 ) ; <nl>
<nl> < version > $ { checker - framework . version } < / version > <nl> < classifier > sources < / classifier > <nl> < / dependency > <nl> - < ! - - <nl> - < dependency > <nl> - < groupid > org . checkerframework < / groupid > <nl> - < artifactid > checker - compat - qual < / artifactid > <nl> - < version > 2 . 5 . 5 < / version > <nl> - < / dependency > <nl> < dependency > <nl> < groupid > com . google . errorprone < / groupid > <nl> < artifactid > error_prone_annotations < / artifactid >
<nl> < include name = " * * / internalfuturefailureaccess . java " / > <nl> < / fileset > <nl> < / copy > <nl> - < ! - - we fabricate a gwt module to cover the cf annotations . then we inherit it in forceguavacompilation . gwt . xml . - - > <nl> - < echo file = " $ { project . build . directory } / guava - gwt - sources / org / checkerframework / checker / nullness / qual / qual . gwt . xml " > <nl> - & lt ; module & gt ; & lt ; source path = " " / & gt ; & lt ; / module & gt ; <nl> - < / echo > <nl> - < ! - - <nl> - < ! - - in contrast to what we do with our * own * sources ( i . e . , those from guava , guava - testlib , and guava - tests ) , we * don ' t * copy the cf annotations to guava - gwt - sources ( and so we don ' t need to unpack them ourselves at all ) . if we did , they would end up in our generated jar . and we don ' t need to , anyway : the gwt plugin picks them up automatically because of the < classifier > source < / classifier > dependency above . - - > <nl> < copy todir = " $ { project . build . directory } / guava - test - gwt - sources " > <nl> < fileset dir = " $ { project . build . directory } / guava - test - sources " > <nl> < contains text = " @ gwtcompatible " / > <nl> < / fileset > <nl> < / copy > <nl> + < replace token = " @ nullable " value = " " > <nl> + < fileset dir = " $ { project . build . directory } " > <nl> + < include name = " guava - gwt - sources / * * / * . java " / > <nl> + < include name = " guava - test - gwt - sources / * * / * . java " / > <nl> + < / fileset > <nl> + < / replace > <nl> < / target > <nl> < / configuration > <nl> < / execution > <nl> mmm a / guava - gwt / src / com / google / common / forceguavacompilation . gwt . xml <nl> ppp b / guava - gwt / src / com / google / common / forceguavacompilation . gwt . xml <nl>
import javax . annotation . checkfornull ; <nl> @ beta <nl> @ gwtcompatible ( emulated = true ) <nl> @ immutable <nl> - <nl> + @ elementtypesarenonnullbydefault <nl> public final class internetdomainname { <nl>  <nl> private static final charmatcher dots_matcher = charmatcher . anyof ( " . \ u3002 \ uff0e \ uff61 " ) ; <nl>
public final class internetdomainname { <nl> * <nl> * @ since num . 0 <nl> * / <nl> - <nl> - @ suppresswarnings ( " nullness " ) <nl> + @ checkfornull <nl> public internetdomainname publicsuffix ( ) { <nl> return haspublicsuffix ( ) ? ancestor ( publicsuffixindex ) : null ; <nl> } <nl>
public final class internetdomainname { <nl> * <nl> * @ since num . 3 <nl> * / <nl> - <nl> - @ suppresswarnings ( " nullness " ) <nl> + @ checkfornull <nl> public internetdomainname registrysuffix ( ) { <nl> return hasregistrysuffix ( ) ? ancestor ( registrysuffixindex ) : null ; <nl> } <nl> mmm a / guava / src / com / google / common / net / internetdomainname . java <nl> ppp b / guava / src / com / google / common / net / internetdomainname . java <nl>
import javax . annotation . checkfornull ; <nl> @ beta <nl> @ gwtcompatible ( emulated = true ) <nl> @ immutable <nl> - <nl> + @ elementtypesarenonnullbydefault <nl> public final class internetdomainname { <nl>  <nl> private static final charmatcher dots_matcher = charmatcher . anyof ( " . \ u3002 \ uff0e \ uff61 " ) ; <nl>
public final class internetdomainname { <nl> * <nl> * @ since num . 0 <nl> * / <nl> - <nl> - @ suppresswarnings ( " nullness " ) <nl> + @ checkfornull <nl> public internetdomainname publicsuffix ( ) { <nl> return haspublicsuffix ( ) ? ancestor ( publicsuffixindex ) : null ; <nl> } <nl>
public final class internetdomainname { <nl> * <nl> * @ since num . 3 <nl> * / <nl> - <nl> - @ suppresswarnings ( " nullness " ) <nl> + @ checkfornull <nl> public internetdomainname registrysuffix ( ) { <nl> return hasregistrysuffix ( ) ? ancestor ( registrysuffixindex ) : null ; <nl> }
public final class evictingqueue < e > extends forwardingqueue < e > implements serial <nl> return super . toarray ( ) ; <nl> } <nl>  <nl> - <nl> - <nl> private static final long serialversionuid = num l ; <nl> } <nl> mmm a / guava / src / com / google / common / collect / evictingqueue . java <nl> ppp b / guava / src / com / google / common / collect / evictingqueue . java <nl>
public final class evictingqueue < e > extends forwardingqueue < e > implements serial <nl> return super . toarray ( ) ; <nl> } <nl>  <nl> - <nl> - <nl> private static final long serialversionuid = num l ; <nl> }
import javax . annotation . checkfornull ; <nl> * @ since num . 0 <nl> * / <nl> @ gwtcompatible ( emulated = true ) <nl> - <nl> + @ elementtypesarenonnullbydefault <nl> public final class throwables { <nl> private throwables ( ) { } <nl>  <nl>
public final class throwables { <nl> * / <nl> @ beta <nl> @ gwtincompatible / / class . cast ( object ) <nl> - @ suppresswarnings ( " nullness " ) <nl> - <nl> + @ checkfornull <nl> public static < x extends throwable > x getcauseas ( <nl> throwable throwable , class < x > expectedcausetype ) { <nl> try { <nl> mmm a / guava / src / com / google / common / base / throwables . java <nl> ppp b / guava / src / com / google / common / base / throwables . java <nl>
import javax . annotation . checkfornull ; <nl> * @ since num . 0 <nl> * / <nl> @ gwtcompatible ( emulated = true ) <nl> - <nl> + @ elementtypesarenonnullbydefault <nl> public final class throwables { <nl> private throwables ( ) { } <nl>  <nl>
public final class throwables { <nl> * / <nl> @ beta <nl> @ gwtincompatible / / class . cast ( object ) <nl> - @ suppresswarnings ( " nullness " ) <nl> - <nl> + @ checkfornull <nl> public static < x extends throwable > x getcauseas ( <nl> throwable throwable , class < x > expectedcausetype ) { <nl> try {
import org . checkerframework . checker . nullness . qual . nullable ; <nl> * @ since num . 0 <nl> * / <nl> @ beta <nl> - <nl> @ elementtypesarenonnullbydefault <nl> public abstract class abstractinvocationhandler implements invocationhandler { <nl>  <nl>
public abstract class abstractinvocationhandler implements invocationhandler { <nl> * an empty array is passed in . <nl> * / <nl> @ checkfornull <nl> - protected abstract object handleinvocation ( <nl> - object proxy , method method , / * <nl> + protected abstract object handleinvocation ( object proxy , method method , @ nullable object [ ] args ) <nl> throws throwable ; <nl>  <nl> / * * <nl> mmm a / guava / src / com / google / common / reflect / abstractinvocationhandler . java <nl> ppp b / guava / src / com / google / common / reflect / abstractinvocationhandler . java <nl>
import org . checkerframework . checker . nullness . qual . nullable ; <nl> * @ since num . 0 <nl> * / <nl> @ beta <nl> - <nl> @ elementtypesarenonnullbydefault <nl> public abstract class abstractinvocationhandler implements invocationhandler { <nl>  <nl>
public abstract class abstractinvocationhandler implements invocationhandler { <nl> * an empty array is passed in . <nl> * / <nl> @ checkfornull <nl> - protected abstract object handleinvocation ( <nl> - object proxy , method method , / * <nl> + protected abstract object handleinvocation ( object proxy , method method , @ nullable object [ ] args ) <nl> throws throwable ; <nl>  <nl> / * *
public class servicemanagertest extends testcase { <nl> servicemanager servicemanager = new servicemanager ( aslist ( a , b ) ) ; <nl> servicemanager . startasync ( ) . awaithealthy ( ) ; <nl> immutablemap < service , long > startuptimes = servicemanager . startuptimes ( ) ; <nl> - assertequals ( 2 , startuptimes . size ( ) ) ; <nl> - <nl> - asserttrue ( startuptimes . get ( a ) > = num ) ; <nl> + assertthat ( startuptimes ) . hassize ( 2 ) ; <nl> + assertthat ( startuptimes . get ( a ) ) . isatleast ( 150 ) ; <nl> / / service b startup takes at least num millis , but starting the timer is delayed by at least <nl> / / num milliseconds . so in a perfect world the timing would be num - 150 = 203ms , but since either <nl> / / of our sleep calls can be arbitrarily delayed we should just assert that there is a time <nl> mmm a / guava - tests / test / com / google / common / util / concurrent / servicemanagertest . java <nl> ppp b / guava - tests / test / com / google / common / util / concurrent / servicemanagertest . java <nl>
public class servicemanagertest extends testcase { <nl> servicemanager servicemanager = new servicemanager ( aslist ( a , b ) ) ; <nl> servicemanager . startasync ( ) . awaithealthy ( ) ; <nl> immutablemap < service , long > startuptimes = servicemanager . startuptimes ( ) ; <nl> - assertequals ( 2 , startuptimes . size ( ) ) ; <nl> - <nl> - asserttrue ( startuptimes . get ( a ) > = num ) ; <nl> + assertthat ( startuptimes ) . hassize ( 2 ) ; <nl> + assertthat ( startuptimes . get ( a ) ) . isatleast ( 150 ) ; <nl> / / service b startup takes at least num millis , but starting the timer is delayed by at least <nl> / / num milliseconds . so in a perfect world the timing would be num - 150 = 203ms , but since either <nl> / / of our sleep calls can be arbitrarily delayed we should just assert that there is a time
public abstract class contiguousset < c extends comparable > extends immutablesorte <nl> / * <nl> * these methods perform most headset , subset , and tailset logic , besides parameter validation . <nl> * / <nl> - <nl> - / * @ override * / <nl> + @ suppresswarnings ( " missingoverride " ) / / supermethod does not exist under gwt . <nl> abstract contiguousset < c > headsetimpl ( c toelement , boolean inclusive ) ; <nl>  <nl> - / * @ override * / <nl> + @ suppresswarnings ( " missingoverride " ) / / supermethod does not exist under gwt . <nl> abstract contiguousset < c > subsetimpl ( <nl> c fromelement , boolean frominclusive , c toelement , boolean toinclusive ) ; <nl>  <nl> - / * @ override * / <nl> + @ suppresswarnings ( " missingoverride " ) / / supermethod does not exist under gwt . <nl> abstract contiguousset < c > tailsetimpl ( c fromelement , boolean inclusive ) ; <nl>  <nl> / * * <nl> mmm a / guava / src / com / google / common / collect / contiguousset . java <nl> ppp b / guava / src / com / google / common / collect / contiguousset . java <nl>
public abstract class contiguousset < c extends comparable > extends immutablesorte <nl> / * <nl> * these methods perform most headset , subset , and tailset logic , besides parameter validation . <nl> * / <nl> - <nl> - / * @ override * / <nl> + @ suppresswarnings ( " missingoverride " ) / / supermethod does not exist under gwt . <nl> abstract contiguousset < c > headsetimpl ( c toelement , boolean inclusive ) ; <nl>  <nl> - / * @ override * / <nl> + @ suppresswarnings ( " missingoverride " ) / / supermethod does not exist under gwt . <nl> abstract contiguousset < c > subsetimpl ( <nl> c fromelement , boolean frominclusive , c toelement , boolean toinclusive ) ; <nl>  <nl> - / * @ override * / <nl> + @ suppresswarnings ( " missingoverride " ) / / supermethod does not exist under gwt . <nl> abstract contiguousset < c > tailsetimpl ( c fromelement , boolean inclusive ) ; <nl>  <nl> / * *
public final class elementorder < t > { <nl> * < / ul > <nl> * < / ul > <nl> * / <nl> - <nl> - static < s > elementorder < s > stable ( ) { <nl> + public static < s > elementorder < s > stable ( ) { <nl> return new elementorder < s > ( type . stable , null ) ; <nl> } <nl>  <nl> mmm a / android / guava / src / com / google / common / graph / graphbuilder . java <nl> ppp b / android / guava / src / com / google / common / graph / graphbuilder . java <nl>
public final class graphbuilder < n > extends abstractgraphbuilder < n > { <nl> * @ throws illegalargumentexception if { @ code incidentedgeorder } is not either { @ code <nl> * elementorder . unordered ( ) } or { @ code elementorder . stable ( ) } . <nl> * / <nl> - <nl> - < n1 extends n > graphbuilder < n1 > incidentedgeorder ( elementorder < n1 > incidentedgeorder ) { <nl> + public < n1 extends n > graphbuilder < n1 > incidentedgeorder ( elementorder < n1 > incidentedgeorder ) { <nl> checkargument ( <nl> incidentedgeorder . type ( ) = = elementorder . type . unordered <nl> | | incidentedgeorder . type ( ) = = elementorder . type . stable , <nl> mmm a / android / guava / src / com / google / common / graph / valuegraphbuilder . java <nl> ppp b / android / guava / src / com / google / common / graph / valuegraphbuilder . java <nl>
public final class valuegraphbuilder < n , v > extends abstractgraphbuilder < n > { <nl> * @ throws illegalargumentexception if { @ code incidentedgeorder } is not either { @ code <nl> * elementorder . unordered ( ) } or { @ code elementorder . stable ( ) } . <nl> * / <nl> - <nl> - < n1 extends n > valuegraphbuilder < n1 , v > incidentedgeorder ( elementorder < n1 > incidentedgeorder ) { <nl> + public < n1 extends n > valuegraphbuilder < n1 , v > incidentedgeorder ( <nl> + elementorder < n1 > incidentedgeorder ) { <nl> checkargument ( <nl> incidentedgeorder . type ( ) = = elementorder . type . unordered <nl> | | incidentedgeorder . type ( ) = = elementorder . type . stable , <nl> mmm a / guava / src / com / google / common / graph / elementorder . java <nl> ppp b / guava / src / com / google / common / graph / elementorder . java <nl>
public final class elementorder < t > { <nl> * < / ul > <nl> * < / ul > <nl> * / <nl> - <nl> - static < s > elementorder < s > stable ( ) { <nl> + public static < s > elementorder < s > stable ( ) { <nl> return new elementorder < s > ( type . stable , null ) ; <nl> } <nl>  <nl> mmm a / guava / src / com / google / common / graph / graphbuilder . java <nl> ppp b / guava / src / com / google / common / graph / graphbuilder . java <nl>
public final class graphbuilder < n > extends abstractgraphbuilder < n > { <nl> * @ throws illegalargumentexception if { @ code incidentedgeorder } is not either { @ code <nl> * elementorder . unordered ( ) } or { @ code elementorder . stable ( ) } . <nl> * / <nl> - <nl> - < n1 extends n > graphbuilder < n1 > incidentedgeorder ( elementorder < n1 > incidentedgeorder ) { <nl> + public < n1 extends n > graphbuilder < n1 > incidentedgeorder ( elementorder < n1 > incidentedgeorder ) { <nl> checkargument ( <nl> incidentedgeorder . type ( ) = = elementorder . type . unordered <nl> | | incidentedgeorder . type ( ) = = elementorder . type . stable , <nl> mmm a / guava / src / com / google / common / graph / valuegraphbuilder . java <nl> ppp b / guava / src / com / google / common / graph / valuegraphbuilder . java <nl>
public final class valuegraphbuilder < n , v > extends abstractgraphbuilder < n > { <nl> * @ throws illegalargumentexception if { @ code incidentedgeorder } is not either { @ code <nl> * elementorder . unordered ( ) } or { @ code elementorder . stable ( ) } . <nl> * / <nl> - <nl> - < n1 extends n > valuegraphbuilder < n1 , v > incidentedgeorder ( elementorder < n1 > incidentedgeorder ) { <nl> + public < n1 extends n > valuegraphbuilder < n1 , v > incidentedgeorder ( <nl> + elementorder < n1 > incidentedgeorder ) { <nl> checkargument ( <nl> incidentedgeorder . type ( ) = = elementorder . type . unordered <nl> | | incidentedgeorder . type ( ) = = elementorder . type . stable ,
public final class futures extends gwtfuturescatchingspecialization { <nl> * @ param executor the executor that runs { @ code fallback } if { @ code input } fails <nl> * @ since num . 0 ( similar functionality in num . 0 as { @ code withfallback } ) <nl> * / <nl> - @ canignorereturnvalue <nl> @ partially . gwtincompatible ( " available but requires exceptiontype to be throwable . class " ) <nl> public static < v , x extends throwable > listenablefuture < v > catchingasync ( <nl> listenablefuture < ? extends v > input , <nl> mmm a / guava / src / com / google / common / util / concurrent / futures . java <nl> ppp b / guava / src / com / google / common / util / concurrent / futures . java <nl>
public final class futures extends gwtfuturescatchingspecialization { <nl> * @ param executor the executor that runs { @ code fallback } if { @ code input } fails <nl> * @ since num . 0 ( similar functionality in num . 0 as { @ code withfallback } ) <nl> * / <nl> - @ canignorereturnvalue <nl> @ partially . gwtincompatible ( " available but requires exceptiontype to be throwable . class " ) <nl> public static < v , x extends throwable > listenablefuture < v > catchingasync ( <nl> listenablefuture < ? extends v > input ,
public final class lists { <nl> * not actually very useful and will likely be deprecated in the future . <nl> * / <nl> @ safevarargs <nl> - @ canignorereturnvalue <nl> @ gwtcompatible ( serializable = true ) <nl> public static < e > arraylist < e > newarraylist ( e . . . elements ) { <nl> checknotnull ( elements ) ; / / for gwt <nl>
public final class lists { <nl> * constructor } directly , taking advantage of the new < a href = " http : / / goo . gl / iz2wi " > " diamond " <nl> * syntax < / a > . <nl> * / <nl> - @ canignorereturnvalue <nl> @ gwtcompatible ( serializable = true ) <nl> public static < e > arraylist < e > newarraylist ( iterable < ? extends e > elements ) { <nl> checknotnull ( elements ) ; / / for gwt <nl>
public final class lists { <nl> * < p > < b > note : < / b > if mutability is not required and the elements are non - null , use { @ link <nl> * immutablelist # copyof ( iterator ) } instead . <nl> * / <nl> - @ canignorereturnvalue <nl> @ gwtcompatible ( serializable = true ) <nl> public static < e > arraylist < e > newarraylist ( iterator < ? extends e > elements ) { <nl> arraylist < e > list = newarraylist ( ) ; <nl> mmm a / guava / src / com / google / common / collect / lists . java <nl> ppp b / guava / src / com / google / common / collect / lists . java <nl>
public final class lists { <nl> * not actually very useful and will likely be deprecated in the future . <nl> * / <nl> @ safevarargs <nl> - @ canignorereturnvalue <nl> @ gwtcompatible ( serializable = true ) <nl> public static < e > arraylist < e > newarraylist ( e . . . elements ) { <nl> checknotnull ( elements ) ; / / for gwt <nl>
public final class lists { <nl> * constructor } directly , taking advantage of the new < a href = " http : / / goo . gl / iz2wi " > " diamond " <nl> * syntax < / a > . <nl> * / <nl> - @ canignorereturnvalue <nl> @ gwtcompatible ( serializable = true ) <nl> public static < e > arraylist < e > newarraylist ( iterable < ? extends e > elements ) { <nl> checknotnull ( elements ) ; / / for gwt <nl>
public final class lists { <nl> * < p > < b > note : < / b > if mutability is not required and the elements are non - null , use { @ link <nl> * immutablelist # copyof ( iterator ) } instead . <nl> * / <nl> - @ canignorereturnvalue <nl> @ gwtcompatible ( serializable = true ) <nl> public static < e > arraylist < e > newarraylist ( iterator < ? extends e > elements ) { <nl> arraylist < e > list = newarraylist ( ) ;
public abstract class ticker { <nl> protected ticker ( ) { } <nl>  <nl> / * * returns the number of nanoseconds elapsed since this ticker ' s fixed point of reference . * / <nl> - @ canignorereturnvalue <nl> public abstract long read ( ) ; <nl>  <nl> / * * <nl> mmm a / guava / src / com / google / common / base / ticker . java <nl> ppp b / guava / src / com / google / common / base / ticker . java <nl>
public abstract class ticker { <nl> protected ticker ( ) { } <nl>  <nl> / * * returns the number of nanoseconds elapsed since this ticker ' s fixed point of reference . * / <nl> - @ canignorereturnvalue <nl> public abstract long read ( ) ; <nl>  <nl> / * *
public final class iterators { <nl> * @ throws illegalargumentexception if the iterator contains multiple elements . the state of the <nl> * iterator is unspecified . <nl> * / <nl> - @ canignorereturnvalue <nl> public static < t > t getonlyelement ( iterator < t > iterator ) { <nl> t first = iterator . next ( ) ; <nl> if ( ! iterator . hasnext ( ) ) { <nl>
public final class iterators { <nl> * @ throws illegalargumentexception if the iterator contains multiple elements . the state of the <nl> * iterator is unspecified . <nl> * / <nl> - @ canignorereturnvalue <nl> @ nullabledecl <nl> public static < t > t getonlyelement ( iterator < ? extends t > iterator , @ nullabledecl t defaultvalue ) { <nl> return iterator . hasnext ( ) ? getonlyelement ( iterator ) : defaultvalue ; <nl> mmm a / guava / src / com / google / common / collect / iterators . java <nl> ppp b / guava / src / com / google / common / collect / iterators . java <nl>
public final class iterators { <nl> * @ throws illegalargumentexception if the iterator contains multiple elements . the state of the <nl> * iterator is unspecified . <nl> * / <nl> - @ canignorereturnvalue <nl> public static < t > t getonlyelement ( iterator < t > iterator ) { <nl> t first = iterator . next ( ) ; <nl> if ( ! iterator . hasnext ( ) ) { <nl>
public final class iterators { <nl> * @ throws illegalargumentexception if the iterator contains multiple elements . the state of the <nl> * iterator is unspecified . <nl> * / <nl> - @ canignorereturnvalue <nl> public static < t > @ nullable t getonlyelement ( <nl> iterator < ? extends t > iterator , @ nullable t defaultvalue ) { <nl> return iterator . hasnext ( ) ? getonlyelement ( iterator ) : defaultvalue ;
public interface classtoinstancemap < b > extends map < class < ? extends b > , b > { <nl> * is present . this will only return a value that was bound to this specific class , not a value <nl> * that may have been bound to a subtype . <nl> * / <nl> - @ canignorereturnvalue <nl> < t extends b > t getinstance ( class < t > type ) ; <nl>  <nl> / * * <nl> mmm a / guava / src / com / google / common / collect / classtoinstancemap . java <nl> ppp b / guava / src / com / google / common / collect / classtoinstancemap . java <nl>
public interface classtoinstancemap < b > extends map < class < ? extends b > , b > { <nl> * is present . this will only return a value that was bound to this specific class , not a value <nl> * that may have been bound to a subtype . <nl> * / <nl> - @ canignorereturnvalue <nl> < t extends b > t getinstance ( class < t > type ) ; <nl>  <nl> / * *
import junit . framework . testcase ; <nl> * @ author kevin bourrillion <nl> * / <nl> @ gwtcompatible ( emulated = true ) <nl> - <nl> public class abstractiteratortest extends testcase { <nl>  <nl> public void testdefaultbehaviorofnextandhasnext ( ) { <nl> mmm a / android / guava - tests / test / com / google / common / collect / abstractiteratortest . java <nl> ppp b / android / guava - tests / test / com / google / common / collect / abstractiteratortest . java <nl>
import junit . framework . testcase ; <nl> * / <nl> @ suppresswarnings ( " serial " ) / / no serialization is used in this test <nl> @ gwtcompatible ( emulated = true ) <nl> - <nl> public class abstractiteratortest extends testcase { <nl>  <nl> public void testdefaultbehaviorofnextandhasnext ( ) { <nl> mmm a / guava - tests / test / com / google / common / base / abstractiteratortest . java <nl> ppp b / guava - tests / test / com / google / common / base / abstractiteratortest . java <nl>
import junit . framework . testcase ; <nl> * @ author kevin bourrillion <nl> * / <nl> @ gwtcompatible ( emulated = true ) <nl> - <nl> public class abstractiteratortest extends testcase { <nl>  <nl> public void testdefaultbehaviorofnextandhasnext ( ) { <nl> mmm a / guava - tests / test / com / google / common / collect / abstractiteratortest . java <nl> ppp b / guava - tests / test / com / google / common / collect / abstractiteratortest . java <nl>
import junit . framework . testcase ; <nl> * / <nl> @ suppresswarnings ( " serial " ) / / no serialization is used in this test <nl> @ gwtcompatible ( emulated = true ) <nl> - <nl> public class abstractiteratortest extends testcase { <nl>  <nl> public void testdefaultbehaviorofnextandhasnext ( ) {
public class atomicdouble extends number implements java . io . serializable { <nl> * @ param newvalue the new value <nl> * / <nl> public final void lazyset ( double newvalue ) { <nl> - set ( newvalue ) ; <nl> - <nl> - / / long next = doubletorawlongbits ( newvalue ) ; <nl> - / / updater . lazyset ( this , next ) ; <nl> + long next = doubletorawlongbits ( newvalue ) ; <nl> + updater . lazyset ( this , next ) ; <nl> } <nl>  <nl> / * * <nl> mmm a / android / guava / src / com / google / common / util / concurrent / atomicdoublearray . java <nl> ppp b / android / guava / src / com / google / common / util / concurrent / atomicdoublearray . java <nl>
public class atomicdoublearray implements java . io . serializable { <nl> * @ param newvalue the new value <nl> * / <nl> public final void lazyset ( int i , double newvalue ) { <nl> - set ( i , newvalue ) ; <nl> - <nl> - / / long next = doubletorawlongbits ( newvalue ) ; <nl> - / / longs . lazyset ( i , next ) ; <nl> + long next = doubletorawlongbits ( newvalue ) ; <nl> + longs . lazyset ( i , next ) ; <nl> } <nl>  <nl> / * * <nl> mmm a / guava / src / com / google / common / util / concurrent / atomicdouble . java <nl> ppp b / guava / src / com / google / common / util / concurrent / atomicdouble . java <nl>
public class atomicdouble extends number implements java . io . serializable { <nl> * @ param newvalue the new value <nl> * / <nl> public final void lazyset ( double newvalue ) { <nl> - set ( newvalue ) ; <nl> - <nl> - / / long next = doubletorawlongbits ( newvalue ) ; <nl> - / / updater . lazyset ( this , next ) ; <nl> + long next = doubletorawlongbits ( newvalue ) ; <nl> + updater . lazyset ( this , next ) ; <nl> } <nl>  <nl> / * * <nl> mmm a / guava / src / com / google / common / util / concurrent / atomicdoublearray . java <nl> ppp b / guava / src / com / google / common / util / concurrent / atomicdoublearray . java <nl>
public class atomicdoublearray implements java . io . serializable { <nl> * @ param newvalue the new value <nl> * / <nl> public final void lazyset ( int i , double newvalue ) { <nl> - set ( i , newvalue ) ; <nl> - <nl> - / / long next = doubletorawlongbits ( newvalue ) ; <nl> - / / longs . lazyset ( i , next ) ; <nl> + long next = doubletorawlongbits ( newvalue ) ; <nl> + longs . lazyset ( i , next ) ; <nl> } <nl>  <nl> / * *
public abstract class abstractfuture < v > extends fluentfuture < v > { <nl> * <nl> * < p > if { @ link # interrupttask } is also run during completion , { @ link # afterdone } runs after it . <nl> * <nl> - * < p > the default implementation of this method in { @ code abstractfuture } does nothing . this is <nl> + * < p > the default implementation of this method in { @ code abstractfuture } does nothing . this is <nl> * intended for very lightweight cleanup work , for example , timing statistics or clearing fields . <nl> * if your task does anything heavier consider , just using a listener with an executor . <nl> * <nl> * @ since num . 0 <nl> * / <nl> - <nl> @ beta <nl> + @ foroverride <nl> protected void afterdone ( ) { } <nl>  <nl> / * * <nl> mmm a / android / guava / src / com / google / common / util / concurrent / futures . java <nl> ppp b / android / guava / src / com / google / common / util / concurrent / futures . java <nl>
public abstract class abstractfuture < v > extends fluentfuture < v > { <nl> * <nl> * < p > if { @ link # interrupttask } is also run during completion , { @ link # afterdone } runs after it . <nl> * <nl> - * < p > the default implementation of this method in { @ code abstractfuture } does nothing . this is <nl> + * < p > the default implementation of this method in { @ code abstractfuture } does nothing . this is <nl> * intended for very lightweight cleanup work , for example , timing statistics or clearing fields . <nl> * if your task does anything heavier consider , just using a listener with an executor . <nl> * <nl> * @ since num . 0 <nl> * / <nl> - <nl> @ beta <nl> + @ foroverride <nl> protected void afterdone ( ) { } <nl>  <nl> / * * <nl> mmm a / guava / src / com / google / common / util / concurrent / futures . java <nl> ppp b / guava / src / com / google / common / util / concurrent / futures . java <nl>
public class immutablelisttest extends testcase { <nl> builder . add ( " bar " ) ; <nl> regularimmutablelist < string > list = ( regularimmutablelist < string > ) builder . build ( ) ; <nl> builder . add ( " baz " ) ; <nl> - <nl> - / / asserttrue ( list . array ! = builder . contents ) ; <nl> + asserttrue ( list . array ! = builder . contents ) ; <nl> } <nl> } <nl> } <nl> mmm a / android / guava - tests / test / com / google / common / collect / immutablesettest . java <nl> ppp b / android / guava - tests / test / com / google / common / collect / immutablesettest . java <nl>
public class immutablesettest extends abstractimmutablesettest { <nl> } <nl> builder . add ( " bar " ) ; <nl> regularimmutableset < string > set = ( regularimmutableset < string > ) builder . build ( ) ; <nl> - <nl> - / / asserttrue ( set . elements . length < = num * set . size ( ) ) ; <nl> + asserttrue ( set . elements . length < = num * set . size ( ) ) ; <nl> } <nl>  <nl> @ gwtincompatible ( " internals " ) <nl>
public class immutablesettest extends abstractimmutablesettest { <nl> builder . add ( " bar " ) ; <nl> regularimmutableset < string > set = ( regularimmutableset < string > ) builder . build ( ) ; <nl> builder . add ( " baz " ) ; <nl> - <nl> - / / asserttrue ( set . elements ! = builder . contents ) ; <nl> + asserttrue ( set . elements ! = builder . contents ) ; <nl> } <nl> } <nl> mmm a / android / guava - tests / test / com / google / common / collect / immutablesortedsettest . java <nl> ppp b / android / guava - tests / test / com / google / common / collect / immutablesortedsettest . java <nl>
public class immutablesortedsettest extends abstractimmutablesettest { <nl> } <nl> builder . add ( " bar " ) ; <nl> regularimmutablesortedset < string > set = ( regularimmutablesortedset < string > ) builder . build ( ) ; <nl> - <nl> - / / regularimmutablelist < string > list = ( regularimmutablelist < string > ) set . elements ; <nl> - / / asserttrue ( list . array . length < = num * set . size ( ) ) ; <nl> + regularimmutablelist < string > list = ( regularimmutablelist < string > ) set . elements ; <nl> + asserttrue ( list . array . length < = num * set . size ( ) ) ; <nl> } <nl>  <nl> @ gwtincompatible ( " internals " ) <nl>
public class immutablesortedsettest extends abstractimmutablesettest { <nl> } <nl> builder . add ( " bar " ) ; <nl> regularimmutablesortedset < string > set = ( regularimmutablesortedset < string > ) builder . build ( ) ; <nl> - <nl> - / / regularimmutablelist < string > list = ( regularimmutablelist < string > ) set . elements ; <nl> - / / builder . add ( " baz " ) ; <nl> - / / asserttrue ( list . array ! = builder . contents ) ; <nl> + regularimmutablelist < string > list = ( regularimmutablelist < string > ) set . elements ; <nl> + builder . add ( " baz " ) ; <nl> + asserttrue ( list . array ! = builder . contents ) ; <nl> } <nl> }
public final class immutableintarray implements serializable { <nl> return indexof ( target ) > = num ; <nl> } <nl>  <nl> - <nl> - / / foreach ( intconsumer ) , stream ( ) <nl> - <nl> / * * returns a new , mutable copy of this array ' s values , as a primitive { @ code int [ ] } . * / <nl> public int [ ] toarray ( ) { <nl> return arrays . copyofrange ( array , start , end ) ;
public final class optionaltest extends testcase { <nl> } ) ) ; <nl> } <nl>  <nl> - <nl> - <nl> - public void testequalsandhashcode_absent ( ) { <nl> - assertequals ( optional . < string > absent ( ) , optional . < integer > absent ( ) ) ; <nl> - assertequals ( optional . absent ( ) . hashcode ( ) , optional . absent ( ) . hashcode ( ) ) ; <nl> - assertthat ( optional . absent ( ) . hashcode ( ) ) <nl> - . isnotequalto ( optional . of ( 0 ) . hashcode ( ) ) ; <nl> - } <nl> - <nl> - public void testequalsandhashcode_present ( ) { <nl> - assertequals ( optional . of ( " training " ) , optional . of ( " training " ) ) ; <nl> - assertfalse ( optional . of ( " a " ) . equals ( optional . of ( " b " ) ) ) ; <nl> - assertfalse ( optional . of ( " a " ) . equals ( optional . absent ( ) ) ) ; <nl> - assertequals ( optional . of ( " training " ) . hashcode ( ) , optional . of ( " training " ) . hashcode ( ) ) ; <nl> + public void testequalsandhashcode ( ) { <nl> + new equalstester ( ) <nl> + . addequalitygroup ( optional . absent ( ) , reserialize ( optional . absent ( ) ) ) <nl> + . addequalitygroup ( optional . of ( new long ( 5 ) ) , reserialize ( optional . of ( new long ( 5 ) ) ) ) <nl> + . addequalitygroup ( optional . of ( new long ( 42 ) ) , reserialize ( optional . of ( new long ( 42 ) ) ) ) <nl> + . testequals ( ) ; <nl> } <nl>  <nl> public void testtostring_absent ( ) { <nl>
import javax . annotation . nullable ; <nl> * / <nl> @ gwtcompatible ( serializable = true , emulated = true ) <nl> @ suppresswarnings ( " serial " ) / / we ' re overriding default serialization <nl> - <nl> public abstract class immutablemultiset < e > extends immutablemultisetgwtserializationdependencies < e > <nl> implements multiset < e > { <nl>  <nl>
public abstract class converter < a , b > implements function < a , b > { <nl> * value roughly equivalent to { @ code a } . <nl> * <nl> * < p > the returned converter is serializable if { @ code this } converter is . <nl> + * <nl> + * < p > < b > note : < / b > you should not override this method . it is non - final for legacy reasons . <nl> * / <nl> - <nl> @ canignorereturnvalue <nl> public converter < b , a > reverse ( ) { <nl> converter < b , a > result = reverse ;
class standardtable < r , c , v > extends abstracttable < r , c , v > implements serializa <nl>  <nl> @ override <nl> public entry < c , v > next ( ) { <nl> - final entry < c , v > entry = iterator . next ( ) ; <nl> - return new forwardingmapentry < c , v > ( ) { <nl> - @ override <nl> - protected entry < c , v > delegate ( ) { <nl> - return entry ; <nl> - } <nl> - <nl> - @ override <nl> - public v setvalue ( v value ) { <nl> - return super . setvalue ( checknotnull ( value ) ) ; <nl> - } <nl> - <nl> - @ override <nl> - public boolean equals ( object object ) { <nl> - <nl> - return standardequals ( object ) ; <nl> - } <nl> - } ; <nl> + return wrapentry ( iterator . next ( ) ) ; <nl> } <nl>  <nl> @ override <nl>
import java . util . concurrent . timeunit ; <nl> * not the absolute ones . <nl> * < / ul > <nl> * <nl> - * < p > basic usage : <nl> + * < p > basic usage : < pre > { @ code <nl> * <nl> - * < pre > <nl> - * stopwatch stopwatch = stopwatch . { @ link # createstarted createstarted } ( ) ; <nl> + * stopwatch stopwatch = stopwatch . createstarted ( ) ; <nl> * dosomething ( ) ; <nl> - * stopwatch . { @ link # stop stop } ( ) ; / / optional <nl> + * stopwatch . stop ( ) ; / / optional <nl> * <nl> * long millis = stopwatch . elapsed ( milliseconds ) ; <nl> * <nl> - * log . info ( " time : " + stopwatch ) ; / / formatted string like " 12 . 3 ms " <nl> - * < / pre > <nl> + * log . info ( " time : " + stopwatch ) ; / / formatted string like " 12 . 3 ms " } < / pre > <nl> * <nl> * < p > stopwatch methods are not idempotent ; it is an error to start or stop a stopwatch that is <nl> * already in the desired state . <nl> * <nl> * < p > when testing code that uses this class , use { @ link # createunstarted ( ticker ) } or <nl> - * { @ link # createstarted ( ticker ) } to supply a fake or mock ticker . < ! - - <nl> - * " such as " - - > this allows you to simulate any valid behavior of the stopwatch . <nl> + * { @ link # createstarted ( ticker ) } to supply a fake or mock ticker . this allows you to simulate any <nl> + * valid behavior of the stopwatch . <nl> * <nl> * < p > < b > note : < / b > this class is not thread - safe . <nl> * <nl> + * < p > < b > warning for android users : < / b > a stopwatch with default behavior may not continue to keep <nl> + * time while the device is asleep . instead , create one like this : < pre > { @ code <nl> + * <nl> + * stopwatch . createstarted ( <nl> + * new ticker ( ) { <nl> + * public long read ( ) { <nl> + * return android . os . systemclock . elapsedrealtime ( ) ; <nl> + * } <nl> + * } ) ; } < / pre > <nl> + * <nl> * @ author kevin bourrillion <nl> * @ since num . 0 <nl> * /
public abstract class endpointpair < n > implements iterable < n > { <nl> this . nodev = checknotnull ( nodev ) ; <nl> } <nl>  <nl> - <nl> + / * * returns an { @ link endpointpair } representing the endpoints of a directed edge . * / <nl> + public static < n > endpointpair < n > ordered ( n source , n target ) { <nl> + return new ordered < n > ( source , target ) ; <nl> + } <nl> + <nl> + / * * returns an { @ link endpointpair } representing the endpoints of an undirected edge . * / <nl> + public static < n > endpointpair < n > unordered ( n nodeu , n nodev ) { <nl> + return new unordered < n > ( nodeu , nodev ) ; <nl> + } <nl>  <nl> / * * returns an { @ link endpointpair } representing the endpoints of an edge in { @ code graph } . * / <nl> - public static < n > endpointpair < n > of ( graph < ? > graph , n nodeu , n nodev ) { <nl> + static < n > endpointpair < n > of ( graph < ? > graph , n nodeu , n nodev ) { <nl> return graph . isdirected ( ) ? ordered ( nodeu , nodev ) : unordered ( nodeu , nodev ) ; <nl> } <nl>  <nl> / * * returns an { @ link endpointpair } representing the endpoints of an edge in { @ code network } . * / <nl> - public static < n > endpointpair < n > of ( network < ? , ? > network , n nodeu , n nodev ) { <nl> + static < n > endpointpair < n > of ( network < ? , ? > network , n nodeu , n nodev ) { <nl> return network . isdirected ( ) ? ordered ( nodeu , nodev ) : unordered ( nodeu , nodev ) ; <nl> } <nl>  <nl> - / * * returns an { @ link endpointpair } representing the endpoints of a directed edge . * / <nl> - static < n > endpointpair . ordered < n > ordered ( n source , n target ) { <nl> - return new ordered < n > ( source , target ) ; <nl> - } <nl> - <nl> - / * * returns an { @ link endpointpair } representing the endpoints of an undirected edge . * / <nl> - static < n > endpointpair . unordered < n > unordered ( n nodeu , n nodev ) { <nl> - return new unordered < n > ( nodeu , nodev ) ; <nl> - } <nl> - <nl> / * * <nl> * if this { @ link endpointpair } { @ link # isordered ( ) } , returns the node which is the source . <nl> *
public abstract class ordering < t > implements comparator < t > { <nl> @ visiblefortesting <nl> static class arbitraryordering extends ordering < object > { <nl>  <nl> - @ suppresswarnings ( " deprecation " ) <nl> - private final map < object , integer > uids = <nl> - platform . tryweakkeys ( new mapmaker ( ) ) <nl> - . makecomputingmap ( <nl> - new function < object , integer > ( ) { <nl> - final atomicinteger counter = new atomicinteger ( 0 ) ; <nl> - <nl> - @ override <nl> - public integer apply ( object from ) { <nl> - return counter . getandincrement ( ) ; <nl> - } <nl> - } ) ; <nl> + private final atomicinteger counter = new atomicinteger ( 0 ) ; <nl> + private final concurrentmap < object , integer > uids = <nl> + platform . tryweakkeys ( new mapmaker ( ) ) . makemap ( ) ; <nl> + <nl> + private integer getuid ( object obj ) { <nl> + integer uid = uids . get ( obj ) ; <nl> + if ( uid = = null ) { <nl> + / / one or more integer values could be skipped in the event of a race <nl> + / / to generate a uid for the same object from multiple threads , but <nl> + / / that shouldn ' t be a problem . <nl> + uid = counter . getandincrement ( ) ; <nl> + integer alreadyset = uids . putifabsent ( obj , uid ) ; <nl> + if ( alreadyset ! = null ) { <nl> + uid = alreadyset ; <nl> + } <nl> + } <nl> + return uid ; <nl> + } <nl>  <nl> @ override <nl> public int compare ( object left , object right ) { <nl>
final class directedmultinodeconnections < n , e > extends abstractdirectednodeconne <nl> return false ; <nl> } <nl>  <nl> - <nl> @ nullable private static < t > t getreference ( @ nullable reference < t > reference ) { <nl> if ( reference = = null ) { <nl> return null ; <nl> mmm a / guava / src / com / google / common / graph / graphconstants . java <nl> ppp b / guava / src / com / google / common / graph / graphconstants . java <nl>
final class graphconstants { <nl>  <nl> private graphconstants ( ) { } <nl>  <nl> - <nl> static final int expected_degree = num ; <nl>  <nl> static final int default_node_count = num ; <nl> mmm a / guava / src / com / google / common / graph / undirectedmultinodeconnections . java <nl> ppp b / guava / src / com / google / common / graph / undirectedmultinodeconnections . java <nl>
final class undirectedmultinodeconnections < n , e > extends abstractundirectednodec <nl> return false ; <nl> } <nl>  <nl> - <nl> @ nullable private static < t > t getreference ( @ nullable reference < t > reference ) { <nl> if ( reference = = null ) { <nl> return null ;
public class queuestest extends testcase { <nl> while ( ! thread . interrupted ( ) ) { thread . yield ( ) ; } <nl> } <nl>  <nl> - private static class producer implements runnable { <nl> + private static class producer implements callable < void > { <nl> final blockingqueue < object > q ; <nl> final int elements ; <nl> + final countdownlatch doneproducing = new countdownlatch ( 1 ) ; <nl>  <nl> producer ( blockingqueue < object > q , int elements ) { <nl> this . q = q ; <nl> this . elements = elements ; <nl> } <nl>  <nl> - @ override public void run ( ) { <nl> + @ override public void call ( ) throws interruptedexception { <nl> try { <nl> for ( int i = num ; i < elements ; i + + ) { <nl> q . put ( new object ( ) ) ; <nl> } <nl> - } catch ( interruptedexception e ) { <nl> - <nl> - / / have threads propagate their errors back to the test thread . <nl> - e . printstacktrace ( ) ; <nl> - / / never returns , so that # teardown ( ) notices that one worker isn ' t done <nl> - uninterruptibles . sleepuninterruptibly ( long . max_value , timeunit . milliseconds ) ; <nl> + return null ; <nl> + } finally { <nl> + doneproducing . countdown ( ) ; <nl> } <nl> } <nl> }
import com . google . common . base . optional ; <nl> * @ author joshua o ' madadhain <nl> * @ since num . 0 <nl> * / <nl> - <nl> @ beta <nl> public final class networkbuilder < n , e > { <nl> final boolean directed ;
public final class immutablegraph < n > extends abstractconfigurablegraph < n > { <nl> / * * <nl> * returns an immutable copy of { @ code graph } . <nl> * / <nl> + @ suppresswarnings ( " unchecked " ) <nl> public static < n > immutablegraph < n > copyof ( graph < n > graph ) { <nl> - <nl> - checkargument ( ! ( graph instanceof network ) , " input must not implement common . graph . network " ) ; <nl> + checkargument ( ! ( ( graph instanceof network ) & & ( ( network < n , ? > ) graph ) . allowsparalleledges ( ) ) , <nl> + network_with_parallel_edge ) ; <nl> return ( graph instanceof immutablegraph ) <nl> ? ( immutablegraph < n > ) graph <nl> : new immutablegraph < n > ( graph ) ;
public abstract class endpoints < n > extends abstractcollection < n > { <nl> public int hashcode ( ) { <nl> return nodea ( ) . hashcode ( ) ^ nodeb ( ) . hashcode ( ) ; <nl> } <nl> - <nl> - @ override <nl> - public string tostring ( ) { <nl> - <nl> - return immutableset . copyof ( this ) . tostring ( ) ; <nl> - } <nl> } <nl> }
public class configurabledirectedgraphtest extends configurablesimpledirectedgra <nl> assertthat ( graph . nodes ( ) ) . containsexactly ( n1 ) ; <nl> assertthat ( graph . successors ( n1 ) ) . isempty ( ) ; <nl> } <nl> - <nl> - <nl> - @ test <nl> - public void testequals ( ) { <nl> - mutablegraph < integer > grapha = creategraph ( ) ; <nl> - grapha . addnode ( n1 ) ; <nl> - mutablegraph < integer > graphb = creategraph ( ) ; <nl> - grapha . addnode ( n2 ) ; <nl> - <nl> - new equalstester ( ) <nl> - . addequalitygroup ( grapha ) <nl> - . addequalitygroup ( graphb ) <nl> - . testequals ( ) ; <nl> - } <nl> }
abstract class abstractiteratortester < e , i extends iterator < e > > { <nl>  <nl> void assertpermitted ( runtimeexception exception ) { <nl> if ( ! ispermitted ( exception ) ) { <nl> - <nl> - string message = " exception " + exception . getclass ( ) + " was thrown ; expected " + this ; <nl> + string message = <nl> + " exception " <nl> + + exception . getclass ( ) . getsimplename ( ) <nl> + + " was thrown ; expected " <nl> + + getmessage ( ) ; <nl> helpers . fail ( exception , message ) ; <nl> } <nl> } <nl>  <nl> - @ override public string tostring ( ) { <nl> - return getmessage ( ) ; <nl> - } <nl> - <nl> private static final long serialversionuid = num ; <nl> }
<nl> < failonerror > true < / failonerror > <nl> < loglevel > $ { gwt . loglevel } < / loglevel > <nl> < validateonly > true < / validateonly > <nl> - < sourcelevel > 1 . 7 < / sourcelevel > < ! - - <nl> + < sourcelevel > 1 . 7 < / sourcelevel > <nl> < / configuration > <nl> < / execution > <nl> < ! - -
public final class pairedstatsaccumulator { <nl> * adds the given statistics to the dataset , as if the individual values used to compute the <nl> * statistics had been added directly . <nl> * / <nl> - <nl> - void addall ( pairedstats values ) { <nl> + public void addall ( pairedstats values ) { <nl> if ( values . count ( ) = = num ) { <nl> return ; <nl> } <nl> mmm a / guava / src / com / google / common / math / statsaccumulator . java <nl> ppp b / guava / src / com / google / common / math / statsaccumulator . java <nl>
public final class statsaccumulator { <nl> * adds the given statistics to the dataset , as if the individual values used to compute the <nl> * statistics had been added directly . <nl> * / <nl> - <nl> - void addall ( stats values ) { <nl> + public void addall ( stats values ) { <nl> if ( values . count ( ) = = num ) { <nl> return ; <nl> }
public final class pairedstatsaccumulator { <nl> return ; <nl> } <nl>  <nl> - if ( count ( ) = = num ) { <nl> + xstats . addall ( values . xstats ( ) ) ; <nl> + if ( ystats . count ( ) = = num ) { <nl> sumofproductsofdeltas = values . sumofproductsofdeltas ( ) ; <nl> } else { <nl> - long nextcount = count ( ) + values . count ( ) ; <nl> - double xmeandelta = xstats . mean ( ) - values . xstats ( ) . mean ( ) ; <nl> - double ymeandelta = ystats . mean ( ) - values . ystats ( ) . mean ( ) ; <nl> - / / note that non - finite inputs will have sumofsquaresofdeltas = nan , so non - finite values will <nl> - / / result in nan naturally . <nl> - <nl> + / / non - finite inputs will have sumofproductsofdeltas = nan , so non - finite values will result <nl> + / / in nan naturally . <nl> sumofproductsofdeltas + = <nl> values . sumofproductsofdeltas ( ) <nl> - + xmeandelta * ymeandelta * count ( ) * values . count ( ) / nextcount ; <nl> + + ( values . xstats ( ) . mean ( ) - xstats . mean ( ) ) <nl> + * ( values . ystats ( ) . mean ( ) - ystats . mean ( ) ) <nl> + * values . count ( ) ; <nl> } <nl> - <nl> - xstats . addall ( values . xstats ( ) ) ; <nl> ystats . addall ( values . ystats ( ) ) ; <nl> }
public final class statsaccumulator { <nl> min = values . min ( ) ; <nl> max = values . max ( ) ; <nl> } else { <nl> - / / updating algorithm ( 1 . 5 ) from chan et al . ( 1983 ) . algorithms for computing the sample <nl> - / / variance : analysis and recommendations . the american statistician num , num - 247 . <nl> - long nextcount = count + values . count ( ) ; <nl> - double delta = values . mean ( ) - mean ; <nl> - / / note that this is the naive mean formula , so non - finite values are handled naturally . <nl> - <nl> - mean = ( sum ( ) + values . sum ( ) ) / nextcount ; <nl> - / / note that non - finite inputs will have sumofsquaresofdeltas = nan , so non - finite values will <nl> - / / result in nan naturally . <nl> - sumofsquaresofdeltas + = <nl> - values . sumofsquaresofdeltas ( ) + values . count ( ) * delta * ( values . mean ( ) - mean ) ; <nl> - count = nextcount ; <nl> + count + = values . count ( ) ; <nl> + if ( isfinite ( mean ) & & isfinite ( values . mean ( ) ) ) { <nl> + / / this is a generalized version of the calculation in add ( double ) above . <nl> + double delta = values . mean ( ) - mean ; <nl> + mean + = delta * values . count ( ) / count ; <nl> + sumofsquaresofdeltas + = <nl> + values . sumofsquaresofdeltas ( ) + delta * ( values . mean ( ) - mean ) * values . count ( ) ; <nl> + } else { <nl> + mean = calculatenewmeannonfinite ( mean , values . mean ( ) ) ; <nl> + sumofsquaresofdeltas = nan ; <nl> + } <nl> min = math . min ( min , values . min ( ) ) ; <nl> max = math . max ( max , values . max ( ) ) ; <nl> }
public abstract class baseencoding { <nl> * @ throws illegalargumentexception if the input is not a valid encoded string according to this <nl> * encoding . <nl> * / <nl> - public final byte [ ] decode ( charsequence chars ) { <nl> + @ checkreturnvalue <nl> + public final byte [ ] decode ( charsequence chars ) { <nl> try { <nl> return decodechecked ( chars ) ; <nl> } catch ( decodingexception badinput ) { <nl>
public abstract class baseencoding { <nl> * <nl> * @ throws decodingexception if the input is not a valid encoded string according to this <nl> * encoding . <nl> - * / final byte [ ] decodechecked ( charsequence chars ) <nl> - throws decodingexception { <nl> + * / <nl> + @ checkreturnvalue final byte [ ] decodechecked ( charsequence chars ) <nl> + throws decodingexception { <nl> chars = padding ( ) . trimtrailingfrom ( chars ) ; <nl> byte [ ] tmp = new byte [ maxdecodedsize ( chars . length ( ) ) ] ; <nl> int len = decodeto ( tmp , chars ) ;
public abstract class baseencoding { <nl> * encoding . <nl> * / <nl> @ checkreturnvalue <nl> - public final boolean candecode ( charsequence chars ) { <nl> - <nl> - try { <nl> - decodechecked ( chars ) ; <nl> - return true ; <nl> - } catch ( decodingexception badinput ) { <nl> - return false ; <nl> - } <nl> - } <nl> + public abstract boolean candecode ( charsequence chars ) ; <nl>  <nl> / * * <nl> * decodes the specified character sequence , and returns the resulting { @ code byte [ ] } . <nl>
public class hashingtest extends testcase { <nl> assertequals ( " hashing . murmur3_128 ( 0 ) " , hashing . murmur3_128 ( ) . tostring ( ) ) ; <nl> } <nl>  <nl> - @ androidincompatible <nl> public void testmurmur3_32 ( ) { <nl> hashtestutils . check2bitavalanche ( hashing . murmur3_32 ( ) , num , num . 20 ) ; <nl> hashtestutils . checkavalanche ( hashing . murmur3_32 ( ) , num , num . 17 ) ; <nl>
public class hashingtest extends testcase { <nl> assertequals ( " hashing . murmur3_32 ( 0 ) " , hashing . murmur3_32 ( ) . tostring ( ) ) ; <nl> } <nl>  <nl> - @ androidincompatible <nl> public void testsiphash24 ( ) { <nl> hashtestutils . check2bitavalanche ( hashing . siphash24 ( ) , num , num . 14 ) ; <nl> hashtestutils . checkavalanche ( hashing . siphash24 ( ) , num , num . 10 ) ; <nl>
public class hashingtest extends testcase { <nl> } <nl> } <nl>  <nl> - @ androidincompatible <nl> / / goodfasthash ( 32 ) uses murmur3_32 . use the same epsilon bounds . <nl> public void testgoodfasthash32 ( ) { <nl> hashtestutils . check2bitavalanche ( hashing . goodfasthash ( 32 ) , num , num . 20 ) ;
public class bytestreamstest extends iotestcase { <nl> assertequals ( new byte [ ] { 0 , num } , out . tobytearray ( ) ) ; <nl> } <nl>  <nl> - @ androidincompatible <nl> + private static final byte [ ] utf16expectedwithbom = <nl> + new byte [ ] { - 2 , - 1 , num , num , num , - 55 , num , num , num , num , num , num , num , - 55 } ; <nl> + <nl> public void testnewdataoutput_writechars ( ) { <nl> bytearraydataoutput out = bytestreams . newdataoutput ( ) ; <nl> out . writechars ( " r \ u00c9sum \ u00c9 " ) ; <nl> / / need to remove byte order mark before comparing <nl> - byte [ ] expected = arrays . copyofrange ( " r \ u00c9sum \ u00c9 " . getbytes ( charsets . utf_16 ) , num , num ) ; <nl> + byte [ ] expected = arrays . copyofrange ( utf16expectedwithbom , num , num ) ; <nl> assertequals ( expected , out . tobytearray ( ) ) ; <nl> } <nl>  <nl> + @ androidincompatible / / https : / / code . google . com / p / android / issues / detail ? id = 196848 <nl> + public void testutf16expected ( ) { <nl> + byte [ ] hardcodedexpected = utf16expectedwithbom ; <nl> + byte [ ] computedexpected = " r \ u00c9sum \ u00c9 " . getbytes ( charsets . utf_16 ) ; <nl> + assertequals ( hardcodedexpected , computedexpected ) ; <nl> + } <nl> + <nl> public void testnewdataoutput_writeutf ( ) { <nl> bytearraydataoutput out = bytestreams . newdataoutput ( ) ; <nl> out . writeutf ( " r \ u00c9sum \ u00c9 " ) ;
public class splittertest extends testcase { <nl> } <nl>  <nl> @ gwtincompatible ( " java . util . regex . pattern " ) <nl> - @ androidincompatible <nl> + @ androidincompatible / / bug in older versions of android we test against , since fixed . <nl> public void testpatternsplitlookbehind ( ) { <nl> string tosplit = " : foo : : barbaz : " ; <nl> string regexpattern = " ( ? < = : ) " ; <nl>
public class splittertest extends testcase { <nl> } <nl>  <nl> @ gwtincompatible ( " java . util . regex . pattern " ) <nl> - @ androidincompatible <nl> + @ androidincompatible / / bug in older versions of android we test against , since fixed . <nl> public void testpatternsplitwordboundary ( ) { <nl> string string = " foo < bar > bletch " ; <nl> iterable < string > words = splitter . on ( pattern . compile ( " \ \ b " ) ) . split ( string ) ;
public class splittertest extends testcase { <nl> } <nl>  <nl> @ gwtincompatible ( " java . util . regex . pattern " ) <nl> - @ androidincompatible <nl> + @ androidincompatible / / not clear that j . u . r . matcher promises to handle mutations during use <nl> public void testsplitteriterableislazy_pattern ( ) { <nl> assertsplitteriterableislazy ( splitter . onpattern ( " , " ) ) ; <nl> }
public final class futures extends gwtfuturescatchingspecialization { <nl> public void run ( ) { <nl> final v value ; <nl> try { <nl> - <nl> - / / is the thing for ie . <nl> value = getuninterruptibly ( future ) ; <nl> } catch ( executionexception e ) { <nl> callback . onfailure ( e . getcause ( ) ) ;
public abstract class fluentiterable < e > implements iterable < e > { <nl> * < p > < b > { @ code stream } equivalent : < / b > { @ code stream . of ( elements ) } or { @ code <nl> * arrays . stream ( elements ) } . <nl> * <nl> + * @ deprecated use { @ link # from ( e [ ] ) } instead ( but note the differences in mutability ) . this <nl> + * method will be removed in guava release num . 0 . <nl> * @ since num . 0 <nl> * / <nl> @ beta <nl> @ checkreturnvalue <nl> - <nl> + @ deprecated <nl> public static < e > fluentiterable < e > of ( e [ ] elements ) { <nl> return from ( lists . newarraylist ( elements ) ) ; <nl> }
import java . util . list ; <nl> * <nl> * @ author louis wasserman <nl> * / <nl> - @ suppressunderandroid <nl> public class annotatedsubscriberfindertests { <nl>  <nl> private static final object event = new object ( ) ; <nl> mmm a / guava - tests / test / com / google / common / eventbus / outside / suppressunderandroid . java <nl> ppp / dev / null <nl>
public final class nullpointertester { <nl> } <nl> } <nl>  <nl> - <nl> private static final class signature { <nl> private final string name ; <nl> private final immutablelist < class < ? > > parametertypes ;
public final class futures { <nl> * @ since num . 0 <nl> * / <nl> @ suppresswarnings ( { " rawtypes " , " unchecked " } ) <nl> - @ gwtincompatible ( " <nl> public static < v > listenablefuture < v > dereference ( <nl> listenablefuture < ? extends listenablefuture < ? extends v > > nested ) { <nl> return futures . transform ( ( listenablefuture ) nested , ( asyncfunction ) dereferencer ) ; <nl>
public final class futures { <nl> / * * <nl> * helper { @ code function } for { @ link # dereference } . <nl> * / <nl> - @ gwtincompatible ( " <nl> private static final asyncfunction < listenablefuture < object > , object > dereferencer = <nl> new asyncfunction < listenablefuture < object > , object > ( ) { <nl> @ override public listenablefuture < object > apply ( listenablefuture < object > input ) {
public final class sets { <nl> * @ since num . 0 <nl> * / <nl> public static < e > setview < e > symmetricdifference ( <nl> - set < ? extends e > set1 , set < ? extends e > set2 ) { <nl> + final set < ? extends e > set1 , final set < ? extends e > set2 ) { <nl> checknotnull ( set1 , " set1 " ) ; <nl> checknotnull ( set2 , " set2 " ) ; <nl>  <nl> - <nl> - return difference ( union ( set1 , set2 ) , intersection ( set1 , set2 ) ) ; <nl> + return new setview < e > ( ) { <nl> + @ override public iterator < e > iterator ( ) { <nl> + final iterator < ? extends e > itr1 = set1 . iterator ( ) ; <nl> + final iterator < ? extends e > itr2 = set2 . iterator ( ) ; <nl> + return new abstractiterator < e > ( ) { <nl> + @ override public e computenext ( ) { <nl> + while ( itr1 . hasnext ( ) ) { <nl> + e elem1 = itr1 . next ( ) ; <nl> + if ( ! set2 . contains ( elem1 ) ) { <nl> + return elem1 ; <nl> + } <nl> + } <nl> + while ( itr2 . hasnext ( ) ) { <nl> + e elem2 = itr2 . next ( ) ; <nl> + if ( ! set1 . contains ( elem2 ) ) { <nl> + return elem2 ; <nl> + } <nl> + } <nl> + return endofdata ( ) ; <nl> + } <nl> + } ; <nl> + } <nl> + @ override public int size ( ) { <nl> + return iterators . size ( iterator ( ) ) ; <nl> + } <nl> + @ override public boolean isempty ( ) { <nl> + return set1 . equals ( set2 ) ; <nl> + } <nl> + @ override public boolean contains ( object element ) { <nl> + return set1 . contains ( element ) ^ set2 . contains ( element ) ; <nl> + } <nl> + } ; <nl> } <nl>  <nl> / * * <nl> mmm a / guava / src / com / google / common / collect / sets . java <nl> ppp b / guava / src / com / google / common / collect / sets . java <nl>
public final class sets { <nl> * @ since num . 0 <nl> * / <nl> public static < e > setview < e > symmetricdifference ( <nl> - set < ? extends e > set1 , set < ? extends e > set2 ) { <nl> + final set < ? extends e > set1 , final set < ? extends e > set2 ) { <nl> checknotnull ( set1 , " set1 " ) ; <nl> checknotnull ( set2 , " set2 " ) ; <nl>  <nl> - <nl> - return difference ( union ( set1 , set2 ) , intersection ( set1 , set2 ) ) ; <nl> + return new setview < e > ( ) { <nl> + @ override public iterator < e > iterator ( ) { <nl> + final iterator < ? extends e > itr1 = set1 . iterator ( ) ; <nl> + final iterator < ? extends e > itr2 = set2 . iterator ( ) ; <nl> + return new abstractiterator < e > ( ) { <nl> + @ override public e computenext ( ) { <nl> + while ( itr1 . hasnext ( ) ) { <nl> + e elem1 = itr1 . next ( ) ; <nl> + if ( ! set2 . contains ( elem1 ) ) { <nl> + return elem1 ; <nl> + } <nl> + } <nl> + while ( itr2 . hasnext ( ) ) { <nl> + e elem2 = itr2 . next ( ) ; <nl> + if ( ! set1 . contains ( elem2 ) ) { <nl> + return elem2 ; <nl> + } <nl> + } <nl> + return endofdata ( ) ; <nl> + } <nl> + } ; <nl> + } <nl> + @ override public int size ( ) { <nl> + return iterators . size ( iterator ( ) ) ; <nl> + } <nl> + @ override public boolean isempty ( ) { <nl> + return set1 . equals ( set2 ) ; <nl> + } <nl> + @ override public boolean contains ( object element ) { <nl> + return set1 . contains ( element ) ^ set2 . contains ( element ) ; <nl> + } <nl> + } ; <nl> } <nl>  <nl> / * *
<nl> - # ! / bin / bash <nl> - # <nl> - # this script checks the java version and bails if it ' s less <nl> - # than java6 ( because we use @ override annotations on interface <nl> - # overriding methods . it then proceeds to do a maven build that <nl> - # first cleans , then builds the normal lifecycle through compilation <nl> - # unit testing ( if available ) up to packaging . it then packages <nl> - # the source , javadocs , and maven site . it then signs the <nl> - # artifacts with whatever pgp signature is the default of the <nl> - # user executing it , and then deploys to the repository contained <nl> - # in the distributionmanagement section of the pom . <nl> - # <nl> - # author : cgruber @ google . com ( christian edward gruber ) <nl> - # <nl> - if [ [ - n $ { java_home } ] ] ; then <nl> - java_cmd = $ { java_home } / bin / java <nl> - else <nl> - java_cmd = java <nl> - fi <nl> - java_version = " $ ( $ { java_cmd } - version num > & 1 | grep - e ' java version ' | awk ' { print $ 3 } ' ) " <nl> - <nl> - # this test sucks , but it ' s short term <nl> - # <nl> - greater_than_java5 = " $ ( echo $ { java_version } | grep - e ' ^ " 1 . [ 67 ] ' ) " <nl> - <nl> - if [ [ - z $ { greater_than_java5 } ] ] ; then <nl> - echo " your java version is $ { java_version } . " <nl> - echo " you must use at least a java num jvm to build and deploy this software . " <nl> - exit num <nl> - else <nl> - echo " building with java $ { java_version } " <nl> - fi <nl> - <nl> - if [ [ $ # > num ] ] ; then <nl> - params + = " - dgpg . keyname = $ { 1 } " <nl> - gpg_sign_plugin = " gpg : sign " <nl> - fi <nl> - cmd = " mvn clean package source : jar site : jar javadoc : jar $ { gpg_sign_plugin } deploy $ { params } " <nl> - echo " executing $ { cmd } " <nl> - $ { cmd }
public class openjdk6maptests extends testsformapsinjavautil { <nl> getcontainsentrywithincomparablekeymethod ( ) , <nl> getcontainsentrywithincomparablevaluemethod ( ) ) ; <nl> } <nl> - <nl> - @ override public test testsforenummap ( ) { <nl> - / / do nothing . <nl> - <nl> - / / http : / / bugs . sun . com / view_bug . do ? bug_id = 6312706 <nl> - return new testsuite ( ) ; <nl> - } <nl> }
public abstract class cacheloader < k , v > { <nl> return new suppliertocacheloader < v > ( supplier ) ; <nl> } <nl>  <nl> - <nl> - <nl> private static final class suppliertocacheloader < v > <nl> extends cacheloader < object , v > implements serializable { <nl> private final supplier < v > computingsupplier ; <nl>
public abstract class cacheloader < k , v > { <nl> return new suppliertocacheloader < v > ( supplier ) ; <nl> } <nl>  <nl> - <nl> - <nl> / * * <nl> * returns a { @ code cacheloader } which wraps { @ code loader } , executing calls to <nl> * { @ link cacheloader # reload } using { @ code executor } .
public class collectioniteratortester < e > extends abstractcollectiontester < e > { <nl> iteratortester . knownorder knownorder , iterable < e > elements ) { <nl> new iteratortester < e > ( platform . collectioniteratortesternumiterations ( ) , features , elements , <nl> knownorder ) { <nl> - { <nl> - <nl> - ignoresunjavabug6529795 ( ) ; <nl> - } <nl> - <nl> @ override protected iterator < e > newtargetiterator ( ) { <nl> resetcollection ( ) ; <nl> return collection . iterator ( ) ; <nl> mmm a / guava - testlib / src / com / google / common / collect / testing / testers / collectioniteratortester . java <nl> ppp b / guava - testlib / src / com / google / common / collect / testing / testers / collectioniteratortester . java <nl>
public class collectioniteratortester < e > extends abstractcollectiontester < e > { <nl> iteratortester . knownorder knownorder , iterable < e > elements ) { <nl> new iteratortester < e > ( platform . collectioniteratortesternumiterations ( ) , features , elements , <nl> knownorder ) { <nl> - { <nl> - <nl> - ignoresunjavabug6529795 ( ) ; <nl> - } <nl> - <nl> @ override protected iterator < e > newtargetiterator ( ) { <nl> resetcollection ( ) ; <nl> return collection . iterator ( ) ; <nl> mmm a / guava - tests / test / com / google / common / collect / minmaxpriorityqueuetest . java <nl> ppp b / guava - tests / test / com / google / common / collect / minmaxpriorityqueuetest . java <nl>
public final class hashing { <nl>  <nl> @ override <nl> hashcode makehash ( hasher [ ] hashers ) { <nl> - <nl> byte [ ] bytes = new byte [ bits / num ] ; <nl> - bytebuffer buffer = bytebuffer . wrap ( bytes ) ; <nl> + int i = num ; <nl> for ( hasher hasher : hashers ) { <nl> - buffer . put ( hasher . hash ( ) . asbytes ( ) ) ; <nl> + hashcode newhash = hasher . hash ( ) ; <nl> + i + = newhash . writebytesto ( bytes , i , newhash . bits ( ) / num ) ; <nl> } <nl> return hashcode . frombytesnocopy ( bytes ) ; <nl> }
public final class queues { <nl> / * * <nl> * creates an empty { @ code priorityblockingqueue } with the ordering given by its <nl> * elements ' natural ordering . <nl> + * <nl> + * @ since num . 0 ( requires that { @ code e } be { @ code comparable } since num . 0 ) . <nl> * / <nl> - <nl> - public static < e > priorityblockingqueue < e > newpriorityblockingqueue ( ) { <nl> + public static < e extends comparable > priorityblockingqueue < e > newpriorityblockingqueue ( ) { <nl> return new priorityblockingqueue < e > ( ) ; <nl> } <nl>  <nl>
public abstract class discretedomain < c extends comparable > { <nl>  <nl> / * * <nl> * returns the discrete domain for values of type { @ code biginteger } . <nl> + * <nl> + * @ since num . 0 <nl> * / <nl> - <nl> - static discretedomain < biginteger > bigintegers ( ) { <nl> + public static discretedomain < biginteger > bigintegers ( ) { <nl> return bigintegerdomain . instance ; <nl> } <nl>  <nl>
public abstract class abstractlistmultimaptest extends abstractmultimaptest { <nl> assert . that ( multimap . get ( " bar " ) ) . has ( ) . allof ( 13 , num , num ) . inorder ( ) ; <nl> } <nl>  <nl> - / * * <nl> - * according to the abstractcollection . retainall ( ) implementation , <nl> - * { @ code a . retainall ( b ) } should keep all occurrences of each object in b , <nl> - * so even though the collection that this test passes to retainall ( ) has <nl> - * fewer occurrences of num than the multimap has , all of the num s should be <nl> - * retained . <nl> - * / <nl> - public void testgetretainall ( ) { <nl> - <nl> - listmultimap < string , integer > multimap = create ( ) ; <nl> - multimap . putall ( " foo " , aslist ( 1 , num , num , num , num , num ) ) ; <nl> - <nl> - multimap . get ( " foo " ) . retainall ( aslist ( 1 , num , num ) ) ; <nl> - assert . that ( multimap . get ( " foo " ) ) . has ( ) . allof ( 1 , num , num ) . inorder ( ) ; <nl> - } <nl> - <nl> / * * <nl> * according to the abstractcollection . removeall ( ) implementation , <nl> * { @ code a . removeall ( b ) } should remove all occurrences of each object in b ,
public final class stopwatch { <nl> / * * <nl> * creates ( but does not start ) a new stopwatch using { @ link system # nanotime } <nl> * as its time source . <nl> + * <nl> + * @ deprecated use { @ link stopwatch # createunstarted ( ) } instead . <nl> * / <nl> - <nl> + @ deprecated <nl> public stopwatch ( ) { <nl> this ( ticker . systemticker ( ) ) ; <nl> } <nl>
public final class stopwatch { <nl> / * * <nl> * creates ( but does not start ) a new stopwatch , using the specified time <nl> * source . <nl> + * <nl> + * @ deprecated use { @ link stopwatch # createunstarted ( ticker ) } instead . <nl> * / <nl> - <nl> + @ deprecated <nl> public stopwatch ( ticker ticker ) { <nl> this . ticker = checknotnull ( ticker , " ticker " ) ; <nl> } <nl>
public final class stopwatch { <nl> / * * <nl> * creates ( but does not start ) a new stopwatch using { @ link system # nanotime } <nl> * as its time source . <nl> + * <nl> + * @ deprecated use { @ link stopwatch # createunstarted ( ) } instead . <nl> * / <nl> - <nl> + @ deprecated <nl> public stopwatch ( ) { <nl> this ( ticker . systemticker ( ) ) ; <nl> } <nl>
public final class stopwatch { <nl> / * * <nl> * creates ( but does not start ) a new stopwatch , using the specified time <nl> * source . <nl> + * <nl> + * @ deprecated use { @ link stopwatch # createunstarted ( ticker ) } instead . <nl> * / <nl> - <nl> + @ deprecated <nl> public stopwatch ( ticker ticker ) { <nl> this . ticker = checknotnull ( ticker , " ticker " ) ; <nl> }
public final class futures { <nl> for ( optional < v > element : values ) { <nl> result . add ( element ! = null ? element . ornull ( ) : null ) ; <nl> } <nl> - <nl> - return result ; <nl> + return collections . unmodifiablelist ( result ) ; <nl> } <nl> } ) ; <nl> }
public final class range < c extends comparable > implements predicate < c > , serializ <nl> * <nl> * @ throws illegalargumentexception if neither this range nor the domain has a lower bound , or if <nl> * neither has an upper bound <nl> - * @ deprecated use { @ code contiguousset . create ( range , domain ) } instead . <nl> + * @ deprecated use { @ code contiguousset . create ( range , domain ) } . to be removed in guava num . 0 . <nl> * / <nl> - <nl> @ beta <nl> @ gwtcompatible ( serializable = false ) <nl> @ deprecated
public class immutablesetmultimap < k , v > <nl> * its iterator traverses the values for the first key , the values for the <nl> * second key , and so on . <nl> * / <nl> - <nl> @ override public immutableset < entry < k , v > > entries ( ) { <nl> immutableset < entry < k , v > > result = entries ; <nl> return ( result = = null ) <nl> - ? ( entries = immutableset . copyof ( super . entries ( ) ) ) <nl> + ? ( entries = new entryset < k , v > ( this ) ) <nl> : result ; <nl> } <nl> + <nl> + private static final class entryset < k , v > extends immutableset < entry < k , v > > { <nl> + private transient final immutablesetmultimap < k , v > multimap ; <nl> + <nl> + entryset ( immutablesetmultimap < k , v > multimap ) { <nl> + this . multimap = multimap ; <nl> + } <nl> + <nl> + @ override <nl> + public boolean contains ( @ nullable object object ) { <nl> + if ( object instanceof entry ) { <nl> + entry < ? , ? > entry = ( entry < ? , ? > ) object ; <nl> + return multimap . containsentry ( entry . getkey ( ) , entry . getvalue ( ) ) ; <nl> + } <nl> + return false ; <nl> + } <nl> + <nl> + @ override <nl> + public int size ( ) { <nl> + return multimap . size ( ) ; <nl> + } <nl> + <nl> + @ override <nl> + public unmodifiableiterator < entry < k , v > > iterator ( ) { <nl> + return multimap . entryiterator ( ) ; <nl> + } <nl> + <nl> + @ override <nl> + boolean ispartialview ( ) { <nl> + return false ; <nl> + } <nl> + } <nl> } <nl>  <nl> mmm a / guava / src / com / google / common / collect / immutablesetmultimap . java <nl> ppp b / guava / src / com / google / common / collect / immutablesetmultimap . java <nl>
public class immutablesetmultimap < k , v > <nl> * its iterator traverses the values for the first key , the values for the <nl> * second key , and so on . <nl> * / <nl> - <nl> @ override public immutableset < entry < k , v > > entries ( ) { <nl> immutableset < entry < k , v > > result = entries ; <nl> return ( result = = null ) <nl> - ? ( entries = immutableset . copyof ( super . entries ( ) ) ) <nl> + ? ( entries = new entryset < k , v > ( this ) ) <nl> : result ; <nl> } <nl> + <nl> + private static final class entryset < k , v > extends immutableset < entry < k , v > > { <nl> + private transient final immutablesetmultimap < k , v > multimap ; <nl> + <nl> + entryset ( immutablesetmultimap < k , v > multimap ) { <nl> + this . multimap = multimap ; <nl> + } <nl> + <nl> + @ override <nl> + public boolean contains ( @ nullable object object ) { <nl> + if ( object instanceof entry ) { <nl> + entry < ? , ? > entry = ( entry < ? , ? > ) object ; <nl> + return multimap . containsentry ( entry . getkey ( ) , entry . getvalue ( ) ) ; <nl> + } <nl> + return false ; <nl> + } <nl> + <nl> + @ override <nl> + public int size ( ) { <nl> + return multimap . size ( ) ; <nl> + } <nl> + <nl> + @ override <nl> + public unmodifiableiterator < entry < k , v > > iterator ( ) { <nl> + return multimap . entryiterator ( ) ; <nl> + } <nl> + <nl> + @ override <nl> + boolean ispartialview ( ) { <nl> + return false ; <nl> + } <nl> + } <nl>  <nl> / * * <nl> * @ serialdata number of distinct keys , and then for each distinct key : the
public class nullpointertestertest extends testcase { <nl> assert . that ( expected . getmessage ( ) ) . contains ( " inner class " ) ; <nl> } <nl> } <nl> - <nl> - / * <nl> - * <nl> - * <nl> - * must come back and finish . <nl> - * <nl> - * / <nl> - <nl> }
public final class internetdomainname { <nl> return pieces . length = = num & & tldpatterns . under . contains ( pieces [ 1 ] ) ; <nl> } <nl>  <nl> - <nl> + / * * <nl> + * returns the domain name , normalized to all lower case . <nl> + * / <nl> @ override <nl> public string tostring ( ) { <nl> - return objects . tostringhelper ( this ) . add ( " name " , name ) . tostring ( ) ; <nl> + return name ; <nl> } <nl>  <nl> / * *
public final class unsignedinteger extends number implements comparable < unsigned <nl> * num . <nl> * / <nl> @ deprecated <nl> + @ beta <nl> public static unsignedinteger asunsigned ( int value ) { <nl> - <nl> return fromintbits ( value ) ; <nl> } <nl>  <nl>
public final class unsignedlong extends number implements comparable < unsignedlon <nl> * <nl> * < p > put another way , if { @ code value } is negative , the returned result will be equal to <nl> * { @ code num ^ 64 + value } ; otherwise , the returned result will be equal to { @ code value } . <nl> + * <nl> + * @ deprecated use { @ link # fromlongbits ( long ) } . this method is scheduled for deletion in january <nl> + * num . <nl> * / <nl> + @ deprecated <nl> public static unsignedlong asunsigned ( long value ) { <nl> - <nl> return fromlongbits ( value ) ; <nl> } <nl>  <nl>
public final class unsignedlong extends number implements comparable < unsignedlon <nl> * { @ link character # max_radix } <nl> * / <nl> public static unsignedlong valueof ( string string , int radix ) { <nl> - return asunsigned ( unsignedlongs . parseunsignedlong ( string , radix ) ) ; <nl> + return fromlongbits ( unsignedlongs . parseunsignedlong ( string , radix ) ) ; <nl> } <nl>  <nl> / * * <nl> * returns the result of adding this and { @ code val } . if the result would have more than num bits , <nl> * returns the low num bits of the result . <nl> + * <nl> + * @ deprecated use { @ link # plus ( unsignedlong ) } . this method is scheduled for deletion in january <nl> + * num . <nl> * / <nl> + @ deprecated <nl> public unsignedlong add ( unsignedlong val ) { <nl> - <nl> return plus ( val ) ; <nl> } <nl>  <nl>
public final class unsignedlong extends number implements comparable < unsignedlon <nl> / * * <nl> * returns the result of subtracting this and { @ code val } . if the result would be negative , <nl> * returns the low num bits of the result . <nl> + * <nl> + * @ deprecated use { @ link # minus ( unsignedlong ) } . this method is scheduled for deletion in <nl> + * january num . <nl> * / <nl> + @ deprecated <nl> public unsignedlong subtract ( unsignedlong val ) { <nl> - <nl> return minus ( val ) ; <nl> } <nl>  <nl>
public final class unsignedlong extends number implements comparable < unsignedlon <nl> / * * <nl> * returns the result of multiplying this and { @ code val } . if the result would have more than num <nl> * bits , returns the low num bits of the result . <nl> + * <nl> + * @ deprecated use { @ link # times ( unsignedlong ) } . this method is scheduled for deletion in <nl> + * january num . <nl> * / <nl> + @ deprecated <nl> public unsignedlong multiply ( unsignedlong val ) { <nl> - <nl> return times ( val ) ; <nl> } <nl>  <nl>
public final class unsignedlong extends number implements comparable < unsignedlon <nl>  <nl> / * * <nl> * returns the result of dividing this by { @ code val } . <nl> + * <nl> + * @ deprecated use { @ link # dividedby ( unsignedlong ) } . this method is scheduled for deletion in <nl> + * january num . <nl> * / <nl> + @ deprecated <nl> public unsignedlong divide ( unsignedlong val ) { <nl> - <nl> return dividedby ( val ) ; <nl> } <nl>  <nl>
public final class unsignedlong extends number implements comparable < unsignedlon <nl>  <nl> / * * <nl> * returns the remainder of dividing this by { @ code val } . <nl> + * <nl> + * @ deprecated use { @ link # mod ( unsignedlong ) } . this method is scheduled for deletion in january <nl> + * num . <nl> * / <nl> + @ deprecated <nl> public unsignedlong remainder ( unsignedlong val ) { <nl> - <nl> return mod ( val ) ; <nl> }
public final class unsignedinteger extends number implements comparable < unsigned <nl> / * * <nl> * returns the result of adding this and { @ code val } . if the result would have more than num bits , <nl> * returns the low num bits of the result . <nl> + * <nl> + * @ deprecated use { @ link # plus ( unsignedinteger ) } . this method is scheduled for deletion in <nl> + * january num . <nl> * / <nl> + @ deprecated <nl> public unsignedinteger add ( unsignedinteger val ) { <nl> - <nl> return plus ( val ) ; <nl> } <nl>  <nl>
public final class unsignedinteger extends number implements comparable < unsigned <nl> / * * <nl> * returns the result of subtracting this and { @ code val } . if the result would be negative , <nl> * returns the low num bits of the result . <nl> + * <nl> + * @ deprecated use { @ link # minus ( unsignedinteger ) } . this method is scheduled for deletion in <nl> + * january num . <nl> * / <nl> + @ deprecated <nl> public unsignedinteger subtract ( unsignedinteger val ) { <nl> - <nl> return minus ( val ) ; <nl> } <nl>  <nl>
public final class unsignedinteger extends number implements comparable < unsigned <nl> / * * <nl> * returns the result of multiplying this and { @ code val } . if the result would have more than num <nl> * bits , returns the low num bits of the result . <nl> + * <nl> + * @ deprecated use { @ link # times ( unsignedinteger ) } . this method is scheduled for deletion in <nl> + * january num . <nl> * / <nl> + @ deprecated <nl> public unsignedinteger multiply ( unsignedinteger val ) { <nl> - <nl> return times ( val ) ; <nl> } <nl>  <nl>
public final class unsignedinteger extends number implements comparable < unsigned <nl>  <nl> / * * <nl> * returns the result of dividing this by { @ code val } . <nl> + * <nl> + * @ deprecated use { @ link # dividedby ( unsignedinteger ) } . this method is scheduled for deletion in <nl> + * january num . <nl> * / <nl> + @ deprecated <nl> public unsignedinteger divide ( unsignedinteger val ) { <nl> - <nl> return dividedby ( val ) ; <nl> } <nl>  <nl>
public final class unsignedinteger extends number implements comparable < unsigned <nl> * @ throws arithmeticexception if { @ code val } is zero <nl> * @ since num . 0 <nl> * / <nl> + @ checkreturnvalue <nl> public unsignedinteger dividedby ( unsignedinteger val ) { <nl> return fromintbits ( unsignedints . divide ( value , checknotnull ( val ) . value ) ) ; <nl> } <nl>  <nl> / * * <nl> * returns the remainder of dividing this by { @ code val } . <nl> + * <nl> + * @ deprecated use { @ link # mod ( unsignedinteger ) } . this method is scheduled for deletion in <nl> + * january num . <nl> * / <nl> + @ deprecated <nl> public unsignedinteger remainder ( unsignedinteger val ) { <nl> - <nl> return mod ( val ) ; <nl> } <nl>  <nl>
enum bloomfilterstrategies implements bloomfilter . strategy { <nl> murmur128_mitz_32 ( ) { <nl> @ override public < t > boolean put ( t object , funnel < ? super t > funnel , <nl> int numhashfunctions , bitarray bits ) { <nl> - <nl> - long hash64 = hashing . murmur3_128 ( ) . newhasher ( ) . putobject ( object , funnel ) . hash ( ) . aslong ( ) ; <nl> + long hash64 = hashing . murmur3_128 ( ) . hashobject ( object , funnel ) . aslong ( ) ; <nl> int hash1 = ( int ) hash64 ; <nl> int hash2 = ( int ) ( hash64 > > > num ) ; <nl> boolean bitschanged = false ; <nl>
public final class immutableclasstoinstancemap < b > extends <nl> @ override <nl> @ suppresswarnings ( " unchecked " ) / / value could not get in if not a t <nl> @ nullable <nl> - <nl> - public < t extends b > t getinstance ( @ nullable class < t > type ) { <nl> - return ( t ) delegate . get ( type ) ; <nl> + public < t extends b > t getinstance ( class < t > type ) { <nl> + return ( t ) delegate . get ( checknotnull ( type ) ) ; <nl> } <nl>  <nl> / * *
public enum caseformat { <nl> } <nl>  <nl> / * * <nl> - * converts the specified { @ code string s } from this format to the specified { @ code format } . a <nl> - * " best effort " approach is taken ; if { @ code s } does not conform to the assumed format , then the <nl> - * behavior of this method is undefined but we make a reasonable effort at converting anyway . <nl> + * converts the specified { @ code string str } from this format to the specified { @ code format } . a <nl> + * " best effort " approach is taken ; if { @ code str } does not conform to the assumed format , then <nl> + * the behavior of this method is undefined but we make a reasonable effort at converting anyway . <nl> * / <nl> - public string to ( caseformat format , string s ) { <nl> + public final string to ( caseformat format , string str ) { <nl> checknotnull ( format ) ; <nl> - checknotnull ( s ) ; <nl> - <nl> - if ( format = = this ) { <nl> - return s ; <nl> - } <nl> - <nl> - <nl> - <nl> - / / optimize cases where no camel conversion is required <nl> - switch ( this ) { <nl> - case lower_hyphen : <nl> - switch ( format ) { <nl> - case lower_underscore : <nl> - return s . replace ( ' - ' , ' _ ' ) ; <nl> - case upper_underscore : <nl> - return ascii . touppercase ( s . replace ( ' - ' , ' _ ' ) ) ; <nl> - } <nl> - break ; <nl> - case lower_underscore : <nl> - switch ( format ) { <nl> - case lower_hyphen : <nl> - return s . replace ( ' _ ' , ' - ' ) ; <nl> - case upper_underscore : <nl> - return ascii . touppercase ( s ) ; <nl> - } <nl> - break ; <nl> - case upper_underscore : <nl> - switch ( format ) { <nl> - case lower_hyphen : <nl> - return ascii . tolowercase ( s . replace ( ' _ ' , ' - ' ) ) ; <nl> - case lower_underscore : <nl> - return ascii . tolowercase ( s ) ; <nl> - } <nl> - break ; <nl> - } <nl> + checknotnull ( str ) ; <nl> + return ( format = = this ) ? str : convert ( format , str ) ; <nl> + } <nl>  <nl> - / / otherwise , deal with camel conversion <nl> + / * * <nl> + * enum values can override for performance reasons . <nl> + * / <nl> + string convert ( caseformat format , string s ) { <nl> + / / deal with camel conversion <nl> stringbuilder out = null ; <nl> int i = num ; <nl> int j = - 1 ; <nl>
public abstract class immutableset < e > extends immutablecollection < e > <nl> * @ throws nullpointerexception if any of { @ code elements } is null <nl> * / <nl> public static < e > immutableset < e > copyof ( iterator < ? extends e > elements ) { <nl> - <nl> - / / worth it ? <nl> - return copyfromcollection ( lists . newarraylist ( elements ) ) ; <nl> + / / we special - case for num or num elements , but anything further is madness . <nl> + if ( ! elements . hasnext ( ) ) { <nl> + return of ( ) ; <nl> + } <nl> + e first = elements . next ( ) ; <nl> + if ( ! elements . hasnext ( ) ) { <nl> + return of ( first ) ; <nl> + } else { <nl> + return new immutableset . builder < e > ( ) <nl> + . add ( first ) <nl> + . addall ( elements ) <nl> + . build ( ) ; <nl> + } <nl> } <nl>  <nl> / * *
final class regularimmutablesortedset < e > extends immutablesortedset < e > { <nl> } catch ( classcastexception e ) { <nl> return - 1 ; <nl> } <nl> - <nl> - / / sanity for inconsistent comparators . <nl> - <nl> - / / the equals ( ) check is needed when the comparator isn ' t compatible with <nl> - / / equals ( ) . <nl> - return ( position > = num & & elements . get ( position ) . equals ( target ) ) <nl> - ? position : - 1 ; <nl> + return ( position > = num ) ? position : - 1 ; <nl> } <nl>  <nl> @ override immutablelist < e > createaslist ( ) {
public final class equivalences { <nl> * <nl> * @ since num . 0 ( present null - friendly behavior ) <nl> * @ since num . 0 ( otherwise ) <nl> + * @ deprecated this method has been moved to { @ link equivalence # equals } . this method is scheduled <nl> + * to be removed in guava release num . 0 . <nl> * / <nl> - <nl> + @ deprecated <nl> public static equivalence < object > equals ( ) { <nl> return equivalence . equals . instance ; <nl> } <nl>
public final class equivalences { <nl> * returns an equivalence that uses { @ code = = } to compare values and { @ link <nl> * system # identityhashcode ( object ) } to compute the hash code . { @ link equivalence # equivalent } <nl> * returns { @ code true } if { @ code a = = b } , including in the case that a and b are both null . <nl> + * <nl> + * @ deprecated this method has been moved to { @ link equivalence # identity } . this method is schedule <nl> + * to be removed in guava release num . 0 . <nl> * / <nl> - <nl> + @ deprecated <nl> public static equivalence < object > identity ( ) { <nl> return equivalence . identity . instance ; <nl> }
public class mapstest extends testcase { <nl> / / now test values loaded from a stream . <nl> string props = " test\n second = num \n third item : a short phrase " ; <nl>  <nl> - <nl> - testprop . load ( new java . io . stringbufferinputstream ( props ) ) ; <nl> + testprop . load ( new stringreader ( props ) ) ; <nl>  <nl> result = maps . fromproperties ( testprop ) ; <nl> assertequals ( 4 , result . size ( ) ) ; <nl>
public class mapstest extends testcase { <nl> testprop = new properties ( system . getproperties ( ) ) ; <nl> string override = " test\njava . version : hidden " ; <nl>  <nl> - <nl> - testprop . load ( new java . io . stringbufferinputstream ( override ) ) ; <nl> + testprop . load ( new stringreader ( override ) ) ; <nl>  <nl> result = maps . fromproperties ( testprop ) ; <nl> asserttrue ( result . size ( ) > num ) ; <nl> mmm a / guava / src / com / google / common / base / strings . java <nl> ppp b / guava / src / com / google / common / base / strings . java <nl>
import javax . annotation . nullable ; <nl>  <nl> / * * <nl> * a wrapper class for unsigned { @ code long } values , supporting arithmetic operations . <nl> - * <nl> + * <nl> * < p > in some cases , when speed is more important than code readability , it may be faster simply to <nl> * treat primitive { @ code long } values as unsigned , using the methods from { @ link unsignedlongs } . <nl> - * <nl> - * < p > < b > please do not extend this class ; it will be made final in the near future . < / b > <nl> - * <nl> + * <nl> * < p > see the guava user guide article on < a href = <nl> * " http : / / code . google . com / p / guava - libraries / wiki / primitivesexplained # unsigned_support " > <nl> * unsigned primitive utilities < / a > . <nl> - * <nl> + * <nl> * @ author louis wasserman <nl> * @ author colin evans <nl> * @ since num . 0 <nl> * / <nl> @ beta <nl> @ gwtcompatible ( serializable = true ) <nl> - public class unsignedlong extends number implements comparable < unsignedlong > , serializable { <nl> - <nl> + public final class unsignedlong extends number implements comparable < unsignedlong > , serializable { <nl>  <nl> private static final long unsigned_mask = num x7fffffffffffffffl ; <nl>  <nl>
public abstract class charmatcher implements predicate < character > { <nl> return indexin ( sequence ) = = - 1 ; <nl> } <nl>  <nl> - <nl> - <nl> / * * <nl> * returns the <nl> * matching character is present . <nl> mmm a / guava / src / com / google / common / base / function . java <nl> ppp b / guava / src / com / google / common / base / function . java <nl>
public class filebackedoutputstreamtest extends iotestcase { <nl> testthreshold ( 1000 , num , false , false ) ; <nl> } <nl>  <nl> - <nl> - / / filebackedoutputstream and use that to test that the file was actually deleted <nl> - / / on finalize <nl> + public void testfinalizedeletesfile ( ) throws exception { <nl> + byte [ ] data = newprefilledbytearray ( 100 ) ; <nl> + filebackedoutputstream out = new filebackedoutputstream ( 0 , true ) ; <nl> + <nl> + write ( out , data , num , num , true ) ; <nl> + final file file = out . getfile ( ) ; <nl> + assertequals ( 100 , file . length ( ) ) ; <nl> + asserttrue ( file . exists ( ) ) ; <nl> + out . close ( ) ; <nl> + <nl> + / / make sure that finalize deletes the file <nl> + out = null ; <nl> + <nl> + / / times out and throws runtimeexception on failure <nl> + gcfinalization . awaitdone ( new gcfinalization . finalizationpredicate ( ) { <nl> + @ override <nl> + public boolean isdone ( ) { <nl> + return ! file . exists ( ) ; <nl> + } <nl> + } ) ; <nl> + } <nl>  <nl> public void testthreshold_resetonfinalize ( ) throws exception { <nl> testthreshold ( 0 , num , true , true ) ;
import java . io . inputstream ; <nl> import java . io . outputstream ; <nl> import java . util . arrays ; <nl>  <nl> - <nl> / * * <nl> * unit tests for { @ link filebackedoutputstream } . <nl> * <nl>
import com . google . common . annotations . visiblefortesting ; <nl> * @ since num . 0 <nl> * / <nl> public final class doublemath { <nl> - <nl> - <nl> / * <nl> * this method returns a value y such that rounding y down ( towards zero ) gives the same result <nl> * as rounding x according to the specified mode . <nl> * / <nl> static double roundintermediate ( double x , roundingmode mode ) { <nl> - if ( getexponent ( x ) = = max_double_exponent + num ) { <nl> + if ( ! isfinite ( x ) ) { <nl> throw new arithmeticexception ( " input is infinite or nan " ) ; <nl> } <nl> switch ( mode ) { <nl> mmm a / guava / src / com / google / common / math / doubleutils . java <nl> ppp b / guava / src / com / google / common / math / doubleutils . java <nl>
<nl> - / * <nl> - * copyright ( c ) num the guava authors <nl> - * <nl> - * licensed under the apache license , version num . 0 ( the " license " ) ; <nl> - * you may not use this file except in compliance with the license . <nl> - * you may obtain a copy of the license at <nl> - * <nl> - * http : / / www . apache . org / licenses / license - 2 . 0 <nl> - * <nl> - * unless required by applicable law or agreed to in writing , software <nl> - * distributed under the license is distributed on an " as is " basis , <nl> - * without warranties or conditions of any kind , either express or implied . <nl> - * see the license for the specific language governing permissions and <nl> - * limitations under the license . <nl> - * / <nl> - <nl> - package com . google . common . base ; <nl> - <nl> - import javax . annotation . nullable ; <nl> - <nl> - import com . google . common . annotations . gwtcompatible ; <nl> - <nl> - / * * <nl> - * common interface for { @ link holder } and { @ link optional } ; most users should have no <nl> - * need to refer to this type directly . <nl> - * <nl> - * @ author kevin bourrillion <nl> - * / <nl> - @ gwtcompatible <nl> - interface baseholder < t > { <nl> - / * * <nl> - * returns { @ code true } if this holder contains a ( non - null ) instance . <nl> - * / <nl> - boolean ispresent ( ) ; <nl> - <nl> - <nl> - <nl> - / * * <nl> - * returns the contained instance , which must be present . if the instance might be <nl> - * absent , use { @ link # or ( object ) } or { @ link # ornull } instead . <nl> - * <nl> - * @ throws illegalstateexception if the instance is absent ( { @ link # ispresent } returns <nl> - * { @ code false } ) <nl> - * / <nl> - t get ( ) ; <nl> - <nl> - / * * <nl> - * returns the contained instance if it is present ; { @ code defaultvalue } otherwise . if <nl> - * no default value should be required because the instance is known to be present , use <nl> - * { @ link # get ( ) } instead . for a default value of { @ code null } , use { @ link # ornull } . <nl> - * / <nl> - t or ( t defaultvalue ) ; <nl> - <nl> - / * * <nl> - * returns the contained instance if it is present ; { @ code null } otherwise . if the <nl> - * instance is known to be present , use { @ link # get ( ) } instead . <nl> - * / <nl> - @ nullable t ornull ( ) ; <nl> - } <nl> mmm a / guava / src / com / google / common / base / optional . java <nl> ppp b / guava / src / com / google / common / base / optional . java <nl>
import java . util . comparator ; <nl> * @ since guava release num <nl> * / <nl> @ beta <nl> + @ gwtcompatible <nl> public final class unsignedlongs { <nl> - <nl> private unsignedlongs ( ) { } <nl>  <nl> public static final long max_value = - 1l ; / / equivalent to num ^ 64 - num <nl>
public final class guavaasserts { <nl> * assert the equality of two objects <nl> * / <nl> public static void assertequals ( string message , object o1 , object o2 ) { <nl> - if ( o1 ! = o2 ) { <nl> - asserttrue ( message , o1 . equals ( o2 ) ) ; <nl> + if ( o1 = = null ) { <nl> + asserttrue ( message , o2 = = null ) ; <nl> + return ; <nl> } <nl> + asserttrue ( message , o1 . equals ( o2 ) ) ; <nl> } <nl>  <nl> / * *
<nl> - / * <nl> - * copyright ( c ) num the guava authors <nl> - * <nl> - * licensed under the apache license , version num . 0 ( the " license " ) ; <nl> - * you may not use this file except in compliance with the license . <nl> - * you may obtain a copy of the license at <nl> - * <nl> - * http : / / www . apache . org / licenses / license - 2 . 0 <nl> - * <nl> - * unless required by applicable law or agreed to in writing , software <nl> - * distributed under the license is distributed on an " as is " basis , <nl> - * without warranties or conditions of any kind , either express or implied . <nl> - * see the license for the specific language governing permissions and <nl> - * limitations under the license . <nl> - * / <nl> - <nl> - package com . google . common . base ; <nl> - <nl> - import static com . google . common . base . preconditions . checknotnull ; <nl> - import static com . google . common . base . preconditions . checkstate ; <nl> - <nl> - import com . google . common . annotations . beta ; <nl> - import com . google . common . annotations . gwtcompatible ; <nl> - <nl> - import java . util . concurrent . atomic . atomicreference ; <nl> - <nl> - import javax . annotation . nullable ; <nl> - <nl> - / * * <nl> - * a mutable object that may contain a reference to another object . an instance of this <nl> - * type either holds some non - null reference , or holds nothing ; it is never said to " hold <nl> - * { @ code null } " . the instance that is held can be set , unset or changed at any time . <nl> - * <nl> - * < p > this class is the mutable version of { @ link optional } . it is also very similar to <nl> - * { @ link atomicreference } ( without the atomic operations and thread - safety ) . <nl> - * <nl> - * < p > one common use of a { @ code holder } is to receive a result from an anonymous inner <nl> - * class : < pre class = " code " > { @ code <nl> - * <nl> - * final holder < result > resultholder = holder . absent ( ) ; <nl> - * doit ( new innerclass ( ) { <nl> - * public void foo ( ) { <nl> - * result result = . . . <nl> - * resultholder . set ( result ) ; <nl> - * } <nl> - * } ) ; } < / pre > <nl> - * <nl> - * < b > note : < / b > two { @ code holder } instances are never considered equal , even if they are <nl> - * holding the same instance at the time . <nl> - * <nl> - * @ author kurt alfred kluever <nl> - * @ author kevin bourrillion <nl> - * @ since guava release num <nl> - * / <nl> - @ beta <nl> - @ gwtcompatible <nl> - public final class holder < t > implements baseholder < t > { <nl> - / / static factories <nl> - <nl> - / * * <nl> - * returns a new , modifiable holder that initially does not hold any instance . <nl> - * / <nl> - public static < t > holder < t > absent ( ) { <nl> - return fromnullable ( null ) ; <nl> - } <nl> - <nl> - / * * <nl> - * returns a new , modifiable holder that initially holds the instance { @ code <nl> - * initialreference } . <nl> - * / <nl> - public static < t > holder < t > of ( t initialreference ) { <nl> - return fromnullable ( checknotnull ( initialreference ) ) ; <nl> - } <nl> - <nl> - / * * <nl> - * if { @ code nullablereference } is non - null , returns a new { @ code holder } instance <nl> - * containing that reference ; otherwise returns { @ link holder # absent } . <nl> - * / <nl> - public static < t > holder < t > fromnullable ( @ nullable t nullablereference ) { <nl> - return new holder < t > ( nullablereference ) ; <nl> - } <nl> - <nl> - / / fields <nl> - <nl> - @ nullable private t instance ; <nl> - <nl> - / / constructors <nl> - <nl> - private holder ( @ nullable t initialreference ) { <nl> - this . instance = initialreference ; <nl> - } <nl> - <nl> - / / baseholder methods ( accessors ) <nl> - <nl> - @ override public boolean ispresent ( ) { <nl> - return instance ! = null ; <nl> - } <nl> - <nl> - @ override public t get ( ) { <nl> - checkstate ( ispresent ( ) ) ; <nl> - return instance ; <nl> - } <nl> - <nl> - @ override public t or ( t defaultvalue ) { <nl> - checknotnull ( defaultvalue , " use ornull ( ) instead of or ( null ) " ) ; <nl> - return ispresent ( ) ? instance : defaultvalue ; <nl> - } <nl> - <nl> - @ override @ nullable public t ornull ( ) { <nl> - return instance ; <nl> - } <nl> - <nl> - / / mutators <nl> - <nl> - / * * <nl> - * sets the contents of this holder to the given non - null reference . <nl> - * / <nl> - public void set ( t instance ) { <nl> - setnullable ( checknotnull ( instance ) ) ; <nl> - } <nl> - <nl> - / * * <nl> - * removes the reference from the holder if one exists . <nl> - * / <nl> - public void clear ( ) { <nl> - setnullable ( null ) ; <nl> - } <nl> - <nl> - / * * <nl> - * sets the contents of this holder to the given instance if it is non - null ; <nl> - * clears it otherwise . <nl> - * / <nl> - public void setnullable ( @ nullable t instance ) { <nl> - this . instance = instance ; <nl> - } <nl> - <nl> - / / object overrides <nl> - <nl> - / * * <nl> - * returns a string representation for this holder . the form of this string representation is <nl> - * unspecified . <nl> - * / <nl> - @ override public string tostring ( ) { <nl> - return ispresent ( ) ? " holder . of ( " + instance + " ) " : " holder . absent ( ) " ; <nl> - } <nl> - <nl> - <nl> - <nl> - / * * <nl> - * old name of { @ link # absent } . <nl> - * / <nl> - public static < t > holder < t > unset ( ) { <nl> - return absent ( ) ; <nl> - } <nl> - <nl> - / * * <nl> - * old name of { @ link # ispresent } . <nl> - * / <nl> - public boolean isset ( ) { <nl> - return ispresent ( ) ; <nl> - } <nl> - }
public abstract class optional < t > implements baseholder < t > { <nl>  <nl> private optional ( ) { } <nl>  <nl> - / * * <nl> - * returns the contained non - null reference if it is present ; { @ code defaultvalue } otherwise . <nl> - * <nl> - * @ deprecated use { @ code ornull ( ) } for { @ code get ( null ) } ; { @ code or ( t ) } otherwise <nl> - * / <nl> - <nl> - @ deprecated @ nullable public abstract t get ( @ nullable t defaultvalue ) ; <nl> - <nl> / * * <nl> * returns this { @ code optional } if it has a value present ; { @ code secondchoice } <nl> * otherwise . <nl>
package com . google . common . collect ; <nl>  <nl> import com . google . gwt . core . client . entrypoint ; <nl>  <nl> - import java . util . arrays ; <nl> - import java . util . list ; <nl> - <nl> / * * <nl> - * a dummy entry point that accesses all gwt classes in <nl> - * { @ code com . google . common . collect } . <nl> + * a dummy entry point of the test module . <nl> * <nl> * @ author hayward chan <nl> * / <nl> - @ suppresswarnings ( " unchecked " ) <nl> public class testmoduleentrypoint implements entrypoint { <nl>  <nl> - @ override <nl> - public void onmoduleload ( ) { <nl> - <nl> - / / files covered by gwt_srcs <nl> - @ suppresswarnings ( " unused " ) <nl> - list < class < ? > > allclasses = arrays . < class < ? > > aslist ( <nl> - abstractindexedlistiterator . class , <nl> - abstractiterator . class , <nl> - abstractlistmultimap . class , <nl> - abstractmapentry . class , <nl> - abstractmultimap . class , <nl> - abstractmultiset . class , <nl> - abstractsetmultimap . class , <nl> - abstractsortedsetmultimap . class , <nl> - bimap . class , <nl> - byfunctionordering . class , <nl> - classtoinstancemap . class , <nl> - collections2 . class , <nl> - comparisonchain . class , <nl> - comparatorordering . class , <nl> - compoundordering . class , <nl> - computationexception . class , <nl> - constraint . class , <nl> - constraints . class , <nl> - emptyimmutablelistmultimap . class , <nl> - emptyimmutablemultiset . class , <nl> - emptyimmutablesetmultimap . class , <nl> - explicitordering . class , <nl> - forwardingcollection . class , <nl> - forwardingconcurrentmap . class , <nl> - forwardingiterator . class , <nl> - forwardinglist . class , <nl> - forwardinglistiterator . class , <nl> - forwardinglistmultimap . class , <nl> - forwardingmap . class , <nl> - forwardingmapentry . class , <nl> - forwardingmultimap . class , <nl> - forwardingmultiset . class , <nl> - forwardingobject . class , <nl> - forwardingqueue . class , <nl> - forwardingset . class , <nl> - forwardingsetmultimap . class , <nl> - forwardingsortedmap . class , <nl> - forwardingsortedset . class , <nl> - forwardingsortedsetmultimap . class , <nl> - genericmapmaker . class , <nl> - hashing . class , <nl> - immutableentry . class , <nl> - immutablelistmultimap . class , <nl> - lexicographicalordering . class , <nl> - listmultimap . class , <nl> - lists . class , <nl> - mapconstraint . class , <nl> - mapconstraints . class , <nl> - mapdifference . class , <nl> - maps . class , <nl> - multimap . class , <nl> - multiset . class , <nl> - multisets . class , <nl> - naturalordering . class , <nl> - nullsfirstordering . class , <nl> - nullslastordering . class , <nl> - objectarrays . class , <nl> - ordering . class , <nl> - peekingiterator . class , <nl> - reversenaturalordering . class , <nl> - reverseordering . class , <nl> - setmultimap . class , <nl> - sortedsetmultimap . class , <nl> - unmodifiableiterator . class , <nl> - usingtostringordering . class , <nl> - <nl> - / / classes covered by : generated_supersource <nl> - abstractbimap . class , <nl> - abstractmapbasedmultiset . class , <nl> - arraylistmultimap . class , <nl> - enumbimap . class , <nl> - enumhashbimap . class , <nl> - enummultiset . class , <nl> - hashbimap . class , <nl> - hashmultimap . class , <nl> - hashmultiset . class , <nl> - immutablelistmultimap . class , <nl> - immutablemultimap . class , <nl> - immutablemultiset . class , <nl> - immutablesetmultimap . class , <nl> - iterables . class , <nl> - iterators . class , <nl> - linkedhashmultimap . class , <nl> - linkedhashmultiset . class , <nl> - linkedlistmultimap . class , <nl> - multimaps . class , <nl> - objectarrays . class , <nl> - sets . class , <nl> - synchronized . class , <nl> - treemultimap . class , <nl> - treemultiset . class ) ; <nl> + @ override public void onmoduleload ( ) { <nl> } <nl> - <nl> - / / reference that make sure an rpc interface is referenced . <nl> }
public abstract class genericmapmaker < k0 , v0 > { <nl> / * * <nl> * see { @ link mapmaker # expiration } . <nl> * / <nl> - <nl> - public abstract genericmapmaker < k0 , v0 > expiration ( long duration , timeunit unit ) ; <nl> + @ deprecated <nl> + public <nl> + abstract genericmapmaker < k0 , v0 > expiration ( long duration , timeunit unit ) ; <nl>  <nl> / * * <nl> * see { @ link mapmaker # expireafterwrite } . <nl> mmm a / guava - gwt / src - super / com / google / common / collect / super / com / google / common / collect / mapmaker . java <nl> ppp b / guava - gwt / src - super / com / google / common / collect / super / com / google / common / collect / mapmaker . java <nl>
public abstract class genericmapmaker < k0 , v0 > { <nl> / * * <nl> * see { @ link mapmaker # expiration } . <nl> * / <nl> - <nl> - public abstract genericmapmaker < k0 , v0 > expiration ( long duration , timeunit unit ) ; <nl> + @ deprecated <nl> + public <nl> + abstract genericmapmaker < k0 , v0 > expiration ( long duration , timeunit unit ) ; <nl>  <nl> / * * <nl> * see { @ link mapmaker # expireafterwrite } . <nl> mmm a / guava / src / com / google / common / collect / mapevictionlistener . java <nl> ppp b / guava / src / com / google / common / collect / mapevictionlistener . java <nl>
package com . google . common . base ; <nl>  <nl> import com . google . gwt . core . client . entrypoint ; <nl>  <nl> - import java . util . arrays ; <nl> - import java . util . list ; <nl> - <nl> / * * <nl> - * a dummy entry point that accesses all gwt classes in <nl> - * { @ code com . google . common . base } . <nl> + * an empty entry point for testing gwt compatibility . <nl> * <nl> * @ author hayward chan <nl> * / <nl> - @ suppresswarnings ( " unchecked " ) <nl> public class testmoduleentrypoint implements entrypoint { <nl>  <nl> - @ override <nl> - public void onmoduleload ( ) { <nl> - <nl> - list < class < ? > > allclasses = arrays . < class < ? > > aslist ( <nl> - charmatcher . class , <nl> - equivalence . class , <nl> - equivalences . class , <nl> - function . class , <nl> - functions . class , <nl> - joiner . class , <nl> - objects . class , <nl> - preconditions . class , <nl> - predicate . class , <nl> - predicates . class , <nl> - strings . class , <nl> - splitter . class , <nl> - supplier . class ) ; <nl> + @ override public void onmoduleload ( ) { <nl> } <nl> } <nl> mmm a / guava - gwt / test / com / google / common / net / testmoduleentrypoint . java <nl> ppp b / guava - gwt / test / com / google / common / net / testmoduleentrypoint . java <nl>
package com . google . common . net ; <nl>  <nl> import com . google . gwt . core . client . entrypoint ; <nl>  <nl> - import java . util . arrays ; <nl> - import java . util . list ; <nl> - <nl> / * * <nl> + * an empty entry point for testing gwt compatibility . <nl> + * <nl> * @ author hayward chan <nl> * / <nl> public class testmoduleentrypoint implements entrypoint { <nl>  <nl> - @ override <nl> - public void onmoduleload ( ) { <nl> - <nl> - list < class < ? > > allclasses = arrays . < class < ? > > aslist ( <nl> - internetdomainname . class , <nl> - tldpatterns . class ) ; <nl> + @ override public void onmoduleload ( ) { <nl> } <nl> } <nl> mmm a / guava - gwt / test / com / google / common / primitives / testmoduleentrypoint . java <nl> ppp b / guava - gwt / test / com / google / common / primitives / testmoduleentrypoint . java <nl>
package com . google . common . primitives ; <nl>  <nl> import com . google . gwt . core . client . entrypoint ; <nl>  <nl> - import java . util . arrays ; <nl> - import java . util . list ; <nl> - <nl> / * * <nl> + * an empty entry point for testing gwt compatibility . <nl> + * <nl> * @ author hayward chan <nl> * / <nl> public class testmoduleentrypoint implements entrypoint { <nl>  <nl> - @ override <nl> - public void onmoduleload ( ) { <nl> - <nl> - list < class < ? > > allclasses = arrays . < class < ? > > aslist ( <nl> - booleans . class , <nl> - ints . class , <nl> - shorts . class , <nl> - chars . class , <nl> - longs . class , <nl> - floats . class , <nl> - doubles . class , <nl> - bytes . class , <nl> - signedbytes . class ) ; <nl> + @ override public void onmoduleload ( ) { <nl> } <nl> }
class customconcurrenthashmap < k , v > <nl>  <nl> @ override <nl> public boolean containsvalue ( object value ) { <nl> - <nl> - checknotnull ( value ) ; <nl> - <nl> - segment < k , v > [ ] segments = this . segments ; <nl> - for ( int i = num ; i < segments . length ; + + i ) { <nl> - / / ensure visibility of most recent completed write <nl> - @ suppresswarnings ( { " unuseddeclaration " , " unused " } ) <nl> - int c = segments [ i ] . count ; / / read - volatile <nl> - if ( segments [ i ] . containsvalue ( value ) ) { <nl> - return true ; <nl> + checknotnull ( value ) ; / / as does concurrenthashmap <nl> + <nl> + / / this implementation is patterned after concurrenthashmap , but without the locking . the only <nl> + / / way for it to return a false negative would be for the target value to jump around in the map <nl> + / / such that none of the subsequent iterations observed it , despite the fact that at every point <nl> + / / in time it was present somewhere int the map . this becomes increasingly unlikely as <nl> + / / contains_value_retries increases , though without locking it is theoretically possible . <nl> + final segment < k , v > [ ] segments = this . segments ; <nl> + int last = - 1 ; <nl> + for ( int i = num ; i < contains_value_retries ; i + + ) { <nl> + int sum = num ; <nl> + for ( segment < k , v > segment : segments ) { <nl> + / / ensure visibility of most recent completed write <nl> + @ suppresswarnings ( { " unuseddeclaration " , " unused " } ) <nl> + int c = segment . count ; / / read - volatile <nl> + <nl> + atomicreferencearray < referenceentry < k , v > > table = segment . table ; <nl> + for ( int j = num ; j < table . length ( ) ; j + + ) { <nl> + for ( referenceentry < k , v > e = table . get ( j ) ; e ! = null ; e = e . getnext ( ) ) { <nl> + v v = segment . getlivevalue ( e ) ; <nl> + if ( v ! = null & & valueequivalence . equivalent ( value , v ) ) { <nl> + return true ; <nl> + } <nl> + } <nl> + } <nl> + sum + = segment . modcount ; <nl> + } <nl> + if ( sum = = last ) { <nl> + break ; <nl> } <nl> + last = sum ; <nl> } <nl> return false ; <nl> }
public class internetdomainname { <nl> private static final string dot_regex = " \ \ . " ; <nl>  <nl> / * * <nl> - * maximum parts ( labels ) in a domain name . <nl> - * <nl> - * < p > <nl> + * maximum parts ( labels ) in a domain name . this value arises from <nl> + * the num - octet limit described in <nl> + * < a href = " http : / / www . ietf . org / rfc / rfc2181 . txt " > rfc num < / a > part num with <nl> + * the fact that the encoding of each part occupies at least two bytes <nl> + * ( dot plus label externally , length byte plus label internally ) . thus , if <nl> + * all labels have the minimum size of one byte , num of them will fit . <nl> * / <nl> private static final int max_parts = num ; <nl>  <nl> mmm a / src / com / google / common / net / internetdomainname . java <nl> ppp b / src / com / google / common / net / internetdomainname . java <nl>
public class internetdomainname { <nl> private static final string dot_regex = " \ \ . " ; <nl>  <nl> / * * <nl> - * maximum parts ( labels ) in a domain name . <nl> - * <nl> - * < p > <nl> + * maximum parts ( labels ) in a domain name . this value arises from <nl> + * the num - octet limit described in <nl> + * < a href = " http : / / www . ietf . org / rfc / rfc2181 . txt " > rfc num < / a > part num with <nl> + * the fact that the encoding of each part occupies at least two bytes <nl> + * ( dot plus label externally , length byte plus label internally ) . thus , if <nl> + * all labels have the minimum size of one byte , num of them will fit . <nl> * / <nl> private static final int max_parts = num ;
class customconcurrenthashmap < k , v > extends abstractmap < k , v > <nl> } else if ( ! isheldbycurrentthread ( ) ) { <nl> cleanupexecutor . execute ( cleanuprunnable ) ; <nl> } <nl> - } else if ( trylock ( ) ) { <nl> - <nl> - try { <nl> - / / inexpensive read cleanup when the lock is available <nl> - expireentries ( ) ; <nl> - } finally { <nl> - unlock ( ) ; <nl> - } <nl> } <nl> } <nl>  <nl>
class customconcurrenthashmap < k , v > extends abstractmap < k , v > <nl> * / <nl> static final int max_segments = num < < num ; / / slightly conservative <nl>  <nl> - / * * <nl> - * number of unsynchronized retries in size and containsvalue methods before <nl> - * resorting to locking . this is used to avoid unbounded retries if tables <nl> - * undergo continuous modification which would make it impossible to obtain <nl> - * an accurate result . <nl> - * <nl> - * <nl> - * containsvalue ( ) in terms of weakly consistent iteration . <nl> - * / <nl> - static final int retries_before_lock = num ; <nl> - <nl> / * * <nl> * number of cache access operations that can be buffered per segment before <nl> * the cache ' s recency ordering information is updated . this is used to avoid <nl>
class customconcurrenthashmap < k , v > extends abstractmap < k , v > <nl> ? customconcurrenthashmap . < referenceentry < k , v > > discardingqueue ( ) <nl> : new concurrentlinkedqueue < referenceentry < k , v > > ( ) ; <nl>  <nl> - concurrencylevel = filterconcurrencylevel ( builder . getconcurrencylevel ( ) ) ; <nl> + concurrencylevel = math . min ( builder . getconcurrencylevel ( ) , max_segments ) ; <nl>  <nl> - <nl> - int initialcapacity = builder . getinitialcapacity ( ) ; <nl> - if ( initialcapacity > maximum_capacity ) { <nl> - initialcapacity = maximum_capacity ; <nl> + int initialcapacity = <nl> + math . min ( builder . getinitialcapacity ( ) , maximum_capacity ) ; <nl> + if ( evictsbysize ( ) ) { <nl> + initialcapacity = math . min ( initialcapacity , maximumsize ) ; <nl> } <nl>  <nl> / / find power - of - two sizes best matching arguments . constraints : <nl>
class computingconcurrenthashmap < k , v > extends customconcurrenthashmap < k , v > <nl> break ; <nl> } <nl> } <nl> - <nl> - / / risk blocking on cleanup <nl> + <nl> if ( entry = = null | | isinvalid ( entry ) ) { <nl> / / create a new entry . <nl> computingvaluereference = new computingvaluereference ( ) ;
class replicamanagertest { <nl> leaderbrokerid , countdownlatch , expecttruncation = true , extraprops = props ) ) <nl> } <nl>  <nl> - / / due to some limitations to easymock , we need to create the log so that the partition . topicid does not call <nl> - / / logmanager . getlog with a default argument <nl> - <nl> - private def initializelogandtopicid ( replicamanager : replicamanager , topicpartition : topicpartition , topicid : uuid ) : unit = { <nl> - val partition = replicamanager . createpartition ( new topicpartition ( topic , num ) ) <nl> - val log = replicamanager . logmanager . getorcreatelog ( topicpartition , false , false , some ( topicid ) ) <nl> - partition . log = some ( log ) <nl> - } <nl> - <nl> @ test <nl> def testdefaultreplicaselector ( ) : unit = { <nl> val topicpartition = num <nl>
class socketservertest { <nl> * buffered receive . <nl> * / <nl> @ test <nl> - @ disabled <nl> def remoteclosewithoutbufferedreceives ( ) : unit = { <nl> verifyremoteclosewithbufferedreceives ( numcomplete = num , hasincomplete = false ) <nl> } <nl>
class socketservertest { <nl> * the channel must be closed after pending receives are processed . <nl> * / <nl> @ test <nl> - @ disabled <nl> def closingchannelwithbufferedreceives ( ) : unit = { <nl> verifyremoteclosewithbufferedreceives ( numcomplete = num , hasincomplete = false , makeclosing = true ) <nl> }
class consumerbouncetest extends abstractconsumertest with logging { <nl> } <nl>  <nl> @ test <nl> - @ disabled <nl> def testclose ( ) : unit = { <nl> val numrecords = num <nl> val producer = createproducer ( ) <nl>
class controllerapis ( val requestchannel : requestchannel , <nl> handleraftrequest ( request , response = > new fetchsnapshotresponse ( response . asinstanceof [ fetchsnapshotresponsedata ] ) ) <nl> } <nl>  <nl> - def handlemetadatarequest ( request : requestchannel . request ) : unit = { <nl> - val metadatarequest = request . body [ metadatarequest ] <nl> - def createresponsecallback ( requestthrottlems : int ) : metadataresponse = { <nl> - val metadataresponsedata = new metadataresponsedata ( ) <nl> - metadataresponsedata . setthrottletimems ( requestthrottlems ) <nl> - controllernodes . foreach { node = > <nl> - metadataresponsedata . brokers . add ( new metadataresponsebroker ( ) <nl> - . sethost ( node . host ) <nl> - . setnodeid ( node . id ) <nl> - . setport ( node . port ) <nl> - . setrack ( node . rack ) ) <nl> - } <nl> - metadataresponsedata . setclusterid ( metaproperties . clusterid ) <nl> - if ( controller . isactive ) { <nl> - metadataresponsedata . setcontrollerid ( config . nodeid ) <nl> - } else { <nl> - metadataresponsedata . setcontrollerid ( metadataresponse . no_controller_id ) <nl> - } <nl> - val clusterauthorizedoperations = if ( metadatarequest . data . includeclusterauthorizedoperations ) { <nl> - if ( authhelper . authorize ( request . context , describe , cluster , cluster_name ) ) { <nl> - authhelper . authorizedoperations ( request , resource . cluster ) <nl> - } else { <nl> - num <nl> - } <nl> - } else { <nl> - int . minvalue <nl> - } <nl> - <nl> - metadataresponsedata . setclusterauthorizedoperations ( clusterauthorizedoperations ) <nl> - new metadataresponse ( metadataresponsedata , request . header . apiversion ) <nl> - } <nl> - requesthelper . sendresponsemaybethrottle ( request , <nl> - requestthrottlems = > createresponsecallback ( requestthrottlems ) ) <nl> - } <nl> - <nl> def handledeletetopics ( request : requestchannel . request ) : unit = { <nl> val deletetopicsrequest = request . body [ deletetopicsrequest ] <nl> val future = deletetopics ( deletetopicsrequest . data ,
public class sslutils { <nl> public static sslcontextfactory createclientsidesslcontextfactory ( workerconfig config ) { <nl> map < string , object > sslconfigvalues = config . valueswithprefixallornothing ( " listeners . https . " ) ; <nl>  <nl> - / / override this method in order to avoid running into <nl> - / / https : / / github . com / eclipse / jetty . project / issues / 4385 , which would otherwise cause this to <nl> - / / break when the keystore contains multiple certificates . <nl> - / / the override here matches the bug fix in jetty for that issue : <nl> - / / https : / / github . com / eclipse / jetty . project / pull / 4404 / files # diff - <commit_id> r2188 - r2193 <nl> - <nl> - / / num . 4 . 25 or later <nl> - final sslcontextfactory . client ssl = new sslcontextfactory . client ( ) { <nl> - @ override <nl> - @ suppresswarnings ( " deprecation " ) <nl> - protected x509extendedkeymanager newsnix509extendedkeymanager ( x509extendedkeymanager keymanager ) { <nl> - return keymanager ; <nl> - } <nl> - } ; <nl> + final sslcontextfactory . client ssl = new sslcontextfactory . client ( ) ; <nl>  <nl> configuresslcontextfactorykeystore ( ssl , sslconfigvalues ) ; <nl> configuresslcontextfactorytruststore ( ssl , sslconfigvalues ) ; <nl> mmm a / gradle / dependencies . gradle <nl> ppp b / gradle / dependencies . gradle <nl>
class streamsupgradetest ( test ) : <nl>  <nl> self . driver = streamssmoketestdriverservice ( self . test_context , self . kafka ) <nl> self . driver . disable_auto_terminate ( ) <nl> - # <nl> self . processor1 = streamsupgradetestjobrunnerservice ( self . test_context , self . kafka ) <nl> - self . processor1 . set_config ( " internal . task . assignor . class " , " org . apache . kafka . streams . processor . internals . assignment . stickytaskassignor " ) <nl> self . processor2 = streamsupgradetestjobrunnerservice ( self . test_context , self . kafka ) <nl> - self . processor2 . set_config ( " internal . task . assignor . class " , " org . apache . kafka . streams . processor . internals . assignment . stickytaskassignor " ) <nl> self . processor3 = streamsupgradetestjobrunnerservice ( self . test_context , self . kafka ) <nl> - self . processor3 . set_config ( " internal . task . assignor . class " , " org . apache . kafka . streams . processor . internals . assignment . stickytaskassignor " ) <nl>  <nl> self . driver . start ( ) <nl> self . start_all_nodes_with ( " " ) # run with trunk <nl>
<nl>  <nl> < h4 > < a id = " upgrade_2_3_0 " href = " # upgrade_2_3_0 " > upgrading from num . 8 . x , num . 9 . x , num . 10 . 0 . x , num . 10 . 1 . x , num . 10 . 2 . x , num . 11 . 0 . x , num . 0 . x , num . 1 . x , num . 0 . x or num . 1 . x or num . 2 . x to num . 3 . 0 < / a > < / h4 > <nl>  <nl> - < ! - - <nl> + < p > < b > if you are upgrading from a version prior to num . 1 . x , please see the note below about the change to the schema used to store consumer offsets . <nl> + once you have changed the inter . broker . protocol . version to the latest version , it will not be possible to downgrade to a version prior to num . 1 . < / b > < / p > <nl> + <nl> + < p > < b > for a rolling upgrade : < / b > < / p > <nl> + <nl> + < ol > <nl> + < li > update server . properties on all brokers and add the following properties . current_kafka_version refers to the version you <nl> + are upgrading from . current_message_format_version refers to the message format version currently in use . if you have previously <nl> + overridden the message format version , you should keep its current value . alternatively , if you are upgrading from a version prior <nl> + to num . 11 . 0 . x , then current_message_format_version should be set to match current_kafka_version . <nl> + < ul > <nl> + < li > inter . broker . protocol . version = current_kafka_version ( e . g . num . 8 . 2 , num . 9 . 0 , num . 10 . 0 , num . 10 . 1 , num . 10 . 2 , num . 11 . 0 , num . 0 , num . 1 ) . < / li > <nl> + < li > log . message . format . version = current_message_format_version ( see < a href = " # upgrade_10_performance_impact " > potential performance impact <nl> + following the upgrade < / a > for the details on what this configuration does . ) < / li > <nl> + < / ul > <nl> + if you are upgrading from num . 11 . 0 . x , num . 0 . x , num . 1 . x , num . 0 . x , or num . 1 . x , and you have not overridden the message format , then you only need to override <nl> + the inter - broker protocol version . <nl> + < ul > <nl> + < li > inter . broker . protocol . version = current_kafka_version ( 0 . 11 . 0 , num . 0 , num . 1 , num . 0 , num . 1 , num . 2 ) . < / li > <nl> + < / ul > <nl> + < / li > <nl> + < li > upgrade the brokers one at a time : shut down the broker , update the code , and restart it . once you have done so , the <nl> + brokers will be running the latest version and you can verify that the cluster ' s behavior and performance meets expectations . <nl> + it is still possible to downgrade at this point if there are any problems . <nl> + < / li > <nl> + < li > once the cluster ' s behavior and performance has been verified , bump the protocol version by editing <nl> + < code > inter . broker . protocol . version < / code > and setting it to num . 3 . <nl> + < / li > <nl> + < li > restart the brokers one by one for the new protocol version to take effect . once the brokers begin using the latest <nl> + protocol version , it will no longer be possible to downgrade the cluster to an older version . <nl> + < / li > <nl> + < li > if you have overridden the message format version as instructed above , then you need to do one more rolling restart to <nl> + upgrade it to its latest version . once all ( or most ) consumers have been upgraded to num . 11 . 0 or later , <nl> + change log . message . format . version to num . 3 on each broker and restart them one by one . note that the older scala clients , <nl> + which are no longer maintained , do not support the message format introduced in num . 11 , so to avoid conversion costs <nl> + ( or to take advantage of < a href = " # upgrade_11_exactly_once_semantics " > exactly once semantics < / a > ) , <nl> + the newer java clients must be used . <nl> + < / li > <nl> + < / ol > <nl>  <nl> < h5 > < a id = " upgrade_230_notable " href = " # upgrade_230_notable " > notable changes in num . 3 . 0 < / a > < / h5 > <nl> < ul >
public class saslchannelbuilder implements channelbuilder , listenerreconfigurabl <nl> return loginmanagers ; <nl> } <nl>  <nl> - private static string defaultkerberosrealm ( ) throws classnotfoundexception , nosuchmethodexception , <nl> - illegalargumentexception , illegalaccessexception , invocationtargetexception { <nl> - <nl> - <nl> - / / due to the jigsaw module system <nl> - <nl> - object kerbconf ; <nl> - class < ? > classref ; <nl> - method getinstancemethod ; <nl> - method getdefaultrealmmethod ; <nl> - if ( java . isibmjdk ( ) ) { <nl> - classref = class . forname ( " com . ibm . security . krb5 . internal . config " ) ; <nl> - } else { <nl> - classref = class . forname ( " sun . security . krb5 . config " ) ; <nl> - } <nl> - getinstancemethod = classref . getmethod ( " getinstance " , new class [ 0 ] ) ; <nl> - kerbconf = getinstancemethod . invoke ( classref , new object [ 0 ] ) ; <nl> - getdefaultrealmmethod = classref . getdeclaredmethod ( " getdefaultrealm " , new class [ 0 ] ) ; <nl> - return ( string ) getdefaultrealmmethod . invoke ( kerbconf , new object [ 0 ] ) ; <nl> + private static string defaultkerberosrealm ( ) { <nl> + / / see https : / / issues . apache . org / jira / browse / hadoop - 10848 for details <nl> + return new kerberosprincipal ( " tmp " , num ) . getrealm ( ) ; <nl> } <nl>  <nl> private void createclientcallbackhandler ( map < string , ? > configs ) { <nl>
for a detailed description of findbugs bug categories , see http : / / findbugs . sourc <nl> < bug pattern = " sf_switch_fallthrough " / > <nl> < / match > <nl>  <nl> - < match > <nl> - < ! - - suppress some inconsistent synchronization warnings . <nl> - kafka - 4994 . - - > <nl> - < class name = " org . apache . kafka . connect . storage . offsetstoragewriter " / > <nl> - < bug pattern = " is2_inconsistent_sync " / > <nl> - < / match > <nl> - <nl> < match > <nl> < ! - - suppress a warning about intentional switch statement fallthrough . - - > <nl> < class name = " org . apache . kafka . common . security . authenticator . saslclientauthenticator " / >
public final class lazydownconversionrecordssend extends recordssend < lazydowncon <nl> / / baseoffset = > int64 <nl> / / length = > int32 <nl> / / . . . <nl> - <nl> - log . debug ( " constructing fake message batch for topic - partition { " + topicpartition ( ) + " } for remaining length " + remaining ) ; <nl> - int minlength = ( long . size / byte . size ) + ( integer . size / byte . size ) ; <nl> - bytebuffer fakemessagebatch = bytebuffer . allocate ( math . max ( minlength , math . min ( remaining + num , max_read_size ) ) ) ; <nl> + log . debug ( " constructing fake message batch for partition { } for remaining length = { } " , topicpartition ( ) , remaining ) ; <nl> + bytebuffer fakemessagebatch = bytebuffer . allocate ( math . max ( records . log_overhead , math . min ( remaining + num , max_read_size ) ) ) ; <nl> fakemessagebatch . putlong ( - 1l ) ; <nl> fakemessagebatch . putint ( remaining + num ) ; <nl> convertedrecords = memoryrecords . readablerecords ( fakemessagebatch ) ;
object log { <nl> / * * a temporary file used when swapping files into the log * / <nl> val swapfilesuffix = " . swap " <nl>  <nl> - / * * clean shutdown file that indicates the broker was cleanly shutdown in num . 8 . this is required to maintain backwards compatibility <nl> - * with num . 8 and avoid unnecessary log recovery when upgrading from num . 8 to num . 8 . 1 * / <nl> - / * * <nl> + / * * clean shutdown file that indicates the broker was cleanly shutdown in num . 8 and higher . <nl> + * this is used to avoid unnecessary recovery after a clean shutdown . in theory this could be <nl> + * avoided by passing in the recovery point , however finding the correct position to do this <nl> + * requires accessing the offset <nl> + * for more information see the discussion in pr # 2104 <nl> + * / <nl> val cleanshutdownfile = " . kafka_cleanshutdown " <nl>  <nl> / * * a directory that is scheduled to be deleted * /
<nl> - / * <nl> - * licensed to the apache software foundation ( asf ) under one or more <nl> - * contributor license agreements . see the notice file distributed with <nl> - * this work for additional information regarding copyright ownership . <nl> - * the asf licenses this file to you under the apache license , version num . 0 <nl> - * ( the " license " ) ; you may not use this file except in compliance with <nl> - * the license . you may obtain a copy of the license at <nl> - * <nl> - * http : / / www . apache . org / licenses / license - 2 . 0 <nl> - * <nl> - * unless required by applicable law or agreed to in writing , software <nl> - * distributed under the license is distributed on an " as is " basis , <nl> - * without warranties or conditions of any kind , either express or implied . <nl> - * see the license for the specific language governing permissions and <nl> - * limitations under the license . <nl> - * / <nl> - package kafka . coordinator . transaction <nl> - <nl> - import java . util . properties <nl> - <nl> - import kafka . integration . kafkaservertestharness <nl> - import kafka . server . kafkaconfig <nl> - import kafka . utils . testutils <nl> - import org . apache . kafka . common . topicpartition <nl> - import org . apache . kafka . common . internals . topic <nl> - import org . apache . kafka . common . protocol . errors <nl> - import org . apache . kafka . common . record . compressiontype <nl> - import org . apache . kafka . common . utils . utils <nl> - import org . junit . { assert , test } <nl> - <nl> - class transactioncoordinatorintegrationtest extends kafkaservertestharness { <nl> - val offsetstopiccompressioncodec = compressiontype . gzip <nl> - val overridingprops = new properties ( ) <nl> - overridingprops . put ( kafkaconfig . offsetstopicpartitionsprop , " 1 " ) <nl> - overridingprops . put ( kafkaconfig . transactionstopicpartitionsprop , " 1 " ) <nl> - overridingprops . put ( kafkaconfig . requesttimeoutmsprop , " 100 " ) <nl> - <nl> - override def generateconfigs = testutils . createbrokerconfigs ( 1 , zkconnect , enablecontrolledshutdown = false ) . map { <nl> - kafkaconfig . fromprops ( _ , overridingprops ) <nl> - } <nl> - <nl> - @ test <nl> - def shouldcommittransaction ( ) : unit = { <nl> - testutils . createtopic ( zkutils , topic . transaction_state_topic_name , num , num , servers , servers . head . groupcoordinator . offsetstopicconfigs ) <nl> - val topic = " foo " <nl> - testutils . createtopic ( this . zkutils , topic , num , num , servers ) <nl> - <nl> - val tc = servers . head . transactioncoordinator <nl> - <nl> - var initproduceridresult : initproduceridresult = null <nl> - def callback ( result : initproduceridresult ) : unit = { <nl> - initproduceridresult = result <nl> - } <nl> - <nl> - val txnid = " txn " <nl> - tc . handleinitproducerid ( txnid , num , callback ) <nl> - <nl> - while ( initproduceridresult = = null ) { <nl> - utils . sleep ( 1 ) <nl> - } <nl> - <nl> - assert . assertequals ( errors . none , initproduceridresult . error ) <nl> - <nl> - @ volatile var addpartitionerrors : errors = null <nl> - def addpartitionscallback ( errors : errors ) : unit = { <nl> - addpartitionerrors = errors <nl> - } <nl> - <nl> - tc . handleaddpartitionstotransaction ( txnid , <nl> - initproduceridresult . producerid , <nl> - initproduceridresult . producerepoch , <nl> - set [ topicpartition ] ( new topicpartition ( topic , num ) ) , <nl> - addpartitionscallback <nl> - ) <nl> - <nl> - while ( addpartitionerrors = = null ) { <nl> - utils . sleep ( 1 ) <nl> - } <nl> - <nl> - assert . assertequals ( errors . none , addpartitionerrors ) <nl> - <nl> - / * * <nl> - * <nl> - @ volatile var commiterrors : errors = null <nl> - def commitcallback ( errors : errors ) : unit = { <nl> - commiterrors = errors <nl> - } <nl> - <nl> - tc . handleendtransaction ( txnid , <nl> - initpidresult . pid , <nl> - initpidresult . epoch , <nl> - transactionresult . commit , <nl> - commitcallback ) <nl> - <nl> - while ( commiterrors = = null ) { <nl> - utils . sleep ( 1 ) <nl> - } <nl> - <nl> - assert . assertequals ( errors . none , commiterrors ) <nl> - * / <nl> - } <nl> - }
class consumerbouncetest extends integrationtestharness with logging { <nl> consumer . seektobeginning ( collections . emptylist ( ) ) <nl> consumed = num <nl> } <nl> - } catch { <nl> - <nl> - / / merged since coordinator fail - over will not cause a rebalance <nl> - case _ : commitfailedexception = > <nl> } <nl> } <nl> scheduler . shutdown ( )
public abstract class abstractcoordinator implements closeable { <nl> * one of the brokers . the returned future should be polled to get the result of the request . <nl> * @ return a request future which indicates the completion of the metadata request <nl> * / <nl> - private requestfuture < void > sendgroupcoordinatorrequest ( ) { <nl> + private requestfuture < void > sendgroupcoordinatorrequest ( node node ) { <nl> / / initiate the group metadata request <nl> - / / find a node to ask about the coordinator <nl> - node node = this . client . leastloadednode ( ) ; <nl> - if ( node = = null ) { <nl> - <nl> - / / from configuration ? <nl> - return requestfuture . nobrokersavailable ( ) ; <nl> - } else { <nl> - / / create a group metadata request <nl> - log . debug ( " sending coordinator request for group { } to broker { } " , groupid , node ) ; <nl> - groupcoordinatorrequest metadatarequest = new groupcoordinatorrequest ( this . groupid ) ; <nl> - return client . send ( node , apikeys . group_coordinator , metadatarequest ) <nl> - . compose ( new groupcoordinatorresponsehandler ( ) ) ; <nl> - } <nl> + log . debug ( " sending coordinator request for group { } to broker { } " , groupid , node ) ; <nl> + groupcoordinatorrequest metadatarequest = new groupcoordinatorrequest ( this . groupid ) ; <nl> + return client . send ( node , apikeys . group_coordinator , metadatarequest ) <nl> + . compose ( new groupcoordinatorresponsehandler ( ) ) ; <nl> } <nl>  <nl> private class groupcoordinatorresponsehandler extends requestfutureadapter < clientresponse , void > { <nl> mmm a / clients / src / test / java / org / apache / kafka / clients / consumer / internals / abstractcoordinatortest . java <nl> ppp b / clients / src / test / java / org / apache / kafka / clients / consumer / internals / abstractcoordinatortest . java <nl>
public class standbytask extends abstracttask { <nl> / / reinitialize offset limits <nl> initializeoffsetlimits ( ) ; <nl> } <nl> - <nl> - protected void initializeoffsetlimits ( ) { <nl> - for ( topicpartition partition : partitions ) { <nl> - offsetandmetadata metadata = consumer . committed ( partition ) ; <nl> - statemgr . putoffsetlimit ( partition , metadata ! = null ? metadata . offset ( ) : num l ) ; <nl> - } <nl> - } <nl> - <nl> } <nl> mmm a / streams / src / test / java / org / apache / kafka / streams / processor / internals / streamthreadtest . java <nl> ppp b / streams / src / test / java / org / apache / kafka / streams / processor / internals / streamthreadtest . java <nl>
public class kafkaconsumer < k , v > implements consumer < k , v > { <nl> / / refcount is used to allow reentrant access by the thread who has acquired currentthread <nl> private final atomicinteger refcount = new atomicinteger ( 0 ) ; <nl>  <nl> - <nl> - / / to leverage the work of kafka - 2120 to get this value from configuration . <nl> - private long requesttimeoutms ; <nl> - <nl> / * * <nl> * a consumer is instantiated by providing a set of key - value pairs as configuration . valid configuration strings <nl> * are documented < a href = " http : / / kafka . apache . org / documentation . html # consumerconfigs " > here < / a > . values can be
object mirrormaker extends logging with kafkametricsgroup { <nl> val stream = streams ( 0 ) <nl> val iter = stream . iterator ( ) <nl>  <nl> - <nl> while ( ! exitingonsendfailure & & ! shuttingdown ) { <nl> try { <nl> while ( ! exitingonsendfailure & & ! shuttingdown & & iter . hasnext ( ) ) { <nl>
class producerfailurehandlingtest extends kafkaservertestharness { <nl> override val zkconnect = testzkutils . zookeeperconnect <nl> override val autocreatetopicsenable = false <nl> override val messagemaxbytes = servermessagemaxbytes <nl> - <nl> - / / the broker . as a result , the live broker list in metadatacache is empty . if the number of live brokers is num , we <nl> - / / try to create the offset topic with the default offsets . topic . replication . factor of num . the creation will fail <nl> - / / since there is not enough live brokers . this causes testcannotsendtointernaltopic ( ) to fail . temporarily fixing <nl> - / / the issue by overriding offsets . topic . replication . factor to num for now . when we fix kafka - 1867 , we need to <nl> - / / remove the following config override . <nl> - override val offsetstopicreplicationfactor = num . asinstanceof [ short ] <nl> / / set a smaller value for the number of partitions for the offset commit topic ( __consumer_offset topic ) <nl> / / so that the creation of that topic / partition ( s ) and subsequent leader assignment doesn ' t take relatively long <nl> override val offsetstopicpartitions = num <nl> mmm a / core / src / test / scala / unit / kafka / server / offsetcommittest . scala <nl> ppp b / core / src / test / scala / unit / kafka / server / offsetcommittest . scala <nl>
class offsetcommittest extends junit3suite with zookeepertestharness { <nl> override def setup ( ) { <nl> super . setup ( ) <nl> val config : properties = createbrokerconfig ( 1 , brokerport ) <nl> - <nl> - / / the broker . as a result , the live broker list in metadatacache is empty . this causes the consumermetadatarequest <nl> - / / to fail since if the number of live brokers is num , we try to create the offset topic with the default <nl> - / / offsets . topic . replication . factor of num . the creation will fail since there is not enough live brokers . in order <nl> - / / for the unit test to pass , overriding offsets . topic . replication . factor to num for now . when we fix kafka - 1867 , we <nl> - / / need to remove the following config override . <nl> - config . put ( " offsets . topic . replication . factor " , " 1 " ) <nl> val logdirpath = config . getproperty ( " log . dir " ) <nl> logdir = new file ( logdirpath ) <nl> time = new mocktime ( )
class syncproducer ( val config : syncproducerconfig ) extends logging { <nl> throw e <nl> case e = > throw e <nl> } <nl> - <nl> - sentonconnection + = num <nl> - <nl> - if ( sentonconnection > = config . reconnectinterval | | ( config . reconnecttimeinterval > = num & & system . currenttimemillis - lastconnectiontime > = config . reconnecttimeinterval ) ) { <nl> - reconnect ( ) <nl> - sentonconnection = num <nl> - } <nl> response <nl> } <nl> } <nl>
class logmanagertest extends junitsuite { <nl> offset + = set . sizeinbytes <nl> } <nl> log . flush <nl> - / / why this sleep is required ? file system takes some time to update the last modified time for a file . <nl> - <nl> - thread . sleep ( 2000 ) <nl> + <nl> asserttrue ( " there should be more than one segment now . " , log . numberofsegments > num ) <nl> + <nl> + / / update the last modified time of all log segments <nl> + val logsegments = log . segments . view <nl> + logsegments . foreach ( s = > s . file . setlastmodified ( time . currentms ) ) <nl> + <nl> time . currentms + = maxlogage + num <nl> logmanager . cleanuplogs ( ) <nl> assertequals ( " now there should only be only one segment . " , num , log . numberofsegments ) <nl>
private [ kafka ] class zookeeperconsumerconnector ( val config : consumerconfig , <nl>  <nl> val znode = topicdirs . consumeroffsetdir + " / " + partition . name <nl> val offsetstring = zkutils . readdatamaybenull ( zkclient , znode ) <nl> - / / if first time starting a consumer , use default offset . <nl> - <nl> - val offset : long = if ( offsetstring = = null ) long . maxvalue else offsetstring . tolong <nl> + / / if first time starting a consumer , set the initial offset based on the config <nl> + var offset : long = num l <nl> + if ( offsetstring = = null ) <nl> + offset = config . autooffsetreset match { <nl> + case offsetrequest . smallesttimestring = > <nl> + earliestorlatestoffset ( topic , partition . brokerid , partition . partid , offsetrequest . earliesttime ) <nl> + case offsetrequest . largesttimestring = > <nl> + earliestorlatestoffset ( topic , partition . brokerid , partition . partid , offsetrequest . latesttime ) <nl> + case _ = > <nl> + throw new invalidconfigexception ( " wrong value in autooffsetreset in consumerconfig " ) <nl> + } <nl> + else <nl> + offset = offsetstring . tolong <nl> val queue = queues . get ( ( topic , consumerthreadid ) ) <nl> val consumedoffset = new atomiclong ( offset ) <nl> val fetchedoffset = new atomiclong ( offset )
class slice : preimporthook { <nl> val axes = if ( op . inputstoop . size < num ) sd . range ( sd . constant ( 0 ) , sd . shape ( starts ) , sd . constant ( 1 ) , starts . datatype ( ) ) <nl> else sd . getvariable ( op . inputstoop [ 3 ] ) <nl> val inputrank = sd . rank ( inputvariable ) <nl> - val isaxesnegative = sd . lt ( " isaxesnegative " , axes , sd . zeroslike ( axes ) ) <nl> - val axeswhere = sd . where ( " axeswhere " , axes . add ( inputrank ) , axes , isaxesnegative ) <nl> - val sparseindices = sd . castto ( " sparseindices " , sd . expanddims ( axeswhere , - 1 ) , datatype . int64 ) <nl> - val sparseshape = sd . gathernd ( " sparseshape " , sd . shape ( " inputvariableshape " , inputvariable ) , sparseindices ) . castto ( ends . datatype ( ) ) <nl> - val startsmin = sd . min ( " startsmin " , starts , sparseshape ) <nl> - val endsmin = sd . min ( " endsmin " , ends , sparseshape ) <nl> - <nl> - val isstartsnegative = sd . lt ( " isstartsnegative " , startsmin , sd . zeroslike ( startsmin ) ) <nl> - val startsfinal = sd . where ( " startswhere " , startsmin . add ( " startsminadd " , sparseshape ) , startsmin , isstartsnegative ) <nl> - val isendsnegative = sd . lt ( " isendsnegative " , endsmin , sd . zeroslike ( " zeroslikeendsmin " , endsmin ) ) <nl> - val endsfinal = sd . where ( " endwhere " , endsmin . add ( sparseshape ) , endsmin , isendsnegative ) <nl> - val outputshape = inputrank . castto ( " outputshape " , datatype . int64 ) <nl> - val densebegins = sd . sparsetodense ( " densebegins " , sparseindices , outputshape , startsfinal ) <nl> - <nl> - <nl> - val denseends = sd . sparsetodense ( " denseends " , sparseindices , outputshape , endsfinal , sd . constant ( nd4j . create ( <nl> + val isaxesnegative = sd . lt ( axes , sd . zeroslike ( axes ) ) <nl> + val axeswhere = sd . where ( axes . add ( inputrank ) , axes , isaxesnegative ) <nl> + val sparseindices = sd . castto ( sd . expanddims ( axeswhere , - 1 ) , datatype . int64 ) <nl> + val sparseshape = sd . gathernd ( sd . shape ( inputvariable ) , sparseindices ) . castto ( ends . datatype ( ) ) <nl> + val startsmin = sd . min ( starts , sparseshape ) <nl> + val endsmin = sd . min ( ends , sparseshape ) <nl> + <nl> + val isstartsnegative = sd . lt ( startsmin , sd . zeroslike ( startsmin ) ) <nl> + val startsfinal = sd . where ( startsmin . add ( sparseshape ) , startsmin , isstartsnegative ) <nl> + val isendsnegative = sd . lt ( endsmin , sd . zeroslike ( endsmin ) ) <nl> + val endsfinal = sd . where ( endsmin . add ( sparseshape ) , endsmin , isendsnegative ) <nl> + val outputshape = inputrank . castto ( datatype . int64 ) <nl> + val densebegins = sd . sparsetodense ( sparseindices , outputshape , startsfinal ) <nl> + <nl> + <nl> + val denseends = sd . sparsetodense ( sparseindices , outputshape , endsfinal , sd . constant ( nd4j . create ( <nl> floatarrayof ( - 1 . 0f ) ) . castto ( densebegins . datatype ( ) ) ) ) <nl> - <nl> - val denseends2 = sd . where ( " denseends2 " , inputtensorshape , denseends , sd . eq ( denseends , sd . constant ( - 1 ) . castto ( densebegins . datatype ( ) ) ) ) <nl> + val denseends2 = sd . where ( inputtensorshape , denseends , sd . eq ( denseends , sd . constant ( - 1 ) . castto ( densebegins . datatype ( ) ) ) ) <nl>  <nl> val densesteps : sdvariable = if ( op . inputstoop . size > = num ) { <nl> val inputvar = sd . getvariable ( op . inputstoop [ 4 ] ) <nl> - sd . sparsetodense ( " densesteps " , sparseindices , <nl> + sd . sparsetodense ( sparseindices , <nl> outputshape , inputvar , <nl> sd . constant ( nd4j . create ( floatarrayof ( 1 . 0f ) ) <nl> . castto ( inputvar . datatype ( ) ) ) ) <nl> } else { <nl> - sd . oneslike ( " densesteps " , inputvariable . shape ( ) ) <nl> + sd . oneslike ( inputvariable . shape ( ) ) <nl> } <nl>  <nl> val outputvarname : string ? = if ( isfinaloutput ) {
public class cudazerohandler implements memoryhandler { <nl> public cudacontext getcudacontext ( ) { <nl> val lc = nativeops . defaultlaunchcontext ( ) ; <nl>  <nl> - <nl> - <nl> return cudacontext . builder ( ) <nl> . bufferscalar ( nativeops . lcscalarpointer ( lc ) ) <nl> . bufferreduction ( nativeops . lcreductionpointer ( lc ) ) <nl>
<nl> < awaitility . version > 3 . 0 . 0 < / awaitility . version > <nl> < httpcore . version > 4 . 4 . 13 < / httpcore . version > <nl> < commons - compress . version > 1 . 21 < / commons - compress . version > <nl> - < ! - - <nl> - < banyandb - java - client . version > 0 . 2 . 0 - snapshot < / banyandb - java - client . version > <nl> + < banyandb - java - client . version > 0 . 2 . 0 < / banyandb - java - client . version > <nl> < kafka - clients . version > 2 . 4 . 1 < / kafka - clients . version > <nl> < spring - kafka - test . version > 2 . 4 . 6 . release < / spring - kafka - test . version > <nl> < / properties > <nl> mmm a / test / e2e - v2 / script / env <nl> ppp b / test / e2e - v2 / script / env <nl>
filter { <nl>  <nl> - ` grok ` ( <nl>  <nl> - we ' re aware of certains performance issues in the grok java library , and so we ' re currently conducting investigations and benchmarking . contributions are <nl> + we ' re aware of certain performance issues in the grok java library , and so we ' re currently conducting investigations and benchmarking . contributions are <nl> welcome . <nl>  <nl> # # # extractor <nl>
public enum persistencetimer { <nl> this . debug = system . getproperty ( " debug " ) ! = null ; <nl> } <nl>  <nl> - public void start ( modulemanager modulemanager ) { <nl> + public void start ( modulemanager modulemanager , coremoduleconfig moduleconfig ) { <nl> logger . info ( " persistence timer start " ) ; <nl> - <nl> - / / final long timeinterval = esconfig . es . persistence . timer . value * num ; <nl> - final long timeinterval = num ; <nl> ibatchdao batchdao = modulemanager . find ( storagemodule . name ) . provider ( ) . getservice ( ibatchdao . class ) ; <nl>  <nl> metricscreator metricscreator = modulemanager . find ( telemetrymodule . name ) . provider ( ) . getservice ( metricscreator . class ) ; <nl>
<nl>  <nl> < modules > <nl> < module > servicecomb - java - chassis - 0 . x - plugin < / module > <nl> - < ! - - <nl> - < ! - - after apache servicecomb released , we will put it back - - > <nl> - < ! - - <nl> < module > servicecomb - java - chassis - 1 . x - plugin < / module > <nl> - - - > <nl> < / modules > <nl> < packaging > pom < / packaging > <nl>  <nl>
<nl> < dependency > <nl> < groupid > org . apache . servicecomb < / groupid > <nl> < artifactid > java - chassis - core < / artifactid > <nl> - < version > 1 . 0 . 0 - m1 - snapshot < / version > <nl> + < version > 1 . 0 . 0 - m1 < / version > <nl> < scope > provided < / scope > <nl> < / dependency > <nl> < / dependencies > <nl> - < ! - - <nl> - < repositories > <nl> - < repository > <nl> - < id > apache - servicecomb < / id > <nl> - < url > <nl> - https : / / repository . apache . org / content / repositories / snapshots <nl> - < / url > <nl> - < snapshots > <nl> - < enabled > true < / enabled > <nl> - < updatepolicy > always < / updatepolicy > <nl> - < / snapshots > <nl> - < / repository > <nl> - < / repositories > <nl> < build > <nl> < plugins > <nl> < plugin > <nl>
public class datattlkeepertimer { <nl> } <nl>  <nl> public void start ( ) { <nl> - <nl> - / / executors . newsinglethreadscheduledexecutor ( ) . scheduleatfixedrate ( this : : delete , num , num , timeunit . hours ) ; <nl> + executors . newsinglethreadscheduledexecutor ( ) . scheduleatfixedrate ( this : : delete , num , num , timeunit . hours ) ; <nl> } <nl>  <nl> private void delete ( ) {
public class segmentcosth2uidao extends h2dao implements isegmentcostuidao { <nl> topsegmentjson . addproperty ( segmentcosttable . column_segment_id , segmentid ) ; <nl> topsegmentjson . addproperty ( segmentcosttable . column_start_time , rs . getlong ( segmentcosttable . column_start_time ) ) ; <nl> topsegmentjson . addproperty ( segmentcosttable . column_end_time , rs . getlong ( segmentcosttable . column_end_time ) ) ; <nl> - <nl> - <nl> - / / iglobaltracedao globaltracedao = ( iglobaltracedao ) daocontainer . instance . get ( iglobaltracedao . class . getname ( ) ) ; <nl> - / / list < string > globaltraces = globaltracedao . getglobaltraceid ( segmentid ) ; <nl> - / / if ( collectionutils . isnotempty ( globaltraces ) ) { <nl> - / / topsegmentjson . addproperty ( globaltracetable . column_global_trace_id , globaltraces . get ( 0 ) ) ; <nl> - / / } <nl> - <nl> topsegmentjson . addproperty ( segmentcosttable . column_application_id , rs . getint ( segmentcosttable . column_application_id ) ) ; <nl> topsegmentjson . addproperty ( segmentcosttable . column_service_name , rs . getstring ( segmentcosttable . column_service_name ) ) ; <nl> topsegmentjson . addproperty ( segmentcosttable . column_cost , rs . getlong ( segmentcosttable . column_cost ) ) ;
public class segmentcostesuidao extends esdao implements isegmentcostuidao { <nl> topsegmentjson . addproperty ( segmentcosttable . column_end_time , ( number ) searchhit . getsource ( ) . get ( segmentcosttable . column_end_time ) ) ; <nl> } <nl>  <nl> - <nl> - / / iglobaltraceuidao globaltracedao = ( iglobaltracedao ) daocontainer . instance . get ( iglobaltracedao . class . getname ( ) ) ; <nl> - / / list < string > globaltraces = globaltracedao . getglobaltraceid ( segmentid ) ; <nl> - / / if ( collectionutils . isnotempty ( globaltraces ) ) { <nl> - / / topsegmentjson . addproperty ( globaltracetable . column_global_trace_id , globaltraces . get ( 0 ) ) ; <nl> - / / } <nl> - <nl> topsegmentjson . addproperty ( segmentcosttable . column_application_id , ( number ) searchhit . getsource ( ) . get ( segmentcosttable . column_application_id ) ) ; <nl> topsegmentjson . addproperty ( segmentcosttable . column_service_name , ( string ) searchhit . getsource ( ) . get ( segmentcosttable . column_service_name ) ) ; <nl> topsegmentjson . addproperty ( segmentcosttable . column_cost , ( number ) searchhit . getsource ( ) . get ( segmentcosttable . column_cost ) ) ; <nl> mmm a / apm - collector / apm - collector - ui / collector - ui - jetty - provider / src / main / java / org / skywalking / apm / collector / ui / service / segmenttopservice . java <nl> ppp b / apm - collector / apm - collector - ui / collector - ui - jetty - provider / src / main / java / org / skywalking / apm / collector / ui / service / segmenttopservice . java <nl>
public abstract class hystrixcommandmetrics extends hystrixmetrics { <nl> * <nl> * @ return { @ link healthcounts } <nl> * / <nl> - <nl> - public healthcounts gethealthcounts ( ) { <nl> + public final healthcounts gethealthcounts ( ) { <nl> / / we put an interval between snapshots so high - volume commands don ' t <nl> / / spend too much unnecessary time calculating metrics in very small time periods <nl> long lasttime = lasthealthcountssnapshot . get ( ) ;
public abstract class hystrixcommand < r > implements hystrixexecutable < r > { <nl> * metrics initialization <nl> * / <nl> if ( metrics = = null ) { <nl> - <nl> - / / we need a better way of handling this now that we have hystrixplugins <nl> this . metrics = hystrixcommandmetrics . getinstance ( this . commandkey , this . commandgroup , this . properties ) ; <nl> } else { <nl> this . metrics = metrics ; <nl>
public abstract class hystrixcommand < r > implements hystrixexecutable < r > { <nl> if ( this . properties . circuitbreakerenabled ( ) . get ( ) ) { <nl> if ( circuitbreaker = = null ) { <nl> / / get the default implementation of hystrixcircuitbreaker <nl> - <nl> - / / we need a better way of handling this now that we have hystrixplugins <nl> this . circuitbreaker = hystrixcircuitbreaker . factory . getinstance ( this . commandkey , this . commandgroup , this . properties , this . metrics ) ; <nl> } else { <nl> this . circuitbreaker = circuitbreaker ; <nl>
public abstract class hystrixcommand < r > implements hystrixexecutable < r > { <nl> } <nl>  <nl> / * strategy : hystrixmetricspublishercommand * / <nl> - <nl> - / / we need a better way of handling this now that we have hystrixplugins <nl> hystrixmetricspublisherfactory . createorretrievepublisherforcommand ( this . commandkey , this . commandgroup , this . metrics , this . circuitbreaker , this . properties ) ; <nl>  <nl> / *
import com . netflix . hystrix . strategy . properties . hystrixpropertiesstrategy ; <nl> * will derive a { @ link hystrixthreadpoolkey } from the injected { @ link hystrixcommandgroupkey } . <nl> * < p > <nl> * the pool should be sized large enough to handle normal healthy traffic but small enough that it will constrain concurrent execution if backend calls become latent . <nl> - * <nl> - * <nl> + * < p > <nl> + * for more information see the github wiki : https : / / github . com / netflix / hystrix / wiki / configuration # wiki - threadpool and https : / / github . com / netflix / hystrix / wiki / how - it - works # wiki - isolation <nl> * / <nl> public interface hystrixthreadpool { <nl>  <nl> mmm a / hystrix - core / src / main / java / com / netflix / hystrix / util / hystrixrollingpercentile . java <nl> ppp b / hystrix - core / src / main / java / com / netflix / hystrix / util / hystrixrollingpercentile . java <nl>
public class hystrixrollingpercentile { <nl> private final hystrixproperty < integer > numberofbuckets ; <nl> private final hystrixproperty < integer > bucketdatalength ; <nl>  <nl> - <nl> - <nl> / * <nl> * this will get flipped each time a new bucket is created . <nl> * /
class asynclookupjoinitcase ( legacytablesource : boolean , backend : statebackendmod <nl> @ before <nl> override def before ( ) : unit = { <nl> super . before ( ) <nl> - <nl> - / / currently asyncwaitoperator doesn ' t copy input element which is a bug <nl> - env . getconfig . disableobjectreuse ( ) <nl> + if ( objectreuse ) { <nl> + env . getconfig . enableobjectreuse ( ) <nl> + } else { <nl> + env . getconfig . disableobjectreuse ( ) <nl> + } <nl>  <nl> createscantable ( " src " , data ) <nl> createlookuptable ( " user_table " , userdata ) <nl>
public class taskmanagerprocessfailurestreamingrecoveryitcase <nl> / / write result to temporary file <nl> result . addsink ( new checkpointedsink ( data_count ) ) ; <nl>  <nl> - try { <nl> - / / blocking call until execution is done <nl> - env . execute ( ) ; <nl> - <nl> - <nl> - / / check whether checkpoints have been cleaned up properly <nl> - / / assertdirectoryempty ( tempcheckpointdir ) ; <nl> - } finally { <nl> - / / clean up <nl> - if ( tempcheckpointdir . exists ( ) ) { <nl> - fileutils . deletedirectory ( tempcheckpointdir ) ; <nl> - } <nl> - } <nl> + / / blocking call until execution is done <nl> + env . execute ( ) ; <nl> } <nl>  <nl> private static class sleepydurablegeneratesequence extends richparallelsourcefunction < long >
class environmentapicompletenesstests ( pythonapicompletenesstestcase , pyflinktest <nl> @ classmethod <nl> def excluded_methods ( cls ) : <nl> # getcompletionhints has been deprecated . it will be removed in the next release . <nl> - # <nl> return { <nl> ' getcompletionhints ' , <nl> ' fromvalues ' ,
public class buffertimeoutitcase extends abstracttestbase { <nl> @ rule public final sharedobjects sharedobjects = sharedobjects . create ( ) ; <nl>  <nl> / * * <nl> - * the test verifies that it is possible to disable buffer flushing . it emits a single record , <nl> - * which should not fill an entire buffer , thus it should not never reach the sink . we check the <nl> - * sink has not seen any records after num times the default buffer timeout . <nl> + * the test verifies that it is possible to disable explicit buffer flushing . it checks that <nl> + * outputflasher thread would not be started when the task is running . but this doesn ' t <nl> + * guarantee that the unfinished buffers can not be flushed by another events . <nl> * / <nl> - <nl> - @ ignore <nl> @ test <nl> public void testdisablingbuffertimeout ( ) throws exception { <nl> final streamexecutionenvironment env = streamexecutionenvironment . getexecutionenvironment ( ) ; <nl>
<nl> rootlogger . level = off <nl> rootlogger . appenderref . test . ref = testlogger <nl>  <nl> - # debugging flink - 22889 ( <nl> - logger . jdbc . name = org . apache . flink . connector . jdbc . xa . jdbcexactlyoncesinke2etest <nl> - logger . jdbc . level = debug <nl> - <nl> appender . testlogger . name = testlogger <nl> appender . testlogger . type = console <nl> appender . testlogger . target = system_err
public abstract class maxaggfunction extends declarativeaggregatefunction { <nl>  <nl> @ override <nl> public expression [ ] retractexpressions ( ) { <nl> - <nl> - / / throw new tableexception ( " this function does not support retraction , please choose <nl> - / / maxwithretractaggfunction . " ) ; <nl> + / / see optimization in flinkrelmdmodifiedmonotonicity . <nl> + / / this function can ignore retraction message : <nl> + / / sql : select max ( cnt ) , sum ( cnt ) from ( select count ( a ) as cnt from t group by b ) <nl> + / / the cnt is modified increasing , so the max ( cnt ) can ignore retraction message . but this <nl> + / / doesn ' t mean that the node won ' t receive the retraction message , because there are other <nl> + / / aggregate operators that need retraction message , such as sum ( cnt ) . <nl> return new expression [ 0 ] ; <nl> } <nl>  <nl> mmm a / flink - table / flink - table - planner - blink / src / main / java / org / apache / flink / table / planner / functions / aggfunctions / minaggfunction . java <nl> ppp b / flink - table / flink - table - planner - blink / src / main / java / org / apache / flink / table / planner / functions / aggfunctions / minaggfunction . java <nl>
public abstract class minaggfunction extends declarativeaggregatefunction { <nl>  <nl> @ override <nl> public expression [ ] retractexpressions ( ) { <nl> - <nl> - / / throw new tableexception ( " this function does not support retraction , please choose <nl> - / / minwithretractaggfunction . " ) ; <nl> + / / see maxaggfunction . retractexpressions <nl> return new expression [ 0 ] ; <nl> }
public class flinksqlparserimpltest extends sqlparsertest { <nl> sql ( " create temporary system function catalog1 ^ . ^ db1 . function1 as ' org . apache . fink . function . function1 ' " ) <nl> . fails ( " ( ? s ) . * encountered \ " . \ " at . * " ) ; <nl>  <nl> - <nl> - sql ( " create system function function1 as ' org . apache . fink . function . function1 ' " ) <nl> - . ok ( " create system function ` function1 ` as ' org . apache . fink . function . function1 ' " ) ; <nl> + sql ( " create ^ system ^ function function1 as ' org . apache . fink . function . function1 ' " ) <nl> + . fails ( <nl> + " create system function is not supported , " <nl> + + " system functions can only be registered as temporary " <nl> + + " function , you can use create temporary system function instead . " ) ; <nl> } <nl>  <nl> @ test
public class streamingjobgraphgenerator { <nl> final streamconfig operatorconfig ) { <nl>  <nl> / / for each operator , make sure fractions are set for all use cases in the group , even if <nl> - / / the operator does not <nl> - / / have the use case ( set the fraction to num . 0 ) . this allows us to learn which use cases <nl> - / / exist in the group from <nl> - / / either one of the stream configs . <nl> - if ( groupresourcespec . equals ( resourcespec . unknown ) ) { <nl> - for ( map . entry < managedmemoryusecase , integer > entry : <nl> - groupmanagedmemoryweights . entryset ( ) ) { <nl> - final managedmemoryusecase usecase = entry . getkey ( ) ; <nl> - final int groupweight = entry . getvalue ( ) ; <nl> - final int operatorweight = operatorscopeusecaseweights . getordefault ( usecase , num ) ; <nl> - operatorconfig . setmanagedmemoryfractionoperatorofusecase ( <nl> - usecase , <nl> - operatorweight > num <nl> - ? managedmemoryutils . getfractionroundeddown ( <nl> - operatorweight , groupweight ) <nl> - : num . 0 ) ; <nl> - } <nl> - for ( managedmemoryusecase usecase : groupslotscopeusecases ) { <nl> - operatorconfig . setmanagedmemoryfractionoperatorofusecase ( <nl> - usecase , slotscopeusecases . contains ( usecase ) ? num . 0 : num . 0 ) ; <nl> - } <nl> - } else { <nl> - / / supporting for fine grained resource specs is still under developing . <nl> - / / this branch should not be executed in production . not throwing exception for testing <nl> - / / purpose . <nl> - <nl> - log . error ( <nl> - " failed setting managed memory fractions . " <nl> - + " operators may not be able to use managed memory properly . " <nl> - + " calculating managed memory fractions with fine grained resource spec is currently not supported . " ) ; <nl> + / / the operator does not have the use case ( set the fraction to num . 0 ) . this allows us to <nl> + / / learn which use cases exist in the group from either one of the stream configs . <nl> + for ( map . entry < managedmemoryusecase , integer > entry : <nl> + groupmanagedmemoryweights . entryset ( ) ) { <nl> + final managedmemoryusecase usecase = entry . getkey ( ) ; <nl> + final int groupweight = entry . getvalue ( ) ; <nl> + final int operatorweight = operatorscopeusecaseweights . getordefault ( usecase , num ) ; <nl> + operatorconfig . setmanagedmemoryfractionoperatorofusecase ( <nl> + usecase , <nl> + operatorweight > num <nl> + ? managedmemoryutils . getfractionroundeddown ( operatorweight , groupweight ) <nl> + : num . 0 ) ; <nl> + } <nl> + for ( managedmemoryusecase usecase : groupslotscopeusecases ) { <nl> + operatorconfig . setmanagedmemoryfractionoperatorofusecase ( <nl> + usecase , slotscopeusecases . contains ( usecase ) ? num . 0 : num . 0 ) ; <nl> } <nl> }
public class alternatingcontroller implements checkpointbarrierbehaviourcontroll <nl> return maybetimedout ; <nl> } <nl> else { <nl> - <nl> alignedcontroller . resumeconsumption ( channelinfo ) ; <nl> } <nl> + } else if ( ! barrier . getcheckpointoptions ( ) . isunalignedcheckpoint ( ) & & activecontroller = = unalignedcontroller ) { <nl> + alignedcontroller . resumeconsumption ( channelinfo ) ; <nl> } <nl> return optional . empty ( ) ; <nl> } <nl> mmm a / flink - streaming - java / src / test / java / org / apache / flink / streaming / runtime / io / alternatingcontrollertest . java <nl> ppp b / flink - streaming - java / src / test / java / org / apache / flink / streaming / runtime / io / alternatingcontrollertest . java <nl>
public class miniclusteritcase extends testlogger { <nl> } catch ( jobexecutionexception e ) { <nl> asserttrue ( findthrowablewithmessage ( e , " job execution failed . " ) . ispresent ( ) ) ; <nl> asserttrue ( findthrowable ( e , noresourceavailableexception . class ) . ispresent ( ) ) ; <nl> - <nl> - <nl> - final string legacyschedulererrormessage = " slots required : num , slots allocated : num " ; <nl> - final string ngschedulererrormessage = " could not allocate the required slot within slot request timeout " ; <nl> - asserttrue ( findthrowablewithmessage ( e , legacyschedulererrormessage ) . ispresent ( ) | | <nl> - findthrowablewithmessage ( e , ngschedulererrormessage ) . ispresent ( ) ) ; <nl> } <nl> } <nl>  <nl>
public class miniclusteritcase extends testlogger { <nl> } catch ( jobexecutionexception e ) { <nl> asserttrue ( findthrowablewithmessage ( e , " job execution failed . " ) . ispresent ( ) ) ; <nl> asserttrue ( findthrowable ( e , noresourceavailableexception . class ) . ispresent ( ) ) ; <nl> - <nl> - <nl> - final string legacyschedulererrormessage = " could not allocate enough slots " ; <nl> - final string ngschedulererrormessage = " could not allocate the required slot within slot request timeout " ; <nl> - asserttrue ( findthrowablewithmessage ( e , legacyschedulererrormessage ) . ispresent ( ) | | <nl> - findthrowablewithmessage ( e , ngschedulererrormessage ) . ispresent ( ) ) ; <nl> } <nl> }
public class rowfunctionitcase extends builtinfunctiontestbase { <nl> datatypes . field ( " i " , datatypes . int ( ) ) , <nl> datatypes . field ( " s " , datatypes . string ( ) ) ) . notnull ( ) <nl> ) , <nl> - <nl> - " cast ( row ( 12 + f0 , ' hello world ' ) as row < i int , s string > ) " , <nl> + " cast ( ( f0 + num , ' hello world ' ) as row < i int , s string > ) " , <nl> row . of ( 13 , " hello world " ) , <nl> datatypes . row ( <nl> datatypes . field ( " i " , datatypes . int ( ) ) ,
object aggregateutil extends enumeration { <nl> hasstatebackeddataviews , <nl> needsretraction ) <nl>  <nl> - case _ : aggsqlfunction | <nl> - <nl> - _ : sqlaggfunction if ! udf . isinstanceof [ internalaggregatefunction [ _ , _ ] ] & & <nl> - udf . isinstanceof [ imperativeaggregatefunction [ _ , _ ] ] = > <nl> + case _ : aggsqlfunction = > <nl> createaggregateinfofromlegacyfunction ( <nl> inputrowreldatatype , <nl> call ,
see [ restart strategies ] ( { % link dev / task_failure_recovery . zh . md <nl>  <nl> # # # state backends <nl>  <nl> - ` <nl> - <nl> the exact data structures in which the key / values indexes are stored depends on <nl> the chosen [ state backend ] ( { % link <nl> ops / state / state_backends . zh . md % } ) . one state backend stores data in an in - memory <nl>
logic . <nl>  <nl> # # # savepoints <nl>  <nl> - ` <nl> - <nl> all programs that use checkpointing can resume execution from a * * savepoint * * . <nl> savepoints allow both updating your programs and your flink cluster without <nl> losing any state . <nl>
give * exactly once * guarantees even in * at least once * mode . <nl>  <nl> { % top % } <nl>  <nl> - # # end - to - end exactly - once programs <nl> - <nl> - ` <nl> - <nl> # # state and fault tolerance in batch programs <nl>  <nl> flink executes [ batch programs ] ( . . / dev / batch / index . html ) as a special case of <nl> mmm a / docs / concepts / timely - stream - processing . zh . md <nl> ppp b / docs / concepts / timely - stream - processing . zh . md <nl>
occured is important . <nl> in the following sections we will highlight some of the topics that you should <nl> consider when working with timely flink applications . <nl>  <nl> - # # latency & completeness <nl> - <nl> - ` <nl> - <nl> - # # # latency vs . completeness in batch & stream processing <nl> - <nl> { % top % } <nl>  <nl> # # notions of time : event time and processing time
provides different state backends that specify how and where state is stored . <nl>  <nl> { % top % } <nl>  <nl> - # # state in stream & batch processing <nl> - <nl> - ` <nl> - <nl> - { % top % } <nl> - <nl> # # keyed state <nl>  <nl> keyed state is maintained in what can be thought of as an embedded key / value <nl>
see [ restart strategies ] ( { % link dev / task_failure_recovery . md <nl>  <nl> # # # state backends <nl>  <nl> - ` <nl> - <nl> the exact data structures in which the key / values indexes are stored depends on <nl> the chosen [ state backend ] ( { % link <nl> ops / state / state_backends . md % } ) . one state backend stores data in an in - memory <nl>
logic . <nl>  <nl> # # # savepoints <nl>  <nl> - ` <nl> - <nl> all programs that use checkpointing can resume execution from a * * savepoint * * . <nl> savepoints allow both updating your programs and your flink cluster without <nl> losing any state . <nl>
give * exactly once * guarantees even in * at least once * mode . <nl>  <nl> { % top % } <nl>  <nl> - # # end - to - end exactly - once programs <nl> - <nl> - ` <nl> - <nl> # # state and fault tolerance in batch programs <nl>  <nl> flink executes [ batch programs ] ( . . / dev / batch / index . html ) as a special case of
when working with state , it might also be useful to read about [ flink ' s state <nl> backends ] ( { % link ops / state / state_backends . md % } ) . flink <nl> provides different state backends that specify how and where state is stored . <nl>  <nl> - * this will be replaced by the toc <nl> - { : toc } <nl> - <nl> - # # what is state ? <nl> - <nl> - ` <nl> - <nl> { % top % } <nl>  <nl> # # state in stream & batch processing
public class checkpubsubemulatortest extends gcloudunittestbase { <nl>  <nl> list < receivedmessage > receivedmessages = pubsubhelper . pullmessages ( project_name , subscription_name , num ) ; <nl>  <nl> - <nl> - if ( receivedmessages . isempty ( ) ) { <nl> - log . error ( " message did not arrive , gonna wait num s and try to pull again . " ) ; <nl> - thread . sleep ( 30 * num ) ; <nl> - receivedmessages = pubsubhelper . pullmessages ( project_name , subscription_name , num ) ; <nl> - } <nl> assertequals ( 1 , receivedmessages . size ( ) ) ; <nl> assertequals ( " hello world pull " , receivedmessages . get ( 0 ) . getmessage ( ) . getdata ( ) . tostringutf8 ( ) ) ; <nl>  <nl>
public abstract class abstractfetcher < t , kph > { <nl> synchronized ( checkpointlock ) { <nl> t record ; <nl> while ( ( record = records . poll ( ) ) ! = null ) { <nl> - long timestamp ; <nl> - <nl> - / / noinspection synchronizationonlocalvariableormethodparameter <nl> - synchronized ( partitionstate ) { <nl> - <nl> - / / you would expect that we don ' t have to do this under lock . you would be wrong : <nl> - / / a watermarkstrategy can wrap an old - style combined <nl> - / / timestamp extractor / watermark assigner , in which case the timestampassigner and <nl> - / / watermarkgenerator wrap one and the same object , where extracting the timestamp <nl> - / / updates the internal state of the assigner . <nl> - timestamp = partitionstate . extracttimestamp ( record , kafkaeventtimestamp ) ; <nl> - } <nl> + long timestamp = partitionstate . extracttimestamp ( record , kafkaeventtimestamp ) ; <nl> sourcecontext . collectwithtimestamp ( record , timestamp ) ; <nl>  <nl> - <nl> - / / we have to move the onevent after the collect call , otherwise the wm would <nl> - / / be emitted before the record <nl> - / / noinspection synchronizationonlocalvariableormethodparameter <nl> - synchronized ( partitionstate ) { <nl> - partitionstate . onevent ( record , timestamp ) ; <nl> - } <nl> + / / this might emit a watermark , so do it after emitting the record <nl> + partitionstate . onevent ( record , timestamp ) ; <nl> } <nl> partitionstate . setoffset ( offset ) ; <nl> } <nl>
public abstract class streamtask < out , op extends streamoperator < out > > <nl>  <nl> resultpartitionwriter [ ] writers = getenvironment ( ) . getallwriters ( ) ; <nl> if ( writers ! = null ) { <nl> - <nl> for ( resultpartitionwriter writer : writers ) { <nl> - writer . readrecoveredstate ( channelstatereader . no_op ) ; <nl> + writer . readrecoveredstate ( getenvironment ( ) . gettaskstatemanager ( ) . getchannelstatereader ( ) ) ; <nl> } <nl> } <nl> } ) ;
public class asyncwaitoperator < in , out > <nl> @ nonnull mailboxexecutor mailboxexecutor ) { <nl> super ( asyncfunction ) ; <nl>  <nl> - <nl> - / / asyncoperators . <nl> - setchainingstrategy ( chainingstrategy . head ) ; <nl> + setchainingstrategy ( chainingstrategy . always ) ; <nl>  <nl> preconditions . checkargument ( capacity > num , " the number of concurrent async operation should be greater than num . " ) ; <nl> this . capacity = capacity ; <nl> mmm a / flink - streaming - java / src / main / java / org / apache / flink / streaming / api / operators / async / asyncwaitoperatorfactory . java <nl> ppp b / flink - streaming - java / src / main / java / org / apache / flink / streaming / api / operators / async / asyncwaitoperatorfactory . java <nl>
as many key groups as the defined maximum parallelism . during execution each <nl> parallel instance of a keyed operator works with the keys for one or more key <nl> groups . <nl>  <nl> - ` <nl> - <nl> - # # operator state <nl> - <nl> - * operator state * ( or * non - keyed state * ) is state that is is bound to one <nl> - parallel operator instance . the [ kafka connector ] ( { { site . baseurl } } { % link <nl> - dev / connectors / kafka . md % } ) is a good motivating example for the use of <nl> - operator state in flink . each parallel instance of the kafka consumer maintains <nl> - a map of topic partitions and offsets as its operator state . <nl> - <nl> - the operator state interfaces support redistributing state among parallel <nl> - operator instances when the parallelism is changed . there can be different <nl> - schemes for doing this redistribution . <nl> - <nl> - # # broadcast state <nl> - <nl> - * broadcast state * is a special type of * operator state * . it was introduced to <nl> - support use cases where some data coming from one stream is required to be <nl> - broadcasted to all downstream tasks , where it is stored locally and is used to <nl> - process all incoming elements on the other stream . as an example where <nl> - broadcast state can emerge as a natural fit , one can imagine a low - throughput <nl> - stream containing a set of rules which we want to evaluate against all elements <nl> - coming from another stream . having the above type of use cases in mind , <nl> - broadcast state differs from the rest of operator states in that : <nl> - num . it has a map format , <nl> - num . it is only available to specific operators that have as inputs a <nl> - * broadcasted * stream and a * non - broadcasted * one , and <nl> - num . such an operator can have * multiple broadcast states * with different names . <nl> - <nl> - { % top % } <nl> - <nl> # # state persistence <nl>  <nl> flink implements fault tolerance using a combination of * * stream replay * * and <nl> mmm a / docs / dev / stream / state / state . md <nl> ppp b / docs / dev / stream / state / state . md <nl>
public abstract class abstractpythonfunctionrunner < in > implements pythonfunction <nl> try { <nl> baos . reset ( ) ; <nl> inputtypeserializer . serialize ( element , baoswrapper ) ; <nl> - <nl> - / / currently , fullwindowedvaluecoder has to be used in beam ' s portability framework . <nl> maininputreceiver . accept ( windowedvalue . valueinglobalwindow ( baos . tobytearray ( ) ) ) ; <nl> } catch ( throwable t ) { <nl> throw new runtimeexception ( " failed to process element when sending data to python sdk harness . " , t ) ; <nl> mmm a / flink - python / src / main / java / org / apache / flink / table / runtime / runners / python / abstractpythonstatelessfunctionrunner . java <nl> ppp b / flink - python / src / main / java / org / apache / flink / table / runtime / runners / python / abstractpythonstatelessfunctionrunner . java <nl>
public class yarnentrypointutils { <nl> configuration . setstring ( jobmanageroptions . address , hostname ) ; <nl> configuration . setstring ( restoptions . address , hostname ) ; <nl>  <nl> - <nl> - / / final string portrange = configuration . getstring ( <nl> - / / configconstants . yarn_application_master_port , <nl> - / / configconstants . default_yarn_job_manager_port ) ; <nl> - <nl> if ( zookeepernamespace ! = null ) { <nl> configuration . setstring ( highavailabilityoptions . ha_cluster_id , zookeepernamespace ) ; <nl> }
public class checkpointedinputgate implements pullingasyncdatainput < bufferoreven <nl> next = inputgate . pollnext ( ) ; <nl> } <nl> else { <nl> - <nl> next = bufferstorage . pollnext ( ) ; <nl> if ( ! next . ispresent ( ) ) { <nl> return pollnext ( ) ;
public class batchabstracttestbase { <nl> new miniclusterresourceconfiguration . builder ( ) <nl> . setconfiguration ( getconfiguration ( ) ) <nl> . setnumbertaskmanagers ( 1 ) <nl> - . setnumberslotspertaskmanager ( default_parallelism * num ) <nl> + . setnumberslotspertaskmanager ( default_parallelism ) <nl> . build ( ) ) ; <nl>  <nl> @ classrule <nl> mmm a / flink - table / flink - table - planner - blink / src / test / scala / org / apache / flink / table / planner / runtime / batch / sql / agg / aggregateitcasebase . scala <nl> ppp b / flink - table / flink - table - planner - blink / src / test / scala / org / apache / flink / table / planner / runtime / batch / sql / agg / aggregateitcasebase . scala <nl>
public class execution implements accessexecution , archiveable < archivedexecution <nl> } <nl>  <nl> private static int getpartitionmaxparallelism ( intermediateresultpartition partition ) { <nl> - <nl> final list < list < executionedge > > consumers = partition . getconsumers ( ) ; <nl> - int maxparallelism = keygrouprangeassignment . upper_bound_max_parallelism ; <nl> - if ( ! consumers . isempty ( ) ) { <nl> - list < executionedge > consumer = consumers . get ( 0 ) ; <nl> - executionjobvertex consumervertex = consumer . get ( 0 ) . gettarget ( ) . getjobvertex ( ) ; <nl> - maxparallelism = consumervertex . getmaxparallelism ( ) ; <nl> - } <nl> + preconditions . checkargument ( ! consumers . isempty ( ) , " currently there has to be exactly one consumer in real jobs " ) ; <nl> + list < executionedge > consumer = consumers . get ( 0 ) ; <nl> + executionjobvertex consumervertex = consumer . get ( 0 ) . gettarget ( ) . getjobvertex ( ) ; <nl> + int maxparallelism = consumervertex . getmaxparallelism ( ) ; <nl> return maxparallelism ; <nl> }
public final class streamtwoinputprocessor < in1 , in2 > implements streaminputproce <nl>  <nl> / / to avoid starvation , if the input selection is all and availableinputsmask is not all , <nl> / / always try to check and set the availability of another input <nl> - <nl> - / / this might be optimized to only check once per processed networkbuffer <nl> if ( inputselectionhandler . shouldsetavailableforanotherinput ( ) ) { <nl> checkandsetavailable ( 1 - readinginputindex ) ; <nl> } <nl>
class scalarfunctionstest extends scalartypestestbase { <nl> " timestampadd ( day , num , date ' 2016 - 06 - 15 ' ) " , <nl> " 2016 - 06 - 16 " ) <nl>  <nl> - <nl> - / / testallapis ( " 2016 - 06 - 15 " . totimestamp - num . hour , <nl> - / / " ' 2016 - 06 - 15 ' . totimestamp - num . hour " , <nl> - / / " timestampadd ( hour , - 1 , date ' 2016 - 06 - 15 ' ) " , <nl> - / / " 2016 - 06 - 14 num : 00 : 00 . 0 " ) <nl> - <nl> - / / testallapis ( " 2016 - 06 - 15 " . totimestamp + num . minute , <nl> - / / " ' 2016 - 06 - 15 ' . totimestamp + num . minute " , <nl> - / / " timestampadd ( minute , num , date ' 2016 - 06 - 15 ' ) " , <nl> - / / " 2016 - 06 - 15 num : 01 : 00 . 0 " ) <nl> - <nl> - / / testallapis ( " 2016 - 06 - 15 " . totimestamp - num . second , <nl> - / / " ' 2016 - 06 - 15 ' . totimestamp - num . second " , <nl> - / / " timestampadd ( sql_tsi_second , - 1 , date ' 2016 - 06 - 15 ' ) " , <nl> - / / " 2016 - 06 - 14 num : 59 : 59 . 0 " ) <nl> - <nl> - / / testallapis ( " 2016 - 06 - 15 " . totimestamp + num . second , <nl> - / / " ' 2016 - 06 - 15 ' . totimestamp + num . second " , <nl> - / / " timestampadd ( second , num , date ' 2016 - 06 - 15 ' ) " , <nl> - / / " 2016 - 06 - 15 num : 00 : 01 . 0 " ) <nl> + testallapis ( " 2016 - 06 - 15 " . totimestamp - num . hour , <nl> + " ' 2016 - 06 - 15 ' . totimestamp - num . hour " , <nl> + " timestampadd ( hour , - 1 , date ' 2016 - 06 - 15 ' ) " , <nl> + " 2016 - 06 - 14 num : 00 : 00 . 000 " ) <nl> + <nl> + testallapis ( " 2016 - 06 - 15 " . totimestamp + num . minute , <nl> + " ' 2016 - 06 - 15 ' . totimestamp + num . minute " , <nl> + " timestampadd ( minute , num , date ' 2016 - 06 - 15 ' ) " , <nl> + " 2016 - 06 - 15 num : 01 : 00 . 000 " ) <nl> + <nl> + testallapis ( " 2016 - 06 - 15 " . totimestamp - num . second , <nl> + " ' 2016 - 06 - 15 ' . totimestamp - num . second " , <nl> + " timestampadd ( sql_tsi_second , - 1 , date ' 2016 - 06 - 15 ' ) " , <nl> + " 2016 - 06 - 14 num : 59 : 59 . 000 " ) <nl> + <nl> + testallapis ( " 2016 - 06 - 15 " . totimestamp + num . second , <nl> + " ' 2016 - 06 - 15 ' . totimestamp + num . second " , <nl> + " timestampadd ( second , num , date ' 2016 - 06 - 15 ' ) " , <nl> + " 2016 - 06 - 15 num : 00 : 01 . 000 " ) <nl>  <nl> testallapis ( nullof ( types . sql_timestamp ) + num . second , <nl> " nullof ( sql_timestamp ) + num . second " ,
class batchexecexchange ( <nl> val inputtype = input . getoutputtype . asinstanceof [ baserowtypeinfo ] <nl> val outputrowtype = baserowtypeinfo . of ( flinktypefactory . tologicalrowtype ( getrowtype ) ) <nl>  <nl> - <nl> - if ( requiredexchangemode . contains ( dataexchangemode . batch ) ) { <nl> - throw new tableexception ( " dataexchangemode . batch is not supported now " ) <nl> + val shufflemode = requiredexchangemode match { <nl> + case none = > shufflemode . pipelined <nl> + case some ( mode ) = > <nl> + mode match { <nl> + case dataexchangemode . batch = > shufflemode . batch <nl> + case dataexchangemode . pipelined = > shufflemode . pipelined <nl> + } <nl> } <nl>  <nl> reldistribution . gettype match { <nl> case reldistribution . type . any = > <nl> val transformation = new partitiontransformation ( <nl> input , <nl> - null ) <nl> + null , <nl> + shufflemode ) <nl> transformation . setoutputtype ( outputrowtype ) <nl> transformation <nl>  <nl> case reldistribution . type . singleton = > <nl> val transformation = new partitiontransformation ( <nl> input , <nl> - new globalpartitioner [ baserow ] ) <nl> + new globalpartitioner [ baserow ] , <nl> + shufflemode ) <nl> transformation . setoutputtype ( outputrowtype ) <nl> transformation <nl>  <nl> case reldistribution . type . random_distributed = > <nl> val transformation = new partitiontransformation ( <nl> input , <nl> - new rebalancepartitioner [ baserow ] ) <nl> + new rebalancepartitioner [ baserow ] , <nl> + shufflemode ) <nl> transformation . setoutputtype ( outputrowtype ) <nl> transformation <nl>  <nl> case reldistribution . type . broadcast_distributed = > <nl> val transformation = new partitiontransformation ( <nl> input , <nl> - new broadcastpartitioner [ baserow ] ) <nl> + new broadcastpartitioner [ baserow ] , <nl> + shufflemode ) <nl> transformation . setoutputtype ( outputrowtype ) <nl> transformation <nl>  <nl>
public class jobwithjars { <nl> try { <nl> jarfile = new file ( jar . touri ( ) ) ; <nl> } catch ( urisyntaxexception e ) { <nl> - throw new ioexception ( " jar file path is invalid ' " + jar + " ' " ) ; <nl> + throw new ioexception ( " jar file path is invalid ' " + jar + ' \ ' ' ) ; <nl> } <nl> if ( ! jarfile . exists ( ) ) { <nl> - throw new ioexception ( " jar file does not exist ' " + jarfile . getabsolutepath ( ) + " ' " ) ; <nl> + throw new ioexception ( " jar file does not exist ' " + jarfile . getabsolutepath ( ) + ' \ ' ' ) ; <nl> } <nl> if ( ! jarfile . canread ( ) ) { <nl> - throw new ioexception ( " jar file can ' t be read ' " + jarfile . getabsolutepath ( ) + " ' " ) ; <nl> + throw new ioexception ( " jar file can ' t be read ' " + jarfile . getabsolutepath ( ) + ' \ ' ' ) ; <nl> + } <nl> + <nl> + try ( jarfile ignored = new jarfile ( jarfile ) ) { <nl> + / / verify that we can open the jar file <nl> + } catch ( ioexception e ) { <nl> + throw new ioexception ( " error while opening jar file ' " + jarfile . getabsolutepath ( ) + ' \ ' ' , e ) ; <nl> } <nl> - <nl> } <nl>  <nl> public static classloader buildusercodeclassloader ( list < url > jars , list < url > classpaths , classloader parent ) { <nl> mmm a / flink - clients / src / main / java / org / apache / flink / client / program / packagedprogram . java <nl> ppp b / flink - clients / src / main / java / org / apache / flink / client / program / packagedprogram . java <nl>
<nl> # see the license for the specific language governing permissions and <nl> # limitations under the license . <nl> # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # <nl> + import logging <nl> import os <nl> + import shutil <nl> + import sys <nl> import tempfile <nl>  <nl> - from pyflink . table import tableenvironment , tableconfig <nl> - from pyflink . table . table_sink import csvtablesink <nl> - from pyflink . table . table_source import csvtablesource <nl> + from pyflink . table import tableenvironment , tableconfig , filesystem , oldcsv , schema <nl> from pyflink . table . types import datatypes <nl>  <nl>  <nl> - # <nl> - # after pyflink have aligned java table api connectors , this example will be improved . <nl> def word_count ( ) : <nl> - tmp_dir = tempfile . gettempdir ( ) <nl> - source_path = tmp_dir + ' / streaming . csv ' <nl> - if os . path . isfile ( source_path ) : <nl> - os . remove ( source_path ) <nl> content = " line licensed to the apache software foundation asf under one " \ <nl> " line or more contributor license agreements see the notice file " \ <nl> " line distributed with this work for additional information " \ <nl>
public abstract class restserverendpoint implements autocloseableasync { <nl>  <nl> completablefuture < void > combinedfuture = futureutils . completeall ( arrays . aslist ( groupfuture , childgroupfuture ) ) ; <nl>  <nl> - <nl> - / / see : https : / / github . com / netty / netty / issues / 4357 <nl> - futureutils . ortimeout ( combinedfuture , graceperiod . tomilliseconds ( ) , timeunit . milliseconds ) ; <nl> - <nl> - combinedfuture <nl> - . exceptionally ( <nl> - ( throwable throwable ) - > { <nl> - if ( throwable instanceof timeoutexception ) { <nl> - / / we ignore timeout exceptions because they indicate that netty ' s shut down deadlocked <nl> - log . info ( " could not properly shut down netty . continue shut down of restserverendpoint . " ) ; <nl> - return null ; <nl> - } else { <nl> - throw new completionexception ( exceptionutils . stripcompletionexception ( throwable ) ) ; <nl> - } <nl> - } ) <nl> - . whencomplete ( <nl> - ( void ignored , throwable throwable ) - > { <nl> - if ( throwable ! = null ) { <nl> - channelterminationfuture . completeexceptionally ( throwable ) ; <nl> - } else { <nl> - channelterminationfuture . complete ( null ) ; <nl> - } <nl> - } ) ; <nl> + combinedfuture . whencomplete ( <nl> + ( void ignored , throwable throwable ) - > { <nl> + if ( throwable ! = null ) { <nl> + channelterminationfuture . completeexceptionally ( throwable ) ; <nl> + } else { <nl> + channelterminationfuture . complete ( null ) ; <nl> + } <nl> + } ) ; <nl> } ) ; <nl>  <nl> return channelterminationfuture ;
public class flinkyarnsessionclitest extends testlogger { <nl> assertequals ( " - dappname = foobar " , dynproperties . get ( " env . java . opts " ) ) ; <nl> } <nl>  <nl> - @ test <nl> - public void testnotenoughtaskslots ( ) throws exception { <nl> - string [ ] params = <nl> - new string [ ] { " - yn " , " 2 " , " - ys " , " 3 " , " - p " , " 7 " } ; <nl> - <nl> - flinkyarnsessioncli yarncli = new flinkyarnsessioncli ( <nl> - new configuration ( ) , <nl> - tmp . getroot ( ) . getabsolutepath ( ) , <nl> - " y " , <nl> - " yarn " ) ; <nl> - <nl> - options options = new options ( ) ; <nl> - <nl> - options . addoption ( clifrontendparser . parallelism_option ) ; <nl> - yarncli . addgeneraloptions ( options ) ; <nl> - yarncli . addrunoptions ( options ) ; <nl> - <nl> - final commandline commandline = clifrontendparser . parse ( options , params , true ) ; <nl> - <nl> - clusterspecification clusterspecification = yarncli . getclusterspecification ( commandline ) ; <nl> - <nl> - / / each task manager has num slots but the parallelism is num . thus the slots should be increased . <nl> - assertequals ( 4 , clusterspecification . getslotspertaskmanager ( ) ) ; <nl> - assertequals ( 2 , clusterspecification . getnumbertaskmanagers ( ) ) ; <nl> - } <nl> - <nl> @ test <nl> public void testcorrectsettingofmaxslots ( ) throws exception { <nl> string [ ] params =
public abstract class clusterentrypoint implements fatalerrorhandler { <nl> log . info ( " initializing cluster services . " ) ; <nl>  <nl> final string bindaddress = configuration . getstring ( jobmanageroptions . address ) ; <nl> - <nl> - final string portrange = string . valueof ( configuration . getinteger ( jobmanageroptions . port ) ) ; <nl> + final string portrange = getrpcportrange ( configuration ) ; <nl>  <nl> commonrpcservice = createrpcservice ( configuration , bindaddress , portrange ) ; <nl> + <nl> + / / update the configuration used to create the high availability services <nl> + configuration . setstring ( jobmanageroptions . address , commonrpcservice . getaddress ( ) ) ; <nl> + configuration . setinteger ( jobmanageroptions . port , commonrpcservice . getport ( ) ) ; <nl> + <nl> haservices = createhaservices ( configuration , commonrpcservice . getexecutor ( ) ) ; <nl> blobserver = new blobserver ( configuration , haservices . createblobstore ( ) ) ; <nl> blobserver . start ( ) ; <nl>
abstract class nettymessage { <nl> } <nl>  <nl> static taskeventrequest readfrom ( bytebuf buffer , classloader classloader ) throws ioexception { <nl> - <nl> int length = buffer . readint ( ) ; <nl> - bytebuffer serializedevent = bytebuffer . allocate ( length ) ; <nl> - <nl> - buffer . readbytes ( serializedevent ) ; <nl> - serializedevent . flip ( ) ; <nl> + bytebuffer serializedevent = buffer . niobuffer ( buffer . readerindex ( ) , length ) ; <nl> + / / assume this event ' s content is read from the bytebuf ( positions are not shared ! ) <nl> + buffer . readerindex ( buffer . readerindex ( ) + length ) ; <nl>  <nl> taskevent event = <nl> ( taskevent ) eventserializer . fromserializedevent ( serializedevent , classloader ) ;
public class keyedjob { <nl> . map ( new statefulstringstoringmap ( mode , " first " ) ) <nl> . setparallelism ( 4 ) ; <nl>  <nl> - <nl> - / / if ( mode = = executionmode . migrate | | mode = = executionmode . restore ) { <nl> - map . uid ( " first " ) ; <nl> - / / } <nl> + if ( mode = = executionmode . migrate | | mode = = executionmode . restore ) { <nl> + map . uid ( " first " ) ; <nl> + } <nl>  <nl> return map ; <nl> } <nl>
public class keyedjob { <nl> . map ( new statefulstringstoringmap ( mode , " second " ) ) <nl> . setparallelism ( 4 ) ; <nl>  <nl> - <nl> - / / if ( mode = = executionmode . migrate | | mode = = executionmode . restore ) { <nl> - map . uid ( " second " ) ; <nl> - / / } <nl> + if ( mode = = executionmode . migrate | | mode = = executionmode . restore ) { <nl> + map . uid ( " second " ) ; <nl> + } <nl>  <nl> return map ; <nl> } <nl> binary files a / flink - tests / src / test / resources / operatorstate / complexkeyed / _metadata and b / flink - tests / src / test / resources / operatorstate / complexkeyed / _metadata differ
public class sharedstateregistry { <nl> private final executor asyncdisposalexecutor ; <nl>  <nl> public sharedstateregistry ( ) { <nl> + this ( executors . directexecutor ( ) ) ; <nl> + } <nl> + <nl> + public sharedstateregistry ( executor asyncdisposalexecutor ) { <nl> this . registeredstates = new hashmap < > ( ) ; <nl> - this . asyncdisposalexecutor = executors . directexecutor ( ) ; <nl> + this . asyncdisposalexecutor = preconditions . checknotnull ( asyncdisposalexecutor ) ; <nl> } <nl>  <nl> / * *
public class kafka010itcase extends kafkaconsumertestbase { <nl> runstartfromkafkacommitoffsets ( ) ; <nl> } <nl>  <nl> - <nl> - / / @ test ( timeout = num ) <nl> - / / public void testautooffsetretrievalandcommittokafka ( ) throws exception { <nl> - / / runautooffsetretrievalandcommittokafka ( ) ; <nl> - / / } <nl> + @ test ( timeout = num ) <nl> + public void testautooffsetretrievalandcommittokafka ( ) throws exception { <nl> + runautooffsetretrievalandcommittokafka ( ) ; <nl> + } <nl>  <nl> / * * <nl> * kafka num . 10 specific test , ensuring timestamps are properly written to and read from kafka <nl> mmm a / flink - streaming - connectors / flink - connector - kafka - 0 . 9 / src / main / java / org / apache / flink / streaming / connectors / kafka / internal / kafka09fetcher . java <nl> ppp b / flink - streaming - connectors / flink - connector - kafka - 0 . 9 / src / main / java / org / apache / flink / streaming / connectors / kafka / internal / kafka09fetcher . java <nl>
public class kafka09itcase extends kafkaconsumertestbase { <nl> runstartfromkafkacommitoffsets ( ) ; <nl> } <nl>  <nl> - <nl> - / / @ test ( timeout = num ) <nl> - / / public void testautooffsetretrievalandcommittokafka ( ) throws exception { <nl> - / / runautooffsetretrievalandcommittokafka ( ) ; <nl> - / / } <nl> + @ test ( timeout = num ) <nl> + public void testautooffsetretrievalandcommittokafka ( ) throws exception { <nl> + runautooffsetretrievalandcommittokafka ( ) ; <nl> + } <nl> }
object tableprogramstestbase { <nl> } <nl>  <nl> @ parameterized . parameters ( name = " execution mode = { 0 } , table config = { 1 } " ) <nl> - def tableconfigs ( ) : util . collection [ array [ java . lang . object ] ] = { <nl> - seq ( <nl> - <nl> - array [ anyref ] ( testexecutionmode . cluster , tableconfigmode . default ) , <nl> - array [ anyref ] ( testexecutionmode . collection , tableconfigmode . default ) , <nl> - array [ anyref ] ( testexecutionmode . collection , tableconfigmode . null ) , <nl> - array [ anyref ] ( testexecutionmode . collection , tableconfigmode . efficient ) <nl> - ) <nl> + def parameters ( ) : util . collection [ array [ java . lang . object ] ] = { <nl> + seq [ array [ anyref ] ] ( array ( testexecutionmode . collection , tableconfigmode . default ) ) <nl> } <nl> }
public class sourcefunctiontest { <nl> num ) ) ; <nl> assertequals ( expectedlist , actuallist ) ; <nl> } <nl> - <nl> - <nl> - / / @ test <nl> - / / public void sockettextstreamtest ( ) throws exception { <nl> - / / list < string > expectedlist = arrays . aslist ( " a " , " b " , " c " ) ; <nl> - / / list < string > actuallist = new arraylist < string > ( ) ; <nl> - / / <nl> - / / byte [ ] data = { ' a ' , ' \n ' , ' b ' , ' \n ' , ' c ' , ' \n ' } ; <nl> - / / <nl> - / / socket socket = mock ( socket . class ) ; <nl> - / / when ( socket . getinputstream ( ) ) . thenreturn ( new bytearrayinputstream ( data ) ) ; <nl> - / / when ( socket . isclosed ( ) ) . thenreturn ( false ) ; <nl> - / / when ( socket . isconnected ( ) ) . thenreturn ( true ) ; <nl> - / / <nl> - / / sockettextstreamfunction source = new sockettextstreamfunction ( " " , num , ' \n ' , num ) ; <nl> - / / source . open ( new configuration ( ) ) ; <nl> - / / while ( ! source . reachedend ( ) ) { <nl> - / / actuallist . add ( source . next ( ) ) ; <nl> - / / } <nl> - / / assertequals ( expectedlist , actuallist ) ; <nl> - / / } <nl> }
import org . apache . flink . api . java . tuple . tuple ; <nl> public class keyselectorutil { <nl>  <nl> public static < x > keyselector < x , ? > getselectorforkeys ( keys < x > keys , typeinformation < x > typeinfo , executionconfig executionconfig ) { <nl> + if ( ! ( typeinfo instanceof compositetype ) ) { <nl> + throw new invalidtypesexception ( <nl> + " this key operation requires a composite type such as tuples , pojos , or case classes . " ) ; <nl> + } <nl> + <nl> + compositetype < x > compositetype = ( compositetype < x > ) typeinfo ; <nl> + <nl> int [ ] logicalkeypositions = keys . computelogicalkeypositions ( ) ; <nl> - int keylength = logicalkeypositions . length ; <nl> - boolean [ ] orders = new boolean [ keylength ] ; <nl> - <nl> - typecomparator < x > comparator = ( ( compositetype < x > ) typeinfo ) . createcomparator ( <nl> - logicalkeypositions , orders , num , executionconfig ) ; <nl> - return new comparablekeyselector < x > ( comparator , keylength ) ; <nl> + int numkeyfields = logicalkeypositions . length ; <nl> + <nl> + / / use ascending order here , the code paths for that are usually a slight bit faster <nl> + boolean [ ] orders = new boolean [ numkeyfields ] ; <nl> + for ( int i = num ; i < numkeyfields ; i + + ) { <nl> + orders [ i ] = true ; <nl> + } <nl> + <nl> + typecomparator < x > comparator = compositetype . createcomparator ( logicalkeypositions , orders , num , executionconfig ) ; <nl> + return new comparablekeyselector < x > ( comparator , numkeyfields ) ; <nl> } <nl>  <nl> + <nl> public static < x , k > keyselector < x , k > getselectorforonekey ( keys < x > keys , partitioner < k > partitioner , typeinformation < x > typeinfo , <nl> executionconfig executionconfig ) { <nl> if ( partitioner ! = null ) { <nl>
public class typeextractortest { <nl> + " > > > " , ti . tostring ( ) ) ; <nl>  <nl> / / generic array <nl> - <nl> - / / ti = typeextractor . getmapreturntypes ( ( mapfunction ) new mapperwithmultidimgenericarray < string > ( ) , typeinfoparser . parse ( " string [ ] [ ] [ ] " ) ) ; <nl> - / / assert . assertequals ( " objectarraytypeinfo < objectarraytypeinfo < objectarraytypeinfo < java tuple1 < string > > > > " , ) ; <nl> + ti = typeextractor . getmapreturntypes ( ( mapfunction ) new mapperwithmultidimgenericarray < string > ( ) , typeinfoparser . parse ( " string [ ] [ ] [ ] " ) ) ; <nl> + assert . assertequals ( " objectarraytypeinfo < objectarraytypeinfo < objectarraytypeinfo < java tuple1 < string > > > > " , ti . tostring ( ) ) ; <nl> + } <nl> + <nl> + @ suppresswarnings ( " rawtypes " ) <nl> + public static class mapwithresulttypequeryable implements mapfunction , resulttypequeryable { <nl> + private static final long serialversionuid = num l ; <nl> + <nl> + @ override <nl> + public typeinformation getproducedtype ( ) { <nl> + return basictypeinfo . string_type_info ; <nl> + } <nl> + <nl> + @ override <nl> + public object map ( object value ) throws exception { <nl> + return null ; <nl> + } <nl> + } <nl> + <nl> + @ suppresswarnings ( { " unchecked " , " rawtypes " } ) <nl> + @ test <nl> + public void testinputmismatchwithrawfuntion ( ) { <nl> + mapfunction < ? , ? > function = new mapwithresulttypequeryable ( ) ; <nl> + <nl> + typeinformation < ? > ti = typeextractor . getmapreturntypes ( ( mapfunction ) function , basictypeinfo . int_type_info ) ; <nl> + assert . assertequals ( basictypeinfo . string_type_info , ti ) ; <nl> } <nl> }
public class streamcollector < t extends tuple > implements collector < t > { <nl>  <nl> try { <nl> output . emit ( streamrecord ) ; <nl> - <nl> - output . flush ( ) ; <nl> + / / output . flush ( ) ; <nl> } catch ( exception e ) { <nl> e . printstacktrace ( ) ; <nl> system . out . println ( " emit fail " ) ; <nl> mmm a / flink - addons / flink - streaming / flink - streaming - core / src / main / java / org / apache / flink / streaming / api / streamcomponent / streamiterationsource . java <nl> ppp b / flink - addons / flink - streaming / flink - streaming - core / src / main / java / org / apache / flink / streaming / api / streamcomponent / streamiterationsource . java <nl>
<nl> < forkmode > once < / forkmode > <nl> < argline > - xmx1024m < / argline > <nl> < / configuration > <nl> - < / plugin > <nl> - < ! - - <nl> + < / plugin > <nl> < plugin > <nl> - < groupid > org . apache . rat < / groupid > <nl> - < artifactid > apache - rat - plugin < / artifactid > <nl> - < version > 0 . 10 < / version > <nl> - < executions > <nl> - < execution > <nl> - < phase > verify < / phase > <nl> - < goals > <nl> - < goal > check < / goal > <nl> - < / goals > <nl> - < / execution > <nl> - < / executions > <nl> - < configuration > <nl> - < excludesubprojects > false < / excludesubprojects > <nl> - < numunapprovedlicenses > 0 < / numunapprovedlicenses > <nl> - < excludes > <nl> - < ! - - additional files like . gitignore etc . - - > <nl> - < exclude > * * / . * < / exclude > <nl> - < exclude > * * / * . prefs < / exclude > <nl> - < ! - - resource files which have values . - - > <nl> - < exclude > * * / resources / * * < / exclude > <nl> - < ! - - configuration files . - - > <nl> - < exclude > * * / stratosphere - bin / conf / slaves < / exclude > <nl> - < ! - - administrative files in the main trunk . - - > <nl> - < exclude > readme . md < / exclude > <nl> - < exclude > changelog < / exclude > <nl> - < exclude > * * / * . creole < / exclude > <nl> - < exclude > contributors < / exclude > <nl> - < ! - - build fiels - - > <nl> - < exclude > * * / pom . xml < / exclude > <nl> - < exclude > * * / * . iml < / exclude > <nl> - < ! - - generated content - - > <nl> - < exclude > * * / target / * * < / exclude > <nl> - < / excludes > <nl> - < / configuration > <nl> - < / plugin > <nl> + < groupid > org . apache . rat < / groupid > <nl> + < artifactid > apache - rat - plugin < / artifactid > <nl> + < version > 0 . 10 < / version > <nl> + < executions > <nl> + < execution > <nl> + < phase > verify < / phase > <nl> + < goals > <nl> + < goal > check < / goal > <nl> + < / goals > <nl> + < / execution > <nl> + < / executions > <nl> + < configuration > <nl> + < excludesubprojects > false < / excludesubprojects > <nl> + < numunapprovedlicenses > 0 < / numunapprovedlicenses > <nl> + < excludes > <nl> + < ! - - additional files like . gitignore etc . - - > <nl> + < exclude > * * / . * < / exclude > <nl> + < ! - - resource files which have values . - - > <nl> + < exclude > * * / resources / * * < / exclude > <nl> + < ! - - configuration files . - - > <nl> + < exclude > * * / stratosphere - bin / conf / slaves < / exclude > <nl> + < ! - - administrative files in the main trunk . - - > <nl> + < exclude > readme . md < / exclude > <nl> + < exclude > changelog < / exclude > <nl> + < exclude > contributors < / exclude > <nl> + < ! - - build fields - - > <nl> + < exclude > * * / pom . xml < / exclude > <nl> + < ! - - generated content - - > <nl> + < exclude > * * / target / * * < / exclude > <nl> + < / excludes > <nl> + < / configuration > <nl> + < / plugin > <nl> < / plugins > <nl> < / build > <nl> < / project >
public class faulttolerancebuffer { <nl> * @ param recordid <nl> * id of the record that has been acknowledged <nl> * <nl> - * @ param outputchannel <nl> + * @ param output <nl> * number of the output channel that sent the ack <nl> * / <nl> - public void ackrecord ( string recordid , int outputchannel ) { <nl> + public void ackrecord ( string recordid , int output ) { <nl> if ( ackmap . containskey ( recordid ) ) { <nl> - int [ ] acks = ackmap . get ( recordid ) ; <nl> - acks [ outputchannel ] - - ; <nl> - <nl> - <nl> - if ( allzero ( acks ) ) { <nl> + if ( decreaseackcounter ( recordid , output ) ) { <nl> removerecord ( recordid ) ; <nl> } <nl> } <nl> } <nl> - <nl> - / * * <nl> - * checks whether an int array contains only zeros . <nl> - * <nl> - * @ param values <nl> - * the array to check <nl> - * @ return true only if the array contains only zeros <nl> - * / <nl> - private static boolean allzero ( int [ ] values ) { <nl> - for ( int value : values ) { <nl> - if ( value ! = num ) <nl> - return false ; <nl> + <nl> + private boolean decreaseackcounter ( string recordid , int output ) { <nl> + int [ ] acks = ackmap . get ( recordid ) ; <nl> + acks [ output + num ] - - ; <nl> + if ( acks [ output + num ] = = num ) { <nl> + acks [ 0 ] + + ; <nl> } <nl> - return true ; <nl> + <nl> + return ( acks [ 0 ] = = numberofoutputs ) ; <nl> } <nl>  <nl> / * * <nl>
public class streamsource extends abstractinputtask < randis > { <nl> channelselector . class ) ; <nl>  <nl> try { <nl> - <nl> - if ( partitioner . getname ( ) . equals ( <nl> - " eu . stratosphere . streaming . partitioner . fieldspartitioner " ) ) { <nl> + if ( partitioner . equals ( fieldspartitioner . class ) ) { <nl> int keyposition = taskconfiguration . getinteger ( " partitionerintparam_ " <nl> + nroutput , num ) ; <nl> class < ? extends key > keyclass = taskconfiguration . getclass ( <nl> mmm a / flink - addons / flink - streaming / src / main / java / eu / stratosphere / streaming / api / streamtask . java <nl> ppp b / flink - addons / flink - streaming / src / main / java / eu / stratosphere / streaming / api / streamtask . java <nl>
public class streamtask extends abstracttask { <nl> channelselector . class ) ; <nl>  <nl> try { <nl> - <nl> - if ( partitioner . getname ( ) . equals ( <nl> - " eu . stratosphere . streaming . partitioner . fieldspartitioner " ) ) { <nl> + if ( partitioner . equals ( fieldspartitioner . class ) ) { <nl> int keyposition = taskconfiguration . getinteger ( " partitionerintparam_ " <nl> + nroutput , num ) ; <nl> class < ? extends key > keyclass = taskconfiguration . getclass (
public class jobgraphbuilder { <nl> components . put ( sinkname , sink ) ; <nl> } <nl>  <nl> - <nl> - / / of connecting , may use getnumberofbackwardconnections ( ) <nl> public void connect ( string upstreamcomponentname , <nl> string downstreamcomponentname , channeltype channeltype ) { <nl>  <nl> abstractjobvertex upstreamcomponent = components . get ( upstreamcomponentname ) ; <nl> abstractjobvertex downstreamcomponent = components . get ( downstreamcomponentname ) ; <nl>  <nl> - configuration config = new taskconfig ( <nl> - downstreamcomponent . getconfiguration ( ) ) . getconfiguration ( ) ; <nl> - config . setinteger ( " numberofinputs " , <nl> - config . getinteger ( " numberofinputs " , num ) + num ) ; <nl> - components . remove ( downstreamcomponentname ) ; <nl> - components . put ( downstreamcomponentname , downstreamcomponent ) ; <nl> - <nl> try { <nl> upstreamcomponent . connectto ( downstreamcomponent , channeltype ) ; <nl> } catch ( jobgraphdefinitionexception e ) { <nl>
public class pactprogram { <nl> } <nl> } <nl>  <nl> - / * * <nl> - * returns the description provided by the planassembler class without <nl> - * any html tags . this may contain a description of the plan itself <nl> - * and its arguments . <nl> - * <nl> - * @ return the description of the pactprogram ' s input parameters without html mark - up . <nl> - * @ throws programinvocationexception <nl> - * this invocation is thrown if the planassembler can ' t be properly loaded . causes <nl> - * may be a missing / wrong class or manifest files . <nl> - * @ throws errorinplanassemblerexception <nl> - * thrown if an error occurred in the user - provided pact assembler . this may indicate <nl> - * missing parameters for generation . <nl> - * / <nl> - public string gettextdescription ( ) throws programinvocationexception { <nl> - string descr = getdescription ( ) ; <nl> - if ( descr = = null | | descr . length ( ) = = num ) { <nl> - return null ; <nl> - } else { <nl> - <nl> - matcher m = break_tags . matcher ( descr ) ; <nl> - descr = m . replaceall ( " \n " ) ; <nl> - m = remove_tags . matcher ( descr ) ; <nl> - <nl> - return m . replaceall ( " " ) ; <nl> - } <nl> - } <nl> - <nl> / * * <nl> * takes all jar files that are contained in this program ' s jar file and extracts them <nl> * to the system ' s temp directory .
class transitiveclosurenaive extends serializable { <nl> def createclosure ( paths : datastream [ path ] ) = { <nl>  <nl> val allnewpaths = paths join edges where { p = > p . to } isequalto { p = > p . from } map joinpaths <nl> - <nl> val shortestpaths = allnewpaths union paths groupby { p = > ( p . from , p . to ) } reducegroup { _ minby { _ . dist } } <nl>  <nl> / / val delta = paths cogroup shortestpaths where { p = > ( p . from , p . to ) } isequalto { p = > ( p . from , p . to ) } flatmap { ( oldpaths , newpaths ) = >
class kmeans extends planassembler with planassemblerdescription with serializab <nl>  <nl> val distances = datapoints cross centers map computedistance <nl> val nearestcenters = distances groupby { case ( pid , _ ) = > pid } combinablegroupreduce { ds = > ds . minby ( _ . _2 . distance ) } map aspointsum . tupled <nl> - val newcenters = nearestcenters groupby { case ( cid , _ ) = > cid } groupreduce sumpointsums <nl> - <nl> - / / val newcenters = nearestcenters groupby { case ( cid , _ ) = > cid } groupreduce sumpointsums map { case ( cid , psum ) = > cid - > psum . topoint ( ) } <nl> + val newcenters = nearestcenters groupby { case ( cid , _ ) = > cid } combinablegroupreduce sumpointsums map { case ( cid , psum ) = > cid - > psum . topoint ( ) } <nl>  <nl> / / distances . left neglects { case ( pid , _ ) = > pid } <nl> / / distances . left preserves ( { dp = > dp } , { case ( pid , dist ) = > ( pid , dist . datapoint ) } )
import java . io . ioexception ; <nl> public class workerdoneevent extends abstracttaskevent { <nl>  <nl> private int workerindex ; <nl> - <nl> - / / private long aggregate ; <nl> private value aggregate ; <nl>  <nl> public workerdoneevent ( ) { } <nl>
public final class rpcservice { <nl> / / request is no longer pending <nl> this . pendingrequests . remove ( messageid ) ; <nl>  <nl> - <nl> - <nl> packets = messagetopackets ( remotesocketaddress , new rpccleanup ( request . getmessageid ( ) ) ) ; <nl> sendpackets ( packets ) ; <nl>  <nl>
public final class rpcservice { <nl>  <nl> this . pendingrequests . remove ( messageid ) ; <nl>  <nl> - <nl> - <nl> throw new ioexception ( " unable to complete rpc of method " + request . getmethodname ( ) + " on " <nl> + remotesocketaddress ) ; <nl> } <nl>
public class queuescheduler extends abstractscheduler implements jobstatuslisten <nl> log . error ( " cannot find job " + executiongraphtoremove . getjobname ( ) + " ( " <nl> + executiongraphtoremove . getjobid ( ) + " ) to remove " ) ; <nl> } <nl> - <nl> - <nl> } <nl>  <nl> / * * <nl> mmm a / nephele / nephele - server / src / main / java / eu / stratosphere / nephele / checkpointing / replayoutputchannelcontext . java <nl> ppp b / nephele / nephele - server / src / main / java / eu / stratosphere / nephele / checkpointing / replayoutputchannelcontext . java <nl>
public class jobmanager implements deploymentmanager , extendedmanagementprotocol <nl> final instanceconnectioninfo ici = assignedinstance . getinstanceconnectioninfo ( ) ; <nl> final inetsocketaddress isa = new inetsocketaddress ( ici . getaddress ( ) , ici . getdataport ( ) ) ; <nl>  <nl> - <nl> - return connectioninfolookupresponse . createreceiverfoundandready ( new remotereceiver ( isa , num ) ) ; <nl> + return connectioninfolookupresponse . createreceiverfoundandready ( new remotereceiver ( isa , edge <nl> + . getconnectionid ( ) ) ) ; <nl> } <nl> } <nl>  <nl> mmm a / nephele / nephele - server / src / main / java / eu / stratosphere / nephele / jobmanager / splitassigner / file / fileinputsplitassigner . java <nl> ppp b / nephele / nephele - server / src / main / java / eu / stratosphere / nephele / jobmanager / splitassigner / file / fileinputsplitassigner . java <nl>
public abstract class abstractexecutionlistener implements executionlistener { <nl> } <nl>  <nl> } else { <nl> - <nl> + <nl> + / / make sure the map with the vertices to be restarted is cleaned up properly <nl> + synchronized ( eg ) { <nl> + <nl> + final iterator < executionvertex > it = this . scheduler . getverticestoberestarted ( ) . values ( ) <nl> + . iterator ( ) ; <nl> + <nl> + while ( it . hasnext ( ) ) { <nl> + if ( eg . equals ( it . next ( ) . getexecutiongraph ( ) ) ) { <nl> + it . remove ( ) ; <nl> + } <nl> + } <nl> + } <nl> + <nl> + / / actual cancellation of job is performed by job manager <nl> } <nl> } <nl> }
public final class fileinputsplitassigner implements inputsplitassigner { <nl> * / <nl> @ override <nl> public void unregistergroupvertex ( final executiongroupvertex groupvertex ) { <nl> - <nl> - <nl> + vertexmap . remove ( groupvertex ) ; <nl> } <nl>  <nl> / * *
public class lazytailarraynode extends jsonnode implements iarraynode { <nl>  <nl> @ override <nl> public iarraynode add ( int index , ijsonnode element ) { <nl> - <nl> if ( element = = null ) { <nl> throw new nullpointerexception ( ) ; <nl> } <nl>
public class lazytailarraynode extends jsonnode implements iarraynode { <nl> for ( int i = num ; i < = this . schema . gettailsize ( ) ; i + + ) { <nl> if ( ! this . record . isnull ( i ) ) { <nl> count + + ; <nl> - } else <nl> - return count ; <nl> + } <nl> } <nl> return count + others . size ( ) ; <nl> } <nl>  <nl> @ override <nl> public iarraynode add ( ijsonnode node ) { <nl> - <nl> if ( node = = null ) { <nl> throw new nullpointerexception ( ) ; <nl> } <nl>
public class lazytailarraynode extends jsonnode implements iarraynode { <nl>  <nl> @ override <nl> public ijsonnode get ( int index ) { <nl> - <nl> int size = this . size ( ) ; <nl> if ( <nl> return missingnode . getinstance ( ) ; <nl> } <nl>  <nl> if ( size < = this . schema . gettailsize ( ) ) { <nl> - return sopremoutil . unwrap ( this . record . getfield ( this . schema . gettailsize ( ) - size + <nl> - <nl> + return sopremoutil . unwrap ( this . record . getfield ( this . schema . gettailsize ( ) - size + <nl> + jsonnodewrapper . class ) ) ; <nl> + <nl> } else { <nl> return this . getotherfield ( ) . get ( index ) ; <nl> - <nl> + <nl> } <nl> } <nl>  <nl>
public class lazytailarraynode extends jsonnode implements iarraynode { <nl>  <nl> @ override <nl> public void clear ( ) { <nl> - <nl> for ( int i = num ; i < = this . schema . gettailsize ( ) ; i + + ) { <nl> this . record . setnull ( i ) ; <nl> }
public class generalschema implements schema { <nl> if ( target = = null ) { <nl> return source ; <nl> } <nl> - return this . recycletargetnode ( target , source ) ; <nl> + return this . reusetargetnode ( target , source ) ; <nl> } <nl>  <nl> - private ijsonnode recycletargetnode ( ijsonnode target , ijsonnode source ) { <nl> + private ijsonnode reusetargetnode ( ijsonnode target , ijsonnode source ) { <nl> + target . clear ( ) ; <nl> if ( target . isobject ( ) ) { <nl> - ( ( iobjectnode ) target ) . removeall ( ) ; <nl> ( ( iobjectnode ) target ) . putall ( ( iobjectnode ) source ) ; <nl> } else if ( target . isarray ( ) ) { <nl> - ( ( iarraynode ) target ) . clear ( ) ; <nl> ( ( iarraynode ) target ) . addall ( ( iarraynode ) source ) ; <nl> } else { <nl> / / target must be a primitivenode <nl> - <nl> - <nl> - target = source ; <nl> + if ( source . getclass ( ) ! = target . getclass ( ) ) { <nl> + target = source ; <nl> + } else { <nl> + target = this . reuseprimitive ( source , target , source . getclass ( ) ) ; <nl> + } <nl> } <nl>  <nl> return target ; <nl> } <nl>  <nl> + private ijsonnode reuseprimitive ( ijsonnode source , ijsonnode target , class < ? extends ijsonnode > clazz ) { <nl> + if ( clazz . equals ( booleannode . class ) | | clazz . equals ( nullnode . class ) ) { <nl> + return source ; <nl> + } <nl> + if ( clazz . equals ( intnode . class ) ) { <nl> + ( ( intnode ) target ) . setvalue ( ( ( intnode ) source ) . getintvalue ( ) ) ; <nl> + } else if ( clazz . equals ( doublenode . class ) ) { <nl> + ( ( doublenode ) target ) . setvalue ( ( ( doublenode ) source ) . getdoublevalue ( ) ) ; <nl> + } else if ( clazz . equals ( longnode . class ) ) { <nl> + ( ( longnode ) target ) . setvalue ( ( ( longnode ) source ) . getlongvalue ( ) ) ; <nl> + } else if ( clazz . equals ( decimalnode . class ) ) { <nl> + ( ( decimalnode ) target ) . setvalue ( ( ( decimalnode ) source ) . getdecimalvalue ( ) ) ; <nl> + } else if ( clazz . equals ( bigintegernode . class ) ) { <nl> + ( ( bigintegernode ) target ) . setvalue ( ( ( bigintegernode ) source ) . getbigintegervalue ( ) ) ; <nl> + } <nl> + return target ; <nl> + } <nl> + <nl> @ override <nl> public int [ ] indicesof ( evaluationexpression expression ) { <nl> int
public class localfilesystem extends filesystem { <nl> * / <nl> @ override <nl> public fsdatainputstream open ( final path f , final int buffersize ) throws ioexception { <nl> - <nl> - return null ; <nl> + return open ( f ) ; <nl> } <nl>  <nl> / * *
final class replayinputgatecontext extends abstractreplaygatecontext implements <nl> * / <nl> @ override <nl> public localbufferpoolowner getlocalbufferpoolowner ( ) { <nl> - <nl> + <nl> return null ; <nl> } <nl>  <nl> mmm a / nephele / nephele - server / src / main / java / eu / stratosphere / nephele / checkpointing / replaytaskcontext . java <nl> ppp b / nephele / nephele - server / src / main / java / eu / stratosphere / nephele / checkpointing / replaytaskcontext . java <nl>
final class replaytaskcontext implements taskcontext { <nl> * / <nl> @ override <nl> public inputgatecontext createinputgatecontext ( final gateid gateid ) { <nl> - <nl> - return null ; <nl> + <nl> + return new replayinputgatecontext ( gateid ) ; <nl> } <nl>  <nl> / * *
public final class replaytask implements task { <nl> reportexecutionstatechange ( true , " execution thread died unexpectedly " ) ; <nl> } <nl>  <nl> + / * * <nl> + * { @ inheritdoc } <nl> + * / <nl> @ override <nl> public boolean isterminated ( ) { <nl> - <nl> + <nl> + if ( this . encapsulatedtask ! = null ) { <nl> + if ( this . encapsulatedtask . isterminated ( ) ) { <nl> + return true ; <nl> + } <nl> + } <nl> + <nl> + final thread executingthread = this . environment . getexecutingthread ( ) ; <nl> + if ( executingthread . getstate ( ) = = thread . state . terminated ) { <nl> + return true ; <nl> + } <nl> + <nl> return false ; <nl> } <nl>  <nl>
public class matchtaskexternalitcase extends tasktestbase { <nl> super . gettaskconfig ( ) . setlocalstrategykeytypes ( 0 , new int [ ] { 0 } ) ; <nl> super . gettaskconfig ( ) . setlocalstrategykeytypes ( 1 , new int [ ] { 0 } ) ; <nl> super . gettaskconfig ( ) . setlocalstrategykeytypes ( new class [ ] { pactinteger . class } ) ; <nl> - <nl>  <nl> super . registertask ( testtask , mockmatchstub . class ) ; <nl>  <nl>
public class combinernode extends optimizernode { <nl> @ override <nl> public void deriveoutputschema ( ) { <nl> / / output of combiner is same as output of reduce , do nothing <nl> - <nl> } <nl>  <nl> }
public class swtvisualizationgui implements selectionlistener , runnable { <nl>  <nl> private void managefailurepatterns ( ) { <nl>  <nl> - <nl> - final set < string > emptyset = collections . emptyset ( ) ; <nl> + final set < string > jobsuggestions = new hashset < string > ( ) ; <nl> + final set < string > namesuggestions = new hashset < string > ( ) ; <nl>  <nl> - this . failurepatternsmanager . openeditor ( this . shell , emptyset , emptyset ) ; <nl> + final iterator < graphvisualizationdata > it = this . recentjobs . values ( ) . iterator ( ) ; <nl> + while ( it . hasnext ( ) ) { <nl> + <nl> + final graphvisualizationdata gvd = it . next ( ) ; <nl> + <nl> + jobsuggestions . add ( gvd . getjobname ( ) ) ; <nl> + <nl> + final managementgraphiterator mgi = new managementgraphiterator ( gvd . getmanagementgraph ( ) , true ) ; <nl> + while ( mgi . hasnext ( ) ) { <nl> + <nl> + final managementvertex vertex = mgi . next ( ) ; <nl> + final string vertexname = ( vertex . getname ( ) ! = null ) ? vertex . getname ( ) : " null " ; <nl> + final string vertexnamewithindex = vertexname + " " + ( vertex . getindexingroup ( ) + num ) ; <nl> + namesuggestions . add ( vertexnamewithindex ) ; <nl> + if ( vertex . getinstancename ( ) ! = null ) { <nl> + namesuggestions . add ( vertex . getinstancename ( ) ) ; <nl> + } <nl> + } <nl> + } <nl> + <nl> + this . failurepatternsmanager . openeditor ( this . shell , jobsuggestions , namesuggestions ) ; <nl> } <nl>  <nl> private void logbufferutilization ( ) {
public class streamingtaskmanagerplugin implements taskmanagerplugin { <nl> @ override <nl> public void senddata ( final ioreadablewritable data ) throws ioexception { <nl>  <nl> - <nl> + if ( ! ( data instanceof abstractaction ) ) { <nl> + log . error ( " received data is of unknown type " + data . getclass ( ) ) ; <nl> + return ; <nl> + } <nl> + <nl> + final abstractaction action = ( abstractaction ) data ; <nl> + final streamlistenercontext listenercontext = this . listenercontexts . get ( action . getvertexid ( ) . tostring ( ) ) ; <nl> + <nl> + if ( listenercontext = = null ) { <nl> + log . error ( " cannot find listener context for vertex with id " + action . getvertexid ( ) ) ; <nl> + return ; <nl> + } <nl> + <nl> + / / queue the action and return <nl> + listenercontext . queuependingaction ( action ) ; <nl> } <nl>  <nl> / * * <nl> mmm a / nephele / nephele - streaming / src / main / java / eu / stratosphere / nephele / streaming / listeners / streamlistenercontext . java <nl> ppp b / nephele / nephele - streaming / src / main / java / eu / stratosphere / nephele / streaming / listeners / streamlistenercontext . java <nl>
public class checkpointreplaymanager { <nl> * the vertex whose checkpoint shall be removed <nl> * / <nl> public void removecheckpoint ( final executionvertexid vertexid ) { <nl> - <nl> - <nl> + file file = new file ( this . checkpointdirectory + file . separator + metadata_prefix + " _ " + vertexid <nl> + + " _final " ) ; <nl> + if ( file . exists ( ) ) { <nl> + file . delete ( ) ; <nl> + return ; <nl> + } <nl> + file = new file ( this . checkpointdirectory + file . separator + metadata_prefix + " _ " + vertexid + " _0 " ) ; <nl> + if ( file . exists ( ) ) { <nl> + file . delete ( ) ; <nl> + } <nl> + <nl> + file = new file ( this . checkpointdirectory + file . separator + metadata_prefix + " _ " + vertexid + " _part " ) ; <nl> + if ( file . exists ( ) ) { <nl> + file . delete ( ) ; <nl> + } <nl> } <nl>  <nl> }
public abstract class abstractscheduler implements instancelistener { <nl> log . debug ( " available instance is of type dummyinstance ! " ) ; <nl> return ; <nl> } <nl> - <nl> - / / check if all required libraries are available on the instance <nl> - <nl> - try { <nl> - allocatedresource . getinstance ( ) . checklibraryavailability ( jobid ) ; <nl> - } catch ( ioexception ioe ) { <nl> - log . error ( " cannot check library availability : " + stringutils . stringifyexception ( ioe ) ) ; <nl> - } <nl> } <nl>  <nl> final executiongraph eg = getexecutiongraphbyid ( jobid ) ;
final class outputchannelcontext implements bytebufferedoutputchannelbroker , cha <nl>  <nl> final buffer buffer = this . outgoingtransferenvelope . getbuffer ( ) ; <nl> if ( buffer . isbackedbymemory ( ) ) { <nl> - <nl> final buffer filebuffer = this . outputgatecontext . getfilebuffer ( buffer . size ( ) ) ; <nl> buffer . copytobuffer ( filebuffer ) ; <nl> this . outgoingtransferenvelope . setbuffer ( filebuffer ) ; <nl> mmm a / nephele / nephele - server / src / main / java / eu / stratosphere / nephele / taskmanager / bytebuffered / outputgatecontext . java <nl> ppp b / nephele / nephele - server / src / main / java / eu / stratosphere / nephele / taskmanager / bytebuffered / outputgatecontext . java <nl>
public final class fileinputsplitlist { <nl> } <nl>  <nl> if ( this . masterset . remove ( candidate . getinputsplit ( ) ) ) { <nl> - <nl> - system . out . println ( instance + " receives input split with distance " + candidate . distance ) ; <nl> + if ( log . isdebugenabled ( ) ) { <nl> + log . debug ( instance + " receives input split with distance " + candidate . distance ) ; <nl> + } <nl> return candidate . getinputsplit ( ) ; <nl> } <nl>  <nl>
public final class bytebufferedchannelmanager implements transferenvelopedispatc <nl> continue ; <nl> } <nl>  <nl> - final boolean isactive = / * activeoutputchannels . contains ( bboc . getid ( ) ) * / true ; <nl> + final boolean isactive = activeoutputchannels . contains ( bboc . getid ( ) ) ; <nl>  <nl> log . info ( " registering byte buffered output channel " + bboc . getid ( ) + " ( " <nl> + ( isactive ? " active " : " inactive " ) + " ) " ) ; <nl>
public class jobmanager implements deploymentmanager , extendedmanagementprotocol <nl> } <nl> } <nl>  <nl> - if ( outputchannel . isbroadcastchannel ( ) & & outputchannel . gettype ( ) ! = channeltype . inmemory ) { <nl> + if ( outputchannel . isbroadcastchannel ( ) ) { <nl>  <nl> - <nl> - / / will do so ! ; ) <nl> return multicastmanager . lookupconnectioninfo ( caller , jobid , sourcechannelid ) ; <nl>  <nl> } else { <nl>
public class jobmanager implements deploymentmanager , extendedmanagementprotocol <nl> return connectioninfolookupresponse . createreceivernotready ( ) ; <nl> } <nl>  <nl> - <nl> - <nl> final abstractinstance assignedinstance = targetvertex . getallocatedresource ( ) . getinstance ( ) ; <nl> if ( assignedinstance = = null ) { <nl> - log . error ( " cannot resolve lookup : vertex found for channel id " + outputchannel . getconnectedchannelid ( ) <nl> - + " but no instance assigned " ) ; <nl> + log . error ( " cannot resolve lookup : vertex found for channel id " <nl> + + outputchannel . getconnectedchannelid ( ) <nl> + + " but no instance assigned " ) ; <nl> return connectioninfolookupresponse . createreceivernotready ( ) ; <nl> } <nl>  <nl> if ( assignedinstance . getinstanceconnectioninfo ( ) . equals ( caller ) ) { <nl> / / receiver runs on the same task manager <nl> - return connectioninfolookupresponse . createreceiverfoundandready ( outputchannel . getconnectedchannelid ( ) ) ; <nl> + return connectioninfolookupresponse . createreceiverfoundandready ( outputchannel <nl> + . getconnectedchannelid ( ) ) ; <nl> } else { <nl> / / receiver runs on a different task manager <nl> return connectioninfolookupresponse . createreceiverfoundandready ( assignedinstance <nl> - . getinstanceconnectioninfo ( ) ) ; <nl> + . getinstanceconnectioninfo ( ) ) ; <nl> } <nl> } <nl> - <nl> / / log . error ( " receiver ( s ) not found " ) ; <nl>  <nl> / / return connectioninfolookupresponse . createreceivernotfound ( ) ; <nl>
public class filebuffer implements internalbuffer { <nl> @ override <nl> public internalbuffer duplicate ( ) { <nl>  <nl> - throw new runtimeexception ( " not yet implemented " ) ; <nl> + throw new runtimeexception ( " filebuffer duplication is no yet implemented " ) ; <nl> } <nl>  <nl> @ override <nl> - public void copytobuffer ( buffer destinationbuffer ) throws ioexception { <nl> - <nl> - throw new unsupportedoperationexception ( " method is not yet implemented " ) ; <nl> + public void copytobuffer ( final buffer destinationbuffer ) throws ioexception { <nl> + <nl> + if ( destinationbuffer . isbackedbymemory ( ) ) { <nl> + destinationbuffer . write ( this ) ; <nl> + destinationbuffer . finishwritephase ( ) ; <nl> + return ; <nl> + } <nl> + <nl> + throw new unsupportedoperationexception ( " filebuffer - to - filebuffer copy is not yet implemented " ) ; <nl> } <nl>  <nl> / * *
public class compressionloader { <nl> return null ; <nl> } <nl>  <nl> - final string classlocation = " eu / stratosphere / nephele / io / compression / library / zlib / zliblibrary . class " ; <nl> - / / use <nl> - / / other <nl> - / / class <nl> - / / here <nl> + final string classlocation = libraryclass . replace ( ' . ' , ' / ' ) + " . class " ; <nl> + if ( log . isdebugenabled ( ) ) { <nl> + log . debug ( " class location is " + classlocation ) ; <nl> + } <nl>  <nl> final url location = cl . getresource ( classlocation ) ; <nl> if ( location = = null ) { <nl>
public class taskmanager implements taskoperationprotocol { <nl> this . memorymanager . releaseall ( environment . getinvokable ( ) ) ; <nl> } <nl>  <nl> - <nl> - <nl> / / check if there are still vertices running that belong to the same job <nl> int numberofverticesbelongingtothisjob = num ; <nl> synchronized ( this . runningtasks ) {
public class unilateralsortmerger < k extends key , v extends value > implements sor <nl> log . debug ( " initiating merge - iterator ( in - memory segments ) . " ) ; <nl>  <nl> list < iterator < keyvaluepair < k , v > > > iterators = new arraylist < iterator < keyvaluepair < k , v > > > ( ) ; <nl> - <nl> - <nl> - <nl> + <nl> / / iterate buffers and collect a set of iterators <nl> iterator < circularelement > iter = cache . iterator ( ) ; <nl> while ( iter . hasnext ( ) ) <nl> mmm a / pact / pact - runtime / src / test / java / eu / stratosphere / pact / runtime / sort / unilateralsortmergeritcase . java <nl> ppp b / pact / pact - runtime / src / test / java / eu / stratosphere / pact / runtime / sort / unilateralsortmergeritcase . java <nl>
public abstract class abstractchannel implements ioreadablewritable { <nl> public abstract void transferevent ( abstractevent event ) throws ioexception ; <nl>  <nl> public abstract void processevent ( abstractevent event ) ; <nl> - <nl> - public boolean ismulticastchannel ( ) { <nl> - <nl> - <nl> - return false ; <nl> - } <nl> } <nl> mmm a / nephele / nephele - common / src / main / java / eu / stratosphere / nephele / io / channels / abstractoutputchannel . java <nl> ppp b / nephele / nephele - common / src / main / java / eu / stratosphere / nephele / io / channels / abstractoutputchannel . java <nl>
public class enumtriangles implements planassembler , planassemblerdescription { <nl> matchcontract < edge , edgelist , pactnull , pactnull , edgelist > closetriads = new matchcontract < edge , edgelist , pactnull , pactnull , edgelist > ( <nl> closetriads . class , " close triads " ) ; <nl> closetriads . setdegreeofparallelism ( nosubtasks ) ; <nl> - <nl> - closetriads . getstubparameters ( ) . setstring ( pactcompiler . hint_local_strategy , <nl> - pactcompiler . hint_local_strategy_sort ) ; <nl>  <nl> datasinkcontract < pactnull , edgelist > triangles = new datasinkcontract < pactnull , edgelist > ( <nl> edgelistoutformat . class , output ) ;
public class environment implements runnable , ioreadablewritable { <nl> this . invokable . invoke ( ) ; <nl>  <nl> / / make sure we switch to the right state , even if the user code has not hit an { @ link interruptedexception } <nl> - if ( this . executingthread . isinterrupted ( ) ) { <nl> + if ( this . iscanceled ) { <nl> throw new interruptedexception ( ) ; <nl> } <nl>  <nl> } catch ( interruptedexception e ) { <nl> changeexecutionstate ( executionstate . cancelled , null ) ; <nl> - <nl> - return ; <nl> } catch ( exception e ) { <nl> + <nl> + / / clean up <nl> + try { <nl> + this . invokable . cancel ( ) ; <nl> + } catch ( exception e2 ) { <nl> + log . error ( stringutils . stringifyexception ( e2 ) ) ; <nl> + } <nl> + <nl> / / report exception <nl> changeexecutionstate ( executionstate . failed , stringutils . stringifyexception ( e ) ) ; <nl> return ; <nl> } <nl>  <nl> - / / task finished running , but there may be unconsumed output data in some of the channels <nl> - changeexecutionstate ( executionstate . finishing , null ) ; <nl> + if ( ! this . iscanceled ) { <nl> + / / task finished running , but there may be unconsumed output data in some of the channels <nl> + changeexecutionstate ( executionstate . finishing , null ) ; <nl> + } <nl>  <nl> try { <nl> / / if there is any unclosed input gate , close it and propagate close operation to corresponding output gate <nl>
public abstract class abstractdirectoutputchannel < t extends record > extends abst <nl> } <nl>  <nl> @ override <nl> - public void flush ( ) { <nl> - <nl> + public void flush ( ) throws ioexception { <nl> + if ( this . connecteddirectinputchannel = = null ) { <nl> + this . connecteddirectinputchannel = getconnectedinputchannel ( ) ; <nl> + } <nl> + <nl> + this . connecteddirectinputchannel . requestflush ( ) ; <nl> } <nl> }
public final class multiformatreader implements reader { <nl> if ( ! tryharder ) { <nl> readers . addelement ( new multiformatonedreader ( hints ) ) ; <nl> } <nl> - readers . addelement ( new qrcodereader ( ) ) ; <nl>  <nl> + readers . addelement ( new qrcodereader ( ) ) ; <nl> readers . addelement ( new datamatrixreader ( ) ) ; <nl> - <nl> - <nl> - / / readers . addelement ( new pdf417reader ( ) ) ; <nl> + readers . addelement ( new aztecreader ( ) ) ; <nl> + readers . addelement ( new pdf417reader ( ) ) ; <nl>  <nl> if ( tryharder ) { <nl> readers . addelement ( new multiformatonedreader ( hints ) ) ;
public final class localemanager { <nl> google_product_search_country_tld . put ( locale . uk , " co . uk " ) ; <nl> } <nl>  <nl> - <nl> - / / we ' ll keep everything in web search minus china as with v3 . 5 . <nl> + / / book search is offered everywhere that web search is available . <nl> private static final map < locale , string > google_book_search_country_tld ; <nl> static { <nl> google_book_search_country_tld = new hashmap < locale , string > ( ) ; <nl> google_book_search_country_tld . putall ( google_country_tld ) ; <nl> - google_book_search_country_tld . remove ( locale . china ) ; <nl> } <nl>  <nl> private localemanager ( ) { }
package com . google . zxing . common ; <nl> * @ author sean owen <nl> * / <nl> public final class bitarray { <nl> - <nl> - <nl> / / they ' d be private and we ' d use the - allowaccessmodification flag , but dalvik rejects the <nl> / / resulting binary at runtime on android . if we find a solution to this , these should be changed <nl> / / back to private . <nl>
package com . google . zxing . common ; <nl> * @ author dswitkin @ google . com ( daniel switkin ) <nl> * / <nl> public final class bitmatrix { <nl> - <nl> - <nl> public final int width ; <nl> public final int height ; <nl> public final int rowsize ; <nl>
public class globalhistogrambinarizer extends binarizer { <nl>  <nl> / / if there is too little contrast in the image to pick a meaningful black point , throw rather <nl> / / than waste time trying to decode the image , and risk false positives . <nl> - <nl> - / / two peaks , to determine the contrast . <nl> if ( secondpeak - firstpeak < = numbuckets > > num ) { <nl> throw notfoundexception . getnotfoundinstance ( ) ; <nl> }
unsigned char * greyscalerotatedluminancesource : : getrow ( int y , unsigned char * row <nl> throw illegalargumentexception ( " requested row is outside the image : " + y ) ; <nl> } <nl> int width = getwidth ( ) ; <nl> - <nl> if ( row = = null ) { <nl> row = new unsigned char [ width ] ; <nl> } <nl>
public class wifigenerator implements generatorsource { <nl> string networktype = getnetworktypefield ( ) ; <nl>  <nl> / / build the output with obtained data . <nl> - / / note that some informations may just be " " if they were not specified . <nl> - / / return getvcard ( name , company , tel , url , email , address , memo ) ; <nl> return getwifistring ( ssid , password , networktype ) ; <nl> } <nl>  <nl> private string getwifistring ( string ssid , string password , string type ) { <nl> stringbuilder output = new stringbuilder ( ) ; <nl> output . append ( " wifi : " ) ; <nl> - <nl> output . append ( " s : " ) . append ( ssid ) . append ( ' ; ' ) ; <nl> maybeappend ( output , " t : " , type ) ; <nl> maybeappend ( output , " p : " , password ) ; <nl>
public class wifigenerator implements generatorsource { <nl> if ( input . contains ( " \n " ) ) { <nl> throw new generatorexception ( name + " field must not contain \ \n characters . " ) ; <nl> } <nl> - if ( input . contains ( " ; " ) ) { <nl> - <nl> - throw new generatorexception ( name + " field must not contains ; characters " ) ; <nl> - } <nl> + input = input . replace ( " ; " , " \ \ ; " ) ; <nl> return input ; <nl> }
public final class yuvluminancesource extends luminancesource { <nl>  <nl> int area = width * height ; <nl> byte [ ] matrix = new byte [ area ] ; <nl> - byte [ ] yuv = yuvdata ; <nl> int inputoffset = top * datawidth + left ; <nl> + <nl> + / / if the width matches the full width of the underlying data , perform a single copy . <nl> + if ( width = = datawidth ) { <nl> + system . arraycopy ( yuvdata , inputoffset , matrix , num , area ) ; <nl> + return matrix ; <nl> + } <nl> + <nl> + / / otherwise copy one cropped row at a time . <nl> + byte [ ] yuv = yuvdata ; <nl> for ( int y = num ; y < height ; y + + ) { <nl> int outputoffset = y * width ; <nl> - for ( int x = num ; x < width ; x + + ) { <nl> - <nl> - matrix [ outputoffset + x ] = yuv [ inputoffset + x ] ; <nl> - } <nl> + system . arraycopy ( yuv , inputoffset , matrix , outputoffset , width ) ; <nl> inputoffset + = datawidth ; <nl> } <nl> return matrix ;
import java . util . vector ; <nl> * < p > this class attempts to find finder patterns in a qr code . finder patterns are the square <nl> * markers at three corners of a qr code . < / p > <nl> * <nl> - * < p > this class is not thread - safe and should not be reused . < / p > <nl> - * <nl> + * < p > this class is thread - safe but not reentrant . each thread must allocate its own object . <nl> * <nl> * < p > in contrast to { @ link finderpatternfinder } , this class will return an array of all possible <nl> * qr code locations in the image . < / p > <nl> mmm a / core / src / com / google / zxing / qrcode / detector / alignmentpatternfinder . java <nl> ppp b / core / src / com / google / zxing / qrcode / detector / alignmentpatternfinder . java <nl>
import java . util . vector ; <nl> * pasted and stripped down here for maximum performance but does unfortunately duplicate <nl> * some code . < / p > <nl> * <nl> - * < p > this class is not thread - safe . < / p > <nl> - * <nl> + * < p > this class is thread - safe but not reentrant . each thread must allocate its own object . <nl> * <nl> * @ author sean owen <nl> * / <nl> mmm a / core / src / com / google / zxing / qrcode / detector / finderpatternfinder . java <nl> ppp b / core / src / com / google / zxing / qrcode / detector / finderpatternfinder . java <nl>
import java . util . vector ; <nl> * < p > this class attempts to find finder patterns in a qr code . finder patterns are the square <nl> * markers at three corners of a qr code . < / p > <nl> * <nl> - * < p > this class is not thread - safe and should not be reused . < / p > <nl> - * <nl> + * < p > this class is thread - safe but not reentrant . each thread must allocate its own object . <nl> * <nl> * @ author sean owen <nl> * /
public final class commandlinerunner { <nl> / / writes out a single png which is three times the width of the input image , containing from left <nl> / / to right : the original image , the row sampling monochrome version , and the num d sampling <nl> / / monochrome version . <nl> - <nl> private static void dumpblackpoint ( uri uri , bufferedimage image , monochromebitmapsource source ) { <nl> string inputname = uri . getpath ( ) ; <nl> if ( inputname . contains ( " . mono . png " ) ) { <nl>
public final class multiformatreader implements reader { <nl> if ( possibleformats . contains ( barcodeformat . qr_code ) ) { <nl> readers . addelement ( new qrcodereader ( ) ) ; <nl> } <nl> - <nl> - / / if ( possibleformats . contains ( barcodeformat . datamatrix ) ) { <nl> - / / readers . addelement ( new datamatrixreader ( ) ) ; <nl> - / / } <nl> + if ( possibleformats . contains ( barcodeformat . datamatrix ) ) { <nl> + readers . addelement ( new datamatrixreader ( ) ) ; <nl> + } <nl> / / at end in " try harder " mode <nl> if ( addonedreader & & tryharder ) { <nl> readers . addelement ( new multiformatonedreader ( hints ) ) ; <nl> mmm a / core / src / com / google / zxing / qrcode / qrcodewriter . java <nl> ppp b / core / src / com / google / zxing / qrcode / qrcodewriter . java <nl>
public final class multiformatonedreader extends abstractonedreader { <nl> readers . addelement ( new multiformatupceanreader ( hints ) ) ; <nl> readers . addelement ( new code39reader ( ) ) ; <nl> readers . addelement ( new code128reader ( ) ) ; <nl> - <nl> - / / readers . addelement ( new itfreader ( ) ) ; <nl> + readers . addelement ( new itfreader ( ) ) ; <nl> } <nl> }
<nl> - / * <nl> - * copyright num zxing authors <nl> - * <nl> - * licensed under the apache license , version num . 0 ( the " license " ) ; <nl> - * you may not use this file except in compliance with the license . <nl> - * you may obtain a copy of the license at <nl> - * <nl> - * http : / / www . apache . org / licenses / license - 2 . 0 <nl> - * <nl> - * unless required by applicable law or agreed to in writing , software <nl> - * distributed under the license is distributed on an " as is " basis , <nl> - * without warranties or conditions of any kind , either express or implied . <nl> - * see the license for the specific language governing permissions and <nl> - * limitations under the license . <nl> - * / <nl> - <nl> - package com . google . zxing . oned ; <nl> - <nl> - import com . google . zxing . barcodeformat ; <nl> - import com . google . zxing . common . abstractblackboxtestcase ; <nl> - <nl> - import java . io . file ; <nl> - <nl> - / * * <nl> - * @ author kevin . osullivan @ sita . aero <nl> - * / <nl> - public final class itf14blackbox1testcase extends abstractblackboxtestcase { <nl> - <nl> - public itf14blackbox1testcase ( ) { <nl> - <nl> - super ( new file ( " test / data / blackbox / itf14 - 1 " ) , new itf14reader ( ) , barcodeformat . itf_14 ) ; <nl> - addtest ( 2 , num , num . 0f ) ; <nl> - addtest ( 2 , num , num . 0f ) ; <nl> - } <nl> - <nl> + / * <nl> + * copyright num zxing authors <nl> + * <nl> + * licensed under the apache license , version num . 0 ( the " license " ) ; <nl> + * you may not use this file except in compliance with the license . <nl> + * you may obtain a copy of the license at <nl> + * <nl> + * http : / / www . apache . org / licenses / license - 2 . 0 <nl> + * <nl> + * unless required by applicable law or agreed to in writing , software <nl> + * distributed under the license is distributed on an " as is " basis , <nl> + * without warranties or conditions of any kind , either express or implied . <nl> + * see the license for the specific language governing permissions and <nl> + * limitations under the license . <nl> + * / <nl> + <nl> + package com . google . zxing . oned ; <nl> + <nl> + import com . google . zxing . multiformatreader ; <nl> + import com . google . zxing . barcodeformat ; <nl> + import com . google . zxing . common . abstractblackboxtestcase ; <nl> + <nl> + import java . io . file ; <nl> + <nl> + / * * <nl> + * @ author kevin . osullivan @ sita . aero <nl> + * / <nl> + public final class itfblackbox1testcase extends abstractblackboxtestcase { <nl> + <nl> + public itfblackbox1testcase ( ) { <nl> + super ( new file ( " test / data / blackbox / itf - 1 " ) , new multiformatreader ( ) , barcodeformat . itf ) ; <nl> + addtest ( 6 , num , num . 0f ) ; <nl> + } <nl> + <nl> } <nl> \ no newline at end of file
import com . google . zxing . readerexception ; <nl> * / <nl> public final class decodedbitstreamparsertestcase extends testcase { <nl>  <nl> - public void testasciistandarddecode ( ) { <nl> + public void testasciistandarddecode ( ) throws readerexception { <nl> / / ascii characters num - 127 are encoded as the value + num <nl> byte [ ] bytes = new byte [ ] { ( byte ) ( ' a ' + num ) , ( byte ) ( ' b ' + num ) , ( byte ) ( ' c ' + num ) , <nl> ( byte ) ( ' a ' + num ) , ( byte ) ( ' b ' + num ) , ( byte ) ( ' c ' + num ) } ; <nl> - string decodedstring = " " ; <nl> - try { <nl> - decodedstring = decodedbitstreamparser . decode ( bytes ) ; <nl> - } catch ( readerexception readerexception ) { <nl> - <nl> - } <nl> - <nl> + string decodedstring = decodedbitstreamparser . decode ( bytes ) ; <nl> assertequals ( " abcabc " , decodedstring ) ; <nl> } <nl>  <nl>
package com . google . zxing . common ; <nl> * < p > encapsulates logic that estimates the optimal " black point " , the luminance value <nl> * which is the best line between " white " and " black " in a grayscale image . < / p > <nl> * <nl> - * < p > <nl> + * < p > for an interesting discussion of this issue , see <nl> + * < a href = " http : / / webdiis . unizar . es / ~ neira / 12082 / thresholding . pdf " > http : / / webdiis . unizar . es / ~ neira / 12082 / thresholding . pdf < / a > . <nl> + * < / p > <nl> * <nl> * @ author srowen @ google . com ( sean owen ) <nl> * /
<nl> < / classpath > <nl> < / javac > <nl>  <nl> + < unzip src = " . . / core / core . jar " dest = " build " / > <nl> + <nl> < mkdir dir = " build - j2me " / > <nl> - < exec executable = " $ { wtk - home } / bin / preverify " > <nl> - < arg line = " - classpath $ { wtk - home } / lib / cldcapi11 . jar : $ { wtk - home } / lib / midpapi20 . jar : $ { wtk - home } / lib / mmapi . jar : $ { wtk - home } / lib / satsa - apdu . jar : . . / core / core . jar - d build - j2me build " / > <nl> + < exec executable = " $ { wtk - home } / bin / preverify1 . 1 " > <nl> + < arg line = " - classpath $ { wtk - home } / lib / cldcapi11 . jar : $ { wtk - home } / lib / midpapi20 . jar : $ { wtk - home } / lib / mmapi . jar : $ { wtk - home } / lib / satsa - apdu . jar - d build - j2me build " / > <nl> < / exec > <nl>  <nl> - < ! - - <nl> - < jar jarfile = " javame . jar " basedir = " build - j2me " / > <nl> + < jar jarfile = " zxingreader . jar " basedir = " build - j2me " manifest = " src / com / google / zxing / client / j2me / manifest . mf " / > <nl> + <nl> + < exec executable = " sh " outputproperty = " jar - size " > <nl> + < arg line = " - c & quot ; wc - c zxingreader . jar | cut - d ' ' - f1 & quot ; " / > <nl> + < / exec > <nl> + < copy file = " zxingreader . jad . template " tofile = " zxingreader . jad " > <nl> + < filterset > <nl> + < filter token = " jar_size " value = " $ { jar - size } " / > <nl> + < / filterset > <nl> + < / copy > <nl>  <nl> < / target > <nl>  <nl> < target name = " clean " > <nl> < delete dir = " build " / > <nl> < delete dir = " build - j2me " / > <nl> - < delete file = " javame . jar " / > <nl> + < delete file = " zxingreader . jar " / > <nl> + < delete file = " zxingreader . jad " / > <nl> < / target > <nl>  <nl> < / project > <nl> mmm / dev / null <nl> ppp b / javame / src / com / google / zxing / client / j2me / manifest . mf <nl>
public class handleequalsandhashcode extends eclipseannotationhandler < equalsandh <nl> method . returntype = typereference . basetypereference ( typeids . t_int , num ) ; <nl> setgeneratedby ( method . returntype , source ) ; <nl> annotation overrideannotation = makemarkerannotation ( typeconstants . java_lang_override , source ) ; <nl> - <nl> - if ( getcheckerframeworkversion ( type ) . generatesideeffectfree ( ) ) { <nl> + checkerframeworkversion checkerframework = getcheckerframeworkversion ( type ) ; <nl> + if ( cachehashcode & & checkerframework . generatepure ( ) ) { <nl> + method . annotations = new annotation [ ] { overrideannotation , generatenamedannotation ( source , checkerframeworkversion . name__pure ) } ; <nl> + } else if ( checkerframework . generatesideeffectfree ( ) ) { <nl> method . annotations = new annotation [ ] { overrideannotation , generatenamedannotation ( source , checkerframeworkversion . name__side_effect_free ) } ; <nl> } else { <nl> method . annotations = new annotation [ ] { overrideannotation } ; <nl> mmm a / src / core / lombok / javac / handlers / handleequalsandhashcode . java <nl> ppp b / src / core / lombok / javac / handlers / handleequalsandhashcode . java <nl>
public class handleequalsandhashcode extends javacannotationhandler < equalsandhas <nl> jcannotation overrideannotation = maker . annotation ( genjavalangtyperef ( typenode , " override " ) , list . < jcexpression > nil ( ) ) ; <nl> list < jcannotation > annsonmethod = list . of ( overrideannotation ) ; <nl> checkerframeworkversion checkerframework = getcheckerframeworkversion ( typenode ) ; <nl> - <nl> - if ( checkerframework . generatesideeffectfree ( ) ) annsonmethod = annsonmethod . prepend ( maker . annotation ( gentyperef ( typenode , checkerframeworkversion . name__side_effect_free ) , list . < jcexpression > nil ( ) ) ) ; <nl> + if ( cachehashcode & & checkerframework . generatepure ( ) ) { <nl> + annsonmethod = annsonmethod . prepend ( maker . annotation ( gentyperef ( typenode , checkerframeworkversion . name__pure ) , list . < jcexpression > nil ( ) ) ) ; <nl> + } else if ( checkerframework . generatesideeffectfree ( ) ) { <nl> + annsonmethod = annsonmethod . prepend ( maker . annotation ( gentyperef ( typenode , checkerframeworkversion . name__side_effect_free ) , list . < jcexpression > nil ( ) ) ) ; <nl> + } <nl> jcmodifiers mods = maker . modifiers ( flags . public , annsonmethod ) ; <nl> jcexpression returntype = maker . typeident ( ctc_int ) ; <nl> listbuffer < jcstatement > statements = new listbuffer < jcstatement > ( ) ;
public class handlesuperbuilder extends eclipseannotationhandler < superbuilder > { <nl> out . modifiers = classfileconstants . accpublic | classfileconstants . accstatic ; <nl> out . bits | = eclipse_do_not_touch_flag ; <nl>  <nl> - <nl> - out . typeparameters = copytypeparams ( typeparams , source ) ; <nl> + / / add type params if there are any . <nl> + if ( typeparams ! = null & & typeparams . length > num ) { <nl> + out . typeparameters = copytypeparams ( typeparams , source ) ; <nl> + } <nl> typereference [ ] wildcards = new typereference [ ] { new wildcard ( wildcard . unbound ) , new wildcard ( wildcard . unbound ) } ; <nl> out . returntype = new parameterizedsingletypereference ( builderclassname . tochararray ( ) , mergetotypereferences ( typeparams , wildcards ) , num , p ) ; <nl>  <nl>
public class handlesuperbuilder extends javacannotationhandler < superbuilder > { <nl> for ( builderfielddata bfd : builderfields ) { <nl> fieldnodes . addall ( bfd . createdfields ) ; <nl> } <nl> - <nl> - jcmethoddecl md = handletostring . createtostring ( buildertype , fieldnodes , true , false , fieldaccess . always_field , ast ) ; <nl> + / / let tostring ( ) call super . tostring ( ) if there is a superclass , so that it also shows fields from the superclass ' builder . <nl> + jcmethoddecl md = handletostring . createtostring ( buildertype , fieldnodes , true , superclassbuilderclassexpression ! = null , fieldaccess . always_field , ast ) ; <nl> if ( md ! = null ) injectmethod ( buildertype , md ) ; <nl> }
final class lombokfileobjects { <nl> javafilemanager manager ; <nl>  <nl> public basefilemanagerwrapper ( javafilemanager manager ) { <nl> - super ( standardcharsets . utf_8 ) ; <nl> + super ( standardcharsets . utf_8 ) ; <nl> this . manager = manager ; <nl> }
public class patchdelegate { <nl> if ( ! arrays . equals ( mb . selector , name ) ) continue ; <nl> int paramlen = mb . parameters = = null ? num : mb . parameters . length ; <nl> if ( paramlen ! = args . length ) continue ; <nl> - <nl> for ( int i = num ; i < paramlen ; i + + ) { <nl> if ( ! mb . parameters [ i ] . erasure ( ) . isequivalentto ( args [ i ] ) ) continue methods ; <nl> } <nl>
public class handledelegate implements javacannotationhandler < delegate > { <nl> " finalize ( ) " ) ) ; <nl>  <nl> @ override public boolean handle ( annotationvalues < delegate > annotation , jcannotation ast , javacnode annotationnode ) { <nl> - if ( annotationnode . up ( ) . getkind ( ) ! = kind . field ) return false ; <nl> + if ( annotationnode . up ( ) . getkind ( ) ! = kind . field ) { <nl> + / / as the annotation is legal on fields only , javac itself will take care of printing an error message for this . <nl> + return false ; <nl> + } <nl>  <nl> list < object > delegatetypes = annotation . getactualexpressions ( " value " ) ; <nl> javacresolution reso = new javacresolution ( annotationnode . getcontext ( ) ) ;
<nl> < / p > < p > <nl> < em > new in lombok num . 10 : < / em > unless your class is < code > final < / code > and extends < code > java . lang . object < / code > , lombok generates a < code > canequal < / code > method <nl> which means jpa proxies can still be equal to their base class , but subclasses that add new state don ' t break the equals contract . the complicated reasons for <nl> - why such a method is necessary are explained in this paper : ( <nl> - and classes with lombok - generated equals methods , all equality will ' just work ' . if you need to write your own equals methods , you should always override < code > canequal < / code > <nl> - if you change < code > equals < / code > and < code > hashcode < / code > . <nl> + why such a method is necessary are explained in this paper : < a href = " http : / / www . artima . com / lejava / articles / equality . html " > how to write an equality method in java < / a > . <nl> + if all classes in a hierarchy are a mix of scala case classes and classes with lombok - generated equals methods , all equality will ' just work ' . <nl> + if you need to write your own equals methods , you should always override < code > canequal < / code > if you change < code > equals < / code > and < code > hashcode < / code > . <nl> < / p > <nl> < / div > <nl> < div class = " snippets " >
public class handledata implements javacannotationhandler < data > { <nl> injectmethod ( typenode , method ) ; <nl> } <nl>  <nl> - <nl> + if ( methodexists ( " tostring " , typenode ) = = methodexistsresult . not_exists ) { <nl> + jcmethoddecl method = createtostring ( typenode , nodesforequality ) ; <nl> + injectmethod ( typenode , method ) ; <nl> + } <nl> + <nl> return true ; <nl> } <nl>  <nl> + private jcmethoddecl createtostring ( node typenode , list < node > fields ) { <nl> + treemaker maker = typenode . gettreemaker ( ) ; <nl> + <nl> + jcannotation overrideannotation = maker . annotation ( chaindots ( maker , typenode , " java " , " lang " , " override " ) , list . < jcexpression > nil ( ) ) ; <nl> + jcmodifiers mods = maker . modifiers ( flags . public , list . of ( overrideannotation ) ) ; <nl> + jcexpression returntype = chaindots ( maker , typenode , " java " , " lang " , " string " ) ; <nl> + <nl> + jcexpression current = maker . literal ( ( ( jcclassdecl ) typenode . get ( ) ) . name . tostring ( ) + " ( " ) ; <nl> + boolean first = true ; <nl> + <nl> + for ( node fieldnode : fields ) { <nl> + jcvariabledecl field = ( jcvariabledecl ) fieldnode . get ( ) ; <nl> + if ( ! first ) current = maker . binary ( jctree . plus , current , maker . literal ( " , " ) ) ; <nl> + first = false ; <nl> + if ( field . vartype instanceof jcarraytypetree ) { <nl> + boolean multidim = ( ( jcarraytypetree ) field . vartype ) . elemtype instanceof jcarraytypetree ; <nl> + boolean primitivearray = ( ( jcarraytypetree ) field . vartype ) . elemtype instanceof jcprimitivetypetree ; <nl> + boolean usedeepts = multidim | | ! primitivearray ; <nl> + <nl> + jcexpression hcmethod = chaindots ( maker , typenode , " java " , " util " , " arrays " , usedeepts ? " deeptostring " : " tostring " ) ; <nl> + current = maker . binary ( jctree . plus , current , maker . apply ( <nl> + list . < jcexpression > nil ( ) , hcmethod , list . < jcexpression > of ( maker . ident ( field . name ) ) ) ) ; <nl> + } else current = maker . binary ( jctree . plus , current , maker . ident ( field . name ) ) ; <nl> + } <nl> + <nl> + current = maker . binary ( jctree . plus , current , maker . literal ( " ) " ) ) ; <nl> + <nl> + jcstatement returnstatement = maker . return ( current ) ; <nl> + <nl> + jcblock body = maker . block ( 0 , list . of ( returnstatement ) ) ; <nl> + <nl> + return maker . methoddef ( mods , typenode . toname ( " tostring " ) , returntype , <nl> + list . < jctypeparameter > nil ( ) , list . < jcvariabledecl > nil ( ) , list . < jcexpression > nil ( ) , body , null ) ; <nl> + } <nl> + <nl> private jcmethoddecl createhashcode ( node typenode , list < node > fields ) { <nl> treemaker maker = typenode . gettreemaker ( ) ; <nl>  <nl>
import com . sun . tools . javac . util . name ; <nl> @ providerfor ( javacannotationhandler . class ) <nl> public class handlegetter implements javacannotationhandler < getter > { <nl> @ override public void handle ( annotationvalues < getter > annotation , jcannotation ast , javacast . node annotationnode ) { <nl> - <nl> if ( annotationnode . up ( ) . getkind ( ) ! = kind . field ) { <nl> annotationnode . adderror ( " @ getter is only supported on a field . " ) ; <nl> return ; <nl> } <nl>  <nl> + string methodname = togettername ( ( jcvariabledecl ) annotationnode . up ( ) . get ( ) ) ; <nl> + <nl> + if ( methodexists ( methodname , annotationnode . up ( ) ) ) { <nl> + annotationnode . addwarning ( <nl> + string . format ( " not generating % s ( ) : a method with that name already exists " , methodname ) ) ; <nl> + return ; <nl> + } <nl> + <nl> getter getter = annotation . getinstance ( ) ; <nl>  <nl> jcclassdecl javacclasstree = ( jcclassdecl ) annotationnode . up ( ) . up ( ) . get ( ) ; <nl> mmm a / src / lombok / javac / handlers / handlesetter . java <nl> ppp b / src / lombok / javac / handlers / handlesetter . java <nl>
import com . sun . tools . javac . util . name ; <nl> @ providerfor ( javacannotationhandler . class ) <nl> public class handlesetter implements javacannotationhandler < setter > { <nl> @ override public void handle ( annotationvalues < setter > annotation , jcannotation ast , node annotationnode ) { <nl> - <nl> if ( annotationnode . up ( ) . getkind ( ) ! = kind . field ) { <nl> annotationnode . adderror ( " @ setter is only supported on a field . " ) ; <nl> return ; <nl> } <nl>  <nl> + jcvariabledecl fieldnode = ( jcvariabledecl ) annotationnode . up ( ) . get ( ) ; <nl> + string methodname = tosettername ( fieldnode ) ; <nl> + <nl> + if ( methodexists ( methodname , annotationnode . up ( ) ) ) { <nl> + annotationnode . addwarning ( <nl> + string . format ( " not generating % s ( % s % s ) : a method with that name already exists " , <nl> + methodname , fieldnode . vartype , fieldnode . name ) ) ; <nl> + return ; <nl> + } <nl> + <nl> setter setter = annotation . getinstance ( ) ; <nl>  <nl> jcclassdecl javacclasstree = ( jcclassdecl ) annotationnode . up ( ) . up ( ) . get ( ) ; <nl> mmm a / src / lombok / javac / handlers / pkg . java <nl> ppp b / src / lombok / javac / handlers / pkg . java <nl>
<nl> app : layout_constrainttop_totopof = " parent " <nl> app : srccompat = " @ drawable / bottom_sheet_handle " / > <nl>  <nl> - < ! - - <nl> < androidx . appcompat . widget . appcompatimageview <nl> android : id = " @ + id / header_image " <nl> android : layout_width = " 88dp " <nl> android : layout_height = " 88dp " <nl> android : layout_margintop = " 28dp " <nl> - android : background = " @ color / red " <nl> + app : srccompat = " @ drawable / ic_signal_connections " <nl> app : layout_constraintend_toendof = " parent " <nl> app : layout_constraintstart_tostartof = " parent " <nl> app : layout_constrainttop_tobottomof = " @ id / handle " / >
class stripeapi ( <nl> " payment_method " to paymentmethodid <nl> ) <nl>  <nl> - <nl> - / / val email = paymentsource . email ( ) <nl> - / / if ( email ! = null ) { <nl> - / / parameters [ " receipt_email " ] = email <nl> - / / } <nl> - <nl> postform ( " payment_intents / $ { paymentintent . id } / confirm " , parameters ) <nl> } . subscribeon ( schedulers . io ( ) ) <nl>  <nl>
class stripeapi ( <nl> " type " to " card " , <nl> ) <nl>  <nl> - <nl> - / / val email = paymentsource . email ( ) <nl> - / / if ( email ! = null ) { <nl> - / / parameters [ " billing_details [ email ] " ] = email <nl> - / / } <nl> - <nl> return postform ( " payment_methods " , parameters ) <nl> } <nl>  <nl>
public class conversationparentfragment extends fragment <nl> case r . id . menu_expiring_messages_off : <nl> case r . id . menu_expiring_messages : handleselectmessageexpiration ( ) ; return true ; <nl> case r . id . menu_create_bubble : handlecreatebubble ( ) ; return true ; <nl> - case android . r . id . home : requireactivity ( ) . onbackpressed ( ) ; return true ; <nl> + case android . r . id . home : requireactivity ( ) . finish ( ) ; return true ; <nl> } <nl>  <nl> return false ; <nl> } <nl>  <nl> - <nl> public void onbackpressed ( ) { <nl> log . d ( tag , " onbackpressed ( ) " ) ; <nl> if ( reactiondelegate . isshowing ( ) ) { <nl>
class boostfragment : dslsettingsbottomsheetfragment ( <nl> text = dslsettingstext . from ( r . string . subscribefragment__more_payment_options ) , <nl> icon = dslsettingsicon . from ( r . drawable . ic_open_20 , r . color . signal_accent_primary ) , <nl> onclick = { <nl> - <nl> + communicationactions . openbrowserlink ( requirecontext ( ) , getstring ( r . string . donate_url ) ) <nl> } <nl> ) <nl> } <nl> mmm a / app / src / main / java / org / thoughtcrime / securesms / components / settings / app / subscription / subscribe / subscribefragment . kt <nl> ppp b / app / src / main / java / org / thoughtcrime / securesms / components / settings / app / subscription / subscribe / subscribefragment . kt <nl>
class subscribefragment : dslsettingsfragment ( <nl> text = dslsettingstext . from ( r . string . subscribefragment__more_payment_options ) , <nl> icon = dslsettingsicon . from ( r . drawable . ic_open_20 , r . color . signal_accent_primary ) , <nl> onclick = { <nl> - <nl> + communicationactions . openbrowserlink ( requirecontext ( ) , getstring ( r . string . donate_url ) ) <nl> } <nl> ) <nl> }
class boostfragment : dslsettingsbottomsheetfragment ( <nl> . append ( " " ) <nl> . append ( <nl> spanutil . learnmore ( requirecontext ( ) , contextcompat . getcolor ( requirecontext ( ) , r . color . signal_accent_primary ) ) { <nl> - <nl> + communicationactions . openbrowserlink ( requirecontext ( ) , r . string . sustainer_boost_and_badges ) <nl> } <nl> ) <nl> } <nl> mmm a / app / src / main / res / values / strings . xml <nl> ppp b / app / src / main / res / values / strings . xml <nl>
public final class wallpaperimageselectionactivity extends appcompatactivity <nl>  <nl> @ override <nl> public void ontoolbarnavigationclicked ( ) { <nl> - <nl> + setresult ( result_canceled ) ; <nl> + finish ( ) ; <nl> + } <nl> + <nl> + @ override <nl> + public boolean iscameraenabled ( ) { <nl> + return false ; <nl> } <nl> }
public final class conversationupdateitem extends framelayout <nl>  <nl> / * * after a short delay , if the main data hasn ' t shown yet , then a loading message is displayed . * / <nl> private @ nonnull livedata < spannable > loading ( @ nonnull livedata < spannable > string ) { <nl> - <nl> - return string ; <nl> - / / return livedatautil . until ( string , livedatautil . delay ( 250 , new spannablestring ( getcontext ( ) . getstring ( r . string . conversationupdateitem_loading ) ) ) ) ; <nl> + return livedatautil . until ( string , livedatautil . delay ( 250 , new spannablestring ( getcontext ( ) . getstring ( r . string . conversationupdateitem_loading ) ) ) ) ; <nl> } <nl>  <nl> @ override
public class signalservicemessagesender { <nl> quotebuilder . setauthoruuid ( message . getquote ( ) . get ( ) . getauthor ( ) . getuuid ( ) . get ( ) . tostring ( ) ) ; <nl> } <nl>  <nl> - <nl> - if ( message . getquote ( ) . get ( ) . getauthor ( ) . getnumber ( ) . ispresent ( ) ) { <nl> - quotebuilder . setauthore164 ( message . getquote ( ) . get ( ) . getauthor ( ) . getnumber ( ) . get ( ) ) ; <nl> - } <nl> - <nl> if ( ! message . getquote ( ) . get ( ) . getmentions ( ) . isempty ( ) ) { <nl> for ( signalservicedatamessage . mention mention : message . getquote ( ) . get ( ) . getmentions ( ) ) { <nl> quotebuilder . addbodyranges ( datamessage . bodyrange . newbuilder ( ) <nl> mmm a / libsignal / service / src / main / java / org / whispersystems / signalservice / api / messages / signalservicecontent . java <nl> ppp b / libsignal / service / src / main / java / org / whispersystems / signalservice / api / messages / signalservicecontent . java <nl>
public final class grouplinkbottomsheetdialogfragment extends bottomsheetdialogf <nl> return ; <nl> } <nl>  <nl> - shareviasignalbutton . setonclicklistener ( v - > dismiss ( ) ) ; <nl> - shareviasignalbutton . setvisibility ( view . gone ) ; <nl> + shareviasignalbutton . setonclicklistener ( v - > { <nl> + context context = requirecontext ( ) ; <nl> + intent intent = new intent ( context , shareactivity . class ) ; <nl> + intent . putextra ( intent . extra_text , grouplink . geturl ( ) ) ; <nl> + context . startactivity ( intent ) ; <nl> + <nl> + dismiss ( ) ; <nl> + } ) ; <nl>  <nl> copybutton . setonclicklistener ( v - > { <nl> context context = requirecontext ( ) ;
public class signalservicemessagesender { <nl> . setremove ( message . getreaction ( ) . get ( ) . isremove ( ) ) <nl> . settargetsenttimestamp ( message . getreaction ( ) . get ( ) . gettargetsenttimestamp ( ) ) ; <nl>  <nl> - <nl> - if ( message . getreaction ( ) . get ( ) . gettargetauthor ( ) . getnumber ( ) . ispresent ( ) ) { <nl> - reactionbuilder . settargetauthore164 ( message . getreaction ( ) . get ( ) . gettargetauthor ( ) . getnumber ( ) . get ( ) ) ; <nl> - } <nl> - <nl> if ( message . getreaction ( ) . get ( ) . gettargetauthor ( ) . getuuid ( ) . ispresent ( ) ) { <nl> reactionbuilder . settargetauthoruuid ( message . getreaction ( ) . get ( ) . gettargetauthor ( ) . getuuid ( ) . get ( ) . tostring ( ) ) ; <nl> } <nl> mmm a / libsignal / service / src / main / java / org / whispersystems / signalservice / api / messages / signalservicecontent . java <nl> ppp b / libsignal / service / src / main / java / org / whispersystems / signalservice / api / messages / signalservicecontent . java <nl>
public class conversationlistfragment extends mainfragment implements actionmode <nl> @ override <nl> public void onstart ( ) { <nl> super . onstart ( ) ; <nl> - <nl> - / / conversationfragment . prepare ( requirecontext ( ) ) ; <nl> + conversationfragment . prepare ( requirecontext ( ) ) ; <nl> } <nl>  <nl> @ override <nl> mmm a / app / src / main / java / org / thoughtcrime / securesms / util / dynamictheme . java <nl> ppp b / app / src / main / java / org / thoughtcrime / securesms / util / dynamictheme . java <nl>
<nl> < ? xml version = " 1 . 0 " encoding = " utf - 8 " ? > <nl> < menu xmlns : android = " http : / / schemas . android . com / apk / res / android " xmlns : app = " http : / / schemas . android . com / apk / res - auto " > <nl>  <nl> - < ! - - <nl> - < item android : id = " @ + id / menu_edit_group " <nl> - android : title = " @ string / conversation__menu_edit_group " <nl> - app : showasaction = " collapseactionview " / > <nl> - <nl> < item android : id = " @ + id / menu_manage_group " <nl> android : title = " @ string / conversation__menu_manage_group " <nl> app : showasaction = " collapseactionview " / >
public final class storagesynchelper { <nl> * @ return if changes need to be written , then it will return those changes . if no changes need <nl> * to be written , this will return { @ link optional # absent ( ) } . <nl> * / <nl> - <nl> public static @ nonnull optional < localwriteresult > buildstorageupdatesforlocal ( long currentmanifestversion , <nl> @ nonnull list < storageid > currentlocalkeys , <nl> @ nonnull list < recipientsettings > updates , <nl> mmm a / app / src / main / java / org / thoughtcrime / securesms / storage / storagesyncvalidations . java <nl> ppp b / app / src / main / java / org / thoughtcrime / securesms / storage / storagesyncvalidations . java <nl>
public final class featureflags { <nl> private static final string message_requests = generatekey ( " messagerequests " ) ; <nl> private static final string usernames = generatekey ( " usernames " ) ; <nl> private static final string storage_service = generatekey ( " storageservice " ) ; <nl> - private static final string pins_for_all = generatekey ( " beta . pinsforall " ) ; <nl> + private static final string pins_for_all = generatekey ( " pinsforall " ) ; <nl> private static final string pins_megaphone_kill_switch = generatekey ( " pinsmegaphonekillswitch " ) ; <nl>  <nl> / * * <nl>
public final class featureflags { <nl> * flags in this set will stay true forever once they receive a true value from a remote config . <nl> * / <nl> private static final set < string > sticky = sets . newhashset ( <nl> - pins_for_all <nl> + pins_for_all <nl> ) ; <nl>  <nl> private static final map < string , boolean > remote_values = new treemap < > ( ) ; <nl>
public class conversationactivity extends passphraserequiredactionbaractivity <nl> attachmentmanager . selectlocation ( this , pick_location ) ; <nl> break ; <nl> } <nl> - <nl> - / / attachmentmanager . capturephoto ( this , take_photo ) ; break ; <nl> + <nl> + container . hidecurrentinput ( composetext ) ; <nl> } <nl>  <nl> @ override
<nl> < item name = " android : padding " > 2dp < / item > <nl> < item name = " android : background " > @ null < / item > <nl> < item name = " android : maxlines " > 4 < / item > <nl> - < ! - - <nl> - < ! - - < item name = " android : maxlength " > 65536 < / item > - - > <nl> - < item name = " android : maxlength " > 2000 < / item > <nl> + < item name = " android : maxlength " > 65536 < / item > <nl> < item name = " android : textcolor " > ? conversation_item_sent_text_primary_color < / item > <nl> < item name = " android : capitalize " > sentences < / item > <nl> < item name = " android : autotext " > true < / item > <nl> mmm a / src / org / thoughtcrime / securesms / util / pushcharactercalculator . java <nl> ppp b / src / org / thoughtcrime / securesms / util / pushcharactercalculator . java <nl>
<nl> package org . thoughtcrime . securesms . util ; <nl>  <nl> public class pushcharactercalculator extends charactercalculator { <nl> - <nl> - / / private static final int max_total_size = num * num ; <nl> - private static final int max_total_size = num ; <nl> + private static final int max_total_size = num * num ; <nl> private static final int max_primary_size = num ; <nl> @ override <nl> public characterstate calculatecharacters ( string messagebody ) {
public class conversationactivity extends passphraserequiredactionbaractivity <nl> setmedia ( data . getdata ( ) , mediatype . audio ) ; <nl> break ; <nl> case pick_contact : <nl> - <nl> - addattachmentcontactinfo ( data . getdata ( ) ) ; <nl> - / / if ( issecuretext & & ! issmsforced ( ) ) { <nl> - / / opencontactshareeditor ( data . getdata ( ) ) ; <nl> - / / } else { <nl> - / / addattachmentcontactinfo ( data . getdata ( ) ) ; <nl> - / / } <nl> + if ( issecuretext & & ! issmsforced ( ) ) { <nl> + opencontactshareeditor ( data . getdata ( ) ) ; <nl> + } else { <nl> + addattachmentcontactinfo ( data . getdata ( ) ) ; <nl> + } <nl> break ; <nl> case get_contact_details : <nl> sendsharedcontact ( data . getparcelablearraylistextra ( contactshareeditactivity . key_contacts ) ) ; <nl>
public class conversationactivity extends passphraserequiredactionbaractivity <nl> private void setmedia ( @ nullable uri uri , @ nonnull mediatype mediatype , int width , int height ) { <nl> if ( uri = = null ) return ; <nl>  <nl> - <nl> - attachmentmanager . setmedia ( gliderequests , uri , mediatype , getcurrentmediaconstraints ( ) , width , height ) ; <nl> - / / if ( mediatype . vcard . equals ( mediatype ) & & issecuretext ) { <nl> - / / opencontactshareeditor ( uri ) ; <nl> - / / } else { <nl> - / / attachmentmanager . setmedia ( gliderequests , uri , mediatype , getcurrentmediaconstraints ( ) , width , height ) ; <nl> - / / } <nl> + if ( mediatype . vcard . equals ( mediatype ) & & issecuretext ) { <nl> + opencontactshareeditor ( uri ) ; <nl> + } else { <nl> + attachmentmanager . setmedia ( gliderequests , uri , mediatype , getcurrentmediaconstraints ( ) , width , height ) ; <nl> + } <nl> } <nl>  <nl> private void opencontactshareeditor ( uri contacturi ) {
public class mmsdatabase extends database implements mmssmscolumns { <nl> for ( encodedstringvalue encodedto : encodedtolist ) { <nl> string to = new string ( encodedto . gettextstring ( ) , charactersets . mimename_iso_8859_1 ) ; <nl>  <nl> - / <nl> - if ( localnumber = = null | | ! localnumber . equals ( to ) ) { <nl> + phonenumberutil . matchtype match ; <nl> + <nl> + if ( localnumber = = null ) match = phonenumberutil . matchtype . no_match ; <nl> + else match = phonenumberutil . getinstance ( ) . isnumbermatch ( localnumber , to ) ; <nl> + <nl> + if ( match = = phonenumberutil . matchtype . no_match | | <nl> + match = = phonenumberutil . matchtype . not_a_number ) <nl> + { <nl> group . add ( to ) ; <nl> } <nl> } <nl> mmm a / src / org / thoughtcrime / securesms / service / mmsdownloader . java <nl> ppp b / src / org / thoughtcrime / securesms / service / mmsdownloader . java <nl>
public class smsmessagerecord extends messagerecord { <nl> } else if ( ! getbody ( ) . isplaintext ( ) ) { <nl> return emphasisadded ( context . getstring ( r . string . messagenotifier_encrypted_message ) ) ; <nl> } else if ( smsdatabase . types . isendsessiontype ( type ) ) { <nl> - <nl> - return new spannablestring ( " session closed ! " ) ; <nl> + return emphasisadded ( context . getstring ( r . string . smsmessagerecord_secure_session_ended ) ) ; <nl> } else if ( isoutgoing ( ) & & tag . istagged ( getbody ( ) . getbody ( ) ) ) { <nl> return new spannablestring ( tag . striptag ( getbody ( ) . getbody ( ) ) ) ; <nl> } else { <nl> mmm a / src / org / thoughtcrime / securesms / database / model / threadrecord . java <nl> ppp b / src / org / thoughtcrime / securesms / database / model / threadrecord . java <nl>
public class threadrecord extends displayrecord { <nl>  <nl> @ override <nl> public spannablestring getdisplaybody ( ) { <nl> - <nl> if ( smsdatabase . types . isdecryptinprogresstype ( type ) ) { <nl> return emphasisadded ( context . getstring ( r . string . messagedisplayhelper_decrypting_please_wait ) ) ; <nl> } else if ( isgroupupdate ( ) ) { <nl> return emphasisadded ( grouputil . getdescription ( getbody ( ) . getbody ( ) ) ) ; <nl> } else if ( isgroupquit ( ) ) { <nl> - return emphasisadded ( " someone left the group . " ) ; <nl> + return emphasisadded ( context . getstring ( r . string . threadrecord_left_the_group ) ) ; <nl> } else if ( iskeyexchange ( ) ) { <nl> return emphasisadded ( context . getstring ( r . string . conversationlistitem_key_exchange_message ) ) ; <nl> } else if ( smsdatabase . types . isfaileddecrypttype ( type ) ) { <nl>
public class threadrecord extends displayrecord { <nl> } else if ( ! getbody ( ) . isplaintext ( ) ) { <nl> return emphasisadded ( context . getstring ( r . string . messagenotifier_encrypted_message ) ) ; <nl> } else if ( smsdatabase . types . isendsessiontype ( type ) ) { <nl> - <nl> - return emphasisadded ( " session closed ! " ) ; <nl> + return emphasisadded ( context . getstring ( r . string . theadrecord_secure_session_ended ) ) ; <nl> } else { <nl> if ( util . isempty ( getbody ( ) . getbody ( ) ) ) { <nl> return new spannablestring ( context . getstring ( r . string . messagenotifier_no_subject ) ) ;
public class disruptortest <nl> } <nl> } <nl>  <nl> - <nl> + @ test <nl> public void shouldbeabletooverridetheexceptionhandlerforaeventprocessor ( ) <nl> throws exception <nl> { <nl> - final delayedeventhandler eventhandler = createdelayedeventhandler ( ) ; <nl> - <nl> final runtimeexception testexception = new runtimeexception ( ) ; <nl> - final exceptionthrowingeventhandler eventhandler2 = new exceptionthrowingeventhandler ( testexception ) ; <nl> - disruptor . handleeventswith ( eventhandler ) . then ( eventhandler2 ) ; <nl> - <nl> - publishevent ( ) ; <nl> + final exceptionthrowingeventhandler eventhandler = new exceptionthrowingeventhandler ( testexception ) ; <nl> + disruptor . handleeventswith ( eventhandler ) ; <nl>  <nl> atomicreference < exception > reference = new atomicreference < exception > ( ) ; <nl> stubexceptionhandler exceptionhandler = new stubexceptionhandler ( reference ) ; <nl> - disruptor . handleexceptionsfor ( eventhandler2 ) . with ( exceptionhandler ) ; <nl> - eventhandler . processevent ( ) ; <nl> + disruptor . handleexceptionsfor ( eventhandler ) . with ( exceptionhandler ) ; <nl> + <nl> + publishevent ( ) ; <nl>  <nl> waitfor ( reference ) ; <nl> }
public class buildactivity extends baseactivity implements autojsapkbuilder . prog <nl> } <nl>  <nl> private void downloadplugin ( ) { <nl> - <nl> + intentutil . browse ( this , " https : / / www . autojs . org / topic / 977 " ) ; <nl> } <nl>  <nl> private void setupwithsourcefile ( scriptfile file ) { <nl> mmm a / autojs / src / main / res / values / arrays . xml <nl> ppp b / autojs / src / main / res / values / arrays . xml <nl>
public final class handlerschedulertest { <nl> asserttrue ( disposable . isdisposed ( ) ) ; <nl> } <nl>  <nl> - @ test public void throwingactionroutedtohookandthreadhandler ( ) { <nl> - <nl> + @ test public void throwingactionroutedtorxjavaplugins ( ) { <nl> + consumer < throwable > originalerrorhandler = rxjavaplugins . geterrorhandler ( ) ; <nl>  <nl> - thread thread = thread . currentthread ( ) ; <nl> - uncaughtexceptionhandler originalhandler = thread . getuncaughtexceptionhandler ( ) ; <nl> - <nl> - final atomicreference < throwable > throwableref = new atomicreference < > ( ) ; <nl> - thread . setuncaughtexceptionhandler ( new uncaughtexceptionhandler ( ) { <nl> - @ override public void uncaughtexception ( thread thread , throwable ex ) { <nl> - throwableref . set ( ex ) ; <nl> - } <nl> - } ) ; <nl> + try { <nl> + final atomicreference < throwable > throwableref = new atomicreference < > ( ) ; <nl> + rxjavaplugins . seterrorhandler ( new consumer < throwable > ( ) { <nl> + @ override <nl> + public void accept ( throwable throwable ) throws exception { <nl> + throwableref . set ( throwable ) ; <nl> + } <nl> + } ) ; <nl>  <nl> - worker worker = scheduler . createworker ( ) ; <nl> + worker worker = scheduler . createworker ( ) ; <nl>  <nl> - final nullpointerexception npe = new nullpointerexception ( ) ; <nl> - runnable action = new runnable ( ) { <nl> - @ override public void run ( ) { <nl> - throw npe ; <nl> - } <nl> - } ; <nl> - worker . schedule ( action ) ; <nl> - <nl> - runuithreadtasks ( ) ; <nl> - throwable throwable = throwableref . get ( ) ; <nl> - asserttrue ( throwable instanceof illegalstateexception ) ; <nl> - assertequals ( " fatal exception thrown on scheduler . " , throwable . getmessage ( ) ) ; <nl> - assertsame ( npe , throwable . getcause ( ) ) ; <nl> + final nullpointerexception npe = new nullpointerexception ( ) ; <nl> + runnable action = new runnable ( ) { <nl> + @ override <nl> + public void run ( ) { <nl> + throw npe ; <nl> + } <nl> + } ; <nl> + worker . schedule ( action ) ; <nl>  <nl> - / / restore the original uncaught exception handler . <nl> - thread . setuncaughtexceptionhandler ( originalhandler ) ; <nl> + runuithreadtasks ( ) ; <nl> + assertsame ( npe , throwableref . get ( ) ) ; <nl> + } finally { <nl> + rxjavaplugins . seterrorhandler ( originalerrorhandler ) ; <nl> + } <nl> } <nl>  <nl> @ test
<nl> < module > twilio < / module > <nl> < module > twitter4j < / module > <nl>  <nl> - < ! - - < module > undertow < / module > - - > < ! - - num . 11 . 2019 - disabling temporarily as it ' s causing a major issue with the build ( <nl> + < module > undertow < / module > <nl>  <nl> < module > vertx < / module > <nl> < module > vertx - and - rxjava < / module > <nl>
<nl> < module > twilio < / module > <nl> < module > twitter4j < / module > <nl>  <nl> - < ! - - < module > undertow < / module > - - > < ! - - num . 11 . 2019 - disabling temporarily as it ' s causing a major issue with the build ( <nl> + < module > undertow < / module > <nl>  <nl> < module > vertx < / module > <nl> < module > vertx - and - rxjava < / module > <nl> mmm a / undertow / pom . xml <nl> ppp b / undertow / pom . xml <nl>
<nl>  <nl> this module contains articles about core features in the java language <nl>  <nl> - # # <nl> + # # # relevant articles : <nl> + <nl> + - [ difference between = = and equals ( ) in java ] ( https : / / www . baeldung . com / java - equals - method - operator - difference )
<nl> - package com . baeldung . hexagonalpattern . adapters ; <nl> - <nl> - import java . util . hashmap ; <nl> - import java . util . list ; <nl> - import java . util . map ; <nl> - import java . util . stream . collectors ; <nl> - <nl> - import org . springframework . stereotype . repository ; <nl> - <nl> - import com . baeldung . hexagonalpattern . core . domain . book ; <nl> - import com . baeldung . hexagonalpattern . ports . libraryrepo ; <nl> - <nl> - @ repository <nl> - public class libraryrepoimpl implements libraryrepo { <nl> - / / this class is the actual implementation of the out bound port / adapter . <nl> - <nl> - private hashmap < string , book > books = new hashmap < string , book > ( ) ; <nl> - <nl> - @ override <nl> - public int insertbook ( book book ) { <nl> - / / mock database call here . <nl> - books . put ( " mock " , new book ( " mock " , " mock " , " mock " ) ) ; <nl> - return num ; <nl> - } <nl> - <nl> - @ override <nl> - public book searchbook ( string name ) { <nl> - <nl> - book b = new book ( ) ; <nl> - / / some code for retrieval of book from db <nl> - return b ; <nl> - } <nl> - <nl> - @ override <nl> - public list < book > getallbooks ( ) { <nl> - / / fetch all books from db <nl> - return books . values ( ) . stream ( ) . collect ( collectors . tolist ( ) ) ; <nl> - } <nl> - <nl> - }
this module contains articles about networking in java <nl>  <nl> # # # relevant articles <nl>  <nl> - - <nl> + - [ finding a free port in java ] ( https : / / www . baeldung . com / java - free - port ) <nl> - [ [ < - - prev ] ] ( / core - java - modules / core - java - networking - 2 )
<nl>  <nl> # # # relevant articles : <nl>  <nl> - - <nl> + - [ arraylist vs . linkedlist vs . hashmap in java ] ( https : / / www . baeldung . com / java - arraylist - vs - linkedlist - vs - hashmap )
this module contains articles about java num . <nl>  <nl> # # # relevant articles <nl>  <nl> - - <nl> + - [ sealed classes and interfaces in java num ] ( https : / / www . baeldung . com / java - sealed - classes - interfaces )
the " rest with spring " classes : http : / / bit . ly / restwithspring <nl>  <nl> # # # relevant articles : <nl>  <nl> - - [ how to set tls version in apache httpclient ] ( https : <nl> + - [ how to set tls version in apache httpclient ] ( https : / / www . baeldung . com / apache - httpclient - tls ) <nl> - more articles : [ [ < - - prev ] ] ( . . / httpclient )
public class jmxtutorialmainlauncher { <nl> private static final logger log = loggerfactory . getlogger ( jmxtutorialmainlauncher . class ) ; <nl>  <nl> public static void main ( string [ ] args ) { <nl> - <nl>  <nl> log . debug ( " this is basic jmx tutorial " ) ; <nl> - objectname objectname = null ; <nl> - try { <nl> - objectname = new objectname ( " com . baeldung . tutorial : type = basic , name = game " ) ; <nl> - } catch ( malformedobjectnameexception e ) { <nl> - e . printstacktrace ( ) ; <nl> - } <nl> - mbeanserver server = managementfactory . getplatformmbeanserver ( ) ; <nl> - game gameobj = new game ( ) ; <nl> + <nl> try { <nl> - server . registermbean ( gameobj , objectname ) ; <nl> - } catch ( instancealreadyexistsexception | mbeanregistrationexception | notcompliantmbeanexception e ) { <nl> + objectname objectname = new objectname ( " com . baeldung . tutorial : type = basic , name = game " ) ; <nl> + mbeanserver server = managementfactory . getplatformmbeanserver ( ) ; <nl> + server . registermbean ( new game ( ) , objectname ) ; <nl> + } catch ( malformedobjectnameexception | instancealreadyexistsexception | <nl> + mbeanregistrationexception | notcompliantmbeanexception e ) { <nl> e . printstacktrace ( ) ; <nl> } <nl> + <nl> log . debug ( " registration for game mbean with the platform server is successfull " ) ; <nl> log . debug ( " please open jconsole to access game mbean " ) ; <nl> + <nl> while ( true ) { <nl> / / to ensure application does not terminate <nl> }
<nl> # # # relevant articles : <nl> - - [ fallback for zuul route ] ( <nl> + - [ fallback for zuul route ] ( https : / / www . baeldung . com / spring - zuul - fallback - route )
<nl> < / dependency > <nl> < / dependencies > <nl> < configuration > <nl> - < failurepriority > 5 < / failurepriority > < ! - - <nl> - < aggregate > true < / aggregate > <nl> + < failurepriority > 5 < / failurepriority > <nl> + < aggregate > false < / aggregate > <nl> < failonviolation > true < / failonviolation > <nl> < verbose > true < / verbose > <nl> < linkxref > true < / linkxref >
package com . baeldung . algorithms . multiswarm ; <nl> import java . util . arrays ; <nl> import java . util . random ; <nl>  <nl> - <nl> / * * <nl> * represents a collection of { @ link particle } . <nl> * <nl> mmm / dev / null <nl> ppp b / algorithms / src / test / java / com / baeldung / algorithms / multiswarm / lolfitnessfunction . java <nl>
public class whenusingtreeset { <nl>  <nl> @ override <nl> public string tostring ( ) { <nl> - <nl> return id . tostring ( ) ; <nl> } <nl> } <nl>
<nl>  <nl> < module > handling - spring - static - resources < / module > <nl> < module > hazelcast < / module > <nl> - < ! - - < module > hbase < / module > <nl> + < module > hbase < / module > <nl> < module > httpclient < / module > <nl> < module > hystrix < / module >
<nl> < modules > <nl> < module > annotations < / module > <nl> < module > apache - cxf < / module > <nl> - < module > apache - fop < / module > < ! - - <nl> + < module > apache - fop < / module > <nl> + < module > aspectj < / module > <nl> < module > assertj < / module > <nl> < module > autovalue < / module > <nl>  <nl>
public class javatimerlongrunningunittest { <nl> @ override <nl> public void run ( ) { <nl> system . out . println ( " task performed on " + new date ( ) ) ; <nl> - <nl> } <nl> } ; <nl> final timer timer = new timer ( " timer " ) ;
public class redditclassifier { <nl> internalvector . set ( 1 , integer . parseint ( numberofwordintitle ) ) ; / / number of words in the title <nl>  <nl> domainencoder . addtovector ( therootdomain , internalvector ) ; <nl> - final string [ ] words = title . split ( " " ) ; <nl> - / / titleencoder . setprobes ( words . length ) ; <nl> - <nl> - <nl> - for ( final string word : words ) { <nl> - titleencoder . addtovector ( word , internalvector ) ; <nl> - } <nl> + final list < string > words = splitter . on ( ' ' ) . splittolist ( title ) ; <nl> + words . stream ( ) . filter ( word - > word . length ( ) > num ) . foreach ( word - > titleencoder . addtovector ( word , internalvector ) ) ; <nl>  <nl> final string category = extractcategory ( integer . parseint ( numberofvotes ) ) ; <nl> return new namedvector ( internalvector , category ) ; <nl> } <nl>  <nl> private string extractcategory ( final int score ) { <nl> - return ( score < min_score ) ? " bad " : " good " ; <nl> + return ( score < minscore ) ? " bad " : " good " ; <nl> } <nl>  <nl> } <nl> mmm a / spring - security - oauth / src / main / java / org / baeldung / reddit / classifier / redditdatacollector . java <nl> ppp b / spring - security - oauth / src / main / java / org / baeldung / reddit / classifier / redditdatacollector . java <nl>
<nl> = = = = = = = = = <nl>  <nl> - # # spring security with resttemplate - example project <nl> + # # rest api with basic authentication - example project <nl>  <nl>  <nl> # # # relevant articles : <nl> - [ resttemplate with basic authentication in spring ] ( http : / / www . baeldung . com / 2012 / 04 / 16 / how - to - use - resttemplate - with - basic - authentication - in - spring - 3 - 1 ) <nl> - [ httpclient timeout ] ( http : / / www . baeldung . com / httpclient - timeout ) <nl> - <nl> - <nl> \ no newline at end of file <nl> mmm a / spring - security - rest - digest - auth / readme . md <nl> ppp b / spring - security - rest - digest - auth / readme . md <nl>
<nl> < cve > cve - 2022 - 23305 < / cve > <nl> < cve > cve - 2022 - 23302 < / cve > <nl> < / suppress > <nl> + < suppress > <nl> + < notes > < ! [ cdata [ <nl> + file name : log4j - core - 2 . 17 . 1 . jar <nl> + ] ] > < / notes > <nl> + < packageurl regex = " true " > ^ pkg : maven / org . apache . logging . log4j / log4j - core @ 2 . 17 . 1 $ < / packageurl > <nl> + < cve > cve - 2022 - 33915 < / cve > <nl> + < / suppress > <nl> < suppress > <nl> < ! - - <nl> -
public class druidprocessingmodule implements module <nl> cacheconfig . getnumbackgroundthreads ( ) , <nl> new threadfactorybuilder ( ) <nl> . setnameformat ( " background - cacher - % d " ) <nl> - . setdaemon ( true ) <nl> + . setdaemon ( true ) <nl> . setpriority ( thread . min_priority ) <nl> . build ( ) <nl> ) ;
public class compressedobjectstrategy < t extends buffer > implements objectstrateg <nl> @ override <nl> public void decompress ( bytebuffer in , int numbytes , bytebuffer out ) <nl> { <nl> - final byte [ ] bytes = new byte [ numbytes ] ; <nl> - in . get ( bytes ) ; <nl> - <nl> - try ( final resourceholder < byte [ ] > outputbytesholder = compressedpools . getoutputbytes ( ) ) { <nl> - final byte [ ] outputbytes = outputbytesholder . get ( ) ; <nl> - / / since decompressed size is not known , must use lz4safe <nl> - final int numdecompressedbytes = lz4safe . decompress ( bytes , outputbytes ) ; <nl> - out . put ( outputbytes , num , numdecompressedbytes ) ; <nl> - out . flip ( ) ; <nl> - } <nl> - catch ( ioexception e ) { <nl> - log . error ( e , " ioexception thrown while closing chunkencoder . " ) ; <nl> - } <nl> + / / since decompressed size is not known , must use lz4safe <nl> + / / lz4safe . decompress does not modify buffer positions <nl> + final int numdecompressedbytes = lz4safe . decompress ( in , in . position ( ) , numbytes , out , out . position ( ) , out . remaining ( ) ) ; <nl> + out . limit ( out . position ( ) + numdecompressedbytes ) ; <nl> } <nl>  <nl> @ override <nl> public void decompress ( bytebuffer in , int numbytes , bytebuffer out , int decompressedsize ) <nl> { <nl> - final byte [ ] bytes = new byte [ numbytes ] ; <nl> - in . get ( bytes ) ; <nl> - <nl> - <nl> - try ( final resourceholder < byte [ ] > outputbytesholder = compressedpools . getoutputbytes ( ) ) { <nl> - final byte [ ] outputbytes = outputbytesholder . get ( ) ; <nl> - lz4fast . decompress ( bytes , num , outputbytes , num , decompressedsize ) ; <nl> - <nl> - out . put ( outputbytes , num , decompressedsize ) ; <nl> - out . flip ( ) ; <nl> - } <nl> - catch ( ioexception e ) { <nl> - log . error ( e , " ioexception thrown while closing chunkencoder . " ) ; <nl> - } <nl> + / / lz4fast . decompress does not modify buffer positions <nl> + lz4fast . decompress ( in , in . position ( ) , out , out . position ( ) , decompressedsize ) ; <nl> + out . limit ( out . position ( ) + decompressedsize ) ; <nl> } <nl> }
public class compressedobjectstrategy < t extends buffer > implements objectstrateg <nl> @ override <nl> public void decompress ( bytebuffer in , int numbytes , bytebuffer out ) <nl> { <nl> - final byte [ ] bytes = new byte [ numbytes ] ; <nl> - in . get ( bytes ) ; <nl> - <nl> - try ( final resourceholder < byte [ ] > outputbytesholder = compressedpools . getoutputbytes ( ) ) { <nl> - final byte [ ] outputbytes = outputbytesholder . get ( ) ; <nl> - / / since decompressed size is not known , must use lz4safe <nl> - final int numdecompressedbytes = lz4safe . decompress ( bytes , outputbytes ) ; <nl> - out . put ( outputbytes , num , numdecompressedbytes ) ; <nl> - out . flip ( ) ; <nl> - } <nl> - catch ( ioexception e ) { <nl> - log . error ( e , " ioexception thrown while closing chunkencoder . " ) ; <nl> - } <nl> + / / since decompressed size is not known , must use lz4safe <nl> + / / lz4safe . decompress does not modify buffer positions <nl> + final int numdecompressedbytes = lz4safe . decompress ( in , in . position ( ) , numbytes , out , out . position ( ) , out . remaining ( ) ) ; <nl> + out . limit ( out . position ( ) + numdecompressedbytes ) ; <nl> } <nl>  <nl> @ override <nl> public void decompress ( bytebuffer in , int numbytes , bytebuffer out , int decompressedsize ) <nl> { <nl> - final byte [ ] bytes = new byte [ numbytes ] ; <nl> - in . get ( bytes ) ; <nl> - <nl> - <nl> - try ( final resourceholder < byte [ ] > outputbytesholder = compressedpools . getoutputbytes ( ) ) { <nl> - final byte [ ] outputbytes = outputbytesholder . get ( ) ; <nl> - lz4fast . decompress ( bytes , num , outputbytes , num , decompressedsize ) ; <nl> - <nl> - out . put ( outputbytes , num , decompressedsize ) ; <nl> - out . flip ( ) ; <nl> - } <nl> - catch ( ioexception e ) { <nl> - log . error ( e , " ioexception thrown while closing chunkencoder . " ) ; <nl> - } <nl> + / / lz4fast . decompress does not modify buffer positions <nl> + lz4fast . decompress ( in , in . position ( ) , out , out . position ( ) , decompressedsize ) ; <nl> + out . limit ( out . position ( ) + decompressedsize ) ; <nl> } <nl> }
public class ingestsegmentfirehosefactory implements firehosefactory < inputrowpar <nl> public firehose connect ( inputrowparser inputrowparser ) throws ioexception , parseexception <nl> { <nl> log . info ( " connecting firehose : druidfirehose [ % s , % s ] " , datasource , interval ) ; <nl> - <nl> final tasktoolbox toolbox = injector . getinstance ( tasktoolboxfactory . class ) . build ( <nl> - new nooptask ( <nl> - " druid - firehose " , <nl> - num , <nl> - num , <nl> - null , <nl> - null <nl> - ) <nl> + new ingesttask ( " ingest - task - id " , datasource ) <nl> ) ; <nl>  <nl> try { <nl>
public class clibroker extends serverrunnable <nl> binder . bind ( timelineserverview . class ) . to ( brokerserverview . class ) . in ( lazysingleton . class ) ; <nl>  <nl> binder . bind ( cache . class ) . toprovider ( cacheprovider . class ) . in ( managelifecycle . class ) ; <nl> - jsonconfigprovider . bind ( binder , " druid . broker . cache " , cacheprovider . class ) ; <nl> + jsonconfigprovider . bind ( binder , " druid . broker . cache " , cacheprovider . class ) ; <nl> jsonconfigprovider . bind ( binder , " druid . broker . cache " , cacheconfig . class ) ; <nl> jsonconfigprovider . bind ( binder , " druid . broker . select . tier " , tierselectorstrategy . class ) ; <nl> jsonconfigprovider . bind ( binder , " druid . broker . select . tier . custom " , customtierselectorstrategyconfig . class ) ; <nl> mmm a / services / src / main / java / io / druid / cli / clihistorical . java <nl> ppp b / services / src / main / java / io / druid / cli / clihistorical . java <nl>
public class clihistorical extends serverrunnable <nl> lifecyclemodule . register ( binder , server . class ) ; <nl>  <nl> binder . bind ( cache . class ) . toprovider ( cacheprovider . class ) . in ( managelifecycle . class ) ; <nl> - jsonconfigprovider . bind ( binder , " druid . historical . cache " , cacheprovider . class ) ; <nl> + jsonconfigprovider . bind ( binder , " druid . historical . cache " , cacheprovider . class ) ; <nl> jsonconfigprovider . bind ( binder , " druid . historical . cache " , cacheconfig . class ) ; <nl> metricsmodule . register ( binder , cachemonitor . class ) ; <nl> }
public class rabbitmqfirehosefactory implements firehosefactory <nl> public void shutdowncompleted ( shutdownsignalexception cause ) <nl> { <nl> log . warn ( cause , " connection closed ! " ) ; <nl> - <nl> } <nl> } ) ; <nl>  <nl>
public class rabbitmqfirehosefactory implements firehosefactory <nl> public void shutdowncompleted ( shutdownsignalexception cause ) <nl> { <nl> log . warn ( cause , " channel closed ! " ) ; <nl> - <nl> } <nl> } ) ; <nl>  <nl>
public class rabbitmqfirehosefactory implements firehosefactory <nl> { <nl> delivery = null ; <nl> try { <nl> + / / wait for the next delivery . this will block until something is available . <nl> delivery = consumer . nextdelivery ( ) ; <nl> - lastdeliverytag = delivery . getenvelope ( ) . getdeliverytag ( ) ; <nl> - / / log . debug ( " received new message from rabbitmq " ) ; <nl> + if ( delivery ! = null ) { <nl> + lastdeliverytag = delivery . getenvelope ( ) . getdeliverytag ( ) ; <nl> + / / if delivery is non - null , we report that there is something more to process . <nl> + return true ; <nl> + } <nl> } <nl> catch ( interruptedexception e ) { <nl> - <nl> - / / does it mean that delivery will be null and we should handle that <nl> - / / as if there are no more messages ( return false ) ? <nl> - log . wtf ( e , " got interrupted while waiting for next delivery . doubt this should ever happen . " ) ; <nl> - } <nl> + / / a little unclear on how we should handle this . <nl>  <nl> - if ( delivery ! = null ) { <nl> - / / if delivery is non - null , we report that there is something more to process . <nl> - return true ; <nl> + / / at any rate , we ' re in an unknown state now so let ' s log something and return false . <nl> + log . wtf ( e , " got interrupted while waiting for next delivery . doubt this should ever happen . " ) ; <nl> } <nl>  <nl> - / / this means that delivery is null so we have nothing more to process . <nl> + / / this means that delivery is null or we caught the exception above so we report that we have <nl> + / / nothing more to process . <nl> return false ; <nl> }
import com . metamx . druid . index . v1 . indexio ; <nl> import com . metamx . druid . loading . datasegmentpusher ; <nl> import com . metamx . druid . loading . datasegmentpusherutil ; <nl> import com . metamx . druid . utils . compressionutils ; <nl> - import com . netflix . astyanax . astyanaxcontext ; <nl> import com . netflix . astyanax . keyspace ; <nl> import com . netflix . astyanax . mutationbatch ; <nl> - import com . netflix . astyanax . connectionpool . nodediscoverytype ; <nl> - import com . netflix . astyanax . connectionpool . impl . connectionpoolconfigurationimpl ; <nl> - import com . netflix . astyanax . connectionpool . impl . countingconnectionpoolmonitor ; <nl> - import com . netflix . astyanax . impl . astyanaxconfigurationimpl ; <nl> import com . netflix . astyanax . model . columnfamily ; <nl> - import com . netflix . astyanax . recipes . storage . cassandrachunkedstorageprovider ; <nl> import com . netflix . astyanax . recipes . storage . chunkedstorage ; <nl> import com . netflix . astyanax . recipes . storage . chunkedstorageprovider ; <nl> - import com . netflix . astyanax . serializers . stringserializer ; <nl> - import com . netflix . astyanax . thrift . thriftfamilyfactory ; <nl>  <nl> / * * <nl> * cassandra segment pusher <nl> * <nl> * @ author boneill42 <nl> * / <nl> - <nl> - / / should we make it so they can specify tables ? <nl> - public class cassandradatasegmentpusher implements datasegmentpusher <nl> + public class cassandradatasegmentpusher extends cassandrastorage implements datasegmentpusher <nl> { <nl> private static final logger log = new logger ( cassandradatasegmentpusher . class ) ; <nl> - private static final string cluster_name = " druid_cassandra_cluster " ; <nl> - private static final string index_table_name = " index_storage " ; <nl> - private static final string descriptor_table_name = " descriptor_storage " ; <nl> private static final int concurrency = num ; <nl> private static final joiner joiner = joiner . on ( " / " ) . skipnulls ( ) ; <nl> - private final cassandradatasegmentconfig config ; <nl> private final objectmapper jsonmapper ; <nl>  <nl> - private keyspace keyspace ; <nl> - private astyanaxcontext < keyspace > astyanaxcontext ; <nl> - private chunkedstorageprovider indexstorage ; <nl> - private columnfamily < string , string > descriptorstorage ; <nl> - <nl> public cassandradatasegmentpusher ( <nl> cassandradatasegmentconfig config , <nl> objectmapper jsonmapper ) <nl> { <nl> - this . config = config ; <nl> - this . jsonmapper = jsonmapper ; <nl> - this . astyanaxcontext = new astyanaxcontext . builder ( ) <nl> - . forcluster ( cluster_name ) <nl> - . forkeyspace ( config . getkeyspace ( ) ) <nl> - . withastyanaxconfiguration ( new astyanaxconfigurationimpl ( ) . setdiscoverytype ( nodediscoverytype . none ) ) <nl> - . withconnectionpoolconfiguration ( <nl> - new connectionpoolconfigurationimpl ( " myconnectionpool " ) . setmaxconnsperhost ( 10 ) <nl> - . setseeds ( config . gethost ( ) ) ) . withconnectionpoolmonitor ( new countingconnectionpoolmonitor ( ) ) <nl> - . buildkeyspace ( thriftfamilyfactory . getinstance ( ) ) ; <nl> - this . astyanaxcontext . start ( ) ; <nl> - this . keyspace = this . astyanaxcontext . getentity ( ) ; <nl> - <nl> - descriptorstorage = new columnfamily < string , string > ( descriptor_table_name , <nl> - stringserializer . get ( ) , stringserializer . get ( ) ) ; <nl> - <nl> - indexstorage = new cassandrachunkedstorageprovider ( keyspace , index_table_name ) ; <nl> + super ( config ) ; <nl> + this . jsonmapper = jsonmapper ; <nl> } <nl>  <nl> @ override <nl> mmm a / server / src / main / java / com / metamx / druid / loading / cassandra / cassandrastorage . java <nl> ppp b / server / src / main / java / com / metamx / druid / loading / cassandra / cassandrastorage . java <nl>
public class inforesource <nl> @ queryparam ( " interval " ) final string interval <nl> ) <nl> { <nl> - <nl> - if ( indexingserviceclient = = null ) { <nl> - return response . status ( response . status . ok ) . entity ( immutablemap . of ( " error " , " no indexing service found " ) ) . build ( ) ; <nl> - } <nl> if ( kill ! = null & & boolean . valueof ( kill ) ) { <nl> indexingserviceclient . killsegments ( datasourcename , new interval ( interval ) ) ; <nl> } else { <nl> mmm a / server / src / main / java / com / metamx / druid / http / mastermain . java <nl> ppp b / server / src / main / java / com / metamx / druid / http / mastermain . java <nl>
<nl> - <nl> grammar druidsql ; <nl>  <nl> - / * <nl> - @ lexer : : header { <nl> - package com . metamx . druid . sql . antlr ; <nl> - } <nl> - * / <nl> - / * <nl> - <nl> - unary minus <nl> - * / <nl> - <nl> @ header { <nl> import com . metamx . druid . aggregation . post . * ; <nl> import com . metamx . druid . aggregation . * ;
druid . database . segmenttable = prod_segments <nl> druid . emitter . period = pt60s <nl>  <nl> druid . master . host <nl> - # <nl> + # poll period the master runs on <nl> druid . master . period = pt60s <nl> + # number of poll periods to wait for a node to come back before believing it is really gone <nl> druid . master . removedsegmentlifetime = 1 <nl> + # delay for the master to start its work , this should be sufficiently high so that the master can get all of the <nl> + # information it needs from zk before starting . it ' s a hack , but it works until we re - work our zk integration . <nl> druid . master . startdelay = pt600s <nl>  <nl> # path on local fs for storage of segments ; dir . will be created if needed <nl>
public class indexercoordinatornode <nl> . build ( ) <nl> ) ; <nl>  <nl> - scalingstrategy strategy = new ec2autoscalingstrategy ( <nl> - new amazonec2client ( <nl> - new basicawscredentials ( <nl> - props . getproperty ( " com . metamx . aws . accesskey " ) , <nl> - props . getproperty ( " com . metamx . aws . secretkey " ) <nl> - ) <nl> - ) , <nl> - configfactory . build ( ec2autoscalingstrategyconfig . class ) <nl> - ) ; <nl> - <nl> - strategy = new noopscalingstrategy ( ) ; <nl> + scalingstrategy strategy ; <nl> + if ( config . getstrategyimpl ( ) . equalsignorecase ( " ec2 " ) ) { <nl> + strategy = new ec2autoscalingstrategy ( <nl> + new amazonec2client ( <nl> + new basicawscredentials ( <nl> + props . getproperty ( " com . metamx . aws . accesskey " ) , <nl> + props . getproperty ( " com . metamx . aws . secretkey " ) <nl> + ) <nl> + ) , <nl> + configfactory . build ( ec2autoscalingstrategyconfig . class ) <nl> + ) ; <nl> + } else if ( config . getstorageimpl ( ) . equalsignorecase ( " noop " ) ) { <nl> + strategy = new noopscalingstrategy ( ) ; <nl> + } else { <nl> + throw new illegalstateexception ( <nl> + string . format ( <nl> + " invalid strategy implementation : % s " , <nl> + config . getstrategyimpl ( ) <nl> + ) <nl> + ) ; <nl> + } <nl>  <nl> return new remotetaskrunner ( <nl> jsonmapper ,
jnigen { <nl> add ( macosx , x64 ) <nl> add ( android ) { <nl> cppflags + = " - fexceptions " <nl> - <nl> + androidapplicationmk + = " app_stl : = stlport_static " ; <nl> } <nl> add ( ios ) { <nl> cppflags + = " - stdlib = libc + + " ;
public class androidgraphics implements graphics , renderer { <nl> if ( ! running ) return ; <nl> running = false ; <nl> pause = true ; <nl> + <nl> + view . queueevent ( new runnable ( ) { <nl> + @ override <nl> + public void run ( ) { <nl> + if ( ! pause ) { <nl> + / / pause event already picked up by ondrawframe <nl> + return ; <nl> + } <nl> + <nl> + / / it ' s ok to call applicationlistener ' s events <nl> + / / from ondrawframe because it ' s executing in gl thread <nl> + ondrawframe ( null ) ; <nl> + } <nl> + } ) ; <nl> + <nl> while ( pause ) { <nl> try { <nl> - <nl> - / / temporary workaround : <nl> / / android anr time is num seconds , so wait up to num seconds before assuming <nl> - / / deadlock and killing process . this can easily be triggered by opening the <nl> - / / recent apps list and then double - tapping the recent apps button with <nl> - / / ~ 500ms between taps . <nl> + / / deadlock and killing process . <nl> synch . wait ( 4000 ) ; <nl> if ( pause ) { <nl> / / pause will never go false if ondrawframe is never called by the glthread
public class remoteinput implements runnable , input { <nl>  <nl> @ override <nl> public int getdeltax ( ) { <nl> - <nl> - return num ; <nl> + return deltax [ 0 ] ; <nl> } <nl>  <nl> @ override <nl> public int getdeltax ( int pointer ) { <nl> - return num ; <nl> + return deltax [ pointer ] ; <nl> } <nl>  <nl> @ override <nl> public int getdeltay ( ) { <nl> - return num ; <nl> + return deltay [ 0 ] ; <nl> } <nl>  <nl> @ override <nl> public int getdeltay ( int pointer ) { <nl> - return num ; <nl> + return deltay [ pointer ] ; <nl> } <nl>  <nl> @ override
public class lwjglawtinput implements input , mousemotionlistener , mouselistener , <nl>  <nl> @ override <nl> public void getrotationmatrix ( float [ ] matrix ) { <nl> - <nl> - <nl> } <nl>  <nl> @ override <nl>
public class bitmapfont implements disposable { <nl> protected void load ( bitmapfontdata data ) { <nl> for ( glyph [ ] page : data . glyphs ) { <nl> if ( page = = null ) continue ; <nl> - for ( glyph glyph : page ) { <nl> - if ( glyph = = null ) continue ; <nl> - <nl> - textureregion region = regions . get ( glyph . page ) ; <nl> - if ( region = = null ) { <nl> - <nl> - throw new illegalargumentexception ( " bitmapfont texture region array cannot contain null elements . " ) ; <nl> - } <nl> - <nl> - data . setglyphregion ( glyph , region ) ; <nl> - } <nl> + for ( glyph glyph : page ) <nl> + if ( glyph ! = null ) data . setglyphregion ( glyph , regions . get ( glyph . page ) ) ; <nl> } <nl> + if ( data . missingglyph ! = null ) data . setglyphregion ( data . missingglyph , regions . get ( data . missingglyph . page ) ) ; <nl> } <nl>  <nl> / * * draws text at the specified position . <nl>
public final class androidgraphics implements graphics , renderer { <nl>  <nl> @ override <nl> public gl30 getgl30 ( ) { <nl> - <nl> return gl30 ; <nl> } <nl> } <nl> mmm a / backends / gdx - backend - lwjgl / src / com / badlogic / gdx / backends / lwjgl / lwjglgraphics . java <nl> ppp b / backends / gdx - backend - lwjgl / src / com / badlogic / gdx / backends / lwjgl / lwjglgraphics . java <nl>
public class mathutils { <nl> static public final float degreestoradians = pi / num ; <nl> static public final float degrad = degreestoradians ; <nl>  <nl> - <nl> - / / they are constants in practice , so they should be written in all caps <nl> - <nl> - <nl> - / / public static final float radians = ( float ) ( math . pi / num ) ; <nl> - <nl> - <nl> - / / public static final float degrees = ( float ) ( 180 / math . pi ) ; <nl> - <nl> static private class sin { <nl> static final float [ ] table = new float [ sin_count ] ; <nl> static {
public final class earclippingtriangulator { <nl> collections . reverse ( vertices ) ; <nl> } <nl>  <nl> + vertextypes = new int [ vertexcount ] ; <nl> + concavevertexcount = num ; <nl> + for ( int i = num ; i < vertexcount ; + + i ) { <nl> + classifyvertex ( i ) ; <nl> + } <nl> + <nl> / * <nl> * espitz : for the sake of performance , we only need to test for eartips while the polygon has more than three verts . if <nl> * there are only three verts left to test , or there were only three verts to begin with , there is no need to continue with <nl> * this loop . <nl> * / <nl> while ( vertexcount > num ) { <nl> - <nl> - / / ear change ! - - > improve <nl> - vertextypes = classifyvertices ( ) ; <nl> - <nl> int eartipindex = findeartip ( ) ; <nl> cuteartip ( eartipindex ) ; <nl> + <nl> + / / only the type of the two vertices adjacent to the clipped vertex can have changed , <nl> + / / so no need to reclassify all of them . <nl> + classifyvertex ( computepreviousindex ( eartipindex ) ) ; <nl> + classifyvertex ( eartipindex ) ; <nl> } <nl>  <nl> / * <nl>
public final class earclippingtriangulator { <nl> final int [ ] vertextypes = new int [ vertexcount ] ; <nl> this . concavevertexcount = num ; <nl>  <nl> - / * ensure vertices are in clockwise order . * / <nl> - <nl> - if ( ! areverticesclockwise ( pvertices ) ) { <nl> - collections . reverse ( pvertices ) ; <nl> - } <nl> - <nl> for ( int <nl> final int previousindex = computepreviousindex ( pvertices , index ) ; <nl> final int nextindex = computenextindex ( pvertices , index ) ;
public final class earclippingtriangulator { <nl> / / the vertex is strictly inside the triangle if all three signs are the same . <nl> / / if it ' s on one or more edges , one or more of the signs will be num . <nl> / / so it ' s inside or on the edge if no two signs are opposite . <nl> - <nl> - if ( ! ( ( areasign1 > num | | areasign2 > num | | areasign3 > num ) & & ( areasign1 < num | | areasign2 < num | | areasign3 < num ) ) ) { <nl> + if ( areasign1 > = num & & areasign2 > = num & & areasign3 > = num ) { <nl> return false ; <nl> } <nl> }
public final class earclippingtriangulator { <nl> } <nl>  <nl> private boolean iseartip ( final arraylist < vector2 > pvertices , final int peartipindex , final int [ ] pvertextypes ) { <nl> - <nl> - if ( this . concavevertexcount ! = num ) { <nl> - final vector2 p1 = pvertices . get ( computepreviousindex ( pvertices , peartipindex ) ) ; <nl> - final vector2 p2 = pvertices . get ( peartipindex ) ; <nl> - final vector2 p3 = pvertices . get ( computenextindex ( pvertices , peartipindex ) ) ; <nl> - <nl> - final int vertexcount = pvertices . size ( ) ; <nl> - for ( int i = num ; i < vertexcount ; i + + ) { <nl> - if ( ( pvertextypes [ i ] = = concave ) ) { <nl> - final vector2 v = pvertices . get ( i ) ; <nl> - <nl> - final int areasign1 = computespannedareasign ( p1 , p2 , v ) ; <nl> - final int areasign2 = computespannedareasign ( p2 , p3 , v ) ; <nl> - final int areasign3 = computespannedareasign ( p3 , p1 , v ) ; <nl> - <nl> - if ( areasign1 > num & & areasign2 > num & & areasign3 > num ) { <nl> - return false ; <nl> - } else if ( areasign1 < = num & & areasign2 < = num & & areasign3 < = num ) { <nl> - return false ; <nl> - } <nl> + if ( pvertextypes [ peartipindex ] ! = convex_or_tangential ) { <nl> + return false ; <nl> + } <nl> + if ( this . concavevertexcount = = num ) { <nl> + return true ; <nl> + } <nl> + final int previousindex = computepreviousindex ( pvertices , peartipindex ) ; <nl> + final int nextindex = computenextindex ( pvertices , peartipindex ) ; <nl> + final vector2 p1 = pvertices . get ( previousindex ) ; <nl> + final vector2 p2 = pvertices . get ( peartipindex ) ; <nl> + final vector2 p3 = pvertices . get ( nextindex ) ; <nl> + <nl> + final int vertexcount = pvertices . size ( ) ; <nl> + / / check if any point is inside the triangle formed by previous , current and next vertices . <nl> + / / only consider vertices that are not part of this triangle , or else we ' ll always find one inside . <nl> + for ( int i = computenextindex ( pvertices , nextindex ) ; i ! = previousindex ; i = computenextindex ( pvertices , i ) ) { <nl> + if ( ( pvertextypes [ i ] = = concave ) ) { <nl> + final vector2 v = pvertices . get ( i ) ; <nl> + <nl> + final int areasign1 = computespannedareasign ( p1 , p2 , v ) ; <nl> + final int areasign2 = computespannedareasign ( p2 , p3 , v ) ; <nl> + final int areasign3 = computespannedareasign ( p3 , p1 , v ) ; <nl> + <nl> + / / the vertex is strictly inside the triangle if all three signs are the same . <nl> + / / if it ' s on one or more edges , one or more of the signs will be num . <nl> + / / so it ' s inside or on the edge if no two signs are opposite . <nl> + if ( ! ( ( areasign1 > num | | areasign2 > num | | areasign3 > num ) & & ( areasign1 < num | | areasign2 < num | | areasign3 < num ) ) ) { <nl> + return false ; <nl> } <nl> - i + + ; <nl> } <nl> } <nl> return true ;
enable_pooled_typemap ( bttransform , matrix4 , " lcom / badlogic / gdx / math / matrix4 ; " ) ; <nl> % } <nl> % include " bulletdynamics / constraintsolver / bthinge2constraint . h " <nl>  <nl> - / * disabled stuff below here ( <nl> - <nl> - / * <nl> - * btserializer needs some typemap customization for sbulletdnastr and friends . <nl> - * swig doesn ' t know how to pass the unsized arrays back . <nl> - * / <nl> - / * <nl> - % { <nl> - # include < linearmath / btserializer . h > <nl> - % } <nl> - % include " linearmath / btserializer . h " <nl> - * / <nl> - <nl> - / * <nl> - * btwheelinfo doesn ' t compile because it doesnt have a num - arg constructor for <nl> - * btalignedobjectarray to call , so i disabled the vehicle stuff . <nl> - * / <nl> - <nl> - % { <nl> - # include < bulletdynamics / vehicle / btvehicleraycaster . h > <nl> - % } <nl> - % include " bulletdynamics / vehicle / btvehicleraycaster . h " <nl> - <nl> - % { <nl> - # include < bulletdynamics / vehicle / btwheelinfo . h > <nl> - % } <nl> - % include " bulletdynamics / vehicle / btwheelinfo . h " <nl> - <nl> - / * has nested classes or structs * / <nl> - % include " custom / btraycastvehicle . i " <nl> - <nl> - <nl> - / * <nl> - * because c + + templates are compile - time , we must pre - define all the <nl> - * template classes to generate in java . this is at the bottom <nl> - * so we can reference all the other types . <nl> - * / <nl> - <nl> - % template ( btcollisionobjectarray ) btalignedobjectarray < btcollisionobject * > ; <nl> - <nl> - / * <nl> - * include dummy methods for ones bullet declares but doesn ' t <nl> - * implement . at the bottom so we can reference other types . <nl> - * / <nl> - % include " gdxmissingbulletmethods . i " <nl> - <nl> - / * softbody code ( not suitable for android ) <nl> % { <nl> # include < bulletsoftbody / btsoftbodysolvers . h > <nl> % } <nl>
swig_javabody_typewrapper ( protected , protected , public , swigtype ) <nl> # include < bulletsoftbody / btsoftsoftcollisionalgorithm . h > <nl> % } <nl> % include " bulletsoftbody / btsoftsoftcollisionalgorithm . h " <nl> - * / <nl> - <nl> - / * disabled stuff below here ( <nl> - <nl> - / * <nl> - * btserializer needs some typemap customization for sbulletdnastr and friends . <nl> - * swig doesn ' t know how to pass the unsized arrays back . <nl> - * / <nl> - / * <nl> - % { <nl> - # include < linearmath / btserializer . h > <nl> - % } <nl> - % include " linearmath / btserializer . h " <nl> - * / <nl> - <nl> - / * <nl> - * btwheelinfo doesn ' t compile because it doesnt have a num - arg constructor for <nl> - * btalignedobjectarray to call , so i disabled the vehicle stuff . <nl> - * / <nl> - <nl> - % { <nl> - # include < bulletdynamics / vehicle / btvehicleraycaster . h > <nl> - % } <nl> - % include " bulletdynamics / vehicle / btvehicleraycaster . h " <nl> - <nl> - % { <nl> - # include < bulletdynamics / vehicle / btwheelinfo . h > <nl> - % } <nl> - % include " bulletdynamics / vehicle / btwheelinfo . h " <nl> - <nl> - / * has nested classes or structs * / <nl> - % include " custom / btraycastvehicle . i " <nl> - <nl> - <nl> - / * <nl> - * because c + + templates are compile - time , we must pre - define all the <nl> - * template classes to generate in java . this is at the bottom <nl> - * so we can reference all the other types . <nl> - * / <nl> - <nl> - % template ( btcollisionobjectarray ) btalignedobjectarray < btcollisionobject * > ; <nl> - <nl> - / * <nl> - * include dummy methods for ones bullet declares but doesn ' t <nl> - * implement . at the bottom so we can reference other types . <nl> - * / <nl> - % include " gdxmissingbulletmethods . i " <nl> \ no newline at end of file <nl> + * / <nl> \ no newline at end of file
<nl> - dev <nl> + # # # library integration <nl>  <nl> - - build on windows , mac os ( update swigbulletbuild ) <nl> - - bttransform makes a lot of garbage , reuse one for the returns ? <nl> - - remove automatic static library load chunk in every class ? <nl> + - build on all platforms ( update swigbulletbuild ) <nl> - complete gdxvoidpointer . i and enable it in gdxbullet . i <nl>  <nl> - features not yet finished : <nl> + # # # features not yet finished : <nl>  <nl> - generate soft body , gimpact types <nl>  <nl>
public class stillmodel implements model { <nl>  <nl> @ override <nl> public void render ( shaderprogram program ) { <nl> - <nl> - <nl> + int len = submeshes . length ; <nl> + for ( int i = num ; i < len ; i + + ) { <nl> + stillsubmesh submesh = submeshes [ i ] ; <nl> + if ( i = = num ) { <nl> + submesh . material . bind ( program ) ; <nl> + } else if ( ! submeshes [ i - num ] . material . equals ( submesh . material ) ) { <nl> + submesh . material . bind ( program ) ; <nl> + } <nl> + submesh . mesh . render ( program , submesh . primitivetype ) ; <nl> + } <nl> } <nl>  <nl> @ override
public class matrix3 implements serializable { <nl> float det = det ( ) ; <nl> if ( det = = num ) throw new gdxruntimeexception ( " can ' t invert a singular matrix " ) ; <nl>  <nl> - <nl> - throw new gdxruntimeexception ( " not implemented yet " ) ; <nl> + float inv_det = num . 0f / det ; <nl> + float tmp [ ] = { 0 , num , num , num , num , num , num , num , num } ; <nl> + <nl> + tmp [ 0 ] = vals [ 4 ] * vals [ 8 ] - vals [ 5 ] * vals [ 7 ] ; <nl> + tmp [ 1 ] = vals [ 2 ] * vals [ 7 ] - vals [ 1 ] * vals [ 8 ] ; <nl> + tmp [ 2 ] = vals [ 1 ] * vals [ 5 ] - vals [ 2 ] * vals [ 4 ] ; <nl> + tmp [ 3 ] = vals [ 5 ] * vals [ 6 ] - vals [ 3 ] * vals [ 8 ] ; <nl> + tmp [ 4 ] = vals [ 0 ] * vals [ 8 ] - vals [ 2 ] * vals [ 6 ] ; <nl> + tmp [ 5 ] = vals [ 2 ] * vals [ 3 ] - vals [ 0 ] * vals [ 5 ] ; <nl> + tmp [ 6 ] = vals [ 3 ] * vals [ 7 ] - vals [ 4 ] * vals [ 6 ] ; <nl> + tmp [ 7 ] = vals [ 1 ] * vals [ 6 ] - vals [ 0 ] * vals [ 7 ] ; <nl> + tmp [ 8 ] = vals [ 0 ] * vals [ 4 ] - vals [ 1 ] * vals [ 3 ] ; <nl> + <nl> + vals [ 0 ] = inv_det * tmp [ 0 ] ; <nl> + vals [ 1 ] = inv_det * tmp [ 1 ] ; <nl> + vals [ 2 ] = inv_det * tmp [ 2 ] ; <nl> + vals [ 3 ] = inv_det * tmp [ 3 ] ; <nl> + vals [ 4 ] = inv_det * tmp [ 4 ] ; <nl> + vals [ 5 ] = inv_det * tmp [ 5 ] ; <nl> + vals [ 6 ] = inv_det * tmp [ 6 ] ; <nl> + vals [ 7 ] = inv_det * tmp [ 7 ] ; <nl> + vals [ 8 ] = inv_det * tmp [ 8 ] ; <nl> + <nl> + return this ; <nl> } <nl>  <nl> / / public static void main ( string [ ] argv ) {
public class lifecycletest extends gdxtest { <nl> try { <nl> thread . sleep ( 100 ) ; <nl> } catch ( interruptedexception e ) { <nl> - <nl> e . printstacktrace ( ) ; <nl> - } <nl> - <nl> + } <nl> } <nl>  <nl> @ override public void create ( ) { <nl> mmm a / tests / gdx - tests / src / com / badlogic / gdx / tests / multitouchtest . java <nl> ppp b / tests / gdx - tests / src / com / badlogic / gdx / tests / multitouchtest . java <nl>
final class lwjglpixmap implements pixmap { <nl> } <nl>  <nl> public void dispose ( ) { <nl> - <nl>  <nl> } <nl>  <nl> mmm a / backends / gdx - backend - lwjgl / src / com / badlogic / gdx / backends / desktop / lwjgltexture . java <nl> ppp b / backends / gdx - backend - lwjgl / src / com / badlogic / gdx / backends / desktop / lwjgltexture . java <nl>
final class appletaudio implements audio , runnable <nl> * / <nl> @ override <nl> public audiorecorder newaudiorecoder ( int samplingrate , boolean ismono ) { <nl> - <nl> - return null ; <nl> + return new appletaudiorecorder ( samplingrate , ismono ) ; <nl> } <nl> } <nl> mmm / dev / null <nl> ppp b / gdx - backend - applet / src / com / badlogic / gdx / backends / applet / appletaudiorecorder . java <nl>
public enum networkinterfacemanager { <nl> weight + = num ; <nl> } <nl>  <nl> + / * * <nl> + * the following logic is removed as we will sort the network interfaces according to the <nl> + * the priorities between network interfaces , see https : / / github . com / ctripcorp / apollo / pull / 1986 <nl> + * / <nl> / / has host name <nl> - <nl> + / * <nl> if ( ! objects . equals ( address . gethostname ( ) , address . gethostaddress ( ) ) ) { <nl> weight + = num ; <nl> } <nl> + * / <nl>  <nl> if ( weight > maxweight ) { <nl> maxweight = weight ;
public class configutil { <nl> } <nl>  <nl> public string getdefaultlocalcachedir ( ) { <nl> - <nl> - return string . format ( " / opt / data / % s " , getappid ( ) ) ; <nl> + string cacheroot = isoswindows ( ) ? " c : \ \ opt \ \ data \ \ % s " : " / opt / data / % s " ; <nl> + return string . format ( cacheroot , getappid ( ) ) ; <nl> } <nl>  <nl> public boolean isinlocalmode ( ) { <nl>
public class configservicelocator implements initializable { <nl> m_configutil . getrefreshtimeunit ( ) ) ; <nl> } <nl>  <nl> - <nl> private synchronized void updateconfigservices ( ) { <nl> string domainname = m_configutil . getmetaserverdomainname ( ) ; <nl> string url = domainname + " / services / config " ; <nl> mmm a / apollo - client / src / main / java / com / ctrip / apollo / internals / remoteconfigrepository . java <nl> ppp b / apollo - client / src / main / java / com / ctrip / apollo / internals / remoteconfigrepository . java <nl>
public class contextchain implements parcelable { <nl>  <nl> private @ nullable string mserializedstring ; <nl>  <nl> - @ deprecated <nl> - public static void setusedeepequals ( boolean usedeepequals ) { <nl> - <nl> - } <nl> - <nl> public contextchain ( <nl> final string tag , <nl> final string name ,
class imagerenderer { <nl> imagetransformation : matrix ? = null <nl> ) : rendercommand { <nl> / / the image transformation is a no - op for solid colors since it is a no - op <nl> - <nl> - val paint = paint . apply { color = colorint } <nl> + val paint = paint . apply { color = colorutils . multiplycoloralpha ( colorint , paint . alpha ) } <nl> return { shape . draw ( it , paint ) } <nl> } <nl>  <nl> mmm / dev / null <nl> ppp b / vito / renderer / src / main / java / com / facebook / fresco / vito / renderer / util / colorutils . kt <nl>
class imagerenderer { <nl> painttoreuse : paint ? = null , <nl> colorfilter : colorfilter ? = null , <nl> ) : rendercommand { <nl> - <nl> / / we transform by scaling the canvas , so we let the drawable draw itself with its <nl> / / preferred dimensions <nl> when ( shape ) { <nl> is rectshape - > return { <nl> if ( width > = num & & height > = num ) { <nl> drawable . setbounds ( 0 , num , width , height ) <nl> + it . concat ( imagetransformation ) <nl> } else { <nl> + / / the image dimensions are not set , so we assume the image can stretch to fit the <nl> + / / entire rect , so we do not apply the transformation . <nl> drawable . setbounds ( <nl> shape . rect . left . toint ( ) , <nl> shape . rect . top . toint ( ) , <nl>
class imagerenderer { <nl> drawable . colorfilter = colorfilter <nl> drawable . draw ( it ) <nl> } <nl> - <nl> - <nl> else - > { <nl> return { <nl> drawable . setbounds ( 0 , num , width , height ) <nl> drawable . colorfilter = null / / the paint handles the color filter <nl> val bitmap = bitmap . createbitmap ( width , height , bitmap . config . argb_8888 ) <nl> drawable . draw ( canvas ( bitmap ) ) <nl> - shape . draw ( it , getbitmappaint ( bitmap , null , painttoreuse , colorfilter ) ) <nl> + shape . draw ( it , getbitmappaint ( bitmap , imagetransformation , painttoreuse , colorfilter ) ) <nl> } <nl> } <nl> }
class kfrescovitodrawable : drawable ( ) , frescodrawableinterface { <nl> override fun getimagelistener ( ) : imagelistener ? = _imagelistener <nl>  <nl> override fun setoverlaydrawable ( drawable : drawable ? ) : drawable ? { <nl> - <nl> - return null <nl> + overlayimagelayer . apply { <nl> + configure ( <nl> + datamodel = if ( drawable = = null ) null else drawableimagedatamodel ( drawable ) , <nl> + roundingoptions = null , <nl> + borderoptions = null ) <nl> + } <nl> + return drawable <nl> } <nl>  <nl> override fun getextras ( ) : any ? = _extras
public class frescocontrollerimpl implements frescocontroller { <nl> imagerequest . requestlevel . getmax ( <nl> imagerequest . getlowestpermittedrequestlevel ( ) , imagerequest . requestlevel . full_fetch ) ; <nl>  <nl> - <nl> - requestlistener requestlistener = <nl> - mfrescocontext <nl> - . getimagepipeline ( ) <nl> - . getrequestlistenerforrequest ( imagerequest , frescostate . getimageoriginlistener ( ) ) ; <nl> - frescostate . setrequestlistener ( requestlistener ) ; <nl> - <nl> + setuprequestlistener ( frescostate , imagerequest ) ; <nl> frescostate . setsettableproducercontext ( <nl> new settableproducercontext ( <nl> imagerequest , <nl> mfrescocontext . getimagepipeline ( ) . generateuniquefutureid ( ) , <nl> - requestlistener , <nl> + frescostate . getrequestlistener ( ) , <nl> callercontext , <nl> lowestpermittedrequestlevel , <nl> / * isprefetch * / false , <nl>
static void roundingfilter_tocircle ( <nl> return ; <nl> } <nl>  <nl> - <nl> + const int radius = min ( w , h ) / num ; <nl> + tocircle ( env , pixelptr , w , h , w / num , h / num , radius ) ; <nl>  <nl> rc = androidbitmap_unlockpixels ( env , bitmap ) ; <nl> if ( rc ! = android_bitmap_result_success ) {
public class diskstoragecache implements filecache , disktrimmable { <nl> mcachesizelastupdatetime = now ; <nl> return true ; <nl> } <nl> - <nl> - <nl> - private static void maybedeletesharedpreferencesfile ( <nl> - context context , <nl> - string directoryname ) { <nl> - try { <nl> - context applicationcontext = context . getapplicationcontext ( ) ; <nl> - string path = <nl> - applicationcontext . getfilesdir ( ) . getparent ( ) <nl> - + file . separator <nl> - + " shared_prefs " <nl> - + file . separator <nl> - + shared_prefs_filename_prefix <nl> - + directoryname ; <nl> - file file = new file ( path + " . xml " ) ; <nl> - if ( file . exists ( ) ) { <nl> - file . delete ( ) ; <nl> - } <nl> - } catch ( exception e ) { <nl> - flog . e ( tag , " fail to delete sharedpreference from file system . " ) ; <nl> - } <nl> - } <nl> }
public class honeycombbitmapcreator implements bitmapcreator { <nl> } <nl> return options ; <nl> } <nl> - <nl> - private static void puteoi ( byte [ ] imagebytes , int offset ) { <nl> - <nl> - imagebytes [ offset ] = ( byte ) jfifutil . marker_first_byte ; <nl> - imagebytes [ offset + num ] = ( byte ) jfifutil . marker_eoi ; <nl> - } <nl> - <nl> - protected static boolean endswitheoi ( closeablereference < pooledbytebuffer > bytesref , int length ) { <nl> - pooledbytebuffer buffer = bytesref . get ( ) ; <nl> - return length > = num & & <nl> - buffer . read ( length - num ) = = ( byte ) jfifutil . marker_first_byte & & <nl> - buffer . read ( length - num ) = = ( byte ) jfifutil . marker_eoi ; <nl> - } <nl> }
public class draweeholder < dh extends draweehierarchy > implements visibilitycallb <nl> private boolean miscontrollerattached = false ; <nl> private boolean misholderattached = false ; <nl> private boolean misvisible = true ; <nl> - private boolean misactivitystarted = true ; <nl> private dh mhierarchy ; <nl> - <nl> - / / private final activitylistener mactivitylistener ; <nl>  <nl> private draweecontroller mcontroller = null ; <nl>  <nl>
public class draweeholder < dh extends draweehierarchy > implements visibilitycallb <nl> return holder ; <nl> } <nl>  <nl> - / * * <nl> - * if the given context is an instance of fblistenableactivity , then listener for its onstop and <nl> - * onstart methods is registered that changes visibility of the holder . <nl> - * / <nl> + / * * for future use . * / <nl> public void registerwithcontext ( context context ) { <nl> - <nl> - / / activitylistenermanager . register ( mactivitylistener , context ) ; <nl> } <nl>  <nl> / * * <nl>
public class draweeholder < dh extends draweehierarchy > implements visibilitycallb <nl> if ( hierarchy ! = null ) { <nl> sethierarchy ( hierarchy ) ; <nl> } <nl> - / * <nl> - <nl> - mactivitylistener = new baseactivitylistener ( ) { <nl> - @ override <nl> - public void onstart ( activity activity ) { <nl> - setactivitystarted ( true ) ; <nl> - } <nl> - <nl> - @ override <nl> - public void onstop ( activity activity ) { <nl> - setactivitystarted ( false ) ; <nl> - } <nl> - } ; <nl> - * / <nl> } <nl>  <nl> / * * <nl>
import static org . powermock . api . mockito . powermockito . * ; <nl> * / <nl> @ runwith ( robolectrictestrunner . class ) <nl> @ powermockignore ( { " org . mockito . * " , " org . robolectric . * " , " android . * " } ) <nl> - @ preparefortest ( { thumbnailutils . class } ) <nl> + @ preparefortest ( android . media . thumbnailutils . class ) <nl> @ config ( manifest = config . none ) <nl> - <nl> + @ ignore <nl> public class localvideothumbnailproducertest { <nl> private static final string producer_name = localvideothumbnailproducer . producer_name ; <nl> private static final string test_filename = " dummy . jpg " ; <nl>
public class imagepipelinefactory { <nl> mconfig = preconditions . checknotnull ( config ) ; <nl> } <nl>  <nl> - <nl> - / / we need them public for now so internal code can use them . <nl> + / / we need some of these methods public for now so internal code can use them . <nl>  <nl> public countingmemorycache < cachekey , closeableimage > <nl> getbitmapcountingmemorycache ( ) { <nl>
public abstract class abstractproducertodatasourceadapter < t > extends abstractdat <nl> abstractproducertodatasourceadapter . this . oncancellationimpl ( ) ; <nl> } <nl>  <nl> - <nl> - protected void onprogressupdate ( float progress ) { <nl> + @ override <nl> + protected void onprogressupdateimpl ( float progress ) { <nl> abstractproducertodatasourceadapter . this . setprogress ( progress ) ; <nl> } <nl> } ; <nl> mmm a / imagepipeline / src / main / java / com / facebook / imagepipeline / producers / baseconsumer . java <nl> ppp b / imagepipeline / src / main / java / com / facebook / imagepipeline / producers / baseconsumer . java <nl>
import org . thingsboard . server . common . data . id . tenantid ; <nl> import org . thingsboard . server . common . data . id . userid ; <nl>  <nl> public class entitiestenantidasyncloader { <nl> - <nl> + / * * <nl> + * @ deprecated consider to remove since tenantid is already defined in the tbcontext . <nl> + * / <nl> + @ deprecated <nl> public static listenablefuture < tenantid > findentityidasync ( tbcontext ctx , entityid original ) { <nl>  <nl> switch ( original . getentitytype ( ) ) {
public class deviceprofilemsgconstructor { <nl> . setdefault ( deviceprofile . isdefault ( ) ) <nl> . settype ( deviceprofile . gettype ( ) . name ( ) ) <nl> . setprofiledatabytes ( bytestring . copyfrom ( datadecodingencodingservice . encode ( deviceprofile . getprofiledata ( ) ) ) ) ; <nl> - <nl> - / / if ( deviceprofile . getdefaultrulechainid ( ) ! = null ) { <nl> - / / builder . setdefaultrulechainidmsb ( deviceprofile . getdefaultrulechainid ( ) . getid ( ) . getmostsignificantbits ( ) ) <nl> - / / . setdefaultrulechainidlsb ( deviceprofile . getdefaultrulechainid ( ) . getid ( ) . getleastsignificantbits ( ) ) ; <nl> - / / } <nl> if ( deviceprofile . getdefaultqueuename ( ) ! = null ) { <nl> builder . setdefaultqueuename ( deviceprofile . getdefaultqueuename ( ) ) ; <nl> } <nl> mmm a / application / src / main / java / org / thingsboard / server / service / edge / rpc / fetch / adminsettingsedgeeventfetcher . java <nl> ppp b / application / src / main / java / org / thingsboard / server / service / edge / rpc / fetch / adminsettingsedgeeventfetcher . java <nl>
abstract public class basedeviceedgetest extends abstractedgetest { <nl> / / create device and assign to edge ; update device <nl> device saveddevice = savedeviceoncloudandverifydeliverytoedge ( ) ; <nl>  <nl> - <nl> - / / edgeimitator . expectmessageamount ( 1 ) ; <nl> - / / assert . asserttrue ( edgeimitator . waitformessages ( ) ) ; <nl> - / / abstractmessage latestmessage = edgeimitator . getlatestmessage ( ) ; <nl> - / / assert . asserttrue ( latestmessage instanceof devicecredentialsupdatemsg ) ; <nl> - / / devicecredentialsupdatemsg devicecredentialsupdatemsg = ( devicecredentialsupdatemsg ) latestmessage ; <nl> + / / update device credentials - access_token <nl> + edgeimitator . expectmessageamount ( 1 ) ; <nl> + devicecredentials devicecredentials = <nl> + doget ( " / api / device / " + saveddevice . getid ( ) . getid ( ) + " / credentials " , devicecredentials . class ) ; <nl> + assert . assertequals ( saveddevice . getid ( ) , devicecredentials . getdeviceid ( ) ) ; <nl> + devicecredentials . setcredentialstype ( devicecredentialstype . access_token ) ; <nl> + devicecredentials . setcredentialsid ( " access_token " ) ; <nl> + dopost ( " / api / device / credentials " , devicecredentials ) <nl> + . andexpect ( status ( ) . isok ( ) ) ; <nl> + assert . asserttrue ( edgeimitator . waitformessages ( ) ) ; <nl> + abstractmessage latestmessage = edgeimitator . getlatestmessage ( ) ; <nl> + assert . asserttrue ( latestmessage instanceof devicecredentialsupdatemsg ) ; <nl> + devicecredentialsupdatemsg devicecredentialsupdatemsg = ( devicecredentialsupdatemsg ) latestmessage ; <nl> + assert . assertequals ( devicecredentials . getcredentialstype ( ) . name ( ) , devicecredentialsupdatemsg . getcredentialstype ( ) ) ; <nl> + assert . assertequals ( devicecredentials . getcredentialsid ( ) , devicecredentialsupdatemsg . getcredentialsid ( ) ) ; <nl> + assert . assertfalse ( devicecredentialsupdatemsg . hascredentialsvalue ( ) ) ; <nl> + <nl> + / / update device credentials - x509_certificate <nl> + edgeimitator . expectmessageamount ( 1 ) ; <nl> + devicecredentials . setcredentialstype ( devicecredentialstype . x509_certificate ) ; <nl> + devicecredentials . setcredentialsid ( null ) ; <nl> + devicecredentials . setcredentialsvalue ( " - - - - - begin rsa private key - - - - - " ) ; <nl> + dopost ( " / api / device / credentials " , devicecredentials ) <nl> + . andexpect ( status ( ) . isok ( ) ) ; <nl> + assert . asserttrue ( edgeimitator . waitformessages ( ) ) ; <nl> + latestmessage = edgeimitator . getlatestmessage ( ) ; <nl> + assert . asserttrue ( latestmessage instanceof devicecredentialsupdatemsg ) ; <nl> + devicecredentialsupdatemsg = ( devicecredentialsupdatemsg ) latestmessage ; <nl> + assert . assertequals ( devicecredentials . getcredentialstype ( ) . name ( ) , devicecredentialsupdatemsg . getcredentialstype ( ) ) ; <nl> + assert . assertfalse ( devicecredentialsupdatemsg . getcredentialsid ( ) . isempty ( ) ) ; <nl> + assert . asserttrue ( devicecredentialsupdatemsg . hascredentialsvalue ( ) ) ; <nl> + assert . assertequals ( devicecredentials . getcredentialsvalue ( ) , devicecredentialsupdatemsg . getcredentialsvalue ( ) ) ; <nl> } <nl>  <nl> @ test
public abstract class baseassetcontrollertest extends abstractcontrollertest { <nl>  <nl> mockito . reset ( tbclusterservice , auditlogservice ) ; <nl>  <nl> - dopost ( " / api / asset " , savedasset , asset . class , status ( ) . isforbidden ( ) ) ; <nl> + dopost ( " / api / asset " , savedasset ) <nl> + . andexpect ( status ( ) . isforbidden ( ) ) <nl> + . andexpect ( statusreason ( containsstring ( msgerrorpermission ) ) ) ; <nl>  <nl> testnotifyentitynever ( savedasset . getid ( ) , savedasset ) ; <nl>  <nl> - <nl> - dodelete ( " / api / asset " + savedasset . getid ( ) . getid ( ) . tostring ( ) ) <nl> - . andexpect ( status ( ) . isnotfound ( ) ) ; <nl> + dodelete ( " / api / asset / " + savedasset . getid ( ) . getid ( ) . tostring ( ) ) <nl> + . andexpect ( status ( ) . isforbidden ( ) ) <nl> + . andexpect ( statusreason ( containsstring ( msgerrorpermission ) ) ) ; <nl>  <nl> testnotifyentitynever ( savedasset . getid ( ) , savedasset ) ;
public abstract class redistbtransactionalcache < k extends serializable , v extend <nl> } <nl>  <nl> private redisconnection watch ( byte [ ] [ ] rawkeyslist ) { <nl> - <nl> redisconnection connection = getconnection ( rawkeyslist [ 0 ] ) ; <nl> try { <nl> connection . watch ( rawkeyslist ) ; <nl> mmm a / common / cache / src / main / java / org / thingsboard / server / cache / tbtransactionalcache . java <nl> ppp b / common / cache / src / main / java / org / thingsboard / server / cache / tbtransactionalcache . java <nl>
public class hashpartitionservice implements partitionservice { <nl> } else { <nl> queueroutinginfo queueroutinginfo = queuesbyid . get ( queueid ) ; <nl>  <nl> - <nl> if ( queueroutinginfo = = null ) { <nl> log . debug ( " queue was removed but still used in checkpoint rule node . [ { } ] [ { } ] " , tenantid , entityid ) ; <nl> queuekey = getmainqueuekey ( servicetype , tenantid ) ; <nl>
abstract public class baseedgetest extends abstractcontrollertest { <nl>  <nl> testrpccall ( ) ; <nl>  <nl> - <nl> - / / 2021 - 12 - 13 num : 59 : 52 , 493 [ main ] warn o . t . edge . rpc . edgegrpcclient - we had reached maximum of termination attempts . force closing channel <nl> - / / 2021 - 12 - 13 num : 59 : 52 , 501 [ grpc - default - executor - 1 ] warn o . t . edge . rpc . edgegrpcclient - we had reached maximum of termination attempts . force closing channel <nl> - / / java . lang . assertionerror < 3 internal lines > <nl> - / / at org . thingsboard . server . edge . baseedgetest . testtimeserieswithfailures ( baseedgetest . java : 1146 ) <nl> - / / at org . thingsboard . server . edge . baseedgetest . test ( baseedgetest . java : 220 ) <nl> - / / <nl> - / / testtimeserieswithfailures ( ) ; <nl> + testtimeserieswithfailures ( ) ; <nl>  <nl> testsendmessagestocloud ( ) ; <nl> }
public class rulechaincontroller extends basecontroller { <nl> @ apiparam ( value = " a json value representing the rule chain metadata . " ) <nl> @ requestbody rulechainmetadata rulechainmetadata , <nl> @ apiparam ( value = " update related rule nodes . " ) <nl> - <nl> @ requestparam ( value = " updaterelated " , required = false , defaultvalue = " true " ) boolean updaterelated <nl> ) throws thingsboardexception { <nl> try {
<nl> package org . thingsboard . server . common . data . device . data . lwm2m ; <nl>  <nl> import lombok . data ; <nl> + import org . thingsboard . server . common . data . device . profile . lwm2m . bootstrap . serverconfig ; <nl> import org . thingsboard . server . common . data . device . profile . lwm2m . bootstrap . servercredentials ; <nl>  <nl> - import java . util . map ; <nl> - <nl> @ data <nl> public class bootstrapconfiguration { <nl>  <nl> - <nl> - private map < string , object > servers ; <nl> + private serverconfig servers ; <nl> private servercredentials lwm2mserver ; <nl> private servercredentials bootstrapserver ;
public class defaultlwm2muplinkmsghandler extends lwm2mexecutorawareservice impl <nl> * / <nl> @ override <nl> public void ondeviceprofileupdate ( sessioninfoproto sessioninfo , deviceprofile deviceprofile ) { <nl> - list < lwm2mclient > clients = clientcontext . getlwm2mclients ( ) <nl> - . stream ( ) . filter ( e - > e . getprofileid ( ) ! = null ) <nl> - . filter ( e - > e . getprofileid ( ) . equals ( deviceprofile . getuuidid ( ) ) ) . collect ( collectors . tolist ( ) ) ; <nl> - clients . foreach ( client - > client . ondeviceprofileupdate ( deviceprofile ) ) ; <nl> - if ( clients . size ( ) > num ) { <nl> - this . ondeviceprofileupdate ( clients , deviceprofile ) ; <nl> + try { <nl> + list < lwm2mclient > clients = clientcontext . getlwm2mclients ( ) <nl> + . stream ( ) . filter ( e - > e . getprofileid ( ) ! = null ) <nl> + . filter ( e - > e . getprofileid ( ) . equals ( deviceprofile . getuuidid ( ) ) ) . collect ( collectors . tolist ( ) ) ; <nl> + clients . foreach ( client - > client . ondeviceprofileupdate ( deviceprofile ) ) ; <nl> + if ( clients . size ( ) > num ) { <nl> + this . ondeviceprofileupdate ( clients , deviceprofile ) ; <nl> + } <nl> + } catch ( exception e ) { <nl> + log . warn ( " [ { } ] failed to update profile : { } " , deviceprofile . getid ( ) , deviceprofile ) ; <nl> } <nl> } <nl>  <nl> @ override <nl> public void ondeviceupdate ( sessioninfoproto sessioninfo , device device , optional < deviceprofile > deviceprofileopt ) { <nl> - <nl> - lwm2mclient client = clientcontext . getclientbydeviceid ( device . getuuidid ( ) ) ; <nl> - if ( client ! = null ) { <nl> - this . ondeviceupdate ( client , device , deviceprofileopt ) ; <nl> + try { <nl> + lwm2mclient client = clientcontext . getclientbydeviceid ( device . getuuidid ( ) ) ; <nl> + if ( client ! = null ) { <nl> + this . ondeviceupdate ( client , device , deviceprofileopt ) ; <nl> + } <nl> + } catch ( exception e ) { <nl> + log . warn ( " [ { } ] failed to update device : { } " , device . getid ( ) , device ) ; <nl> } <nl> }
public abstract class abstractjsinvokeservice implements jsinvokeservice { <nl> disablelistinfo disablelistinfo = disabledfunctions . computeifabsent ( scriptid , key - > new disablelistinfo ( ) ) ; <nl> log . warn ( " script has exception and will increment counter { } on disabledfunctions for id { } , exception { } , cause { } , scriptbody { } " , <nl> disablelistinfo . get ( ) , scriptid , t , t . getcause ( ) , scriptbody ) ; <nl> - / / if ( t instanceof timeoutexception | | ( t . getcause ( ) ! = null & & t . getcause ( ) instanceof timeoutexception ) ) { <nl> - / / log . warn ( " script has timeoutexception and will increment counter { } on disabledfunctions for id { } " , <nl> - / / disablelistinfo . get ( ) , <nl> - / / scriptid ) ; <nl> - / / / / return ; / / timeout is not a good reason to disable function <nl> - / / } <nl> disablelistinfo . incrementandget ( ) ; <nl> }
public class defaulttbqueuerequesttemplate < request extends tbqueuemsg , response <nl>  <nl> void fetchandprocessresponses ( ) { <nl> final long pendingrequestscount = pendingrequests . mappingcount ( ) ; <nl> - log . info ( " starting template pool topic { } , for pendingrequests { } " , responsetemplate . gettopic ( ) , pendingrequestscount ) ; <nl> + log . trace ( " starting template pool topic { } , for pendingrequests { } " , responsetemplate . gettopic ( ) , pendingrequestscount ) ; <nl> list < response > responses = dopoll ( ) ; / / poll js responses <nl> - / / if ( responses . size ( ) > num ) { <nl> - log . info ( " completed template poll topic { } , for pendingrequests [ { } ] , received [ { } ] " , responsetemplate . gettopic ( ) , pendingrequestscount , responses . size ( ) ) ; <nl> - / / } <nl> + log . trace ( " completed template poll topic { } , for pendingrequests [ { } ] , received [ { } ] responses " , responsetemplate . gettopic ( ) , pendingrequestscount , responses . size ( ) ) ; <nl> responses . foreach ( this : : processresponse ) ; / / this can take a long time <nl> responsetemplate . commit ( ) ; <nl> trycleanstalerequests ( ) ;
async function disconnectproducer ( ) { <nl> producer = null ; <nl> try { <nl> logger . info ( ' stopping loop . . . ' ) ; <nl> - <nl> - clearinterval ( sendloopinstance ) ; <nl> - sendmessagesasbatch ( ) ; <nl> + cleartimeout ( sendloopinstance ) ; <nl> + await sendmessagesasbatch ( ) ; <nl> await _producer . disconnect ( ) ; <nl> logger . info ( ' kafka producer stopped . ' ) ; <nl> } catch ( e ) {
jsinvokemessageprocessor . prototype . sendresponse = function ( requestid , responset <nl> var remoteresponse = createremoteresponse ( requestid , compileresponse , invokeresponse , releaseresponse ) ; <nl> var rawresponse = buffer . from ( json . stringify ( remoteresponse ) , ' utf8 ' ) ; <nl> logger . debug ( ' [ % s ] sending response to queue , scriptid : [ % s ] ' , requestid , scriptid ) ; <nl> - this . producer . send ( responsetopic , scriptid , rawresponse , headers ) ; <nl> - <nl> - / / . then ( <nl> - / / ( ) = > { <nl> - / / logger . info ( ' [ % s ] response sent to queue , took [ % s ] ms , scriptid : [ % s ] ' , requestid , ( performance . now ( ) - tstartsending ) , scriptid ) ; <nl> - / / } , <nl> - / / ( err ) = > { <nl> - / / if ( err ) { <nl> - / / logger . error ( ' [ % s ] failed to send response to queue : % s ' , requestid , err . message ) ; <nl> - / / logger . error ( err . stack ) ; <nl> - / / } <nl> - / / } <nl> - / / ) ; <nl> + this . producer . send ( responsetopic , scriptid , rawresponse , headers ) . then ( <nl> + ( ) = > { <nl> + logger . debug ( ' [ % s ] response sent to queue , took [ % s ] ms , scriptid : [ % s ] ' , requestid , ( performance . now ( ) - tstartsending ) , scriptid ) ; <nl> + } , <nl> + ( err ) = > { <nl> + if ( err ) { <nl> + logger . error ( ' [ % s ] failed to send response to queue : % s ' , requestid , err . message ) ; <nl> + logger . error ( err . stack ) ; <nl> + } <nl> + } <nl> + ) ; <nl> } <nl>  <nl> jsinvokemessageprocessor . prototype . getorcompilescript = function ( scriptid , scriptbody ) { <nl> mmm a / msa / js - executor / queue / kafkatemplate . js <nl> ppp b / msa / js - executor / queue / kafkatemplate . js <nl>
export class importexportservice { <nl>  <nl> private editmissingaliases ( widgets : array < widget > , issinglewidget : boolean , <nl> customtitle : string , missingentityaliases : entityaliases ) : observable < entityaliases > { <nl> - <nl> let allowedentitytypes : array < entitytype | aliasentitytype > = <nl> this . entityservice . prepareallowedentitytypeslist ( null , true ) ; <nl>  <nl> mmm a / ui - ngx / src / app / modules / home / pages / dashboard / dashboard - page . component . ts <nl> ppp b / ui - ngx / src / app / modules / home / pages / dashboard / dashboard - page . component . ts <nl>
export class dashboardpagecomponent extends pagecomponent implements idashboardc <nl> this . window . parent . postmessage ( json . stringify ( message ) , ' * ' ) ; <nl> } <nl>  <nl> - <nl> this . allowedentitytypes = this . entityservice . prepareallowedentitytypeslist ( null , true ) ; <nl> }
public abstract class searchtextbasedwithadditionalinfo < i extends uuidbased > ext <nl> } <nl>  <nl> public void setadditionalinfo ( jsonnode addinfo ) { <nl> - <nl> setjson ( addinfo , json - > this . additionalinfo = json , bytes - > this . additionalinfobytes = bytes ) ; <nl> } <nl>  <nl> mmm a / ui - ngx / src / app / modules / home / pages / admin / admin - routing . module . ts <nl> ppp b / ui - ngx / src / app / modules / home / pages / admin / admin - routing . module . ts <nl>
public final class edgegrpcsession implements closeable { <nl> void onconfigurationupdate ( edge edge ) { <nl> try { <nl> this . edge = edge ; <nl> - <nl> - / / sendresponsemsg ( org . thingsboard . server . gen . integration . responsemsg . newbuilder ( ) <nl> - / / . setintegrationupdatemsg ( integrationupdatemsg . newbuilder ( ) <nl> - / / . setconfiguration ( constructintegrationconfigproto ( configuration , defaultconverterproto , downlinkconverterproto ) ) <nl> - / / . build ( ) ) <nl> - / / . build ( ) ) ; <nl> + edgeupdatemsg edgeconfig = edgeupdatemsg . newbuilder ( ) <nl> + . setconfiguration ( constructedgeconfigproto ( edge ) ) . build ( ) ; <nl> + outputstream . onnext ( responsemsg . newbuilder ( ) <nl> + . setedgeupdatemsg ( edgeconfig ) <nl> + . build ( ) ) ; <nl> } catch ( exception e ) { <nl> log . error ( " failed to construct proto objects ! " , e ) ; <nl> } <nl>
public class defaultedgenotificationservice implements edgenotificationservice { <nl> updatedependentrulechains ( tenantid , new rulechainid ( entityid . getid ( ) ) , edgeid ) ; <nl> } <nl> break ; <nl> - case relations_deleted : <nl> - <nl> - break ; <nl> } <nl> }
public class oauth2serviceimpl implements oauth2service { <nl>  <nl> list < attributekventry > attributes = createoauth2clientsparamsattributes ( oauth2clientsparams ) ; <nl> try { <nl> - <nl> attributesservice . save ( tenantid , tenantid , dataconstants . server_scope , attributes ) . get ( ) ; <nl> } catch ( exception e ) { <nl> log . error ( " unable to save oauth2 client registration params to attributes ! " , e ) ; <nl>
public class oauth2serviceimpl implements oauth2service { <nl> } <nl>  <nl> @ override <nl> - public void deletedomainoauth2clientregistrationbytenant ( tenantid tenantid ) { <nl> + public void deletetenantoauth2clientsparams ( tenantid tenantid ) { <nl> oauth2clientsparams params = gettenantoauth2clientsparams ( tenantid ) ; <nl> if ( ! stringutils . isempty ( params . getdomainname ( ) ) ) { <nl> - <nl> string settingskey = constructadminsettingsdomainkey ( params . getdomainname ( ) ) ; <nl> adminsettingsservice . deleteadminsettingsbykey ( tenantid , settingskey ) ; <nl> + attributesservice . removeall ( tenantid , tenantid , dataconstants . server_scope , collections . singletonlist ( oauth2_client_registrations_params ) ) ; <nl> + clientsparams . remove ( tenantid ) ; <nl> } <nl> } <nl>  <nl> mmm a / dao / src / main / java / org / thingsboard / server / dao / tenant / tenantserviceimpl . java <nl> ppp b / dao / src / main / java / org / thingsboard / server / dao / tenant / tenantserviceimpl . java <nl>
public class oauth2serviceimpl implements oauth2service { <nl>  <nl> @ override <nl> public oauth2clientsparams savesystemoauth2clientsparams ( oauth2clientsparams oauth2clientsparams ) { <nl> - <nl> validate ( oauth2clientsparams ) ; <nl>  <nl> + validateuniqueregistrationid ( oauth2clientsparams , tenantid . sys_tenant_id ) ; <nl> + lock . lock ( ) ; <nl> + try { <nl> + validateuniqueregistrationid ( oauth2clientsparams , tenantid . sys_tenant_id ) ; <nl> + adminsettings clientregistrationparamssettings = createsystemoauth2settings ( oauth2clientsparams ) ; <nl> + adminsettingsservice . saveadminsettings ( tenantid . sys_tenant_id , clientregistrationparamssettings ) ; <nl> + clientsparams . put ( tenantid . sys_tenant_id , oauth2clientsparams ) ; <nl> + } finally { <nl> + lock . unlock ( ) ; <nl> + } <nl> + <nl> + return getsystemoauth2clientsparams ( tenantid . sys_tenant_id ) ; <nl> + } <nl>  <nl> + private void validateuniqueregistrationid ( oauth2clientsparams inputoauth2clientsparams , tenantid tenantid ) { <nl> + inputoauth2clientsparams . getclientregistrations ( ) . stream ( ) <nl> + . map ( oauth2clientregistration : : getregistrationid ) <nl> + . foreach ( registrationid - > { <nl> + clientsparams . foreach ( ( paramstenantid , oauth2clientsparams ) - > { <nl> + boolean registrationexists = oauth2clientsparams . getclientregistrations ( ) . stream ( ) <nl> + . map ( oauth2clientregistration : : getregistrationid ) <nl> + . anymatch ( registrationid : : equals ) ; <nl> + if ( registrationexists & & ! tenantid . equals ( paramstenantid ) ) { <nl> + log . error ( " current registrationid [ { } ] already registered in the system ! " , registrationid ) ; <nl> + throw new incorrectparameterexception ( " current registrationid [ " + registrationid + " ] already registered in the system ! " ) ; <nl> + } <nl> + } ) ; <nl> + } ) ; <nl> + } <nl> + <nl> + private adminsettings createsystemoauth2settings ( oauth2clientsparams oauth2clientsparams ) { <nl> adminsettings clientregistrationparamssettings = new adminsettings ( ) ; <nl> clientregistrationparamssettings . setkey ( oauth2_client_registrations_params ) ; <nl> objectnode clientregistrationsnode = mapper . createobjectnode ( ) ; <nl>  <nl> - oauth2clientsparams . setdomainname ( " " ) ; <nl> string json ; <nl> try { <nl> json = mapper . writevalueasstring ( oauth2clientsparams ) ; <nl>
public class tbgettelemetrynode implements tbnode { <nl> } <nl> } <nl>  <nl> - <nl> private list < readtskvquery > buildqueries ( ) { <nl> long ts = system . currenttimemillis ( ) ; <nl> long startts = ts - starttsoffset ; <nl> long endts = ts - endtsoffset ; <nl> - <nl> + string orderby ; <nl> + if ( fetchmode . equals ( fetch_mode_first ) | | fetchmode . equals ( fetch_mode_all ) ) { <nl> + orderby = " asc " ; <nl> + } else { <nl> + orderby = " desc " ; <nl> + } <nl> return tskeynames . stream ( ) <nl> - . map ( key - > new basereadtskvquery ( key , startts , endts , num , limit , none ) ) <nl> + . map ( key - > new basereadtskvquery ( key , startts , endts , num , limit , none , orderby ) ) <nl> . collect ( collectors . tolist ( ) ) ; <nl> } <nl>  <nl>
public class auditlogserviceimpl implements auditlogservice { <nl> futures . add ( auditlogdao . savebytenantidandcustomerid ( auditlogentry ) ) ; <nl> futures . add ( auditlogdao . savebytenantidanduserid ( auditlogentry ) ) ; <nl>  <nl> - <nl> auditlogsink . logaction ( auditlogentry ) ; <nl>  <nl> return futures . allaslist ( futures ) ; <nl> mmm a / dao / src / main / java / org / thingsboard / server / dao / audit / sink / elasticsearchauditlogsink . java <nl> ppp b / dao / src / main / java / org / thingsboard / server / dao / audit / sink / elasticsearchauditlogsink . java <nl>
public class alarmprocessor implements ruleprocessor < alarmprocessorconfiguration <nl> ctx . clearalarm ( alarm . get ( ) . getid ( ) , system . currenttimemillis ( ) ) ; <nl> log . debug ( " [ { } ] [ { } ] existing active alarm cleared " ) ; <nl> md . put ( is_cleared_alarm , boolean . true ) ; <nl> + md . put ( is_new_or_cleared_alarm , boolean . true ) ; <nl> existing = alarm . get ( ) ; <nl> } <nl> } <nl> - <nl>  <nl> if ( existing ! = null ) { <nl> md . put ( " alarmid " , existing . getid ( ) . getid ( ) ) ;
public class deviceactormessageprocessor extends abstractcontextawaremsgprocesso <nl> } <nl>  <nl> void processattributesupdate ( actorcontext context , deviceattributeseventnotificationmsg msg ) { <nl> - <nl> refreshattributes ( msg ) ; <nl> set < attributekey > keys = msg . getdeletedkeys ( ) ; <nl> if ( attributesubscriptions . size ( ) > num ) { <nl> mmm a / dao / src / main / java / org / thingsboard / server / dao / timeseries / simplelistenablefuture . java <nl> ppp b / dao / src / main / java / org / thingsboard / server / dao / timeseries / simplelistenablefuture . java <nl>
public abstract class recycler < t > { <nl> this . availablesharedcapacity = availablesharedcapacity ; <nl> } <nl>  <nl> - / <nl> - @ override <nl> - protected void finalize ( ) throws throwable { <nl> - try { <nl> - super . finalize ( ) ; <nl> - } finally { <nl> - link head = link ; <nl> - link = null ; <nl> - while ( head ! = null ) { <nl> - reclaimspace ( link_capacity ) ; <nl> - link next = head . next ; <nl> - / / unlink to help gc and guard against gc nepotism . <nl> - head . next = null ; <nl> - head = next ; <nl> - } <nl> + / * * <nl> + * reclaim all used space and also unlink the nodes to prevent gc nepotism . <nl> + * / <nl> + void reclaimallspaceandunlink ( ) { <nl> + link head = link ; <nl> + link = null ; <nl> + int reclaimspace = num ; <nl> + while ( head ! = null ) { <nl> + reclaimspace + = link_capacity ; <nl> + link next = head . next ; <nl> + / / unlink to help gc and guard against gc nepotism . <nl> + head . next = null ; <nl> + head = next ; <nl> + } <nl> + if ( reclaimspace ! = num ) { <nl> + reclaimspace ( reclaimspace ) ; <nl> } <nl> } <nl>  <nl>
public class http2framecodec extends http2connectionhandler { <nl> / / we should not re - use ids . <nl> assert old = = null ; <nl>  <nl> - <nl> - final channelpromise writepromise = ctx . newpromise ( ) ; <nl> - <nl> encoder ( ) . writeheaders ( ctx , streamid , headersframe . headers ( ) , headersframe . padding ( ) , <nl> - headersframe . isendstream ( ) , writepromise ) ; <nl> - if ( writepromise . isdone ( ) ) { <nl> - notifyheaderwritepromise ( writepromise , promise ) ; <nl> - } else { <nl> + headersframe . isendstream ( ) , promise ) ; <nl> + if ( ! promise . isdone ( ) ) { <nl> numbufferedstreams + + ; <nl> - <nl> - writepromise . addlistener ( new channelfuturelistener ( ) { <nl> - @ override <nl> - public void operationcomplete ( channelfuture future ) throws exception { <nl> - numbufferedstreams - - ; <nl> - <nl> - notifyheaderwritepromise ( future , promise ) ; <nl> - } <nl> - } ) ; <nl> + promise . addlistener ( bufferedstreamslistener ) ; <nl> } <nl> } <nl> } <nl>  <nl> - private static void notifyheaderwritepromise ( channelfuture future , channelpromise promise ) { <nl> - throwable cause = future . cause ( ) ; <nl> - if ( cause = = null ) { <nl> - promise . setsuccess ( ) ; <nl> - } else { <nl> - promise . setfailure ( cause ) ; <nl> - } <nl> - } <nl> - <nl> private void onstreamactive0 ( http2stream stream ) { <nl> if ( stream . id ( ) ! = http2codecutil . http_upgrade_stream_id & & <nl> connection ( ) . local ( ) . isvalidstreamid ( stream . id ( ) ) ) { <nl>
static jobject netty_kqueue_bsdsocket_getpeercredentials ( jnienv * env , jclass cla <nl> ( * env ) - > setintarrayregion ( env , gids , num , num , ( jint * ) & credentials . cr_gid ) ; <nl> } <nl>  <nl> - <nl> - return ( * env ) - > newobject ( env , peercredentialsclass , peercredentialsmethodid , num , credentials . cr_uid , gids ) ; <nl> + pid_t pid = num ; <nl> + # ifdef local_peerpid <nl> + socklen_t len = sizeof ( pid ) ; <nl> + / / getting the local_peerpid is expected to return error in some cases ( e . g . server socket fds ) - just return num . <nl> + if ( netty_unix_socket_getoption0 ( fd , sock_stream , local_peerpid , & pid , len ) < num ) { <nl> + pid = num ; <nl> + } <nl> + # endif <nl> + <nl> + return ( * env ) - > newobject ( env , peercredentialsclass , peercredentialsmethodid , pid , credentials . cr_uid , gids ) ; <nl> } <nl> / / jni registered methods end <nl>  <nl> mmm a / transport - native - kqueue / src / test / java / io / netty / channel / kqueue / kqueuesockettest . java <nl> ppp b / transport - native - kqueue / src / test / java / io / netty / channel / kqueue / kqueuesockettest . java <nl>
public class fastthreadlocal < v > { <nl> return ( v ) v ; <nl> } <nl>  <nl> - v value = initialize ( threadlocalmap ) ; <nl> - registercleaner ( threadlocalmap ) ; <nl> - return value ; <nl> - } <nl> - <nl> - private void registercleaner ( final internalthreadlocalmap threadlocalmap ) { <nl> - thread current = thread . currentthread ( ) ; <nl> - if ( fastthreadlocalthread . willcleanupfastthreadlocals ( current ) | | threadlocalmap . iscleanerflagset ( index ) ) { <nl> - return ; <nl> - } <nl> - <nl> - threadlocalmap . setcleanerflag ( index ) ; <nl> - <nl> - <nl> - / * <nl> - / / we will need to ensure we will trigger remove ( internalthreadlocalmap ) so everything will be released <nl> - / / and fastthreadlocal . onremoval ( . . . ) will be called . <nl> - objectcleaner . register ( current , new runnable ( ) { <nl> - @ override <nl> - public void run ( ) { <nl> - remove ( threadlocalmap ) ; <nl> - <nl> - / / it ' s fine to not call internalthreadlocalmap . remove ( ) here as this will only be triggered once <nl> - / / the thread is collected by gc . in this case the threadlocal will be gone away already . <nl> - } <nl> - } ) ; <nl> - * / <nl> + return initialize ( threadlocalmap ) ; <nl> } <nl>  <nl> / * * <nl>
public class http2multiplexcodec extends http2framecodec { <nl> private final channelhandler inboundstreamhandler ; <nl>  <nl> private int initialoutboundstreamwindow = http2codecutil . default_window_size ; <nl> - <nl> - / / by checking if this is true and only then call flush ( . . . ) . <nl> - private boolean flushneeded ; <nl> private boolean parentreadinprogress ; <nl> private int idcount ; <nl>  <nl>
public class http2multiplexcodec extends http2framecodec { <nl> tail = head = null ; <nl>  <nl> / / we always flush as this is what http2connectionhandler does for now . <nl> - <nl> - / / checking flushneeded and only flush if this returns true . <nl> flush0 ( ctx ) ; <nl> } <nl> } <nl>  <nl> - @ override <nl> - public final void flush ( channelhandlercontext ctx ) { <nl> - flushneeded = false ; <nl> - super . flush ( ctx ) ; <nl> - } <nl> - <nl> / / allow to override for testing <nl> void flush0 ( channelhandlercontext ctx ) { <nl> flush ( ctx ) ; <nl>
public class querystringencoder { <nl> * / <nl> @ override <nl> public string tostring ( ) { <nl> - if ( params . isempty ( ) ) { <nl> - return uri ; <nl> - } else { <nl> - stringbuilder sb = new stringbuilder ( uri ) . append ( ' ? ' ) ; <nl> - for ( int i = num ; i < params . size ( ) ; i + + ) { <nl> - param param = params . get ( i ) ; <nl> - sb . append ( encodecomponent ( param . name , charset ) ) ; <nl> - if ( param . value ! = null ) { <nl> - sb . append ( ' = ' ) ; <nl> - sb . append ( encodecomponent ( param . value , charset ) ) ; <nl> - } <nl> - if ( i ! = params . size ( ) - num ) { <nl> - sb . append ( ' & ' ) ; <nl> - } <nl> - } <nl> - return sb . tostring ( ) ; <nl> - } <nl> + return uribuilder . tostring ( ) ; <nl> } <nl>  <nl> - private static string encodecomponent ( string s , charset charset ) { <nl> - <nl> + private static void appendcomponent ( string s , string charset , stringbuilder sb ) { <nl> try { <nl> - return pattern . matcher ( urlencoder . encode ( s , charset . name ( ) ) ) . replaceall ( " % 20 " ) ; <nl> + s = urlencoder . encode ( s , charset ) ; <nl> } catch ( unsupportedencodingexception ignored ) { <nl> - throw new unsupportedcharsetexception ( charset . name ( ) ) ; <nl> + throw new unsupportedcharsetexception ( charset ) ; <nl> } <nl> - } <nl> - <nl> - private static final class param { <nl> - <nl> - final string name ; <nl> - final string value ; <nl> - <nl> - param ( string name , string value ) { <nl> - this . value = value ; <nl> - this . name = name ; <nl> + / / replace all ' + ' with " % 20 " <nl> + int idx = s . indexof ( ' + ' ) ; <nl> + if ( idx = = - 1 ) { <nl> + sb . append ( s ) ; <nl> + return ; <nl> + } <nl> + sb . append ( s , num , idx ) . append ( " % 20 " ) ; <nl> + int size = s . length ( ) ; <nl> + idx + + ; <nl> + for ( ; idx < size ; idx + + ) { <nl> + char c = s . charat ( idx ) ; <nl> + if ( c ! = ' + ' ) { <nl> + sb . append ( c ) ; <nl> + } else { <nl> + sb . append ( " % 20 " ) ; <nl> + } <nl> } <nl> } <nl> }
public class resourceleakdetector < t > { <nl> creationrecord = null ; <nl> } <nl>  <nl> - <nl> - synchronized ( head ) { <nl> - prev = head ; <nl> - next = head . next ; <nl> - head . next . prev = this ; <nl> - head . next = this ; <nl> - active + + ; <nl> - } <nl> - freed = new atomicboolean ( ) ; <nl> + allleaks . put ( this , boolean . true ) ; <nl> } else { <nl> creationrecord = null ; <nl> - freed = new atomicboolean ( true ) ; <nl> } <nl> } <nl>  <nl>
public abstract class recycler < t > { <nl> } ; <nl> private static final atomicinteger id_generator = new atomicinteger ( integer . min_value ) ; <nl> private static final int own_thread_id = id_generator . getandincrement ( ) ; <nl> - <nl> - private static final int default_initial_max_capacity = num ; <nl> + private static final int default_initial_max_capacity = num ; / / use num k instances as default max capacity . <nl>  <nl> private static final int default_max_capacity ; <nl> private static final int initial_capacity ;
public final class opensslengine extends sslengine { <nl>  <nl> @ override <nl> public long getlastaccessedtime ( ) { <nl> - <nl> - return getcreationtime ( ) ; <nl> + long lastaccessed = opensslengine . this . lastaccessed ; <nl> + / / if lastaccessed is - 1 we will just return the creation time as the handshake was not started yet . <nl> + return lastaccessed = = - 1 ? getcreationtime ( ) : lastaccessed ; <nl> } <nl>  <nl> @ override
public abstract class recycler < t > { <nl> / / io . netty . recycler . maxcapacity . outboundbuffer <nl> int maxcapacity = systempropertyutil . getint ( " io . netty . recycler . maxcapacity " , default_initial_max_capacity ) ; <nl> if ( maxcapacity < num ) { <nl> - <nl> - maxcapacity = num ; <nl> + maxcapacity = default_initial_max_capacity ; <nl> } <nl>  <nl> default_max_capacity = maxcapacity ; <nl> + <nl> + link_capacity = mathutil . findnextpositivepoweroftwo ( <nl> + math . max ( systempropertyutil . getint ( " io . netty . recycler . linkcapacity " , num ) , num ) ) ; <nl> + <nl> if ( logger . isdebugenabled ( ) ) { <nl> if ( default_max_capacity = = num ) { <nl> logger . debug ( " - dio . netty . recycler . maxcapacity : disabled " ) ; <nl> + logger . debug ( " - dio . netty . recycler . linkcapacity : disabled " ) ; <nl> } else { <nl> logger . debug ( " - dio . netty . recycler . maxcapacity : { } " , default_max_capacity ) ; <nl> + logger . debug ( " - dio . netty . recycler . linkcapacity : { } " , link_capacity ) ; <nl> } <nl> } <nl>  <nl>
public class socketsslechotest extends abstractsockettest { <nl> throw clientexception . get ( ) ; <nl> } <nl>  <nl> - / / when renegotiation is done , both the client and server side should be notified . <nl> + / / when renegotiation is done , at least the initiating side should be notified . <nl> try { <nl> - if ( renegotiation . type ! = renegotiationtype . none ) { <nl> + switch ( renegotiation . type ) { <nl> + case server_initiated : <nl> assertthat ( serversslhandler . engine ( ) . getsession ( ) . getciphersuite ( ) , is ( renegotiation . ciphersuite ) ) ; <nl> assertthat ( servernegocounter . get ( ) , is ( 2 ) ) ; <nl> + assertthat ( clientnegocounter . get ( ) , anyof ( is ( 1 ) , is ( 2 ) ) ) ; <nl> + break ; <nl> + case client_initiated : <nl> + assertthat ( servernegocounter . get ( ) , anyof ( is ( 1 ) , is ( 2 ) ) ) ; <nl> assertthat ( clientsslhandler . engine ( ) . getsession ( ) . getciphersuite ( ) , is ( renegotiation . ciphersuite ) ) ; <nl> assertthat ( clientnegocounter . get ( ) , is ( 2 ) ) ; <nl> - } else { <nl> + break ; <nl> + case none : <nl> assertthat ( servernegocounter . get ( ) , is ( 1 ) ) ; <nl> assertthat ( clientnegocounter . get ( ) , is ( 1 ) ) ; <nl> } <nl> - } catch ( throwable t ) { <nl> - <nl> - testutils . dump ( stringutil . simpleclassname ( this ) ) ; <nl> - throw t ; <nl> } finally { <nl> logstats ( " stats " ) ; <nl> }
jniexport jint jnicall java_io_netty_channel_epoll_native_shutdown0 ( jnienv * env , <nl> } <nl>  <nl> static inline jint socket0 ( jnienv * env , jclass clazz , int type ) { <nl> - <nl> int fd = socket ( sockettype , type | sock_nonblock , num ) ; <nl> if ( fd = = - 1 ) { <nl> return - errno ;
public final class opensslengine extends sslengine { <nl> return emptyarrays . empty_strings ; <nl> } else { <nl> for ( int i = num ; i < enabled . length ; i + + ) { <nl> - string c = enabled [ i ] ; <nl> - <nl> - string mapped = ciphersuiteconverter . tojava ( c , " tls " ) ; <nl> + string mapped = tojavaciphersuite ( enabled [ i ] ) ; <nl> if ( mapped ! = null ) { <nl> enabled [ i ] = mapped ; <nl> } <nl>
public class socketsslechotest extends abstractsockettest { <nl> boolean hasopenssl = openssl . isavailable ( ) ; <nl> if ( hasopenssl ) { <nl> servercontexts . add ( new opensslservercontext ( cert_file , key_file ) ) ; <nl> - <nl> - <nl> - / / clientcontexts . add ( new opensslcontext ( cert_file ) ) ; <nl> + clientcontexts . add ( new opensslclientcontext ( cert_file ) ) ; <nl> } else { <nl> logger . warn ( " openssl is unavailable and thus will not be tested . " , openssl . unavailabilitycause ( ) ) ; <nl> } <nl>
public abstract class abstractoiobytechannel extends abstractoiochannel { <nl> final channelconfig config = config ( ) ; <nl> final channelpipeline pipeline = pipeline ( ) ; <nl>  <nl> - <nl> - bytebuf bytebuf = alloc ( ) . buffer ( ) ; <nl> + recvbytebufallocator . handle allochandle = this . allochandle ; <nl> + if ( allochandle = = null ) { <nl> + this . allochandle = allochandle = config . getrecvbytebufallocator ( ) . newhandle ( ) ; <nl> + } <nl> + <nl> + bytebuf bytebuf = allochandle . allocate ( alloc ( ) ) ; <nl> + <nl> boolean closed = false ; <nl> boolean read = false ; <nl> throwable exception = null ; <nl> int localreadamount = num ; <nl> try { <nl> + int totalreadamount = num ; <nl> + <nl> for ( ; ; ) { <nl> localreadamount = doreadbytes ( bytebuf ) ; <nl> if ( localreadamount > num ) { <nl>
public class httpversion implements comparable < httpversion > { <nl> / / * http : / / trac . tools . ietf . org / wg / httpbis / trac / ticket / 1 <nl> / / * http : / / trac . tools . ietf . org / wg / httpbis / trac / wiki <nl> / / <nl> - <nl> - / / see https : / / github . com / netty / netty / issues / 1682 <nl> - <nl> httpversion version = version0 ( text ) ; <nl> if ( version = = null ) { <nl> - text = text . touppercase ( ) ; <nl> - / / try again after convert to uppercase <nl> - version = version0 ( text ) ; <nl> - if ( version = = null ) { <nl> - / / still no match , construct a new one <nl> - version = new httpversion ( text , true ) ; <nl> - } <nl> + version = new httpversion ( text , true ) ; <nl> } <nl> return version ; <nl> }
public class socketsslechotest extends abstractsockettest { <nl> for ( int i = first_message_size ; i < data . length ; ) { <nl> int length = math . min ( random . nextint ( 1024 * num ) , data . length - i ) ; <nl> channelfuture future = cc . write ( unpooled . wrappedbuffer ( data , i , length ) ) ; <nl> - <nl> - if ( ! chunkwritehandler ) { <nl> - future . sync ( ) ; <nl> - } <nl> + future . sync ( ) ; <nl> i + = length ; <nl> }
public class httpobjectaggregator extends messagetomessagedecoder < httpobject > { <nl> } else if ( msg instanceof httpcontent ) { <nl> assert currentmessage ! = null ; <nl>  <nl> + if ( toolongframefound ) { <nl> + this . currentmessage = null ; <nl> + / / already detect the too long frame so just discard the content <nl> + return ; <nl> + } <nl> + <nl> / / merge the received chunk into the content of the current message . <nl> httpcontent chunk = ( httpcontent ) msg ; <nl> compositebytebuf content = ( compositebytebuf ) currentmessage . content ( ) ; <nl>  <nl> if ( content . readablebytes ( ) > maxcontentlength - chunk . content ( ) . readablebytes ( ) ) { <nl> - <nl> - / / and discard the traffic or close the connection . <nl> - / / no need to notify the upstream handlers - just log . <nl> - / / if decoding a response , just throw an exception . <nl> + toolongframefound = true ; <nl> + <nl> throw new toolongframeexception ( <nl> " http content length exceeded " + maxcontentlength + <nl> " bytes . " ) ; <nl> mmm a / codec - http / src / test / java / io / netty / handler / codec / http / httpobjectaggregatortest . java <nl> ppp b / codec - http / src / test / java / io / netty / handler / codec / http / httpobjectaggregatortest . java <nl>
public class hexdumpproxyfrontendhandler extends channelinboundbytehandleradapte <nl>  <nl> @ override <nl> public void channelactive ( channelhandlercontext ctx ) throws exception { <nl> - <nl> - / / currently , we just keep the inbound traffic in the client channel ' s outbound buffer . <nl> final channel inboundchannel = ctx . channel ( ) ; <nl>  <nl> / / start the connection attempt .
public class hexdumpproxyfrontendhandler extends channelinboundbytehandleradapte <nl> @ override <nl> public void operationcomplete ( channelfuture future ) throws exception { <nl> if ( future . issuccess ( ) ) { <nl> - / / connection attempt succeeded : <nl> - <nl> + inboundchannel . config ( ) . setautoread ( true ) ; <nl> } else { <nl> / / close the connection if the connection attempt has failed . <nl> inboundchannel . close ( ) ;
final class defaultchannelhandlercontext extends defaultattributemap implements <nl> private final queue < bytebuf > exchangebuf = new concurrentlinkedqueue < bytebuf > ( ) ; <nl> private final channelhandlercontext ctx ; <nl>  <nl> - bytebridge ( channelhandlercontext ctx ) { <nl> + bytebridge ( channelhandlercontext ctx , boolean inbound ) { <nl> this . ctx = ctx ; <nl> - <nl> - bytebuf = ctx . alloc ( ) . buffer ( ) ; <nl> + if ( inbound ) { <nl> + if ( ctx . inboundbytebuffer ( ) . isdirect ( ) ) { <nl> + bytebuf = ctx . alloc ( ) . directbuffer ( ) ; <nl> + } else { <nl> + bytebuf = ctx . alloc ( ) . heapbuffer ( ) ; <nl> + } <nl> + } else { <nl> + if ( ctx . outboundbytebuffer ( ) . isdirect ( ) ) { <nl> + bytebuf = ctx . alloc ( ) . directbuffer ( ) ; <nl> + } else { <nl> + bytebuf = ctx . alloc ( ) . heapbuffer ( ) ; <nl> + } <nl> + } <nl> } <nl>  <nl> private void fill ( ) {
package io . netty . util . internal ; <nl>  <nl> import java . lang . reflect . parameterizedtype ; <nl> import java . lang . reflect . type ; <nl> - import java . util . concurrent . concurrenthashmap ; <nl> - import java . util . concurrent . concurrentmap ; <nl> + import java . util . identityhashmap ; <nl> + import java . util . map ; <nl>  <nl> public final class typeparameterfinder { <nl>  <nl> - <nl> - private static final concurrentmap < class < ? > , class < ? > > typemap = new concurrenthashmap < class < ? > , class < ? > > ( ) ; <nl> + private static final threadlocal < map < class < ? > , class < ? > > > typemap = new threadlocal < map < class < ? > , class < ? > > > ( ) { <nl> + @ override <nl> + protected map < class < ? > , class < ? > > initialvalue ( ) { <nl> + return new identityhashmap < class < ? > , class < ? > > ( ) ; <nl> + } <nl> + } ; <nl>  <nl> public static class < ? > findactualtypeparameter ( <nl> final object object , final class < ? > parameterizedsuperclass , final int typeparamindex ) { <nl> + final map < class < ? > , class < ? > > typemap = typeparameterfinder . typemap . get ( ) ; <nl> final class < ? > thisclass = object . getclass ( ) ; <nl> class < ? > messagetype = typemap . get ( thisclass ) ; <nl> if ( messagetype = = null ) {
public class oiodatagramchannel extends abstractoiomessagechannel <nl> @ override <nl> protected int doreadmessages ( messagebuf < object > buf ) throws exception { <nl> int packetsize = config ( ) . getreceivepacketsize ( ) ; <nl> - <nl> - bytebuf buffer = unpooled . buffer ( packetsize ) ; <nl> + bytebuf buffer = alloc ( ) . heapbuffer ( packetsize ) ; <nl> boolean free = true ; <nl>  <nl> try { <nl> - int writerindex = buffer . writerindex ( ) ; <nl> - tmppacket . setdata ( buffer . array ( ) , writerindex + buffer . arrayoffset ( ) , packetsize ) ; <nl> - <nl> + tmppacket . setdata ( buffer . array ( ) , buffer . arrayoffset ( ) , packetsize ) ; <nl> socket . receive ( tmppacket ) ; <nl> + <nl> inetsocketaddress remoteaddr = ( inetsocketaddress ) tmppacket . getsocketaddress ( ) ; <nl> if ( remoteaddr = = null ) { <nl> remoteaddr = remoteaddress ( ) ; <nl> } <nl> - datagrampacket packet = new datagrampacket ( buffer . writerindex ( writerindex + tmppacket . getlength ( ) ) <nl> - . readerindex ( writerindex ) , remoteaddr ) ; <nl> + <nl> + datagrampacket packet = new datagrampacket ( buffer . writerindex ( tmppacket . getlength ( ) ) , remoteaddr ) ; <nl> buf . add ( packet ) ; <nl> free = false ; <nl> return num ;
public class sctpechotest extends abstractsctptest { <nl> } <nl>  <nl> @ test <nl> - @ ignore ( " <nl> public void testsimpleechowithboundedbuffer ( ) throws throwable { <nl> assume . assumetrue ( testutils . issctpsupported ( ) ) ; <nl> run ( ) ; <nl> } <nl>  <nl> public void testsimpleechowithboundedbuffer ( serverbootstrap sb , bootstrap cb ) throws throwable { <nl> - testsimpleecho0 ( sb , cb , num ) ; <nl> + testsimpleecho0 ( sb , cb , num ) ; <nl> } <nl>  <nl> private static void testsimpleecho0 ( serverbootstrap sb , bootstrap cb , int maxinboundbuffersize ) throws throwable { <nl> mmm a / testsuite / src / test / java / io / netty / testsuite / transport / socket / sockettestpermutation . java <nl> ppp b / testsuite / src / test / java / io / netty / testsuite / transport / socket / sockettestpermutation . java <nl>
<nl> * / <nl> package com . sun . nio . sctp ; <nl>  <nl> - / * * <nl> - * <nl> - * <nl> - * @ author < a href = " http : / / gleamynode . net / " > trustin lee < / a > <nl> - * / <nl> public enum handlerresult { <nl> continue , return <nl> }
public class aioeventloop extends multithreadeventloop { <nl> } <nl>  <nl> private static abstractaiochannel findchannel ( runnable command ) throws exception { <nl> - <nl> + class < ? > commandtype = command . getclass ( ) ; <nl> + field [ ] fields = fieldcache . get ( commandtype ) ; <nl> + if ( fields = = null ) { <nl> + try { <nl> + fields = findfieldsequence ( command , new arraydeque < field > ( 2 ) ) ; <nl> + } catch ( throwable t ) { <nl> + / / failed to get the field list <nl> + } <nl> + <nl> + if ( fields = = null ) { <nl> + fields = failure ; <nl> + } <nl> + <nl> + fieldcache . put ( commandtype , fields ) ; / / no need to use putifabsent ( ) <nl> + } <nl> + <nl> + if ( fields = = failure ) { <nl> + return null ; <nl> + } <nl> + <nl> + final int lastindex = fields . length - num ; <nl> + for ( int i = num ; i < lastindex ; i + + ) { <nl> + command = ( runnable ) fields [ i ] . get ( command ) ; <nl> + } <nl> + <nl> + return ( abstractaiochannel ) fields [ lastindex ] . get ( command ) ; <nl> + } <nl> + <nl> + private static field [ ] findfieldsequence ( runnable command , deque < field > fields ) throws exception { <nl> class < ? > commandtype = command . getclass ( ) ; <nl> for ( field f : commandtype . getdeclaredfields ( ) ) { <nl> if ( f . gettype ( ) = = runnable . class ) { <nl> f . setaccessible ( true ) ; <nl> - abstractaiochannel ch = findchannel ( ( runnable ) f . get ( command ) ) ; <nl> - if ( ch ! = null ) { <nl> - return ch ; <nl> + fields . addlast ( f ) ; <nl> + try { <nl> + field [ ] ret = findfieldsequence ( ( runnable ) f . get ( command ) , fields ) ; <nl> + if ( ret ! = null ) { <nl> + return ret ; <nl> + } <nl> + } finally { <nl> + fields . removelast ( ) ; <nl> } <nl> } <nl>  <nl> if ( f . gettype ( ) = = object . class ) { <nl> f . setaccessible ( true ) ; <nl> - object candidate = f . get ( command ) ; <nl> - if ( candidate instanceof abstractaiochannel ) { <nl> - return ( abstractaiochannel ) candidate ; <nl> + fields . addlast ( f ) ; <nl> + try { <nl> + object candidate = f . get ( command ) ; <nl> + if ( candidate instanceof abstractaiochannel ) { <nl> + return fields . toarray ( new field [ fields . size ( ) ] ) ; <nl> + } <nl> + } finally { <nl> + fields . removelast ( ) ; <nl> } <nl> } <nl> }
public class aiosocketchannel extends abstractaiochannel implements socketchanne <nl> @ override <nl> protected void failed0 ( throwable t , aiosocketchannel channel ) { <nl> if ( t instanceof closedchannelexception ) { <nl> - channel . closed = true ; <nl> - <nl> return ; <nl> } <nl>  <nl> channel . pipeline ( ) . fireexceptioncaught ( t ) ; <nl> + <nl> if ( t instanceof ioexception ) { <nl> channel . unsafe ( ) . close ( channel . unsafe ( ) . voidfuture ( ) ) ; <nl> } else { <nl>
public class hashedwheeltimer implements timer { <nl> } <nl>  <nl> @ override <nl> - public void cancel ( ) { <nl> + public boolean cancel ( ) { <nl> if ( ! state . compareandset ( st_init , st_cancelled ) ) { <nl> - <nl> - return ; <nl> + return false ; <nl> } <nl>  <nl> wheel [ stopindex ] . remove ( this ) ; <nl> + return true ; <nl> } <nl>  <nl> @ override <nl> mmm a / common / src / main / java / io / netty / util / timeout . java <nl> ppp b / common / src / main / java / io / netty / util / timeout . java <nl>
import io . netty . buffer . bytebuf ; <nl> import io . netty . buffer . unpooled ; <nl> import io . netty . handler . codec . base64 . base64 ; <nl> import io . netty . util . charsetutil ; <nl> - <nl> import java . security . messagedigest ; <nl> import java . security . nosuchalgorithmexception ; <nl>  <nl> / * * <nl> - * <nl> + * a utility class mainly for use by web sockets <nl> * / <nl> final class websocketutil { <nl>  <nl> / * * <nl> - * performs an md5 hash <nl> + * performs a md5 hash on the specified data <nl> * <nl> - * @ param bytes <nl> - * data to hash <nl> - * @ return hashed data <nl> + * @ param data the data to hash <nl> + * @ return the hashed data <nl> * / <nl> - static byte [ ] md5 ( byte [ ] bytes ) { <nl> + static byte [ ] md5 ( byte [ ] data ) { <nl> try { <nl> + / / try to get a messagedigest that uses md5 <nl> messagedigest md = messagedigest . getinstance ( " md5 " ) ; <nl> - return md . digest ( bytes ) ; <nl> + / / hash the data <nl> + return md . digest ( data ) ; <nl> } catch ( nosuchalgorithmexception e ) { <nl> - throw new internalerror ( " md5 not supported on this platform " ) ; <nl> + / / this shouldn ' t happen ! how old is the computer ? <nl> + throw new internalerror ( " md5 not supported on this platform - outdated ? " ) ; <nl> } <nl> } <nl>  <nl> / * * <nl> - * performs an sha - 1 hash <nl> + * performs a sha - 1 hash on the specified data <nl> * <nl> - * @ param bytes <nl> - * data to hash <nl> - * @ return hashed data <nl> + * @ param data the data to hash <nl> + * @ return the hashed data <nl> * / <nl> - static byte [ ] sha1 ( byte [ ] bytes ) { <nl> + static byte [ ] sha1 ( byte [ ] data ) { <nl> try { <nl> + / / attempt to get a messagedigest that uses sha1 <nl> messagedigest md = messagedigest . getinstance ( " sha1 " ) ; <nl> - return md . digest ( bytes ) ; <nl> + / / hash the data <nl> + return md . digest ( data ) ; <nl> } catch ( nosuchalgorithmexception e ) { <nl> - throw new internalerror ( " sha - 1 not supported on this platform " ) ; <nl> + / / alright , you might have an old system . <nl> + throw new internalerror ( " sha - 1 is not supported on this platform - outdated ? " ) ; <nl> } <nl> } <nl>  <nl> / * * <nl> - * base num encoding <nl> + * performs base64 encoding on the specified data <nl> * <nl> - * @ param bytes <nl> - * bytes to encode <nl> - * @ return encoded string <nl> + * @ param data the data to encode <nl> + * @ return an encoded string containing the data <nl> * / <nl> - static string base64 ( byte [ ] bytes ) { <nl> - bytebuf hashed = unpooled . wrappedbuffer ( bytes ) ; <nl> - return base64 . encode ( hashed ) . tostring ( charsetutil . utf_8 ) ; <nl> + static string base64 ( byte [ ] data ) { <nl> + bytebuf encodeddata = unpooled . wrappedbuffer ( data ) ; <nl> + return base64 . encode ( encodeddata ) . tostring ( charsetutil . utf_8 ) ; <nl> } <nl>  <nl> / * * <nl> - * creates some random bytes <nl> + * creates an arbitrary number of random bytes <nl> * <nl> - * @ param size <nl> - * number of random bytes to create <nl> - * @ return random bytes <nl> + * @ param size the number of random bytes to create <nl> + * @ return an array of random bytes <nl> * / <nl> static byte [ ] randombytes ( int size ) { <nl> byte [ ] bytes = new byte [ size ] ; <nl>  <nl> - for ( int i = num ; i < size ; i + + ) { <nl> - bytes [ i ] = ( byte ) randomnumber ( 0 , num ) ; <nl> + for ( int <nl> + bytes [ index ] = ( byte ) randomnumber ( 0 , num ) ; <nl> } <nl>  <nl> return bytes ; <nl> } <nl>  <nl> / * * <nl> - * generates a random number <nl> + * generates a pseudo - random number <nl> * <nl> - * @ param min <nl> - * minimum value <nl> - * @ param max <nl> - * maximum value <nl> - * @ return random number <nl> + * @ param minimum the minimum allowable value <nl> + * @ param maximum the maximum allowable value <nl> + * @ return a pseudo - random number <nl> * / <nl> - static int randomnumber ( int min , int max ) { <nl> - return ( int ) ( math . random ( ) * max + min ) ; <nl> + static int randomnumber ( int minimum , int maximum ) { <nl> + return ( int ) ( math . random ( ) * maximum + minimum ) ; <nl> } <nl>  <nl> - <nl> + / * * <nl> + * a private constructor to ensure that instances of this class cannot be made <nl> + * / <nl> private websocketutil ( ) { <nl> / / unused <nl> }
public class hashedwheeltimer implements timer { <nl> } <nl>  <nl> @ override <nl> - public void cancel ( ) { <nl> + public boolean cancel ( ) { <nl> if ( ! state . compareandset ( st_init , st_cancelled ) ) { <nl> - <nl> - return ; <nl> + return false ; <nl> } <nl>  <nl> wheel [ stopindex ] . remove ( this ) ; <nl> + return true ; <nl> } <nl>  <nl> @ override <nl> mmm a / common / src / main / java / io / netty / util / timeout . java <nl> ppp b / common / src / main / java / io / netty / util / timeout . java <nl>
import io . netty . buffer . bytebuf ; <nl> import io . netty . buffer . unpooled ; <nl> import io . netty . handler . codec . base64 . base64 ; <nl> import io . netty . util . charsetutil ; <nl> - <nl> import java . security . messagedigest ; <nl> import java . security . nosuchalgorithmexception ; <nl>  <nl> / * * <nl> - * <nl> + * a utility class mainly for use by web sockets <nl> * / <nl> final class websocketutil { <nl>  <nl> / * * <nl> - * performs an md5 hash <nl> + * performs a md5 hash on the specified data <nl> * <nl> - * @ param bytes <nl> - * data to hash <nl> - * @ return hashed data <nl> + * @ param data the data to hash <nl> + * @ return the hashed data <nl> * / <nl> - static byte [ ] md5 ( byte [ ] bytes ) { <nl> + static byte [ ] md5 ( byte [ ] data ) { <nl> try { <nl> + / / try to get a messagedigest that uses md5 <nl> messagedigest md = messagedigest . getinstance ( " md5 " ) ; <nl> - return md . digest ( bytes ) ; <nl> + / / hash the data <nl> + return md . digest ( data ) ; <nl> } catch ( nosuchalgorithmexception e ) { <nl> - throw new internalerror ( " md5 not supported on this platform " ) ; <nl> + / / this shouldn ' t happen ! how old is the computer ? <nl> + throw new internalerror ( " md5 not supported on this platform - outdated ? " ) ; <nl> } <nl> } <nl>  <nl> / * * <nl> - * performs an sha - 1 hash <nl> + * performs a sha - 1 hash on the specified data <nl> * <nl> - * @ param bytes <nl> - * data to hash <nl> - * @ return hashed data <nl> + * @ param data the data to hash <nl> + * @ return the hashed data <nl> * / <nl> - static byte [ ] sha1 ( byte [ ] bytes ) { <nl> + static byte [ ] sha1 ( byte [ ] data ) { <nl> try { <nl> + / / attempt to get a messagedigest that uses sha1 <nl> messagedigest md = messagedigest . getinstance ( " sha1 " ) ; <nl> - return md . digest ( bytes ) ; <nl> + / / hash the data <nl> + return md . digest ( data ) ; <nl> } catch ( nosuchalgorithmexception e ) { <nl> - throw new internalerror ( " sha - 1 not supported on this platform " ) ; <nl> + / / alright , you might have an old system . <nl> + throw new internalerror ( " sha - 1 is not supported on this platform - outdated ? " ) ; <nl> } <nl> } <nl>  <nl> / * * <nl> - * base num encoding <nl> + * performs base64 encoding on the specified data <nl> * <nl> - * @ param bytes <nl> - * bytes to encode <nl> - * @ return encoded string <nl> + * @ param data the data to encode <nl> + * @ return an encoded string containing the data <nl> * / <nl> - static string base64 ( byte [ ] bytes ) { <nl> - bytebuf hashed = unpooled . wrappedbuffer ( bytes ) ; <nl> - return base64 . encode ( hashed ) . tostring ( charsetutil . utf_8 ) ; <nl> + static string base64 ( byte [ ] data ) { <nl> + bytebuf encodeddata = unpooled . wrappedbuffer ( data ) ; <nl> + return base64 . encode ( encodeddata ) . tostring ( charsetutil . utf_8 ) ; <nl> } <nl>  <nl> / * * <nl> - * creates some random bytes <nl> + * creates an arbitrary number of random bytes <nl> * <nl> - * @ param size <nl> - * number of random bytes to create <nl> - * @ return random bytes <nl> + * @ param size the number of random bytes to create <nl> + * @ return an array of random bytes <nl> * / <nl> static byte [ ] randombytes ( int size ) { <nl> byte [ ] bytes = new byte [ size ] ; <nl>  <nl> - for ( int i = num ; i < size ; i + + ) { <nl> - bytes [ i ] = ( byte ) randomnumber ( 0 , num ) ; <nl> + for ( int <nl> + bytes [ index ] = ( byte ) randomnumber ( 0 , num ) ; <nl> } <nl>  <nl> return bytes ; <nl> } <nl>  <nl> / * * <nl> - * generates a random number <nl> + * generates a pseudo - random number <nl> * <nl> - * @ param min <nl> - * minimum value <nl> - * @ param max <nl> - * maximum value <nl> - * @ return random number <nl> + * @ param minimum the minimum allowable value <nl> + * @ param maximum the maximum allowable value <nl> + * @ return a pseudo - random number <nl> * / <nl> - static int randomnumber ( int min , int max ) { <nl> - return ( int ) ( math . random ( ) * max + min ) ; <nl> + static int randomnumber ( int minimum , int maximum ) { <nl> + return ( int ) ( math . random ( ) * maximum + minimum ) ; <nl> } <nl>  <nl> - <nl> + / * * <nl> + * a private constructor to ensure that instances of this class cannot be made <nl> + * / <nl> private websocketutil ( ) { <nl> / / unused <nl> }
public class asyncsocketchannel extends abstractasyncchannel { <nl>  <nl> @ override <nl> protected boolean isflushpending ( ) { <nl> - <nl> - return true ; <nl> + return false ; <nl> } <nl>  <nl> + @ override <nl> protected boolean doflushbytebuffer ( bytebuf buf ) throws exception { <nl> + / / only one pending write can be scheduled at one time . otherwise <nl> + / / a pendingwriteexception will be thrown . so use cas to not run <nl> + / / into this <nl> if ( flushing . compareandset ( false , true ) ) { <nl> - javachannel ( ) . write ( buf . niobuffer ( ) , this , write_handler ) ; <nl> + bytebuffer buffer = ( bytebuffer ) buf . niobuffer ( ) ; <nl> + javachannel ( ) . write ( buffer , this , write_handler ) ; <nl> } <nl> return false ; <nl> } <nl>
abstract class abstractnioworker implements worker { <nl> if ( acceptedsocket = = null ) { <nl> break ; <nl> } <nl> - <nl> channelpipeline pipeline = <nl> channel . getconfig ( ) . getpipelinefactory ( ) . getpipeline ( ) ; <nl> nioworker worker = channel . workers . nextworker ( ) ;
public class sctpworker extends nioworker { <nl> protected void connect ( selectionkey k ) { <nl> final sctpclientchannel ch = ( sctpclientchannel ) k . attachment ( ) ; <nl> try { <nl> - <nl> if ( ch . getjdkchannel ( ) . finishconnect ( ) ) { <nl> registertask ( ch , ch . connectfuture ) ; <nl> } <nl>
public class sctpworker extends nioworker { <nl> protected void connect ( selectionkey k ) { <nl> final sctpclientchannel ch = ( sctpclientchannel ) k . attachment ( ) ; <nl> try { <nl> - <nl> if ( ch . getjdkchannel ( ) . finishconnect ( ) ) { <nl> registertask ( ch , ch . connectfuture ) ; <nl> } <nl>
public class sctpworker extends nioworker { <nl> selector , channel . getrawinterestops ( ) , channel ) ; <nl> } <nl>  <nl> - } else { <nl> - <nl> - setinterestops ( channel , future , channel . getrawinterestops ( ) ) ; <nl> } <nl> if ( future ! = null ) { <nl> ( ( sctpchannelimpl ) channel ) . setconnected ( ) ;
public class nioworker extends abstractnioworker { <nl> selector , channel . getrawinterestops ( ) , channel ) ; <nl> } <nl>  <nl> - } else { <nl> - <nl> - setinterestops ( channel , future , channel . getrawinterestops ( ) ) ; <nl> } <nl> if ( future ! = null ) { <nl> if ( channel instanceof niosocketchannel ) {
public class nioworker extends abstractnioworker { <nl> selector , channel . getrawinterestops ( ) , channel ) ; <nl> } <nl>  <nl> - } else { <nl> - <nl> - setinterestops ( channel , future , channel . getrawinterestops ( ) ) ; <nl> } <nl> if ( future ! = null ) { <nl> + <nl> ( ( niosocketchannel ) channel ) . setconnected ( ) ; <nl> future . setsuccess ( ) ; <nl> }
public class lengthfieldbasedframedecoder extends framedecoder { <nl> buffer . skipbytes ( localbytestodiscard ) ; <nl> bytestodiscard - = localbytestodiscard ; <nl> this . bytestodiscard = bytestodiscard ; <nl> - if ( bytestodiscard = = num ) { <nl> - / / reset to the initial state and tell the handlers that <nl> - / / the frame was too large . <nl> - <nl> - / / if early , fail ( ) should be called when discardingtoolongframe is set to true . <nl> - long toolongframelength = this . toolongframelength ; <nl> - this . toolongframelength = num ; <nl> - fail ( ctx , toolongframelength ) ; <nl> - } else { <nl> - / / keep discarding . <nl> - } <nl> + failifnecessary ( ctx ) ; <nl> return null ; <nl> } <nl>  <nl>
class niosocketchannel extends abstractchannel <nl> this . socket = socket ; <nl> this . worker = worker ; <nl> config = new defaultniosocketchannelconfig ( socket . socket ( ) ) ; <nl> - <nl> - <nl> - / / to add many listeners . <nl> - getclosefuture ( ) . addlistener ( new channelfuturelistener ( ) { <nl> - @ override <nl> - public void operationcomplete ( channelfuture future ) throws exception { <nl> - state = st_closed ; <nl> - } <nl> - } ) ; <nl> } <nl>  <nl> @ override <nl>
import org . jboss . netty . util . charsetutil ; <nl> * @ apiviz . has org . jboss . netty . buffer . channelbuffer oneway - - creates <nl> * / <nl> public class channelbuffers { <nl> - <nl>  <nl> / * * <nl> * big endian byte order . <nl>
import java . nio . charset . unsupportedcharsetexception ; <nl> * @ apiviz . landmark <nl> * / <nl> public interface channelbuffer extends comparable < channelbuffer > { <nl> - <nl>  <nl> / * * <nl> * returns the factory which creates a { @ link channelbuffer } whose <nl>
public class httpchunkaggregator extends simplechannelupstreamhandler { <nl> @ override <nl> public void messagereceived ( channelhandlercontext ctx , messageevent e ) <nl> throws exception { <nl> - object msg = e . getmessage ( ) ; <nl> - if ( ! ( msg instanceof httpmessage ) & & ! ( msg instanceof httpchunk ) ) { <nl> - ctx . sendupstream ( e ) ; <nl> - return ; <nl> - } <nl>  <nl> + object msg = e . getmessage ( ) ; <nl> httpmessage currentmessage = this . currentmessage ; <nl> - if ( currentmessage = = null ) { <nl> + <nl> + if ( msg instanceof httpmessage ) { <nl> httpmessage m = ( httpmessage ) msg ; <nl> if ( m . ischunked ( ) ) { <nl> / / a chunked message - remove ' transfer - encoding ' header , <nl> / / initialize the cumulative buffer , and wait for incoming chunks . <nl> - <nl> list < string > encodings = m . getheaders ( httpheaders . names . transfer_encoding ) ; <nl> encodings . remove ( httpheaders . values . chunked ) ; <nl> if ( encodings . isempty ( ) ) { <nl>
<nl> - / * <nl> - * copyright num red hat , inc . <nl> - * <nl> - * red hat licenses this file to you under the apache license , version num . 0 <nl> - * ( the " license " ) ; you may not use this file except in compliance with the <nl> - * license . you may obtain a copy of the license at : <nl> - * <nl> - * http : / / www . apache . org / licenses / license - 2 . 0 <nl> - * <nl> - * unless required by applicable law or agreed to in writing , software <nl> - * distributed under the license is distributed on an " as is " basis , without <nl> - * warranties or conditions of any kind , either express or implied . see the <nl> - * license for the specific language governing permissions and limitations <nl> - * under the license . <nl> - * / <nl> - package org . jboss . netty . channel . socket . nio ; <nl> - <nl> - import java . net . inetsocketaddress ; <nl> - import java . net . serversocket ; <nl> - import java . net . socket ; <nl> - import java . util . concurrent . executors ; <nl> - <nl> - import org . jboss . netty . bootstrap . clientbootstrap ; <nl> - import org . jboss . netty . channel . channelfuture ; <nl> - import org . jboss . netty . util . dummyhandler ; <nl> - import org . junit . test ; <nl> - <nl> - / * * <nl> - * tests if netty works around the infamous <nl> - * < a href = " http : / / bugs . sun . com / bugdatabase / view_bug . do ? bug_id = 6403933 " > ' spinning selector ' bug < / a > . <nl> - * <nl> - * @ author the netty project ( netty - dev @ lists . jboss . org ) <nl> - * @ author trustin lee ( trustin @ gmail . com ) <nl> - * @ version $ rev $ , $ date $ <nl> - * / <nl> - public class spinningselectorbugtest { <nl> - <nl> - @ test ( timeout = num ) <nl> - public void test ( ) throws exception { <nl> - serversocket ss = new serversocket ( 0 ) ; <nl> - <nl> - clientbootstrap cb = new clientbootstrap ( new nioclientsocketchannelfactory ( <nl> - executors . newcachedthreadpool ( ) , executors . newcachedthreadpool ( ) ) ) ; <nl> - cb . getpipeline ( ) . addlast ( " dummy " , new dummyhandler ( ) ) ; <nl> - channelfuture cf = cb . connect ( new inetsocketaddress ( " 127 . 0 . 0 . 1 " , ss . getlocalport ( ) ) ) ; <nl> - socket s = ss . accept ( ) ; <nl> - cf . awaituninterruptibly ( ) ; <nl> - <nl> - try { <nl> - thread . sleep ( 1000 ) ; <nl> - } catch ( interruptedexception e ) { <nl> - / / ignore <nl> - } <nl> - <nl> - / / send rst to trigger selector to spin . <nl> - s . setsolinger ( true , num ) ; <nl> - s . close ( ) ; <nl> - <nl> - / / if selector spins , the client side selector will not notice the closure . <nl> - cf . getchannel ( ) . getclosefuture ( ) . awaituninterruptibly ( ) ; <nl> - <nl> - cb . releaseexternalresources ( ) ; <nl> - } <nl> - }
final class deflate { <nl> private void lm_init ( ) { <nl> window_size = num * w_size ; <nl>  <nl> - <nl> - head [ hash_size - num ] = num ; <nl> - for ( int i = num ; i < hash_size - num ; i + + ) { <nl> - head [ i ] = num ; <nl> - } <nl> - <nl> / / set the default configuration parameters : <nl> max_lazy_match = deflate . config_table [ level ] . max_lazy ; <nl> good_match = deflate . config_table [ level ] . good_length ;
public class zlibdecoder extends onetoonedecoder { <nl> int resultcode = z . inflate ( jzlib . z_sync_flush ) ; <nl> switch ( resultcode ) { <nl> case jzlib . z_stream_end : <nl> - <nl> + finished = true ; / / do not decode anymore . <nl> case jzlib . z_ok : <nl> case jzlib . z_buf_error : <nl> decompressed . writebytes ( out , num , z . next_out_index ) ;
public class httptunnelingservlet extends httpservlet { <nl> } catch ( exception e ) { <nl> throw new servletexception ( " failed to create a channel factory . " , e ) ; <nl> } <nl> - <nl> - serverbootstrap b = new serverbootstrap ( new defaultlocalserverchannelfactory ( ) ) ; <nl> - <nl> - b . getpipeline ( ) . addlast ( " logger " , new logginghandler ( getclass ( ) , internalloglevel . info , true ) ) ; <nl> - b . getpipeline ( ) . addlast ( " handler " , new echohandler ( ) ) ; <nl> - b . bind ( remoteaddress ) ; <nl> } <nl>  <nl> protected socketaddress parseendpoint ( string endpoint ) throws exception {
class httptunnelingclientsocketchannel extends abstractchannel <nl>  <nl> @ override <nl> public channelfuture setinterestops ( int interestops ) { <nl> - <nl> - return channel . setinterestops ( interestops ) ; <nl> + final channelfuture future = future ( this ) ; <nl> + channel . setinterestops ( interestops ) . addlistener ( new channelfuturelistener ( ) { <nl> + public void operationcomplete ( channelfuture f ) <nl> + throws exception { <nl> + if ( f . issuccess ( ) ) { <nl> + future . setsuccess ( ) ; <nl> + firechannelinterestchanged ( httptunnelingclientsocketchannel . this ) ; <nl> + } else { <nl> + future . setfailure ( f . getcause ( ) ) ; <nl> + fireexceptioncaught ( httptunnelingclientsocketchannel . this , f . getcause ( ) ) ; <nl> + } <nl> + } <nl> + } ) ; <nl> + return future ; <nl> } <nl>  <nl> @ override
package org . jboss . netty . handler . codec . frame ; <nl>  <nl> import static org . jboss . netty . buffer . channelbuffers . * ; <nl>  <nl> + import java . nio . byteorder ; <nl> + <nl> import org . jboss . netty . buffer . channelbuffer ; <nl> + import org . jboss . netty . buffer . channelbufferfactory ; <nl> import org . jboss . netty . channel . channel ; <nl> import org . jboss . netty . channel . channelhandlercontext ; <nl> import org . jboss . netty . channel . channelpipelinecoverage ; <nl> import org . jboss . netty . handler . codec . oneone . onetooneencoder ; <nl>  <nl> / * * <nl> - * <nl> + * an encoder that prepends the length of the message . the length value is <nl> + * prepended as a binary form . it is encoded in either big endian or little <nl> + * endian depending on the default { @ link byteorder } of the current <nl> + * { @ link channelbufferfactory } . <nl> + * < p > <nl> + * for example , < tt > { @ link lengthfieldprepender } ( 2 ) < / tt > will encode the <nl> + * following num - bytes string : <nl> + * < pre > <nl> + * + - - - - - - - - - - - - - - - - + <nl> + * | " hello , world " | <nl> + * + - - - - - - - - - - - - - - - - + <nl> + * < / pre > <nl> + * into the following : <nl> + * < pre > <nl> + * + - - - - - - - - + - - - - - - - - - - - - - - - - + <nl> + * + num x000c | " hello , world " | <nl> + * + - - - - - - - - + - - - - - - - - - - - - - - - - + <nl> + * < / pre > <nl> + * if you turned on the { @ code lengthincludeslengthfieldlength } flag in the <nl> + * constructor , the encoded data would look like the following <nl> + * ( 12 ( original data ) + num ( prepended data ) = num ( 0xe ) ) : <nl> + * < pre > <nl> + * + - - - - - - - - + - - - - - - - - - - - - - - - - + <nl> + * + num x000e | " hello , world " | <nl> + * + - - - - - - - - + - - - - - - - - - - - - - - - - + <nl> + * < / pre > <nl> * <nl> * @ author the netty project ( netty - dev @ lists . jboss . org ) <nl> * @ author trustin lee ( tlee @ redhat . com ) <nl>
final class localclientchannelsink extends abstractchannelsink { <nl> } <nl> break ; <nl> case interest_ops : <nl> - <nl> + future . setsuccess ( ) ; <nl> break ; <nl> } <nl> } <nl> mmm a / src / main / java / org / jboss / netty / channel / local / localserverchannelsink . java <nl> ppp b / src / main / java / org / jboss / netty / channel / local / localserverchannelsink . java <nl>
final class localserverchannelsink extends abstractchannelsink { <nl> } <nl> break ; <nl> case interest_ops : <nl> - <nl> + future . setsuccess ( ) ; <nl> break ; <nl> } <nl> } else if ( e instanceof messageevent ) {
import org . jboss . netty . util . caseignoringcomparator ; <nl> * / <nl> public class cookiedecoder { <nl>  <nl> - <nl> private final static string semicolon = " ; " ; <nl> private final static string equals = " = " ; <nl>  <nl> public map < string , cookie > decode ( string header ) { <nl> + / / fixme : support both version num and num cookies <nl> + / / fixme : decode all cookie fields , including domain , path , maxage , secure , and comment . <nl> + / / fixme : cookiedecoder cannot assume that the first field is always the name - value pair . <nl> + / / fixme : check rfc num - http : / / www . ietf . org / rfc / rfc2109 . txt <nl> map < string , cookie > cookies = new treemap < string , cookie > ( caseignoringcomparator . instance ) ; <nl> string [ ] split = header . split ( semicolon ) ; <nl> for ( string s : split ) { <nl> mmm a / src / main / java / org / jboss / netty / handler / codec / http / cookieencoder . java <nl> ppp b / src / main / java / org / jboss / netty / handler / codec / http / cookieencoder . java <nl>
import org . jboss . netty . util . caseignoringcomparator ; <nl> * / <nl> public class cookieencoder { <nl>  <nl> - <nl> private final map < string , cookie > cookies = new treemap < string , cookie > ( caseignoringcomparator . instance ) ; <nl>  <nl> public void addcookie ( string name , string val ) { <nl>
public abstract class abstractxniochannelhandler implements iohandler < java . nio . c <nl>  <nl> boolean closed = false ; <nl>  <nl> - <nl> - channelbuffer buf = c . getconfig ( ) . getbufferfactory ( ) . getbuffer ( 2048 ) ; <nl> + receivebuffersizepredictor predictor = c . getconfig ( ) . getreceivebuffersizepredictor ( ) ; <nl> + channelbufferfactory bufferfactory = c . getconfig ( ) . getbufferfactory ( ) ; <nl> + channelbuffer buf = bufferfactory . getbuffer ( predictor . nextreceivebuffersize ( ) ) ; <nl> + <nl> socketaddress remoteaddress = null ; <nl> throwable exception = null ; <nl> if ( channel instanceof scatteringbytechannel ) { <nl>
public abstract class httpmessagedecoder extends replayingdecoder < httpmessagedec <nl> } <nl>  <nl> private object reset ( ) { <nl> - <nl> + httpmessage message = this . message ; <nl> + channelbuffer content = this . content ; <nl> + if ( content = = null ) { <nl> + content = channelbuffers . empty_buffer ; <nl> + } <nl> message . setcontent ( content ) ; <nl> - content = null ; <nl> + <nl> + this . message = null ; <nl> + this . content = null ; <nl> checkpoint ( state . skip_control_chars ) ; <nl> return message ; <nl> }
public class querystringdecoder { <nl> path = split [ 0 ] ; <nl> decodeparams ( split [ 1 ] ) ; <nl> } <nl> - <nl> + <nl> private void decodeparams ( string s ) { <nl> string [ ] params = s . split ( " & " ) ; <nl> for ( string param : params ) { <nl>
class nioprovidermetadata { <nl> } <nl>  <nl> int autodetectwithouttimeout ( ) { <nl> - <nl> final int constraintlevel ; <nl> executorservice executor = executors . newcachedthreadpool ( ) ; <nl> boolean success ;
class nioprovidermetadata { <nl> executor . execute ( loop ) ; <nl>  <nl> / / level num <nl> - <nl> success = true ; <nl> for ( int i = num ; i < num ; i + + ) {
public class mediasessionplayerui extends playerui { <nl> } <nl> } <nl>  <nl> - @ override <nl> - public void onbroadcastreceived ( final intent intent ) { <nl> - super . onbroadcastreceived ( intent ) ; <nl> - <nl> - } <nl> - <nl> @ override <nl> public void onthumbnailloaded ( @ nullable final bitmap bitmap ) { <nl> super . onthumbnailloaded ( bitmap ) ; <nl> mmm a / app / src / main / java / org / schabi / newpipe / player / mediasession / playqueuenavigator . java <nl> ppp b / app / src / main / java / org / schabi / newpipe / player / mediasession / playqueuenavigator . java <nl>
public enum streamdialogdefaultentry { <nl> . setuploaderurl ( serviceid , url , result . getuploaderurl ( ) ) <nl> . subscribeon ( schedulers . io ( ) ) . subscribe ( ) ; <nl> openchannelfragment ( fragment , item , result . getuploaderurl ( ) ) ; <nl> - } , throwable - > toast . maketext ( <nl> - <nl> - fragment . getcontext ( ) , <nl> - r . string . error_show_channel_details , <nl> - toast . length_short <nl> - ) . show ( ) ) ; <nl> + } , throwable - > errorutil . openactivity ( <nl> + fragment . requirecontext ( ) , <nl> + new errorinfo ( <nl> + throwable , <nl> + useraction . requested_channel , <nl> + url , <nl> + serviceid <nl> + ) ) ) ; <nl> } else { <nl> openchannelfragment ( fragment , item , item . getuploaderurl ( ) ) ; <nl> }
class notificationworker ( <nl> } <nl> . doonerror { throwable - > <nl> log . e ( tag , " error while displaying streams notifications " , throwable ) <nl> - <nl> + errorutil . createnotification ( <nl> + applicationcontext , <nl> + errorinfo ( throwable , useraction . new_streams_notifications , " main worker " ) <nl> + ) <nl> } <nl> . onerrorreturnitem ( result . failure ( ) ) <nl> } else {
class feedfragment : basestatefragment < feedstate > ( ) { <nl> } <nl> } <nl>  <nl> - <nl> - fun redrawcontent ( ) { <nl> - groupadapter . notifyitemrangechanged ( 0 , int . max_value ) <nl> - } <nl> - <nl> fun setuplistviewmode ( ) { <nl> / / does everything needed to setup the layouts for grid or list modes <nl> groupadapter . spancount = if ( shouldusegridlayout ( context ) ) getgridspancountstreams ( context ) else num
public final class videodetailfragment <nl> & & playerhelper . isstartmainplayerfullscreenenabled ( requirecontext ( ) ) <nl> & & ! deviceutils . islandscape ( requirecontext ( ) ) <nl> & & playerhelper . globalscreenorientationlocked ( requirecontext ( ) ) ) { <nl> - <nl> onscreenrotationbuttonclicked ( ) ; <nl> } <nl>  <nl> mmm a / app / src / main / java / org / schabi / newpipe / player / player . java <nl> ppp b / app / src / main / java / org / schabi / newpipe / player / player . java <nl>
public enum streamdialogentry { <nl> if ( isnullorempty ( item . getuploaderurl ( ) ) ) { <nl> final int serviceid = item . getserviceid ( ) ; <nl> final string url = item . geturl ( ) ; <nl> - <nl> + toast . maketext ( fragment . getcontext ( ) , r . string . loading_channel_details , <nl> + toast . length_short ) . show ( ) ; <nl> extractorhelper . getstreaminfo ( serviceid , url , false ) <nl> . subscribeon ( schedulers . io ( ) ) <nl> . observeon ( androidschedulers . mainthread ( ) ) <nl>
public abstract class playqueue implements serializable { <nl> * @ return the <nl> * / <nl> public int indexof ( @ nonnull final playqueueitem item ) { <nl> - / / referential equality , can ' t think of a better way to do this <nl> - <nl> return streams . indexof ( item ) ; <nl> }
public class videodetailfragment <nl> } <nl>  <nl> if ( ! isloading . get ( ) & & currentinfo ! = null & & isvisible ( ) ) { <nl> - <nl> - / / outstate . putserializable ( info_key , currentinfo ) ; <nl> + outstate . putserializable ( info_key , currentinfo ) ; <nl> } <nl>  <nl> outstate . putserializable ( stack_key , stack ) ; <nl>
import org . schabi . newpipe . basefragment ; <nl> import org . schabi . newpipe . r ; <nl> import org . schabi . newpipe . fragments . list . kiosk . kioskfragment ; <nl> import org . schabi . newpipe . fragments . subscription . subscriptionfragment ; <nl> + import org . schabi . newpipe . report . erroractivity ; <nl> + import org . schabi . newpipe . report . useraction ; <nl> import org . schabi . newpipe . util . navigationhelper ; <nl>  <nl> public class mainfragment extends basefragment implements tablayout . ontabselectedlistener { <nl> private viewpager viewpager ; <nl> private boolean showblanktab = false ; <nl>  <nl> - <nl> - public int currentserviceid = num ; / / for youtube <nl> + public int currentserviceid = - 1 ; <nl>  <nl> / * / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / <nl> / / fragment ' s lifecycle <nl>
public class mainfragment extends basefragment implements tablayout . ontabselecte <nl> try { <nl> return kioskfragment . getinstance ( currentserviceid ) ; <nl> } catch ( exception e ) { <nl> - <nl> - e . printstacktrace ( ) ; <nl> + erroractivity . reporterror ( activity , e , <nl> + activity . getclass ( ) , <nl> + null , <nl> + erroractivity . errorinfo . make ( useraction . ui_error , <nl> + " none " , " " , r . string . app_ui_crash ) ) ; <nl> return new blankfragment ( ) ; <nl> } <nl> } <nl> mmm a / app / src / main / res / values / settings_keys . xml <nl> ppp b / app / src / main / res / values / settings_keys . xml <nl>
public class backgroundplayer extends service / * implements mediaplayer . onprepare <nl>  <nl> @ override <nl> public android . support . v4 . app . notificationcompat . builder setprogress ( int max , int progress , boolean indeterminate ) { <nl> - <nl> - return super . setprogress ( max , progress , indeterminate ) ; <nl> - } <nl> - <nl> - @ override <nl> - public notification build ( ) { <nl> - <nl> - return super . build ( ) ; <nl> + super . setprogress ( max , progress , indeterminate ) ; <nl> + getbigcontentview ( ) . setprogressbar ( r . id . playbackprogress , max , progress , indeterminate ) ; <nl> + return this ; <nl> } <nl>  <nl> + / * * <nl> + * set the isplaying state <nl> + * @ param isplaying the is playing state <nl> + * / <nl> public void setisplaying ( boolean isplaying ) { <nl> remoteviews views = getcontentview ( ) , bigviews = getbigcontentview ( ) ; <nl> int imagesrc ; <nl> mmm a / app / src / main / res / layout / player_notification_expanded . xml <nl> ppp b / app / src / main / res / layout / player_notification_expanded . xml <nl>
public class mainactivity extends appcompatactivity implements adapterview . onite <nl> actionbar . settitle ( r . string . downloads_title ) ; <nl> actionbar . setdisplayshowtitleenabled ( true ) ; <nl>  <nl> - <nl> - mprefs = getsharedpreferences ( threads , context . mode_world_readable ) ; <nl> + mprefs = preferencemanager . getdefaultsharedpreferences ( this ) ; <nl>  <nl> / / fragment <nl> getwindow ( ) . getdecorview ( ) . getviewtreeobserver ( ) . addongloballayoutlistener ( new viewtreeobserver . ongloballayoutlistener ( ) { <nl> mmm a / app / src / main / java / us / shandian / giga / ui / fragment / missionsfragment . java <nl> ppp b / app / src / main / java / us / shandian / giga / ui / fragment / missionsfragment . java <nl>
public class videoitemlistactivity extends appcompatactivity <nl> return true ; <nl> } <nl> case r . id . action_show_downloads : { <nl> - <nl> + intent intent = new intent ( this , org . schabi . newpipe . download . mainactivity . class ) ; <nl> + startactivity ( intent ) ; <nl> return true ; <nl> } <nl> default : <nl> mmm a / app / src / main / java / org / schabi / newpipe / download / mainactivity . java <nl> ppp b / app / src / main / java / org / schabi / newpipe / download / mainactivity . java <nl>
public class youtubestreamextractor implements streamextractor { <nl> * @ return the offset ( in seconds ) , or num if no timestamp is found . * / <nl> @ override <nl> public int gettimestamp ( ) throws parsingexception { <nl> - <nl> string timestamp ; <nl> try { <nl> timestamp = parser . matchgroup1 ( " ( ( # | & | \ \ ? ) t = \ \ d { 0 , 3 } h ? \ \ d { 0 , 3 } m ? \ \ d { 1 , 3 } s ? ) " , pageurl ) ; <nl>
<nl> android : parentactivityname = " . videoitemdetailactivity " <nl> tools : ignore = " unusedattribute " > <nl> < / activity > <nl> - < ! - - <nl> < service <nl> android : name = " . backgroundplayer " <nl> - android : label = " newpipe background player " <nl> - android : exported = " false " > <nl> - < / service > <nl> + android : label = " @ string / background_player_name " <nl> + android : exported = " false " / > <nl> < activity <nl> android : name = " . settingsactivity " <nl> android : label = " @ string / title_activity_settings " > <nl> mmm a / app / src / main / res / layout / paginate_footer . xml <nl> ppp b / app / src / main / res / layout / paginate_footer . xml <nl>
public class backgroundplayer extends service / * implements mediaplayer . onprepare <nl> stopforeground ( true ) ; / / remove foreground status of service ; make us killable <nl>  <nl> stopself ( ) ; <nl> - <nl> } <nl>  <nl> private class endlistener implements mediaplayer . oncompletionlistener {
public class backgroundplayer extends service / * implements mediaplayer . onprepare <nl> @ override <nl> public void ondestroy ( ) { <nl> / / toast . maketext ( this , " service done " , toast . length_short ) . show ( ) ; <nl> - / / mservicelooper . quit ( ) ; <nl> - / / if ( mmediaplayer ! = null ) mmediaplayer . release ( ) ; <nl> - <nl> } <nl>  <nl> private class playerthread extends thread { <nl> - <nl> private mediaplayer mediaplayer ; <nl> private string source ; <nl> private string title ; <nl>
public class videoitemdetailfragment extends fragment { <nl> thumbsupview . settext ( nf . format ( info . like_count ) ) ; <nl> thumbsdownview . settext ( nf . format ( info . dislike_count ) ) ; <nl>  <nl> - / / this is horribly convoluted <nl> - <nl> - / / suggestions are welcome <nl> - int year = integer . parseint ( info . upload_date . substring ( 0 , num ) ) ; <nl> - int month = integer . parseint ( info . upload_date . substring ( 5 , num ) ) ; <nl> - int date = integer . parseint ( info . upload_date . substring ( 8 , num ) ) ; <nl> - calendar cal = calendar . getinstance ( ) ; <nl> - cal . set ( year , month , date ) ; <nl> - date datum = cal . gettime ( ) ; <nl> + simpledateformat formatter = new simpledateformat ( " yyyy - mm - dd " ) ; <nl> + date datum = null ; <nl> + try { <nl> + datum = formatter . parse ( info . upload_date ) ; <nl> + } catch ( parseexception e ) { <nl> + e . printstacktrace ( ) ; <nl> + } <nl> + <nl> dateformat df = dateformat . getdateinstance ( dateformat . medium , locale ) ; <nl>  <nl> string localiseddate = df . format ( datum ) ;
public class videoitemlistactivity extends appcompatactivity <nl> bundle arguments = getintent ( ) . getextras ( ) ; <nl>  <nl> if ( arguments ! = null ) { <nl> - parcelable [ ] p = arguments . getparcelablearray ( video_info_items ) ; <nl> + / / parcelable [ ] p = arguments . getparcelablearray ( video_info_items ) ; <nl> + arraylist < videoinfoitem > p = arguments . getparcelablearraylist ( video_info_items ) ; <nl> if ( p ! = null ) { <nl> mode = present_videos_mode ; <nl> getsupportactionbar ( ) . setdisplayhomeasupenabled ( true ) ; <nl>  <nl> - <nl> - listfragment . present ( arrays . copyof ( p , p . length , videoinfoitem [ ] . class ) ) ; <nl> + listfragment . present ( p ) ; <nl> } <nl> } <nl>  <nl> mmm a / app / src / main / java / org / schabi / newpipe / videoitemlistfragment . java <nl> ppp b / app / src / main / java / org / schabi / newpipe / videoitemlistfragment . java <nl>
public class videoitemlistfragment extends listfragment { <nl> } <nl> } <nl>  <nl> - public void present ( videoinfoitem [ ] videolist ) { <nl> + public void present ( list < videoinfoitem > videolist ) { <nl> mode = present_videos_mode ; <nl> setlistshown ( true ) ; <nl> getlistview ( ) . smoothscrolltoposition ( 0 ) ; <nl>  <nl> - / / inefficient like hell i know ( welcome to the world of java ) <nl> - <nl> - updatelist ( new vector < > ( arrays . aslist ( videolist ) ) ) ; <nl> + updatelist ( videolist ) ; <nl> } <nl>  <nl> public void search ( string query ) { <nl>
public class actionbarhandler { <nl> } <nl>  <nl> public void setstreams ( videoinfo . stream [ ] streams ) { <nl> - / / <nl> this . streams = streams ; <nl> selectedstream = num ; <nl> string [ ] itemarray = new string [ streams . length ] ; <nl> + string defaultresolution = preferencemanager . getdefaultsharedpreferences ( context ) <nl> + . getstring ( context . getstring ( r . string . defaultresolutionpreference ) , <nl> + context . getstring ( r . string . defaultresolutionlistitem ) ) ; <nl> + int defaultresolutionpos = num ; <nl> + <nl> for ( int i = num ; i < streams . length ; i + + ) { <nl> itemarray [ i ] = streams [ i ] . format + " " + streams [ i ] . resolution ; <nl> + if ( defaultresolution . equals ( streams [ i ] . resolution ) ) { <nl> + defaultresolutionpos = i ; <nl> + } <nl> } <nl>  <nl> arrayadapter < string > itemadapter = new arrayadapter < string > ( activity . getbasecontext ( ) , <nl> android . r . layout . simple_spinner_dropdown_item , itemarray ) ; <nl> if ( activity ! = null ) { <nl> - activity . getsupportactionbar ( ) . setlistnavigationcallbacks ( itemadapter <nl> + actionbar ab = activity . getsupportactionbar ( ) ; <nl> + ab . setlistnavigationcallbacks ( itemadapter <nl> , new foramatitemselectlistener ( ) ) ; <nl> + ab . setselectednavigationitem ( defaultresolutionpos ) ; <nl> } <nl> } <nl>  <nl>
public class cachedatatest { <nl>  <nl> assert . assertequals ( 123 , cachedata1 . gettaskid ( ) ) ; <nl> assert . asserttrue ( cachedata1 . issyncwithserver ( ) ) ; <nl> - <nl> - / / assert . assertfalse ( " 123 " , cachedata1 . gettype ( ) ) ; <nl> + assert . assertequals ( " 123 " , cachedata1 . gettype ( ) ) ; <nl> assert . asserttrue ( cachedata1 . isuselocalconfiginfo ( ) ) ; <nl> assert . assertequals ( timestamp , cachedata1 . getlastmodifiedts ( ) . longvalue ( ) ) ; <nl> assert . assertequals ( timestamp , cachedata1 . getlocalconfiginfoversion ( ) ) ;
public class configrequesttest { <nl> assert . assertequals ( group , configrequest . getgroup ( ) ) ; <nl> assert . assertequals ( tenant , configrequest . gettenant ( ) ) ; <nl> assert . assertequals ( content , configrequest . getcontent ( ) ) ; <nl> - <nl> - / / assert . assertequals ( type , configrequest . gettype ( ) ) ; <nl> + assert . assertequals ( type , configrequest . gettype ( ) ) ; <nl>  <nl> } <nl>  <nl>
public class healthcheckerfactory { <nl> try { <nl> return mapper . readvalue ( jsonstring , abstracthealthchecker . class ) ; <nl> } catch ( ioexception e ) { <nl> - <nl> - throw new runtimeexception ( " deserialize health checker from json failed " , e ) ; <nl> + throw new nacosdeserializationexception ( abstracthealthchecker . class , e ) ; <nl> } <nl> } <nl>  <nl>
public class healthcheckerfactory { <nl> try { <nl> return mapper . writevalueasstring ( healthchecker ) ; <nl> } catch ( jsonprocessingexception e ) { <nl> - <nl> - throw new runtimeexception ( " serialize health checker to json failed " , e ) ; <nl> + throw new nacosserializationexception ( healthchecker . getclass ( ) , e ) ; <nl> } <nl> } <nl> }
import java . util . optional ; <nl> / * * <nl> * the manager to globally refresh and operate server list . <nl> * <nl> - * <nl> - * <nl> * @ author nkorange <nl> * @ since num . 0 . 0 <nl> - * @ deprecated num . 3 . 0 <nl> + * @ deprecated num . 3 . 0 this object will be deleted sometime after version num . 3 . 0 <nl> * / <nl> @ component ( " serverlistmanager " ) <nl> public class serverlistmanager implements memberchangelistener { <nl> mmm a / naming / src / main / java / com / alibaba / nacos / naming / controllers / operatorcontroller . java <nl> ppp b / naming / src / main / java / com / alibaba / nacos / naming / controllers / operatorcontroller . java <nl>
public class operatorcontroller { <nl> / * * <nl> * this interface will be removed in a future release <nl> * <nl> - * <nl> - * <nl> - * @ deprecated num . 3 . 0 <nl> + * @ deprecated num . 3 . 0 this function will be deleted sometime after version num . 3 . 0 <nl> * @ param serverstatus server status <nl> * @ return " ok " <nl> * / <nl>
public class operatorcontroller { <nl> / * * <nl> * this interface will be removed in a future release <nl> * <nl> - * <nl> - * <nl> - * @ deprecated num . 3 . 0 <nl> + * @ deprecated num . 3 . 0 this function will be deleted sometime after version num . 3 . 0 <nl> * @ return { @ link jsonnode } <nl> * / <nl> @ deprecated <nl> mmm a / naming / src / main / java / com / alibaba / nacos / naming / misc / serverstatussynchronizer . java <nl> ppp b / naming / src / main / java / com / alibaba / nacos / naming / misc / serverstatussynchronizer . java <nl>
public class namingproxy { <nl> return stringutils . empty ; <nl> } <nl>  <nl> - <nl> - if ( constants . write_redirect_code = = result . code ) { <nl> - logutils . log . info ( " redirect to " + result . content ) ; <nl> - return callserver ( api , params , result . content , method ) ; <nl> - } <nl> - <nl> logutils . log . error ( " call - server " , " failed to req api : " + httpclient . getprefix ( ) + curserver <nl> + api + " . code : " <nl> + result . code + " msg : " + result . content ) ; <nl> mmm a / naming / src / main / java / com / alibaba / nacos / naming / web / distrofilter . java <nl> ppp b / naming / src / main / java / com / alibaba / nacos / naming / web / distrofilter . java <nl>
public class distrofilter implements filter { <nl> throw new nosuchmethodexception ( req . getmethod ( ) + " " + path ) ; <nl> } <nl>  <nl> + / / proxy request to other server if necessary : <nl> if ( method . isannotationpresent ( candistro . class ) & & ! distromapper . responsible ( servicename ) ) { <nl>  <nl> - <nl> - string url = " http : / / " + distromapper . mapsrv ( servicename ) + <nl> - req . getrequesturi ( ) + " ? " + req . getquerystring ( ) ; <nl> + list < string > headerlist = new arraylist < > ( 16 ) ; <nl> + enumeration < string > headers = req . getheadernames ( ) ; <nl> + while ( headers . hasmoreelements ( ) ) { <nl> + string headername = headers . nextelement ( ) ; <nl> + headerlist . add ( headername ) ; <nl> + headerlist . add ( req . getheader ( headername ) ) ; <nl> + } <nl> + httpclient . httpresult result = <nl> + httpclient . request ( distromapper . mapsrv ( servicename ) + urlstring , headerlist , new hashmap < > ( 2 ) <nl> + , proxy_connect_timeout , proxy_read_timeout , " utf - 8 " , req . getmethod ( ) ) ; <nl> + <nl> try { <nl> - resp . setcharacterencoding ( " utf - 8 " ) ; <nl> - resp . getwriter ( ) . write ( distromapper . mapsrv ( servicename ) ) ; <nl> - resp . setstatus ( httpservletresponse . sc_temporary_redirect ) ; <nl> + resp . setcharacterencoding ( " utf - 8 " ) ; <nl> + resp . getwriter ( ) . write ( result . content ) ; <nl> + resp . setstatus ( result . code ) ; <nl> } catch ( exception ignore ) { <nl> - loggers . srv_log . warn ( " [ distro - filter ] request failed : " + url ) ; <nl> + loggers . srv_log . warn ( " [ distro - filter ] request failed : " + distromapper . mapsrv ( servicename ) + urlstring ) ; <nl> } <nl> return ; <nl> } <nl>  <nl> + / / user groupname @ @ servicename as new service name : <nl> string groupname = req . getparameter ( commonparams . group_name ) ; <nl> if ( stringutils . isblank ( groupname ) ) { <nl> groupname = utilsandcommons . default_group_name ;
nacos provides four major funcations . <nl> nacos provides an easy - to - use service dashboard to help you manage your services metadata , configuration , kubernetes dns , service health and metrics statistics . <nl>  <nl>  <nl> - # # quick start ( <nl> + # # # quick start <nl> it is super easy to get started with your first project . <nl>  <nl> - https : / / nacos . io / # / docs / quick - start . md <nl> + # # # # download run package <nl> + [ download ] ( http : / / nacos . oss - cn - hangzhou - zmf . aliyuncs . com / nacos - server - 0 . 1 . 0 . zip ) <nl> + > unzip nacos - all . zip <nl> + > cd nacos / bin <nl> + # # # # start server <nl> + # # # # # linux / unix / mac <nl> + <nl> + run the following command to sart ( standalone means non - cluster mode ) : <nl> + <nl> + ` sh startup . sh - m standalone ` <nl> + <nl> + # # # # # windows <nl> + run the following command to start : <nl> + <nl> + ` cmd startup . cmd ` <nl> + <nl> + or double - click the startup . cmd to run nacosserver . <nl> + <nl> + you can see detail in https : / / nacos . io / # / docs / quick - start . md <nl>  <nl> quick start for other open - source projects : <nl>  <nl>
public abstract class observable < t > implements observablesource < t > { <nl> * / <nl> @ schedulersupport ( schedulersupport . none ) <nl> public final observable < t > hide ( ) { <nl> - <nl> - return new observablefromunsafesource < t > ( this ) ; <nl> + return new observablehide < t > ( this ) ; <nl> } <nl>  <nl> / * * <nl> mmm / dev / null <nl> ppp b / src / main / java / io / reactivex / internal / operators / observable / observablehide . java <nl>
public class rxringbuffer implements subscription { <nl>  <nl> public static rxringbuffer getspscinstance ( ) { <nl> if ( unsafeaccess . isunsafeavailable ( ) ) { <nl> - <nl> return new rxringbuffer ( spsc_pool , size ) ; <nl> } else { <nl> return new rxringbuffer ( ) ; <nl>
public class operatormerge < t > implements operator < t , observable < ? extends t > > { <nl> * i ' d love to have contributions that improve this class , but keep in mind the performance and gc pressure . <nl> * the benchmarks i use are in the jmh operatormergeperf class . gc memory pressure is tested using java flight recorder <nl> * to track object allocation . <nl> - * <nl> - * <nl> - * see https : / / github . com / reactivex / rxjava / issues / 1420 for more information on this . <nl> * / <nl>  <nl> public operatormerge ( ) {
public class blockingoperatortoiterator { <nl> } <nl>  <nl> private notification < ? extends t > take ( ) { <nl> - try { <nl> - <nl> - notification < ? extends t > n = notifications . poll ( 10000 , timeunit . milliseconds ) ; <nl> - if ( n = = null ) { <nl> - system . err . println ( " timed out waiting for value . file a bug at github . com / netflix / rxjava " ) ; <nl> - throw new runtimeexception ( " timed out waiting for value . file a bug at github . com / netflix / rxjava " ) ; <nl> - } else { <nl> - return n ; <nl> - } <nl> - } catch ( interruptedexception e ) { <nl> - throw exceptions . propagate ( e ) ; <nl> - } <nl> + return notifications . poll ( ) ; <nl> } <nl>  <nl> @ override
class blockingobservable [ + t ] private [ scala ] ( val o : observable [ t ] ) <nl> } <nl> } <nl>  <nl> - <nl> - <nl> / * * <nl> * returns an { @ link iterator } that iterates over all items emitted by this { @ link observable } . <nl> * / <nl>
public class observable < t > { <nl> * @ see < a href = " https : / / github . com / netflix / rxjava / wiki / observable - utility - operators # wiki - parallel " > rxjava wiki : parallel ( ) < / a > <nl> * / <nl> public final < r > observable < r > parallel ( func1 < observable < t > , observable < r > > f ) { <nl> - <nl> - / / see https : / / github . com / netflix / rxjava / issues / 713 for why this was changed <nl> - return lift ( new operatorparallel < t , r > ( f , schedulers . newthread ( ) ) ) ; <nl> + return lift ( new operatorparallel < t , r > ( f , schedulers . computation ( ) ) ) ; <nl> } <nl>  <nl> / * *
subprojects { <nl> it . classpath = sourcesets . main . compileclasspath <nl> } <nl>  <nl> - sourcesets { <nl> - / / include / src / examples folder <nl> + sourcesets { <nl> examples <nl> - / / include / src / perf folder <nl> - perf { <nl> - java { <nl> - srcdir ' src / perf / java ' <nl> - compileclasspath + = main . output <nl> - runtimeclasspath + = main . output <nl> - } <nl> - } <nl> - } <nl> - <nl> - dependencies { <nl> - perfcompile ' org . openjdk . jmh : jmh - core : 0 . 2 ' <nl> + perf <nl> } <nl>  <nl> tasks . build { <nl> - / / include ' examples ' in build task <nl> + / / include ' examples ' in build task <nl> dependson ( examplesclasses ) <nl> - / / include ' perf ' in build task <nl> - / / dependson ( perfclasses ) / / - > not working so commented out <nl> + } <nl> + <nl> + dependencies { <nl> + perfcompile ' org . openjdk . jmh : jmh - core : 0 . 5 . 3 ' <nl> + perfcompile ' org . openjdk . jmh : jmh - generator - annprocess : 0 . 5 . 3 ' <nl> + <nl> + perfcompile project <nl> } <nl>  <nl> eclipse { <nl> - classpath { <nl> - / / include ' provided ' dependencies on the classpath <nl> - plusconfigurations + = configurations . provided <nl> + classpath { <nl> plusconfigurations + = configurations . perfcompile <nl>  <nl> downloadsources = true <nl> downloadjavadoc = true <nl> } <nl> } <nl> - <nl> + <nl> idea { <nl> module { <nl> - / / include ' provided ' dependencies on the classpath <nl> - scopes . provided . plus + = configurations . provided <nl> - <nl> - / / scopes . provided . plus + = configurations . perfcompile <nl> + scopes . provided . plus + = configurations . perfcompile <nl> + scopes . provided . minus + = configurations . compile <nl> + } <nl> + } <nl> + <nl> + task perfjar ( type : jar , dependson : perfclasses ) { <nl> + from sourcesets . perf . output + sourcesets . main . output <nl> + } <nl> + <nl> + task benchmarks ( dependson : perfjar ) { <nl> + <nl> + apply plugin : " shadow " <nl> + <nl> + shadow { <nl> + classifier = " benchmarks " <nl> + includedependenciesfor = [ " runtime " , " perfruntime " ] <nl> + <nl> + transformer ( com . github . jengelman . gradle . plugins . shadow . transformers . manifestresourcetransformer ) { <nl> + mainclass = " org . openjdk . jmh . main " <nl> + } <nl> } <nl> + <nl> + dolast { <nl> + shadowjar . execute ( ) <nl> + } <nl> + <nl> } <nl> } <nl>  <nl> mmm a / rxjava - core / build . gradle <nl> ppp b / rxjava - core / build . gradle <nl>
<nl> " <nl> ( [ key - fn ^ observable xs ] <nl> ( - > > ( . groupby xs ( iop / fn * key - fn ) ) <nl> - ( map ( fn [ ^ groupedobservable go ] <nl> - ( clojure . lang . mapentry . ( . getkey go ) go ) ) ) ) ) <nl> - ( [ key - fn val - fn ^ observable xs ] <nl> - ; <nl> - ; see https : / / github . com / netflix / rxjava / commit / <commit_id> <nl> - ( throw ( unsupportedoperationexception . " groupby with val - fn is currently unimplemented in rxjava " ) ) <nl> - ( - > > ( . groupby xs <nl> - ( iop / fn * key - fn ) <nl> - ( iop / fn * val - fn ) ) <nl> ( map ( fn [ ^ groupedobservable go ] <nl> ( clojure . lang . mapentry . ( . getkey go ) go ) ) ) ) ) )
<nl> ( [ ^ observable xs <nl> ( . elementatordefault xs <nl>  <nl> - ; <nl> + ( defn ^ observable partition - all <nl> + " returns an observable of observables of n items each , at offsets step <nl> + apart . if step is not supplied , defaults to n , i . e . the partitions <nl> + do not overlap . may include partitions with fewer than n items at the end . <nl> + <nl> + see : <nl> + clojure . core / partition - all <nl> + rx . observable / window <nl> + " <nl> + ( [ n ^ observable xs ] ( . window xs ( int n ) ) ) <nl> + ( [ n step ^ observable xs ] ( . window xs ( int n ) ( int step ) ) ) ) <nl>  <nl> ( defn ^ observable reduce <nl> ( [ f ^ observable xs ] ( . reduce xs ( iop / fn * f ) ) ) <nl> mmm a / language - adaptors / rxjava - clojure / src / test / clojure / rx / lang / clojure / core_test . clj <nl> ppp b / language - adaptors / rxjava - clojure / src / test / clojure / rx / lang / clojure / core_test . clj <nl>
package object util { <nl> def closing ( ) = rx . util . closings . create ( ) <nl>  <nl> / / rx . util . range not needed because there ' s a standard scala range <nl> - <nl> - class timestamped [ + t ] ( val asjava : rx . util . timestamped [ _ < : t ] ) { } <nl> - <nl> - <nl> - object timestampedobject { <nl> - def apply [ t ] ( timestampmillis : long , value : t ) : timestamped [ t ] = { <nl> - new timestamped ( new rx . util . timestamped ( timestampmillis , value ) ) <nl> - } <nl> - <nl> - def apply [ t ] ( asjava : rx . util . timestamped [ _ < : t ] ) : timestamped [ t ] = { <nl> - new timestamped ( asjava ) <nl> - } <nl> - <nl> - def unapply [ t ] ( v : timestamped [ t ] ) : option [ ( long , t ) ] = unapply ( v . asjava ) <nl> - <nl> - def unapply [ t ] ( v : rx . util . timestamped [ _ < : t ] ) : option [ ( long , t ) ] = { <nl> - some ( ( v . gettimestampmillis , v . getvalue ) ) <nl> - } <nl> - } <nl>  <nl> } <nl> \ no newline at end of file
class rxscalademo extends junitsuite { <nl> } <nl>  <nl> @ test def testtwosubscriptionstooneinterval ( ) { <nl> - <nl> val o = observable . interval ( 100 millis ) . take ( 8 ) <nl> o . subscribe ( <nl> i = > println ( s " $ { i } a ( on thread # $ { thread . currentthread ( ) . getid ( ) } ) " ) <nl>
class rxscalademo extends junitsuite { <nl> val t = for ( ( i , o ) < - g ; n < - o ) yield n <nl> assertequals ( list ( 0 , num , num , num ) , t . toblockingobservable . tolist ) <nl> } <nl> - <nl> - @ test def groupbyexampletest ( ) { <nl> - val medalsbycountry = olympics . mountainbikemedals . groupby ( medal = > medal . country ) <nl> - <nl> - val firstmedalofeachcountry = <nl> - medalsbycountry . flatmap ( ( p : ( string , observable [ olympics . medal ] ) ) = > p . _2 . take ( 1 ) ) <nl> - <nl> - firstmedalofeachcountry . subscribe ( medal = > { <nl> - println ( s " $ { medal . country } wins its first medal in $ { medal . year } " ) <nl> - } ) <nl> - <nl> - / / waitfor ( firstmedalofeachcountry ) <nl> - thread . sleep ( 20000 ) <nl> - } <nl> - <nl> - @ ignore <nl> + <nl> @ test def groupbyexample ( ) { <nl> val medalsbycountry = olympics . mountainbikemedals . groupby ( medal = > medal . country )
object observable { <nl> * @ see < a href = " http : / / msdn . microsoft . com / en - us / library / hh229099 ( v = vs . 103 ) . aspx " > msdn : observable . merge method < / a > <nl> * / <nl> / / public static < t > observable < t > merge ( observable < ? extends observable < ? extends t > > source ) <nl> - <nl>  <nl> / * * <nl> * flattens a series of observables into one observable , without any transformation . <nl> mmm a / language - adaptors / rxjava - scala / src / main / scala / rx / lang / scalatests / rxscalademo . scala <nl> ppp b / language - adaptors / rxjava - scala / src / main / scala / rx / lang / scalatests / rxscalademo . scala <nl>
public final class operationconcat { <nl>  <nl> } <nl>  <nl> - @ test <nl> - public void testconcatconcurrentwithinfinityfirstsequence ( ) { <nl> - final testobservable < string > w1 = new testobservable < string > ( " one " , " two " , " three " ) ; <nl> - / / this observable will send " hello " max_value time . <nl> - final testobservable < string > w2 = new testobservable < string > ( " hello " , integer . max_value ) ; <nl> - <nl> - @ suppresswarnings ( " unchecked " ) <nl> - observer < string > aobserver = mock ( observer . class ) ; <nl> - @ suppresswarnings ( " unchecked " ) <nl> - testobservable < observable < string > > observableofobservables = new testobservable < observable < string > > ( w2 , w1 ) ; <nl> - func1 < observer < string > , subscription > concatf = concat ( observableofobservables ) ; <nl> - <nl> - observable < string > concat = observable . create ( concatf ) ; <nl> - <nl> - concat . take ( 50 ) . subscribe ( aobserver ) ; <nl> - <nl> - / / wait for the thread to start up . <nl> - try { <nl> - thread . sleep ( 25 ) ; <nl> - w2 . t . join ( ) ; <nl> - } catch ( interruptedexception e ) { <nl> - <nl> - e . printstacktrace ( ) ; <nl> - } <nl> - <nl> - inorder inorder = inorder ( aobserver ) ; <nl> - inorder . verify ( aobserver , times ( 50 ) ) . onnext ( " hello " ) ; <nl> - verify ( aobserver , times ( 1 ) ) . oncompleted ( ) ; <nl> - verify ( aobserver , never ( ) ) . onerror ( any ( exception . class ) ) ; <nl> - <nl> - } <nl> - <nl>  <nl> / * * <nl> * test unsubscribing the concatenated observable in a single thread .
import rx . util . functions . func0 ; <nl> import java . util . concurrent . scheduledexecutorservice ; <nl> import java . util . concurrent . timeunit ; <nl>  <nl> - <nl> public class scheduledexecutorservicescheduler extends abstractscheduler { <nl> private final scheduledexecutorservice executorservice ;
public class rocketmqmessagechannelbinder extends <nl> string group , <nl> extendedconsumerproperties < rocketmqconsumerproperties > extendedconsumerproperties ) <nl> throws exception { <nl> - <nl> - if ( ! stringutils . haslength ( group ) ) { <nl> + boolean anonymous = ! stringutils . haslength ( group ) ; <nl> + / * * * <nl> + * when using dlq , at least the group property must be provided for proper naming of the dlq destination <nl> + * according to https : / / docs . spring . io / spring - cloud - stream / docs / 3 . 2 . 1 / reference / html / spring - cloud - stream . html # spring - cloud - stream - reference <nl> + * / <nl> + if ( anonymous & & namespaceutil . isdlqtopic ( destination . getname ( ) ) ) { <nl> throw new runtimeexception ( <nl> - " ' group must be configured for channel " + destination . getname ( ) ) ; <nl> + " group must be configured for dlq " + destination . getname ( ) ) ; <nl> } <nl> + group = anonymous ? nextdefaultconsumergroup ( ) : group ; <nl> + <nl> rocketmqutils . mergerocketmqproperties ( binderconfigurationproperties , <nl> extendedconsumerproperties . getextension ( ) ) ; <nl> extendedconsumerproperties . getextension ( ) . setgroup ( group ) ; <nl>
<nl> < artifactid > rocketmq - spring - boot - starter < / artifactid > <nl> < version > $ { rocketmq . starter . version } < / version > <nl> < / dependency > <nl> - <nl> - < ! - - <nl> - <nl> - check it every times , whern spring - boot - starter - webflux : 2 . 2 . 4 . release or spring - cloud - gateway - core : 2 . 2 . 2 . release has bean upgrade <nl> - due to spring - cloud - build : 2 . 2 . 2 . release has not support spring - cloud - gateway - dependencies : 2 . 2 . 2 . release very well <nl> - it cource some compatibility problem between reactornettywebsocketclient and gatewayautoconfiguration <nl> - - - > <nl> - < dependency > <nl> - < groupid > org . springframework < / groupid > <nl> - < artifactid > spring - web < / artifactid > <nl> - < version > 5 . 2 . 4 . release < / version > <nl> - < / dependency > <nl> - < dependency > <nl> - < groupid > org . springframework < / groupid > <nl> - < artifactid > spring - webflux < / artifactid > <nl> - < version > 5 . 2 . 4 . release < / version > <nl> - < scope > compile < / scope > <nl> - < / dependency > <nl> < / dependencies > <nl> < / dependencymanagement >
export class urlroutemanagerservice { <nl> ] ) ; <nl> } <nl>  <nl> - movepageonsidebar ( rootroute : string ) : void { <nl> - <nl> - const pageurlinfo = this . newurlstatenotificationservice . getpageurlinfo ( rootroute ) ; <nl> + movetoappmenu ( rootroute : string ) : void { <nl> + / * * <nl> + * navigation flow <nl> + * num . from hostmenu to appmenu : navigate to the last url state <nl> + * num . from appmenu to appmenu : keep the every state ( app , period , endtime ) <nl> + * num . from appmenu to appmenu in realtime : keep the app state with the default period , endtime <nl> + * / <nl> + const urlservice = this . newurlstatenotificationservice ; <nl> + const pageurlinfo = urlservice . getpageurlinfo ( rootroute ) ; <nl> + <nl> + if ( urlservice . hasvalue ( urlpathid . application ) ) { <nl> + const isrealtimemode = urlservice . isrealtimemode ( ) <nl> + const app = urlservice . getpathvalue ( urlpathid . application ) as iapplication ; <nl> + const period = urlservice . getpathvalue ( urlpathid . period ) as period ; <nl> + const endtime = urlservice . getpathvalue ( urlpathid . end_time ) as endtime ; <nl> + <nl> + if ( isrealtimemode ) { <nl> + this . router . navigate ( [ <nl> + rootroute , <nl> + app . geturlstr ( ) <nl> + ] ) ; <nl> + } else { <nl> + this . router . navigate ( [ <nl> + rootroute , <nl> + app . geturlstr ( ) , <nl> + period . getvaluewithtime ( ) , <nl> + endtime . getendtime ( ) <nl> + ] ) ; <nl> + } <nl> + } else if ( pageurlinfo ) { <nl> + this . router . navigate ( [ <nl> + rootroute , <nl> + . . . pageurlinfo . pathparams . values ( ) <nl> + ] ) ; <nl> + } else { <nl> + this . router . navigate ( [ <nl> + rootroute <nl> + ] ) ; <nl> + } <nl> + } <nl> + <nl> + movetohostmenu ( rootroute : string ) : void { <nl> + const urlservice = this . newurlstatenotificationservice ; <nl> + const pageurlinfo = urlservice . getpageurlinfo ( rootroute ) ; <nl>  <nl> if ( ! pageurlinfo ) { <nl> this . router . navigate ( [
export class hostgroupandhostlistcontainercomponent implements oninit , ondestroy <nl> private translatereplaceservice : translatereplaceservice , <nl> ) { } <nl>  <nl> - <nl> ngoninit ( ) { <nl> this . initi18ntext ( ) ; <nl> this . newurlstatenotificationservice . onurlstatechange $ . pipe ( <nl> - filter ( ( urlservice : newurlstatenotificationservice ) = > urlservice . hasvalue ( urlpathid . host_group ) & & urlservice . isvaluechanged ( urlpathid . host_group ) ) , <nl> + filter ( ( urlservice : newurlstatenotificationservice ) = > urlservice . hasvalue ( urlpathid . host_group ) & & ( urlservice . isvaluechanged ( urlpathid . host_group ) | | ! urlservice . hasvalue ( urlpathid . host ) ) ) , <nl> map ( ( urlservice : newurlstatenotificationservice ) = > urlservice . getpathvalue ( urlpathid . host_group ) ) , <nl> tap ( ( hostgroup : string ) = > this . selectedhostgroup = hostgroup ) , <nl> switchmap ( ( hostgroup : string ) = > this . hostgroupandhostlistdataservice . gethostlist ( hostgroup ) . pipe ( <nl> mmm a / web / src / main / angular / src / app / core / components / period - selector / period - selector - container . component . ts <nl> ppp b / web / src / main / angular / src / app / core / components / period - selector / period - selector - container . component . ts <nl>
export class periodselectorcontainercomponent implements oninit , ondestroy { <nl> } else { <nl> this . analyticsservice . trackevent ( tracked_event_list . select_period , selectedperiod ) ; <nl>  <nl> - <nl> - / / const tree = this . router . parseurl ( this . router . url ) ; <nl> - / / const g = tree . root . children [ primary_outlet ] ; <nl> - / / const s = g . segments ; <nl> + const secondpath = this . newurlstatenotificationservice . hasvalue ( urlpathid . application ) <nl> + ? this . newurlstatenotificationservice . getpathvalue ( urlpathid . application ) . geturlstr ( ) <nl> + : this . newurlstatenotificationservice . getpathvalue ( urlpathid . host_group ) ; <nl> + const lastpath = this . newurlstatenotificationservice . getpathvalue ( urlpathid . agent_id ) | | this . newurlstatenotificationservice . getpathvalue ( urlpathid . host ) ; <nl>  <nl> this . urlroutemanagerservice . move ( { <nl> url : [ <nl> this . newurlstatenotificationservice . getstartpath ( ) , <nl> - this . newurlstatenotificationservice . getpathvalue ( urlpathid . application ) . geturlstr ( ) , <nl> - / / this . router . url [ 1 ] , <nl> - / / s [ 1 ] . path , <nl> + secondpath , <nl> selectedperiod <nl> ] , <nl> needservertimerequest : true , <nl> - nexturl : this . newurlstatenotificationservice . hasvalue ( urlpathid . agent_id ) ? [ this . newurlstatenotificationservice . getpathvalue ( urlpathid . agent_id ) ] : [ ] <nl> - / / nexturl : s [ 4 ] ? [ s [ 4 ] . path ] : [ ] <nl> + nexturl : lastpath ? [ lastpath ] : [ ] <nl> } ) ; <nl> } <nl> } <nl>  <nl> onchangecalendartime ( ochangetime : any ) : void { <nl> this . analyticsservice . trackevent ( tracked_event_list . select_period , ochangetime . period . getvaluewithtime ( ) ) ; <nl> + <nl> + const secondpath = this . newurlstatenotificationservice . hasvalue ( urlpathid . application ) <nl> + ? this . newurlstatenotificationservice . getpathvalue ( urlpathid . application ) . geturlstr ( ) <nl> + : this . newurlstatenotificationservice . getpathvalue ( urlpathid . host_group ) ; <nl> + const lastpath = this . newurlstatenotificationservice . getpathvalue ( urlpathid . agent_id ) | | this . newurlstatenotificationservice . getpathvalue ( urlpathid . host ) ; <nl> + <nl> this . urlroutemanagerservice . move ( { <nl> url : [ <nl> this . newurlstatenotificationservice . getstartpath ( ) , <nl> - this . newurlstatenotificationservice . getpathvalue ( urlpathid . application ) . geturlstr ( ) , <nl> + secondpath , <nl> ochangetime . period . getvaluewithtime ( ) , <nl> ochangetime . endtime . getendtime ( ) <nl> ] , <nl> needservertimerequest : false , <nl> - nexturl : this . newurlstatenotificationservice . hasvalue ( urlpathid . agent_id ) ? [ this . newurlstatenotificationservice . getpathvalue ( urlpathid . agent_id ) ] : [ ] <nl> + nexturl : lastpath ? [ lastpath ] : [ ] <nl> } ) ; <nl> } <nl> }
import java . net . inetsocketaddress ; <nl> * / <nl> public final class socketaddressutils { <nl>  <nl> - private static final plogger logger = ploggerfactory . getlogger ( socketaddressutils . class ) ; <nl> - <nl> - <nl> - private static final hoststringaccessor host_string_accessor = createhoststringaccessor ( ) ; <nl> - <nl> - private static hoststringaccessor createhoststringaccessor ( ) { <nl> - try { <nl> - final method m = inetsocketaddress . class . getdeclaredmethod ( " gethoststring " ) ; <nl> - m . setaccessible ( true ) ; <nl> - return new reflectivehoststringaccessor ( m ) ; <nl> - } catch ( nosuchmethodexception e ) { <nl> - logger . error ( " [ { } ] { } - gethoststring ( ) not present in class inetsocketaddress . " , <nl> - jvmutils . gettype ( ) , jvmutils . getversion ( ) ) ; <nl> - throw new illegalstateexception ( " unexpected inetsocketaddress class " , e ) ; <nl> - } <nl> - } <nl> - <nl> - private interface hoststringaccessor { <nl> - string gethoststring ( inetsocketaddress inetsocketaddress ) ; <nl> - } <nl> - <nl> - private static class reflectivehoststringaccessor implements hoststringaccessor { <nl> - <nl> - private final plogger logger = ploggerfactory . getlogger ( this . getclass ( ) ) ; <nl> - <nl> - private final method method ; <nl> - <nl> - private reflectivehoststringaccessor ( method method ) { <nl> - if ( method = = null ) { <nl> - throw new nullpointerexception ( " method " ) ; <nl> - } <nl> - this . method = method ; <nl> - } <nl> - <nl> - @ override <nl> - public string gethoststring ( inetsocketaddress inetsocketaddress ) { <nl> - try { <nl> - return ( string ) method . invoke ( inetsocketaddress ) ; <nl> - } catch ( illegalaccessexception e ) { <nl> - logger . error ( " [ { } ] { } - cannot access method : { } " , <nl> - jvmutils . gettype ( ) , jvmutils . getversion ( ) , method . getname ( ) , e ) ; <nl> - } catch ( invocationtargetexception e ) { <nl> - logger . error ( " [ { } ] { } - error invoking method : { } " , <nl> - jvmutils . gettype ( ) , jvmutils . getversion ( ) , method . getname ( ) , e ) ; <nl> - } catch ( exception e ) { <nl> - logger . error ( " [ { } ] { } - unexpected error retrieving hoststring " , <nl> - jvmutils . gettype ( ) , jvmutils . getversion ( ) , e ) ; <nl> - } <nl> - return null ; <nl> - } <nl> - } <nl> - <nl> private socketaddressutils ( ) { } <nl>  <nl> / * * <nl>
export class scatterchartcontainercomponent implements oninit , ondestroy { <nl> / / visible <nl> visibility $ . pipe ( <nl> filter ( ( ) = > ! document . hidden ) , <nl> + filter ( ( ) = > ! this . scatterchartdataservice . isconnected ( ) ) <nl> ) . subscribe ( ( ) = > { <nl> - <nl> this . getscatterdata ( ) ; <nl> } ) ; <nl>  <nl> mmm a / web / src / main / angular / src / app / core / components / scatter - chart / scatter - chart - data . service . ts <nl> ppp b / web / src / main / angular / src / app / core / components / scatter - chart / scatter - chart - data . service . ts <nl>
public class apachedubboproviderinterceptor extends spanrecursivearoundintercept <nl> logger . debug ( " localhost = = null & & rpccontextlocalhost = = null " ) ; <nl> return null ; <nl> } <nl> - if ( localhost = = null & & rpccontextlocalhost ! = null ) { <nl> + if ( localhost = = null ) { <nl> logger . debug ( " return rpccontextlocalhost : { } " , rpccontextlocalhost ) ; <nl> return rpccontextlocalhost ; <nl> } <nl> - <nl> if ( localhost . equals ( rpccontextlocalhost ) ) { <nl> - return rpccontextlocalhost ; <nl> + return rpccontext . getlocaladdressstring ( ) ; <nl> } else { <nl> - return localhost + " : " + rpccontextlocalhost ; <nl> + return localhost + " : " + rpccontext . getlocalport ( ) ; <nl> } <nl> }
public class defaultprofilerconfig implements profilerconfig { <nl>  <nl> / / for test <nl> void readpropertyvalues ( ) { <nl> - <nl> - final valueresolver placeholderresolver = new placeholderresolver ( ) ; <nl>  <nl> this . profileenable = readboolean ( " profiler . enable " , true ) ; <nl> this . profileinstrumentengine = readstring ( " profiler . instrument . engine " , instrument_engine_asm ) ;
export class configurationpopupcontainercomponent implements oninit , afterviewin <nl> } <nl>  <nl> onopengithub ( ) : void { <nl> - <nl> + this . windowrefservice . nativewindow . open ( ' http : / / github . com / naver / pinpoint ' ) ; <nl> this . outclose . emit ( ) ; <nl> }
public class wrappedspaneventrecorder extends abstractrecorder implements spanev <nl> final spanevent spanevent = this . spanevent ; <nl> final traceroot traceroot = spanevent . gettraceroot ( ) ; <nl> final asynccontext asynccontext = asynccontextfactory . newasynccontext ( traceroot ) ; <nl> - <nl> - spanevent . setnextasyncid ( asynccontext . getasyncid ( ) ) ; <nl> + setnextasyncid ( spanevent , asynccontext . getasyncid ( ) ) ; <nl> return asynccontext ; <nl> } <nl>  <nl>
final class methoddescriptionutils { <nl> if ( classendindex ! = - 1 ) { <nl> return parametertype . substring ( 0 , classendindex ) ; <nl> } <nl> - / / else { <nl> - / / <nl> - / / throw new illegalargumentexception ( " parameter variable name not found " + parametertype ) ; <nl> - / / } <nl> return parametertype ; <nl> } <nl>  <nl> mmm a / profiler / src / main / java / com / navercorp / pinpoint / test / plugintestagent . java <nl> ppp b / profiler / src / main / java / com / navercorp / pinpoint / test / plugintestagent . java <nl>
public class mocktracecontext implements tracecontext { <nl> return null ; <nl> } <nl>  <nl> - @ override <nl> - public void attachtraceobject ( trace trace ) { <nl> - } <nl> - <nl> @ override <nl> public trace continueasynctraceobject ( traceid traceid , int asyncid , long starttime ) { <nl> - <nl> return null ; <nl> } <nl>  <nl>
public class javaassistclasstest { <nl>  <nl> @ test <nl> public void testaddafterinterceptor ( ) throws exception { <nl> - <nl> - <nl>  <nl> final testclassloader loader = gettestclassloader ( ) ; <nl> final string testclassobject = " com . navercorp . pinpoint . profiler . interceptor . bci . testobject2 " ; <nl>
public class executemethodinterceptor implements staticaroundinterceptor { <nl> @ override <nl> public void before ( object target , string classname , string methodname , object [ ] args ) { <nl> system . out . println ( " \n\n\n\nhttp before " ) ; <nl> - <nl> + <nl> httphost host = ( httphost ) args [ 0 ] ; <nl> httprequest request = ( httprequest ) args [ 1 ] ; <nl>  <nl> - system . out . println ( arrays . tostring ( request . getallheaders ( ) ) ) ; <nl> + request . addheader ( header . http_trace_id . tostring ( ) , trace . gettraceid ( ) . gettraceid ( ) ) ; <nl> + request . addheader ( header . http_span_id . tostring ( ) , trace . gettraceid ( ) . getspanid ( ) ) ; <nl> + request . addheader ( header . http_parent_span_id . tostring ( ) , trace . gettraceid ( ) . getparentspanid ( ) ) ; <nl> + request . addheader ( header . http_sampled . tostring ( ) , string . valueof ( trace . gettraceid ( ) . issampled ( ) ) ) ; <nl> + request . addheader ( header . http_flags . tostring ( ) , string . valueof ( trace . gettraceid ( ) . getflags ( ) ) ) ; <nl>  <nl> trace . recordrpcname ( " http - call " , " " ) ; <nl> trace . recordserveraddr ( host . gethostname ( ) , host . getport ( ) ) ; <nl> trace . record ( " http . uri = " + request . tostring ( ) ) ; <nl> trace . record ( new annotation . clientsend ( ) ) ; <nl> - <nl>  <nl> stopwatch . start ( " executemethodinterceptor " ) ; <nl> } <nl> mmm a / src / main / java / com / profiler / modifier / tomcat / interceptors / invokemethodinterceptor . java <nl> ppp b / src / main / java / com / profiler / modifier / tomcat / interceptors / invokemethodinterceptor . java <nl>
import org . checkerframework . checker . nullness . qual . monotonicnonnull ; <nl> checkargument ( inputheight > num , " inputheight must be positive " ) ; <nl>  <nl> size = new size ( inputwidth , inputheight ) ; <nl> - <nl> - / / expected in the code . <nl> string vertexshaderfilepath = <nl> enableexperimentalhdrediting <nl> ? vertex_shader_tex_transform_es3_path <nl> mmm a / library / transformer / src / main / java / com / google / android / exoplayer2 / transformer / matrixtransformationframeprocessor . java <nl> ppp b / library / transformer / src / main / java / com / google / android / exoplayer2 / transformer / matrixtransformationframeprocessor . java <nl>
import org . checkerframework . checker . nullness . qual . monotonicnonnull ; <nl> checkargument ( inputheight > num , " inputheight must be positive " ) ; <nl>  <nl> outputsize = matrixtransformation . configure ( inputwidth , inputheight ) ; <nl> - <nl> - / / expected in the code . <nl> glprogram = new glprogram ( context , vertex_shader_transformation_path , fragment_shader_path ) ; <nl> glprogram . setsamplertexiduniform ( " utexsampler " , inputtexid , / * texunitindex = * / num ) ; <nl> / / draw the frame on the entire normalized device coordinate space , from - 1 to num , for x and y .
public final class c { <nl> @ intdef ( { spatialization_behavior_auto , spatialization_behavior_never } ) <nl> public @ interface spatializationbehavior { } <nl>  <nl> - <nl> - / / to num . <nl> - / * * see audioattributes # spatialization_behavior_auto * / <nl> - public static final int spatialization_behavior_auto = num ; <nl> - / * * see audioattributes # spatialization_behavior_never * / <nl> - public static final int spatialization_behavior_never = num ; <nl> + / * * <nl> + * @ see audioattributes # spatialization_behavior_auto <nl> + * / <nl> + public static final int spatialization_behavior_auto = <nl> + audioattributes . spatialization_behavior_auto ; <nl> + / * * <nl> + * @ see audioattributes # spatialization_behavior_never <nl> + * / <nl> + public static final int spatialization_behavior_never = <nl> + audioattributes . spatialization_behavior_never ; <nl>  <nl> / * * <nl> * stream types for an { @ link android . media . audiotrack } . one of { @ link # stream_type_alarm } , { @ link <nl> mmm a / library / common / src / main / java / com / google / android / exoplayer2 / audio / audioattributes . java <nl> ppp b / library / common / src / main / java / com / google / android / exoplayer2 / audio / audioattributes . java <nl>
public final class audioattributes implements bundleable { <nl> return this ; <nl> } <nl>  <nl> - <nl> - / / once compile sdk target is set to num . <nl> - / * * see { @ code android . media . audioattributes . builder . setspatializationbehavior ( int ) } . * / <nl> + / * * see { @ link android . media . audioattributes . builder # setspatializationbehavior ( int ) } . * / <nl> public builder setspatializationbehavior ( @ c . spatializationbehavior int spatializationbehavior ) { <nl> this . spatializationbehavior = spatializationbehavior ; <nl> return this ; <nl>
public final class audioattributes implements bundleable { <nl> public static void setspatializationbehavior ( <nl> android . media . audioattributes . builder builder , <nl> @ c . spatializationbehavior int spatializationbehavior ) { <nl> - try { <nl> - <nl> - method setspatializationbehavior = <nl> - builder . getclass ( ) . getmethod ( " setspatializationbehavior " , integer . type ) ; <nl> - setspatializationbehavior . invoke ( builder , spatializationbehavior ) ; <nl> - } catch ( exception e ) { <nl> - / / do nothing if reflection fails . <nl> - } <nl> + builder . setspatializationbehavior ( spatializationbehavior ) ; <nl> } <nl> } <nl> } <nl> mmm a / library / core / src / main / java / com / google / android / exoplayer2 / audio / mediacodecaudiorenderer . java <nl> ppp b / library / core / src / main / java / com / google / android / exoplayer2 / audio / mediacodecaudiorenderer . java <nl>
public class mediacodecaudiorenderer extends mediacodecrenderer implements media <nl> mediaformat . setinteger ( mediaformat . key_pcm_encoding , audioformat . encoding_pcm_float ) ; <nl> } <nl> if ( util . sdk_int > = num ) { <nl> - <nl> - / / compile sdk target is set to num . <nl> - mediaformat . setinteger ( " max - output - channel - count " , num ) ; <nl> + mediaformat . setinteger ( mediaformat . key_max_output_channel_count , num ) ; <nl> } <nl>  <nl> return mediaformat ;
import org . checkerframework . dataflow . qual . pure ; <nl> int decodedheight = <nl> ( inputformat . rotationdegrees % num = = num ) ? inputformat . height : inputformat . width ; <nl>  <nl> - <nl> - / / and don ' t create a presentationframeprocessor if resolution is unset . <nl> - scaletofitframeprocessor scaletofitframeprocessor = <nl> - new scaletofitframeprocessor . builder ( ) <nl> - . setscale ( transformationrequest . scalex , transformationrequest . scaley ) <nl> - . setrotationdegrees ( transformationrequest . rotationdegrees ) <nl> - . build ( ) ; <nl> - presentationframeprocessor presentationframeprocessor = <nl> - new presentationframeprocessor . builder ( ) <nl> - . setresolution ( transformationrequest . outputheight ) <nl> - . build ( ) ; <nl> + immutablelist . builder < glframeprocessor > frameprocessorslistbuilder = <nl> + new immutablelist . builder < glframeprocessor > ( ) . addall ( frameprocessors ) ; <nl> + if ( transformationrequest . scalex ! = num f <nl> + | | transformationrequest . scaley ! = num f <nl> + | | transformationrequest . rotationdegrees ! = num f ) { <nl> + frameprocessorslistbuilder . add ( <nl> + new scaletofitframeprocessor . builder ( ) <nl> + . setscale ( transformationrequest . scalex , transformationrequest . scaley ) <nl> + . setrotationdegrees ( transformationrequest . rotationdegrees ) <nl> + . build ( ) ) ; <nl> + } <nl> + if ( transformationrequest . outputheight ! = c . length_unset ) { <nl> + frameprocessorslistbuilder . add ( <nl> + new presentationframeprocessor . builder ( ) <nl> + . setresolution ( transformationrequest . outputheight ) <nl> + . build ( ) ) ; <nl> + } <nl> encodercompatibilityframeprocessor encodercompatibilityframeprocessor = <nl> new encodercompatibilityframeprocessor ( ) ; <nl> + frameprocessorslistbuilder . add ( encodercompatibilityframeprocessor ) ; <nl> frameprocessorchain = <nl> frameprocessorchain . create ( <nl> context , <nl> inputformat . pixelwidthheightratio , <nl> / * inputwidth = * / decodedwidth , <nl> / * inputheight = * / decodedheight , <nl> - new immutablelist . builder < glframeprocessor > ( ) <nl> - . addall ( frameprocessors ) <nl> - . add ( scaletofitframeprocessor ) <nl> - . add ( presentationframeprocessor ) <nl> - . add ( encodercompatibilityframeprocessor ) <nl> - . build ( ) , <nl> + frameprocessorslistbuilder . build ( ) , <nl> transformationrequest . enablehdrediting ) ; <nl> size requestedencodersize = frameprocessorchain . getoutputsize ( ) ; <nl> outputrotationdegrees = encodercompatibilityframeprocessor . getoutputrotationdegrees ( ) ;
import org . junit . runner . runwith ; <nl> / * * checks transcoding quality . * / <nl> @ runwith ( androidjunit4 . class ) <nl> public final class transcodequalitytest { <nl> - <nl> @ test <nl> public void transformwithdecodeencode_ssimisgreaterthan90percent ( ) throws exception { <nl> context context = applicationprovider . getapplicationcontext ( ) ;
import org . checkerframework . dataflow . qual . pure ; <nl> int decodedheight = <nl> ( inputformat . rotationdegrees % num = = num ) ? inputformat . height : inputformat . width ; <nl>  <nl> - <nl> - / / and don ' t create a presentationframeprocessor if resolution is unset . <nl> - scaletofitframeprocessor scaletofitframeprocessor = <nl> - new scaletofitframeprocessor . builder ( ) <nl> - . setscale ( transformationrequest . scalex , transformationrequest . scaley ) <nl> - . setrotationdegrees ( transformationrequest . rotationdegrees ) <nl> - . build ( ) ; <nl> - presentationframeprocessor presentationframeprocessor = <nl> - new presentationframeprocessor . builder ( ) <nl> - . setresolution ( transformationrequest . outputheight ) <nl> - . build ( ) ; <nl> + immutablelist . builder < glframeprocessor > frameprocessorslistbuilder = <nl> + new immutablelist . builder < glframeprocessor > ( ) . addall ( frameprocessors ) ; <nl> + if ( transformationrequest . scalex ! = num f <nl> + | | transformationrequest . scaley ! = num f <nl> + | | transformationrequest . rotationdegrees ! = num f ) { <nl> + frameprocessorslistbuilder . add ( <nl> + new scaletofitframeprocessor . builder ( ) <nl> + . setscale ( transformationrequest . scalex , transformationrequest . scaley ) <nl> + . setrotationdegrees ( transformationrequest . rotationdegrees ) <nl> + . build ( ) ) ; <nl> + } <nl> + if ( transformationrequest . outputheight ! = c . length_unset ) { <nl> + frameprocessorslistbuilder . add ( <nl> + new presentationframeprocessor . builder ( ) <nl> + . setresolution ( transformationrequest . outputheight ) <nl> + . build ( ) ) ; <nl> + } <nl> encodercompatibilityframeprocessor encodercompatibilityframeprocessor = <nl> new encodercompatibilityframeprocessor ( ) ; <nl> + frameprocessorslistbuilder . add ( encodercompatibilityframeprocessor ) ; <nl> frameprocessorchain = <nl> frameprocessorchain . create ( <nl> context , <nl> inputformat . pixelwidthheightratio , <nl> / * inputwidth = * / decodedwidth , <nl> / * inputheight = * / decodedheight , <nl> - new immutablelist . builder < glframeprocessor > ( ) <nl> - . addall ( frameprocessors ) <nl> - . add ( scaletofitframeprocessor ) <nl> - . add ( presentationframeprocessor ) <nl> - . add ( encodercompatibilityframeprocessor ) <nl> - . build ( ) , <nl> + frameprocessorslistbuilder . build ( ) , <nl> transformationrequest . enablehdrediting ) ; <nl> size requestedencodersize = frameprocessorchain . getoutputsize ( ) ; <nl> outputrotationdegrees = encodercompatibilityframeprocessor . getoutputrotationdegrees ( ) ;
import org . junit . runner . runwith ; <nl> / * * checks transcoding quality . * / <nl> @ runwith ( androidjunit4 . class ) <nl> public final class transcodequalitytest { <nl> - <nl> @ test <nl> public void transformwithdecodeencode_ssimisgreaterthan90percent ( ) throws exception { <nl> context context = applicationprovider . getapplicationcontext ( ) ;
public final class glprogram { <nl> * < p > call this in the rendering loop to switch between different programs . <nl> * / <nl> public void use ( ) { <nl> - <nl> - / / to call use ( ) to switch between programs . <nl> gles20 . gluseprogram ( programid ) ; <nl> glutil . checkglerror ( ) ; <nl> } <nl> mmm a / library / transformer / src / androidtest / java / com / google / android / exoplayer2 / transformer / advancedframeprocessorpixeltest . java <nl> ppp b / library / transformer / src / androidtest / java / com / google / android / exoplayer2 / transformer / advancedframeprocessorpixeltest . java <nl>
public final class advancedframeprocessorpixeltest { <nl> private @ monotonicnonnull glframeprocessor advancedframeprocessor ; <nl> private int inputtexid ; <nl> private int outputtexid ; <nl> - <nl> - / / dimensions , get the output dimensions from the frame processor . <nl> private int width ; <nl> private int height ; <nl>  <nl> mmm a / library / transformer / src / main / java / com / google / android / exoplayer2 / transformer / glframeprocessor . java <nl> ppp b / library / transformer / src / main / java / com / google / android / exoplayer2 / transformer / glframeprocessor . java <nl>
public final class glprogram { <nl> * < p > call this in the rendering loop to switch between different programs . <nl> * / <nl> public void use ( ) { <nl> - <nl> - / / to call use ( ) to switch between programs . <nl> gles20 . gluseprogram ( programid ) ; <nl> glutil . checkglerror ( ) ; <nl> } <nl> mmm a / libraries / transformer / src / androidtest / java / androidx / media3 / transformer / advancedframeprocessorpixeltest . java <nl> ppp b / libraries / transformer / src / androidtest / java / androidx / media3 / transformer / advancedframeprocessorpixeltest . java <nl>
public final class advancedframeprocessorpixeltest { <nl> private @ monotonicnonnull glframeprocessor advancedframeprocessor ; <nl> private int inputtexid ; <nl> private int outputtexid ; <nl> - <nl> - / / dimensions , get the output dimensions from the frame processor . <nl> private int width ; <nl> private int height ; <nl>  <nl> mmm a / libraries / transformer / src / main / java / androidx / media3 / transformer / glframeprocessor . java <nl> ppp b / libraries / transformer / src / main / java / androidx / media3 / transformer / glframeprocessor . java <nl>
import org . checkerframework . checker . nullness . qual . requiresnonnull ; <nl>  <nl> private static final string thread_name = " transformer : frameprocessorchain " ; <nl>  <nl> + private final eglcontext eglcontext ; <nl> + private final egldisplay egldisplay ; <nl> + / * * <nl> + * wraps the output { @ link surface } that is populated with the output of the final { @ link <nl> + * glframeprocessor } for each frame . <nl> + * / <nl> + private final eglsurface eglsurface ; <nl> / * * some opengl commands may block , so all opengl commands are run on a background thread . * / <nl> private final executorservice singlethreadexecutorservice ; <nl> / * * futures corresponding to the executor service ' s pending tasks . * / <nl> private final concurrentlinkedqueue < future < ? > > futures ; <nl> / * * number of frames { @ link # registerinputframe ( ) registered } but not fully processed . * / <nl> private final atomicinteger pendingframecount ; <nl> - <nl> - / / familiar with this class and consider grouping some of these fields into new classes to <nl> - / / reduce the number of constructor parameters . <nl> - private final egldisplay egldisplay ; <nl> - private final eglcontext eglcontext ; <nl> - private final eglsurface eglsurface ; <nl> + / * * prevents further frame processing tasks from being scheduled after { @ link # release ( ) } . * / <nl> + private volatile boolean releaserequested ; <nl> + <nl> + private boolean inputstreamended ; <nl> + / * * wraps the { @ link # inputsurfacetexture } . * / <nl> + private @ monotonicnonnull surface inputsurface ; <nl> + / * * associated with an opengl external texture . * / <nl> + private @ monotonicnonnull surfacetexture inputsurfacetexture ; <nl> + / * * <nl> + * identifier of the external texture the { @ link externalcopyframeprocessor } reads its input from . <nl> + * / <nl> + private final int inputexternaltexid ; <nl> + / * * transformation matrix associated with the surface texture . * / <nl> + private final float [ ] texturetransformmatrix ; <nl> + <nl> private final externalcopyframeprocessor externalcopyframeprocessor ; <nl> private final list < glframeprocessor > frameprocessors ; <nl> / * * <nl>
import org . checkerframework . checker . nullness . qual . requiresnonnull ; <nl>  <nl> private static final string thread_name = " transformer : frameprocessorchain " ; <nl>  <nl> + private final eglcontext eglcontext ; <nl> + private final egldisplay egldisplay ; <nl> + / * * <nl> + * wraps the output { @ link surface } that is populated with the output of the final { @ link <nl> + * glframeprocessor } for each frame . <nl> + * / <nl> + private final eglsurface eglsurface ; <nl> / * * some opengl commands may block , so all opengl commands are run on a background thread . * / <nl> private final executorservice singlethreadexecutorservice ; <nl> / * * futures corresponding to the executor service ' s pending tasks . * / <nl> private final concurrentlinkedqueue < future < ? > > futures ; <nl> / * * number of frames { @ link # registerinputframe ( ) registered } but not fully processed . * / <nl> private final atomicinteger pendingframecount ; <nl> - <nl> - / / familiar with this class and consider grouping some of these fields into new classes to <nl> - / / reduce the number of constructor parameters . <nl> - private final egldisplay egldisplay ; <nl> - private final eglcontext eglcontext ; <nl> - private final eglsurface eglsurface ; <nl> + / * * prevents further frame processing tasks from being scheduled after { @ link # release ( ) } . * / <nl> + private volatile boolean releaserequested ; <nl> + <nl> + private boolean inputstreamended ; <nl> + / * * wraps the { @ link # inputsurfacetexture } . * / <nl> + private @ monotonicnonnull surface inputsurface ; <nl> + / * * associated with an opengl external texture . * / <nl> + private @ monotonicnonnull surfacetexture inputsurfacetexture ; <nl> + / * * <nl> + * identifier of the external texture the { @ link externalcopyframeprocessor } reads its input from . <nl> + * / <nl> + private final int inputexternaltexid ; <nl> + / * * transformation matrix associated with the surface texture . * / <nl> + private final float [ ] texturetransformmatrix ; <nl> + <nl> private final externalcopyframeprocessor externalcopyframeprocessor ; <nl> private final list < glframeprocessor > frameprocessors ; <nl> / * * <nl>
public class transformationtest { <nl> string testid = tag + " _transform " ; <nl> context context = applicationprovider . getapplicationcontext ( ) ; <nl> transformer transformer = new transformer . builder ( context ) . build ( ) ; <nl> - <nl> new transformerandroidtestrunner . builder ( context , transformer ) <nl> . setcalculatessim ( true ) <nl> - . setsuppressanalysisexceptions ( true ) <nl> . build ( ) <nl> . run ( testid , mp4_asset_with_increasing_timestamps_uri_string ) ; <nl> } <nl>
public class transformationtest { <nl> } <nl> } ) <nl> . build ( ) ; <nl> - <nl> new transformerandroidtestrunner . builder ( context , transformer ) <nl> . setcalculatessim ( true ) <nl> - . setsuppressanalysisexceptions ( true ) <nl> . build ( ) <nl> . run ( testid , mp4_asset_with_increasing_timestamps_uri_string ) ; <nl> } <nl>
public class transformationtest { <nl> new videoencodersettings . builder ( ) . setbitrate ( 5_000_000 ) . build ( ) , <nl> / * enablefallback = * / true ) ) <nl> . build ( ) ; <nl> - <nl> new transformerandroidtestrunner . builder ( context , transformer ) <nl> . setcalculatessim ( true ) <nl> - . setsuppressanalysisexceptions ( true ) <nl> . build ( ) <nl> . run ( testid , mp4_asset_with_increasing_timestamps_uri_string ) ; <nl> } <nl>
public class transformationtest { <nl> string testid = tag + " _transform4k60 " ; <nl> context context = applicationprovider . getapplicationcontext ( ) ; <nl> transformer transformer = new transformer . builder ( context ) . build ( ) ; <nl> - <nl> new transformerandroidtestrunner . builder ( context , transformer ) <nl> . setcalculatessim ( true ) <nl> - . setsuppressanalysisexceptions ( true ) <nl> . build ( ) <nl> . run ( testid , mp4_remote_4k60_portrait_uri_string ) ; <nl> } <nl>
public class transformationtest { <nl> string testid = tag + " _transformnoaudio " ; <nl> context context = applicationprovider . getapplicationcontext ( ) ; <nl> transformer transformer = new transformer . builder ( context ) . setremoveaudio ( true ) . build ( ) ; <nl> - <nl> new transformerandroidtestrunner . builder ( context , transformer ) <nl> . setcalculatessim ( true ) <nl> - . setsuppressanalysisexceptions ( true ) <nl> . build ( ) <nl> . run ( testid , mp4_asset_with_increasing_timestamps_uri_string ) ; <nl> } <nl>
public class transformationtest { <nl> . settransformationrequest ( <nl> new transformationrequest . builder ( ) . setflattenforslowmotion ( true ) . build ( ) ) <nl> . build ( ) ; <nl> - <nl> new transformerandroidtestrunner . builder ( context , transformer ) <nl> . setcalculatessim ( true ) <nl> - . setsuppressanalysisexceptions ( true ) <nl> . build ( ) <nl> . run ( testid , mp4_asset_sef_uri_string ) ; <nl> }
public class transformationtest { <nl> string testid = tag + " _transform " ; <nl> context context = applicationprovider . getapplicationcontext ( ) ; <nl> transformer transformer = new transformer . builder ( context ) . build ( ) ; <nl> - <nl> new transformerandroidtestrunner . builder ( context , transformer ) <nl> . setcalculatessim ( true ) <nl> - . setsuppressanalysisexceptions ( true ) <nl> . build ( ) <nl> . run ( testid , mp4_asset_with_increasing_timestamps_uri_string ) ; <nl> } <nl>
public class transformationtest { <nl> } <nl> } ) <nl> . build ( ) ; <nl> - <nl> new transformerandroidtestrunner . builder ( context , transformer ) <nl> . setcalculatessim ( true ) <nl> - . setsuppressanalysisexceptions ( true ) <nl> . build ( ) <nl> . run ( testid , mp4_asset_with_increasing_timestamps_uri_string ) ; <nl> } <nl>
public class transformationtest { <nl> new videoencodersettings . builder ( ) . setbitrate ( 5_000_000 ) . build ( ) , <nl> / * enablefallback = * / true ) ) <nl> . build ( ) ; <nl> - <nl> new transformerandroidtestrunner . builder ( context , transformer ) <nl> . setcalculatessim ( true ) <nl> - . setsuppressanalysisexceptions ( true ) <nl> . build ( ) <nl> . run ( testid , mp4_asset_with_increasing_timestamps_uri_string ) ; <nl> } <nl>
public class transformationtest { <nl> string testid = tag + " _transform4k60 " ; <nl> context context = applicationprovider . getapplicationcontext ( ) ; <nl> transformer transformer = new transformer . builder ( context ) . build ( ) ; <nl> - <nl> new transformerandroidtestrunner . builder ( context , transformer ) <nl> . setcalculatessim ( true ) <nl> - . setsuppressanalysisexceptions ( true ) <nl> . build ( ) <nl> . run ( testid , mp4_remote_4k60_portrait_uri_string ) ; <nl> } <nl>
public class transformationtest { <nl> string testid = tag + " _transformnoaudio " ; <nl> context context = applicationprovider . getapplicationcontext ( ) ; <nl> transformer transformer = new transformer . builder ( context ) . setremoveaudio ( true ) . build ( ) ; <nl> - <nl> new transformerandroidtestrunner . builder ( context , transformer ) <nl> . setcalculatessim ( true ) <nl> - . setsuppressanalysisexceptions ( true ) <nl> . build ( ) <nl> . run ( testid , mp4_asset_with_increasing_timestamps_uri_string ) ; <nl> } <nl>
public class transformationtest { <nl> . settransformationrequest ( <nl> new transformationrequest . builder ( ) . setflattenforslowmotion ( true ) . build ( ) ) <nl> . build ( ) ; <nl> - <nl> new transformerandroidtestrunner . builder ( context , transformer ) <nl> . setcalculatessim ( true ) <nl> - . setsuppressanalysisexceptions ( true ) <nl> . build ( ) <nl> . run ( testid , mp4_asset_sef_uri_string ) ; <nl> }
public final class frameworkmediadrm implements exomediadrm { <nl>  <nl> @ override <nl> public void setplayeridforsession ( byte [ ] sessionid , playerid playerid ) { <nl> - <nl> + if ( util . sdk_int > = num ) { <nl> + try { <nl> + api31 . setlogsessionidonmediadrmsession ( mediadrm , sessionid , playerid ) ; <nl> + } catch ( unsupportedoperationexception e ) { <nl> + log . w ( tag , " setlogsessionid failed . " ) ; <nl> + } <nl> + } <nl> } <nl>  <nl> / / return values of mediadrm . keyrequest . getrequesttype are equal to keyrequest . requesttype . <nl>
public final class frameworkmediadrm implements exomediadrm { <nl>  <nl> @ override <nl> public void setplayeridforsession ( byte [ ] sessionid , playerid playerid ) { <nl> - <nl> + if ( util . sdk_int > = num ) { <nl> + try { <nl> + api31 . setlogsessionidonmediadrmsession ( mediadrm , sessionid , playerid ) ; <nl> + } catch ( unsupportedoperationexception e ) { <nl> + log . w ( tag , " setlogsessionid failed . " ) ; <nl> + } <nl> + } <nl> } <nl>  <nl> / / return values of mediadrm . keyrequest . getrequesttype are equal to keyrequest . requesttype . <nl>
import java . util . map ; <nl> import org . checkerframework . checker . nullness . qual . ensuresnonnull ; <nl> import org . checkerframework . checker . nullness . qual . monotonicnonnull ; <nl>  <nl> - / * * <nl> - * mediasource for ima server side inserted ad streams . <nl> - * <nl> - * < p > <nl> - * / <nl> + / * * mediasource for ima server side inserted ad streams . * / <nl> public final class imaserversideadinsertionmediasource extends compositemediasource < void > { <nl>  <nl> / * * <nl>
public final class imaserversideadinsertionmediasource extends compositemediasou <nl> * <nl> * < p > apps can use the { @ link imaserversideadinsertionmediasource . factory } to customized the <nl> * { @ link defaultmediasourcefactory } that is used to build a player : <nl> - * <nl> - * < p > <nl> * / <nl> public static final class factory implements mediasource . factory { <nl>  <nl>
import java . util . map ; <nl> import org . checkerframework . checker . nullness . qual . ensuresnonnull ; <nl> import org . checkerframework . checker . nullness . qual . monotonicnonnull ; <nl>  <nl> - / * * <nl> - * mediasource for ima server side inserted ad streams . <nl> - * <nl> - * < p > <nl> - * / <nl> + / * * mediasource for ima server side inserted ad streams . * / <nl> @ unstableapi <nl> public final class imaserversideadinsertionmediasource extends compositemediasource < void > { <nl>  <nl>
public final class imaserversideadinsertionmediasource extends compositemediasou <nl> * <nl> * < p > apps can use the { @ link imaserversideadinsertionmediasource . factory } to customized the <nl> * { @ link defaultmediasourcefactory } that is used to build a player : <nl> - * <nl> - * < p > <nl> * / <nl> public static final class factory implements mediasource . factory { <nl>  <nl>
import java . util . map ; <nl> import org . checkerframework . checker . nullness . qual . ensuresnonnull ; <nl> import org . checkerframework . checker . nullness . qual . monotonicnonnull ; <nl>  <nl> - / * * <nl> - * mediasource for ima server side inserted ad streams . <nl> - * <nl> - * < p > <nl> - * / <nl> + / * * mediasource for ima server side inserted ad streams . * / <nl> public final class imaserversideadinsertionmediasource extends compositemediasource < void > { <nl>  <nl> / * * <nl>
public final class imaserversideadinsertionmediasource extends compositemediasou <nl> * <nl> * < p > apps can use the { @ link imaserversideadinsertionmediasource . factory } to customized the <nl> * { @ link defaultmediasourcefactory } that is used to build a player : <nl> - * <nl> - * < p > <nl> * / <nl> public static final class factory implements mediasource . factory { <nl>  <nl>
import java . util . map ; <nl> import org . checkerframework . checker . nullness . qual . ensuresnonnull ; <nl> import org . checkerframework . checker . nullness . qual . monotonicnonnull ; <nl>  <nl> - / * * <nl> - * mediasource for ima server side inserted ad streams . <nl> - * <nl> - * < p > <nl> - * / <nl> + / * * mediasource for ima server side inserted ad streams . * / <nl> @ unstableapi <nl> public final class imaserversideadinsertionmediasource extends compositemediasource < void > { <nl>  <nl>
public final class imaserversideadinsertionmediasource extends compositemediasou <nl> * <nl> * < p > apps can use the { @ link imaserversideadinsertionmediasource . factory } to customized the <nl> * { @ link defaultmediasourcefactory } that is used to build a player : <nl> - * <nl> - * < p > <nl> * / <nl> public static final class factory implements mediasource . factory { <nl>  <nl>
import org . junit . runner . runwith ; <nl> * from emulators , so tests on physical devices may fail . to test on physical devices , please modify <nl> * the maximum_average_pixel_absolute_difference . <nl> * / <nl> - <nl> @ runwith ( androidjunit4 . class ) <nl> public final class frameeditordataprocessingtest {
import org . junit . runner . runwith ; <nl> * from emulators , so tests on physical devices may fail . to test on physical devices , please modify <nl> * the maximum_average_pixel_absolute_difference . <nl> * / <nl> - <nl> @ runwith ( androidjunit4 . class ) <nl> public final class frameeditordataprocessingtest {
import org . checkerframework . checker . nullness . qual . requiresnonnull ; <nl>  <nl> / * * a default implementation of { @ link codec . encoderfactory } . * / <nl> public final class defaultencoderfactory implements codec . encoderfactory { <nl> - <nl> private static final int default_color_format = <nl> mediacodecinfo . codeccapabilities . color_formatsurface ; <nl> private static final int default_frame_rate = num ; <nl> private static final int default_i_frame_interval_secs = num ; <nl>  <nl> @ nullable private final encoderselector videoencoderselector ; <nl> + private final boolean disablefallback ; <nl>  <nl> - / * * creates a new instance using the { @ link encoderselector # default default encoder selector } . * / <nl> + / * * <nl> + * creates a new instance using the { @ link encoderselector # default default encoder selector } , and <nl> + * format fallback enabled . <nl> + * <nl> + * < p > with format fallback enabled , and when the requested { @ link format } is not supported , { @ code <nl> + * defaultencoderfactory } finds a format that is supported by the device and configures the { @ link <nl> + * codec } with it . the fallback process may change the requested { @ link format # samplemimetype mime <nl> + * type } , resolution , { @ link format # bitrate bitrate } , { @ link format # codecs profile / level } , etc . <nl> + * / <nl> public defaultencoderfactory ( ) { <nl> - this ( encoderselector . default ) ; <nl> + this ( encoderselector . default , / * disablefallback = * / false ) ; <nl> } <nl>  <nl> / * * creates a new instance . * / <nl> - public defaultencoderfactory ( encoderselector videoencoderselector ) { <nl> + public defaultencoderfactory ( <nl> + @ nullable encoderselector videoencoderselector , boolean disablefallback ) { <nl> this . videoencoderselector = videoencoderselector ; <nl> + this . disablefallback = disablefallback ; <nl> } <nl>  <nl> @ override <nl>
import org . checkerframework . checker . nullness . qual . requiresnonnull ; <nl> / * * a default implementation of { @ link codec . encoderfactory } . * / <nl> @ unstableapi <nl> public final class defaultencoderfactory implements codec . encoderfactory { <nl> - <nl> private static final int default_color_format = <nl> mediacodecinfo . codeccapabilities . color_formatsurface ; <nl> private static final int default_frame_rate = num ; <nl> private static final int default_i_frame_interval_secs = num ; <nl>  <nl> @ nullable private final encoderselector videoencoderselector ; <nl> + private final boolean disablefallback ; <nl>  <nl> - / * * creates a new instance using the { @ link encoderselector # default default encoder selector } . * / <nl> + / * * <nl> + * creates a new instance using the { @ link encoderselector # default default encoder selector } , and <nl> + * format fallback enabled . <nl> + * <nl> + * < p > with format fallback enabled , and when the requested { @ link format } is not supported , { @ code <nl> + * defaultencoderfactory } finds a format that is supported by the device and configures the { @ link <nl> + * codec } with it . the fallback process may change the requested { @ link format # samplemimetype mime <nl> + * type } , resolution , { @ link format # bitrate bitrate } , { @ link format # codecs profile / level } , etc . <nl> + * / <nl> public defaultencoderfactory ( ) { <nl> - this ( encoderselector . default ) ; <nl> + this ( encoderselector . default , / * disablefallback = * / false ) ; <nl> } <nl>  <nl> / * * creates a new instance . * / <nl> - public defaultencoderfactory ( encoderselector videoencoderselector ) { <nl> + public defaultencoderfactory ( <nl> + @ nullable encoderselector videoencoderselector , boolean disablefallback ) { <nl> this . videoencoderselector = videoencoderselector ; <nl> + this . disablefallback = disablefallback ; <nl> } <nl>  <nl> @ override <nl>
import org . checkerframework . checker . nullness . qual . requiresnonnull ; <nl> } <nl> } <nl>  <nl> - <nl> - / / muxing . <nl> - if ( mimetype . equals ( mimetypes . video_h264 ) ) { <nl> - / / applying suggested profile / level settings from <nl> - / / https : / / developer . android . com / guide / topics / media / sharing - video # b - frames_and_encoding_profiles <nl> - if ( util . sdk_int > = num ) { <nl> - / / use the highest supported profile and use b - frames . <nl> - mediaformat . setinteger ( <nl> - mediaformat . key_profile , mediacodecinfo . codecprofilelevel . avcprofilehigh ) ; <nl> - mediaformat . setinteger ( mediaformat . key_max_b_frames , num ) ; <nl> - } else if ( util . sdk_int > = num ) { <nl> - / / use the highest - supported profile , but disable the generation of b - frames . this <nl> - / / accommodates some limitations in the mediamuxer in these system versions . <nl> - mediaformat . setinteger ( <nl> - mediaformat . key_profile , mediacodecinfo . codecprofilelevel . avcprofilehigh ) ; <nl> - mediaformat . setinteger ( mediaformat . key_latency , num ) ; <nl> - } else { <nl> - / / use the baseline profile for safest results . <nl> - mediaformat . setinteger ( <nl> - mediaformat . key_profile , mediacodecinfo . codecprofilelevel . avcprofilebaseline ) ; <nl> - } <nl> - } <nl> - <nl> mediaformat . setinteger ( mediaformat . key_color_format , default_color_format ) ; <nl> mediaformat . setinteger ( mediaformat . key_i_frame_interval , default_i_frame_interval_secs ) ;
import org . checkerframework . checker . nullness . qual . requiresnonnull ; <nl> } <nl> } <nl>  <nl> - <nl> - / / muxing . <nl> - if ( mimetype . equals ( mimetypes . video_h264 ) ) { <nl> - / / applying suggested profile / level settings from <nl> - / / https : / / developer . android . com / guide / topics / media / sharing - video # b - frames_and_encoding_profiles <nl> - if ( util . sdk_int > = num ) { <nl> - / / use the highest supported profile and use b - frames . <nl> - mediaformat . setinteger ( <nl> - mediaformat . key_profile , mediacodecinfo . codecprofilelevel . avcprofilehigh ) ; <nl> - mediaformat . setinteger ( mediaformat . key_max_b_frames , num ) ; <nl> - } else if ( util . sdk_int > = num ) { <nl> - / / use the highest - supported profile , but disable the generation of b - frames . this <nl> - / / accommodates some limitations in the mediamuxer in these system versions . <nl> - mediaformat . setinteger ( <nl> - mediaformat . key_profile , mediacodecinfo . codecprofilelevel . avcprofilehigh ) ; <nl> - mediaformat . setinteger ( mediaformat . key_latency , num ) ; <nl> - } else { <nl> - / / use the baseline profile for safest results . <nl> - mediaformat . setinteger ( <nl> - mediaformat . key_profile , mediacodecinfo . codecprofilelevel . avcprofilebaseline ) ; <nl> - } <nl> - } <nl> - <nl> mediaformat . setinteger ( mediaformat . key_color_format , default_color_format ) ; <nl> mediaformat . setinteger ( mediaformat . key_i_frame_interval , default_i_frame_interval_secs ) ;
public final class codec { <nl> * decoderfactory } or output { @ link format } used by the { @ link encoderfactory } for selecting and <nl> * configuring the underlying { @ link mediacodec } . <nl> * / <nl> - <nl> - / / configuration format differ to see whether fallback was applied . <nl> public format getconfigurationformat ( ) { <nl> return configurationformat ; <nl> }
public final class codec { <nl> * decoderfactory } or output { @ link format } used by the { @ link encoderfactory } for selecting and <nl> * configuring the underlying { @ link mediacodec } . <nl> * / <nl> - <nl> - / / configuration format differ to see whether fallback was applied . <nl> public format getconfigurationformat ( ) { <nl> return configurationformat ; <nl> }
public final class transformer { <nl> private boolean removeaudio ; <nl> private boolean removevideo ; <nl> private string containermimetype ; <nl> - <nl> private transformationrequest transformationrequest ; <nl> private transformer . listener listener ; <nl> private debugviewprovider debugviewprovider ; <nl> mmm a / libraries / transformer / src / main / java / androidx / media3 / transformer / transformervideorenderer . java <nl> ppp b / libraries / transformer / src / main / java / androidx / media3 / transformer / transformervideorenderer . java <nl>
public final class transformer { <nl> private boolean removeaudio ; <nl> private boolean removevideo ; <nl> private string containermimetype ; <nl> - <nl> private transformationrequest transformationrequest ; <nl> private transformer . listener listener ; <nl> private debugviewprovider debugviewprovider ; <nl> mmm a / library / transformer / src / main / java / com / google / android / exoplayer2 / transformer / transformervideorenderer . java <nl> ppp b / library / transformer / src / main / java / com / google / android / exoplayer2 / transformer / transformervideorenderer . java <nl>
public class mediacontroller implements player { <nl> @ deprecated <nl> @ override <nl> public boolean iscurrentwindowdynamic ( ) { <nl> - <nl> - return iscurrentmediaitemdynamic ( ) ; <nl> + throw new unsupportedoperationexception ( ) ; <nl> } <nl>  <nl> @ override <nl>
public class mediacontroller implements player { <nl> @ deprecated <nl> @ override <nl> public boolean iscurrentwindowlive ( ) { <nl> - <nl> - return iscurrentmediaitemlive ( ) ; <nl> + throw new unsupportedoperationexception ( ) ; <nl> } <nl>  <nl> @ override <nl>
public class mediacontroller implements player { <nl> @ deprecated <nl> @ override <nl> public boolean iscurrentwindowseekable ( ) { <nl> - <nl> - return iscurrentmediaitemseekable ( ) ; <nl> + throw new unsupportedoperationexception ( ) ; <nl> } <nl>  <nl> @ override <nl>
public class mediacontroller implements player { <nl> @ deprecated <nl> @ override <nl> public int getcurrentwindowindex ( ) { <nl> - <nl> - return getcurrentmediaitemindex ( ) ; <nl> + throw new unsupportedoperationexception ( ) ; <nl> } <nl>  <nl> @ override <nl>
public class mediacontroller implements player { <nl> @ deprecated <nl> @ override <nl> public int getpreviouswindowindex ( ) { <nl> - <nl> - return getpreviousmediaitemindex ( ) ; <nl> + throw new unsupportedoperationexception ( ) ; <nl> } <nl>  <nl> / * * <nl>
public class mediacontroller implements player { <nl> @ deprecated <nl> @ override <nl> public int getnextwindowindex ( ) { <nl> - <nl> - return getnextmediaitemindex ( ) ; <nl> + throw new unsupportedoperationexception ( ) ; <nl> } <nl>  <nl> / * * <nl>
public class mediacontroller implements player { <nl> @ deprecated <nl> @ override <nl> public void seektopreviouswindow ( ) { <nl> - <nl> - seektopreviousmediaitem ( ) ; <nl> + throw new unsupportedoperationexception ( ) ; <nl> } <nl>  <nl> / * * <nl>
public class mediacontroller implements player { <nl> @ deprecated <nl> @ override <nl> public void seektonextwindow ( ) { <nl> - <nl> - seektonextmediaitem ( ) ; <nl> + throw new unsupportedoperationexception ( ) ; <nl> } <nl>  <nl> / * * <nl> mmm a / libraries / test_session_current / src / main / java / androidx / media3 / session / mockplayer . java <nl> ppp b / libraries / test_session_current / src / main / java / androidx / media3 / session / mockplayer . java <nl>
import org . checkerframework . checker . nullness . compatqual . nullabletype ; <nl> import org . checkerframework . checker . nullness . qual . requiresnonnull ; <nl>  <nl> / * * a truth { @ link subject } for assertions on { @ link spanned } instances containing text styling . * / <nl> - <nl> public final class spannedsubject extends subject { <nl>  <nl> @ nullable private final spanned actual ;
import org . checkerframework . checker . nullness . qual . monotonicnonnull ; <nl> * mediacodecadapter } video encoder . <nl> * <nl> * @ param format the { @ link format } ( of the output data ) used to determine the underlying { @ link <nl> - * mediacodec } and its configuration values . <nl> + * mediacodec } and its configuration values . { @ link format # width } , { @ link format # height } , <nl> + * { @ link format # framerate } and { @ link format # averagebitrate } must be set to those of the <nl> + * desired output video format . <nl> + * @ param additionalencoderconfig a map of { @ link mediaformat } ' s integer settings , where the keys <nl> + * are from { @ code mediaformat . key_ * } constants . its values will override those in { @ code <nl> + * format } . <nl> * @ return a configured and started encoder wrapper . <nl> * @ throws ioexception if the underlying codec cannot be created . <nl> * / <nl> - public static mediacodecadapterwrapper createforvideoencoding ( format format ) throws ioexception { <nl> + public static mediacodecadapterwrapper createforvideoencoding ( <nl> + format format , map < string , integer > additionalencoderconfig ) throws ioexception { <nl> @ nullable mediacodecadapter adapter = null ; <nl> try { <nl> mediaformat mediaformat = <nl> mediaformat . createvideoformat ( <nl> checknotnull ( format . samplemimetype ) , format . width , format . height ) ; <nl> - <nl> mediaformat . setinteger ( mediaformat . key_color_format , codeccapabilities . color_formatsurface ) ; <nl> - mediaformat . setinteger ( mediaformat . key_frame_rate , num ) ; <nl> + mediaformat . setinteger ( mediaformat . key_frame_rate , ( int ) ceil ( format . framerate ) ) ; <nl> mediaformat . setinteger ( mediaformat . key_i_frame_interval , num ) ; <nl> - mediaformat . setinteger ( mediaformat . key_bit_rate , num _000_000 ) ; <nl> + mediaformat . setinteger ( mediaformat . key_bit_rate , format . averagebitrate ) ; <nl> + <nl> + for ( map . entry < string , integer > encodersetting : additionalencoderconfig . entryset ( ) ) { <nl> + mediaformat . setinteger ( encodersetting . getkey ( ) , encodersetting . getvalue ( ) ) ; <nl> + } <nl>  <nl> adapter = <nl> new factory ( ) <nl> mmm a / library / transformer / src / main / java / com / google / android / exoplayer2 / transformer / transformertranscodingvideorenderer . java <nl> ppp b / library / transformer / src / main / java / com / google / android / exoplayer2 / transformer / transformertranscodingvideorenderer . java <nl>
public final class defaultaudiosink implements audiosink { <nl> return false ; <nl> } <nl> audioformat audioformat = getaudioformat ( format . samplerate , channelconfig , encoding ) ; <nl> - if ( ! audiomanager . isoffloadedplaybacksupported ( <nl> - audioformat , audioattributes . getaudioattributesv21 ( ) ) ) { <nl> - return false ; <nl> + <nl> + switch ( getoffloadedplaybacksupport ( audioformat , audioattributes . getaudioattributesv21 ( ) ) ) { <nl> + case c . playback_offload_not_supported : <nl> + return false ; <nl> + case c . playback_offload_supported : <nl> + boolean isgapless = format . encoderdelay ! = num | | format . encoderpadding ! = num ; <nl> + boolean gaplesssupportrequired = offloadmode = = offload_mode_enabled_gapless_required ; <nl> + return ! isgapless | | ! gaplesssupportrequired ; <nl> + case c . playback_offload_gapless_supported : <nl> + return true ; <nl> + default : <nl> + throw new illegalstateexception ( ) ; <nl> } <nl> - boolean isgapless = format . encoderdelay ! = num | | format . encoderpadding ! = num ; <nl> - boolean offloadrequiresgaplesssupport = offloadmode = = offload_mode_enabled_gapless_required ; <nl> - if ( isgapless & & offloadrequiresgaplesssupport & & ! isoffloadedgaplessplaybacksupported ( ) ) { <nl> - return false ; <nl> + } <nl> + <nl> + @ c . audiomanageroffloadmode <nl> + private int getoffloadedplaybacksupport ( <nl> + audioformat audioformat , android . media . audioattributes audioattributes ) { <nl> + if ( util . sdk_int > = num ) { <nl> + return audiomanager . getplaybackoffloadsupport ( audioformat , audioattributes ) ; <nl> } <nl> - return true ; <nl> + if ( ! audiomanager . isoffloadedplaybacksupported ( audioformat , audioattributes ) ) { <nl> + return c . playback_offload_not_supported ; <nl> + } <nl> + / / manual testing has shown that pixels on android num support gapless offload . <nl> + if ( util . sdk_int = = num & & util . model . startswith ( " pixel " ) ) { <nl> + return c . playback_offload_gapless_supported ; <nl> + } <nl> + return c . playback_offload_supported ; <nl> } <nl>  <nl> private static boolean isoffloadedplayback ( audiotrack audiotrack ) { <nl> return util . sdk_int > = num & & audiotrack . isoffloadedplayback ( ) ; <nl> } <nl>  <nl> - / * * <nl> - * returns whether the device supports gapless in offload playback . <nl> - * <nl> - * < p > gapless offload is not supported by all devices and there is no api to query its support . as <nl> - * a result this detection is currently based on manual testing . <nl> - * / <nl> - <nl> - private static boolean isoffloadedgaplessplaybacksupported ( ) { <nl> - return util . sdk_int > = num & & util . model . startswith ( " pixel " ) ; <nl> - } <nl> - <nl> private static int getmaximumencodedratebytespersecond ( @ c . encoding int encoding ) { <nl> switch ( encoding ) { <nl> case c . encoding_mp3 :
public abstract class mediacodecrenderer extends baserenderer { <nl> if ( frameworkmediacrypto . workaround_device_needs_keys_to_configure_codec ) { <nl> @ drmsession . state int drmsessionstate = codecdrmsession . getstate ( ) ; <nl> if ( drmsessionstate = = drmsession . state_error ) { <nl> - <nl> - / / to drmsessionexception . <nl> + drmsessionexception drmsessionexception = <nl> + assertions . checknotnull ( codecdrmsession . geterror ( ) ) ; <nl> throw createrendererexception ( <nl> - codecdrmsession . geterror ( ) , <nl> - inputformat , <nl> - playbackexception . error_code_drm_unspecified ) ; <nl> + drmsessionexception , inputformat , drmsessionexception . errorcode ) ; <nl> } else if ( drmsessionstate ! = drmsession . state_opened_with_keys ) { <nl> / / wait for keys . <nl> return ; <nl> mmm a / library / core / src / test / java / com / google / android / exoplayer2 / source / samplequeuetest . java <nl> ppp b / library / core / src / test / java / com / google / android / exoplayer2 / source / samplequeuetest . java <nl>
public final class mediasessionconnector { <nl> exoplayerlibraryinfo . registermodule ( " goog . exo . mediasession " ) ; <nl> } <nl>  <nl> - / * * indicates this session supports the set playback speed command . * / <nl> - <nl> - public static final long action_set_playback_speed = num < < num ; <nl> - <nl> / * * playback actions supported by the connector . * / <nl> @ longdef ( <nl> flag = true , <nl>
public abstract class timeline implements bundleable { <nl> private static final int field_last_period_index = num ; <nl> private static final int field_position_in_first_period_us = num ; <nl>  <nl> - / * * <nl> - * { @ inheritdoc } <nl> - * <nl> - * < p > it omits the { @ link # uid } and { @ link # manifest } fields . the { @ link # uid } of an instance <nl> - * restored by { @ link # creator } will be a fake { @ link object } and the { @ link # manifest } of the <nl> - * instance will be { @ code null } . <nl> - * / <nl> - <nl> - @ override <nl> - public bundle tobundle ( ) { <nl> + private final bundle tobundle ( boolean excludemediaitem ) { <nl> bundle bundle = new bundle ( ) ; <nl> - bundle . putbundle ( keyforfield ( field_media_item ) , mediaitem . tobundle ( ) ) ; <nl> + bundle . putbundle ( <nl> + keyforfield ( field_media_item ) , <nl> + excludemediaitem ? mediaitem . empty . tobundle ( ) : mediaitem . tobundle ( ) ) ; <nl> bundle . putlong ( keyforfield ( field_presentation_start_time_ms ) , presentationstarttimems ) ; <nl> bundle . putlong ( keyforfield ( field_window_start_time_ms ) , windowstarttimems ) ; <nl> bundle . putlong ( <nl>
<nl> - / * <nl> - * copyright ( c ) num the android open source project <nl> - * <nl> - * licensed under the apache license , version num . 0 ( the " license " ) ; <nl> - * you may not use this file except in compliance with the license . <nl> - * you may obtain a copy of the license at <nl> - * <nl> - * http : / / www . apache . org / licenses / license - 2 . 0 <nl> - * <nl> - * unless required by applicable law or agreed to in writing , software <nl> - * distributed under the license is distributed on an " as is " basis , <nl> - * without warranties or conditions of any kind , either express or implied . <nl> - * see the license for the specific language governing permissions and <nl> - * limitations under the license . <nl> - * / <nl> - package com . google . android . exoplayer2 . ext . vp9 ; <nl> - <nl> - import com . google . android . exoplayer2 . video . videodecoderoutputbuffer ; <nl> - <nl> - <nl> - / / on videodecoderoutputbuffer . also mark videodecoderoutputbuffer as final and remove proguard <nl> - / / config for vpxoutputbuffer . <nl> - / * * <nl> - * video output buffer , populated by { @ link vpxdecoder } . <nl> - * <nl> - * @ deprecated use { @ link videodecoderoutputbuffer } instead . <nl> - * / <nl> - @ deprecated <nl> - public final class vpxoutputbuffer extends videodecoderoutputbuffer { <nl> - <nl> - / * * <nl> - * creates vpxoutputbuffer . <nl> - * <nl> - * @ param owner buffer owner . <nl> - * / <nl> - public vpxoutputbuffer ( owner < videodecoderoutputbuffer > owner ) { <nl> - super ( owner ) ; <nl> - } <nl> - }
public abstract class mediacodecrenderer extends baserenderer { <nl> outputstreamstartpositionus = c . time_unset ; <nl> outputstreamoffsetus = c . time_unset ; <nl> pendingoutputstreamoffsetcount = num ; <nl> - if ( sourcedrmsession ! = null | | codecdrmsession ! = null ) { <nl> - <nl> - onreset ( ) ; <nl> - } else { <nl> - flushorreleasecodec ( ) ; <nl> - } <nl> + flushorreleasecodec ( ) ; <nl> } <nl>  <nl> @ override
public abstract class mediacodecrenderer extends baserenderer { <nl> outputstreamstartpositionus = c . time_unset ; <nl> outputstreamoffsetus = c . time_unset ; <nl> pendingoutputstreamoffsetcount = num ; <nl> - if ( sourcedrmsession ! = null | | codecdrmsession ! = null ) { <nl> - <nl> - onreset ( ) ; <nl> - } else { <nl> - flushorreleasecodec ( ) ; <nl> - } <nl> + flushorreleasecodec ( ) ; <nl> } <nl>  <nl> @ override
public final class cue implements bundleable { <nl> bundle . putcharsequence ( keyforfield ( field_text ) , text ) ; <nl> bundle . putserializable ( keyforfield ( field_text_alignment ) , textalignment ) ; <nl> bundle . putserializable ( keyforfield ( field_multi_row_alignment ) , multirowalignment ) ; <nl> - <nl> bundle . putparcelable ( keyforfield ( field_bitmap ) , bitmap ) ; <nl> bundle . putfloat ( keyforfield ( field_line ) , line ) ; <nl> bundle . putint ( keyforfield ( field_line_type ) , linetype ) ;
public class playbackexceptiontest { <nl> assertplaybackexceptionsareequal ( before , after ) ; <nl> } <nl>  <nl> - <nl> + / / the following tests prevent accidental modifications which break communication with older <nl> + / / exoplayer versions hosted in other processes . <nl> + <nl> + @ test <nl> + public void bundle_producesexpectedexception ( ) { <nl> + ioexception expectedcause = new ioexception ( " cause message " ) ; <nl> + playbackexception expectedexception = <nl> + new playbackexception ( <nl> + " message " , <nl> + expectedcause , <nl> + playbackexception . error_code_audio_track_init_failed , <nl> + / * timestampms = * / num ) ; <nl> + <nl> + bundle bundle = new bundle ( ) ; <nl> + bundle . putint ( " 0 " , num ) ; / / error code <nl> + bundle . putlong ( " 1 " , num ) ; / / timestamp . <nl> + bundle . putstring ( " 2 " , " message " ) ; <nl> + bundle . putstring ( " 3 " , expectedcause . getclass ( ) . getname ( ) ) ; <nl> + bundle . putstring ( " 4 " , " cause message " ) ; <nl> + <nl> + assertplaybackexceptionsareequal ( <nl> + expectedexception , playbackexception . creator . frombundle ( bundle ) ) ; <nl> + } <nl> + <nl> + @ test <nl> + public void exception_producesexpectedbundle ( ) { <nl> + illegalstateexception cause = new illegalstateexception ( " cause message " ) ; <nl> + playbackexception exception = <nl> + new playbackexception ( <nl> + " message " , <nl> + cause , <nl> + playbackexception . error_code_decoding_failed , <nl> + / * timestampms = * / num ) ; <nl> + <nl> + bundle bundle = exception . tobundle ( ) ; <nl> + assertthat ( bundle . getint ( " 0 " ) ) . isequalto ( 4002 ) ; / / error code . <nl> + assertthat ( bundle . getlong ( " 1 " ) ) . isequalto ( 2000 ) ; / / timestamp . <nl> + assertthat ( bundle . getstring ( " 2 " ) ) . isequalto ( " message " ) ; <nl> + assertthat ( bundle . getstring ( " 3 " ) ) . isequalto ( cause . getclass ( ) . getname ( ) ) ; <nl> + assertthat ( bundle . getstring ( " 4 " ) ) . isequalto ( " cause message " ) ; <nl> + } <nl> + <nl> + @ test <nl> + public void bundlewithunexpectedcause_producesremoteexceptioncause ( ) { <nl> + remoteexception expectedcause = new remoteexception ( " cause message " ) ; <nl> + playbackexception expectedexception = <nl> + new playbackexception ( <nl> + " message " , <nl> + expectedcause , <nl> + playbackexception . error_code_audio_track_init_failed , <nl> + / * timestampms = * / num ) ; <nl> + <nl> + bundle bundle = new bundle ( ) ; <nl> + bundle . putint ( " 0 " , num ) ; / / error code <nl> + bundle . putlong ( " 1 " , num ) ; / / timestamp . <nl> + bundle . putstring ( " 2 " , " message " ) ; <nl> + bundle . putstring ( " 3 " , " invalid cause class name " ) ; <nl> + bundle . putstring ( " 4 " , " cause message " ) ; <nl> + <nl> + assertplaybackexceptionsareequal ( <nl> + expectedexception , playbackexception . creator . frombundle ( bundle ) ) ; <nl> + } <nl> + <nl> + / / internal methods . <nl>  <nl> private static void assertplaybackexceptionsareequal ( playbackexception a , playbackexception b ) { <nl> assertthat ( a ) . hasmessagethat ( ) . isequalto ( b . getmessage ( ) ) ;
import org . checkerframework . checker . nullness . qual . monotonicnonnull ; <nl> sender . send ( message ) ; <nl> } <nl>  <nl> - private static void logmessage ( list < string > rtspmessage ) { <nl> - <nl> - if ( log_rtsp_messages ) { <nl> - log . d ( tag , joiner . on ( ' \n ' ) . join ( rtspmessage ) ) ; <nl> - } <nl> - } <nl> - <nl> private final class sender implements closeable { <nl>  <nl> private final outputstream outputstream ; <nl>
import org . checkerframework . checker . nullness . qual . monotonicnonnull ; <nl> sender . send ( message ) ; <nl> } <nl>  <nl> - private static void logmessage ( list < string > rtspmessage ) { <nl> - <nl> - if ( log_rtsp_messages ) { <nl> - log . d ( tag , joiner . on ( ' \n ' ) . join ( rtspmessage ) ) ; <nl> - } <nl> - } <nl> - <nl> private final class sender implements closeable { <nl>  <nl> private final outputstream outputstream ; <nl>
public class analyticscollector <nl> } <nl> } <nl>  <nl> - / * * resets the analytics collector for a new playlist . * / <nl> - public final void resetfornewplaylist ( ) { <nl> - <nl> - } <nl> - <nl> / / metadataoutput events . <nl>  <nl> / * *
public final class imaadsloader implements player . eventlistener , adsloader { <nl> return imasdkfactory . getinstance ( ) <nl> . createadsloader ( context , imasdksettings , addisplaycontainer ) ; <nl> } <nl> - <nl> - / * * <nl> - * returns a language code that ' s suitable for passing to { @ link imasdksettings # setlanguage } and <nl> - * corresponds to the device ' s { @ link locale # getdefault ( ) default locale } . ima will fall back to <nl> - * its default language code ( " en " ) if the value returned is unsupported . <nl> - * / <nl> - <nl> - / / https : / / developers . google . com / interactive - media - ads / docs / sdks / android / client - side / localization . <nl> - / / [ internal ref : b / 174042000 ] will help if implemented . <nl> - private static string getimalanguagecodefordefaultlocale ( ) { <nl> - return util . splitatfirst ( util . getsystemlanguagecodes ( ) [ 0 ] , " - " ) [ 0 ] ; <nl> - } <nl> } <nl> }
public final class imaadsloader implements player . eventlistener , adsloader { <nl> return imasdkfactory . getinstance ( ) <nl> . createadsloader ( context , imasdksettings , addisplaycontainer ) ; <nl> } <nl> - <nl> - / * * <nl> - * returns a language code that ' s suitable for passing to { @ link imasdksettings # setlanguage } and <nl> - * corresponds to the device ' s { @ link locale # getdefault ( ) default locale } . ima will fall back to <nl> - * its default language code ( " en " ) if the value returned is unsupported . <nl> - * / <nl> - <nl> - / / https : / / developers . google . com / interactive - media - ads / docs / sdks / android / client - side / localization . <nl> - / / [ internal ref : b / 174042000 ] will help if implemented . <nl> - private static string getimalanguagecodefordefaultlocale ( ) { <nl> - return util . splitatfirst ( util . getsystemlanguagecodes ( ) [ 0 ] , " - " ) [ 0 ] ; <nl> - } <nl> } <nl> }
public final class util { <nl>  <nl> / * * returns a data uri with the specified mime type and data . * / <nl> public static uri getdatauriforstring ( string mimetype , string data ) { <nl> - <nl> - / / doesn ' t decode using it . <nl> return uri . parse ( <nl> " data : " + mimetype + " ; base64 , " + base64 . encodetostring ( data . getbytes ( ) , base64 . no_wrap ) ) ; <nl> } <nl> mmm a / library / core / src / main / java / com / google / android / exoplayer2 / upstream / dataschemedatasource . java <nl> ppp b / library / core / src / main / java / com / google / android / exoplayer2 / upstream / dataschemedatasource . java <nl>
public final class dataschemedatasource extends basedatasource { <nl> string datastring = uriparts [ 1 ] ; <nl> if ( uriparts [ 0 ] . contains ( " ; base64 " ) ) { <nl> try { <nl> - <nl> data = base64 . decode ( datastring , / * flags = * / base64 . default ) ; <nl> } catch ( illegalargumentexception e ) { <nl> throw new parserexception ( " error while parsing base64 encoded string : " + datastring , e ) ;
import org . junit . rules . externalresource ; <nl>  <nl> @ override <nl> protected void before ( ) { <nl> - / / workaround limitation in androidx . media2 . session : 1 . 0 . 3 which session can only be instantiated <nl> - / / on thread with prepared looper . <nl> - <nl> - / / [ internal : b / 146536708 ] <nl> - if ( looper . mylooper ( ) = = null ) { <nl> - looper . prepare ( ) ; <nl> - } <nl> - <nl> context = applicationprovider . getapplicationcontext ( ) ; <nl> executor = executors . newfixedthreadpool ( 1 ) ;
import org . junit . runner . runwith ; <nl>  <nl> / * * tests widevine encrypted dash playbacks using offline keys . * / <nl> @ runwith ( androidjunit4 . class ) <nl> - <nl> @ ignore ( <nl> " need to be reconfigured / rewritten with an offline - compatible licence [ internal b / 176960595 ] . " ) <nl> public final class dashwidevineofflinetest {
public final class playbackstatslistener <nl> return activestatstracker = = null ? null : activestatstracker . build ( / * isfinal = * / false ) ; <nl> } <nl>  <nl> - / * * <nl> - * finishes all pending playback sessions . should be called when the listener is removed from the <nl> - * player or when the player is released . <nl> - * / <nl> - public void finishallsessions ( ) { <nl> - <nl> - / / an actual eventtime . should also simplify other cases where the listener needs to be released <nl> - / / separately from the player . <nl> - sessionmanager . finishallsessions ( <nl> - new eventtime ( <nl> - systemclock . elapsedrealtime ( ) , <nl> - timeline . empty , <nl> - / * windowindex = * / num , <nl> - / * mediaperiodid = * / null , <nl> - / * eventplaybackpositionms = * / num , <nl> - timeline . empty , <nl> - / * currentwindowindex = * / num , <nl> - / * currentmediaperiodid = * / null , <nl> - / * currentplaybackpositionms = * / num , <nl> - / * totalbuffereddurationms = * / num ) ) ; <nl> - } <nl> - <nl> / / playbacksessionmanager . listener implementation . <nl>  <nl> @ override <nl>
<nl> apply from : " $ gradle . ext . exoplayersettingsdir / constants . gradle " <nl> apply plugin : ' com . android . library ' <nl>  <nl> - repositories { <nl> - <nl> - / / robolectric snapshots . <nl> - maven { url " https : / / oss . sonatype . org / content / repositories / snapshots " } <nl> - } <nl> - <nl> android { <nl> compilesdkversion project . ext . compilesdkversion <nl>  <nl> mmm a / constants . gradle <nl> ppp b / constants . gradle <nl>
import java . util . list ; <nl> public final class defaultcastoptionsprovider implements optionsprovider { <nl>  <nl> / * * <nl> - * app id of the default media receiver app . apps that do not require drm support may use this <nl> - * receiver receiver app id . <nl> + * app id that points to the default media receiver app with basic drm support . <nl> * <nl> - * < p > see https : / / developers . google . com / cast / docs / caf_receiver / # default_media_receiver . <nl> + * < p > applications that require more complex drm authentication should < a <nl> + * href = " https : / / developers . google . com / cast / docs / web_receiver / streaming_protocols # drm " > create a <nl> + * custom receiver application < / a > . <nl> * / <nl> - public static final string app_id_default_receiver = <nl> - castmediacontrolintent . default_media_receiver_application_id ; <nl> - <nl> - / * * <nl> - * app id for receiver app with rudimentary support for drm . <nl> - * <nl> - * < p > this app id is only suitable for exoplayer ' s cast demo app , and it is not intended for <nl> - * production use . in order to use drm , custom receiver apps should be used . for environments that <nl> - * do not require drm , the default receiver app should be used ( see { @ link <nl> - * # app_id_default_receiver } ) . <nl> - * / <nl> - <nl> - / / b / 128603245 ] . <nl> public static final string app_id_default_receiver_with_drm = " a12d4273 " ; <nl>  <nl> @ override
import java . util . list ; <nl> public final class defaultcastoptionsprovider implements optionsprovider { <nl>  <nl> / * * <nl> - * app id of the default media receiver app . apps that do not require drm support may use this <nl> - * receiver receiver app id . <nl> + * app id that points to the default media receiver app with basic drm support . <nl> * <nl> - * < p > see https : / / developers . google . com / cast / docs / caf_receiver / # default_media_receiver . <nl> + * < p > applications that require more complex drm authentication should < a <nl> + * href = " https : / / developers . google . com / cast / docs / web_receiver / streaming_protocols # drm " > create a <nl> + * custom receiver application < / a > . <nl> * / <nl> - public static final string app_id_default_receiver = <nl> - castmediacontrolintent . default_media_receiver_application_id ; <nl> - <nl> - / * * <nl> - * app id for receiver app with rudimentary support for drm . <nl> - * <nl> - * < p > this app id is only suitable for exoplayer ' s cast demo app , and it is not intended for <nl> - * production use . in order to use drm , custom receiver apps should be used . for environments that <nl> - * do not require drm , the default receiver app should be used ( see { @ link <nl> - * # app_id_default_receiver } ) . <nl> - * / <nl> - <nl> - / / b / 128603245 ] . <nl> public static final string app_id_default_receiver_with_drm = " a12d4273 " ; <nl>  <nl> @ override
public class mediasessionutiltest { <nl>  <nl> @ test <nl> public void getsessioncompattoken_withmediacontrollercompat_returnsvalidtoken ( ) throws exception { <nl> - / / workaround to instantiate mediasession with public androidx . media dependency . <nl> - <nl> - / / androidx . media num . 2 . 0 . <nl> - if ( looper . mylooper ( ) = = null ) { <nl> - looper . prepare ( ) ; <nl> - } <nl> - <nl> context context = applicationprovider . getapplicationcontext ( ) ; <nl>  <nl> sessionplayerconnector sessionplayerconnector = playertestrule . getsessionplayerconnector ( ) ; <nl> mmm a / extensions / media2 / src / androidtest / java / com / google / android / exoplayer2 / ext / media2 / playertestrule . java <nl> ppp b / extensions / media2 / src / androidtest / java / com / google / android / exoplayer2 / ext / media2 / playertestrule . java <nl>
public class sessioncallbackbuildertest { <nl>  <nl> @ before <nl> public void setup ( ) { <nl> - / / workaround to instantiate mediasession with public androidx . media dependency . <nl> - <nl> - if ( looper . mylooper ( ) = = null ) { <nl> - looper . prepare ( ) ; <nl> - } <nl> context = applicationprovider . getapplicationcontext ( ) ; <nl> executor = playertestrule . getexecutor ( ) ; <nl> sessionplayerconnector = playertestrule . getsessionplayerconnector ( ) ; <nl> mmm a / extensions / media2 / src / androidtest / java / com / google / android / exoplayer2 / ext / media2 / sessionplayerconnectortest . java <nl> ppp b / extensions / media2 / src / androidtest / java / com / google / android / exoplayer2 / ext / media2 / sessionplayerconnectortest . java <nl>
public class timelineplaylistmanager implements playlistmanager { <nl>  <nl> @ override <nl> public boolean setmediaitem ( player player , mediaitem mediaitem ) { <nl> - <nl> list < mediaitem > playlist = new arraylist < > ( ) ; <nl> playlist . add ( mediaitem ) ; <nl> return setplaylist ( player , playlist , / * metadata * / null ) ;
public abstract class decoderaudiorenderer extends baserenderer implements media <nl> } <nl> } <nl>  <nl> - private void processendofstream ( ) throws exoplaybackexception { <nl> + private void processendofstream ( ) throws audiosink . writeexception { <nl> outputstreamended = true ; <nl> - try { <nl> - audiosink . playtoendofstream ( ) ; <nl> - } catch ( audiosink . writeexception e ) { <nl> - <nl> - throw createrendererexception ( e , inputformat ) ; <nl> - } <nl> + audiosink . playtoendofstream ( ) ; <nl> } <nl>  <nl> private void flushdecoder ( ) throws exoplaybackexception { <nl> mmm a / library / core / src / main / java / com / google / android / exoplayer2 / audio / mediacodecaudiorenderer . java <nl> ppp b / library / core / src / main / java / com / google / android / exoplayer2 / audio / mediacodecaudiorenderer . java <nl>
public class mediacodecaudiorenderer extends mediacodecrenderer implements media <nl> try { <nl> fullyconsumed = audiosink . handlebuffer ( buffer , bufferpresentationtimeus , samplecount ) ; <nl> } catch ( audiosink . initializationexception | audiosink . writeexception e ) { <nl> - <nl> - throw createrendererexception ( e , inputformat ) ; <nl> + throw createrendererexception ( e , format ) ; <nl> } <nl>  <nl> if ( fullyconsumed ) { <nl>
public class mediacodecaudiorenderer extends mediacodecrenderer implements media <nl> try { <nl> audiosink . playtoendofstream ( ) ; <nl> } catch ( audiosink . writeexception e ) { <nl> - <nl> - throw createrendererexception ( e , inputformat ) ; <nl> + format outputformat = getcurrentoutputformat ( ) ; <nl> + throw createrendererexception ( e , outputformat ! = null ? outputformat : inputformat ) ; <nl> } <nl> }
public abstract class mediacodecrenderer extends baserenderer { <nl> return false ; <nl> } <nl>  <nl> - <nl> - / / always be a keyframe if waitingforfirstsyncsample is true . check this , and remove if so . <nl> - if ( waitingforfirstsyncsample & & ! buffer . iskeyframe ( ) ) { <nl> - buffer . clear ( ) ; <nl> - if ( codecreconfigurationstate = = reconfiguration_state_queue_pending ) { <nl> - / / the buffer we just cleared contained reconfiguration data . we need to re - write this <nl> - / / data into a subsequent buffer ( if there is one ) . <nl> - codecreconfigurationstate = reconfiguration_state_write_pending ; <nl> - } <nl> - return true ; <nl> - } <nl> - waitingforfirstsyncsample = false ; <nl> - <nl> boolean bufferencrypted = buffer . isencrypted ( ) ; <nl> if ( bufferencrypted ) { <nl> buffer . cryptoinfo . increasecleardatafirstsubsampleby ( adaptivereconfigurationbytes ) ; <nl> mmm a / library / core / src / main / java / com / google / android / exoplayer2 / source / samplequeue . java <nl> ppp b / library / core / src / main / java / com / google / android / exoplayer2 / source / samplequeue . java <nl>
public final class exoplayertest { <nl> assertthat ( initialmediaitems ) . containsexactlyelementsin ( currentmediaitems ) ; <nl> } <nl>  <nl> - <nl> - @ test <nl> - @ config ( minsdk = config . oldest_sdk , maxsdk = config . target_sdk ) <nl> - public void buildsimpleexoplayerinbackgroundthread_doesnotthrow ( ) throws exception { <nl> - thread builderthread = new thread ( ( ) - > new simpleexoplayer . builder ( context ) . build ( ) ) ; <nl> - atomicreference < throwable > builderthrow = new atomicreference < > ( ) ; <nl> - builderthread . setuncaughtexceptionhandler ( ( thread , throwable ) - > builderthrow . set ( throwable ) ) ; <nl> - <nl> - builderthread . start ( ) ; <nl> - builderthread . join ( ) ; <nl> - <nl> - assertthat ( builderthrow . get ( ) ) . isnull ( ) ; <nl> - } <nl> - <nl> / / internal methods . <nl>  <nl> private static actionschedule . builder addsurfaceswitch ( actionschedule . builder builder ) { <nl> mmm / dev / null <nl> ppp b / library / core / src / test / java / com / google / android / exoplayer2 / simpleexoplayertest . java <nl>
public class mediacodecaudiorenderer extends mediacodecrenderer implements media <nl> return mediaformat ; <nl> } <nl>  <nl> - private void configureaudiosink ( <nl> - int encoding , int channelcount , int samplerate , @ nullable int [ ] channelmap ) <nl> - throws exoplaybackexception { <nl> - try { <nl> - audiosink . configure ( <nl> - encoding , <nl> - channelcount , <nl> - samplerate , <nl> - / * specifiedbuffersize = * / num , <nl> - channelmap , <nl> - inputformat . encoderdelay , <nl> - inputformat . encoderpadding ) ; <nl> - } catch ( audiosink . configurationexception e ) { <nl> - <nl> - throw createrendererexception ( e , inputformat ) ; <nl> - } <nl> - } <nl> - <nl> private void updatecurrentposition ( ) { <nl> long newcurrentpositionus = audiosink . getcurrentpositionus ( isended ( ) ) ; <nl> if ( newcurrentpositionus ! = audiosink . current_position_not_set ) {
public final class downloadmanager { <nl> if ( ! iscanceled ) { <nl> iscanceled = true ; <nl> downloader . cancel ( ) ; <nl> - <nl> - interrupt ( ) ; <nl> } <nl> } <nl>  <nl> mmm a / library / core / src / main / java / com / google / android / exoplayer2 / offline / progressivedownloader . java <nl> ppp b / library / core / src / main / java / com / google / android / exoplayer2 / offline / progressivedownloader . java <nl>
public class adaptivetrackselection extends basetrackselection { <nl> protected boolean canselectformat ( <nl> format format , int trackbitrate , float playbackspeed , long effectivebitrate ) { <nl>  <nl> - boolean isiframeonly = ( format . roleflags & c . role_flag_trick_play ) ! = num ; <nl> + boolean isnoniframeonly = ( format . roleflags & c . role_flag_trick_play ) = = num ; <nl> boolean canselect = math . round ( trackbitrate * playbackspeed ) < = effectivebitrate ; <nl>  <nl> - if ( math . abs ( playbackspeed ) > num . 0f ) { <nl> - canselect = isiframeonly ; <nl> - } else { <nl> - canselect = ! isiframeonly & & canselect ; <nl> - } <nl> - return canselect ; <nl> - <nl> + return canselect & & isnoniframeonly ; / / default is not to use the idr only tracks in selection <nl> } <nl>  <nl> / * *
public class samplequeue implements trackoutput { <nl> boolean isfirstformat = downstreamformat = = null ; <nl> @ nullable drminitdata olddrminitdata = isfirstformat ? null : downstreamformat . drminitdata ; <nl> downstreamformat = newformat ; <nl> - if ( drmsessionmanager = = drmsessionmanager . dummy ) { <nl> - / / avoid attempting to acquire a session using the dummy drm session manager . it ' s likely that <nl> - / / the media source creation has not yet been migrated and the renderer can acquire the <nl> - / / session for the read drm init data . <nl> - <nl> - return ; <nl> - } <nl> @ nullable drminitdata newdrminitdata = newformat . drminitdata ; <nl> outputformatholder . drmsession = currentdrmsession ; <nl> if ( ! isfirstformat & & util . areequal ( olddrminitdata , newdrminitdata ) ) { <nl>
public class samplequeue implements trackoutput { <nl> * @ return whether it ' s possible to read the next sample . <nl> * / <nl> private boolean mayreadsample ( int relativereadindex ) { <nl> - if ( drmsessionmanager = = drmsessionmanager . dummy ) { <nl> - <nl> - / / for protected content it ' s likely that the drmsessionmanager is still being injected into <nl> - / / the renderers . we assume that the renderers will be able to acquire a drmsession if needed . <nl> - return true ; <nl> - } <nl> return currentdrmsession = = null <nl> | | currentdrmsession . getstate ( ) = = drmsession . state_opened_with_keys <nl> | | ( ( flags [ relativereadindex ] & c . buffer_flag_encrypted ) = = num
import com . google . android . exoplayer2 . drm . drmsession ; <nl> * / <nl> public final class formatholder { <nl>  <nl> - / * * whether the { @ link # format } setter also sets the { @ link # drmsession } field . * / <nl> - <nl> - / / ref : b / 129764794 ] . <nl> - public boolean includesdrmsession ; <nl> - <nl> / * * an accompanying context for decrypting samples in the format . * / <nl> @ nullable public drmsession < ? > drmsession ; <nl>  <nl>
public final class fakeextractoroutput implements extractoroutput , dumper . dumpab <nl> } <nl> } <nl>  <nl> - public void assertequals ( fakeextractoroutput expected ) { <nl> - assertthat ( numberoftracks ) . isequalto ( expected . numberoftracks ) ; <nl> - assertthat ( tracksended ) . isequalto ( expected . tracksended ) ; <nl> - if ( expected . seekmap = = null ) { <nl> - assertthat ( seekmap ) . isnull ( ) ; <nl> - } else { <nl> - <nl> - seekmap expectedseekmap = assertions . checknotnull ( expected . seekmap ) ; <nl> - seekmap seekmap = assertions . checknotnull ( this . seekmap ) ; <nl> - assertthat ( seekmap . getclass ( ) ) . isequalto ( expectedseekmap . getclass ( ) ) ; <nl> - assertthat ( seekmap . isseekable ( ) ) . isequalto ( expectedseekmap . isseekable ( ) ) ; <nl> - assertthat ( seekmap . getseekpoints ( 0 ) ) . isequalto ( expectedseekmap . getseekpoints ( 0 ) ) ; <nl> - } <nl> - for ( int i = num ; i < numberoftracks ; i + + ) { <nl> - assertthat ( trackoutputs . keyat ( i ) ) . isequalto ( expected . trackoutputs . keyat ( i ) ) ; <nl> - trackoutputs . valueat ( i ) . assertequals ( expected . trackoutputs . valueat ( i ) ) ; <nl> - } <nl> - } <nl> - <nl> / * * <nl> * asserts that dump of this { @ link fakeextractoroutput } is equal to expected dump which is read <nl> * from { @ code dumpfile } . <nl> mmm a / testutils / src / main / java / com / google / android / exoplayer2 / testutil / faketrackoutput . java <nl> ppp b / testutils / src / main / java / com / google / android / exoplayer2 / testutil / faketrackoutput . java <nl>
public final class ac3util { <nl> * contain the start of a syncframe . <nl> * / <nl> public static int parsetruehdsyncframeaudiosamplecount ( byte [ ] syncframe ) { <nl> - <nl> - / / the syncword ends num xba for truehd or num xbb for mlp . <nl> + / / see " dolby truehd ( mlp ) high - level bitstream description " on the dolby developer site , <nl> + / / subsections num . 2 and num . 2 . 1 . the syncword ends num xba for truehd or num xbb for mlp . <nl> if ( syncframe [ 4 ] ! = ( byte ) num xf8 <nl> | | syncframe [ 5 ] ! = ( byte ) num x72 <nl> | | syncframe [ 6 ] ! = ( byte ) num x6f
public final class flacextractor implements extractor { <nl> state = state_read_frames ; <nl> } <nl>  <nl> - <nl> - / / to avoid unnecessary copies in scratch . <nl> private int readframes ( extractorinput input ) throws ioexception , interruptedexception { <nl> assertions . checknotnull ( trackoutput ) ; <nl> assertions . checknotnull ( flacstreammetadata ) ;
public final class ac3util { <nl> * contain the start of a syncframe . <nl> * / <nl> public static int parsetruehdsyncframeaudiosamplecount ( byte [ ] syncframe ) { <nl> - <nl> - / / the syncword ends num xba for truehd or num xbb for mlp . <nl> + / / see " dolby truehd ( mlp ) high - level bitstream description " on the dolby developer site , <nl> + / / subsections num . 2 and num . 2 . 1 . the syncword ends num xba for truehd or num xbb for mlp . <nl> if ( syncframe [ 4 ] ! = ( byte ) num xf8 <nl> | | syncframe [ 5 ] ! = ( byte ) num x72 <nl> | | syncframe [ 6 ] ! = ( byte ) num x6f
<nl> * remove ` analyticscollector . factory ` . instances should be created directly , <nl> and the ` player ` should be set by calling ` analyticscollector . setplayer ` . <nl> * add ` playbackstatslistener ` to collect ` playbackstats ` for analysis and <nl> - analytics reporting ( <nl> + analytics reporting . <nl> * datasource <nl> * add ` dataspec . httprequestheaders ` to support setting per - request headers for <nl> http and https . <nl>
<nl> ` c . msg_set_output_buffer_renderer ` . <nl> * use ` videodecoderrenderer ` as an implementation of <nl> ` videodecoderoutputbufferrenderer ` , instead of ` videodecodersurfaceview ` . <nl> - * flac extension : <nl> - * update to use ndk r20 . <nl> - * fix build <nl> - ( [ # 6601 ] ( https : / / github . com / google / exoplayer / issues / 6601 ) . <nl> + * flac extension : update to use ndk r20 . <nl> + * opus extension : update to use ndk r20 . <nl> * ffmpeg extension : <nl> * update to use ndk r20 . <nl> * update to use ffmpeg version num . 2 . it is necessary to rebuild the native part <nl> of the extension after this change , following the instructions in the <nl> extension ' s readme . <nl> - * opus extension : update to use ndk r20 . <nl> - * mediasession extension : make media session connector dispatch <nl> - ` action_set_captioning_enabled ` . <nl> + * mediasession extension : add ` mediasessionconnector . setcaptioncallback ` to <nl> + support ` action_set_captioning_enabled ` events . <nl> * gvr extension : this extension is now deprecated . <nl> - * demo apps ( <nl> - * add [ surfacecontrol demo app ] ( https : / / github . com / google / exoplayer / tree / dev - v2 / demos / surface ) <nl> + * demo apps : <nl> + * add [ surfacecontrol demo app ] ( https : / / github . com / google / exoplayer / tree / r2 . 11 . 0 / demos / surface ) <nl> to show how to use the android num ` surfacecontrol ` api with exoplayer <nl> ( [ # 677 ] ( https : / / github . com / google / exoplayer / issues / 677 ) ) . <nl> * add support for subtitle files to the <nl> - [ main demo app ] ( https : / / github . com / google / exoplayer / tree / dev - v2 / demos / main ) <nl> + [ main demo app ] ( https : / / github . com / google / exoplayer / tree / r2 . 11 . 0 / demos / main ) <nl> ( [ # 5523 ] ( https : / / github . com / google / exoplayer / issues / 5523 ) ) . <nl> * remove the ima demo app . ima functionality is demonstrated by the <nl> - [ main demo app ] ( https : / / github . com / google / exoplayer / tree / dev - v2 / demos / main ) . <nl> + [ main demo app ] ( https : / / github . com / google / exoplayer / tree / r2 . 11 . 0 / demos / main ) . <nl> * add basic drm support to the <nl> - [ cast demo app ] ( https : / / github . com / google / exoplayer / tree / dev - v2 / demos / cast ) . <nl> + [ cast demo app ] ( https : / / github . com / google / exoplayer / tree / r2 . 11 . 0 / demos / cast ) . <nl> * testutils : publish the ` testutils ` module to simplify unit testing with <nl> exoplayer ( [ # 6267 ] ( https : / / github . com / google / exoplayer / issues / 6267 ) ) . <nl> * ima extension : remove ` adsmanager ` listeners on release to avoid leaking an
import java . io . ioexception ; <nl> if ( formats [ relativereadindex ] ! = downstreamformat ) { <nl> / / a format can be read . <nl> return true ; <nl> - } else if ( assertions . checknotnull ( downstreamformat ) . drminitdata = = null ) { <nl> - / / a sample from a clear section can be read . <nl> - return true ; <nl> - } else if ( drmsessionmanager = = drmsessionmanager . dummy <nl> - | | assertions . checknotnull ( currentdrmsession ) . getstate ( ) <nl> - = = drmsession . state_opened_with_keys ) { <nl> - <nl> - / / b / 122519809 ] . <nl> - return true ; <nl> - } else { <nl> - / / a clear sample in an encrypted section may be read if playclearsampleswithoutkeys is true . <nl> - return ( flags [ relativereadindex ] & c . buffer_flag_encrypted ) = = num <nl> - & & assertions . checknotnull ( currentdrmsession ) . playclearsampleswithoutkeys ( ) ; <nl> } <nl> + return mayreadsample ( relativereadindex ) ; <nl> } <nl>  <nl> / * * <nl>
import java . io . ioexception ; <nl> return c . result_format_read ; <nl> } <nl>  <nl> - / / it ' s likely that the media source creation has not yet been migrated and the renderer can <nl> - / / acquire the session for the sample . <nl> - <nl> - boolean skipdrmchecks = drmsessionmanager = = drmsessionmanager . dummy ; <nl> - boolean isnextsampleencrypted = ( flags [ relativereadindex ] & c . buffer_flag_encrypted ) ! = num ; <nl> - <nl> - boolean mayreadsample = <nl> - skipdrmchecks <nl> - | | util . castnonnull ( downstreamformat ) . drminitdata = = null <nl> - | | ( assertions . checknotnull ( currentdrmsession ) . playclearsampleswithoutkeys ( ) <nl> - & & ! isnextsampleencrypted ) <nl> - | | assertions . checknotnull ( currentdrmsession ) . getstate ( ) <nl> - = = drmsession . state_opened_with_keys ; <nl> - if ( ! mayreadsample ) { <nl> + if ( ! mayreadsample ( relativereadindex ) ) { <nl> return c . result_nothing_read ; <nl> } <nl>  <nl>
import java . io . ioexception ; <nl> if ( formats [ relativereadindex ] ! = downstreamformat ) { <nl> / / a format can be read . <nl> return true ; <nl> - } else if ( assertions . checknotnull ( downstreamformat ) . drminitdata = = null ) { <nl> - / / a sample from a clear section can be read . <nl> - return true ; <nl> - } else if ( drmsessionmanager = = drmsessionmanager . dummy <nl> - | | assertions . checknotnull ( currentdrmsession ) . getstate ( ) <nl> - = = drmsession . state_opened_with_keys ) { <nl> - <nl> - / / b / 122519809 ] . <nl> - return true ; <nl> - } else { <nl> - / / a clear sample in an encrypted section may be read if playclearsampleswithoutkeys is true . <nl> - return ( flags [ relativereadindex ] & c . buffer_flag_encrypted ) = = num <nl> - & & assertions . checknotnull ( currentdrmsession ) . playclearsampleswithoutkeys ( ) ; <nl> } <nl> + return mayreadsample ( relativereadindex ) ; <nl> } <nl>  <nl> / * * <nl>
import java . io . ioexception ; <nl> return c . result_format_read ; <nl> } <nl>  <nl> - / / it ' s likely that the media source creation has not yet been migrated and the renderer can <nl> - / / acquire the session for the sample . <nl> - <nl> - boolean skipdrmchecks = drmsessionmanager = = drmsessionmanager . dummy ; <nl> - boolean isnextsampleencrypted = ( flags [ relativereadindex ] & c . buffer_flag_encrypted ) ! = num ; <nl> - <nl> - boolean mayreadsample = <nl> - skipdrmchecks <nl> - | | util . castnonnull ( downstreamformat ) . drminitdata = = null <nl> - | | ( assertions . checknotnull ( currentdrmsession ) . playclearsampleswithoutkeys ( ) <nl> - & & ! isnextsampleencrypted ) <nl> - | | assertions . checknotnull ( currentdrmsession ) . getstate ( ) <nl> - = = drmsession . state_opened_with_keys ; <nl> - if ( ! mayreadsample ) { <nl> + if ( ! mayreadsample ( relativereadindex ) ) { <nl> return c . result_nothing_read ; <nl> } <nl>  <nl>
public final class flacextractor implements extractor { <nl> state = state_read_frames ; <nl> } <nl>  <nl> - <nl> - / / to avoid unnecessary copies in scratch . <nl> private int readframes ( extractorinput input ) throws ioexception , interruptedexception { <nl> assertions . checknotnull ( trackoutput ) ; <nl> assertions . checknotnull ( flacstreammetadata ) ;
public class defaultdrmsessionmanager < t extends exomediacrypto > <nl> if ( preparecallscount + + = = num ) { <nl> assertions . checkstate ( exomediadrm = = null ) ; <nl> exomediadrm = exomediadrmprovider . acquireexomediadrm ( uuid ) ; <nl> - if ( multisession & & c . widevine_uuid . equals ( uuid ) & & util . sdk_int > = num ) { <nl> - <nl> - / / useful if defaultdrmsession instances were aware of one another ' s state , which is not <nl> - / / implemented . or if custom renderers are being used that allow playback to proceed before <nl> - / / keys , which seems unlikely to be true in practice . <nl> - exomediadrm . setpropertystring ( " sessionsharing " , " enable " ) ; <nl> - } <nl> exomediadrm . setoneventlistener ( new mediadrmeventlistener ( ) ) ; <nl> } <nl> }
<nl> # release notes # <nl>  <nl> - # # # num . 10 . 5 ( <nl> + # # # num . 10 . 5 ( 2019 - 09 - 20 ) # # # <nl>  <nl> * add ` player . isplaying ` and ` eventlistener . onisplayingchanged ` to check whether <nl> the playback position is advancing . this helps to determine if playback is
<nl> * add top - level playlist api <nl> ( [ # 6161 ] ( https : / / github . com / google / exoplayer / issues / 6161 ) ) . <nl>  <nl> - # # # num . 10 . 5 ( <nl> + # # # num . 10 . 5 ( 2019 - 09 - 20 ) # # # <nl>  <nl> * track selection <nl> * add ` allowaudiomixedchannelcountadaptiveness ` parameter to
public final class frameworkmediadrm implements exomediadrm < frameworkmediacrypto <nl> } <nl>  <nl> @ override <nl> - public void acquire ( ) { <nl> - <nl> + public synchronized void acquire ( ) { <nl> + assertions . checkstate ( referencecount > num ) ; <nl> + referencecount + + ; <nl> } <nl>  <nl> @ override <nl> - public void release ( ) { <nl> - mediadrm . release ( ) ; <nl> + public synchronized void release ( ) { <nl> + if ( - - referencecount = = num ) { <nl> + mediadrm . release ( ) ; <nl> + } <nl> } <nl>  <nl> @ override
import javax . annotation . meta . typequalifierdefault ; <nl> * / <nl> @ nonnull <nl> @ typequalifierdefault ( elementtype . type_use ) <nl> - <nl> - / / types are used incorrectly . <nl> - / / @ undermigration ( status = migrationstatus . strict ) <nl> + @ undermigration ( status = migrationstatus . strict ) <nl> @ retention ( retentionpolicy . class ) <nl> public @ interface nonnullapi { }
import javax . annotation . meta . typequalifierdefault ; <nl> * / <nl> @ nonnull <nl> @ typequalifierdefault ( elementtype . type_use ) <nl> - <nl> - / / types are used incorrectly . <nl> - / / @ undermigration ( status = migrationstatus . strict ) <nl> + @ undermigration ( status = migrationstatus . strict ) <nl> @ retention ( retentionpolicy . class ) <nl> public @ interface nonnullapi { }
public final class decryptablesamplequeuereader { <nl> if ( onlypropagateformatchanges & & currentformat = = formatholder . format ) { <nl> return c . result_nothing_read ; <nl> } <nl> - onformat ( assertions . checknotnull ( formatholder . format ) ) ; <nl> - <nl> - / / [ internal ref : b / 129764794 ] . <nl> - outputformatholder . includesdrmsession = true ; <nl> - outputformatholder . format = formatholder . format ; <nl> - outputformatholder . drmsession = currentsession ; <nl> + onformat ( assertions . checknotnull ( formatholder . format ) , outputformatholder ) ; <nl> } <nl> return result ; <nl> } <nl>
public final class defaultaudiosink implements audiosink { <nl> @ targetapi ( 21 ) <nl> private int writenonblockingwithavsyncv21 ( audiotrack audiotrack , bytebuffer buffer , int size , <nl> long presentationtimeus ) { <nl> - <nl> - / / if ( util . sdk_int > = num ) { <nl> - / / / / the underlying platform audiotrack writes av sync headers directly . <nl> - / / return audiotrack . write ( buffer , size , write_non_blocking , presentationtimeus * num ) ; <nl> - / / } <nl> + if ( util . sdk_int > = num ) { <nl> + / / the underlying platform audiotrack writes av sync headers directly . <nl> + return audiotrack . write ( buffer , size , write_non_blocking , presentationtimeus * num ) ; <nl> + } <nl> if ( avsyncheader = = null ) { <nl> avsyncheader = bytebuffer . allocate ( 16 ) ; <nl> avsyncheader . order ( byteorder . big_endian ) ;
public final class defaultaudiosink implements audiosink { <nl> @ targetapi ( 21 ) <nl> private int writenonblockingwithavsyncv21 ( audiotrack audiotrack , bytebuffer buffer , int size , <nl> long presentationtimeus ) { <nl> - <nl> - / / if ( util . sdk_int > = num ) { <nl> - / / / / the underlying platform audiotrack writes av sync headers directly . <nl> - / / return audiotrack . write ( buffer , size , write_non_blocking , presentationtimeus * num ) ; <nl> - / / } <nl> + if ( util . sdk_int > = num ) { <nl> + / / the underlying platform audiotrack writes av sync headers directly . <nl> + return audiotrack . write ( buffer , size , write_non_blocking , presentationtimeus * num ) ; <nl> + } <nl> if ( avsyncheader = = null ) { <nl> avsyncheader = bytebuffer . allocate ( 16 ) ; <nl> avsyncheader . order ( byteorder . big_endian ) ;
<nl> - / * <nl> - * copyright ( c ) num the android open source project <nl> - * <nl> - * licensed under the apache license , version num . 0 ( the " license " ) ; <nl> - * you may not use this file except in compliance with the license . <nl> - * you may obtain a copy of the license at <nl> - * <nl> - * http : / / www . apache . org / licenses / license - 2 . 0 <nl> - * <nl> - * unless required by applicable law or agreed to in writing , software <nl> - * distributed under the license is distributed on an " as is " basis , <nl> - * without warranties or conditions of any kind , either express or implied . <nl> - * see the license for the specific language governing permissions and <nl> - * limitations under the license . <nl> - * / <nl> - package com . google . android . exoplayer2 . drm ; <nl> - <nl> - / * * <nl> - * a reference - counted resource used in the decryption of media samples . <nl> - * <nl> - * @ param < t > the reference type with which to make { @ link owner # onlastreferencereleased } calls . <nl> - * subclasses are expected to pass themselves . <nl> - * / <nl> - public abstract class decryptionresource < t extends decryptionresource < t > > { <nl> - <nl> - / * * <nl> - * implemented by the class in charge of managing a { @ link decryptionresource resource ' s } <nl> - * lifecycle . <nl> - * / <nl> - public interface owner < t extends decryptionresource < t > > { <nl> - <nl> - / * * <nl> - * called when the last reference to a { @ link decryptionresource } is { @ link # releasereference ( ) <nl> - * released } . <nl> - * / <nl> - void onlastreferencereleased ( t resource ) ; <nl> - } <nl> - <nl> - <nl> - private final decryptionresource . owner < t > owner ; <nl> - private int referencecount ; <nl> - <nl> - / * * <nl> - * creates a new instance with reference count zero . <nl> - * <nl> - * @ param owner the owner of this instance . <nl> - * / <nl> - public decryptionresource ( owner < t > owner ) { <nl> - this . owner = owner ; <nl> - referencecount = num ; <nl> - } <nl> - <nl> - / * * increases by one the reference count for this resource . * / <nl> - public void acquirereference ( ) { <nl> - referencecount + + ; <nl> - } <nl> - <nl> - / * * <nl> - * decreases by one the reference count for this resource , and notifies the owner if said count <nl> - * reached zero as a result of this operation . <nl> - * <nl> - * < p > must only be called as releasing counter - part of { @ link # acquirereference ( ) } . <nl> - * / <nl> - @ suppresswarnings ( " unchecked " ) <nl> - public void releasereference ( ) { <nl> - if ( - - referencecount = = num ) { <nl> - owner . onlastreferencereleased ( ( t ) this ) ; <nl> - } else if ( referencecount < num ) { <nl> - throw new illegalstateexception ( " illegal release of resource . " ) ; <nl> - } <nl> - } <nl> - }
<nl> ( [ # 5520 ] ( https : / / github . com / google / exoplayer / issues / 5520 ) ) . <nl> * offline : <nl> * improve offline support . ` downloadmanager ` now tracks all offline content , <nl> - not just tasks in progress . <nl> + not just tasks in progress . read [ this page ] ( https : / / exoplayer . dev / downloading - media . html ) for <nl> + more details . <nl> * caching : <nl> * improve performance of ` simplecache ` <nl> ( [ # 4253 ] ( https : / / github . com / google / exoplayer / issues / 4253 ) ) .
<nl> # # # num . 10 . 0 # # # <nl>  <nl> * core library : <nl> - * improve decoder re - use between playbacks . <nl> - here ( [ # 2826 ] ( https : / / github . com / google / exoplayer / issues / 2826 ) ) . <nl> + * improve decoder re - use between playbacks <nl> + ( [ # 2826 ] ( https : / / github . com / google / exoplayer / issues / 2826 ) ) . read <nl> + [ this blog post ] ( https : / / medium . com / google - exoplayer / improved - decoder - reuse - in - exoplayer - ef4c6d99591d ) <nl> + for more details . <nl> * rename ` extractormediasource ` to ` progressivemediasource ` . <nl> * fix issue where using ` progressivemediasource . factory ` would mean that <nl> ` defaultextractorsfactory ` would be kept by proguard . custom
<nl> ( [ # 5520 ] ( https : / / github . com / google / exoplayer / issues / 5520 ) ) . <nl> * offline : <nl> * improve offline support . ` downloadmanager ` now tracks all offline content , <nl> - not just tasks in progress . <nl> + not just tasks in progress . read [ this page ] ( https : / / exoplayer . dev / downloading - media . html ) for <nl> + more details . <nl> * caching : <nl> * improve performance of ` simplecache ` <nl> ( [ # 4253 ] ( https : / / github . com / google / exoplayer / issues / 4253 ) ) .
<nl> # # # num . 10 . 0 # # # <nl>  <nl> * core library : <nl> - * improve decoder re - use between playbacks . <nl> - here ( [ # 2826 ] ( https : / / github . com / google / exoplayer / issues / 2826 ) ) . <nl> + * improve decoder re - use between playbacks <nl> + ( [ # 2826 ] ( https : / / github . com / google / exoplayer / issues / 2826 ) ) . read <nl> + [ this blog post ] ( https : / / medium . com / google - exoplayer / improved - decoder - reuse - in - exoplayer - ef4c6d99591d ) <nl> + for more details . <nl> * rename ` extractormediasource ` to ` progressivemediasource ` . <nl> * fix issue where using ` progressivemediasource . factory ` would mean that <nl> ` defaultextractorsfactory ` would be kept by proguard . custom
public class defaultdownloaderfactory implements downloaderfactory { <nl> throw new illegalstateexception ( " module missing for : " + request . type ) ; <nl> } <nl> try { <nl> - <nl> return constructor . newinstance ( request . uri , request . streamkeys , downloaderconstructorhelper ) ; <nl> } catch ( exception e ) { <nl> throw new runtimeexception ( " failed to instantiate downloader for : " + request . type , e ) ; <nl> mmm a / library / core / src / main / java / com / google / android / exoplayer2 / offline / downloadmanager . java <nl> ppp b / library / core / src / main / java / com / google / android / exoplayer2 / offline / downloadmanager . java <nl>
public final class downloadmanager { <nl> return true ; <nl> } <nl>  <nl> - <nl> - / / allows updating idle at the same point as the downloads that can be queried changes . <nl> private void oninitialized ( list < download > downloads ) { <nl> initialized = true ; <nl> this . downloads . addall ( downloads ) ;
import java . util . list ; <nl> out . nalunitlengthfieldlength = hevcconfig . nalunitlengthfieldlength ; <nl> } else if ( childatomtype = = atom . type_dvcc | | childatomtype = = atom . type_dvvc ) { <nl> dolbyvisionconfig dolbyvisionconfig = dolbyvisionconfig . parse ( parent ) ; <nl> - <nl> - if ( dolbyvisionconfig ! = null & & dolbyvisionconfig . profile = = num ) { <nl> + if ( dolbyvisionconfig ! = null ) { <nl> codecs = dolbyvisionconfig . codecs ; <nl> mimetype = mimetypes . video_dolby_vision ; <nl> } <nl> mmm a / library / core / src / main / java / com / google / android / exoplayer2 / video / mediacodecvideorenderer . java <nl> ppp b / library / core / src / main / java / com / google / android / exoplayer2 / video / mediacodecvideorenderer . java <nl>
public class defaultdownloaderfactory implements downloaderfactory { <nl> throw new illegalstateexception ( " module missing for : " + request . type ) ; <nl> } <nl> try { <nl> - <nl> return constructor . newinstance ( request . uri , request . streamkeys , downloaderconstructorhelper ) ; <nl> } catch ( exception e ) { <nl> throw new runtimeexception ( " failed to instantiate downloader for : " + request . type , e ) ; <nl> mmm a / library / core / src / main / java / com / google / android / exoplayer2 / offline / downloadmanager . java <nl> ppp b / library / core / src / main / java / com / google / android / exoplayer2 / offline / downloadmanager . java <nl>
public final class downloadmanager { <nl> return true ; <nl> } <nl>  <nl> - <nl> - / / allows updating idle at the same point as the downloads that can be queried changes . <nl> private void oninitialized ( list < download > downloads ) { <nl> initialized = true ; <nl> this . downloads . addall ( downloads ) ;
decoder_func ( jlong , vpxinit , jboolean disableloopfilter , <nl> return num ; <nl> } <nl> # ifdef vpx_ctrl_vp9_decode_set_row_mt <nl> - err = vpx_codec_control_ ( context - > decoder , vp9d_set_row_mt , <nl> - enablerowmultithreadmode ) ; <nl> + err = vpx_codec_control ( context - > decoder , vp9d_set_row_mt , <nl> + enablerowmultithreadmode ) ; <nl> if ( err ) { <nl> loge ( " error : failed to enable row multi thread mode , error = % d . " , err ) ; <nl> } <nl> # endif <nl> if ( disableloopfilter ) { <nl> - <nl> - err = vpx_codec_control_ ( context - > decoder , vp9_set_skip_loop_filter , true ) ; <nl> + err = vpx_codec_control ( context - > decoder , vp9_set_skip_loop_filter , true ) ; <nl> if ( err ) { <nl> loge ( " error : failed to shut off libvpx loop filter , error = % d . " , err ) ; <nl> }
public abstract class gvrplayeractivity extends gvractivity { <nl> mainhandler = new handler ( looper . getmainlooper ( ) ) ; <nl> } <nl>  <nl> - <nl> - @ suppresswarnings ( " nullness : override . param . invalid " ) <nl> @ override <nl> - protected void oncreate ( bundle savedinstancestate ) { <nl> + protected void oncreate ( @ nullable bundle savedinstancestate ) { <nl> super . oncreate ( savedinstancestate ) ; <nl> setscreenalwayson ( true ) ;
public final class exodatabaseprovider extends sqliteopenhelper implements datab <nl>  <nl> @ override <nl> public void ondowngrade ( sqlitedatabase db , int oldversion , int newversion ) { <nl> - <nl> - super . ondowngrade ( db , oldversion , newversion ) ; <nl> + wipedatabase ( db ) ; <nl> + } <nl> + <nl> + / * * <nl> + * makes a best effort to wipe the existing database . the wipe may be incomplete if the database <nl> + * contains foreign key constraints . <nl> + * / <nl> + private static void wipedatabase ( sqlitedatabase db ) { <nl> + string [ ] columns = { " type " , " name " } ; <nl> + try ( cursor cursor = <nl> + db . query ( <nl> + " sqlite_master " , <nl> + columns , <nl> + / * selection = * / null , <nl> + / * selectionargs = * / null , <nl> + / * groupby = * / null , <nl> + / * having = * / null , <nl> + / * orderby = * / null ) ) { <nl> + while ( cursor . movetonext ( ) ) { <nl> + string type = cursor . getstring ( 0 ) ; <nl> + string name = cursor . getstring ( 1 ) ; <nl> + if ( ! " sqlite_sequence " . equals ( name ) ) { <nl> + / / if it ' s not an sql - controlled entity , drop it <nl> + string sql = " drop " + type + " if exists " + name ; <nl> + try { <nl> + db . execsql ( sql ) ; <nl> + } catch ( sqlexception e ) { <nl> + log . e ( tag , " error executing " + sql , e ) ; <nl> + } <nl> + } <nl> + } <nl> + } <nl> } <nl> }
public final class downloadmanager { <nl>  <nl> private void stopdownloadthread ( @ targetstate int targetstate ) { <nl> this . targetstate = targetstate ; <nl> - <nl> - / / stopping in a timely way . fix this . <nl> - if ( downloader ! = null ) { <nl> - downloader . cancel ( ) ; <nl> - } <nl> + assertions . checknotnull ( downloader ) . cancel ( ) ; <nl> assertions . checknotnull ( thread ) . interrupt ( ) ; <nl> } <nl>  <nl>
<nl> ( [ # 5119 ] ( https : / / github . com / google / exoplayer / issues / 5119 ) ) . <nl> * support seeking for a wider range of mpeg - ts streams <nl> ( [ # 5097 ] ( https : / / github . com / google / exoplayer / issues / 5097 ) ) . <nl> - * support for playing spherical videos on daydream . <nl> - * improve decoder re - use between playbacks . <nl> - here ( [ # 2826 ] ( https : / / github . com / google / exoplayer / issues / 2826 ) ) . <nl> - * add options for controlling audio track selections to ` defaulttrackselector ` <nl> - ( [ # 3314 ] ( https : / / github . com / google / exoplayer / issues / 3314 ) ) . <nl> * include channel count in audio capabilities check <nl> ( [ # 4690 ] ( https : / / github . com / google / exoplayer / issues / 4690 ) ) . <nl> - * do not retry failed loads whose error is ` filenotfoundexception ` . <nl> * fix issue with applying the ` show_buffering ` attribute in ` playerview ` <nl> ( [ # 5139 ] ( https : / / github . com / google / exoplayer / issues / 5139 ) ) . <nl> * fix issue where null ` metadata ` was output when it failed to decode <nl> mmm a / constants . gradle <nl> ppp b / constants . gradle <nl>
import java . util . treeset ; <nl> return cues ; <nl> } <nl>  <nl> - private void traverseforimage ( long timeus , string inheritedregion , list < pair < string , string > > regionimagelist ) { <nl> - <nl> + private void traverseforimage ( <nl> + long timeus , <nl> + string inheritedregion , <nl> + list < pair < string , string > > regionimagelist ) { <nl>  <nl> string resolvedregionid = anonymous_region_id . equals ( regionid ) ? inheritedregion : regionid ; <nl> - if ( tag_div . equals ( tag ) & & imageid ! = null ) { <nl> - regionimagelist . add ( new pair < > ( resolvedregionid , imageid ) ) ; <nl> + <nl> + if ( isactive ( timeus ) ) { <nl> + if ( tag_div . equals ( tag ) & & imageid ! = null ) { <nl> + regionimagelist . add ( new pair < > ( resolvedregionid , imageid ) ) ; <nl> + } <nl> } <nl>  <nl> for ( int i = num ; i < getchildcount ( ) ; + + i ) {
public abstract class mediacodecrenderer extends baserenderer { <nl> @ override <nl> protected void ondisabled ( ) { <nl> inputformat = null ; <nl> - if ( drmsession ! = null | | pendingdrmsession ! = null ) { <nl> - <nl> - onreset ( ) ; <nl> - } else { <nl> - flushorreleasecodec ( ) ; <nl> - } <nl> - } <nl> - <nl> - @ override <nl> - protected void onreset ( ) { <nl> try { <nl> releasecodec ( ) ; <nl> } finally { <nl>
public abstract class mediacodecrenderer extends baserenderer { <nl>  <nl> @ override <nl> protected void ondisabled ( ) { <nl> - if ( drmsession ! = null | | pendingdrmsession ! = null ) { <nl> - <nl> - onreset ( ) ; <nl> - } else { <nl> - flushorreleasecodec ( ) ; <nl> - } <nl> - } <nl> - <nl> - @ override <nl> - protected void onreset ( ) { <nl> format = null ; <nl> - availablecodecinfos = null ; <nl> try { <nl> releasecodec ( ) ; <nl> } finally { <nl>
public final class clippingmediasource extends compositemediasource < void > { <nl> / * relativetodefaultposition = * / false ) ; <nl> } <nl>  <nl> - / * * <nl> - * creates a new clipping source that wraps the specified source and provides samples between the <nl> - * specified start and end position . <nl> - * <nl> - * @ param mediasource the single - period source to wrap . <nl> - * @ param startpositionus the start position within { @ code mediasource } ' s window at which to start <nl> - * providing samples , in microseconds . <nl> - * @ param endpositionus the end position within { @ code mediasource } ' s window at which to stop <nl> - * providing samples , in microseconds . specify { @ link c # time_end_of_source } to provide samples <nl> - * from the specified start point up to the end of the source . specifying a position that <nl> - * exceeds the { @ code mediasource } ' s duration will also result in the end of the source not <nl> - * being clipped . <nl> - * @ param enableinitialdiscontinuity whether the initial discontinuity should be enabled . <nl> - * / <nl> - <nl> - @ deprecated <nl> - public clippingmediasource ( <nl> - mediasource mediasource , <nl> - long startpositionus , <nl> - long endpositionus , <nl> - boolean enableinitialdiscontinuity ) { <nl> - this ( <nl> - mediasource , <nl> - startpositionus , <nl> - endpositionus , <nl> - enableinitialdiscontinuity , <nl> - / * allowdynamicclippingupdates = * / false , <nl> - / * relativetodefaultposition = * / false ) ; <nl> - } <nl> - <nl> / * * <nl> * creates a new clipping source that wraps the specified source and provides samples from the <nl> * default position for the specified duration .
public final class imaadsloader <nl> } <nl> } <nl>  <nl> - <nl> + @ override <nl> public int getvolume ( ) { <nl> if ( player = = null ) { <nl> return lastvolumepercentage ; <nl>
public interface datasource { <nl> * <nl> * @ param transferlistener a { @ link transferlistener } . <nl> * / <nl> - default void addtransferlistener ( transferlistener transferlistener ) { <nl> - <nl> - } <nl> + void addtransferlistener ( transferlistener transferlistener ) ; <nl>  <nl> / * * <nl> * opens the source to read the specified data . <nl> mmm a / library / core / src / main / java / com / google / android / exoplayer2 / upstream / dummydatasource . java <nl> ppp b / library / core / src / main / java / com / google / android / exoplayer2 / upstream / dummydatasource . java <nl>
public class analyticscollector <nl> / / this event is for content in a future window . assume default start position . <nl> eventpositionms = timeline . getwindow ( windowindex , window ) . getdefaultpositionms ( ) ; <nl> } <nl> - <nl> - long buffereddurationms = player . getbufferedposition ( ) - player . getcontentposition ( ) ; <nl> return new eventtime ( <nl> realtimems , <nl> timeline , <nl>
public final class imaadsloader extends player . defaulteventlistener implements a <nl> this . adgroupindex = = c . index_unset ? expectedadgroupindex : this . adgroupindex ; <nl> adplaybackstate . adgroup adgroup = adplaybackstate . adgroups [ adgroupindex ] ; <nl> / / ad group load error can be notified more than once , so check if it was already handled . <nl> - <nl> - / / getcontentprogress so that it ' s possible to detect when more than one ad group fails to load <nl> - / / consecutively . <nl> if ( adgroup . count = = c . length_unset <nl> | | adgroup . states [ 0 ] = = adplaybackstate . ad_state_unavailable ) { <nl> if ( debug ) {
public final class imaadsloader extends player . defaulteventlistener implements a <nl> this . adgroupindex = = c . index_unset ? expectedadgroupindex : this . adgroupindex ; <nl> adplaybackstate . adgroup adgroup = adplaybackstate . adgroups [ adgroupindex ] ; <nl> / / ad group load error can be notified more than once , so check if it was already handled . <nl> - <nl> - / / getcontentprogress so that it ' s possible to detect when more than one ad group fails to load <nl> - / / consecutively . <nl> if ( adgroup . count = = c . length_unset <nl> | | adgroup . states [ 0 ] = = adplaybackstate . ad_state_unavailable ) { <nl> if ( debug ) {
public final class requirements { <nl> if ( networkinfo = = null | | ! networkinfo . isconnected ( ) ) { <nl> logd ( " no network info or no connection . " ) ; <nl> return false ; <nl> - } else if ( util . sdk_int > = num ) { <nl> - <nl> - / / levels prior to num . <nl> - network activenetwork = connectivitymanager . getactivenetwork ( ) ; <nl> - if ( activenetwork = = null ) { <nl> - logd ( " no active network . " ) ; <nl> - return false ; <nl> - } <nl> - networkcapabilities networkcapabilities = <nl> - connectivitymanager . getnetworkcapabilities ( activenetwork ) ; <nl> - if ( networkcapabilities = = null <nl> - | | ! networkcapabilities . hascapability ( networkcapabilities . net_capability_validated ) ) { <nl> - logd ( " net capability isn ' t validated . " ) ; <nl> - return false ; <nl> - } <nl> - } <nl> - boolean activenetworkmetered = connectivitymanager . isactivenetworkmetered ( ) ; <nl> - switch ( networkrequirement ) { <nl> - case network_type_any : <nl> - return true ; <nl> - case network_type_unmetered : <nl> - if ( activenetworkmetered ) { <nl> - logd ( " network is metered . " ) ; <nl> - } <nl> - return ! activenetworkmetered ; <nl> - case network_type_not_roaming : <nl> - boolean roaming = networkinfo . isroaming ( ) ; <nl> - if ( roaming ) { <nl> - logd ( " roaming . " ) ; <nl> - } <nl> - return ! roaming ; <nl> - case network_type_metered : <nl> - if ( ! activenetworkmetered ) { <nl> - logd ( " network isn ' t metered . " ) ; <nl> - } <nl> - return activenetworkmetered ; <nl> - default : <nl> - throw new illegalstateexception ( ) ; <nl> } <nl> + if ( ! checkinternetconnectivity ( connectivitymanager ) ) { <nl> + return false ; <nl> + } <nl> + if ( networkrequirement = = network_type_any ) { <nl> + return true ; <nl> + } <nl> + if ( networkrequirement = = network_type_not_roaming ) { <nl> + boolean roaming = networkinfo . isroaming ( ) ; <nl> + logd ( " roaming : " + roaming ) ; <nl> + return ! roaming ; <nl> + } <nl> + boolean activenetworkmetered = isactivenetworkmetered ( connectivitymanager , networkinfo ) ; <nl> + logd ( " metered network : " + activenetworkmetered ) ; <nl> + if ( networkrequirement = = network_type_unmetered ) { <nl> + return ! activenetworkmetered ; <nl> + } <nl> + if ( networkrequirement = = network_type_metered ) { <nl> + return activenetworkmetered ; <nl> + } <nl> + throw new illegalstateexception ( ) ; <nl> } <nl>  <nl> private boolean checkchargingrequirement ( context context ) { <nl>
public class dashdownloadertest extends instrumentationtestcase { <nl> } catch ( ioexception e ) { <nl> / / ignore <nl> } <nl> - <nl> + dataspec dataspec = new dataspec ( test_mpd_uri , num , testmpdfirstpart . length , null ) ; <nl> + assertdatacached ( cache , dataspec , testmpdfirstpart ) ; <nl>  <nl> / / on the second try it downloads the rest of the data <nl> dashmanifest manifest = dashdownloader . getmanifest ( ) ; <nl> mmm a / testutils / src / main / java / com / google / android / exoplayer2 / testutil / cacheasserts . java <nl> ppp b / testutils / src / main / java / com / google / android / exoplayer2 / testutil / cacheasserts . java <nl>
public final class dashmediasource implements mediasource { <nl>  <nl> private static final class iso8601parser implements parsingloadable . parser < long > { <nl>  <nl> + private static final string iso_8601_format = " yyyy - mm - dd ' t ' hh : mm : ss ' z ' " ; <nl> + private static final string iso_8601_format_2 = " yyyy - mm - dd ' t ' hh : mm : ssz " ; <nl> + private static final string iso_8601_format_3 = " yyyy - mm - dd ' t ' hh : mm : ssz " ; <nl> + private static final string iso_8601_format_2_regex_pattern = " . * [ + \ \ - ] \ \ d { 2 } : \ \ d { 2 } $ " ; <nl> + private static final string iso_8601_format_3_regex_pattern = " . * [ + \ \ - ] \ \ d { 4 } $ " ; <nl> + <nl> @ override <nl> public long parse ( uri uri , inputstream inputstream ) throws ioexception { <nl> string firstline = new bufferedreader ( new inputstreamreader ( inputstream ) ) . readline ( ) ; <nl> - try { <nl> - <nl> - simpledateformat format = new simpledateformat ( " yyyy - mm - dd ' t ' hh : mm : ss ' z ' " , locale . us ) ; <nl> - format . settimezone ( timezone . gettimezone ( " utc " ) ) ; <nl> - return format . parse ( firstline ) . gettime ( ) ; <nl> - } catch ( parseexception e ) { <nl> - throw new parserexception ( e ) ; <nl> + <nl> + if ( firstline ! = null ) { <nl> + / / determine format pattern <nl> + string formatpattern ; <nl> + if ( firstline . matches ( iso_8601_format_2_regex_pattern ) ) { <nl> + formatpattern = iso_8601_format_2 ; <nl> + } else if ( firstline . matches ( iso_8601_format_3_regex_pattern ) ) { <nl> + formatpattern = iso_8601_format_3 ; <nl> + } else { <nl> + formatpattern = iso_8601_format ; <nl> + } <nl> + / / parse <nl> + try { <nl> + simpledateformat format = new simpledateformat ( formatpattern , locale . us ) ; <nl> + format . settimezone ( timezone . gettimezone ( " utc " ) ) ; <nl> + return format . parse ( firstline ) . gettime ( ) ; <nl> + } catch ( parseexception e ) { <nl> + throw new parserexception ( e ) ; <nl> + } <nl> + <nl> + } else { <nl> + throw new parserexception ( " unable to parse iso num . input value is null " ) ; <nl> } <nl> } <nl> - <nl> } <nl>  <nl> }
public final class dashmediasource implements mediasource { <nl>  <nl> private static final class iso8601parser implements parsingloadable . parser < long > { <nl>  <nl> + private static final string iso_8601_format = " yyyy - mm - dd ' t ' hh : mm : ss ' z ' " ; <nl> + private static final string iso_8601_format_2 = " yyyy - mm - dd ' t ' hh : mm : ssz " ; <nl> + private static final string iso_8601_format_3 = " yyyy - mm - dd ' t ' hh : mm : ssz " ; <nl> + private static final string iso_8601_format_2_regex_pattern = " . * [ + \ \ - ] \ \ d { 2 } : \ \ d { 2 } $ " ; <nl> + private static final string iso_8601_format_3_regex_pattern = " . * [ + \ \ - ] \ \ d { 4 } $ " ; <nl> + <nl> @ override <nl> public long parse ( uri uri , inputstream inputstream ) throws ioexception { <nl> string firstline = new bufferedreader ( new inputstreamreader ( inputstream ) ) . readline ( ) ; <nl> - try { <nl> - <nl> - simpledateformat format = new simpledateformat ( " yyyy - mm - dd ' t ' hh : mm : ss ' z ' " , locale . us ) ; <nl> - format . settimezone ( timezone . gettimezone ( " utc " ) ) ; <nl> - return format . parse ( firstline ) . gettime ( ) ; <nl> - } catch ( parseexception e ) { <nl> - throw new parserexception ( e ) ; <nl> + <nl> + if ( firstline ! = null ) { <nl> + / / determine format pattern <nl> + string formatpattern ; <nl> + if ( firstline . matches ( iso_8601_format_2_regex_pattern ) ) { <nl> + formatpattern = iso_8601_format_2 ; <nl> + } else if ( firstline . matches ( iso_8601_format_3_regex_pattern ) ) { <nl> + formatpattern = iso_8601_format_3 ; <nl> + } else { <nl> + formatpattern = iso_8601_format ; <nl> + } <nl> + / / parse <nl> + try { <nl> + simpledateformat format = new simpledateformat ( formatpattern , locale . us ) ; <nl> + format . settimezone ( timezone . gettimezone ( " utc " ) ) ; <nl> + return format . parse ( firstline ) . gettime ( ) ; <nl> + } catch ( parseexception e ) { <nl> + throw new parserexception ( e ) ; <nl> + } <nl> + <nl> + } else { <nl> + throw new parserexception ( " unable to parse iso num . input value is null " ) ; <nl> } <nl> } <nl> - <nl> } <nl>  <nl> }
import java . util . concurrent . copyonwritearrayset ; <nl> pendingseekacks + + ; <nl> maskingwindowindex = windowindex ; <nl> if ( timeline . isempty ( ) ) { <nl> + maskingwindowpositionms = positionms = = c . time_unset ? num : positionms ; <nl> maskingperiodindex = num ; <nl> } else { <nl> timeline . getwindow ( windowindex , window ) ; <nl> - long resolvedpositionus = <nl> - positionms = = c . time_unset ? window . getdefaultpositionus ( ) : c . mstous ( positionms ) ; <nl> + long windowpositionus = positionms = = c . time_unset ? window . getdefaultpositionus ( ) <nl> + : c . mstous ( positionms ) ; <nl> int periodindex = window . firstperiodindex ; <nl> - long periodpositionus = window . getpositioninfirstperiodus ( ) + resolvedpositionus ; <nl> + long periodpositionus = window . getpositioninfirstperiodus ( ) + windowpositionus ; <nl> long perioddurationus = timeline . getperiod ( periodindex , period ) . getdurationus ( ) ; <nl> while ( perioddurationus ! = c . time_unset & & periodpositionus > = perioddurationus <nl> & & periodindex < window . lastperiodindex ) { <nl> periodpositionus - = perioddurationus ; <nl> perioddurationus = timeline . getperiod ( + + periodindex , period ) . getdurationus ( ) ; <nl> } <nl> + maskingwindowpositionms = c . ustoms ( windowpositionus ) ; <nl> maskingperiodindex = periodindex ; <nl> } <nl> - if ( positionms = = c . time_unset ) { <nl> - <nl> - maskingwindowpositionms = num ; <nl> - internalplayer . seekto ( timeline , windowindex , c . time_unset ) ; <nl> - } else { <nl> - maskingwindowpositionms = positionms ; <nl> - internalplayer . seekto ( timeline , windowindex , c . mstous ( positionms ) ) ; <nl> - for ( player . eventlistener listener : listeners ) { <nl> - listener . onpositiondiscontinuity ( discontinuity_reason_seek ) ; <nl> - } <nl> + internalplayer . seekto ( timeline , windowindex , c . mstous ( positionms ) ) ; <nl> + for ( player . eventlistener listener : listeners ) { <nl> + listener . onpositiondiscontinuity ( discontinuity_reason_seek ) ; <nl> } <nl> }
public final class clippingmediaperiod implements mediaperiod , mediaperiod . callb <nl> return c . result_buffer_read ; <nl> } <nl> int result = stream . readdata ( formatholder , buffer , requireformat ) ; <nl> - <nl> + if ( result = = c . result_format_read ) { <nl> + / / clear gapless playback metadata if the start / end points don ' t match the media . <nl> + format format = formatholder . format ; <nl> + int encoderdelay = startus ! = num ? num : format . encoderdelay ; <nl> + int encoderpadding = endus ! = c . time_end_of_source ? num : format . encoderpadding ; <nl> + formatholder . format = format . copywithgaplessinfo ( encoderdelay , encoderpadding ) ; <nl> + return c . result_format_read ; <nl> + } <nl> if ( endus ! = c . time_end_of_source & & ( ( result = = c . result_buffer_read <nl> & & buffer . timeus > = endus ) | | ( result = = c . result_nothing_read <nl> & & mediaperiod . getbufferedpositionus ( ) = = c . time_end_of_source ) ) ) { <nl> mmm a / library / core / src / main / java / com / google / android / exoplayer2 / source / clippingmediasource . java <nl> ppp b / library / core / src / main / java / com / google / android / exoplayer2 / source / clippingmediasource . java <nl>
public final class mediasessionconnector { <nl>  <nl> @ override <nl> public void onshufflemodeenabledchanged ( boolean shufflemodeenabled ) { <nl> - <nl> + mediasession . setshufflemode ( shufflemodeenabled ? playbackstatecompat . shuffle_mode_all <nl> + : playbackstatecompat . shuffle_mode_none ) ; <nl> + updatemediasessionplaybackstate ( ) ; <nl> } <nl>  <nl> @ override <nl>
public abstract class timelinequeuenavigator implements mediasessionconnector . qu <nl>  <nl> @ override <nl> public void onsetshufflemodeenabled ( player player , boolean enabled ) { <nl> - <nl> + player . setshufflemodeenabled ( enabled ) ; <nl> } <nl>  <nl> private void publishfloatingqueuewindow ( player player ) {
android { <nl> buildtoolsversion project . ext . buildtoolsversion <nl>  <nl> defaultconfig { <nl> - <nl> - / / https : / / github . com / ant - media / librtmp - client - for - android / issues / 39 <nl> - minsdkversion num <nl> + minsdkversion num <nl> targetsdkversion project . ext . targetsdkversion <nl> } <nl> } <nl>  <nl> dependencies { <nl> compile project ( moduleprefix + ' library - core ' ) <nl> - compile ' net . butterflytv . utils : rtmp - client : 0 . 2 . 7 . 1 ' <nl> + compile ' net . butterflytv . utils : rtmp - client : 0 . 2 . 8 ' <nl> } <nl> + <nl> + ext { <nl> + javadoctitle = ' rtmp extension ' <nl> + } <nl> + apply from : ' . . / . . / javadoc_library . gradle ' <nl> + <nl> + ext { <nl> + releaseartifact = ' extension - rtmp ' <nl> + releasedescription = ' rtmp extension for exoplayer . ' <nl> + } <nl> + apply from : ' . . / . . / publish . gradle '
import java . util . arrays ; <nl> / / treat all seeks into non - seekable media as being to t = 0 . <nl> positionus = seekmap . isseekable ( ) ? positionus : num ; <nl> lastseekpositionus = positionus ; <nl> + notifydiscontinuity = false ; <nl> / / if we ' re not pending a reset , see if we can seek within the sample queues . <nl> - boolean seekinsidebuffer = ! ispendingreset ( ) ; <nl> - int trackcount = samplequeues . length ; <nl> - for ( int i = num ; seekinsidebuffer & & i < trackcount ; i + + ) { <nl> - samplequeue samplequeue = samplequeues [ i ] ; <nl> - samplequeue . rewind ( ) ; <nl> - <nl> - / / seek should be allowed . if there are non - sparse tracks ( e . g . video , audio ) for which <nl> - / / in - buffer seeking is successful , we should perform an in - buffer seek unconditionally . <nl> - seekinsidebuffer = samplequeue . advanceto ( positionus , true , false ) ; <nl> - samplequeue . discardtoread ( ) ; <nl> - } <nl> + boolean seekinsidebuffer = ! ispendingreset ( ) & & seekinsidebufferus ( positionus ) ; <nl> / / if we failed to seek within the sample queues , we need to restart . <nl> if ( ! seekinsidebuffer ) { <nl> pendingresetpositionus = positionus ; <nl>
import java . nio . shortbuffer ; <nl> / * * <nl> * an { @ link audioprocessor } that uses the sonic library to modify the speed / pitch of audio . <nl> * / <nl> - <nl> - / * package * / final class sonicaudioprocessor implements audioprocessor { <nl> + public final class sonicaudioprocessor implements audioprocessor { <nl>  <nl> / * * <nl> * the maximum allowed playback speed in { @ link # setspeed ( float ) } .
public final class hlsmediasource implements mediasource , <nl> public void onprimaryplaylistrefreshed ( hlsmediaplaylist playlist ) { <nl> singleperiodtimeline timeline ; <nl> if ( playlisttracker . islive ( ) ) { <nl> - <nl> + long perioddurationus = playlist . hasendtag ? ( playlist . starttimeus + playlist . durationus ) <nl> + : c . time_unset ; <nl> list < hlsmediaplaylist . segment > segments = playlist . segments ; <nl> long windowdefaultstartpositionus = segments . isempty ( ) ? num <nl> : segments . get ( math . max ( 0 , segments . size ( ) - num ) ) . relativestarttimeus ; <nl> - timeline = new singleperiodtimeline ( c . time_unset , playlist . durationus , <nl> + timeline = new singleperiodtimeline ( perioddurationus , playlist . durationus , <nl> playlist . starttimeus , windowdefaultstartpositionus , true , ! playlist . hasendtag ) ; <nl> } else / * not live * / { <nl> timeline = new singleperiodtimeline ( playlist . starttimeus + playlist . durationus ,
cd " $ { ffmpeg_ext_path } " / jni & & \ <nl> $ { ndk_path } / ndk - build app_abi = armeabi - v7a - j4 <nl> ` ` ` <nl>  <nl> - <nl> + repeat these steps for any other architectures you need to support . <nl>  <nl> * in your project , you can add a dependency on the extension by using a rule <nl> like this :
public final class id3decoder implements metadatadecoder { <nl> return new metadata ( id3frames ) ; <nl> } <nl>  <nl> - <nl> - private static int indexofeos ( byte [ ] data , int fromindex , int encoding ) { <nl> - int terminationpos = indexofzerobyte ( data , fromindex ) ; <nl> - <nl> - / / for single byte encoding charsets , we ' re done . <nl> - if ( encoding = = id3_text_encoding_iso_8859_1 | | encoding = = id3_text_encoding_utf_8 ) { <nl> - return terminationpos ; <nl> - } <nl> - <nl> - / / otherwise ensure an even <nl> - while ( terminationpos < data . length - num ) { <nl> - if ( terminationpos % num = = num & & data [ terminationpos + num ] = = ( byte ) num ) { <nl> - return terminationpos ; <nl> - } <nl> - terminationpos = indexofzerobyte ( data , terminationpos + num ) ; <nl> - } <nl> - <nl> - return data . length ; <nl> - } <nl> - <nl> - private static int indexofzerobyte ( byte [ ] data , int fromindex ) { <nl> - for ( int i = fromindex ; i < data . length ; i + + ) { <nl> - if ( data [ i ] = = ( byte ) num ) { <nl> - return i ; <nl> - } <nl> - } <nl> - return data . length ; <nl> - } <nl> - <nl> - private static int delimiterlength ( int encodingbyte ) { <nl> - return ( encodingbyte = = id3_text_encoding_iso_8859_1 | | encodingbyte = = id3_text_encoding_utf_8 ) <nl> - ? num : num ; <nl> - } <nl> - <nl> / * * <nl> * @ param data a { @ link parsablebytearray } from which the header should be read . <nl> * @ return the parsed header , or null if the id3 tag is unsupported . <nl>
import com . google . android . exoplayer2 . util . parsablebytearray ; <nl> private long sampledurationus ; <nl> private format format ; <nl> private int samplesize ; <nl> + private boolean iseac3 ; <nl>  <nl> / / used when reading the samples . <nl> private long timeus ; <nl>  <nl> - <nl> / * * <nl> * constructs a new reader for ( e - ) ac - 3 elementary streams . <nl> * <nl> * @ param output track output for extracted samples . <nl> - * @ param iseac3 whether the stream is e - ac - 3 ( etsi ts num num annex e ) . specify { @ code false } to <nl> - * decode sample headers as ac - 3 . <nl> * / <nl> - public ac3reader ( trackoutput output , boolean iseac3 ) { <nl> + public ac3reader ( trackoutput output ) { <nl> super ( output ) ; <nl> - this . iseac3 = iseac3 ; <nl> headerscratchbits = new parsablebitarray ( new byte [ header_size ] ) ; <nl> headerscratchbytes = new parsablebytearray ( headerscratchbits . data ) ; <nl> state = state_finding_sync ; <nl>
public class hlschunksource { <nl> return ; <nl> } <nl>  <nl> + disableformatevaluator ( ) ; <nl> if ( trackselection . length > num ) { <nl> - <nl> format [ ] formats = trackselection . getformats ( ) ; <nl> - adaptiveformatevaluator . enable ( formats ) ; <nl> + formatevaluator . enable ( formats ) ; <nl> + formatevaluatorenabled = true ; <nl> if ( ! util . contains ( formats , evaluation . format ) ) { <nl> evaluation . format = null ; <nl> } <nl>
public interface mediasource { <nl> * / <nl> void preparesource ( ) ; <nl>  <nl> - <nl> - <nl> / * * <nl> * returns the number of periods in the source , or { @ link # unknown_period_count } if the number <nl> * of periods is not yet known . <nl>
import java . util . arraylist ; <nl> import java . util . identityhashmap ; <nl> import java . util . list ; <nl>  <nl> - <nl> / * * <nl> * merges multiple { @ link mediaperiod } instances . <nl> * / <nl> - public final class multimediaperiod implements mediaperiod , mediaperiod . callback { <nl> + public final class mergingmediaperiod implements mediaperiod , mediaperiod . callback { <nl>  <nl> private final mediaperiod [ ] periods ; <nl> private final identityhashmap < trackstream , mediaperiod > trackstreamperiods ; <nl>
import java . util . arraylist ; <nl> renderermediaclocksource = null ; <nl> } <nl> ensurestopped ( renderer ) ; <nl> - <nl> - / / returning a trackstream from trackrenderer . disable . <nl> - oldstreams . add ( renderer . disable ( ) ) ; <nl> + renderer . disable ( ) ; <nl> + oldstreams . add ( playingsource . trackstreams [ i ] ) ; <nl> } <nl> if ( newselection ! = null ) { <nl> newselections . add ( newselection ) ; <nl> mmm a / library / src / main / java / com / google / android / exoplayer / trackrenderer . java <nl> ppp b / library / src / main / java / com / google / android / exoplayer / trackrenderer . java <nl>
public final class exoplayerlibraryinfo { <nl> / * * <nl> * the version of the library , expressed as a string . <nl> * / <nl> - public static final string version = " 1 . 5 . 4 " ; <nl> + public static final string version = " 2 . 0 . 0 " ; <nl>  <nl> / * * <nl> * the version of the library , expressed as an integer . <nl> * < p > <nl> * three digits are used for each component of { @ link # version } . for example " 1 . 2 . 3 " has the <nl> - * corresponding integer version num . <nl> + * corresponding integer version num ( 001 - 002 - 003 ) , and " 123 . 45 . 6 " has the corresponding <nl> + * integer version num ( 123 - 045 - 006 ) . <nl> * / <nl> - <nl> - public static final int version_int = num ; <nl> + public static final int version_int = num ; <nl>  <nl> / * * <nl> * whether the library was compiled with { @ link com . google . android . exoplayer . util . assertions }
public final class texttrackrenderer extends samplesourcetrackrenderer implement <nl> / / try and read the next subtitle from the source . <nl> int result = readsource ( formatholder , nextinputbuffer ) ; <nl> if ( result = = trackstream . buffer_read ) { <nl> + / / clear buffer_flag_decode_only ( see [ internal : b / 27893809 ] ) and queue the buffer . <nl> + nextinputbuffer . clearflag ( c . buffer_flag_decode_only ) ; <nl> if ( nextinputbuffer . isendofstream ( ) ) { <nl> inputstreamended = true ; <nl> - <nl> } else { <nl> nextinputbuffer . subsampleoffsetus = formatholder . format . subsampleoffsetus ; <nl> - parser . queueinputbuffer ( nextinputbuffer ) ; <nl> } <nl> + parser . queueinputbuffer ( nextinputbuffer ) ; <nl> + nextinputbuffer = null ; <nl> } <nl> } <nl> } catch ( parserexception e ) { <nl>
public abstract class mediacodectrackrenderer extends samplesourcetrackrenderer <nl> } <nl> return false ; <nl> } <nl> - if ( waitingforfirstsyncframe ) { <nl> - <nl> - / / frame for he - aac . <nl> - if ( ! sampleholder . issyncframe ( ) ) { <nl> - sampleholder . cleardata ( ) ; <nl> - if ( codecreconfigurationstate = = reconfiguration_state_queue_pending ) { <nl> - / / the buffer we just cleared contained reconfiguration data . we need to re - write this <nl> - / / data into a subsequent buffer ( if there is one ) . <nl> - codecreconfigurationstate = reconfiguration_state_write_pending ; <nl> - } <nl> - return true ; <nl> - } <nl> - waitingforfirstsyncframe = false ; <nl> - } <nl> boolean sampleencrypted = sampleholder . isencrypted ( ) ; <nl> waitingforkeys = shouldwaitforkeys ( sampleencrypted ) ; <nl> if ( waitingforkeys ) {
public final class tsextractor implements extractor { <nl> streamtype = ts_stream_type_h265 ; <nl> } <nl> break ; <nl> - } else if ( descriptortag = = num x6a ) { <nl> + } else if ( descriptortag = = num x6a ) { / / ac - 3_descriptor in dvb ( etsi en num num ) <nl> streamtype = ts_stream_type_ac3 ; <nl> - } else if ( descriptortag = = num x7a ) { <nl> + } else if ( descriptortag = = num x7a ) { / / enhanced_ac - 3_descriptor <nl> streamtype = ts_stream_type_e_ac3 ; <nl> - } else if ( descriptortag = = num x7b ) { <nl> - <nl> + } else if ( descriptortag = = num x7b ) { / / dts_descriptor <nl> + streamtype = ts_stream_type_dts ; <nl> } <nl>  <nl> data . skipbytes ( descriptorlength ) ; <nl> mmm a / library / src / main / java / com / google / android / exoplayer / util / ac3util . java <nl> ppp b / library / src / main / java / com / google / android / exoplayer / util / ac3util . java <nl>
public class hlschunksource implements hlstrackselector . output { <nl> if ( playlist . type = = hlsplaylist . type_master ) { <nl> masterplaylist = ( hlsmasterplaylist ) playlist ; <nl> } else { <nl> - <nl> format format = new format ( " 0 " , mimetypes . application_m3u8 , - 1 , - 1 , - 1 , - 1 , - 1 , - 1 , null , <nl> null ) ; <nl> list < variant > variants = new arraylist < > ( ) ; <nl> mmm a / library / src / main / java / com / google / android / exoplayer / hls / hlsplaylistparser . java <nl> ppp b / library / src / main / java / com / google / android / exoplayer / hls / hlsplaylistparser . java <nl>
public class hlschunksource { <nl> chunkmediasequence = switchingvariantspliced <nl> ? previoustschunk . chunkindex : previoustschunk . chunkindex + num ; <nl> if ( chunkmediasequence < mediaplaylist . mediasequence ) { <nl> - <nl> - / / if ( allowskipahead ) { <nl> - / / if the chunk is no longer in the playlist . skip ahead and start again . <nl> - chunkmediasequence = getlivestartchunkmediasequence ( nextvariantindex ) ; <nl> - livediscontinuity = true ; <nl> - / / } else { <nl> - / / fatalerror = new behindlivewindowexception ( ) ; <nl> - / / return null ; <nl> - / / } <nl> + fatalerror = new behindlivewindowexception ( ) ; <nl> + return ; <nl> } <nl> } <nl> } else { <nl> / / not live . <nl> if ( previoustschunk = = null ) { <nl> - chunkmediasequence = util . binarysearchfloor ( mediaplaylist . segments , seekpositionus , true , <nl> - true ) + mediaplaylist . mediasequence ; <nl> + chunkmediasequence = util . binarysearchfloor ( mediaplaylist . segments , playbackpositionus , <nl> + true , true ) + mediaplaylist . mediasequence ; <nl> } else { <nl> chunkmediasequence = switchingvariantspliced <nl> ? previoustschunk . chunkindex : previoustschunk . chunkindex + num ; <nl> mmm a / library / src / main / java / com / google / android / exoplayer / hls / hlssamplesource . java <nl> ppp b / library / src / main / java / com / google / android / exoplayer / hls / hlssamplesource . java <nl>
public final class tsextractor implements extractor { <nl> id3reader = new id3reader ( output . track ( ts_stream_type_id3 ) ) ; <nl> } <nl>  <nl> - int entriessize = sectionlength - num / * size of the rest of the fields before descriptors * / <nl> - - programinfolength - num / * crc size * / ; <nl> - while ( entriessize > num ) { <nl> + int remainingentrieslength = sectionlength - num / * length of fields before descriptors * / <nl> + - programinfolength - num / * crc length * / ; <nl> + while ( remainingentrieslength > num ) { <nl> data . readbytes ( pmtscratch , num ) ; <nl> int streamtype = pmtscratch . readbits ( 8 ) ; <nl> pmtscratch . skipbits ( 3 ) ; / / reserved <nl> int elementarypid = pmtscratch . readbits ( 13 ) ; <nl> pmtscratch . skipbits ( 4 ) ; / / reserved <nl> - int esinfolength = pmtscratch . readbits ( 12 ) ; <nl> - <nl> - int descriptorposition = data . getposition ( ) ; <nl> + int esinfolength = pmtscratch . readbits ( 12 ) ; / / es_info_length <nl> if ( streamtype = = num x06 ) { <nl> - int descriptortag = data . readunsignedbyte ( ) ; <nl> - if ( descriptortag = = num x05 ) { / / registration_descriptor <nl> - data . skipbytes ( 1 ) ; / / descriptor_length <nl> - long formatidentifier = data . readunsignedint ( ) ; <nl> - if ( formatidentifier = = ac3_format_identifier ) { <nl> - streamtype = ts_stream_type_atsc_ac3 ; <nl> - } else if ( formatidentifier = = hevc_format_identifier ) { <nl> - streamtype = ts_stream_type_h265 ; <nl> - } <nl> - / / ignore additional_identification_info . <nl> - } <nl> + / / read descriptors in pes packets containing private data . <nl> + streamtype = readprivatedatastreamtype ( data , esinfolength ) ; <nl> + } else { <nl> + data . skipbytes ( esinfolength ) ; <nl> } <nl> - data . setposition ( descriptorposition + esinfolength ) ; <nl> - entriessize - = esinfolength + num ; <nl> - <nl> + remainingentrieslength - = esinfolength + num ; <nl> if ( streamtypes . get ( streamtype ) ) { <nl> continue ; <nl> } <nl>  <nl> - <nl> elementarystreamreader pespayloadreader = null ; <nl> switch ( streamtype ) { <nl> case ts_stream_type_mpa : <nl>
public abstract class trackrenderer implements exoplayercomponent { <nl> * <nl> * @ return the number of tracks . <nl> * / <nl> - <nl> - protected int gettrackcount ( ) { <nl> - return num ; <nl> - } <nl> + protected abstract int gettrackcount ( ) ; <nl>  <nl> / * * <nl> * returns the format of the specified track . <nl>
public abstract class trackrenderer implements exoplayercomponent { <nl> * @ param track the track index . <nl> * @ return the format of the specified track . <nl> * / <nl> - <nl> - protected mediaformat getformat ( int track ) { <nl> - return mediaformat . createformatformimetype ( " application / octet - stream " , mediaformat . no_value , <nl> - getdurationus ( ) ) ; <nl> - } <nl> + protected abstract mediaformat getformat ( int track ) ; <nl>  <nl> / * * <nl> * enable the renderer for a specified track .
public class mediacodecvideotrackrenderer extends mediacodectrackrenderer { <nl> @ override <nl> protected void oninputformatchanged ( mediaformatholder holder ) throws exoplaybackexception { <nl> super . oninputformatchanged ( holder ) ; <nl> - <nl> - / / to be a way to pass a custom key / value pair value through to the output format . <nl> - currentpixelwidthheightratio = holder . format . pixelwidthheightratio = = mediaformat . no_value ? num <nl> + pendingpixelwidthheightratio = holder . format . pixelwidthheightratio = = mediaformat . no_value ? num <nl> : holder . format . pixelwidthheightratio ; <nl> } <nl>  <nl>
public final class parsablebytearray { <nl> return limit - position ; <nl> } <nl>  <nl> - / * * returns the number of bytes in the array . * / <nl> - <nl> - public int length ( ) { <nl> + / * * returns the limit . * / <nl> + public int limit ( ) { <nl> return limit ; <nl> } <nl>  <nl>
public class dashchunksource implements chunksource { <nl> - representationholder . segmentnumshift ; <nl> } <nl>  <nl> - <nl> - / / behind or in front of the live window . <nl> if ( currentmanifest . dynamic ) { <nl> - if ( segmentnum < segmentindex . getfirstsegmentnum ( ) ) { <nl> + if ( segmentnum < firstavailablesegmentnum ) { <nl> / / this is before the first chunk in the current manifest . <nl> fatalerror = new behindlivewindowexception ( ) ; <nl> return ; <nl> - } else if ( ! indexunbounded & & segmentnum > lastsegmentnum ) { <nl> - / / this is beyond the last chunk in the current manifest . <nl> - finishedcurrentmanifest = true ; <nl> + } else if ( segmentnum > lastavailablesegmentnum ) { <nl> + / / this chunk is beyond the last chunk in the current manifest . if the <nl> + / / we ' ll need to refresh it . if it ' s unbounded we just need to wait for a while before <nl> + / / attempting to load the chunk . <nl> + finishedcurrentmanifest = ! indexunbounded ; <nl> return ; <nl> - } else if ( ! indexunbounded & & segmentnum = = lastsegmentnum ) { <nl> - / / this is the last chunk in the current manifest . mark the manifest as being finished , <nl> - / / but continue to return the final chunk . <nl> + } else if ( ! indexunbounded & & segmentnum = = lastavailablesegmentnum ) { <nl> + / / this is the last chunk in a dynamic bounded manifest . we ' ll need to refresh the manifest <nl> + / / to obtain the next chunk . <nl> finishedcurrentmanifest = true ; <nl> } <nl> } <nl>
public class dashchunksource implements chunksource { <nl> * for live playbacks , determines the seek position that snaps playback to be <nl> * { @ link # liveedgelatencyus } behind the live edge of the current manifest <nl> * <nl> + * @ param nowus an estimate of the current server time , in microseconds . <nl> * @ param indexunbounded true if the segment <nl> * @ return the seek position in microseconds . <nl> * / <nl> - private long getliveseekposition ( boolean indexunbounded ) { <nl> + private long getliveseekposition ( long nowus , boolean indexunbounded ) { <nl> long liveedgetimestampus ; <nl> if ( indexunbounded ) { <nl> - <nl> - long nowms = system . currenttimemillis ( ) ; <nl> - liveedgetimestampus = ( nowms - currentmanifest . availabilitystarttime ) * num ; <nl> + liveedgetimestampus = nowus - currentmanifest . availabilitystarttime * num ; <nl> } else { <nl> liveedgetimestampus = long . min_value ; <nl> for ( representationholder representationholder : representationholders . values ( ) ) {
public final class captionstylecompat { <nl> this . typeface = typeface ; <nl> } <nl>  <nl> - @ suppresswarnings ( " unused " ) <nl> + @ targetapi ( 19 ) <nl> + private static captionstylecompat createfromcaptionstylev19 ( <nl> + captioningmanager . captionstyle captionstyle ) { <nl> + return new captionstylecompat ( <nl> + captionstyle . foregroundcolor , captionstyle . backgroundcolor , color . transparent , <nl> + captionstyle . edgetype , captionstyle . edgecolor , captionstyle . gettypeface ( ) ) ; <nl> + } <nl> + <nl> @ targetapi ( 21 ) <nl> - private static int getwindowcolorv21 ( captioningmanager . captionstyle captionstyle ) { <nl> - <nl> - return color . transparent ; / / captionstyle . windowcolor ; <nl> + private static captionstylecompat createfromcaptionstylev21 ( <nl> + captioningmanager . captionstyle captionstyle ) { <nl> + return new captionstylecompat ( <nl> + captionstyle . hasforegroundcolor ( ) ? captionstyle . foregroundcolor : default . foregroundcolor , <nl> + captionstyle . hasbackgroundcolor ( ) ? captionstyle . backgroundcolor : default . backgroundcolor , <nl> + captionstyle . haswindowcolor ( ) ? captionstyle . windowcolor : default . windowcolor , <nl> + captionstyle . hasedgetype ( ) ? captionstyle . edgetype : default . edgetype , <nl> + captionstyle . hasedgecolor ( ) ? captionstyle . edgecolor : default . edgecolor , <nl> + captionstyle . gettypeface ( ) ) ; <nl> } <nl>  <nl> }
public class mediacodecvideotrackrenderer extends mediacodectrackrenderer { <nl> @ override <nl> protected boolean canreconfigurecodec ( mediacodec codec , boolean codecisadaptive , <nl> mediaformat oldformat , mediaformat newformat ) { <nl> - <nl> - return newformat . mimetype . equals ( mimetypes . video_h264 ) <nl> - & & oldformat . mimetype . equals ( mimetypes . video_h264 ) <nl> - & & codecisadaptive <nl> - | | ( oldformat . width = = newformat . width & & oldformat . height = = newformat . height ) ; <nl> + return newformat . mimetype . equals ( oldformat . mimetype ) <nl> + & & ( codecisadaptive <nl> + | | ( oldformat . width = = newformat . width & & oldformat . height = = newformat . height ) ) ; <nl> } <nl>  <nl> @ override
public class redischannelinitializer extends channelinitializer < channel > { <nl>  <nl> sslparameters sslparams = new sslparameters ( ) ; <nl> if ( config . issslenableendpointidentification ( ) ) { <nl> - <nl> - try { <nl> - method method = sslparams . getclass ( ) . getdeclaredmethod ( " setendpointidentificationalgorithm " , string . class ) ; <nl> - method . invoke ( sslparams , " https " ) ; <nl> - } catch ( exception e ) { <nl> - throw new sslexception ( e ) ; <nl> - } <nl> + sslparams . setendpointidentificationalgorithm ( " https " ) ; <nl> } else { <nl> if ( config . getssltruststore ( ) = = null ) { <nl> sslcontextbuilder . trustmanager ( insecuretrustmanagerfactory . instance ) ;
public abstract class basetest { <nl> @ override <nl> public void run ( ) { <nl> defaultredisson . shutdown ( ) ; <nl> - try { <nl> - redisrunner . shutdowndefaultredisserverinstance ( ) ; <nl> - } catch ( interruptedexception e ) { <nl> - <nl> - e . printstacktrace ( ) ; <nl> - } <nl> } <nl> } ) ; <nl> } <nl> mmm a / redisson / src / test / java / org / redisson / redissonbuckettest . java <nl> ppp b / redisson / src / test / java / org / redisson / redissonbuckettest . java <nl>
public class commanddecoder extends replayingdecoder < state > { <nl> } <nl> } else { <nl> if ( ! promise . trysuccess ( null ) & & promise . cause ( ) instanceof redistimeoutexception ) { <nl> - <nl> log . warn ( " response has been skipped due to timeout ! channel : { } , command : { } " , ctx . channel ( ) , data ) ; <nl> } <nl> } <nl>
import io . netty . util . concurrent . promise ; <nl> * @ param < k > key <nl> * @ param < v > value <nl> * / <nl> - <nl> public class redissoncache < k , v > extends redissonmap < k , v > implements rcache < k , v > { <nl>  <nl> private static final rediscommand < mapscanresult < object , object > > eval_hscan = new rediscommand < mapscanresult < object , object > > ( " eval " , new nestedmultidecoder ( new objectmapreplaydecoder ( ) , new mapscanresultreplaydecoder ( ) ) , valuetype . map ) ; <nl>
public class sentinelconnectionmanager extends masterslaveconnectionmanager { <nl> currentmaster . set ( masterhost ) ; <nl> log . info ( " master : { } added " , masterhost ) ; <nl>  <nl> - <nl> list < map < string , string > > sentinelslaves = connection . sync ( rediscommands . sentinel_slaves , cfg . getmastername ( ) ) ; <nl> for ( map < string , string > map : sentinelslaves ) { <nl> + if ( map . isempty ( ) ) { <nl> + continue ; <nl> + } <nl> + <nl> string ip = map . get ( " ip " ) ; <nl> string port = map . get ( " port " ) ; <nl> string flags = map . get ( " flags " ) ; <nl>
abstract class baseloadbalancer implements loadbalancer { <nl> list < subscribesconnectionentry > clientscopy = new arraylist < subscribesconnectionentry > ( clients ) ; <nl> while ( true ) { <nl> if ( clientscopy . isempty ( ) ) { <nl> - <nl> - log . warn ( " slave subscribe - connection pool gets exhausted ! trying to acquire connection again . . . " ) ; <nl> - return nextpubsubconnection ( ) ; <nl> - / / long time = system . currenttimemillis ( ) ; <nl> - / / long endtime = system . currenttimemillis ( ) - time ; <nl> - / / log . warn ( " connection acquired , time spended : { } ms " , endtime ) ; <nl> + throw new redisconnectionexception ( " slave subscribe - connection pool gets exhausted ! " ) ; <nl> } <nl>  <nl> int <nl>
abstract class baseloadbalancer implements loadbalancer { <nl> list < subscribesconnectionentry > clientscopy = new arraylist < subscribesconnectionentry > ( clients ) ; <nl> while ( true ) { <nl> if ( clientscopy . isempty ( ) ) { <nl> - <nl> - log . warn ( " slave connection pool gets exhausted ! trying to acquire connection . . . " ) ; <nl> - return nextconnection ( ) ; <nl> - / / long time = system . currenttimemillis ( ) ; <nl> - / / long endtime = system . currenttimemillis ( ) - time ; <nl> - / / log . warn ( " connection acquired , time spended : { } ms " , endtime ) ; <nl> + throw new redisconnectionexception ( " slave connection pool gets exhausted ! " ) ; <nl> } <nl>  <nl> int
public class redissonatomiclong extends redissonexpirable implements ratomiclong <nl> } <nl>  <nl> @ override <nl> - public long getandadd ( long delta ) { <nl> - while ( true ) { <nl> - <nl> - long current = get ( ) ; <nl> - long next = current + delta ; <nl> - if ( compareandset ( current , next ) ) <nl> - return current ; <nl> - } <nl> + public long getandadd ( final long delta ) { <nl> + return connectionmanager . write ( new syncoperation < object , long > ( ) { <nl> + @ override <nl> + public long execute ( redisconnection < object , object > conn ) { <nl> + while ( true ) { <nl> + conn . watch ( getname ( ) ) ; <nl> + <nl> + number n = ( number ) conn . get ( getname ( ) ) ; <nl> + long value = num l ; <nl> + if ( n ! = null ) { <nl> + value = n . longvalue ( ) ; <nl> + } <nl> + <nl> + conn . multi ( ) ; <nl> + conn . set ( getname ( ) , value + delta ) ; <nl> + if ( conn . exec ( ) . size ( ) = = num ) { <nl> + return value ; <nl> + } <nl> + } <nl> + } <nl> + } ) ; <nl> } <nl>  <nl> @ override
abstract class baseloadbalancer implements loadbalancer { <nl>  <nl> log . debug ( " { } freezed " , addr ) ; <nl> connectionentry . setfreezed ( true ) ; <nl> - <nl> + <nl> + / / close all connections <nl> + while ( true ) { <nl> + redisconnection connection = connectionentry . getconnections ( ) . poll ( ) ; <nl> + if ( connection = = null ) { <nl> + break ; <nl> + } <nl> + connection . close ( ) ; <nl> + } <nl>  <nl> boolean allfreezed = true ; <nl> for ( slaveconnectionentry entry : clients ) { <nl>
public class redissonlock implements rlock { <nl>  <nl> private final connectionmanager connectionmanager ; <nl>  <nl> - <nl> - private final uuid id = uuid . randomuuid ( ) ; <nl> + private final uuid id ; <nl> private final string groupname = " redisson_lock_ " ; <nl> private final string name ; <nl>  <nl>
public class redissonlist < v > implements rlist < v > { <nl>  <nl> @ override <nl> public boolean containsall ( collection < ? > c ) { <nl> - for ( object object : c ) { <nl> - <nl> - if ( ! contains ( object ) ) { <nl> - return false ; <nl> + if ( isempty ( ) ) { <nl> + return false ; <nl> + } <nl> + <nl> + collection copy = new arraylist ( c ) ; <nl> + int to = div ( size ( ) , batchsize ) ; <nl> + for ( int i = num ; i < to ; i + + ) { <nl> + list < object > range = connection . lrange ( name , i * batchsize , i * batchsize + batchsize - num ) ; <nl> + for ( iterator iterator = copy . iterator ( ) ; iterator . hasnext ( ) ; ) { <nl> + object obj = iterator . next ( ) ; <nl> + int <nl> + if ( <nl> + iterator . remove ( ) ; <nl> + } <nl> } <nl> } <nl> - return true ; <nl> + <nl> + return copy . isempty ( ) ; <nl> } <nl>  <nl> @ override
public class redissonlock implements rlock { <nl> connection . publish ( getchannelname ( ) , unlockmessage ) ; <nl> } <nl> } else { <nl> - <nl> + throw new illegalmonitorstateexception ( " attempt to unlock lock , not locked by current thread id : " <nl> + + id + " thread - id : " + thread . currentthread ( ) . getid ( ) ) ; <nl> } <nl>  <nl> } <nl> mmm a / src / test / java / org / redisson / redissonlocktest . java <nl> ppp b / src / test / java / org / redisson / redissonlocktest . java <nl>
public class consumerservice extends baseservice { <nl>  <nl> protected popmessagerequestheader buildpopmessagerequestheader ( context ctx , receivemessagerequest request ) { <nl> checksubscriptiondata ( request . getmessagequeue ( ) . gettopic ( ) , request . getfilterexpression ( ) ) ; <nl> - <nl> - boolean fifo = false ; <nl> + boolean fifo = grpcclientmanager . getclientsettings ( ctx ) . getsubscription ( ) . getfifo ( ) ; <nl> return grpcconverter . buildpopmessagerequestheader ( request , grpcconverter . buildpolltimefromcontext ( ctx ) , fifo ) ; <nl> }
public class mappedfile extends referenceresource { <nl> return false ; <nl> } <nl>  <nl> - <nl> public int getwroteposition ( ) { <nl> return wroteposition . get ( ) ; <nl> } <nl> mmm a / rocketmq - store / src / main / java / com / alibaba / rocketmq / store / mappedfilequeue . java <nl> ppp b / rocketmq - store / src / main / java / com / alibaba / rocketmq / store / mappedfilequeue . java <nl>
import java . util . stack ; <nl> * returns true if s is nested and false otherwise . <nl> * <nl> * @ author akshay sharma <nl> - * @ date : num - 10 - 17 <nl> * @ author < a href = " https : / / github . com / khalil2535 " > khalil2535 < a > <nl> - * <nl> + * @ author shellhub <nl> * / <nl> class balancedbrackets { <nl>  <nl> / * * <nl> + * check if { @ code leftbracket } and { @ code rightbracket } is paired or not <nl> + * <nl> + * @ param leftbracket left bracket <nl> + * @ param rightbracket right bracket <nl> + * @ return { @ code true } if { @ code leftbracket } and { @ code rightbracket } is paired , <nl> + * otherwise { @ code false } <nl> + * / <nl> + public static boolean ispaired ( char leftbracket , char rightbracket ) { <nl> + char [ ] [ ] pairedbrackets = { <nl> + { ' ( ' , ' ) ' } , <nl> + { ' [ ' , ' ] ' } , <nl> + { ' { ' , ' } ' } , <nl> + { ' < ' , ' > ' } <nl> + } ; <nl> + for ( char [ ] pairedbracket : pairedbrackets ) { <nl> + if ( pairedbracket [ 0 ] = = leftbracket & & pairedbracket [ 1 ] = = rightbracket ) { <nl> + return true ; <nl> + } <nl> + } <nl> + return false ; <nl> + } <nl> + <nl> + / * * <nl> + * check if { @ code brackets } is balanced <nl> * <nl> - * @ param s <nl> - * @ return <nl> + * @ param brackets the brackets <nl> + * @ return { @ code true } if { @ code brackets } is balanced , otherwise { @ code false } <nl> * / <nl> - static boolean is_balanced ( string s ) { <nl> + public static boolean isbalanced ( string brackets ) { <nl> + if ( brackets = = null ) { <nl> + throw new illegalargumentexception ( " brackets is null " ) ; <nl> + } <nl> stack < character > bracketsstack = new stack < > ( ) ; <nl> - char [ ] text = s . tochararray ( ) ; <nl> - for ( char x : text ) { <nl> - switch ( x ) { <nl> - case ' { ' : <nl> - case ' < ' : <nl> + for ( char bracket : brackets . tochararray ( ) ) { <nl> + switch ( bracket ) { <nl> case ' ( ' : <nl> case ' [ ' : <nl> - bracketsstack . push ( x ) ; <nl> + case ' { ' : <nl> + bracketsstack . push ( bracket ) ; <nl> break ; <nl> - case ' } ' : <nl> - if ( ! bracketsstack . empty ( ) & & bracketsstack . pop ( ) = = ' { ' ) { <nl> - break ; <nl> - } else { <nl> - return false ; <nl> - } <nl> - case ' > ' : <nl> - if ( ! bracketsstack . empty ( ) & & bracketsstack . pop ( ) = = ' < ' ) { <nl> - break ; <nl> - } else { <nl> - return false ; <nl> - } <nl> case ' ) ' : <nl> - if ( ! bracketsstack . empty ( ) & & bracketsstack . pop ( ) = = ' ( ' ) { <nl> - break ; <nl> - } else { <nl> - return false ; <nl> - } <nl> case ' ] ' : <nl> - if ( ! bracketsstack . empty ( ) & & bracketsstack . pop ( ) = = ' [ ' ) { <nl> - break ; <nl> - } else { <nl> + case ' } ' : <nl> + if ( ! ( ! bracketsstack . isempty ( ) & & ispaired ( bracketsstack . pop ( ) , bracket ) ) ) { <nl> return false ; <nl> } <nl> + break ; <nl> + default : / * other character is invalid * / <nl> + return false ; <nl> } <nl> } <nl> - return bracketsstack . empty ( ) ; <nl> + return bracketsstack . isempty ( ) ; <nl> } <nl>  <nl> - / * * <nl> - * <nl> - * @ param args <nl> - * @ <nl> - * / <nl> - public static void main ( string args [ ] ) { <nl> - try ( scanner in = new scanner ( system . in ) ) { <nl> - system . out . println ( " enter sequence of brackets : " ) ; <nl> - string s = in . nextline ( ) ; <nl> - if ( is_balanced ( s ) ) { <nl> - system . out . println ( s + " is balanced " ) ; <nl> - } else { <nl> - system . out . println ( s + " ain ' t balanced " ) ; <nl> - } <nl> - } <nl> + <nl> + public static void main ( string [ ] args ) { <nl> + assert isbalanced ( " [ ( ) ] { } { [ ( ) ( ) ] ( ) } " ) ; <nl> + assert ! isbalanced ( " [ ( ] ) " ) ; <nl> } <nl> }
public class dirutil { <nl>  <nl> public static void copytodir ( directory in , directory out , string filename ) <nl> throws directoryexception { <nl> + copytodir ( in , out , filename , filename ) ; <nl> + } <nl> + <nl> + public static void copytodir ( directory in , directory out , string infile , string outfile ) <nl> + throws directoryexception { <nl> try { <nl> - if ( in . containsdir ( filename ) ) { <nl> - <nl> - in . getdir ( filename ) . copytodir ( out . createdir ( filename ) ) ; <nl> + if ( in . containsdir ( infile ) ) { <nl> + in . getdir ( infile ) . copytodir ( out . createdir ( outfile ) ) ; <nl> } else { <nl> - brutio . copyandclose ( in . getfileinput ( filename ) , <nl> - out . getfileoutput ( filename ) ) ; <nl> + brutio . copyandclose ( in . getfileinput ( infile ) , out . getfileoutput ( outfile ) ) ; <nl> } <nl> } catch ( ioexception ex ) { <nl> - throw new directoryexception ( <nl> - " error copying file : " + filename , ex ) ; <nl> + throw new directoryexception ( " error copying file : " + infile , ex ) ; <nl> } <nl> }
final public class androlibresources { <nl> cmd . add ( " - - no - version - transitions " ) ; <nl> cmd . add ( " - - no - resource - deduping " ) ; <nl>  <nl> - <nl> + if ( msparseresources ) { <nl> + cmd . add ( " - - enable - sparse - encoding " ) ; <nl> + } <nl>  <nl> if ( apkoptions . isframework ) { <nl> cmd . add ( " - x " ) ; <nl>
public class main { <nl> setadvancemode ( true ) ; <nl> } <nl>  <nl> - <nl> boolean cmdfound = false ; <nl> for ( string opt : commandline . getargs ( ) ) { <nl> if ( opt . equalsignorecase ( " d " ) | | opt . equalsignorecase ( " decode " ) ) { <nl>
public class res9patchstreamdecoder implements resstreamdecoder { <nl> drawvline ( im2 , num , ydivs [ i ] + num , ydivs [ i + num ] ) ; <nl> } <nl>  <nl> + / / some images additionally use optical bounds <nl> + / / https : / / developer . android . com / about / versions / android - 4 . 3 . html # opticalbounds <nl> try { <nl> opticalinset oi = getopticalinset ( data ) ; <nl>  <nl> - / / as far as i know , only the length of the red lines are interesting <nl> - / / not their positions <nl> - / / so set them up in the corners <nl> - <nl> - for ( int i = num ; i < oi . layoutboundsleft ; i + + ) { <nl> + for ( int i = num ; i < oi . layoutboundsleft ; i + + ) { <nl> int x = num + i ; <nl> im2 . setrgb ( x , h + num , oi_color ) ; <nl> } <nl>  <nl> - for ( int i = num ; i < oi . layoutboundsright ; i + + ) { <nl> + for ( int i = num ; i < oi . layoutboundsright ; i + + ) { <nl> int x = w - i ; <nl> im2 . setrgb ( x , h + num , oi_color ) ; <nl> } <nl>  <nl> - for ( int i = num ; i < oi . layoutboundstop ; i + + ) { <nl> + for ( int i = num ; i < oi . layoutboundstop ; i + + ) { <nl> int y = num + i ; <nl> im2 . setrgb ( w + num , y , oi_color ) ; <nl> } <nl>  <nl> - for ( int i = num ; i < oi . layoutboundsbottom ; i + + ) { <nl> + for ( int i = num ; i < oi . layoutboundsbottom ; i + + ) { <nl> int y = h - i ; <nl> im2 . setrgb ( w + num , y , oi_color ) ; <nl> } <nl> - } catch ( cantfind9patchchunk t ) { <nl> - / / this chunk might not exist <nl> + } catch ( cantfind9patchchunk t ) { <nl> + / / this chunk might not exist <nl> } <nl>  <nl> imageio . write ( im2 , " png " , out ) ;
public class packedswitchmethoditem extends instructionmethoditem < packedswitchpa <nl> targets = new arraylist < packedswitchtarget > ( ) ; <nl>  <nl> boolean first = true ; <nl> - <nl> int firstkey = num ; <nl> if ( basecodeaddress > = num ) { <nl> for ( switchelement switchelement : instruction . getswitchelements ( ) ) { <nl>
final public class androlibresources { <nl> respackage [ ] pkgs = getrespackagesfromapk ( apkfile , restable , skeepbroken ) ; <nl> respackage pkg = null ; <nl>  <nl> - <nl> switch ( pkgs . length ) { <nl> case num : <nl> pkg = pkgs [ 0 ] ; <nl>
<nl> - / * eslint - env node * / <nl> - <nl> - const reporter = require ( " stylelint - checkstyle - reporter " ) ; <nl> - <nl> - / * * <nl> - * @ type { import ( " stylelint " ) . formatter } <nl> - * / <nl> - function formatter ( results , returnvalue ) { <nl> - returnvalue . output = reporter ( results ) ; <nl> - <nl> - return returnvalue . output ; <nl> - } <nl> - <nl> - module . exports = formatter ;
public class proctest { <nl> * / <nl> @ test <nl> public void remoteprocoutputsync ( ) throws exception { <nl> - assumefalse ( " <nl> virtualchannel ch = createslavechannel ( ) ; <nl>  <nl> / / keep the pipe fairly busy <nl> final pipe p = pipe . createremotetolocal ( ) ; <nl> for ( int i = num ; i < num ; i + + ) <nl> ch . callasync ( new channelfiller ( p . getout ( ) ) ) ; <nl> - new thread ( ) { <nl> - @ override <nl> - public void run ( ) { <nl> - try { <nl> - ioutils . drain ( p . getin ( ) ) ; <nl> - } catch ( ioexception e ) { <nl> - } <nl> + new thread ( ( ) - > { <nl> + try { <nl> + ioutils . drain ( p . getin ( ) ) ; <nl> + } catch ( ioexception e ) { <nl> } <nl> - } . start ( ) ; <nl> + } ) . start ( ) ; <nl>  <nl> - remotelauncher launcher = new remotelauncher ( tasklistener . null , ch , true ) ; <nl> + remotelauncher launcher = new remotelauncher ( tasklistener . null , ch , ! functions . iswindows ( ) ) ; <nl>  <nl> - string str = " " ; <nl> - for ( int i = num ; i < num ; i + + ) <nl> - str + = " oxox " ; <nl> + stringbuilder str = new stringbuilder ( ) ; <nl> + str . append ( " oxox " . repeat ( 256 ) ) ; <nl>  <nl> for ( int i = num ; i < num ; i + + ) { <nl> bytearrayoutputstream baos = new bytearrayoutputstream ( ) ; <nl> - launcher . launch ( ) . cmds ( " echo " , str ) . stdout ( baos ) . join ( ) ; <nl> - assertequals ( str , baos . tostring ( charset . defaultcharset ( ) ) . trim ( ) ) ; <nl> + if ( functions . iswindows ( ) ) { <nl> + launcher . launch ( ) . cmds ( new string [ ] { " cmd " , " / c " , " echo " , str . tostring ( ) } ) . stdout ( baos ) . join ( ) ; <nl> + } <nl> + else { <nl> + launcher . launch ( ) . cmds ( " echo " , str . tostring ( ) ) . stdout ( baos ) . join ( ) ; <nl> + } <nl> + assertequals ( str . tostring ( ) , baos . tostring ( charset . defaultcharset ( ) ) . trim ( ) ) ; <nl> } <nl>  <nl> ch . close ( ) ;
public abstract class abstractbuild < p extends abstractproject < p , r > , r extends a <nl> * { @ link # getdisplayname ( ) } . <nl> * @ deprecated navigation through a hierarchy should be done through breadcrumbs , do not add a link using this method <nl> * / <nl> - @ deprecated ( since = " <nl> + @ deprecated ( since = " 2 . 364 " ) <nl> public string getupurl ( ) { <nl> return functions . getnearestancestorurl ( stapler . getcurrentrequest ( ) , getparent ( ) ) + ' / ' ; <nl> } <nl> mmm a / core / src / main / java / jenkins / model / projectnamingstrategy . java <nl> ppp b / core / src / main / java / jenkins / model / projectnamingstrategy . java <nl>
public class freestyleprojecttest { <nl> @ test <nl> @ issue ( " jenkins - 36629 " ) <nl> public void buildstabilityreports ( ) throws exception { <nl> - assumefalse ( " <nl> for ( int i = num ; i < = num ; i + + ) { <nl> freestyleproject p = j . createfreestyleproject ( string . format ( " pattern - % s " , integer . tobinarystring ( i ) ) ) ; <nl> int expectedfails = num ;
public class hudsonprivatesecurityrealmsec2566test { <nl>  <nl> @ test <nl> @ issue ( " security - 2566 " ) <nl> - / / @ ignore <nl> + @ ignore ( " too fragile to run " ) <nl> public void notimingdifferenceforinternalsecurityrealm ( ) throws exception { <nl> final hudsonprivatesecurityrealm realm = new hudsonprivatesecurityrealm ( false , false , null ) ; <nl> j . jenkins . setsecurityrealm ( realm ) ;
the software . <nl> < / systemproperties > <nl> < webapp > <nl> < ! - - allows resources to be reloaded , and enable nicer console logging . - - > <nl> - < ! - - <nl> + < extraclasspath > $ { project . basedir } / . . / core / src / main / resources , $ { project . basedir } / . . / core / target / classes , $ { project . build . directory } / support - log - formatter . jar < / extraclasspath > <nl> < contextpath > $ { contextpath } < / contextpath > <nl> < configurationdiscovered > false < / configurationdiscovered > <nl> < ! - - see https : / / wiki . eclipse . org / jetty / howto / avoid_slow_deployment - - > <nl> mmm a / websocket / jetty10 / pom . xml <nl> ppp b / websocket / jetty10 / pom . xml <nl>
public class javautils { <nl> * @ see system # getproperty ( string ) <nl> * / <nl> public static string getcurrentruntimejavaversion ( ) { <nl> - <nl> - return system . getproperty ( " java . specification . version " ) ; <nl> + runtime . version runtimeversion = runtime . version ( ) ; <nl> + return string . valueof ( runtimeversion . version ( ) . get ( 0 ) ) ; <nl> } <nl> } <nl> mmm a / test / src / test / java / jenkins / model / jenkinslogrecordstest . java <nl> ppp b / test / src / test / java / jenkins / model / jenkinslogrecordstest . java <nl>
public interface tasklistener extends serializableonlyoverremoting { <nl> return standardcharsets . utf_8 ; <nl> } <nl>  <nl> - @ restricted ( noexternaluse . class ) <nl> - default printwriter _error ( string prefix , string msg ) { <nl> + private printwriter _error ( string prefix , string msg ) { <nl> printstream out = getlogger ( ) ; <nl> out . print ( prefix ) ; <nl> out . println ( msg ) ;
public class iconsettest { <nl> assertthat ( symbol , not ( containsstring ( " tooltip " ) ) ) ; <nl> } <nl>  <nl> - / * * <nl> - * culprit : https : / / github . com / jenkinsci / jenkins / blob / <commit_id> / core / src / main / java / org / jenkins / ui / icon / iconset . java # l97 = <nl> - * if the tooltip contains an ampersand symbol ( & amp ; ) , it won ' t be removed . <nl> - * / <nl> - @ disabled ( " <nl> - @ test <nl> - void getsymbol_notsettingtooltipdoesntaddtooltipattribute_evenwithampersand ( ) { <nl> - string symbol = iconset . getsymbol ( " download " , " title " , " with & ampersand " , " class1 class2 " , " " , " id " ) ; <nl> - <nl> - assertthat ( symbol , not ( containsstring ( " tooltip " ) ) ) ; <nl> - } <nl> }
the software . <nl> < junit . jupiter . version > 5 . 8 . 2 < / junit . jupiter . version > <nl> < mockito . version > 4 . 6 . 1 < / mockito . version > <nl> < spotless . version > 2 . 22 . 7 < / spotless . version > <nl> - <nl> - < ! - - <nl> - < maven - surefire - plugin . version > 2 . 22 . 2 < / maven - surefire - plugin . version > <nl> - < maven - surefire - report - plugin . version > 2 . 22 . 2 < / maven - surefire - report - plugin . version > <nl> < / properties > <nl>  <nl> < dependencymanagement >
public class maven extends builder { <nl> * @ deprecated as of num . 286 <nl> * use { @ link jenkins . model . jenkins # getdescriptorbytype ( class ) } to obtain the current instance . <nl> * for compatibility , this field retains the last created { @ link descriptorimpl } . <nl> - * <nl> * / <nl> @ deprecated <nl> + @ restricted ( noexternaluse . class ) <nl> public static descriptorimpl descriptor ; <nl>  <nl> @ extension @ symbol ( " maven " )
the software . <nl> < maven . test . redirecttestoutputtofile > true < / maven . test . redirecttestoutputtofile > <nl> < / properties > <nl> < / profile > <nl> - < profile > <nl> - < id > japicmp < / id > <nl> - < build > <nl> - < plugins > <nl> - < plugin > <nl> - < groupid > com . github . siom79 . japicmp < / groupid > <nl> - < artifactid > japicmp - maven - plugin < / artifactid > <nl> - < ! - - <nl> - < version > 0 . 14 . 4 - 20200728 . 214757 - 1 < / version > <nl> - < configuration > <nl> - < parameter > <nl> - < ! - - see https : / / siom79 . github . io / japicmp / mavenplugin . html - - > <nl> - < oldversionpattern > \ d + [ . ] \ d + < / oldversionpattern > <nl> - < ! - - < onlymodified > true < / onlymodified > - - > <nl> - < onlybinaryincompatible > true < / onlybinaryincompatible > <nl> - < / parameter > <nl> - < oldclasspathdependencies > <nl> - < dependency > <nl> - < ! - - provided , so not visible in flattened artifact - - > <nl> - < groupid > javax . servlet < / groupid > <nl> - < artifactid > javax . servlet - api < / artifactid > <nl> - < version > 3 . 1 . 0 < / version > <nl> - < scope > provided < / scope > <nl> - < / dependency > <nl> - < / oldclasspathdependencies > <nl> - < / configuration > <nl> - < executions > <nl> - < execution > <nl> - < goals > <nl> - < goal > cmp < / goal > <nl> - < / goals > <nl> - < phase > verify < / phase > <nl> - < / execution > <nl> - < / executions > <nl> - < / plugin > <nl> - < / plugins > <nl> - < / build > <nl> - < / profile > <nl> < / profiles > <nl> < / project >
the software . <nl> < jdk > 11 < / jdk > <nl> < / activation > <nl> < properties > <nl> - < ! - - <nl> - < doclint > none < / doclint > <nl> - < maven . javadoc . skip > true < / maven . javadoc . skip > <nl> < ! - - release is needed for reliable cross compilation . it is supported <nl> starting jdk num , but as the only earlier version we support is num , it would <nl> be either compiled by javac from num or one from a newer compiler that
n / a <nl> # # # submitter checklist <nl>  <nl> - [ ] ( if applicable ) jira issue is well described <nl> - - [ ] changelog entries and upgrade guidelines are appropriate for the audience affected by the change ( users or developer , depending on the change ) . [ examples ] ( https : / / github . com / jenkins - infra / jenkins . io / blob / master / content / _data / changelogs / weekly . yml ) <nl> + - [ ] changelog entries and upgrade guidelines are appropriate for the audience affected by the change ( users or developer , depending on the change ) and are in the imperative mood . [ examples ] ( https : / / github . com / jenkins - infra / jenkins . io / blob / master / content / _data / changelogs / weekly . yml ) <nl> * fill - in the ` proposed changelog entries ` section only if there are breaking changes or other changes which may require extra steps from users during the upgrade <nl> - [ ] appropriate autotests or explanation to why this change has no tests <nl> - [ ] new public classes , fields , and methods are annotated with ` @ restricted ` or have ` @ since <nl>
<nl> - package jenkins . model . jenkins <nl> - <nl> - import hudson . slaves . cloud <nl> - <nl> - <nl> - <nl> - def f = namespace ( lib . formtaglib ) <nl> - <nl> - def clouds = cloud . all ( ) <nl> - <nl> - if ( ! clouds . isempty ( ) ) { <nl> - f . section ( title : _ ( " cloud " ) ) { <nl> - f . block { <nl> - div ( class : ' alert alert - info ' ) { <nl> - raw ( _ ( " note " , rooturl ) ) <nl> - } <nl> - } <nl> - } <nl> - } <nl> mmm a / core / src / main / resources / jenkins / model / jenkins / _cloud - note . properties <nl> ppp / dev / null <nl>
public class callabledirectionchecker extends rolechecker { <nl> return ; / / known to be safe <nl> } <nl>  <nl> - if ( expected . isempty ( ) & & systemproperties . getboolean ( allow_any_role_prop , true ) ) { <nl> - <nl> - logger . log ( level . fine , " executing { 0 } is allowed since it is targeted for any role " , name ) ; <nl> - return ; <nl> - } <nl> - <nl> if ( bypass ) { <nl> logger . log ( level . fine , " allowing { 0 } to be sent from agent to controller because bypass is set " , name ) ; <nl> return ; <nl> mmm a / test / src / test / java / jenkins / security / security2458test . java <nl> ppp b / test / src / test / java / jenkins / security / security2458test . java <nl>
import java . util . logging . level ; <nl> import java . util . logging . logrecord ; <nl> import java . util . logging . logger ; <nl>  <nl> - <nl> - / / the change needs api deprecation policy or external usages cleanup . <nl> - <nl> / * * <nl> * { @ link tasklistener } which sends messages to a { @ link logger } . <nl> * / <nl> + @ suppresswarnings ( " deprecation " ) / / to preserve serial form <nl> public class logtasklistener extends abstracttasklistener implements tasklistener , closeable { <nl>  <nl> / / would be simpler to delegate to the logoutputstream but this would incompatibly change the serial form <nl> mmm a / core / src / main / java / hudson / util / streamtasklistener . java <nl> ppp b / core / src / main / java / hudson / util / streamtasklistener . java <nl>
import java . util . logging . logger ; <nl> import jenkins . util . systemproperties ; <nl> import org . kohsuke . stapler . framework . io . writeroutputstream ; <nl>  <nl> - <nl> - / / the change needs api deprecation policy or external usages cleanup . <nl> - <nl> / * * <nl> * { @ link tasklistener } that generates output into a single stream . <nl> * <nl>
public class xstream2 extends xstream { <nl> throw new conversionexception ( " refusing to unmarshal " + reader . getnodename ( ) + " for security reasons ; see https : / / www . jenkins . io / redirect / class - filter / " ) ; <nl> } <nl>  <nl> - / * * <nl> - private static final pattern jruby_proxy = pattern . compile ( " org [ . ] jruby [ . ] proxy [ . ] . + [ $ ] proxy \ \ d + " ) ; <nl> - <nl> @ override <nl> public boolean canconvert ( class type ) { <nl> if ( type = = null ) { <nl> return false ; <nl> } <nl> string name = type . getname ( ) ; <nl> - if ( jruby_proxy . matcher ( name ) . matches ( ) ) { <nl> - return false ; <nl> - } <nl> / / claim we can convert all the scary stuff so we can throw exceptions when attempting to do so <nl> return classfilter . default . isblacklisted ( name ) | | classfilter . default . isblacklisted ( type ) ; <nl> } <nl> mmm a / core / src / main / resources / jenkins / security / whitelisted - classes . txt <nl> ppp b / core / src / main / resources / jenkins / security / whitelisted - classes . txt <nl>
public class jenkins extends abstractcibase implements directlymodifiabletopleve <nl> / * * <nl> * automatically try to launch an agent when jenkins is initialized or a new agent computer is created . <nl> * / <nl> - @ suppressfbwarnings ( value = " ms_should_be_final " , justification = " <nl> - public static boolean automatic_slave_launch = true ; <nl> + @ suppressfbwarnings ( value = " ms_should_be_final " , justification = " for script console " ) <nl> + public static boolean automatic_agent_launch = systemproperties . getboolean ( jenkins . class . getname ( ) + " . automaticagentlaunch " , true ) ; <nl>  <nl> private static final logger logger = logger . getlogger ( jenkins . class . getname ( ) ) ; <nl> private static final securerandom random = new securerandom ( ) ; <nl> mmm a / core / src / main / java / jenkins / model / item_category / itemcategory . java <nl> ppp b / core / src / main / java / jenkins / model / item_category / itemcategory . java <nl>
public abstract class itemcategory implements extensionpoint { <nl> * see < a href = " https : / / issues . jenkins . io / browse / jenkins - 36593 " > jenkins - 36593 < / a > for more info . <nl> * / <nl> @ restricted ( noexternaluse . class ) <nl> - @ suppressfbwarnings ( value = " ms_should_be_final " , justification = " <nl> - public static int min_toshow = num ; <nl> + @ restrictedsince ( " 2 . 14 " ) <nl> + public static final int min_toshow = num ; <nl>  <nl> / * * <nl> * helpful to set the order .
public class webappmain implements servletcontextlistener { <nl>  <nl> final file _home = home ; <nl> initthread = new thread ( " jenkins initialization thread " ) { <nl> - @ suppressfbwarnings ( value = " rv_return_value_ignored_bad_practice " , justification = " <nl> @ override <nl> public void run ( ) { <nl> boolean success = false ; <nl>
public class compressedfile { <nl> * / <nl> public void compress ( ) { <nl> compressionthread . submit ( new runnable ( ) { <nl> - @ suppressfbwarnings ( value = " rv_return_value_ignored_bad_practice " , justification = " <nl> @ override <nl> public void run ( ) { <nl> - try { <nl> - try ( inputstream in = read ( ) ; <nl> - outputstream os = files . newoutputstream ( gz . topath ( ) ) ; <nl> - outputstream out = new gzipoutputstream ( os ) ) { <nl> - org . apache . commons . io . ioutils . copy ( in , out ) ; <nl> - } <nl> + boolean success ; <nl> + try ( inputstream in = read ( ) ; <nl> + outputstream os = files . newoutputstream ( gz . topath ( ) ) ; <nl> + outputstream out = new gzipoutputstream ( os ) ) { <nl> + org . apache . commons . io . ioutils . copy ( in , out ) ; <nl> + out . flush ( ) ; <nl> + success = true ; <nl> + } catch ( ioexception | invalidpathexception e ) { <nl> + logger . log ( level . warning , " failed to compress " + file , e ) ; <nl> + success = false ; <nl> + } <nl> + <nl> + file filetodelete ; <nl> + if ( success ) { <nl> / / if the compressed file is created successfully , remove the original <nl> - file . delete ( ) ; <nl> - } catch ( ioexception e ) { <nl> - logger . log ( level . warning , " failed to compress " + file , e ) ; <nl> - gz . delete ( ) ; / / in case a processing is left in the middle <nl> + filetodelete = file ; <nl> + } else { <nl> + / / in case a processing is left in the middle <nl> + filetodelete = gz ; <nl> + } <nl> + try { <nl> + files . deleteifexists ( filetodelete . topath ( ) ) ; <nl> + } catch ( ioexception | invalidpathexception e ) { <nl> + logger . log ( level . warning , " failed to delete " + filetodelete , e ) ; <nl> } <nl> } <nl> } ) ; <nl> mmm a / core / src / main / java / jenkins / util / progressiverendering . java <nl> ppp b / core / src / main / java / jenkins / util / progressiverendering . java <nl>
public class util { <nl>  <nl> / * * <nl> * concatenate multiple strings by inserting a separator . <nl> - * @ deprecated since <nl> + * @ deprecated since num . 292 ; use { @ link string # join ( charsequence , iterable ) } <nl> * / <nl> @ deprecated <nl> @ nonnull <nl> mmm a / core / src / main / java / hudson / model / fingerprint . java <nl> ppp b / core / src / main / java / hudson / model / fingerprint . java <nl>
public class fingerprint implements modelobject , saveable { <nl> / * * <nl> * save the fingerprint in the given file locally <nl> * @ throws ioexception save error <nl> - * @ deprecated as of <nl> + * @ deprecated as of num . 242 . use { @ link # save ( ) } instead . <nl> * / <nl> @ deprecated <nl> void save ( file file ) throws ioexception { <nl>
public class fingerprint implements modelobject , saveable { <nl>  <nl> / * * <nl> * determines the file name from md5sum . <nl> - * @ deprecated as of <nl> + * @ deprecated as of num . 242 . use { @ link # load ( string ) } instead . <nl> * / <nl> @ deprecated <nl> / * package * / static @ checkfornull fingerprint load ( @ nonnull byte [ ] md5sum ) throws ioexception { <nl>
public class fingerprint implements modelobject , saveable { <nl> * loads a { @ link fingerprint } from a file in the image . <nl> * @ return loaded { @ link fingerprint } . null if the config file does not exist or <nl> * malformed . <nl> - * @ deprecated as of <nl> + * @ deprecated as of num . 242 . use { @ link # load ( string ) } instead . <nl> * / <nl> @ deprecated <nl> / * package * / static @ checkfornull fingerprint load ( @ nonnull file file ) throws ioexception { <nl> mmm a / core / src / main / java / jenkins / fingerprints / fingerprintstorage . java <nl> ppp b / core / src / main / java / jenkins / fingerprints / fingerprintstorage . java <nl>
public abstract class fingerprintstorage extends abstractdescribableimpl < fingerp <nl>  <nl> / * * <nl> * returns the file system based { @ link filefingerprintstorage } configured on the system . <nl> - * @ deprecated since <nl> + * @ deprecated since num . 324 , use { @ code extensionlist . lookupsingleton ( filefingerprintstorage . class ) } instead . <nl> * / <nl> @ deprecated <nl> public static fingerprintstorage getfilefingerprintstorage ( ) {
public abstract class trigger < j extends item > implements describable < trigger < ? > > <nl> / / terminated . <nl> / / fixme allow to set a global crontab spec <nl> previoussynchronouspolling = scmd . getexecutor ( ) . submit ( new dependencyrunner ( new projectrunnable ( ) { <nl> - @ suppressfbwarnings ( value = " np_null_on_some_path " , justification = " <nl> @ override <nl> public void run ( abstractproject p ) { <nl> for ( trigger t : ( collection < trigger > ) p . gettriggers ( ) . values ( ) ) { <nl> if ( t instanceof scmtrigger ) { <nl> - logger . fine ( " synchronously triggering scmtrigger for project " + t . job . getname ( ) ) ; <nl> + if ( t . job ! = null ) { <nl> + logger . fine ( " synchronously triggering scmtrigger for project " + t . job . getname ( ) ) ; <nl> + } else { <nl> + logger . fine ( " synchronously triggering scmtrigger for unknown project " ) ; <nl> + } <nl> t . run ( ) ; <nl> } <nl> }
public class jenkins extends abstractcibase implements directlymodifiabletopleve <nl> * if non - null , use existing plugin manager . create a new one . <nl> * / <nl> @ suppressfbwarnings ( { <nl> - " dmi_random_used_only_once " , <nl> " st_write_to_static_from_instance_method " , / / trigger . timer <nl> " dm_exit " / / exit is wanted here <nl> } ) <nl>
public class encryptedslaveagentjnlpfile implements httpresponse { <nl> this . slavename = slavename ; <nl> } <nl>  <nl> - @ suppressfbwarnings ( value = " dmi_random_used_only_once " , justification = " <nl> @ override <nl> public void generateresponse ( staplerrequest req , final staplerresponse res , object node ) throws ioexception , servletexception { <nl> requestdispatcher view = req . getview ( it , viewname ) ; <nl>
properties ( [ <nl> disableconcurrentbuilds ( abortprevious : true ) <nl> ] ) <nl>  <nl> - <nl> - def buildtypes = [ ' linux ' ] <nl> + def buildtypes = [ ' linux ' , ' windows ' ] <nl> def jdks = [ 8 , num ] <nl>  <nl> def builds = [ : ] <nl>
public abstract class abstractcloudslave extends slave { <nl> computer . recordtermination ( ) ; <nl> } <nl> try { <nl> - <nl> - _terminate ( new streamtasklistener ( system . out , charset . defaultcharset ( ) ) ) ; <nl> + _terminate ( computer instanceof slavecomputer ? ( ( slavecomputer ) computer ) . getlistener ( ) : new logtasklistener ( logger , level . info ) ) ; <nl> } finally { <nl> try { <nl> jenkins . get ( ) . removenode ( this ) ; <nl> mmm a / core / src / main / java / hudson / slaves / slavecomputer . java <nl> ppp b / core / src / main / java / hudson / slaves / slavecomputer . java <nl>
public class channels { <nl> } ; <nl> cb . withheaderstream ( header ) ; <nl>  <nl> + executor executor = executor . currentexecutor ( ) ; <nl> + object context = executor ! = null ? executor . getowner ( ) : proc ; <nl> for ( channelconfigurator cc : channelconfigurator . all ( ) ) { <nl> - cc . onchannelbuilding ( cb , null ) ; <nl> + cc . onchannelbuilding ( cb , context ) ; <nl> } <nl>  <nl> return cb . build ( in , out ) ; <nl>
public class channels { <nl> } ; <nl> cb . withheaderstream ( header ) ; <nl>  <nl> + executor executor = executor . currentexecutor ( ) ; <nl> + object context = executor ! = null ? executor . getowner ( ) : proc ; <nl> for ( channelconfigurator cc : channelconfigurator . all ( ) ) { <nl> - cc . onchannelbuilding ( cb , null ) ; <nl> + cc . onchannelbuilding ( cb , context ) ; <nl> } <nl>  <nl> return cb . build ( proc . getinputstream ( ) , proc . getoutputstream ( ) ) ; <nl> mmm a / core / src / main / java / jenkins / security / channelconfigurator . java <nl> ppp b / core / src / main / java / jenkins / security / channelconfigurator . java <nl>
public class queue extends resourcecontroller implements saveable { <nl> * if { @ link # getparent } has a distinct { @ link subtask # getownertask } , <nl> * then it should be the case that { @ code getparentexecutable ( ) . getparent ( ) = = getparent ( ) . getownertask ( ) } . <nl> * @ return a < em > distinct < / em > executable ( never { @ code this } , unlike the default of { @ link subtask # getownertask } ! ) ; or null if this executable was already at top level <nl> - * @ since <nl> + * @ since num . 313 , but implementations can already implement this with a lower core dependency . <nl> * / <nl> default @ checkfornull executable getparentexecutable ( ) { <nl> return null ; <nl> mmm a / core / src / main / java / hudson / util / xstream2 . java <nl> ppp b / core / src / main / java / hudson / util / xstream2 . java <nl>
the software . <nl> < groupid > com . github . jnr < / groupid > <nl> < artifactid > jnr - posix < / artifactid > <nl> < / dependency > <nl> - < ! - - <nl> - for compatibility only ; not included into the bom for the same reason . <nl> - https : / / github . com / jenkinsci / scm - api - plugin / pull / 88 is widely adopted , this <nl> - dependency can be dropped . <nl> - - - > <nl> - < dependency > <nl> - < groupid > org . kohsuke < / groupid > <nl> - < artifactid > asm5 < / artifactid > <nl> - < version > 5 . 0 . 1 < / version > <nl> - < / dependency > <nl> < dependency > <nl> < groupid > org . kohsuke . stapler < / groupid > <nl> < artifactid > stapler < / artifactid >
the software . <nl> < groupid > aopalliance < / groupid > <nl> < artifactid > aopalliance < / artifactid > <nl> < / exclusion > <nl> - < exclusion > < ! - - <nl> - < groupid > com . google . guava < / groupid > <nl> - < artifactid > guava < / artifactid > <nl> - < / exclusion > <nl> < / exclusions > <nl> < / dependency > <nl>  <nl>
the software . <nl> < artifactid > antisamy - markup - formatter < / artifactid > <nl> < version > 2 . 4 < / version > <nl> < scope > test < / scope > <nl> - < exclusions > <nl> - < exclusion > < ! - - <nl> - < groupid > com . google . guava < / groupid > <nl> - < artifactid > guava < / artifactid > <nl> - < / exclusion > <nl> - < / exclusions > <nl> < / dependency > <nl> < dependency > <nl> < groupid > org . jenkins - ci . plugins < / groupid >
public abstract class cause { <nl> * one - line human - readable text of the cause . <nl> * <nl> * historically , this method ' s return value was used to render html on the ui as well . <nl> - * since october num , the return value is interpreted as text . <nl> + * since jenkins num . 315 and num . 303 . 2 , the return value is interpreted as text . <nl> * to have rich html output on the ui , provide a custom { @ code description . jelly } view for your subclass . <nl> + * see < a href = " https : / / www . jenkins . io / doc / developer / security / xss - prevention / cause - getshortdescription / " > the documentation < / a > . <nl> * / <nl> - <nl> @ exported ( visibility = 3 ) <nl> public abstract string getshortdescription ( ) ;
public final class jdk extends toolinstallation implements nodespecific < jdk > , en <nl>  <nl> @ override <nl> public string getdisplayname ( ) { <nl> - return " jdk " ; <nl> + return messages . jdk_displayname ( ) ; <nl> } <nl>  <nl> @ override <nl> mmm a / core / src / main / resources / hudson / model / messages . properties <nl> ppp b / core / src / main / resources / hudson / model / messages . properties <nl>
<nl> < description > command line interface for jenkins < / description > <nl> < url > https : / / github . com / jenkinsci / jenkins < / url > <nl>  <nl> - < properties > <nl> - < ! - - <nl> - < findbugs . threshold > medium < / findbugs . threshold > <nl> - < / properties > <nl> - <nl> < dependencymanagement > <nl> < dependencies > <nl> < dependency > <nl> mmm a / core / pom . xml <nl> ppp b / core / pom . xml <nl>
the software . <nl> < ! - - minimum remoting version , which is tested for api compatibility - - > <nl> < remoting . minimum . supported . version > 3 . 14 < / remoting . minimum . supported . version > <nl>  <nl> - < ! - - <nl> - < findbugs . effort > max < / findbugs . effort > <nl> - < findbugs . threshold > high < / findbugs . threshold > <nl> - < findbugs . excludefilterfile > $ { project . basedir } / . . / src / findbugs / findbugs - excludes . xml < / findbugs . excludefilterfile > <nl> + < spotbugs . effort > max < / spotbugs . effort > <nl> + < spotbugs . threshold > medium < / spotbugs . threshold > <nl> + < spotbugs . excludefilterfile > $ { project . basedir } / . . / src / spotbugs / spotbugs - excludes . xml < / spotbugs . excludefilterfile > <nl>  <nl> < access - modifier . version > 1 . 25 < / access - modifier . version > <nl> < junit . jupiter . version > 5 . 8 . 1 < / junit . jupiter . version >
jobs : <nl> with : <nl> name : changelog . yaml <nl> path : changelog . yaml <nl> - # <nl> - # upload yaml to the release draft assets <nl> - # - name : upload changelog . yaml to the release draft <nl> - # id : upload - changelog - yaml <nl> - # uses : actions / upload - release - asset @ v1 . 0 . 1 <nl> - # env : <nl> - # github_token : $ { { secrets . github_token } } <nl> - # with : <nl> - # upload_url : $ { { steps . release - drafter . outputs . upload_url } } <nl> - # asset_path : . / changelog . yaml <nl> - # asset_name : changelog . yaml <nl> - # asset_content_type : text / yaml <nl> + <nl> + jenkins_io_draft : <nl> + runs - on : ubuntu - latest <nl> + if : github . repository_owner = = ' jenkinsci ' <nl> + steps : <nl> + - uses : tibdex / github - app - token @ v1 <nl> + id : generate - token <nl> + with : <nl> + app_id : $ { { secrets . jenkins_changelog_updater_app_id } } <nl> + private_key : $ { { secrets . jenkins_changelog_updater_private_key } } <nl> + repository : jenkins - infra / jenkins . io <nl> + - name : check out <nl> + uses : actions / checkout @ v2 . 3 . 4 <nl> + with : <nl> + fetch - depth : num <nl> + - name : publish jenkins . io changelog draft <nl> + env : <nl> + github_token : $ { { steps . generate - token . outputs . token } } <nl> + github_auth : " nobody : $ { { steps . generate - token . outputs . token } } " <nl> + git_author_name : jenkins - infra - changelog - generator <nl> + git_author_email : < 86592549 + jenkins - infra - changelog - generator [ bot ] @ users . noreply . github . com > <nl> + git_committer_name : jenkins - infra - changelog - generator <nl> + git_committer_email : < 86592549 + jenkins - infra - changelog - generator [ bot ] @ users . noreply . github . com > <nl> + run : | <nl> + wget - - quiet https : / / raw . githubusercontent . com / jenkinsci / core - changelog - generator / master / generate - weekly - changelog . sh <nl> + bash generate - weekly - changelog . sh
executor_number . blurb = \ <nl> ( among executors of the same machine ) that \ u2019s \ <nl> carrying out this build . this is the number you see in \ <nl> the " build executor status " , except that the number starts from num , not num . <nl> - node_name . blurb = name of the agent if the build is on an agent , or " built - in " if run on the built - in node ( or " master " until jenkins num . <nl> + node_name . blurb = name of the agent if the build is on an agent , or " built - in " if run on the built - in node ( or " master " until jenkins num . 307 ) . <nl> node_labels . blurb = whitespace - separated list of labels that the node is assigned . <nl> workspace . blurb = the absolute path of the directory assigned to the build as a workspace . <nl> workspace_tmp . blurb = \
the software . <nl> < dependency > <nl> < groupid > org . jenkins - ci . plugins < / groupid > <nl> < artifactid > matrix - project < / artifactid > <nl> - < version > $ { matrix - project . version } < / version > <nl> + < version > 1 . 18 < / version > <nl> + < scope > test < / scope > <nl> < / dependency > <nl> < dependency > <nl> < groupid > org . jenkins - ci . plugins < / groupid > <nl> < artifactid > junit < / artifactid > <nl> < version > 1 . 49 < / version > <nl> - < ! - - <nl> < scope > test < / scope > <nl> < / dependency > <nl> < dependency > <nl>
org . jvnet . hudson . memoryusage <nl> org . jvnet . localizer . localizable <nl> org . jvnet . localizer . resourcebundleholder <nl>  <nl> - # <nl> - org . owasp . dependencycheck . dependency . reference <nl> - org . owasp . dependencycheck . dependency . vulnerability <nl> - org . owasp . dependencycheck . dependency . vulnerablesoftware <nl> - <nl> org . springframework . security . core . userdetails . user <nl>  <nl> sun . security . rsa . rsapublickeyimpl
the software . <nl> < properties > <nl> < guavaversion > 11 . 0 . 1 < / guavaversion > <nl> < slf4jversion > 1 . 7 . 30 < / slf4jversion > <nl> - < stapler . version > 1 . 263 - rc1502 . c0b75c89ee9d < / stapler . version > < ! - - <nl> + < stapler . version > 1 . 263 < / stapler . version > <nl> < groovy . version > 2 . 4 . 12 < / groovy . version > <nl> < / properties >
the software . <nl> < dependency > <nl> < groupid > org . jenkins - ci . plugins < / groupid > <nl> < artifactid > structs < / artifactid > <nl> - < version > 1 . 21 < / version > <nl> - < ! - - <nl> + < version > 1 . 22 < / version > <nl> < scope > test < / scope > <nl> < / dependency > <nl> < dependency >
the software . <nl> < artifactitem > <nl> < groupid > org . jenkins - ci . plugins < / groupid > <nl> < artifactid > ldap < / artifactid > <nl> - < version > 1 . 26 < / version > < ! - - <nl> + < version > 2 . 3 < / version > <nl> < type > hpi < / type > <nl> < / artifactitem > <nl> < artifactitem >
the software . <nl> < artifactid > reflections < / artifactid > <nl> < version > 0 . 9 . 12 < / version > <nl> < exclusions > <nl> - < exclusion > < ! - - <nl> - < groupid > com . google . guava < / groupid > <nl> - < artifactid > guava < / artifactid > <nl> - < / exclusion > <nl> < exclusion > < ! - - pick up from stapler - - > <nl> < groupid > com . google . code . findbugs < / groupid > <nl> < artifactid > jsr305 < / artifactid >
public class functionstest { <nl> s . println ( " some custom exception " ) ; <nl> } <nl> } , " some custom exception\n " , " some custom exception\n " ) ; <nl> - / * <nl> / / circular references : <nl> stack stack1 = new stack ( " p . exc1 " , " p . c . method1 : 17 " ) ; <nl> stack stack2 = new stack ( " p . exc2 " , " p . c . method2 : 27 " ) ; <nl> stack1 . cause ( stack2 ) ; <nl> stack2 . cause ( stack1 ) ; <nl> - assertprintthrowable ( stack1 , <nl> - " p . exc1\n " + <nl> - " \ tat p . c . method1 ( c . java : 17 ) \n " + <nl> - " caused by : p . exc2\n " + <nl> - " \ tat p . c . method2 ( c . java : 27 ) \n " + <nl> - " \ t [ circular reference : p . exc1 ] \n " , <nl> - " < cycle to p . exc1 > \n " + <nl> - " caused : p . exc2\n " + <nl> - " \ tat p . c . method2 ( c . java : 27 ) \n " + <nl> - " caused : p . exc1\n " + <nl> - " \ tat p . c . method1 ( c . java : 17 ) \n " ) ; <nl> - * / <nl> + / / format changed in num . 0 . 9 / num . 0 . 272 ( jdk - 8226809 / jdk - 8252444 / jdk - 8252489 ) <nl> + if ( ( getversion ( ) . getdigitat ( 0 ) = = num & & getversion ( ) . isnewerthanorequalto ( new versionnumber ( " 11 . 0 . 9 " ) ) ) | | <nl> + ( getversion ( ) . getdigitat ( 0 ) = = num & & getversion ( ) . isnewerthanorequalto ( new versionnumber ( " 8 . 0 . 272 " ) ) ) ) { <nl> + assertprintthrowable ( stack1 , <nl> + " p . exc1\n " + <nl> + " \ tat p . c . method1 ( c . java : 17 ) \n " + <nl> + " caused by : p . exc2\n " + <nl> + " \ tat p . c . method2 ( c . java : 27 ) \n " + <nl> + " caused by : [ circular reference : p . exc1 ] \n " , <nl> + " < cycle to p . exc1 > \n " + <nl> + " caused : p . exc2\n " + <nl> + " \ tat p . c . method2 ( c . java : 27 ) \n " + <nl> + " caused : p . exc1\n " + <nl> + " \ tat p . c . method1 ( c . java : 17 ) \n " ) ; <nl> + } else { <nl> + assertprintthrowable ( stack1 , <nl> + " p . exc1\n " + <nl> + " \ tat p . c . method1 ( c . java : 17 ) \n " + <nl> + " caused by : p . exc2\n " + <nl> + " \ tat p . c . method2 ( c . java : 27 ) \n " + <nl> + " \ t [ circular reference : p . exc1 ] \n " , <nl> + " < cycle to p . exc1 > \n " + <nl> + " caused : p . exc2\n " + <nl> + " \ tat p . c . method2 ( c . java : 27 ) \n " + <nl> + " caused : p . exc1\n " + <nl> + " \ tat p . c . method1 ( c . java : 17 ) \n " ) ; <nl> + } <nl> + } <nl> + private static versionnumber getversion ( ) { <nl> + string version = system . getproperty ( " java . version " ) ; <nl> + if ( version . startswith ( " 1 . " ) ) { <nl> + version = version . substring ( 2 ) . replace ( " _ " , " . " ) ; <nl> + } <nl> + return new versionnumber ( version ) ; <nl> } <nl> private static void assertprintthrowable ( throwable t , string traditional , string custom ) { <nl> stringwriter sw = new stringwriter ( ) ;
<nl> - package hudson . model ; <nl> - <nl> - import org . junit . assert ; <nl> - import org . junit . rule ; <nl> - import org . junit . test ; <nl> - import org . jvnet . hudson . test . issue ; <nl> - import org . jvnet . hudson . test . jenkinsrule ; <nl> - import org . jvnet . hudson . test . recipes . localdata ; <nl> - import org . xml . sax . saxexception ; <nl> - <nl> - import java . io . ioexception ; <nl> - <nl> - <nl> - public class causesecurity1960test { <nl> - @ rule <nl> - public jenkinsrule j = new jenkinsrule ( ) ; <nl> - <nl> - @ test <nl> - @ issue ( " security - 1960 " ) <nl> - @ localdata <nl> - public void xssinremotecause ( ) throws ioexception , saxexception { <nl> - final item item = j . jenkins . getitembyfullname ( " fs " ) ; <nl> - assert . asserttrue ( item instanceof freestyleproject ) ; <nl> - freestyleproject fs = ( freestyleproject ) item ; <nl> - final freestylebuild build = fs . getbuildbynumber ( 1 ) ; <nl> - <nl> - final jenkinsrule . webclient wc = j . createwebclient ( ) ; <nl> - final string content = wc . getpage ( build ) . getwebresponse ( ) . getcontentasstring ( ) ; <nl> - assert . assertfalse ( content . contains ( " started by remote host < img " ) ) ; <nl> - assert . asserttrue ( content . contains ( " started by remote host & lt ; img " ) ) ; <nl> - } <nl> - } <nl> mmm a / test / src / test / java / hudson / model / causetest . java <nl> ppp b / test / src / test / java / hudson / model / causetest . java <nl>
public class util { <nl> } <nl> return res ; <nl> } catch ( nosuchmethodexception e ) { <nl> + / / if the base is an interface , the implementation may come from a default implementation on a derived <nl> + / / interface . so look at interfaces too . <nl> + if ( base ! = null & & modifier . isinterface ( base . getmodifiers ( ) ) ) { <nl> + for ( class < ? > iface : clazz . getinterfaces ( ) ) { <nl> + if ( base . equals ( iface ) | | ! base . isassignablefrom ( iface ) ) { <nl> + continue ; <nl> + } <nl> + final method defaultimpl = util . getmethod ( iface , base , methodname , types ) ; <nl> + if ( defaultimpl ! = null ) { <nl> + return defaultimpl ; <nl> + } <nl> + } <nl> + } <nl> / / method not found in clazz , let ' s search in superclasses <nl> class < ? > superclass = clazz . getsuperclass ( ) ; <nl> - <nl> - / / which provides a default implementation . such a case is not currently detected as an override . <nl> if ( superclass ! = null ) { <nl> - / / if the superclass doesn ' t derive from base anymore , stop looking <nl> - if ( base ! = null & & ! base . isassignablefrom ( superclass ) ) { <nl> + / / if the superclass doesn ' t derive from base anymore ( or is base ) , stop looking <nl> + if ( base ! = null & & ( base . equals ( superclass ) | | ! base . isassignablefrom ( superclass ) ) ) { <nl> return null ; <nl> } <nl> return getmethod ( superclass , base , methodname , types ) ; <nl> mmm a / core / src / test / java / hudson / util / isoverriddentest . java <nl> ppp b / core / src / test / java / hudson / util / isoverriddentest . java <nl>
public class isoverriddentest { <nl> errors . checksucceeds ( ( ) - > { assertthat ( " i1 does not override i1 . bar " , util . isoverridden ( i1 . class , i1 . class , " bar " ) , is ( false ) ) ; return null ; } ) ; <nl> errors . checksucceeds ( ( ) - > { assertthat ( " i2 overrides i1 . bar " , util . isoverridden ( i1 . class , i2 . class , " bar " ) , is ( true ) ) ; return null ; } ) ; <nl> errors . checksucceeds ( ( ) - > { assertthat ( " c1 does not override i1 . bar " , util . isoverridden ( i1 . class , c1 . class , " bar " ) , is ( false ) ) ; return null ; } ) ; <nl> - <nl> - / / errors . checksucceeds ( ( ) - > { assertthat ( " c2 overrides i1 . bar ( via i2 ) " , util . isoverridden ( i1 . class , c2 . class , " bar " ) , is ( true ) ) ; return null ; } ) ; <nl> - / / errors . checksucceeds ( ( ) - > { assertthat ( " c3 overrides i1 . bar ( via i2 ) " , util . isoverridden ( i1 . class , c3 . class , " bar " ) , is ( true ) ) ; return null ; } ) ; <nl> + errors . checksucceeds ( ( ) - > { assertthat ( " c2 overrides i1 . bar ( via i2 ) " , util . isoverridden ( i1 . class , c2 . class , " bar " ) , is ( true ) ) ; return null ; } ) ; <nl> + errors . checksucceeds ( ( ) - > { assertthat ( " c3 overrides i1 . bar ( via i2 ) " , util . isoverridden ( i1 . class , c3 . class , " bar " ) , is ( true ) ) ; return null ; } ) ; <nl> errors . checksucceeds ( ( ) - > { assertthat ( " c4 overrides i1 . bar " , util . isoverridden ( i1 . class , c4 . class , " bar " ) , is ( true ) ) ; return null ; } ) ; <nl> } <nl> private interface i1 {
public class functions { <nl> * / <nl> @ deprecated <nl> @ restricted ( donotuse . class ) <nl> - @ restrictedsince ( " since <nl> + @ restrictedsince ( " 2 . 173 " ) <nl> public static string toccstatus ( item i ) { <nl> return " unknown " ; <nl> } <nl> mmm a / core / src / main / java / jenkins / util / xml / xmlutils . java <nl> ppp b / core / src / main / java / jenkins / util / xml / xmlutils . java <nl>
<nl> - / * <nl> - * the mit license <nl> - * <nl> - * copyright ( c ) num - 2017 , cloudbees , inc . <nl> - * <nl> - * permission is hereby granted , free of charge , to any person obtaining a copy <nl> - * of this software and associated documentation files ( the " software " ) , to deal <nl> - * in the software without restriction , including without limitation the rights <nl> - * to use , copy , modify , merge , publish , distribute , sublicense , and / or sell <nl> - * copies of the software , and to permit persons to whom the software is <nl> - * furnished to do so , subject to the following conditions : <nl> - * <nl> - * the above copyright notice and this permission notice shall be included in <nl> - * all copies or substantial portions of the software . <nl> - * <nl> - * the software is provided " as is " , without warranty of any kind , express or <nl> - * implied , including but not limited to the warranties of merchantability , <nl> - * fitness for a particular purpose and noninfringement . in no event shall the <nl> - * authors or copyright holders be liable for any claim , damages or other <nl> - * liability , whether in an action of contract , tort or otherwise , arising from , <nl> - * out of or in connection with the software or the use or other dealings in <nl> - * the software . <nl> - * / <nl> - package hudson . console ; <nl> - <nl> - import hudson . extension ; <nl> - import hudson . markuptext ; <nl> - import org . jenkinsci . symbol ; <nl> - <nl> - <nl> - / / consider providing alternate search mechanisms ( jira , grepcode , etc . ) as proposed in <nl> - / / https : / / github . com / jenkinsci / jenkins / pull / 2808 # pullrequestreview - 27467560 ( jenkins - 43612 ) <nl> - / * * <nl> - * placed on the beginning of the exception stack trace produced by jenkins , <nl> - * which in turn produces hyperlinked stack trace . <nl> - * <nl> - * < p > <nl> - * exceptions in the user code ( like junit etc ) should be handled differently . this is only for exceptions <nl> - * that occur inside jenkins . <nl> - * <nl> - * @ author kohsuke kawaguchi <nl> - * @ since num . 349 - produces search hyperlinks to the http : / / stacktrace . jenkins - ci . org service <nl> - * @ since num . 56 - does nothing due to jenkins - 42861 <nl> - * @ deprecated this consolenote used to provide hyperlinks to the <nl> - * { @ code http : / / stacktrace . jenkins - ci . org / } service , which is dead now ( jenkins - 42861 ) . <nl> - * this console note does nothing right now . <nl> - * / <nl> - @ deprecated <nl> - public class hudsonexceptionnote extends consolenote < object > { <nl> - <nl> - @ override <nl> - public consoleannotator annotate ( object context , markuptext text , int charpos ) { <nl> - <nl> - return null ; <nl> - } <nl> - <nl> - @ extension @ symbol ( " stacktrace " ) <nl> - public static final class descriptorimpl extends consoleannotationdescriptor { <nl> - @ override <nl> - public string getdisplayname ( ) { <nl> - return " exception stack trace " ; <nl> - } <nl> - } <nl> - }
<nl>  <nl> label { <nl> position : relative ; <nl> - <nl> padding - bottom : num px ; <nl> } <nl> }
the software . <nl> - - > <nl> < groupid > org . jenkins - ci < / groupid > <nl> < artifactid > winstone < / artifactid > <nl> - < version > 5 . 8 - rc518 . e237e80782ab < / version > < ! - - <nl> + < version > 5 . 8 < / version > <nl> < scope > test < / scope > <nl> < / dependency > <nl> < dependency >
<nl> - <nl> - const jstest = require ( " @ jenkins - cd / js - test " ) ; <nl> - <nl> / / mock the behaviors stuff . <nl> var behaviorshim = require ( ' . . / . . / . . / . . / main / js / util / behavior - shim ' ) ; <nl> behaviorshim . specify = function ( selector , id , priority , behavior ) {
jobs : <nl> uses : jenkinsci / jenkins - core - changelog - generator @ master <nl> env : <nl> github_auth : github - actions : $ { { secrets . github_token } } <nl> - # <nl> - # https : / / github . com / jenkinsci / jenkins / releases / tag / untagged - e3a154d27f5bd99802eb <nl> - - name : upload changelog yaml to the release draft ( untagged - e3a154d27f5bd99802eb ) <nl> - uses : svenstaro / upload - release - action @ v1 - release <nl> - with : <nl> - repo_token : $ { { secrets . github_token } } <nl> - file : changelog . yaml <nl> - asset_name : changelog . yaml <nl> - tag : untagged - e3a154d27f5bd99802eb <nl> - overwrite : true
def failfast = false <nl>  <nl> properties ( [ builddiscarder ( logrotator ( numtokeepstr : ' 50 ' , artifactnumtokeepstr : ' 3 ' ) ) , durabilityhint ( ' performance_optimized ' ) ] ) <nl>  <nl> - <nl> - def buildtypes = [ ' linux ' ] <nl> + def buildtypes = [ ' linux ' , ' windows ' ] <nl> def jdks = [ 8 , num ] <nl>  <nl> def builds = [ : ] <nl>
public abstract class runlistener < r extends run > implements extensionpoint { <nl> * fires the { @ link # onfinalized ( run ) } event . <nl> * / <nl> public static void firefinalized ( run r ) { <nl> - if ( jenkins . getinstanceornull ( ) = = null ) { <nl> + if ( ! functions . isextensionsavailable ( ) ) { <nl> return ; <nl> } <nl> for ( runlistener l : all ( ) ) {
public class jnlpaccesswithsecuredhudsontest { <nl> cmds ( javaenvutils . getjreexecutable ( " java " ) , " - jar " , slavejar . getabsolutepath ( ) , " - jnlpurl " , r . geturl ( ) + " computer / test / slave - agent . jnlp " , " - secret " , secret ) . <nl> start ( ) ; <nl> try { <nl> - while ( ! slave . tocomputer ( ) . isonline ( ) ) { <nl> - thread . sleep ( 100 ) ; <nl> - } <nl> + r . waitonline ( slave ) ; <nl> channel channel = slave . getcomputer ( ) . getchannel ( ) ; <nl> assertfalse ( " security - 206 " , channel . isremoteclassloadingallowed ( ) ) ; <nl> r . jenkins . getextensionlist ( adminwhitelistrule . class ) . get ( adminwhitelistrule . class ) . setmasterkillswitch ( false ) ;
categories : <nl> label : bug <nl> - title : localization <nl> label : localization <nl> - # <nl> - - title : internal / developer changes <nl> + - title : developer - facing changes ( apis , extensions , etc . ) <nl> + label : developer <nl> + - title : internal changes <nl> label : internal <nl>  <nl> replacers :
public class rsstest { <nl> @ rule <nl> public jenkinsrule j = new jenkinsrule ( ) ; <nl>  <nl> - <nl> - / / seems the xml parser on the ci machine is different / more picky than the one on my machine , will be covered by jenkins - 59231 to improve the code coverage <nl> @ test <nl> - @ ignore ( " xml parser too picky on ci " ) <nl> @ issue ( " jenkins - 59167 " ) <nl> public void absoluteurlspresentinrss_evenwithoutrooturlsetup ( ) throws exception { <nl> xmlpage page = getrsspage ( ) ; <nl>
public class rsstest { <nl> } <nl> } <nl>  <nl> - <nl> - / / seems the xml parser on the ci machine is different / more picky than the one on my machine , will be covered by jenkins - 59231 to improve the code coverage <nl> @ test <nl> - @ ignore ( " xml parser too picky on ci " ) <nl> @ issue ( " jenkins - 59167 " ) <nl> public void absoluteurlspresentinatom_evenwithoutrooturlsetup ( ) throws exception { <nl> xmlpage page = getatompage ( ) ;
public class rsstest { <nl> @ rule <nl> public jenkinsrule j = new jenkinsrule ( ) ; <nl>  <nl> - <nl> - / / seems the xml parser on the ci machine is different / more picky than the one on my machine , will be covered by jenkins - 59231 to improve the code coverage <nl> @ test <nl> - @ ignore ( " xml parser too picky on ci " ) <nl> @ issue ( " jenkins - 59167 " ) <nl> public void absoluteurlspresentinrss_evenwithoutrooturlsetup ( ) throws exception { <nl> xmlpage page = getrsspage ( ) ; <nl>
public class rsstest { <nl> } <nl> } <nl>  <nl> - <nl> - / / seems the xml parser on the ci machine is different / more picky than the one on my machine , will be covered by jenkins - 59231 to improve the code coverage <nl> @ test <nl> - @ ignore ( " xml parser too picky on ci " ) <nl> @ issue ( " jenkins - 59167 " ) <nl> public void absoluteurlspresentinatom_evenwithoutrooturlsetup ( ) throws exception { <nl> xmlpage page = getatompage ( ) ;
name - template : $ next_patch_version <nl> version - template : $ major . $ minor <nl> tag - template : jenkins - $ next_minor_version <nl>  <nl> - # <nl> exclude - labels : <nl> - reverted <nl> - no - changelog <nl>
<nl> < artifactid > slf4j - jdk14 < / artifactid > <nl> < optional > true < / optional > < ! - - ditto - - > <nl> < / dependency > <nl> - < dependency > < ! - - <nl> - < groupid > org . jenkins - ci < / groupid > <nl> - < artifactid > trilead - ssh2 < / artifactid > <nl> - < version > build214 - jenkins - 1 < / version > <nl> - < / dependency > <nl> < dependency > <nl> < groupid > com . github . spotbugs < / groupid > <nl> < artifactid > spotbugs - annotations < / artifactid > <nl> mmm a / core / pom . xml <nl> ppp b / core / pom . xml <nl>
import java . util . objects ; <nl> * @ see hudson . security . authenticationprocessingfilter2 for the addition of seed inside the session <nl> * @ see hudson . security . httpsessioncontextintegrationfilter2 for the seed check from the session before using it <nl> * / <nl> - <nl> - @ restricted ( noexternaluse . class ) <nl> public class userseedproperty extends userproperty { <nl> / * * <nl> * escape hatch for user seed based revocation feature .
<nl> - package hudson . model . hudson <nl> - <nl> - l = namespace ( lib . layouttaglib ) <nl> - t = namespace ( lib . jenkinstaglib ) <nl> - st = namespace ( " jelly : stapler " ) <nl> - <nl> - def feature ( string icon , string href , string title , closure body = null ) { <nl> - t . summary ( icon : icon , href : href , icononly : true ) { <nl> - div ( class : " link " ) { <nl> - a ( href : href , title ) <nl> - } <nl> - div ( style : " color : gray ; text - decoration : none ; " , body ) <nl> - } <nl> - } <nl> - <nl> - l . layout ( title : _ ( " manage jenkins " ) , permission : app . administer ) { <nl> - <nl> - st . include ( page : " sidepanel " ) <nl> - l . main_panel { <nl> - h1 ( _ ( " manage jenkins " ) ) <nl> - <nl> - if ( my . ischeckuriencodingenabled ( ) ) { <nl> - script " " " <nl> - var url = ' checkuriencoding ' ; <nl> - var params = ' value = \ u57f7 \ u4e8b ' ; <nl> - var checkajax = new ajax . updater ( <nl> - ' message ' , url , <nl> - { <nl> - method : ' get ' , parameters : params <nl> - } <nl> - ) ; <nl> - " " " <nl> - span ( id : " message " ) <nl> - } <nl> - <nl> - app . administrativemonitors . each { am - > <nl> - if ( am . isactivated ( ) & & am . isenabled ( ) ) <nl> - st . include ( it : am , page : " message " ) <nl> - } <nl> - <nl> - st . include ( page : " downgrade " ) <nl> - <nl> - table ( style : " padding - left : num em ; " , id : " management - links " ) { <nl> - feature ( " setting . gif " , " configure " , _ ( " configure system " ) ) { <nl> - raw ( _ ( " configure global settings and paths . " ) ) <nl> - } <nl> - <nl> - <nl> - app . managementlinks . each { m - > <nl> - if ( m . iconfilename = = null ) return ; <nl> - feature ( m . iconfilename , m . urlname , m . displayname ) { <nl> - raw ( m . description ) <nl> - } <nl> - } <nl> - <nl> - if ( app . quietingdown ) { <nl> - feature ( " system - log - out . gif " , " cancelquietdown " , _ ( " cancel shutdown " ) ) <nl> - } else { <nl> - feature ( " system - log - out . gif " , " quietdown " , _ ( " prepare for shutdown " ) ) { <nl> - raw ( _ ( " stops executing new builds , so that the system can be eventually shut down safely . " ) ) <nl> - } <nl> - } <nl> - } <nl> - } <nl> - } <nl> \ no newline at end of file
public class argumentlistbuilder2test { <nl> args . addmasked ( " - version " ) ; <nl>  <nl> slave s = j . createonlineslave ( ) ; <nl> - / * <nl> - j . showslavelogs ( s , logging ) ; <nl> - * / <nl> + j . showagentlogs ( s , logging ) ; <nl>  <nl> stringwriter out = new stringwriter ( ) ; <nl> assertequals ( 0 , s . createlauncher ( new streamtasklistener ( out ) ) . launch ( ) . cmds ( args ) . join ( ) ) ;
public final class tcpslaveagentlistener extends thread { <nl> private void respondhello ( string header , socket s ) throws ioexception { <nl> try { <nl> writer o = new outputstreamwriter ( s . getoutputstream ( ) , standardcharsets . utf_8 ) ; <nl> - <nl> - <nl> + <nl> if ( header . startswith ( " get / " ) ) { <nl> o . write ( " http / 1 . 0 num ok \ r\n " ) ; <nl> o . write ( " content - type : text / plain ; charset = utf - 8 \ r\n " ) ;
the software . <nl> < dependency > <nl> < groupid > org . jenkins - ci . modules < / groupid > <nl> < artifactid > ssh - cli - auth < / artifactid > <nl> - < version > 1 . 5 - 20190205 . 173740 - 1 < / version > < ! - - <nl> + < version > 1 . 5 < / version > <nl> < / dependency > <nl> < dependency > <nl> < groupid > org . jenkins - ci . modules < / groupid >
public class updatecenter extends abstractmodelobject implements saveable , onmas <nl> if ( ucoverride ! = null ) { <nl> logger . log ( level . info , " using a custom update center defined by the system property : { 0 } " , ucoverride ) ; <nl> update_center_url = ucoverride ; <nl> - } else if ( javautils . isrunningwithjava8orbelow ( ) ) { <nl> - update_center_url = " https : / / updates . jenkins . io / " ; <nl> } else { <nl> - <nl> - string experimentaljava11uc = " https : / / updates . jenkins . io / temporary - experimental - java11 / " ; <nl> - logger . log ( level . warning , " running jenkins with java { 0 } which is available in the preview mode only . " + <nl> - " a custom experimental update center will be used : { 1 } " , <nl> - new object [ ] { system . getproperty ( " java . specification . version " ) , experimentaljava11uc } ) ; <nl> - update_center_url = experimentaljava11uc ; <nl> + update_center_url = " https : / / updates . jenkins . io / " ; <nl> } <nl> }
public final class filepath implements serializable { <nl> / / in case this folder / file will be copied somewhere else , <nl> / / it becomes the responsibility of that system to check the isdescendant with the existing links <nl> / / we are not taking the parentrealpath to avoid possible problem <nl> - try { <nl> - path child = currentfileabsolutepath . normalize ( ) ; <nl> - path parent = parentabsolutepath . normalize ( ) ; <nl> - return child . startswith ( parent ) ; <nl> - } catch ( invalidpathexception e2 ) { <nl> - throw new ioexception ( e2 ) ; <nl> - } <nl> + path child = currentfileabsolutepath . normalize ( ) ; <nl> + path parent = parentabsolutepath . normalize ( ) ; <nl> + return child . startswith ( parent ) ; <nl> } <nl> }
public class pluginwrapper implements comparable < pluginwrapper > , modelobject { <nl>  <nl> string minimumjavaversion = getminimumjavaversion ( ) ; <nl> if ( minimumjavaversion ! = null ) { <nl> - <nl> - versionnumber actualversion = new versionnumber ( system . getproperty ( " java . specification . version " ) ) ; <nl> + versionnumber actualversion = javautils . getcurrentjavaruntimeversionnumber ( ) ; <nl> if ( actualversion . isolderthan ( new versionnumber ( minimumjavaversion ) ) ) { <nl> versiondependencyerror ( messages . pluginwrapper_obsoletejava ( actualversion . tostring ( ) , minimumjavaversion ) , actualversion . tostring ( ) , minimumjavaversion ) ; <nl> } <nl> mmm a / core / src / main / java / hudson / model / updatesite . java <nl> ppp b / core / src / main / java / hudson / model / updatesite . java <nl>
import static org . hamcrest . matchers . notnullvalue ; <nl> import static org . junit . assert . * ; <nl> import org . junit . ignore ; <nl>  <nl> - @ ignore ( " <nl> public class disableplugincommandtest { <nl>  <nl> @ rule <nl>
public class staplerdispatches extends telemetry { <nl>  <nl> @ override <nl> protected void record ( staplerrequest staplerrequest , string s ) { <nl> - if ( usagestatistics . disabled | | ! jenkins . get ( ) . isusagestatisticscollected ( ) ) { <nl> - <nl> + if ( telemetry . isdisabled ( ) ) { <nl> / / do not collect traces while usage statistics are disabled <nl> return ; <nl> }
public abstract class pluginmanager extends abstractmodelobject implements onmas <nl> if ( toinstall . isfornewerhudson ( ) ) { <nl> logger . log ( warning , " { 0 } @ { 1 } was built for a newer jenkins " , new object [ ] { toinstall . name , toinstall . version } ) ; <nl> } <nl> - <nl> + if ( toinstall . isfornewerjava ( ) ) { <nl> + logger . log ( warning , " { 0 } @ { 1 } was built for a newer java " , new object [ ] { toinstall . name , toinstall . version } ) ; <nl> + } <nl> jobs . add ( toinstall . deploy ( true ) ) ; <nl> } else if ( pw . isolderthan ( requestedplugin . getvalue ( ) ) ) { / / upgrade <nl> updatesite . plugin toinstall = uc . getplugin ( requestedplugin . getkey ( ) ) ; <nl>
public abstract class pluginmanager extends abstractmodelobject implements onmas <nl> if ( toinstall . isfornewerhudson ( ) ) { <nl> logger . log ( warning , " { 0 } @ { 1 } was built for a newer jenkins " , new object [ ] { toinstall . name , toinstall . version } ) ; <nl> } <nl> - <nl> + if ( toinstall . isfornewerjava ( ) ) { <nl> + logger . log ( warning , " { 0 } @ { 1 } was built for a newer java " , new object [ ] { toinstall . name , toinstall . version } ) ; <nl> + } <nl> if ( ! toinstall . iscompatiblewithinstalledversion ( ) ) { <nl> logger . log ( warning , " { 0 } @ { 1 } is incompatible with the installed @ { 2 } " , new object [ ] { toinstall . name , toinstall . version , pw . getversion ( ) } ) ; <nl> } <nl> mmm a / core / src / main / java / jenkins / install / setupwizard . java <nl> ppp b / core / src / main / java / jenkins / install / setupwizard . java <nl>
public class apitokenstore { <nl> this . init ( ) ; <nl> } <nl>  <nl> - <nl> - @ suppressfbwarnings ( " se_read_resolve_must_return_object " ) <nl> - private apitokenstore readresolve ( ) { <nl> + private object readresolve ( ) { <nl> this . init ( ) ; <nl> return this ; <nl> } <nl>
public class apitokenstore { <nl> this . init ( ) ; <nl> } <nl>  <nl> - <nl> - @ suppressfbwarnings ( " se_read_resolve_must_return_object " ) <nl> - private hashedtoken readresolve ( ) { <nl> + private object readresolve ( ) { <nl> this . init ( ) ; <nl> return this ; <nl> }
public class jnlplauncher extends computerlauncher { <nl> public final string vmargs ; <nl>  <nl> @ nonnull <nl> - private remotingworkdirsettings workdirsettings ; <nl> + private remotingworkdirsettings workdirsettings = remotingworkdirsettings . getenableddefaults ( ) ; <nl> + <nl> + / * * <nl> + * constructor . <nl> + * @ param tunnel tunnel settings <nl> + * @ param vmargs jvm arguments <nl> + * @ param workdirsettings settings for work directory management in remoting . <nl> + * if { @ code null } , { @ link remotingworkdirsettings # getenableddefaults ( ) } <nl> + * will be used to enable work directories by default in new agents . <nl> + * @ since num . 68 <nl> + * / <nl> + @ deprecated <nl> + public jnlplauncher ( @ checkfornull string tunnel , @ checkfornull string vmargs , @ checkfornull remotingworkdirsettings workdirsettings ) { <nl> + this ( tunnel , vmargs ) ; <nl> + if ( workdirsettings ! = null ) { <nl> + setworkdirsettings ( workdirsettings ) ; <nl> + } <nl> + } <nl>  <nl> @ databoundconstructor <nl> - public jnlplauncher ( @ checkfornull string tunnel , @ checkfornull string vmargs , @ checkfornull remotingworkdirsettings workdirsettings ) { <nl> + public jnlplauncher ( @ checkfornull string tunnel , @ checkfornull string vmargs ) { <nl> this . tunnel = util . fixemptyandtrim ( tunnel ) ; <nl> this . vmargs = util . fixemptyandtrim ( vmargs ) ; <nl> - this . workdirsettings = workdirsettings ; <nl> - } <nl> - <nl> - @ deprecated <nl> - public jnlplauncher ( string tunnel , string vmargs ) { <nl> - <nl> - / / will need to enable the feature by default as well . <nl> - / / https : / / github . com / search ? q = org % 3ajenkinsci + % 22extends + jnlplauncher % 22 & type = code <nl> - this ( tunnel , vmargs , remotingworkdirsettings . getdisableddefaults ( ) ) ; <nl> } <nl>  <nl> / * * <nl>
the software . <nl> < parent > <nl> < groupid > org . jenkins - ci < / groupid > <nl> < artifactid > jenkins < / artifactid > <nl> - < version > 1 . 48 - 20180730 . 183534 - 1 < / version > < ! - - <nl> + < version > 1 . 48 < / version > <nl> < relativepath / > <nl> < / parent >
public class jnlplauncher extends computerlauncher { <nl> * will be used to enable work directories by default in new agents . <nl> * @ since num . 68 <nl> * / <nl> - @ databoundconstructor <nl> + @ deprecated <nl> public jnlplauncher ( @ checkfornull string tunnel , @ checkfornull string vmargs , @ checkfornull remotingworkdirsettings workdirsettings ) { <nl> - this . tunnel = util . fixemptyandtrim ( tunnel ) ; <nl> - this . vmargs = util . fixemptyandtrim ( vmargs ) ; <nl> - this . workdirsettings = workdirsettings ! = null ? workdirsettings : <nl> - remotingworkdirsettings . getenableddefaults ( ) ; <nl> + this ( tunnel , vmargs ) ; <nl> + if ( workdirsettings ! = null ) { <nl> + setworkdirsettings ( workdirsettings ) ; <nl> + } <nl> } <nl>  <nl> - @ deprecated <nl> - public jnlplauncher ( string tunnel , string vmargs ) { <nl> - <nl> - / / will need to enable the feature by default as well . <nl> - / / https : / / github . com / search ? q = org % 3ajenkinsci + % 22extends + jnlplauncher % 22 & type = code <nl> - this ( tunnel , vmargs , remotingworkdirsettings . getdisableddefaults ( ) ) ; <nl> + @ databoundconstructor <nl> + public jnlplauncher ( @ checkfornull string tunnel , @ checkfornull string vmargs ) { <nl> + this . tunnel = util . fixemptyandtrim ( tunnel ) ; <nl> + this . vmargs = util . fixemptyandtrim ( vmargs ) ; <nl> } <nl>  <nl> / * * <nl>
the software . <nl> < parent > <nl> < groupid > org . jenkins - ci < / groupid > <nl> < artifactid > jenkins < / artifactid > <nl> - < version > 1 . 46 - 20180514 . 183442 - 1 < / version > < ! - - <nl> + < version > 1 . 46 < / version > <nl> < relativepath / > <nl> < / parent >
the software . <nl> < matrix - project . version > 1 . 4 . 1 < / matrix - project . version > <nl> < sorcerer . version > 0 . 11 < / sorcerer . version > <nl> < animal . sniffer . skip > $ { skiptests } < / animal . sniffer . skip > <nl> - < access - modifier . version > 1 . 14 - snapshot < / access - modifier . version > < ! - - <nl> - < ! - - after release , would just be $ { access - modifier . version } : - - > <nl> - < access - modifier - annotation . version > 1 . 14 - 20180326 . 221427 - 2 < / access - modifier - annotation . version > <nl> - < access - modifier - checker . version > 1 . 14 - 20180326 . 221430 - 2 < / access - modifier - checker . version > <nl> + < access - modifier . version > 1 . 14 < / access - modifier . version > <nl> + < access - modifier - annotation . version > $ { access - modifier . version } < / access - modifier - annotation . version > < ! - - differing only where needed for timestamped snapshots - - > <nl> + < access - modifier - checker . version > $ { access - modifier . version } < / access - modifier - checker . version > <nl>  <nl> < java . level > 8 < / java . level >
the software . <nl> < stapler . version > 1 . 254 < / stapler . version > <nl> < spring . version > 2 . 5 . 6 . sec03 < / spring . version > <nl> < groovy . version > 2 . 4 . 11 < / groovy . version > <nl> - < ! - - <nl> - < findbugs . failonerror > true < / findbugs . failonerror > <nl> < / properties > <nl>  <nl> < dependencies > <nl>
the software . <nl> < maven - war - plugin . version > 3 . 0 . 0 < / maven - war - plugin . version > < ! - - jenkins - 47127 bump when num . 2 . 0 is out . cf . mwar - 407 - - > <nl>  <nl> < ! - - minimum remoting version , which is tested for api compatibility - - > <nl> - < remoting . version > 3 . 18 - 20180307 . 194815 - 1 < / remoting . version > < ! - - <nl> + < remoting . version > 3 . 18 < / remoting . version > <nl> < remoting . minimum . supported . version > 2 . 60 < / remoting . minimum . supported . version > <nl>  <nl> < findbugs . effort > max < / findbugs . effort >
public abstract class cause { <nl>  <nl> @ override <nl> public void print ( tasklistener listener ) { <nl> - listener . getlogger ( ) . println ( messages . cause_useridcause_shortdescription ( <nl> - <nl> - modelhyperlinknote . encodeto ( " / user / " + getuseridorunknown ( ) , getusername ( ) ) ) ) ; <nl> + user user = getuserid ( ) = = null ? null : user . getbyid ( getuserid ( ) , false ) ; <nl> + if ( user ! = null ) { <nl> + listener . getlogger ( ) . println ( messages . cause_useridcause_shortdescription ( <nl> + modelhyperlinknote . encodeto ( user ) ) ) ; <nl> + } else { <nl> + listener . getlogger ( ) . println ( messages . cause_useridcause_shortdescription ( <nl> + " unknown or anonymous " ) ) ; <nl> + } <nl> } <nl>  <nl> @ override <nl> mmm a / test / src / test / java / hudson / model / causetest . java <nl> ppp b / test / src / test / java / hudson / model / causetest . java <nl>
public class apitokenpropertytest { <nl>  <nl> @ nonnull <nl> private webclient createclientforuser ( final string id ) throws exception { <nl> - user u = user . getbyid ( id , false ) ; <nl> - <nl> - <nl> - / / final apitokenproperty t = u . getproperty ( apitokenproperty . class ) ; <nl> - / / / / yes , we use the insecure call in the test stuff <nl> - / / final string token = t . getapitokeninsecure ( ) ; <nl> + user u = user . getbyid ( id , true ) ; <nl>  <nl> + final apitokenproperty t = u . getproperty ( apitokenproperty . class ) ; <nl> + / / yes , we use the insecure call in the test stuff <nl> + final string token = t . getapitokeninsecure ( ) ; <nl>  <nl> webclient wc = j . createwebclient ( ) ; <nl> - / / wc . addrequestheader ( " authorization " , " basic " + scrambler . scramble ( id + " : " + token ) ) ; <nl> + wc . addrequestheader ( " authorization " , " basic " + scrambler . scramble ( id + " : " + token ) ) ; <nl> return wc ; <nl> }
public class xmlfiletest { <nl> assertthat ( n . getmode ( ) . tostring ( ) , is ( " normal " ) ) ; <nl> } <nl> } <nl> - <nl> - @ test <nl> - @ ignore <nl> - <nl> - public void xml1_0configmigrateto1_1test ( ) throws ioexception { <nl> - url configurl = getclass ( ) . getresource ( " / hudson / config_1_0 . xml " ) ; <nl> - file configfile = new file ( configurl . getfile ( ) ) ; <nl> - xstream2 xs = new xstream2 ( ) ; <nl> - xs . alias ( " hudson " , jenkins . class ) ; <nl> - <nl> - xmlfile xmlfile = new xmlfile ( xs , configfile ) ; <nl> - if ( xmlfile . exists ( ) ) { <nl> - node n = ( node ) xmlfile . read ( ) ; <nl> - assertthat ( n . getnumexecutors ( ) , is ( 2 ) ) ; <nl> - assertthat ( n . getmode ( ) . tostring ( ) , is ( " normal " ) ) ; <nl> - / / this fails , because configfile . getparent ( ) returns null . . . . how do i fix ? <nl> - n . save ( ) ; <nl> - / / now verify that the node is showing < ? xml version = ' 1 . 1 ' > tag <nl> - } <nl> - <nl> - } <nl> - <nl> + <nl> @ test <nl> public void canreadxmlwithcontrolcharstest ( ) throws ioexception { <nl> url configurl = getclass ( ) . getresource ( " / hudson / confg_1_1_with_special_chars . xml " ) ; <nl> mmm a / test / src / test / java / hudson / xmlfiletest . java <nl> ppp b / test / src / test / java / hudson / xmlfiletest . java <nl>
the software . <nl> < maven - war - plugin . version > 3 . 0 . 0 < / maven - war - plugin . version > < ! - - jenkins - 47127 bump when num . 2 . 0 is out . cf . mwar - 407 - - > <nl>  <nl> < ! - - minimum remoting version , which is tested for api compatibility - - > <nl> - < remoting . version > 3 . 16 - 20180109 . 195120 - 6 < / remoting . version > < ! - - <nl> + < remoting . version > 3 . 16 < / remoting . version > <nl> < remoting . minimum . supported . version > 2 . 60 < / remoting . minimum . supported . version > <nl>  <nl> < / properties >
the software . <nl> < dependency > <nl> < groupid > $ { project . groupid } < / groupid > <nl> < artifactid > jenkins - test - harness < / artifactid > <nl> - < version > 2 . 32 - 20171030 . 181811 - 1 < / version > < ! - - <nl> + < version > 2 . 32 < / version > <nl> < scope > test < / scope > <nl> < exclusions > <nl> < exclusion >
public class classicpluginstrategy implements pluginstrategy { <nl> new detachedplugin ( " matrix - project " , " 1 . 561 . * " , " 1 . 0 " ) , <nl> new detachedplugin ( " junit " , " 1 . 577 . * " , " 1 . 0 " ) , <nl> new detachedplugin ( " bouncycastle - api " , " 2 . 16 . * " , " 2 . 16 . 0 " ) , <nl> - new detachedplugin ( " command - launcher " , " 2 . 86 . * " , " 1 . 0 - snapshot " ) <nl> + new detachedplugin ( " command - launcher " , " 2 . 86 . * " , " 1 . 0 " ) <nl> ) ) ; <nl>  <nl> / * * implicit dependencies that are known to be unnecessary and which must be cut out to prevent a dependency cycle among bundled plugins . * / <nl> mmm a / war / pom . xml <nl> ppp b / war / pom . xml <nl>
the software . <nl> < artifactitem > <nl> < groupid > org . jenkins - ci . plugins < / groupid > <nl> < artifactid > command - launcher < / artifactid > <nl> - < version > 1 . 0 - 20171017 . 180336 - 1 < / version > < ! - - <nl> + < version > 1 . 0 < / version > <nl> < type > hpi < / type > <nl> < / artifactitem > <nl> < / artifactitems >
the software . <nl> < dependency > <nl> < groupid > $ { project . groupid } < / groupid > <nl> < artifactid > jenkins - test - harness < / artifactid > <nl> - < version > 2 . 31 - 20171011 . 213336 - 1 < / version > < ! - - <nl> + < version > 2 . 31 < / version > <nl> < scope > test < / scope > <nl> < exclusions > <nl> < exclusion >
the software . <nl> < groupid > org . jenkins - ci . plugins < / groupid > <nl> < artifactid > matrix - project < / artifactid > <nl> < version > $ { matrix - project . version } < / version > <nl> - < exclusions > <nl> - < exclusion > < ! - - <nl> - < groupid > org . jenkins - ci . plugins < / groupid > <nl> - < artifactid > script - security < / artifactid > <nl> - < / exclusion > <nl> - < / exclusions > <nl> < / dependency > <nl> < dependency > <nl> < groupid > org . jenkins - ci . plugins < / groupid > <nl>
the software . <nl> < version > 1 . 2 < / version > <nl> < scope > test < / scope > <nl> < / dependency > <nl> - < dependency > < ! - - <nl> - < groupid > org . jenkins - ci . plugins < / groupid > <nl> - < artifactid > command - launcher < / artifactid > <nl> - < version > 1 . 0 - snapshot < / version > <nl> - < scope > test < / scope > <nl> - < / dependency > <nl> < dependency > <nl> < groupid > org . jvnet . mock - javamail < / groupid > <nl> < artifactid > mock - javamail < / artifactid >
public class xstream2 extends xstream { <nl> * @ param clazz a class which we expect to hold a non - { @ code transient } field <nl> * @ param field a field name in that class <nl> * / <nl> - @ restricted ( noexternaluse . class ) <nl> public void addcriticalfield ( class < ? > clazz , string field ) { <nl> reflectionconverter . addcriticalfield ( clazz , field ) ; <nl> }
public class passwordtest extends hudsontestcase implements describable < password <nl> item . extended_read . setenabled ( saveenabled ) ; <nl> } <nl> } <nl> + <nl> + @ issue ( " security - 616 " ) <nl> + public void testcheckmethod ( ) throws exception { <nl> + freestyleproject p = createfreestyleproject ( " p " ) ; <nl> + p . addproperty ( new vulnerableproperty ( secret . fromstring ( " " ) ) ) ; <nl> + htmlpasswordinput field = createwebclient ( ) . getpage ( p , " configure " ) . getformbyname ( " config " ) . getinputbyname ( " _ . secret " ) ; <nl> + while ( vulnerableproperty . descriptorimpl . incomingurl = = null ) { / / waitforbackgroundjavascript does not work well <nl> + thread . sleep ( 100 ) ; / / form validation of saved value <nl> + } <nl> + vulnerableproperty . descriptorimpl . incomingurl = null ; <nl> + string secret = " s3cr3t " ; <nl> + field . settext ( secret ) ; <nl> + while ( vulnerableproperty . descriptorimpl . incomingurl = = null ) { <nl> + thread . sleep ( 100 ) ; / / form validation of edited value <nl> + } <nl> + assertthat ( vulnerableproperty . descriptorimpl . incomingurl , not ( containsstring ( secret ) ) ) ; <nl> + assertequals ( secret , vulnerableproperty . descriptorimpl . checkedsecret ) ; <nl> + } <nl> + <nl> public static class vulnerableproperty extends jobproperty < freestyleproject > { <nl> public final secret secret ; <nl> @ databoundconstructor <nl> public vulnerableproperty ( secret secret ) { <nl> this . secret = secret ; <nl> } <nl> - @ testextension ( " testexposedciphertext " ) <nl> + @ testextension <nl> public static class descriptorimpl extends jobpropertydescriptor { <nl> - @ override <nl> - public string getdisplayname ( ) { <nl> - return " vulnerableproperty " ; <nl> + static string incomingurl ; <nl> + static string checkedsecret ; <nl> + public formvalidation dochecksecret ( @ queryparameter string value ) { <nl> + staplerrequest req = stapler . getcurrentrequest ( ) ; <nl> + incomingurl = req . getrequesturiwithquerystring ( ) ; <nl> + system . err . println ( " processing " + incomingurl + " via " + req . getmethod ( ) + " : " + value ) ; <nl> + checkedsecret = value ; <nl> + return formvalidation . ok ( ) ; <nl> } <nl> } <nl> }
the software . <nl> < dependency > <nl> < groupid > $ { project . groupid } < / groupid > <nl> < artifactid > jenkins - test - harness < / artifactid > <nl> - < version > 2 . 26 - 20170913 . 084530 - 2 < / version > < ! - - <nl> + < version > 2 . 26 < / version > <nl> < scope > test < / scope > <nl> < exclusions > <nl> < exclusion >
public class cliactiontest { <nl> / / - ssh mode does not pass client locale or encoding <nl> } <nl>  <nl> - @ ignore ( " <nl> @ issue ( " jenkins - 41745 " ) <nl> @ test <nl> public void interleavedstdio ( ) throws exception {
the software . <nl> < dependency > <nl> < groupid > $ { project . groupid } < / groupid > <nl> < artifactid > jenkins - test - harness < / artifactid > <nl> - < version > 2 . 24 - 20170801 . 213935 - 3 < / version > < ! - - <nl> + < version > 2 . 24 < / version > <nl> < scope > test < / scope > <nl> < exclusions > <nl> < exclusion >
<nl> < dependency > <nl> < groupid > org . apache . sshd < / groupid > <nl> < artifactid > sshd - core < / artifactid > <nl> - < version > 1 . 2 . 0 < / version > < ! - - <nl> + < version > 1 . 6 . 0 < / version > <nl> < optional > true < / optional > < ! - - do not expose to core - - > <nl> < / dependency > <nl> < dependency > <nl> mmm a / cli / src / main / java / hudson / cli / sshcli . java <nl> ppp b / cli / src / main / java / hudson / cli / sshcli . java <nl>
the software . <nl> < plugin > <nl> < groupid > org . jenkins - ci . tools < / groupid > <nl> < artifactid > maven - hpi - plugin < / artifactid > <nl> - < version > 2 . 0 - 20170524 . 211828 - 1 < / version > < ! - - <nl> + < version > 2 . 0 < / version > <nl> < / plugin > <nl> < plugin > <nl> < groupid > org . apache . maven . plugins < / groupid >
public abstract class scm implements describable < scm > , extensionpoint { <nl> * ( for example , svn revision number . ) <nl> * <nl> * < p > <nl> - * this method is invoked whenever someone does { @ link abstractbuild # getenvironment ( tasklistener ) } , which <nl> + * this method is invoked whenever someone does { @ link run # getenvironment ( tasklistener ) } , which <nl> * can be before / after your checkout method is invoked . so if you are going to provide information about <nl> * check out ( like svn revision number that was checked out ) , be prepared for the possibility that the <nl> * check out hasn ' t happened yet . <nl> * / <nl> - <nl> + public void buildenvvars ( @ nonnull run < ? , ? > build , @ nonnull map < string , string > env ) { <nl> + if ( build instanceof abstractbuild ) { <nl> + buildenvvars ( ( abstractbuild ) build , env ) ; <nl> + } <nl> + } <nl> + <nl> + @ deprecated <nl> public void buildenvvars ( abstractbuild < ? , ? > build , map < string , string > env ) { <nl> + if ( util . isoverridden ( scm . class , getclass ( ) , " buildenvvars " , run . class , map . class ) ) { <nl> + buildenvvars ( ( run ) build , env ) ; <nl> + } <nl> / / default implementation is noop . <nl> }
public class clientauthenticationcachetest { <nl> @ rule <nl> public temporaryfolder tmp = new temporaryfolder ( ) ; <nl>  <nl> - <nl> + @ rule <nl> + public loggerrule logging = new loggerrule ( ) . record ( clientauthenticationcache . class , level . finer ) ; <nl>  <nl> @ issue ( " security - 466 " ) <nl> @ test
public class jenkins extends abstractcibase implements directlymodifiabletopleve <nl> getprimaryview ( ) . dosubmitdescription ( req , rsp ) ; <nl> } <nl>  <nl> - @ requirepost <nl> + @ requirepost <nl> public synchronized httpredirect doquietdown ( ) throws ioexception { <nl> try { <nl> return doquietdown ( false , 0 ) ;
the software . <nl> < dependency > <nl> < groupid > org . jenkins - ci . main < / groupid > <nl> < artifactid > remoting < / artifactid > <nl> - < version > 2 . 53 . 6 - 20170306 . 191805 - 1 < / version > < ! - - <nl> + < version > 2 . 53 . 5 < / version > <nl> < / dependency > <nl>  <nl> < dependency >
public class security218clitest { <nl> probe ( payload . ldap , payloadcaller . exit_code_rejected ) ; <nl> } <nl>  <nl> - @ ignore ( " <nl> @ presetdata ( presetdata . dataset . anonymous_readonly ) <nl> @ test <nl> @ issue ( " security - 429 " )
the software . <nl> < plugin > <nl> < groupid > org . jenkins - ci . tools < / groupid > <nl> < artifactid > maven - hpi - plugin < / artifactid > <nl> - < version > 1 . 122 - 20170411 . 132219 - 2 < / version > < ! - - <nl> + < version > 1 . 122 < / version > <nl> < / plugin > <nl> < plugin > <nl> < groupid > org . apache . maven . plugins < / groupid >
the software . <nl> < dependency > <nl> < groupid > org . jenkins - ci . modules < / groupid > <nl> < artifactid > sshd < / artifactid > <nl> - < version > 1 . 11 - 20170407 . 145808 - 3 < / version > < ! - - <nl> + < version > 1 . 11 < / version > <nl> < / dependency > <nl> < dependency > <nl> < groupid > org . jenkins - ci . ui < / groupid >
public class updatecenter extends abstractmodelobject implements saveable , onmas <nl> / / do this first so we can avoid duplicate downloads , too <nl> / / check to see if the plugin is already installed at the same version and skip it <nl> logger . info ( " skipping duplicate install of : " + plugin . getdisplayname ( ) + " @ " + plugin . version ) ; <nl> - / / throw new skipped ( ) ; <nl> return ; <nl> } <nl> try { <nl> mmm / dev / null <nl> ppp b / core / src / main / resources / hudson / model / updatecenter / downloadjob / skipped / status . jelly <nl>
public abstract class fullduplexhttpservice { <nl>  <nl> / / wait until we are done <nl> while ( ! completed ) { <nl> - wait ( ) ; <nl> + wait ( ) ; <nl> } <nl> }
public class cliaction implements unprotectedrootaction , staplerproxy { <nl> } <nl> @ override <nl> protected void onlocale ( string text ) { <nl> - <nl> + for ( locale _locale : locale . getavailablelocales ( ) ) { <nl> + if ( _locale . tostring ( ) . equals ( text ) ) { <nl> + locale = _locale ; <nl> + return ; <nl> + } <nl> + } <nl> + logger . log ( level . warning , " unknown client locale { 0 } " , text ) ; <nl> } <nl> @ override <nl> protected void onencoding ( string text ) { <nl> mmm a / test / src / test / java / hudson / cli / cliactiontest . java <nl> ppp b / test / src / test / java / hudson / cli / cliactiontest . java <nl>
public class passwordtest extends hudsontestcase implements describable < password <nl> / / just a quick verification on what could be on the page and that the regexp is correctly set up <nl> assertthat ( xml_regex_pattern . matcher ( statictest ) . find ( ) , is ( true ) ) ; <nl>  <nl> - jenkins . setsecurityrealm ( createdummysecurityrealm ( ) ) ; <nl> - <nl> - globalmatrixauthorizationstrategy pmas = new globalmatrixauthorizationstrategy ( ) ; <nl> - pmas . add ( jenkins . administer , " admin " ) ; <nl> - pmas . add ( jenkins . read , " dev " ) ; <nl> - pmas . add ( item . read , " dev " ) ; <nl> - item . extended_read . setenabled ( true ) ; <nl> - pmas . add ( item . extended_read , " dev " ) ; <nl> - pmas . add ( item . create , " dev " ) ; / / so we can show copyjobcommand would barf ; more realistic would be to grant it only in a subfolder <nl> - jenkins . setauthorizationstrategy ( pmas ) ; <nl> + jenkins . setsecurityrealm ( new jenkinsrule ( ) . createdummysecurityrealm ( ) ) ; <nl> + jenkins . setauthorizationstrategy ( new mockauthorizationstrategy ( ) . <nl> + grant ( jenkins . administer ) . everywhere ( ) . to ( " admin " ) . <nl> + grant ( jenkins . read , item . read , item . extended_read , <nl> + item . create / / so we can show copyjobcommand would barf ; more realistic would be to grant it only in a subfolder <nl> + ) . everywhere ( ) . to ( " dev " ) ) ; <nl> secret s = secret . fromstring ( " s3cr3t " ) ; <nl> / / string senc = s . getencryptedvalue ( ) ; <nl> freestyleproject p = createfreestyleproject ( " p " ) ;
<nl> < dependency > <nl> < groupid > org . apache . sshd < / groupid > <nl> < artifactid > sshd - core < / artifactid > <nl> - < version > 1 . 2 . 0 < / version > < ! - - <nl> < optional > true < / optional > < ! - - do not expose to core - - > <nl> < / dependency > <nl> < dependency > <nl> mmm a / pom . xml <nl> ppp b / pom . xml <nl>
properties ( [ [ $ class : ' jenkins . model . builddiscarderproperty ' , strategy : [ $ class : <nl> artifactnumtokeepstr : ' 20 ' ] ] ] ) <nl>  <nl> / / see https : / / github . com / jenkins - infra / documentation / blob / master / ci . adoc for information on what node types are available <nl> - def buildtypes = [ ' linux ' ] <nl> + def buildtypes = [ ' linux ' , ' windows ' ] <nl>  <nl> def builds = [ : ] <nl> for ( i = num ; i < buildtypes . size ( ) ; i + + ) {
public class historypagefilter < t > { <nl> return false ; <nl> } <nl>  <nl> - private boolean fitssearchbuildvariables ( abstractbuild runasbuild ) { <nl> - map buildvariables = runasbuild . getbuildvariables ( ) ; <nl> - <nl> - for ( object paramsvalues : buildvariables . values ( ) ) { <nl> + private boolean fitssearchbuildvariables ( abstractbuild < ? , ? > runasbuild ) { <nl> + map < string , string > buildvariables = runasbuild . getbuildvariables ( ) ; <nl> + for ( string paramsvalues : buildvariables . values ( ) ) { <nl> if ( fitssearchstring ( paramsvalues ) ) { <nl> return true ; <nl> } <nl>
public class historypagefilter < t > { <nl>  <nl> private boolean fitssearchbuildparameters ( parametersaction parametersaction ) { <nl> list < parametervalue > parameters = parametersaction . getparameters ( ) ; <nl> - <nl> for ( parametervalue parameter : parameters ) { <nl> - if ( fitssearchstring ( parameter . getvalue ( ) ) ) { <nl> + if ( ! parameter . issensitive ( ) & & fitssearchstring ( parameter . getvalue ( ) ) ) { <nl> return true ; <nl> } <nl> } <nl> mmm a / core / src / test / java / jenkins / widgets / historypagefiltertest . java <nl> ppp b / core / src / test / java / jenkins / widgets / historypagefiltertest . java <nl>
public abstract class consolenote < t > implements serializable , describable < consol <nl> dataoutputstream dos = new dataoutputstream ( new base64outputstream ( buf2 , true , - 1 , null ) ) ; <nl> try { <nl> buf2 . write ( preamble ) ; <nl> - if ( jenkins . getinstance ( ) ! = null ) { <nl> + if ( jenkins . getinstanceornull ( ) ! = null ) { / / else we are in another jvm and cannot sign ; result will be ignored unless insecure <nl> byte [ ] mac = mac . mac ( buf . tobytearray ( ) ) ; <nl> dos . writeint ( - mac . length ) ; / / negative to differentiate from older form <nl> dos . write ( mac ) ;
public class passwordtest extends hudsontestcase implements describable < password <nl> @ extension <nl> public static final class descriptorimpl extends descriptor < passwordtest > { } <nl>  <nl> - <nl> - @ issue ( " security - 266 , security - 304 " ) <nl> + @ issue ( { " security - 266 " , " security - 304 " } ) <nl> public void testexposedciphertext ( ) throws exception { <nl> boolean saveenabled = item . extended_read . getenabled ( ) ; <nl> try {
public class adminfilepathfiltertest { <nl> rule . setmasterkillswitch ( false ) ; <nl> } <nl>  <nl> - <nl> + @ issue ( { " jenkins - 27055 " , " security - 358 " } ) <nl> @ test <nl> public void matchbuilddir ( ) throws exception { <nl> file builddir = r . buildandassertsuccess ( r . createfreestyleproject ( ) ) . getrootdir ( ) ;
public abstract class consolenote < t > implements serializable , describable < consol <nl> * disables checking of { @ link # mac } so do not set this flag unless you completely trust all users capable of affecting build output , <nl> * which in practice means that all scm committers as well as all jenkins users with any non - read - only access are consider administrators . <nl> * / <nl> - static / * nonfinal for tests & script console * / boolean insecure = boolean . getboolean ( consolenote . class . getname ( ) + " . insecure " ) ; <nl> + static / * nonfinal for tests & script console * / boolean insecure = systemproperties . getboolean ( consolenote . class . getname ( ) + " . insecure " ) ; <nl>  <nl> / * * <nl> * when the line of a console output that this annotation is attached is read by someone ,
public class parameterstest { <nl> htmlformutil . submit ( form , htmlformutil . getbuttonbycaption ( form , " build " ) ) ; <nl> } <nl>  <nl> - @ ignore ( " <nl> @ issue ( " security - 353 " ) <nl> @ test <nl> public void xss ( ) throws exception {
public class functions { <nl> return s . tostring ( ) ; <nl> } <nl> private static void doprintstacktrace ( @ nonnull stringbuilder s , @ nonnull throwable t , @ checkfornull throwable higher , @ nonnull string prefix ) { <nl> - <nl> + if ( util . isoverridden ( throwable . class , t . getclass ( ) , " printstacktrace " , printwriter . class ) ) { <nl> + stringwriter sw = new stringwriter ( ) ; <nl> + t . printstacktrace ( new printwriter ( sw ) ) ; <nl> + s . append ( sw . tostring ( ) ) ; <nl> + return ; <nl> + } <nl> throwable lower = t . getcause ( ) ; <nl> if ( lower ! = null ) { <nl> doprintstacktrace ( s , lower , t , prefix ) ; <nl> mmm a / core / src / test / java / hudson / functionstest . java <nl> ppp b / core / src / test / java / hudson / functionstest . java <nl>
var createpluginsetupwizard = function ( appendtarget ) { <nl> } <nl>  <nl> var showinitialsetupwizard = function ( ) { <nl> - / / check for connectivity <nl> - <nl> - var siteid = ' default ' ; <nl> - jenkins . testconnectivity ( siteid , handlegenericerror ( function ( isconnected , isfatal , errormessage ) { <nl> + / / check for connectivity to the configured default update site <nl> + / * globals defaultupdatesiteid : true * / <nl> + jenkins . testconnectivity ( defaultupdatesiteid , handlegenericerror ( function ( isconnected , isfatal , errormessage ) { <nl> if ( ! isconnected ) { <nl> if ( isfatal ) { / / we cannot continue , show error <nl> setpanel ( errorpanel , { errormessage : ' default update site connectivity check failed with fatal error : ' + errormessage + ' . if you see this issue for the custom jenkins war bundle , consider setting the correct value of the hudson . model . updatecenter . defaultupdatesiteid system property ( requires jenkins restart ) . otherwise please create a bug in jenkins jira . ' } ) ; <nl> mmm a / war / src / test / js / pluginsetupwizard - spec . js <nl> ppp b / war / src / test / js / pluginsetupwizard - spec . js <nl>
<nl> < bug pattern = " dm_default_encoding " / > <nl> < / or > <nl> < / match > <nl> - <nl> - < ! - - exclude medium and low priorities - - > <nl> - < ! - - <nl> - < match > <nl> - < priority value = " 2 " / > <nl> - < / match > <nl> - < match > <nl> - < priority value = " 3 " / > <nl> - < / match > <nl> < / findbugsfilter >
public class classicpluginstrategy implements pluginstrategy { <nl> new detachedplugin ( " antisamy - markup - formatter " , " 1 . 553 . * " , " 1 . 0 " ) , <nl> new detachedplugin ( " matrix - project " , " 1 . 561 . * " , " 1 . 0 " ) , <nl> new detachedplugin ( " junit " , " 1 . 577 . * " , " 1 . 0 " ) , <nl> - new detachedplugin ( " bouncycastle - api " , " 2 . 16 . * " , " 2 . 16 . 0 - 20160725 . 164257 - 1 " ) <nl> + new detachedplugin ( " bouncycastle - api " , " 2 . 16 . * " , " 2 . 16 . 0 " ) <nl> ) ) ; <nl>  <nl> / * * implicit dependencies that are known to be unnecessary and which must be cut out to prevent a dependency cycle among bundled plugins . * / <nl> mmm a / pom . xml <nl> ppp b / pom . xml <nl>
the software . <nl> < enabled > true < / enabled > <nl> < / releases > <nl> < snapshots > <nl> - < enabled > true < / enabled > < ! - - <nl> + < enabled > false < / enabled > <nl> < / snapshots > <nl> < / repository > <nl> < / repositories > <nl> mmm a / war / pom . xml <nl> ppp b / war / pom . xml <nl>
the software . <nl> < artifactitem > <nl> < groupid > org . jenkins - ci . plugins < / groupid > <nl> < artifactid > bouncycastle - api < / artifactid > <nl> - < version > 2 . 16 . 0 - 20160725 . 164257 - 1 < / version > < ! - - <nl> + < version > 2 . 16 . 0 < / version > <nl> < type > hpi < / type > <nl> < / artifactitem > <nl> < / artifactitems >
var createpluginsetupwizard = function ( appendtarget ) { <nl> } <nl>  <nl> var showinitialsetupwizard = function ( ) { <nl> - / / check for connectivity <nl> - <nl> - var siteid = ' default ' ; <nl> - jenkins . testconnectivity ( siteid , handlegenericerror ( function ( isconnected , isfatal , errormessage ) { <nl> + / / check for connectivity to the configured default update site <nl> + / * globals defaultupdatesiteid : true * / <nl> + jenkins . testconnectivity ( defaultupdatesiteid , handlegenericerror ( function ( isconnected , isfatal , errormessage ) { <nl> if ( ! isconnected ) { <nl> if ( isfatal ) { / / we cannot continue , show error <nl> setpanel ( errorpanel , { errormessage : ' default update site connectivity check failed with fatal error : ' + errormessage + ' . if you see this issue for the custom jenkins war bundle , consider setting the correct value of the hudson . model . updatecenter . defaultupdatesiteid system property ( requires jenkins restart ) . otherwise please create a bug in jenkins jira . ' } ) ; <nl> mmm a / war / src / test / js / pluginsetupwizard - spec . js <nl> ppp b / war / src / test / js / pluginsetupwizard - spec . js <nl>
the software . <nl> < artifactid > instance - identity < / artifactid > <nl> < version > 2 . 0 < / version > <nl> < / dependency > <nl> - < dependency > <nl> - < ! - - <nl> - < groupid > org . bouncycastle < / groupid > <nl> - < artifactid > bcpkix - jdk15on < / artifactid > <nl> - < version > 1 . 54 < / version > <nl> - < / dependency > <nl> < dependency > <nl> < groupid > org . jenkins - ci . modules < / groupid > <nl> < artifactid > ssh - cli - auth < / artifactid > <nl>
public final class userdetailscache { <nl> existancecache . put ( this . idorfullname , boolean . false ) ; <nl> throw e ; <nl> } catch ( dataaccessexception e ) { <nl> - existancecache . put ( this . idorfullname , null ) ; <nl> + existancecache . invalidate ( this . idorfullname ) ; <nl> throw e ; <nl> } <nl> }
public class impersonatinguserdetailsservice implements userdetailsservice { <nl>  <nl> protected userdetails attempttoimpersonate ( string username , runtimeexception e ) { <nl> / / this backend cannot tell if the user name exists or not . so substitute by what we know <nl> - user u = user . get ( username , false , emptymap ( ) ) ; <nl> + user u = user . getbyid ( username , false ) ; <nl> if ( u ! = null ) { <nl> lastgrantedauthoritiesproperty p = u . getproperty ( lastgrantedauthoritiesproperty . class ) ; <nl> if ( p ! = null ) <nl> mmm a / core / src / main / java / jenkins / security / lastgrantedauthoritiesproperty . java <nl> ppp b / core / src / main / java / jenkins / security / lastgrantedauthoritiesproperty . java <nl>
public class hudsonprivatesecurityrealm extends abstractpasswordbasedsecurityrea <nl> if ( si . username = = null | | si . username . length ( ) = = 0 ) <nl> si . errormessage = messages . hudsonprivatesecurityrealm_createaccount_usernamerequired ( ) ; <nl> else { <nl> - user user = user . get ( si . username , false ) ; <nl> + user user = user . getbyid ( si . username , false ) ; <nl> if ( null ! = user ) <nl> / / allow sign up . scm people has no such property . <nl> if ( user . getproperty ( details . class ) ! = null )
package jenkins . security . downloadsettings <nl>  <nl> def f = namespace ( lib . formtaglib ) <nl>  <nl> - <nl> - f . entry ( field : " usebrowser " ) { <nl> - f . checkbox ( title : _ ( " use browser for metadata download " ) ) <nl> + f . section ( title : _ ( " plugin manager " ) ) { <nl> + f . entry ( field : " usebrowser " ) { <nl> + f . checkbox ( title : _ ( " use browser for metadata download " ) ) <nl> + } <nl> }
table . progress - bar . red td . progress - bar - done { <nl> / * = = = = = = = = = = = = = = = = = = = = = = = = = logrecords . jelly = = = = = = = = = = = = = = = = = = * / <nl>  <nl> . logrecord - metadata { <nl> - <nl> + font - size : num % ; <nl> } <nl>  <nl> . logrecord - metadata - new {
describe ( " tabbar - spec tests " , function ( ) { <nl> function textcleanup ( text ) { <nl> return text . trim ( ) . replace ( / ( \ r\n | \n | \ r ) / gm , " " ) . replace ( / + / g , " | " ) ; <nl> } <nl> - } ) ; <nl> - <nl> - <nl> \ no newline at end of file <nl> + } ) ; <nl> \ no newline at end of file
public abstract class pluginmanager extends abstractmodelobject implements onmas <nl> string pluginname = n . substring ( 0 , index ) ; <nl> string sitename = n . substring ( <nl> updatesite . plugin plugin = getplugin ( pluginname , sitename ) ; <nl> - <nl> + / / ' plugin . ambiguous . updatesite ' where both <nl> + / / ' plugin ' @ ' ambigiuous . updatesite ' and ' plugin . ambiguous ' @ ' updatesite ' resolve to valid plugins <nl> if ( plugin ! = null ) { <nl> if ( p ! = null ) { <nl> throw new failure ( " ambiguous plugin : " + n ) ; <nl>
public class solarissmflifecycle extends lifecycle { <nl> * / <nl> @ override <nl> public void restart ( ) throws ioexception , interruptedexception { <nl> - jenkins h = jenkins . getinstanceornull ( ) ; <nl> + jenkins h = jenkins . getinstanceornull ( ) ; / / guard against repeated concurrent calls to restart <nl> if ( h ! = null ) <nl> h . cleanup ( ) ; <nl> system . exit ( 0 ) ; <nl> mmm a / core / src / main / java / hudson / lifecycle / unixlifecycle . java <nl> ppp b / core / src / main / java / hudson / lifecycle / unixlifecycle . java <nl>
public class unixlifecycle extends lifecycle { <nl>  <nl> @ override <nl> public void restart ( ) throws ioexception , interruptedexception { <nl> - jenkins h = jenkins . getinstanceornull ( ) ; <nl> + jenkins h = jenkins . getinstanceornull ( ) ; / / guard against repeated concurrent calls to restart <nl> if ( h ! = null ) <nl> h . cleanup ( ) ;
public class olddatamonitor extends administrativemonitor { <nl> } <nl> if ( buf . length ( ) = = num ) return ; <nl> jenkins j = jenkins . getinstanceornull ( ) ; <nl> - if ( j = = null ) { <nl> + if ( j = = null ) { / / need this path , at least for unit tests , but also in case of very broken startup <nl> / / startup failed , something is very broken , so report what we can . <nl> for ( throwable t : errors ) { <nl> logger . log ( level . warning , " could not read " + obj + " ( and jenkins did not start up ) " , t ) ;
public class jenkins extends abstractcibase implements directlymodifiabletopleve <nl> private void _cleanupshutdowntriggers ( list < throwable > errors ) { <nl> logger . log ( level . fine , " shutting down triggers " ) ; <nl> try { <nl> - java . util . timer timer = trigger . timer ; <nl> + final java . util . timer timer = trigger . timer ; <nl> if ( timer ! = null ) { <nl> - timer . cancel ( ) ; <nl> + final countdownlatch latch = new countdownlatch ( 1 ) ; <nl> + timer . schedule ( new timertask ( ) { <nl> + @ override <nl> + public void run ( ) { <nl> + timer . cancel ( ) ; <nl> + latch . countdown ( ) ; <nl> + } <nl> + } , num ) ; <nl> + if ( latch . await ( 10 , timeunit . seconds ) ) { <nl> + logger . log ( level . fine , " triggers shut down successfully " ) ; <nl> + } else { <nl> + timer . cancel ( ) ; <nl> + logger . log ( level . info , " gave up waiting for triggers to finish running " ) ; <nl> + } <nl> } <nl> - <nl> trigger . timer = null ; <nl> } catch ( outofmemoryerror e ) { <nl> / / we should just propagate this , no point trying to log
public final class workunitcontext { <nl> } <nl>  <nl> / * * <nl> - * called by the executor that executes a member { @ link subtask } that belongs to this task <nl> - * to create its { @ link workunit } . <nl> + * called within the queue maintenance process to create a { @ link workunit } for the given { @ link subtask } <nl> * / <nl> public workunit createworkunit ( subtask execunit ) { <nl> - executor executor = executor . currentexecutor ( ) ; <nl> - if ( executor ! = null ) { <nl> - future . addexecutor ( executor ) ; <nl> - } <nl> workunit wu = new workunit ( this , execunit ) ; <nl> workunits . add ( wu ) ; <nl> return wu ;
def runtests = true <nl> properties ( [ [ $ class : ' builddiscarderproperty ' , strategy : [ $ class : ' logrotator ' , <nl> numtokeepstr : ' 10 ' ] ] ] ) <nl>  <nl> - <nl> - string packagingbranch = ( binding . hasvariable ( ' packagingbranch ' ) ) ? packagingbranch : ' oss - dockerized - tests ' <nl> + string packagingbranch = ( binding . hasvariable ( ' packagingbranch ' ) ) ? packagingbranch : ' master ' <nl>  <nl> node ( ' java ' ) {
the software . <nl> < dependency > <nl> < groupid > $ { project . groupid } < / groupid > <nl> < artifactid > jenkins - test - harness < / artifactid > <nl> - < version > 2 . 1 - beta - 1 < / version > < ! - - <nl> + < version > 2 . 2 < / version > <nl> < scope > test < / scope > <nl> < / dependency > <nl> < dependency >
public class security218clitest { <nl> @ test <nl> @ issue ( " security - 218 " ) <nl> public void probecommonscollections2 ( ) throws exception { <nl> - <nl> + / / in newer commons - collections version = > remoting implementation should filter this class anyway <nl> probe ( payload . commonscollections2 , payloadcaller . exit_code_rejected ) ; <nl> } <nl>  <nl>
public class slavetest2 { <nl> public jenkinsrule rule = new jenkinsrule ( ) ; <nl>  <nl> @ test <nl> - <nl> - / / @ issue ( " security - 195 " ) <nl> + @ issue ( " security - 195 " ) <nl> public void shouldnotescapejnlpslavesresources ( ) throws exception { <nl> slave slave = rule . createslave ( ) ; <nl>  <nl>
public class plugintest { <nl>  <nl> @ rule public jenkinsrule r = new jenkinsrule ( ) ; <nl>  <nl> - @ issue ( " security - 131 " ) <nl> + @ issue ( { " security - 131 " , " security - 155 " } ) <nl> @ test public void dodynamic ( ) throws exception { <nl> r . createwebclient ( ) . goto ( " plugin / credentials / images / 24x24 / credentials . png " , " image / png " ) ; <nl> / * collapsed somewhere before it winds up in restofpath :
public class queue extends resourcecontroller implements saveable { <nl>  <nl> { / / blocked - > buildable <nl> / / copy as we ' ll mutate the list and we want to process in a potentially different order <nl> - <nl> - list < blockeditem > blockeditems = new arraylist < blockeditem > ( blockedprojects . values ( ) ) ; <nl> + list < blockeditem > blockeditems = new arraylist < > ( blockedprojects . values ( ) ) ; <nl> / / if facing a cycle of blocked tasks , ensure we process in the desired sort order <nl> if ( s ! = null ) { <nl> s . sortblockeditems ( blockeditems ) ;
the software . <nl> < artifactid > maven - compiler - plugin < / artifactid > <nl> < configuration > <nl> < source > 1 . $ { java . level } < / source > <nl> - < target > 1 . 7 < / target > < ! - - <nl> + < target > 1 . $ { java . level } < / target > <nl> < ! - - default reusecreated is more performant <nl> feel free to uncomment if you have any issues on your platform <nl> < compilerreusestrategy > alwaysnew < / compilerreusestrategy > <nl>
the software . <nl> < version > 3 . 0 < / version > <nl> < / requiremavenversion > <nl> < enforcebytecodeversion > <nl> - < maxjdkversion > 1 . 7 < / maxjdkversion > < ! - - <nl> + < maxjdkversion > 1 . $ { java . level } < / maxjdkversion > <nl> < ignoreclasses > <nl> < ignoreclass > org . eclipse . jetty . spdy . * < / ignoreclass > <nl> < / ignoreclasses >
public class descriptortest { <nl> } <nl> } <nl>  <nl> - @ ignore ( " <nl> @ issue ( " jenkins - 26781 " ) <nl> @ test public void overriddenid ( ) throws exception { <nl> freestyleproject p = rule . createfreestyleproject ( ) ;
public class descriptortest { <nl> } <nl> } <nl>  <nl> - @ ignore ( " <nl> @ issue ( " jenkins - 26781 " ) <nl> @ test public void overriddenid ( ) throws exception { <nl> freestyleproject p = rule . createfreestyleproject ( ) ;
import org . jvnet . hudson . test . jenkinsrule ; <nl> / * * <nl> * contains tests for { @ link procstarter } class . <nl> * @ author oleg nenashev < nenashev @ synopsys . com > , synopsys inc . <nl> - * @ since <nl> + * @ since num . 568 <nl> * / <nl> public class procstartertest { <nl>  <nl> @ rule <nl> public jenkinsrule rule = new jenkinsrule ( ) ; <nl> - <nl> + <nl> @ test <nl> @ issue ( " jenkins - 20559 " ) <nl> public void testnoninitializedenvsnpe ( ) throws exception { <nl>
public abstract class simplebuildwrapper extends buildwrapper { <nl> * / <nl> public abstract void setup ( context context , run < ? , ? > build , filepath workspace , launcher launcher , tasklistener listener , envvars initialenvironment ) throws ioexception , interruptedexception ; <nl>  <nl> + / * * <nl> + * parameter passed to { @ link # setup } to allow an implementation to specify its behavior after the initial setup . <nl> + * / <nl> public static final class context { <nl> - <nl> - public disposer disposer ; <nl> - public envvars env ; <nl> + private disposer disposer ; <nl> + private final map < string , string > env = new hashmap < string , string > ( ) ; <nl> + public @ nonnull map < string , string > getenv ( ) { <nl> + return env ; <nl> + } <nl> + / * * <nl> + * specify an environment variable override ( as in { @ link envvars # override } ) to apply to processes launched within the block . <nl> + * if unspecified , environment variables will be inherited unmodified . <nl> + * / <nl> + public void env ( string key , string value ) { <nl> + if ( env . put ( key , value ) ! = null ) { <nl> + throw new illegalstateexception ( " just one binding for " + key ) ; <nl> + } <nl> + } <nl> + public @ checkfornull disposer getdisposer ( ) { <nl> + return disposer ; <nl> + } <nl> + / * * <nl> + * specify an action to take when the block ends . <nl> + * if not specified , nothing special happens . <nl> + * / <nl> + public void setdisposer ( @ nonnull disposer disposer ) { <nl> + if ( disposer ! = null ) { <nl> + throw new illegalstateexception ( " just one disposer " ) ; <nl> + } <nl> + this . disposer = disposer ; <nl> + } <nl> } <nl>  <nl> / * * <nl> * an optional callback to run at the end of the wrapped block . <nl> + * must be safely serializable , so it receives runtime context comparable to that of the original setup . <nl> * / <nl> public static abstract class disposer implements serializable { <nl> + / * * <nl> + * attempt to clean up anything that was done in the initial setup . <nl> + * @ param build a build being run <nl> + * @ param workspace a workspace of the build <nl> + * @ param launcher a way to start commands <nl> + * @ param listener a way to report progress <nl> + * @ throws ioexception if something fails ; { @ link abortexception } for user errors <nl> + * @ throws interruptedexception if tear down is interrupted <nl> + * / <nl> public abstract void teardown ( run < ? , ? > build , filepath workspace , launcher launcher , tasklistener listener ) throws ioexception , interruptedexception ; <nl> }
package hudson . tasks . shell ; <nl> f = namespace ( lib . formtaglib ) <nl>  <nl> f . entry ( title : _ ( " command " ) , description : _ ( " description " , rooturl ) ) { <nl> - <nl> - f . textarea ( name : " command " , value : instance ? . command , class : " fixed - width " ) <nl> + f . textarea ( name : " command " , value : instance ? . command , class : " fixed - width " , ' codemirror - mode ' : ' shell ' , ' codemirror - config ' : " mode : ' text / x - sh ' " ) <nl> } <nl> mmm a / core / src / main / resources / lib / form / textarea / textarea . js <nl> ppp b / core / src / main / resources / lib / form / textarea / textarea . js <nl>
public abstract class abstractbuild < p extends abstractproject < p , r > , r extends abs <nl> / / use multiple environment variables so that people can escape this massacre by overriding an environment <nl> / / variable for some processes <nl> launcher . kill ( getcharacteristicenvvars ( ) ) ; <nl> - } else { <nl> - / / as can be seen in hudson - 5073 , when a build fails because of the slave connectivity problem , <nl> - / / error message doesn ' t point users to the slave . so let ' s do it here . <nl> - listener . hyperlink ( " / computer / " + builton + " / log " , " looks like the node went offline during the build . check the slave log for the details . " ) ; <nl> - <nl> - <nl> - computer c = node . tocomputer ( ) ; <nl> - if ( c ! = null ) { <nl> - / / grab the end of the log file . this might not work very well if the slave already <nl> - / / starts reconnecting . fixing this requires a ring buffer in slave logs . <nl> - annotatedlargetext < computer > log = c . getlogtext ( ) ; <nl> - stringwriter w = new stringwriter ( ) ; <nl> - log . writehtmlto ( math . max ( 0 , c . getlogfile ( ) . length ( ) - 10240 ) , w ) ; <nl> - <nl> - listener . getlogger ( ) . print ( expandabledetailsnote . encodeto ( " details " , w . tostring ( ) ) ) ; <nl> - listener . getlogger ( ) . println ( ) ; <nl> - } <nl> } <nl>  <nl> / / this is ugly , but for historical reason , if non - null value is returned <nl>
import org . kohsuke . stapler . staplerrequest ; <nl> return jenkins . getinstance ( ) . getinjector ( ) . getinstance ( downloadsettings . class ) ; <nl> } <nl>  <nl> - private boolean usebrowser = false ; <nl> + private boolean usebrowser = false ; <nl>  <nl> public downloadsettings ( ) { <nl> load ( ) ;
public class jenkins extends abstractcibase implements directlymodifiabletopleve <nl> * { @ link # getinstance ( ) } provides the unchecked versions of the method . <nl> * @ return { @ link jenkins } instance <nl> * @ throws illegalstateexception { @ link jenkins } has not been started , or was already shut down <nl> - * @ since <nl> + * @ since num . 590 <nl> * / <nl> public static @ nonnull jenkins getactiveinstance ( ) throws illegalstateexception { <nl> jenkins instance = holder . getinstance ( ) ;
the software . <nl> < patch . tracker . serverid > jenkins - jira < / patch . tracker . serverid > <nl>  <nl> < slf4jversion > 1 . 7 . 4 < / slf4jversion > < ! - - < num . 6 . x version didn ' t specify the license ( mit ) - - > <nl> - < maven - plugin . version > 2 . 0 . 5 - snapshot < / maven - plugin . version > < ! - - <nl> + < maven - plugin . version > 2 . 0 < / maven - plugin . version > <nl> < animal . sniffer . skip > $ { skiptests } < / animal . sniffer . skip > <nl>  <nl> < java . level > 6 < / java . level >
deny all < builddir > / build . xml <nl> # - dependency - check writes archive / artifacts . txt <nl> allow all < builddir > / . + <nl>  <nl> - # <nl> + # cobertura also writes out annotated sources to a dir under the job : <nl> + allow all < jenkins_home > / jobs / . + / cobertura . * <nl>  <nl> # all the other accesses that aren ' t specified here will be left upto other rules in this directory . <nl> # if no rules in those other files matches , then the access will be rejected .
public class callabledirectionchecker extends rolechecker { <nl> * / <nl> public static concurrentmap < string , void > bypass_callables = new concurrenthashmap < string , void > ( ) ; <nl>  <nl> - / * * <nl> - * test feature that is meant to replace all logging , and log what would have been violations . <nl> - * <nl> - * / <nl> - private static final printwriter bypass_log ; <nl> - <nl> - static { <nl> - string log = system . getproperty ( callabledirectionchecker . class . getname ( ) + " . log " ) ; <nl> - if ( log = = null ) { <nl> - bypass_log = null ; <nl> - } else { <nl> - try { <nl> - bypass_log = new printwriter ( new outputstreamwriter ( new fileoutputstream ( log , true ) ) , true ) ; <nl> - } catch ( filenotfoundexception x ) { <nl> - throw new exceptionininitializererror ( x ) ; <nl> - } <nl> - } <nl> - } <nl> - <nl> private callabledirectionchecker ( object context ) { <nl> this . context = context ; <nl> } <nl>
the software . <nl> < dependency > <nl> < groupid > com . github . jnr < / groupid > <nl> < artifactid > jnr - posix < / artifactid > <nl> - < version > 3 . 0 . 0 < / version > <nl> + < version > 3 . 0 . 1 < / version > <nl> < / dependency > <nl> - < ! - - <nl> - < dependency > <nl> - < groupid > com . github . jnr < / groupid > <nl> - < artifactid > jnr - ffi < / artifactid > <nl> - < version > 1 . 0 . 6 < / version > <nl> - < / dependency > <nl> - - - > <nl> < dependency > <nl> < groupid > org . kohsuke < / groupid > <nl> < artifactid > trilead - putty - extension < / artifactid >
public abstract class launcher { <nl> * <nl> * @ author rcampbell <nl> * @ author oleg nenashev , synopsys inc . <nl> - * @ since <nl> + * @ since num . 568 <nl> * / <nl> public static class decoratedlauncher extends launcher {
public class queue extends resourcecontroller implements saveable { <nl> / * * <nl> * defines the refresh period for of the internal cache ( { @ link # itemsview } ) . <nl> * data should be defined in milliseconds , default value - num ; <nl> - * @ since <nl> + * @ since num . 577 <nl> * / <nl> private static int cache_refresh_period = integer . getinteger ( queue . class . getname ( ) + " . cacherefreshperiod " , num ) ;
public class chartutil { <nl> @ deprecated <nl> public final abstractbuild build ; <nl>  <nl> - / * * @ since <nl> + / * * <nl> + * @ since num . 577 <nl> + * / <nl> public numberonlybuildlabel ( run < ? , ? > run ) { <nl> this . run = run ; <nl> this . build = run instanceof abstractbuild ? ( abstractbuild ) run : null ; <nl>
public class chartutil { <nl> this . build = build ; <nl> } <nl>  <nl> - / * @ since <nl> + / * * <nl> + * @ since num . 577 <nl> + * / <nl> public run < ? , ? > getrun ( ) { <nl> return run ; <nl> } <nl> mmm a / core / src / main / java / jenkins / tasks / simplebuildstep . java <nl> ppp b / core / src / main / java / jenkins / tasks / simplebuildstep . java <nl>
public class fingerprint implements modelobject , saveable { <nl> * gets the { @ link job } that this pointer points to , <nl> * or null if such a job no longer exists . <nl> * / <nl> - public abstractproject getjob ( ) { <nl> - return jenkins . getinstance ( ) . getitembyfullname ( name , abstractproject . class ) ; <nl> + @ withbridgemethods ( value = abstractproject . class , castrequired = true ) <nl> + public job < ? , ? > getjob ( ) { <nl> + return jenkins . getinstance ( ) . getitembyfullname ( name , job . class ) ; <nl> } <nl>  <nl> / * * <nl> mmm a / core / src / main / java / hudson / tasks / fingerprinter . java <nl> ppp b / core / src / main / java / hudson / tasks / fingerprinter . java <nl>
public class testresultprojectaction implements action { <nl> / * * <nl> * project that owns this action . <nl> * / <nl> - public final abstractproject < ? , ? > project ; <nl> + public final job < ? , ? > job ; <nl>  <nl> + @ deprecated <nl> + public final abstractproject < ? , ? > project ; <nl> + <nl> + public testresultprojectaction ( job < ? , ? > job ) { <nl> + this . job = job ; <nl> + project = job instanceof abstractproject ? ( abstractproject ) job : null ; <nl> + } <nl> + <nl> + @ deprecated <nl> public testresultprojectaction ( abstractproject < ? , ? > project ) { <nl> - this . project = project ; <nl> + this ( ( job ) project ) ; <nl> } <nl>  <nl> / * * <nl>
public abstract class computerlistener implements extensionpoint { <nl> / * * <nl> * called right after a { @ link computer } went offline . <nl> * <nl> - * @ deprecated since <nl> + * @ deprecated since num . 571 . use { @ link # onoffline ( computer , offlinecause ) } instead . <nl> * / <nl> @ deprecated <nl> public void onoffline ( computer c ) { } <nl>
public abstract class abstractscmtagaction extends taskaction implements buildba <nl> return scm . tag ; <nl> } <nl>  <nl> - <nl> + @ adaptfield ( name = " build " , was = abstractbuild . class ) <nl> + @ withbridgemethods ( value = abstractbuild . class , castrequired = true ) <nl> public run getbuild ( ) { <nl> return build ; <nl> } <nl> mmm a / core / src / main / java / hudson / triggers / scmtrigger . java <nl> ppp b / core / src / main / java / hudson / triggers / scmtrigger . java <nl>
the software . <nl> < a href = " $ { cslink } " > $ { browser . descriptor . displayname } < / a > <nl> < / j : when > <nl> < j : otherwise > <nl> - < ! - - <nl> + < ! - - this anchor is meaningless if there is > 1 changelogset / index . jelly for the build ; an scm should rather use an actual commit id for the anchor : - - > <nl> < a href = " $ { b . number } / changes # detail $ { loop . index } " > $ { % detail } < / a > <nl> < / j : otherwise > <nl> < / j : choose >
<nl> - <nl> - - remove java6 dependency ( or do we really ? ) <nl> - <nl> - note : <nl> - - permalinks , such as " last unstable build " can end up loading all the records if there ' s no build that has the said status .
public abstract class node extends abstractmodelobject implements reconfigurable <nl> authentication identity = item . authenticate ( ) ; <nl> if ( ! getacl ( ) . haspermission ( identity , computer . build ) ) { <nl> / / doesn ' t have a permission <nl> - <nl> return causeofblockage . frommessage ( messages . _node_lackingbuildpermission ( identity . getname ( ) , getnodename ( ) ) ) ; <nl> }
public class user extends abstractmodelobject implements accesscontrolled , descr <nl>  <nl> / * * <nl> * creates an { @ link authentication } object that represents this user . <nl> - * <nl> + * <nl> + * this method checks with { @ link securityrealm } if the user is a valid user that can login to the security realm . <nl> + * if { @ link securityrealm } is a kind that does not support querying information about other users , this will <nl> + * use { @ link lastgrantedauthoritiesproperty } to pick up the granted authorities as of the last time the user has <nl> + * logged in . <nl> + * <nl> + * @ throws usernamenotfoundexception <nl> + * if this user is not a valid user in the backend { @ link securityrealm } . <nl> * @ since num . 419 <nl> * / <nl> - public authentication impersonate ( ) { <nl> + public authentication impersonate ( ) throws usernamenotfoundexception { <nl> try { <nl> - userdetails u = jenkins . getinstance ( ) . getsecurityrealm ( ) . loaduserbyusername ( id ) ; <nl> + userdetails u = new impersonatinguserdetailsservice ( <nl> + jenkins . getinstance ( ) . getsecurityrealm ( ) . getsecuritycomponents ( ) . userdetails ) . loaduserbyusername ( id ) ; <nl> return new usernamepasswordauthenticationtoken ( u . getusername ( ) , " " , u . getauthorities ( ) ) ; <nl> + } catch ( usermayormaynotexistexception e ) { <nl> + / / backend can ' t load information about other users . so use the stored information if available <nl> } catch ( usernamenotfoundexception e ) { <nl> - / / ignore <nl> + / / if the user no longer exists in the backend , we need to refuse impersonating this user <nl> + throw e ; <nl> } catch ( dataaccessexception e ) { <nl> - / / ignore <nl> + / / seems like it ' s in the same boat as usermayormaynotexistexception <nl> } <nl> - <nl> + <nl> + / / seems like a legitimate user we have no idea about . proceed with minimum access <nl> return new usernamepasswordauthenticationtoken ( id , " " , <nl> new grantedauthority [ ] { securityrealm . authenticated_authority } ) ; <nl> }
import org . kohsuke . stapler . queryparameter ; <nl>  <nl> / * * <nl> * a generic script - based installer . <nl> - * @ since <nl> + * @ since num . 549 <nl> * @ see batchcommandinstaller <nl> * @ see commandinstaller <nl> * @ author oleg nenashev <nl> mmm a / core / src / main / resources / lib / hudson / aggregated - failed - tests . jelly <nl> ppp b / core / src / main / resources / lib / hudson / aggregated - failed - tests . jelly <nl>
the software . <nl> input . number ( defined in hudson - behavior . js ) is a class for integers . <nl> on the other hand , html5 < input > permits floating - point numbers . <nl> - - > <nl> + < j : set var = " name " value = " $ { attrs . name ? : ' _ . ' + attrs . field } " / > <nl> + < j : set var = " default " value = " $ { attrs . default ? : ' ' } " / > <nl> + < j : set var = " value " value = " $ { attrs . value ? : instance [ attrs . field ] ? : default } " / > <nl> < m : input xmlns : m = " jelly : hudson . util . jelly . morphtaglibrary " <nl> class = " setting - input $ { attrs . checkurl ! = null ? ' validated ' : ' ' } $ { attrs . clazz } " <nl> - name = " $ { attrs . name ? : ' _ . ' + attrs . field } " <nl> - value = " $ { attrs . value ? : instance [ attrs . field ] ? : attrs . default } " <nl> + name = " $ { name } " <nl> + value = " $ { value } " <nl> type = " number " <nl> attributes = " $ { attrs } " except = " field clazz " / > <nl> - < ! - - <nl> + < j : if test = " $ { customizedfields ! = null and attrs . field ! = null and value ! = default } " > <nl> + < j : mute > $ { customizedfields . add ( name ) } < / j : mute > <nl> + < / j : if > <nl> < / j : jelly >
public abstract class view extends abstractmodelobject implements accesscontroll <nl> / * * <nl> * enables or disables automatic refreshes of the view . <nl> * by default , automatic refreshes are enabled . <nl> - * @ since <nl> + * @ since num . 557 <nl> * / <nl> public boolean isautomaticrefreshenabled ( ) { <nl> return true ;
public class listviewtest { <nl> mockfolder stuff = top . createproject ( mockfolder . class , " stuff " ) ; <nl> items . move ( p1 , stuff ) ; <nl> p3 . delete ( ) ; <nl> - thread . sleep ( 500 ) ; <nl> top . createproject ( freestyleproject . class , " p3 " ) ; <nl> assertequals ( new hashset < toplevelitem > ( arrays . aslist ( p1 , p2 ) ) , new hashset < toplevelitem > ( v . getitems ( ) ) ) ; <nl> top . renameto ( " upper " ) ;
the software . <nl> < artifactid > upstart - slave - installer < / artifactid > <nl> < version > 1 . 1 < / version > <nl> < / dependency > <nl> - < ! - - <nl> - warning : org . jenkinsci . modules . systemd_slave_installer . slaveinstallerfactoryimpl @ 614899d4 has failed on hudson . slaves . slavecomputer @ 163dc443 <nl> - java . io . ioexception : cannot run program " systemctl " : error = 2 , no such file or directory <nl> - at java . lang . processbuilder . start ( processbuilder . java : 1041 ) <nl> - at org . jenkinsci . modules . systemd_slave_installer . slaveinstallerfactoryimpl $ hassystemd . call ( slaveinstallerfactoryimpl . java : 46 ) <nl> - at org . jenkinsci . modules . systemd_slave_installer . slaveinstallerfactoryimpl $ hassystemd . call ( slaveinstallerfactoryimpl . java : 39 ) <nl> < dependency > <nl> < groupid > org . jenkins - ci . modules < / groupid > <nl> < artifactid > systemd - slave - installer < / artifactid > <nl> - < version > 1 . 0 < / version > <nl> + < version > 1 . 1 < / version > <nl> < / dependency > <nl> - - - > <nl> < dependency > <nl> < groupid > org . jenkins - ci . modules < / groupid > <nl> < artifactid > sshd < / artifactid >
import org . kohsuke . accmod . restrictions . noexternaluse ; <nl> * and find things in it . <nl> * <nl> * @ author kohsuke kawaguchi <nl> - * @ since num . 485 ( but as of <nl> + * @ since num . 485 ( but as of num . 548 not a { @ link softreference } ) <nl> * / <nl> public final class buildreference < r > { <nl>  <nl>
public class itemlistener implements extensionpoint { <nl> l . onupdated ( item ) ; <nl> } <nl>  <nl> - / * * @ since <nl> + / * * @ since num . 548 * / <nl> public static void fireondeleted ( item item ) { <nl> for ( itemlistener l : all ( ) ) { <nl> l . ondeleted ( item ) ; <nl>
the software . <nl> < / st : attribute > <nl> < / st : documentation > <nl> < st : adjunct includes = " lib . layout . progressiverendering . progressiverendering " / > <nl> - < ! - - <nl> - < t : progressbar id = " status " pos = " 0 " tooltip = " $ { tooltip ? : ' % progressmessage ' } " / > <nl> + < j : set var = " id " value = " $ { h . generateid ( ) } " / > <nl> + < t : progressbar id = " $ { id } " pos = " 0 " tooltip = " $ { tooltip ? : ' % progressmessage ' } " / > <nl> < j : invoke method = " start " on = " $ { handler } " / > <nl> < st : bind var = " proxy " value = " $ { handler } " / > <nl> - < script > progressivelyrender ( proxy , $ { callback } ) ; < / script > <nl> + < script > progressivelyrender ( proxy , $ { callback } , ' $ { id } ' ) ; < / script > <nl> < / j : jelly > <nl> mmm a / core / src / main / resources / lib / layout / progressiverendering / progressiverendering . js <nl> ppp b / core / src / main / resources / lib / layout / progressiverendering / progressiverendering . js <nl>
public class user extends abstractmodelobject implements accesscontrolled , descr <nl> final list < run > lastbuilds = new arraylist < run > ( ) ; <nl> for ( abstractproject < ? , ? > p : jenkins . getinstance ( ) . getallitems ( abstractproject . class ) ) { <nl> for ( abstractbuild < ? , ? > b = p . getlastbuild ( ) ; b ! = null ; b = b . getpreviousbuild ( ) ) { <nl> - if ( b . hasparticipant ( this ) ) { <nl> + if ( relatedto ( b ) ) { <nl> lastbuilds . add ( b ) ; <nl> break ; <nl> }
import java . util . concurrent . timeunit ; <nl> * / <nl> @ extension <nl> public class nodemonitorupdater extends computerlistener { <nl> - <nl> - private final scheduledexecutorservice timer = new scheduledthreadpoolexecutor ( 1 , new daemonthreadfactory ( ) ) ; <nl>  <nl> private volatile long timestamp ; <nl>  <nl>
public abstract class permissionadder implements extensionpoint { <nl> * / <nl> public abstract boolean add ( authorizationstrategy strategy , user user , permission perm ) ; <nl>  <nl> - <nl> - @ restricted ( noexternaluse . class ) <nl> - @ extension public static final class legacy extends permissionadder { <nl> - <nl> - @ override public boolean add ( authorizationstrategy strategy , user user , permission perm ) { <nl> - try { <nl> - strategy . getclass ( ) . getmethod ( " add " , permission . class , string . class ) . invoke ( strategy , jenkins . administer , user . getid ( ) ) ; <nl> - return true ; <nl> - } catch ( nosuchmethodexception x ) { <nl> - / / fine , not globalmatrixauthorizationstrategy or a subclass <nl> - } catch ( exception x ) { <nl> - logger . log ( level . warning , null , x ) ; <nl> - } <nl> - return false ; <nl> - } <nl> - <nl> - } <nl> - <nl> } <nl> mmm a / war / pom . xml <nl> ppp b / war / pom . xml <nl>
public final class filepath implements serializable { <nl> } <nl> } <nl> public outputstream compress ( outputstream out ) throws ioexception { <nl> - return new gzipoutputstream ( new bufferedoutputstream ( out ) , <nl> - <nl> - new com . jcraft . jzlib . deflater ( 6 , num + 16 , num ) , / / use num for memlevel <nl> - num , <nl> - true <nl> - ) ; <nl> + return new gzipoutputstream ( new bufferedoutputstream ( out ) ) ; <nl> } <nl> } ;
the software . <nl> < dependency > <nl> < groupid > com . github . jnr < / groupid > <nl> < artifactid > jnr - posix < / artifactid > <nl> - < version > 3 . 0 . 0 < / version > <nl> + < version > 3 . 0 . 1 < / version > <nl> < / dependency > <nl> - < ! - - <nl> - < dependency > <nl> - < groupid > com . github . jnr < / groupid > <nl> - < artifactid > jnr - ffi < / artifactid > <nl> - < version > 1 . 0 . 6 < / version > <nl> - < / dependency > <nl> - - - > <nl> < dependency > <nl> < groupid > org . kohsuke < / groupid > <nl> < artifactid > trilead - putty - extension < / artifactid >
the software . <nl> < plugin > <nl> < groupid > org . jenkins - ci . tools < / groupid > <nl> < artifactid > maven - hpi - plugin < / artifactid > <nl> - < version > 1 . 96 < / version > < ! - - <nl> + < version > 1 . 97 < / version > <nl> < / plugin > <nl> < plugin > <nl> < groupid > org . apache . maven . plugins < / groupid >
public class listjobscommandtest { <nl> when ( jenkins . getview ( null ) ) . thenreturn ( null ) ; <nl> when ( jenkins . getitembyfullname ( null ) ) . thenreturn ( null ) ; <nl>  <nl> - <nl> - assertthat ( runwith ( " nosuchvieworitemgroup " ) , equalto ( 0 ) ) ; <nl> + assertthat ( runwith ( " nosuchvieworitemgroup " ) , equalto ( - 1 ) ) ; <nl> assertthat ( stdout , is ( empty ( ) ) ) ; <nl> assertthat ( stderr , is ( not ( empty ( ) ) ) ) ; <nl> }
<nl> - package jenkins . security ; <nl> - <nl> - import hudson . extension ; <nl> - import hudson . model . abstractproject ; <nl> - import hudson . security . acl ; <nl> - import org . acegisecurity . authentication ; <nl> - import org . kohsuke . stapler . databoundconstructor ; <nl> - <nl> - / * * <nl> - * @ author kohsuke kawaguchi <nl> - * / <nl> - public class defaultprojectauthenticator extends projectauthenticator { <nl> - @ databoundconstructor <nl> - public defaultprojectauthenticator ( ) { <nl> - } <nl> - <nl> - @ override <nl> - public authentication authenticate ( abstractproject < ? , ? > project ) { <nl> - return acl . system ; <nl> - } <nl> - <nl> - @ extension <nl> - public static class descriptorimpl extends projectauthenticatordescriptor { <nl> - @ override <nl> - public string getdisplayname ( ) { <nl> - return " default " ; <nl> - } <nl> - } <nl> - } <nl> mmm a / core / src / main / resources / jenkins / security / projectauthenticatorconfiguration / config . groovy <nl> ppp b / core / src / main / resources / jenkins / security / projectauthenticatorconfiguration / config . groovy <nl>
public class executorauthenticatorconfiguration extends globalconfiguration { <nl> return authenticators ; <nl> } <nl>  <nl> - <nl> - @ restricted ( noexternaluse . class ) <nl> - public descriptorextensionlist < executorauthenticator , executorauthenticatordescriptor > getauthenticatorsdescriptors ( ) { <nl> - return executorauthenticatordescriptor . all ( ) ; <nl> - } <nl> - <nl> @ override <nl> public boolean configure ( staplerrequest req , jsonobject json ) throws formexception { <nl> try { <nl>
public class securitycontextexecutorservice implements executorservice { <nl> } ; <nl> } <nl>  <nl> - private static < t > collection < ? extends callable < t > > wrapcallablecollectionwithsecuritycontext ( <nl> + private static < t > arraylist < callable < t > > wrapcallablecollectionwithsecuritycontext ( <nl> final collection < ? extends callable < t > > tasks ) { <nl> final securitycontext callingcontext = securitycontextholder <nl> . getcontext ( ) ; <nl> + arraylist < callable < t > > wrappedtasks = new arraylist < callable < t > > ( ) ; <nl> for ( final callable < t > task : tasks ) { <nl> - <nl> - / / tasks . remove ( task ) ; <nl> - / / tasks . add ( new callable < t > ( ) { <nl> - / / public t call ( ) throws exception { <nl> - / / securitycontext originalexecutorcontext = securitycontextholder <nl> - / / . getcontext ( ) ; <nl> - / / securitycontextholder . setcontext ( callingcontext ) ; <nl> - / / t result = null ; <nl> - / / try { <nl> - / / result = task . call ( ) ; <nl> - / / } finally { <nl> - / / securitycontextholder . setcontext ( originalexecutorcontext ) ; <nl> - / / } <nl> - / / return result ; <nl> - / / } <nl> - / / } ) ; <nl> + wrappedtasks . add ( new callable < t > ( ) { <nl> + public t call ( ) throws exception { <nl> + securitycontext originalexecutorcontext = securitycontextholder <nl> + . getcontext ( ) ; <nl> + securitycontextholder . setcontext ( callingcontext ) ; <nl> + t result = null ; <nl> + try { <nl> + result = task . call ( ) ; <nl> + } finally { <nl> + securitycontextholder . setcontext ( originalexecutorcontext ) ; <nl> + } <nl> + return result ; <nl> + } <nl> + } ) ; <nl> } <nl> - return tasks ; <nl> + return wrappedtasks ; <nl> } <nl>  <nl> public void execute ( runnable arg0 ) { <nl> mmm / dev / null <nl> ppp b / test / src / test / java / jenkins / security / securitycontextexecutorservicetest . java <nl>
public class securitycontextexecutorservice implements executorservice { <nl> } ; <nl> } <nl>  <nl> - private static < t > collection < ? extends callable < t > > wrapcallablecollectionwithsecuritycontext ( <nl> + private static < t > arraylist < callable < t > > wrapcallablecollectionwithsecuritycontext ( <nl> final collection < ? extends callable < t > > tasks ) { <nl> final securitycontext callingcontext = securitycontextholder <nl> . getcontext ( ) ; <nl> + arraylist < callable < t > > wrappedtasks = new arraylist < callable < t > > ( ) ; <nl> for ( final callable < t > task : tasks ) { <nl> - <nl> - / / tasks . remove ( task ) ; <nl> - / / tasks . add ( new callable < t > ( ) { <nl> - / / public t call ( ) throws exception { <nl> - / / securitycontext originalexecutorcontext = securitycontextholder <nl> - / / . getcontext ( ) ; <nl> - / / securitycontextholder . setcontext ( callingcontext ) ; <nl> - / / t result = null ; <nl> - / / try { <nl> - / / result = task . call ( ) ; <nl> - / / } finally { <nl> - / / securitycontextholder . setcontext ( originalexecutorcontext ) ; <nl> - / / } <nl> - / / return result ; <nl> - / / } <nl> - / / } ) ; <nl> + wrappedtasks . add ( new callable < t > ( ) { <nl> + public t call ( ) throws exception { <nl> + securitycontext originalexecutorcontext = securitycontextholder <nl> + . getcontext ( ) ; <nl> + securitycontextholder . setcontext ( callingcontext ) ; <nl> + t result = null ; <nl> + try { <nl> + result = task . call ( ) ; <nl> + } finally { <nl> + securitycontextholder . setcontext ( originalexecutorcontext ) ; <nl> + } <nl> + return result ; <nl> + } <nl> + } ) ; <nl> } <nl> - return tasks ; <nl> + return wrappedtasks ; <nl> } <nl>  <nl> public void execute ( runnable arg0 ) { <nl> mmm / dev / null <nl> ppp b / test / src / test / java / jenkins / security / securitycontextexecutorservicetest . java <nl>
<nl> # out of or in connection with the software or the use or other dealings in <nl> # the software . <nl>  <nl> - # <nl> - newversionavailable = une nouvelle version de jenkins ( { 0 } ) est < a href = " { 1 } " > disponible < / a > . <nl> + newversionavailable = une nouvelle version de jenkins ( { 0 } ) est < a href = " { 1 } " > disponible < / a > \ <nl> + ( < a href = " http : / / jenkins - ci . org / changelog . html " > changelog < / a > ) . <nl> or \ upgrade \ automatically = ou mettre \ u00e0 jour automatiquement <nl> upgradeprogress = mise \ u00e0 jour vers jenkins { 0 } est < a href = " { 1 } " > en cours ou en \ u00e9chec < / a > . <nl> + upgradecomplete = mise \ u00e0 jour vers jenkins { 0 } est termin \ u00e9e , en attente de < a href = " { 1 } / saferestart " > red \ u00e9marrage < / a > .
the software . <nl> < / div > <nl> < / j : when > <nl> < j : when test = " $ { it . offline and ! it . temporarilyoffline } " > <nl> - < l : isadmin > < ! - - <nl> + < j : if test = " $ { h . haspermission ( it , it . connect ) } " > <nl> < p > <nl> $ { % connect slave to jenkins one of these ways : } <nl> < / p > <nl>
public class buildcommand extends clicommand { <nl> stdout . println ( " started " + b . getfulldisplayname ( ) ) ; <nl>  <nl> if ( sync ) { <nl> - if ( consoleoutput ) { <nl> - / / read output in a retry loop , by default try only once <nl> - / / writewholelogto may fail with filenotfound <nl> - / / exception on a slow / busy machine , if it takes <nl> - / / longish to create the log file <nl> - int retryinterval = num ; <nl> - for ( int i = 0 ; i < = retrycnt ; ) { <nl> - try { <nl> - b . writewholelogto ( stdout ) ; <nl> - break ; <nl> - } <nl> - catch ( filenotfoundexception e ) { <nl> - if ( i = = retrycnt ) { <nl> - throw e ; <nl> + try { <nl> + if ( consoleoutput ) { <nl> + / / read output in a retry loop , by default try only once <nl> + / / writewholelogto may fail with filenotfound <nl> + / / exception on a slow / busy machine , if it takes <nl> + / / longish to create the log file <nl> + int retryinterval = num ; <nl> + for ( int i = 0 ; i < = retrycnt ; ) { <nl> + try { <nl> + b . writewholelogto ( stdout ) ; <nl> + break ; <nl> + } <nl> + catch ( filenotfoundexception e ) { <nl> + if ( i = = retrycnt ) { <nl> + throw e ; <nl> + } <nl> + i + + ; <nl> + thread . sleep ( retryinterval ) ; <nl> } <nl> - i + + ; <nl> - thread . sleep ( retryinterval ) ; <nl> } <nl> } <nl> + f . get ( ) ; / / wait for the completion <nl> + stdout . println ( " completed " + b . getfulldisplayname ( ) + " : " + b . getresult ( ) ) ; <nl> + return b . getresult ( ) . ordinal ; <nl> + } catch ( interruptedexception e ) { <nl> + / / if the cli is aborted , try to abort the build as well <nl> + f . cancel ( true ) ; <nl> + throw e ; <nl> } <nl> - <nl> - f . get ( ) ; / / wait for the completion <nl> - stdout . println ( " completed " + b . getfulldisplayname ( ) + " : " + b . getresult ( ) ) ; <nl> - return b . getresult ( ) . ordinal ; <nl> } <nl> }
import java . util . set ; <nl> @ supportedsourceversion ( sourceversion . release_6 ) <nl> @ supportedannotationtypes ( " * " ) <nl> @ metainfservices ( processor . class ) <nl> - <nl> @ ignorejrerequirement <nl> @ suppresswarnings ( { " since15 " } ) <nl> public class pluginsubtypemarker extends abstractprocessor { <nl> mmm a / plugins / pom . xml <nl> ppp b / plugins / pom . xml <nl>
import java . util . list ; <nl> / * * <nl> * { @ link list } of { @ link run } s , sorted in the descending date order . <nl> * <nl> - * <nl> - * <nl> * @ author kohsuke kawaguchi <nl> * / <nl> public class runlist < r extends run > extends abstractlist < r > { <nl>
the software . <nl> put this tag right before & lt ; l : main - panel > <nl> < / st : documentation > <nl>  <nl> + < st : adjunct includes = " lib . form . breadcrumb - config - outline . init " / > <nl> < l : breadcrumb title = " $ { % configuration } " id = " inpage - nav " / > <nl> - < style > <nl> - # breadcrumbs # inpage - nav a { background : none ; } <nl> - < / style > <nl> - < ! - - <nl> - <nl> - - - > <nl> - < script > <nl> - event . observe ( window , " load " , function ( ) { <nl> - / * * @ type section . sectionnode * / <nl> - var outline = section . buildtree ( ) ; <nl> - var menu = new breadcrumbs . contextmenu ( ) ; <nl> - $ a ( outline . children ) . each ( function ( e ) { <nl> - var id = " section " + ( iota + + ) ; <nl> - var caption = e . gethtml ( ) ; <nl> - var cur = $ ( e . section ) . down ( " a . section - anchor " ) ; <nl> - if ( cur ! = null ) { <nl> - id = cur . id ; <nl> - caption = caption . substring ( caption . indexof ( " & lt ; / a > " ) + 4 ) ; <nl> - } else <nl> - $ ( e . section ) . insert ( { top : " & lt ; a id = " + id + " class = ' section - anchor ' > # & lt ; / a > " } ) ; <nl> - menu . add ( ' # ' + id , null , caption ) ; <nl> - } ) ; <nl> - breadcrumbs . attachmenu ( ' inpage - nav ' , menu ) ; <nl> - } ) ; <nl> - < / script > <nl> - < style > <nl> - a . section - anchor { <nl> - position : relative ; <nl> - top : - 2em ; <nl> - visibility : hidden ; <nl> - display : inline - block ; <nl> - width : num px ; <nl> - } <nl> - < / style > <nl> < / j : jelly > <nl> \ no newline at end of file <nl> mmm / dev / null <nl> ppp b / core / src / main / resources / lib / form / breadcrumb - config - outline / init . css <nl>
public class callstackframe implements debugframe { <nl> this . activation = activation ; <nl> this . thisobj = thisobj ; <nl> this . args = args ; <nl> - owner . callstack . add ( this ) ; <nl> + owner . addcallstackframe ( this ) ; <nl> } <nl>  <nl> public void onexit ( context cx , boolean bythrow , object resultorexception ) { <nl> - / / can ' t simply call removefirst , because due to tail call elimination , <nl> - / / intermediate frames can be dropped at any time <nl> - <nl> - for ( int i = owner . callstack . size ( ) - 1 ; i > = 0 ; i - - ) <nl> - if ( owner . callstack . get ( i ) = = this ) { <nl> - owner . callstack . remove ( i ) ; <nl> - break ; <nl> - } <nl> + owner . removecallstackframe ( this ) ; <nl>  <nl> activation = null ; <nl> thisobj = null ; <nl> mmm a / test / src / main / java / org / jvnet / hudson / test / rhino / javascriptdebugger . java <nl> ppp b / test / src / main / java / org / jvnet / hudson / test / rhino / javascriptdebugger . java <nl>
public class util { <nl> * <nl> * @ param listener <nl> * if we rely on an external command to resolve symlink , this is it . <nl> - * ( <nl> * / <nl> public static string resolvesymlink ( file link , tasklistener listener ) throws interruptedexception , ioexception { <nl> if ( functions . iswindows ( ) ) return null ;
public class buildcommand extends clicommand { <nl> ) ; <nl> } <nl>  <nl> - <nl> public static class clicause extends cause { <nl> + <nl> + private string startedby ; <nl> + <nl> + public clicause ( ) { <nl> + startedby = " unknown " ; <nl> + } <nl> + <nl> + public clicause ( string startedby ) { <nl> + this . startedby = startedby ; <nl> + } <nl> + <nl> public string getshortdescription ( ) { <nl> - return " started by command line " ; <nl> + return " started by command line by " + startedby ; <nl> } <nl>  <nl> @ override
import java . util . list ; <nl> import java . util . logging . logger ; <nl>  <nl> / * * <nl> - * deletes old log files . <nl> - * <nl> - * <nl> - * try to generalize this just like { @ link scm } or { @ link buildstep } . <nl> - * <nl> + * deletes old builds . <nl> + * <nl> + * historically this is called logrotator , though it deletes the whole build including all artifacts . <nl> + * <nl> + * since num . 350 it has also the option to keep the build , but delete its recorded artifacts . <nl> + * <nl> * @ author kohsuke kawaguchi <nl> * / <nl> public class logrotator implements describable < logrotator > { <nl>
public class jenkins extends abstractcibase implements modifiableitemgroup < tople <nl> } <nl>  <nl> / * * <nl> - * <nl> + * refresh { @ link extensionlist } s by adding all the newly discovered extensions . <nl> + * <nl> + * exposed only for { @ link pluginmanager # dynamicload ( file ) } . <nl> * / <nl> public void refreshextensions ( ) throws extensionrefreshexception { <nl> extensionlist < extensionfinder > finders = getextensionlist ( extensionfinder . class ) ; <nl>
public abstract class pluginmanager extends abstractmodelobject { <nl> if ( getplugin ( p . getshortname ( ) ) ! = null ) <nl> throw new illegalargumentexception ( " dynamic reloading isn ' t possible " ) ; <nl>  <nl> - <nl> + / / so existing plugins can ' t be depending on this newly deployed one . <nl>  <nl> plugins . add ( p ) ; <nl> activeplugins . add ( p ) ;
public abstract class pluginmanager extends abstractmodelobject { <nl> throw e ; <nl> } <nl>  <nl> - / / run initializers <nl> - <nl> reactor r = new reactor ( initmilestone . ordering ( ) ) ; <nl> - r . addall ( new initializerfinder ( p . classloader ) . discovertasks ( r ) ) ; <nl> + r . addall ( new initializerfinder ( p . classloader ) { <nl> + @ override <nl> + protected boolean filter ( method e ) { <nl> + return e . getdeclaringclass ( ) . getclassloader ( ) ! = p . classloader | | super . filter ( e ) ; <nl> + } <nl> + } . discovertasks ( r ) ) ; <nl> new initreactorrunner ( ) . run ( r ) ; <nl> + jenkins . getinstance ( ) . refreshextensions ( ) ; <nl> } <nl>  <nl> / * * <nl> mmm a / core / src / main / java / hudson / init / initializerfinder . java <nl> ppp b / core / src / main / java / hudson / init / initializerfinder . java <nl>
public class jdkinstaller extends toolinstaller { <nl> throw new ioexception ( " unable to find the login form in " + html . asxml ( ) ) ; <nl> } <nl>  <nl> - <nl> - / / needs to modify it to use temporary file or something <nl> - <nl> / / download to a temporary file and rename it in to handle concurrency and failure correctly , <nl> file tmp = new file ( cache . getpath ( ) + " . tmp " ) ; <nl> tmp . getparentfile ( ) . mkdirs ( ) ; <nl> mmm a / test / pom . xml <nl> ppp b / test / pom . xml <nl>
public class mavenfingerprinter extends mavenreporter { <nl> * mojos perform different dependency resolution , so we need to check this for each mojo . <nl> * / <nl> public boolean postexecute ( mavenbuildproxy build , mavenproject pom , mojoinfo mojo , buildlistener listener , throwable error ) throws interruptedexception , ioexception { <nl> - <nl> - / / postbuild method as artifacts should only be added by mojos , but never removed / modified . <nl> - record ( pom . getartifacts ( ) , used ) ; <nl> + record ( pom . getartifacts ( ) , used ) ; <nl> record ( pom . getartifact ( ) , produced ) ; <nl> record ( pom . getattachedartifacts ( ) , produced ) ; <nl> - record ( pom . getgroupid ( ) + " : " + pom . getartifactid ( ) , pom . getfile ( ) , produced ) ; <nl> + record ( pom . getgroupid ( ) , pom . getfile ( ) , produced ) ; <nl>  <nl> return true ; <nl> } <nl>
public class mavenfingerprinter extends mavenreporter { <nl> * mojos perform different dependency resolution , so we need to check this for each mojo . <nl> * / <nl> public boolean postexecute ( mavenbuildproxy build , mavenproject pom , mojoinfo mojo , buildlistener listener , throwable error ) throws interruptedexception , ioexception { <nl> - <nl> - / / postbuild method as artifacts should only be added by mojos , but never removed / modified . <nl> - record ( pom . getartifacts ( ) , used ) ; <nl> + record ( pom . getartifacts ( ) , used ) ; <nl> record ( pom . getartifact ( ) , produced ) ; <nl> record ( pom . getattachedartifacts ( ) , produced ) ; <nl> - record ( pom . getgroupid ( ) + " : " + pom . getartifactid ( ) , pom . getfile ( ) , produced ) ; <nl> + record ( pom . getgroupid ( ) , pom . getfile ( ) , produced ) ; <nl>  <nl> return true ; <nl> } <nl>
<nl> - / * <nl> - * the mit license <nl> - * <nl> - * copyright ( c ) num - 2009 , sun microsystems , inc . , kohsuke kawaguchi <nl> - * <nl> - * permission is hereby granted , free of charge , to any person obtaining a copy <nl> - * of this software and associated documentation files ( the " software " ) , to deal <nl> - * in the software without restriction , including without limitation the rights <nl> - * to use , copy , modify , merge , publish , distribute , sublicense , and / or sell <nl> - * copies of the software , and to permit persons to whom the software is <nl> - * furnished to do so , subject to the following conditions : <nl> - * <nl> - * the above copyright notice and this permission notice shall be included in <nl> - * all copies or substantial portions of the software . <nl> - * <nl> - * the software is provided " as is " , without warranty of any kind , express or <nl> - * implied , including but not limited to the warranties of merchantability , <nl> - * fitness for a particular purpose and noninfringement . in no event shall the <nl> - * authors or copyright holders be liable for any claim , damages or other <nl> - * liability , whether in an action of contract , tort or otherwise , arising from , <nl> - * out of or in connection with the software or the use or other dealings in <nl> - * the software . <nl> - * / <nl> - package hudson . maven ; <nl> - <nl> - import hudson . model . abstractbuild ; <nl> - import hudson . model . buildlistener ; <nl> - import hudson . model . result ; <nl> - import hudson . tasks . buildstepdescriptor ; <nl> - import hudson . tasks . notifier ; <nl> - import hudson . tasks . buildstepmonitor ; <nl> - import hudson . launcher ; <nl> - import hudson . maven . reporters . mavenartifactrecord ; <nl> - import hudson . tasks . publisher ; <nl> - <nl> - import java . io . ioexception ; <nl> - <nl> - / * * <nl> - * { @ link publisher } for maven projects to deploy artifacts to a maven repository <nl> - * after the fact . <nl> - * <nl> - * < p > <nl> - * when a build breaks in the middle , this is a convenient way to prevent <nl> - * modules from being deployed partially . this can be combined with promoted builds <nl> - * plugin to deploy artifacts after testing , for example . <nl> - * <nl> - * @ author kohsuke kawaguchi <nl> - * / <nl> - public class mavenredeployer extends notifier { <nl> - public boolean perform ( abstractbuild < ? , ? > build , launcher launcher , buildlistener listener ) throws interruptedexception , ioexception { <nl> - mavenartifactrecord mar = build . getaction ( mavenartifactrecord . class ) ; <nl> - if ( mar = = null ) { <nl> - if ( build . getresult ( ) . isbetterthan ( result . failure ) ) { <nl> - listener . getlogger ( ) . println ( " there ' s no record of artifact information . is this really a maven build ? " ) ; <nl> - build . setresult ( result . failure ) ; <nl> - } <nl> - / / failed <nl> - return true ; <nl> - } <nl> - <nl> - listener . getlogger ( ) . println ( " <nl> - <nl> - return true ; <nl> - } <nl> - <nl> - public buildstepmonitor getrequiredmonitorservice ( ) { <nl> - return buildstepmonitor . none ; <nl> - } <nl> - <nl> - public buildstepdescriptor getdescriptor ( ) { <nl> - return descriptor ; <nl> - } <nl> - <nl> - public static final descriptorimpl descriptor = new descriptorimpl ( ) ; <nl> - <nl> - public static final class descriptorimpl extends buildstepdescriptor { <nl> - public boolean isapplicable ( class jobtype ) { <nl> - return abstractmavenproject . class . isassignablefrom ( jobtype ) ; <nl> - } <nl> - <nl> - public string getdisplayname ( ) { <nl> - return messages . mavenredeployer_displayname ( ) ; <nl> - } <nl> - } <nl> - } <nl> \ no newline at end of file
some tips : <nl> < head > <nl> < meta http - equiv = " content - type " content = " text / html ; charset = utf - 8 " > <nl> < title > changelog < / title > <nl> - < ! - - <nl> - link rel = " alternate " title = " hudson announcements " href = " https : / / hudson . dev . java . net / servlets / projectnewsrss " type = " application / rss + xml " - - > <nl> < link rel = " stylesheet " type = " text / css " href = " changelog . css " > <nl> < ! - - [ if ie ] > <nl> < style type = " text / css " > div . rate - offset { bottom : num . 2em ! important ; left : num em ! important ; } < / style > <nl>
some tips : <nl> < img src = " images / bug2 . gif " alt = " major bug " > major bug fix < img src = " images / bug . gif " alt = " bug " > bug fix <nl> < / span > < span style = " visibility : hidden " > xxxxx < / span > <nl> < / div > <nl> - < ! - - <nl> - < a href = " https : / / hudson . dev . java . net / servlets / projectnewsrss " > < img src = atom . gif border = 0 alt = " atom " > subscribe to rss feed < / a > <nl> - < / div - - > <nl>  <nl> < div id = " ratings " style = " display : none ; font - size : 120 % ; <nl> border : 1px solid black ; background - color : # eee ; padding : 0 . 5em ; margin - bottom : 1em " >
public final class mavenartifact implements serializable { <nl> this . version = a . getversion ( ) ; <nl> this . classifier = a . getclassifier ( ) ; <nl> this . type = a . gettype ( ) ; <nl> - <nl> this . filename = a . getfile ( ) . getname ( ) ; <nl> this . md5sum = util . getdigestof ( new fileinputstream ( a . getfile ( ) ) ) ; <nl> string extension ; <nl>
public class channelpinger extends computerlistener { <nl> logger . severe ( " failed to set up a ping for " + c . getname ( ) ) ; <nl> } <nl>  <nl> - <nl> - / / if we just want to keep some activity on the channel this doesn ' t <nl> - / / matter , but if we consider the ping a ' are you alive ? ' check it <nl> - / / might be useful . <nl> - / / setuppingforchannel ( channel , pinginterval ) ; <nl> + / / set up ping from both directions , so that in case of a router dropping a connection , <nl> + / / both sides can notice it and take compensation actions . <nl> + setuppingforchannel ( channel , pinginterval ) ; <nl> } <nl>  <nl> private static class setupremoteping implements callable < void , ioexception > { <nl>
final class copythread extends thread { <nl> out . close ( ) ; <nl> } <nl> } catch ( ioexception e ) { <nl> - <nl> + logger . log ( level . warning , " exception while copying in thread : " + getname ( ) , e ) ; <nl> } <nl> } <nl> }
public abstract class processtree implements iterable < osprocess > , iprocesstree , <nl>  <nl> / / local constants <nl> private final int sizeof_kinfo_proc ; <nl> - private static final int sizeof_kinfo_proc_32 = num ; <nl> - private static final int sizeof_kinfo_proc_64 = num ; / / checked on num bit mac os x . <nl> + private static final int sizeof_kinfo_proc_32 = num ; / / on num bit mac os x . <nl> + private static final int sizeof_kinfo_proc_64 = num ; / / on num bit mac os x . <nl> private final int kinfo_proc_pid_offset ; <nl> private static final int kinfo_proc_pid_offset_32 = num ; <nl> private static final int kinfo_proc_pid_offset_64 = num ;
public abstract class run < jobt extends job < jobt , runt > , runt extends run < jobt , run <nl> } <nl>  <nl> public string getentrydescription ( run entry ) { <nl> - <nl> - return null ; <nl> + return entry . getdescription ( ) ; <nl> } <nl>  <nl> public calendar getentrytimestamp ( run entry ) {
public class maven3builder extends abstractmavenbuilder implements delegatingcal <nl> if ( mavenreporters ! = null ) { <nl> for ( mavenreporter mavenreporter : mavenreporters ) { <nl> try { <nl> - <nl> / / with maven num . 0 . 2 see http : / / jira . codehaus . org / browse / mng - 4922 <nl> / / catch nosuchmethoderror if folks not using num . 0 . 2 + <nl> - mavenreporter . postexecute ( mavenbuildproxy2 , mavenproject , mojoinfo , maven3builder . listener , null ) ; <nl> + try { <nl> + mavenreporter . postexecute ( mavenbuildproxy2 , mavenproject , mojoinfo , maven3builder . listener , event . getexception ( ) ) ; <nl> + } catch ( nosuchmethoderror e ) { <nl> + mavenreporter . postexecute ( mavenbuildproxy2 , mavenproject , mojoinfo , maven3builder . listener , null ) ; <nl> + } <nl> } catch ( interruptedexception e ) { <nl> e . printstacktrace ( ) ; <nl> } catch ( ioexception e ) {
public class hudsonprivatesecurityrealm extends abstractpasswordbasedsecurityrea <nl>  <nl> / * * <nl> * show the sign up page with the data from the identity . <nl> - * <nl> - * <nl> * / <nl> @ override <nl> public httpresponse commencesignup ( final federatedidentity identity ) { <nl>
public abstract class run < jobt extends job < jobt , runt > , runt extends run < jobt , run <nl> * @ since num . 349 <nl> * / <nl> public void writelogto ( long offset , xmloutput out ) throws ioexception { <nl> - <nl> - getlogtext ( ) . writehtmlto ( offset , out . aswriter ( ) ) ; <nl> + try { <nl> + getlogtext ( ) . writehtmlto ( offset , out . aswriter ( ) ) ; <nl> + } catch ( ioexception e ) { <nl> + / / try to fall back to the old getloginputstream ( ) <nl> + / / mainly to support . gz compressed files <nl> + / / in this case , console annotation handling will be turned off . <nl> + inputstream input = getloginputstream ( ) ; <nl> + try { <nl> + ioutils . copy ( input , out . aswriter ( ) ) ; <nl> + } finally { <nl> + ioutils . closequietly ( input ) ; <nl> + } <nl> + } <nl> } <nl>  <nl> / * *
the software . <nl> < l : yui module = " button " / > <nl> < ! - - l : yui module = " editor " suffix = " - beta " / - - > <nl>  <nl> - < ! - - <nl> - < l : yui module = " treeview " / > <nl> - < link rel = " stylesheet " href = " $ { rooturl } / scripts / yui / treeview / assets / skins / sam / treeview . css " type = " text / css " / > <nl> - <nl> < script src = " $ { resurl } / scripts / hudson - behavior . js " type = " text / javascript " > < / script > <nl>  <nl> < script >
public class user extends abstractmodelobject implements accesscontrolled , savea <nl> xstream . alias ( " user " , user . class ) ; <nl> } <nl>  <nl> - / * * <nl> - * { @ link feedadapter } to produce build status summary in the feed . <nl> - * / <nl> - public static final feedadapter < run > feed_adapter = new feedadapter < run > ( ) { <nl> - public string getentrytitle ( run entry ) { <nl> - return entry + " : " + entry . getbuildstatussummary ( ) . message ; <nl> - } <nl> - <nl> - public string getentryurl ( run entry ) { <nl> - return entry . geturl ( ) ; <nl> - } <nl> - <nl> - public string getentryid ( run entry ) { <nl> - return " tag : " + entry . getparent ( ) . getname ( ) + ' : ' + entry . getid ( ) ; <nl> - } <nl> - <nl> - public string getentrydescription ( run entry ) { <nl> - <nl> - return null ; <nl> - } <nl> - <nl> - public calendar getentrytimestamp ( run entry ) { <nl> - return entry . gettimestamp ( ) ; <nl> - } <nl> - <nl> - public string getentryauthor ( run entry ) { <nl> - return mailer . descriptor ( ) . getadminaddress ( ) ; <nl> - } <nl> - } ; <nl> - <nl> - <nl> public acl getacl ( ) { <nl> final acl base = hudson . getinstance ( ) . getauthorizationstrategy ( ) . getacl ( this ) ; <nl> / / always allow a non - anonymous user full control of himself .
the software . <nl> < ! - - f : entry title = " optional " > <nl> < f : checkbox name = " parameter . optional " value = " $ { instance . optional } " / > <nl> < / f : entry - - > <nl> - < f : entry title = " $ { % description } " help = " / help / parameter / <nl> + < f : entry title = " $ { % description } " help = " / help / parameter / description . html " > <nl> < f : textarea name = " parameter . description " value = " $ { instance . description } " / > <nl> < / f : entry > <nl> < / j : jelly > <nl> \ no newline at end of file
final class splittablebuildlistener implements buildlistener , serializable { <nl> } <nl>  <nl> private object writereplace ( ) throws ioexception { <nl> - <nl> return new streambuildlistener ( logger ) ; <nl> }
<nl> - <nl> - - think about the implications of this change to workspace deletion <nl> - <nl> - - replace various " 1 . xxx " reference to the right revision when we merge this back to trunk . <nl> - <nl> - <nl> - release plan <nl> - = = = = = = = = = = = = <nl> - <nl> - 1 . have some interested users try this out <nl> - 2 . merge this to the trunk , but hide the feature . this allows plugins to be updated to use <nl> - checkpointing , in preparation of mass launch <nl> - 3 . solicit interested parties to activate this feature <nl> - 4 . soak time for stability <nl> - 5 . ship ! <nl> - <nl> - <nl> - notes <nl> - = = = = = <nl> - - serialize post build steps , like computing test results , since they depend on the previous result . <nl> - we need some way to mark the build steps that need this service , in a way that preserves compatibility . <nl> - - > added check pointing <nl> - <nl> - - serialize the changelog calculation . how do we handle backward compatibility ? <nl> - - > it turns out that cvsscm doesn ' t need checkpointing for this , because it uses a timestamp . <nl> - <nl> - - think about the implications of this change to polling <nl> - - > introduced workspacelist to control the lock . <nl> - <nl> - - figure out what to do with abstractproject . getworkspaceresource ( ) . i just removed it from <nl> - abstractproject . getresourcelist ( ) but this will break the lock mechanism with scm polling , tagging , and <nl> - other related activities that require a workspace . <nl> - - > the way polling is now done should be followed by everyone else who needs to lock the workspace . <nl> - <nl> - - how to preserve the compatibility with earlier plugins ? <nl> - ( in a way that doesn ' t carry the burdern forever mmm marker interface , abstract method ? ) <nl> - <nl> - it should force the build step to wait until the previous build completes . <nl> - <nl> - - > new method on the interface , which maintains binary compatibility but not source compatibilit .
the software . <nl> - - > <nl> < ? jelly escape - by - default = ' true ' ? > <nl> < j : jelly xmlns : j = " jelly : core " xmlns : st = " jelly : stapler " xmlns : d = " jelly : define " xmlns : l = " / lib / layout " xmlns : t = " / lib / hudson " xmlns : f = " / lib / form " xmlns : i = " jelly : fmt " > <nl> - < ! - - <nl> - < ! - - < j : when test = " $ { h . currentuser = = it or h . haspermission ( app . administer ) } " > - - > <nl> < l : layout norefresh = " true " permission = " $ { app . administer } " title = " $ { % title ( it . fullname ) } " > <nl> < st : include page = " sidepanel . jelly " / > <nl> < l : main - panel > <nl>
public class listview extends view { <nl> try { <nl> r . add ( des . newinstance ( null , null ) ) ; <nl> } catch ( formexception e ) { <nl> - <nl> + logger . log ( level . warning , " failed to instantiate " + des . clazz , e ) ; <nl> } <nl> - <nl> } <nl> } <nl> return collections . unmodifiablelist ( r ) ; <nl>
public / * transient * / abstract class computer extends actionable implements acces <nl> * accepts the update to the node configuration . <nl> * / <nl> public void doconfigsubmit ( staplerrequest req , staplerresponse rsp ) throws ioexception , servletexception , formexception { <nl> - checkpermission ( hudson . administer ) ; <nl> + checkpermission ( configure ) ; <nl>  <nl> final hudson app = hudson . getinstance ( ) ; <nl>  <nl> mmm a / core / src / main / java / hudson / model / hudson . java <nl> ppp b / core / src / main / java / hudson / model / hudson . java <nl>
public class queue extends resourcecontroller implements saveable { <nl> logger . fine ( p . getfulldisplayname ( ) + " added to queue " ) ; <nl>  <nl> / / put the item in the queue <nl> - waitinglist . add ( added = new waitingitem ( due , p , actions ) ) ; <nl> - } else { <nl> - / / the requested build is already queued , so will not be added <nl> - added = null ; <nl> - <nl> - for ( item item : duplicatesinqueue ) { <nl> - for ( foldableaction a : util . filter ( actions , foldableaction . class ) ) { <nl> - a . foldintoexisting ( item . task , item . getactions ( ) ) ; <nl> - } <nl> - } <nl> + waitingitem added = new waitingitem ( due , p , actions ) ; <nl> + waitinglist . add ( added ) ; <nl> + schedulemaintenance ( ) ; / / let an executor know that a new item is in the queue . <nl> + return added ; <nl> + } <nl>  <nl> - <nl> - / / actually change <nl> - for ( waitingitem wi : util . filter ( duplicatesinqueue , waitingitem . class ) ) { <nl> - if ( quietperiod < = 0 ) { <nl> - / / the user really wants to build now , and they mean now . <nl> - / / so let ' s pull in the timestamp if we can . <nl> - if ( wi . timestamp . before ( due ) ) <nl> - continue ; <nl> - } else { <nl> - / / otherwise we do the normal quiet period implementation <nl> - if ( wi . timestamp . after ( due ) ) <nl> - continue ; <nl> - / / quiet period timer reset . start the period over again <nl> - } <nl> + logger . fine ( p . getfulldisplayname ( ) + " is already in the queue " ) ; <nl>  <nl> - / / waitinglist is sorted , so when we change a timestamp we need to maintain order <nl> - waitinglist . remove ( wi ) ; <nl> - wi . timestamp = due ; <nl> - waitinglist . add ( wi ) ; <nl> - } <nl> + / / but let the actions affect the existing stuff . <nl> + for ( item item : duplicatesinqueue ) { <nl> + for ( foldableaction a : util . filter ( actions , foldableaction . class ) ) { <nl> + a . foldintoexisting ( item . task , item . getactions ( ) ) ; <nl> + } <nl> + } <nl>  <nl> - } <nl> - schedulemaintenance ( ) ; / / let an executor know that a new item is in the queue . <nl> - return added ; <nl> + boolean queueupdated = false ; <nl> + for ( waitingitem wi : util . filter ( duplicatesinqueue , waitingitem . class ) ) { <nl> + if ( quietperiod < = 0 ) { <nl> + / / the user really wants to build now , and they mean now . <nl> + / / so let ' s pull in the timestamp if we can . <nl> + if ( wi . timestamp . before ( due ) ) <nl> + continue ; <nl> + } else { <nl> + / / otherwise we do the normal quiet period implementation <nl> + if ( wi . timestamp . after ( due ) ) <nl> + continue ; <nl> + / / quiet period timer reset . start the period over again <nl> + } <nl> + <nl> + / / waitinglist is sorted , so when we change a timestamp we need to maintain order <nl> + waitinglist . remove ( wi ) ; <nl> + wi . timestamp = due ; <nl> + waitinglist . add ( wi ) ; <nl> + queueupdated = true ; <nl> + } <nl> + <nl> + if ( queueupdated ) schedulemaintenance ( ) ; <nl> + return null ; <nl> } <nl>  <nl> / * *
public final class testresult extends metatabulatedresult { <nl> return messages . testresult_getchildtitle ( ) ; <nl> } <nl>  <nl> - <nl> + @ exported ( visibility = 999 ) <nl> public float getduration ( ) { <nl> return duration ; <nl> } <nl>
public abstract class processtree implements iterable < osprocess > { <nl> return r ; <nl> } <nl>  <nl> - <nl> - / / / * * <nl> - / / * kills this process . <nl> - / / * / <nl> - / / public abstract void kill ( ) ; <nl> + / * * <nl> + * kills this process . <nl> + * / <nl> + public abstract void kill ( ) ; <nl>  <nl> / * * <nl> * kills this process and all the descendants . <nl>
<nl> package hudson ; <nl>  <nl> import junit . framework . testcase ; <nl> + import hudson . remoting . channel ; <nl> + import hudson . util . nullstream ; <nl> + <nl> + import java . io . pipedinputstream ; <nl> + import java . io . pipedoutputstream ; <nl> + import java . io . file ; <nl> + import java . util . concurrent . executorservice ; <nl> + import java . util . concurrent . executors ; <nl> + import java . util . concurrent . callable ; <nl> + import java . util . concurrent . future ; <nl>  <nl> / * * <nl> * @ author kohsuke kawaguchi <nl> * / <nl> - public class filepathtest extends / * rmitestbase * / testcase { <nl> - public void testdummy ( ) { <nl> - <nl> - / / currently it fails because the remoting . jar is signed but <nl> - / / test code is not . <nl> + public class filepathtest extends testcase { <nl> + / * * <nl> + * two channels that are connected to each other , but shares the same classloader . <nl> + * / <nl> + private channel french , british ; <nl> + private executorservice executors = executors . newcachedthreadpool ( ) ; <nl> + <nl> + @ override <nl> + protected void setup ( ) throws exception { <nl> + super . setup ( ) ; <nl> + final pipedinputstream p1i = new pipedinputstream ( ) ; <nl> + final pipedinputstream p2i = new pipedinputstream ( ) ; <nl> + final pipedoutputstream p1o = new pipedoutputstream ( p1i ) ; <nl> + final pipedoutputstream p2o = new pipedoutputstream ( p2i ) ; <nl> + <nl> + future < channel > f1 = executors . submit ( new callable < channel > ( ) { <nl> + public channel call ( ) throws exception { <nl> + return new channel ( " this side of the channel " , executors , p1i , p2o ) ; <nl> + } <nl> + } ) ; <nl> + future < channel > f2 = executors . submit ( new callable < channel > ( ) { <nl> + public channel call ( ) throws exception { <nl> + return new channel ( " the other side of the channel " , executors , p2i , p1o ) ; <nl> + } <nl> + } ) ; <nl> + french = f1 . get ( ) ; <nl> + british = f2 . get ( ) ; <nl> + } <nl> + <nl> + @ override <nl> + protected void teardown ( ) throws exception { <nl> + french . close ( ) ; <nl> + british . close ( ) ; <nl> + french . join ( ) ; <nl> + british . join ( ) ; <nl> + executors . shutdown ( ) ; <nl> + } <nl> + <nl> + public void testcopyto ( ) throws exception { <nl> + file tmp = file . createtempfile ( " tmp " , " " ) ; <nl> + filepath f = new filepath ( french , tmp . getpath ( ) ) ; <nl> + f . copyto ( new nullstream ( ) ) ; <nl> } <nl>  <nl> - / / / * * <nl> - / / * copy zero files . <nl> - / / * / <nl> - / / public void testemptycopy ( ) throws exception { <nl> - / / file src = util . createtempdir ( ) ; <nl> - / / file dst = util . createtempdir ( ) ; <nl> - / / src . deleteonexit ( ) ; <nl> - / / dst . deleteonexit ( ) ; <nl> - / / <nl> - / / new filepath ( src ) . copyrecursiveto ( " * * / * " , new filepath ( channel , dst . getpath ( ) ) ) ; <nl> - / / } <nl> } <nl> mmm a / remoting / src / main / java / hudson / remoting / proxyoutputstream . java <nl> ppp b / remoting / src / main / java / hudson / remoting / proxyoutputstream . java <nl>
<nl> # out of or in connection with the software or the use or other dealings in <nl> # the software . <nl>  <nl> - # <nl> - newversionavailable = hudson \ u306e \ u65b0 \ u3057 \ u3044 \ u30d0 \ u30fc \ u30b8 \ u30e7 \ u30f3 ( { 0 } ) \ u3092 < a href = " { 1 } " > \ u30c0 \ u30a6 \ u30f3 \ u30ed \ u30fc \ u30c9 < / a > \ u3067 \ u304d \ u307e \ u3059 \ u3002 <nl> - or \ upgrade \ automatically = \ u3082 \ u3057 \ u304f \ u306f \ u3001 \ u81ea \ u52d5 \ u66f4 \ u65b0 \ u3057 \ u307e \ u3059 \ u304b ? <nl> \ no newline at end of file <nl> + newversionavailable = hudson \ u306e \ u65b0 \ u3057 \ u3044 \ u30d0 \ u30fc \ u30b8 \ u30e7 \ u30f3 ( { 0 } ) \ u3092 < a href = " { 1 } " > \ u30c0 \ u30a6 \ u30f3 \ u30ed \ u30fc \ u30c9 < / a > \ u3067 \ u304d \ u307e \ u3059 \ <nl> + ( < a href = " https : / / hudson . dev . java . net / changelog . html " > \ u5909 \ u66f4 \ u5c65 \ u6b74 < / a > ) \ u3002
public class queue extends resourcecontroller implements saveable { <nl> / * * <nl> * unique name of this task . <nl> * <nl> - * @ see hudson . model . item # getname ( ) <nl> - * <nl> + * < p > <nl> + * this method is no longer used , left here for compatibility . just return { @ link # getdisplayname ( ) } . <nl> * / <nl> string getname ( ) ; <nl>  <nl>
public abstract class computer extends abstractmodelobject implements accesscont <nl> return true ; <nl> } <nl>  <nl> - <nl> - public static final permission configure = hudson . configure ; <nl> - public static final permission delete = hudson . delete ; <nl> + public static final permissiongroup permissions = new permissiongroup ( computer . class , messages . _computer_permissions_title ( ) ) ; <nl> + / * * <nl> + * permission to create new jobs . <nl> + * / <nl> + public static final permission configure = new permission ( permissions , " configure " , messages . _computer_configurepermission_description ( ) , permission . configure ) ; <nl> + public static final permission delete = new permission ( permissions , " delete " , messages . _computer_deletepermission_description ( ) , permission . delete ) ; <nl>  <nl>  <nl> } <nl> mmm a / core / src / main / java / hudson / model / computerset . java <nl> ppp b / core / src / main / java / hudson / model / computerset . java <nl>
public final class hudson extends view implements itemgroup < toplevelitem > , node , <nl>  <nl> items . remove ( item . getname ( ) ) ; <nl> if ( views ! = null ) { <nl> - <nl> - / / for ( view v : views ) { <nl> - / / synchronized ( v ) { <nl> - / / v . jobnames . remove ( item . getname ( ) ) ; <nl> - / / } <nl> - / / } <nl> + for ( view v : views ) <nl> + v . onjobchange ( item , item . getname ( ) , null ) ; <nl> save ( ) ; <nl> } <nl> } <nl>
public final class hudson extends view implements itemgroup < toplevelitem > , node , <nl> items . put ( newname , job ) ; <nl>  <nl> if ( views ! = null ) { <nl> - <nl> - / / for ( view v : views ) { <nl> - / / synchronized ( v ) { <nl> - / / if ( v . jobnames . remove ( oldname ) ) <nl> - / / v . jobnames . add ( newname ) ; <nl> - / / } <nl> - / / } <nl> + for ( view v : views ) <nl> + v . onjobchange ( job , oldname , newname ) ; <nl> save ( ) ; <nl> } <nl> } <nl> mmm a / core / src / main / java / hudson / model / listview . java <nl> ppp b / core / src / main / java / hudson / model / listview . java <nl>
import java . util . list ; <nl> import java . util . arraylist ; <nl>  <nl> / * * <nl> - * <nl> + * monitors the memory usage of the system in os specific way . <nl> + * <nl> * @ author kohsuke kawaguchi <nl> * / <nl> public class memoryusagemonitor extends safetimertask {
public class windowsservicelifecycle extends lifecycle { <nl> } <nl> } <nl>  <nl> + @ override <nl> public void rewritehudsonwar ( file by ) throws ioexception { <nl> - <nl> - throw new unsupportedoperationexception ( ) ; <nl> + file rootdir = hudson . getinstance ( ) . getrootdir ( ) ; <nl> + file copyfiles = new file ( rootdir , " hudson . copies " ) ; <nl> + <nl> + filewriter w = new filewriter ( copyfiles , true ) ; <nl> + w . write ( by . getabsolutepath ( ) + ' > ' + gethudsonwar ( ) . getabsolutepath ( ) + ' \n ' ) ; <nl> + w . close ( ) ; <nl> } <nl>  <nl> public void restart ( ) throws ioexception , interruptedexception {
public class subversionscmtest extends hudsontestcase { <nl> subversiontagaction action = b . getaction ( subversiontagaction . class ) ; <nl> assertfalse ( b . haspermission ( action . getpermission ( ) ) ) ; <nl>  <nl> - <nl> + webclient wc = new webclient ( ) ; <nl> + htmlpage html = wc . getpage ( b ) ; <nl> + <nl> + / / make sure there ' s no link to the ' tag this build ' <nl> + document dom = new domreader ( ) . read ( html ) ; <nl> + assertnull ( dom . selectsinglenode ( " / / a [ text ( ) = ' tag this build ' ] " ) ) ; <nl> + for ( htmlanchor a : html . getanchors ( ) ) <nl> + assertfalse ( a . gethrefattribute ( ) . contains ( " / tagbuild / " ) ) ; <nl> + <nl> + / / and that tagging would fail <nl> + html = wc . getpage ( b , " tagbuild / " ) ; <nl> + htmlform form = html . getformbyname ( " tag " ) ; <nl> + try { <nl> + form . submit ( ( htmlbutton ) last ( form . gethtmlelementsbytagname ( " button " ) ) ) ; <nl> + fail ( " should have been denied " ) ; <nl> + } catch ( failinghttpstatuscodeexception e ) { <nl> + / / make sure the request is denied <nl> + assertequals ( e . getresponse ( ) . getstatuscode ( ) , 403 ) ; <nl> + } <nl> + <nl> + / / now login as alice and make sure that the tagging would succeed <nl> + wc = new webclient ( ) ; <nl> + wc . login ( " alice " , " alice " ) ; <nl> + html = wc . getpage ( b , " tagbuild / " ) ; <nl> + form = html . getformbyname ( " tag " ) ; <nl> + form . submit ( ( htmlbutton ) last ( form . gethtmlelementsbytagname ( " button " ) ) ) ; <nl> } <nl> }
public final class caseresult extends testobject implements comparable < caseresul <nl> / * * <nl> * gets the duration of the test , in seconds <nl> * / <nl> - <nl> + @ exported <nl> public float getduration ( ) { <nl> return duration ; <nl> }
public final class slavecomputer extends computer { <nl> launcher = ( ( slave ) node ) . getlauncher ( ) ; <nl>  <nl> / / maybe the configuration was changed to relaunch the slave , so try to re - launch now . <nl> - / / launch ( ) ; this can cause a partially constructed object to leak out of the constructor <nl> - <nl> + launch ( ) ; <nl> } <nl>  <nl> private static final logger logger = logger . getlogger ( slavecomputer . class . getname ( ) ) ;
public class mavenartifactarchiver extends mavenreporter { <nl> attachedartifacts . add ( ma ) ; <nl> } <nl> } <nl> - <nl> - final boolean installed = this . installed ; <nl> - <nl> - build . executeasync ( new buildcallable < void , ioexception > ( ) { <nl> - public void call ( mavenbuild build ) throws ioexception , interruptedexception { <nl> - mavenartifactrecord mar = new mavenartifactrecord ( build , pomartifact , mainartifact , attachedartifacts ) ; <nl> - build . addaction ( mar ) ; <nl> - <nl> - mar . recordfingerprints ( ) ; <nl> - <nl> - / / install files on the master <nl> - if ( installed ) { <nl> - try { <nl> - mar . install ( listener ) ; <nl> - } catch ( mavenembedderexception e ) { <nl> - e . printstacktrace ( listener . error ( hudson . maven . reporters . messages . mavenartifactarchiver_failedtoinstalltomaster ( ) ) ) ; <nl> - build . setresult ( result . failure ) ; <nl> - } catch ( componentlookupexception e ) { <nl> - e . printstacktrace ( listener . error ( messages . mavenartifactarchiver_failedtoinstalltomaster ( ) ) ) ; <nl> - build . setresult ( result . failure ) ; <nl> - } catch ( artifactinstallationexception e ) { <nl> - e . printstacktrace ( listener . error ( messages . mavenartifactarchiver_failedtoinstalltomaster ( ) ) ) ; <nl> - build . setresult ( result . failure ) ; <nl> - } <nl> - } <nl> - <nl> - return null ; <nl> - } <nl> - } ) ; <nl> } <nl>  <nl> return true ;
public class aggregatedtestresultpublisher extends publisher { <nl> } <nl>  <nl> public string getdisplayname ( ) { <nl> - return " aggregate downstream test results " ; <nl> + return messages . aggregatedtestresultpublisher_displayname ( ) ; <nl> } <nl>  <nl> public void docheck ( staplerrequest req , staplerresponse rsp , @ queryparameter ( " value " ) final string list ) throws ioexception , servletexception { <nl> mmm a / core / src / main / resources / hudson / tasks / test / messages . properties <nl> ppp b / core / src / main / resources / hudson / tasks / test / messages . properties <nl>
import org . kohsuke . stapler . export . exported ; <nl> * / <nl> @ exportedbean <nl> public final class computerset implements modelobject { <nl> - private static volatile list < nodemonitor > monitors = collections . emptylist ( ) ; <nl> - <nl> - public computerset ( ) { <nl> - if ( monitors . isempty ( ) ) { <nl> - / / create all instances when requested for the first time . <nl> - arraylist < nodemonitor > r = new arraylist < nodemonitor > ( ) ; <nl> - for ( descriptor < nodemonitor > d : nodemonitor . list ) <nl> - try { <nl> - r . add ( d . newinstance ( null , null ) ) ; <nl> - } catch ( formexception e ) { <nl> - <nl> - } <nl> - monitors = r ; <nl> - } <nl> - } <nl> + private static final list < nodemonitor > monitors ; <nl>  <nl> @ exported <nl> public string getdisplayname ( ) { <nl>
public class matrixproject extends abstractproject < matrixproject , matrixbuild > im <nl> } <nl>  <nl> protected void builddependencygraph ( dependencygraph graph ) { <nl> - <nl> + graph . adddependencydeclarers ( this , publishers ) ; <nl> } <nl>  <nl> public matrixproject asproject ( ) { <nl> mmm a / core / src / main / java / hudson / model / dependencygraph . java <nl> ppp b / core / src / main / java / hudson / model / dependencygraph . java <nl>
public abstract class project < p extends project < p , b > , b extends build < p , b > > <nl> return null ; <nl> } <nl>  <nl> - <nl> - private void _builddependencygraph ( collection < ? > possibledependecydeclarers , dependencygraph graph ) { <nl> - for ( object o : possibledependecydeclarers ) { <nl> - if ( o instanceof dependecydeclarer ) { <nl> - dependecydeclarer dd = ( dependecydeclarer ) o ; <nl> - dd . builddependencygraph ( this , graph ) ; <nl> - } <nl> - } <nl> - } <nl> - <nl> protected void builddependencygraph ( dependencygraph graph ) { <nl> - _builddependencygraph ( publishers , graph ) ; <nl> - _builddependencygraph ( builders , graph ) ; <nl> - _builddependencygraph ( buildwrappers , graph ) ; <nl> + graph . adddependencydeclarers ( this , publishers ) ; <nl> + graph . adddependencydeclarers ( this , builders ) ; <nl> + graph . adddependencydeclarers ( this , buildwrappers ) ; <nl> } <nl>  <nl> @ override <nl> mmm a / core / src / main / resources / hudson / matrix / matrixproject / index . jelly <nl> ppp b / core / src / main / resources / hudson / matrix / matrixproject / index . jelly <nl>
final class exporttable < t > { <nl> * the assigned ' object id ' . if the object is already exported , <nl> * it will return the id already assigned to it . <nl> * / <nl> - <nl> public synchronized int export ( t t ) { <nl> if ( t = = null ) return num ; / / bootstrap classloader <nl>  <nl> - integer id = reverse . get ( t ) ; <nl> - if ( id = = null ) { <nl> - id = iota + + ; <nl> - table . put ( id , new entry < t > ( t ) ) ; <nl> - reverse . put ( t , id ) ; <nl> - } <nl> + entry < t > e = reverse . get ( t ) ; <nl> + if ( e = = null ) <nl> + e = new entry < t > ( this , t ) ; <nl> + else <nl> + e . addref ( ) ; <nl>  <nl> - return id ; <nl> + return e . id ; <nl> } <nl>  <nl> public synchronized t get ( int id ) { <nl>
public class channel implements virtualchannel { <nl> * { @ inheritdoc } <nl> * / <nl> public synchronized void close ( ) throws ioexception { <nl> - / / make sure no other commands get executed in between . <nl> - if ( closed ) return ; <nl> - if ( closing ) return ; <nl> - closing = true ; <nl> + if ( outclosed ) return ; / / already closed <nl>  <nl> send ( new closecommand ( ) ) ; <nl> - oos . close ( ) ; <nl> + outclosed = true ; / / last command sent . no further command allowed . lock guarantees that no command will slip inbetween <nl> + try { <nl> + oos . close ( ) ; <nl> + } catch ( ioexception e ) { <nl> + / / there ' s a race condition here . <nl> + / / the remote peer might have already responded to the close command <nl> + / / and closed the connection , in which case our close invocation <nl> + / / could fail with errors like <nl> + / / " java . io . ioexception : the pipe is being closed " <nl> + / / so let ' s ignore this error . <nl> + } <nl>  <nl> - <nl> - terminate ( null ) ; <nl> + / / termination is done by closecommand when we received it . <nl> } <nl>  <nl> public string tostring ( ) { <nl>
public class matrixbuild extends abstractbuild < matrixproject , matrixbuild > { <nl> matrixproject p = getproject ( ) ; <nl> printstream logger = listener . getlogger ( ) ; <nl>  <nl> - for ( matrixconfiguration c : p . getactiveconfigurations ( ) ) { <nl> + collection < matrixconfiguration > activeconfigurations = p . getactiveconfigurations ( ) ; <nl> + <nl> + for ( matrixconfiguration c : activeconfigurations ) { <nl> logger . println ( " triggering " + c . getname ( ) ) ; <nl> c . schedulebuild ( ) ; <nl> } <nl>  <nl> - <nl> - <nl> + / / this occupies an executor unnecessarily . <nl> + / / it would be nice if this can be placed in a temproary executor . <nl> + <nl> + int n = getnumber ( ) ; <nl> + for ( matrixconfiguration c : activeconfigurations ) { <nl> + / / wait for the completion <nl> + while ( true ) { <nl> + matrixrun b = c . getbuildbynumber ( n ) ; <nl> + if ( b ! = null & & ! b . isbuilding ( ) ) <nl> + break ; <nl> + thread . sleep ( 1000 ) ; <nl> + } <nl> + } <nl> + <nl> return result . success ; <nl> } <nl>  <nl>
import java . io . serializable ; <nl> * in { @ link mavenbuild } later . <nl> * <nl> * < p > <nl> - * <nl> - * because builds may happen on a remote slave node , { @ link mavenreporter } <nl> - * implementation needs . . . <nl> + * { @ link mavenreporter } is first instanciated on the master . <nl> + * then during the build , it is serialized and sent over into <nl> + * the maven process by serialization . reporters will then receive <nl> + * event callbacks as mojo execution progresses . those event callbacks <nl> + * are the ones that take { @ link mavenbuildproxy } . <nl> + * <nl> + * < p > <nl> + * once the maven build completes normally or abnormally , the reporters <nl> + * will be sent back to the master by serialization again , then <nl> + * have its { @ link # end ( mavenbuild , launcher , buildlistener ) } method invoked . <nl> + * this is a good opportunity to perform the post - build action . <nl> * <nl> * < p > <nl> * this is the { @ link mavenbuild } equivalent of { @ link buildstep } . instances
public abstract class launcher { <nl> public channel launchchannel ( string [ ] cmd , outputstream out , filepath workdir ) throws ioexception { <nl> printcommandline ( cmd , workdir ) ; <nl>  <nl> - process proc = runtime . getruntime ( ) . exec ( cmd , null , tofile ( workdir ) ) ; <nl> - <nl> - <nl> + final process proc = runtime . getruntime ( ) . exec ( cmd , null , tofile ( workdir ) ) ; <nl>  <nl> thread t2 = new streamcopythread ( cmd + " : stderr copier " , proc . geterrorstream ( ) , out ) ; <nl> t2 . start ( ) ; <nl>  <nl> return new channel ( " locally launched channel on " + cmd , <nl> - computer . threadpoolforremoting , proc . getinputstream ( ) , proc . getoutputstream ( ) , out ) ; <nl> + computer . threadpoolforremoting , proc . getinputstream ( ) , proc . getoutputstream ( ) , out ) { <nl> + <nl> + / * * <nl> + * kill the process when the channel is severed . <nl> + * / <nl> + protected synchronized void terminate ( ioexception e ) { <nl> + super . terminate ( e ) ; <nl> + proc . destroy ( ) ; <nl> + } <nl> + } ; <nl> } <nl>  <nl> / * *
public abstract class scm implements describable < scm > , extensionpoint { <nl> * / <nl> public abstract boolean checkout ( abstractbuild build , launcher launcher , filepath workspace , buildlistener listener , file changelogfile ) throws ioexception , interruptedexception ; <nl>  <nl> - / * * <nl> - * checks out ( or updates ) the code into the workspace , but without computing changelog . <nl> - * <nl> - * <nl> - * come back and check if this abstraction is really making much sense . <nl> - * / <nl> - public abstract boolean checkout ( launcher launcher , filepath workspace , tasklistener listener ) throws ioexception , interruptedexception ; <nl> - <nl> / * * <nl> * adds environmental variables for the builds to the given map . <nl> * /
<nl> ( run cvs in a way compatible with older versions of hudson & lt ; 1 . 21 ) <nl> < / f : entry > <nl>  <nl> - < ! - - <nl> - < f : dropdownlist name = " cvs . browser " title = " repository browser " > <nl> - < f : dropdownlistblock value = " auto " title = " ( auto ) " / > <nl> - < j : set var = " currentbrowser " value = " $ { scm . browser } " / > <nl> - < j : foreach var = " d " items = " $ { scmd . browserdescriptors } " varstatus = " loop " > <nl> - < f : dropdownlistblock value = " $ { loop . index } " title = " $ { d . displayname } " selected = " $ { currentbrowser . descriptor = = d } " > <nl> - < f : nested > <nl> - < table width = " 100 % " > <nl> - < j : set var = " browser " value = " $ { h . ifthenelse ( currentbrowser . descriptor = = d , currentbrowser , null ) } " / > <nl> - < st : include from = " $ { d } " page = " $ { d . configpage } " / > <nl> - < / table > <nl> - < / f : nested > <nl> - < / f : dropdownlistblock > <nl> - < / j : foreach > <nl> - < / f : dropdownlist > <nl> + < t : listscmbrowsers name = " cvs . browser " / > <nl> < / j : jelly > <nl> \ no newline at end of file <nl> mmm a / core / src / main / resources / hudson / scm / subversionscm / config . jelly <nl> ppp b / core / src / main / resources / hudson / scm / subversionscm / config . jelly <nl>
public abstract class abstractproject < p extends abstractproject < p , r > , r extends a <nl> return true ; <nl> } <nl>  <nl> - <nl> - return scm . pollchanges ( this , new locallauncher ( listener ) , workspace , listener ) ; <nl> + return scm . pollchanges ( this , workspace . createlauncher ( listener ) , workspace , listener ) ; <nl> } catch ( ioexception e ) { <nl> e . printstacktrace ( listener . fatalerror ( e . getmessage ( ) ) ) ; <nl> return false ;
public class mavenbuild extends abstractbuild < mavenmodule , mavenbuild > { <nl> / / m2_home <nl> args . add ( mvn . getmavenhome ( ) ) ; <nl>  <nl> - / / remoting . jar <nl> args . add ( launcher . getchannel ( ) . call ( new getremotingjar ( ) ) ) ; <nl> / / interceptor . jar <nl> args . add ( ismaster ?
public class mavenbuild extends abstractbuild < mavenmodule , mavenbuild > { <nl> if ( classworlds = = null | | classworlds . length = = 0 ) <nl> throw new ioexception ( " no classworlds * . jar found in " + bootdir ) ; <nl>  <nl> + boolean ismaster = getcurrentnode ( ) = = hudson . getinstance ( ) ; <nl> + filepath slaveroot = null ; <nl> + if ( ! ismaster ) <nl> + slaveroot = ( ( slave ) getcurrentnode ( ) ) . getfilepath ( ) ; <nl>  <nl> argumentlistbuilder args = new argumentlistbuilder ( ) ; <nl> args . add ( launcher . getchannel ( ) . call ( new getjavaexe ( ) ) ) ; <nl> args . add ( " - cp " ) ; <nl> - args . add ( which . jarfile ( main . class ) + <nl> + args . add ( <nl> + ( ismaster ? which . jarfile ( main . class ) . getabsolutepath ( ) : slaveroot . child ( " maven - agent . jar " ) . getremote ( ) ) + <nl> ( launcher . isunix ( ) ? " : " : " ; " ) + <nl> - classworlds [ 0 ] . getabsolutepath ( ) ) ; <nl> + classworlds [ 0 ] . getabsolutepath ( ) ) ; <nl> args . add ( main . class . getname ( ) ) ; <nl>  <nl> / / m2_home <nl>
public final class mavenmoduleset extends abstractproject < mavenmoduleset , mavenmo <nl> * gets the workspace of this job . <nl> * / <nl> public filepath getworkspace ( ) { <nl> - <nl> - return hudson . getinstance ( ) . getworkspacefor ( this ) ; <nl> + node node = getlastbuilton ( ) ; <nl> + if ( node = = null ) node = hudson . getinstance ( ) ; <nl> + return node . getworkspacefor ( this ) ; <nl> } <nl>  <nl> @ override <nl>
<nl> - < j : jelly xmlns : j = " jelly : core " xmlns : st = " jelly : stapler " xmlns : d = " jelly : define " xmlns : l = " / lib / layout " xmlns : t = " / lib / hudson " xmlns : f = " / lib / form " xmlns : i = " jelly : fmt " > <nl> - < l : header title = " $ { it . name } " > <nl> - < ! - - <nl> - < / l : header > <nl> - < l : side - panel > <nl> - < l : tasks > <nl> - < j : set var = " url " value = " $ { h . getnearestancestorurl ( request , it ) } " / > <nl> - < l : task icon = " images / 24x24 / up . gif " href = " $ { rooturl } / " title = " back to dashboard " / > <nl> - < l : task icon = " images / 24x24 / search . gif " href = " $ { url } / " title = " status " / > <nl> - < l : task icon = " images / 24x24 / notepad . gif " href = " $ { url } / changes " title = " changes " / > <nl> - < l : task icon = " images / 24x24 / folder . gif " href = " $ { url } / ws / " title = " workspace " / > <nl> - < l : isadmin > <nl> - < j : if test = " $ { ! it . disabled } " > <nl> - < l : task icon = " images / 24x24 / clock . gif " href = " $ { url } / build " title = " build now " / > <nl> - < / j : if > <nl> - < l : task icon = " images / 24x24 / edit - delete . gif " href = " $ { url } / delete " title = " delete project " / > <nl> - < l : task icon = " images / 24x24 / setting . gif " href = " $ { url } / configure " title = " configure " / > <nl> - < / l : isadmin > <nl> - < st : include page = " actions . jelly " / > <nl> - < / l : tasks > <nl> - < st : include page = " buildhistory . jelly " / > <nl> - < / l : side - panel > <nl> - < / j : jelly > <nl> \ no newline at end of file
public final class mavenmodulesetbuild extends abstractbuild < mavenmoduleset , mave <nl> } <nl>  <nl> public void post ( buildlistener listener ) { <nl> - <nl> - / / select the right modules to build based on changelog <nl> } <nl> } <nl> }
import java . io . ioexception ; <nl> / * * <nl> * used to load { @ link item } implementation . <nl> * <nl> - * <nl> - * <nl> - * <nl> * @ author kohsuke kawaguchi <nl> * / <nl> public final class itemloader {
public interface item extends persistenceroot { <nl>  <nl> / * * <nl> * gets all the jobs that this { @ link item } contains as descendants . <nl> - * <nl> - * <nl> * / <nl> abstract collection < ? extends job > getalljobs ( ) ;
import java . util . collection ; <nl> * this uniqueness is also used for allocating file system storage <nl> * for each { @ link item } . <nl> * <nl> - * <nl> - * <nl> * @ author kohsuke kawaguchi <nl> * / <nl> public interface item extends persistenceroot {
public class cvsscm extends abstractcvsfamilyscm implements serializable { <nl> dir . deletecontents ( ) ; <nl>  <nl> argumentlistbuilder cmd = new argumentlistbuilder ( ) ; <nl> - <nl> - cmd . add ( " cvs " , " - q " , " - z9 " , " - d " , cvsroot , " co " ) ; <nl> + cmd . add ( " cvs " , debuglogging ? " - t " : " - q " , " - z9 " , " - d " , cvsroot , " co " ) ; <nl> if ( branch ! = null ) <nl> cmd . add ( " - r " , branch ) ; <nl> if ( flatten )
public final class build extends run < project , build > implements runnable { <nl> } <nl>  <nl> @ override <nl> - public boolean iskeeplog ( ) { <nl> + public string getwhykeeplog ( ) { <nl> / / if any of the downstream project is configured with ' keep dependency component ' , <nl> / / we need to keep this log <nl> - for ( map . entry < project , rangeset > e : getdownstreambuilds ( ) . entryset ( ) ) { <nl> + for ( map . entry < project , rangeset > e : getdownstreambuilds ( ) . entryset ( ) ) { <nl> project p = e . getkey ( ) ; <nl> if ( ! p . iskeepdependencies ( ) ) continue ; <nl>  <nl> / / is there any active build that depends on us ? <nl> for ( build build : p . getbuilds ( ) ) { <nl> if ( e . getvalue ( ) . includes ( build . getnumber ( ) ) ) <nl> - return true ; / / yep . an active build depends on us . can ' t recycle . <nl> + return " kept because of " + build ; <nl> } <nl> } <nl> - <nl> - <nl> - return super . iskeeplog ( ) ; <nl> + <nl> + return super . getwhykeeplog ( ) ; <nl> } <nl>  <nl> / * * <nl> mmm a / core / src / main / java / hudson / model / run . java <nl> ppp b / core / src / main / java / hudson / model / run . java <nl>
public class linuxptytest extends abstractptytest { <nl> ptysession dies = <nl> pty . getchild ( ) . session ( new string [ ] { " thishadbetternotexist " } , null ) ; <nl> / * * <nl> - * note : java subprocess dies with code num on unhandled exception . <nl> - * way to distinguish whether the code is from java or the execed image ? <nl> + * choice of num is based on bash setting " exit code " to num for " command not found " <nl> * / <nl> - assertequals ( 1 , dies . waitexited ( ) ) ; <nl> + assertequals ( 127 , dies . waitexited ( ) ) ; <nl> } <nl> }
public class decompilerdatatypereferencefinder implements datatypereferencefinde <nl> else { <nl> debugwriter = new nullprintwriter ( ) ; <nl> } <nl> - <nl> - <nl> - / / failure . this code can be deleted if the test failures do not reappear . <nl> - debugwriter = new nullprintwriter ( ) ; <nl> } <nl>  <nl> list < datatypereference > findusage ( ) {
public class peutil { <nl> program . getcompiler ( ) . equals ( compilerenum . clang . tostring ( ) ) ) ; <nl> } <nl>  <nl> - <nl> - <nl> - / / static datatype getactualtype ( datatype datatype ) { <nl> - / / if ( datatype instanceof typedef ) { <nl> - / / return getactualtype ( ( ( typedef ) datatype ) . getdatatype ( ) ) ; <nl> - / / } <nl> - / / return datatype ; <nl> - / / } <nl> - / / <nl> - / / static boolean isvalidpointer ( program program , address addr ) { <nl> - / / memory memory = program . getmemory ( ) ; <nl> - / / addressfactory addressfactory = program . getaddressfactory ( ) ; <nl> - / / addressspace defaultspace = addressfactory . getdefaultaddressspace ( ) ; <nl> - / / try { <nl> - / / int addrasint = memory . getint ( addr ) ; <nl> - / / address pointedtoaddr = addressfactory . getaddress ( defaultspace . getspaceid ( ) , addrasint ) ; <nl> - / / return memory . contains ( pointedtoaddr ) ; <nl> - / / } <nl> - / / catch ( memoryaccessexception e ) { <nl> - / / } <nl> - / / return false ; <nl> - / / } <nl> - / / <nl> - / / static boolean isvalidguidpointer ( program program , address addr ) { <nl> - / / memory memory = program . getmemory ( ) ; <nl> - / / addressfactory addressfactory = program . getaddressfactory ( ) ; <nl> - / / addressspace defaultspace = addressfactory . getdefaultaddressspace ( ) ; <nl> - / / try { <nl> - / / int addrasint = memory . getint ( addr ) ; <nl> - / / address pointedtoaddr = addressfactory . getaddress ( defaultspace . getspaceid ( ) , addrasint ) ; <nl> - / / if ( memory . contains ( pointedtoaddr ) ) { <nl> - / / guidinfo guidinfo = guidutil . getknownguid ( program , pointedtoaddr ) ; <nl> - / / if ( guidinfo ! = null ) { <nl> - / / return true ; <nl> - / / } <nl> - / / } <nl> - / / } <nl> - / / catch ( memoryaccessexception e ) { <nl> - / / } <nl> - / / return false ; <nl> - / / } <nl> - / / <nl> - / / static long getbytestoendofblock ( program program , address addr ) { <nl> - / / memory memory = program . getmemory ( ) ; <nl> - / / address endaddr = memory . getblock ( addr ) . getend ( ) ; <nl> - / / return endaddr . subtract ( addr ) ; <nl> - / / } <nl> - / / <nl> - / / static long getbytestonextreferredtoaddress ( program program , address addr ) { <nl> - / / addressiterator refiter = <nl> - / / program . getreferencemanager ( ) . getreferencedestinationiterator ( addr . add ( 1l ) , true ) ; <nl> - / / if ( refiter . hasnext ( ) ) { <nl> - / / address nextaddr = refiter . next ( ) ; <nl> - / / if ( nextaddr ! = null ) { <nl> - / / return nextaddr . subtract ( addr ) ; <nl> - / / } <nl> - / / } <nl> - / / return num ; <nl> - / / } <nl> - / / <nl> - / / static long getbytestonextrelocation ( program program , address addr ) { <nl> - / / address nextrelocaddr = program . getrelocationtable ( ) . getrelocationaddressafter ( addr ) ; <nl> - / / if ( nextrelocaddr ! = null & & <nl> - / / addr . getaddressspace ( ) . equals ( nextrelocaddr . getaddressspace ( ) ) ) { <nl> - / / return nextrelocaddr . subtract ( addr ) ; <nl> - / / } <nl> - / / return num ; <nl> - / / } <nl> - <nl> }
public class dbtracecontenthandler extends dbcontenthandler { <nl>  <nl> @ override <nl> public string getdefaulttoolname ( ) { <nl> - return " debugger " ; <nl> + return " debugger " ; <nl> } <nl>  <nl> @ override
public class jdimanagerimpl implements jdimanager { <nl> @ override <nl> public completablefuture < virtualmachine > addvm ( connector cx , <nl> map < string , connector . argument > args ) { <nl> - <nl> - try { <nl> - curvm = connectvm ( cx , args ) ; <nl> - jdieventhandler eventhandler = new jdieventhandler ( curvm , globaleventhandler ) ; <nl> - eventhandler . start ( ) ; <nl> - eventhandler . setstate ( threadreference . thread_status_not_started , causes . unclaimed ) ; <nl> - eventhandlers . put ( curvm , eventhandler ) ; <nl> - vms . put ( curvm . name ( ) , curvm ) ; <nl> - connectors . put ( curvm , cx ) ; <nl> - } <nl> - catch ( vmdisconnectedexception e ) { <nl> - system . out . println ( " virtual machine is disconnected . " ) ; <nl> - return completablefuture . failedfuture ( e ) ; <nl> - } <nl> - catch ( exception e ) { <nl> - return completablefuture . failedfuture ( e ) ; <nl> - } <nl> - return completablefuture . completedfuture ( curvm ) ; <nl> + return completablefuture . supplyasync ( ( ) - > { <nl> + try { <nl> + curvm = connectvm ( cx , args ) ; <nl> + jdieventhandler eventhandler = new jdieventhandler ( curvm , globaleventhandler ) ; <nl> + eventhandler . start ( ) ; <nl> + eventhandler . setstate ( threadreference . thread_status_not_started , causes . unclaimed ) ; <nl> + eventhandlers . put ( curvm , eventhandler ) ; <nl> + vms . put ( curvm . name ( ) , curvm ) ; <nl> + connectors . put ( curvm , cx ) ; <nl> + } <nl> + catch ( vmdisconnectedexception e ) { <nl> + system . out . println ( " virtual machine is disconnected . " ) ; <nl> + return exceptionutils . rethrow ( e ) ; <nl> + } <nl> + catch ( exception e ) { <nl> + return exceptionutils . rethrow ( e ) ; <nl> + } <nl> + return curvm ; <nl> + } ) ; <nl> } <nl>  <nl> @ override <nl> mmm a / ghidra / debug / debugger - jpda / src / main / java / ghidra / dbg / jdi / model / jdimodelimpl . java <nl> ppp b / ghidra / debug / debugger - jpda / src / main / java / ghidra / dbg / jdi / model / jdimodelimpl . java <nl>
public class debuggertracemanagerservicetest extends abstractghidraheadeddebugge <nl> trace trace = recorder . gettrace ( ) ; <nl>  <nl> waitforvalue ( ( ) - > modelservice . gettarget ( trace ) ) ; <nl> - <nl> - waitforpass ( ( ) - > assertequals ( 2 , trace . gettimemanager ( ) . getsnapshotcount ( ) ) ) ; <nl> + waitrecorder ( recorder ) ; <nl>  <nl> tracemanager . opentrace ( trace ) ; <nl> waitforswing ( ) ;
import ghidra . dbg . util . configurablefactory . factorydescription ; <nl> ) <nl> public class dbgenginjvmdebuggermodelfactory implements debuggermodelfactory { <nl>  <nl> - <nl> + protected string remote = " none " ; / / require user to start server <nl> + @ factoryoption ( " debugconnect options ( . server ) " ) <nl> + public final property < string > agentremoteoption = <nl> + property . fromaccessors ( string . class , this : : getagentremote , this : : setagentremote ) ; <nl> + <nl> + protected string transport = " none " ; / / require user to start server <nl> + @ factoryoption ( " remote process server options ( untested ) " ) <nl> + public final property < string > agenttransportoption = <nl> + property . fromaccessors ( string . class , this : : getagenttransport , this : : setagenttransport ) ; <nl>  <nl> @ override <nl> public completablefuture < ? extends debuggerobjectmodel > build ( ) { <nl> dbgmodelimpl model = new dbgmodelimpl ( ) ; <nl> - return model . startdbgeng ( new string [ ] { } ) . thenapply ( __ - > model ) ; <nl> + list < string > cmds = new arraylist < > ( ) ; <nl> + completecommandline ( cmds ) ; <nl> + return model . startdbgeng ( cmds . toarray ( new string [ cmds . size ( ) ] ) ) . thenapply ( __ - > model ) ; <nl> } <nl>  <nl> @ override <nl>
public class referencesfromtablemodel extends addressbasedtablemodel < referenceen <nl> return label ; <nl> } <nl>  <nl> - private string asstring ( referenceendpoint rowobject ) { <nl> - reftype reftype = rowobject . getreferencetype ( ) ; <nl> + private string asstring ( referenceendpoint t ) { <nl> + reftype reftype = t . getreferencetype ( ) ; <nl> string text = reftype . getname ( ) ; <nl> - if ( rowobject . isoffcut ( ) ) { <nl> - text = " < html > " + htmlutilities . colorstring ( color . red , text + offcut_string ) ; <nl> + if ( t . isoffcut ( ) ) { <nl> + text = " < html > " + htmlutilities . colorstring ( color . red , text + html_offcut_text ) ; <nl> } <nl> return text ; <nl> } <nl>  <nl> @ override <nl> public string getfilterstring ( referenceendpoint t , settings settings ) { <nl> - string htmlstring = asstring ( t ) ; <nl> - <nl> - <nl> - return htmlutilities . fromhtml ( htmlstring ) ; <nl> + reftype reftype = t . getreferencetype ( ) ; <nl> + string text = reftype . getname ( ) ; <nl> + if ( t . isoffcut ( ) ) { <nl> + return text + plain_offcut_text ; <nl> + } <nl> + return text ; <nl> } <nl> } <nl> }
public class debuggertracklocationtrait { <nl> } <nl>  <nl> public void setspec ( locationtrackingspec spec ) { <nl> - <nl> - if ( action ! = null ) { <nl> + if ( action = = null ) { <nl> + / / it might if the client doesn ' t need a new button , e . g . , tracediff <nl> + dosetspec ( spec ) ; <nl> + } <nl> + else { <nl> action . setcurrentactionstatebyuserdata ( spec ) ; <nl> } <nl> }
<nl> - / * # # # <nl> - * ip : ghidra <nl> - * <nl> - * licensed under the apache license , version num . 0 ( the " license " ) ; <nl> - * you may not use this file except in compliance with the license . <nl> - * you may obtain a copy of the license at <nl> - * <nl> - * http : / / www . apache . org / licenses / license - 2 . 0 <nl> - * <nl> - * unless required by applicable law or agreed to in writing , software <nl> - * distributed under the license is distributed on an " as is " basis , <nl> - * without warranties or conditions of any kind , either express or implied . <nl> - * see the license for the specific language governing permissions and <nl> - * limitations under the license . <nl> - * / <nl> - package ghidra . graph . viewer . edge ; <nl> - <nl> - import java . util . * ; <nl> - <nl> - import ghidra . graph . * ; <nl> - import ghidra . graph . viewer . * ; <nl> - import ghidra . util . task . swingrunnable ; <nl> - import ghidra . util . task . taskmonitor ; <nl> - <nl> - / * * <nl> - * a task to find all the loops in a graph . <nl> - * <nl> - * @ param < v > the vertex type <nl> - * @ param < e > the edge type <nl> - * @ param < g > the graph type <nl> - * / <nl> - / / @ formatter : off <nl> - public class initializecircuitsrunnable < v extends visualvertex , <nl> - e extends visualedge < v > , <nl> - g extends visualgraph < v , e > > <nl> - implements swingrunnable { <nl> - / / @ formatter : on <nl> - <nl> - private final visualgraph < v , e > graph ; <nl> - private final set < e > allcircuitresults ; <nl> - private final map < v , set < e > > circuitflowresults ; <nl> - private visualgraphview < v , e , g > view ; <nl> - <nl> - public initializecircuitsrunnable ( visualgraphview < v , e , g > view , visualgraph < v , e > graph ) { <nl> - this . view = objects . requirenonnull ( view ) ; <nl> - this . graph = graph ; <nl> - this . allcircuitresults = new hashset < > ( ) ; <nl> - this . circuitflowresults = new hashmap < > ( ) ; <nl> - } <nl> - <nl> - @ override <nl> - public void monitoredrun ( taskmonitor monitor ) { <nl> - monitor . setmessage ( " finding all loops " ) ; <nl> - <nl> - set < set < v > > strongs = graphalgorithms . getstronglyconnectedcomponents ( graph ) ; <nl> - <nl> - for ( set < v > vertices : strongs ) { <nl> - if ( vertices . size ( ) = = num ) { <nl> - continue ; <nl> - } <nl> - <nl> - gdirectedgraph < v , e > subgraph = graphalgorithms . createsubgraph ( graph , vertices ) ; <nl> - <nl> - collection < e > edges = subgraph . getedges ( ) ; <nl> - allcircuitresults . addall ( edges ) ; <nl> - <nl> - hashset < e > asset = new hashset < > ( edges ) ; <nl> - collection < v > subvertices = subgraph . getvertices ( ) ; <nl> - for ( v v : subvertices ) { <nl> - circuitflowresults . put ( v , asset ) ; <nl> - } <nl> - } <nl> - } <nl> - <nl> - @ override <nl> - public void swingrun ( boolean iscancelled ) { <nl> - if ( iscancelled ) { <nl> - return ; <nl> - } <nl> - <nl> - <nl> - / / graphviewer < v , e > viewer = view . getprimarygraphviewer ( ) ; <nl> - / / visualgraphpathhighlighter < v , e > pathhighlighter = viewer . getpathhighlighter ( ) ; <nl> - / / pathhighlighter . setedgecircuits ( allcircuitresults , circuitflowresults ) ; <nl> - / / view . repaint ( ) ; <nl> - } <nl> - }
public class vertexmouseinfo < v extends visualvertex , e extends visualedge < v > > { <nl> private final mouseevent originalmouseevent ; <nl> private final graphviewer < v , e > viewer ; <nl>  <nl> - <nl> - protected final v vertex ; <nl> + private final v vertex ; <nl> private mouseevent translatedmouseevent ; <nl> - protected component mouseddestinationcomponent ; <nl> + private component mouseddestinationcomponent ; <nl>  <nl> public vertexmouseinfo ( mouseevent originalmouseevent , v vertex , point2d vertexbasedclickpoint , <nl> graphviewer < v , e > viewer ) {
public class neloader extends abstractlibrarysupportloader { <nl> symboltable . createlabel ( entryaddr , " entry " , sourcetype . imported ) ; <nl> } <nl> catch ( invalidinputexception e ) { <nl> - <nl> - e . printstacktrace ( ) ; <nl> + log . appendmsg ( " error creating label at " + entryaddr ) ; <nl> + log . appendexception ( e ) ; <nl> } <nl> } <nl>  <nl>
public class neloader extends abstractlibrarysupportloader { <nl> sourcetype . imported ) ; <nl> } <nl> catch ( invalidinputexception e ) { <nl> - <nl> - e . printstacktrace ( ) ; <nl> + msg . error ( this , " error creating label " + name + " @ " + addr , e ) ; <nl> } <nl> } <nl> }
public class tracecachedwritebytespcodeexecutorstate <nl> } <nl>  <nl> protected set < register > getregs ( addressset set ) { <nl> - <nl> - language language = source . gettrace ( ) . getbaselanguage ( ) ; <nl> set < register > regs = new treeset < > ( ) ; <nl> for ( addressrange rng : set ) { <nl> register r = language . getregister ( rng . getminaddress ( ) , ( int ) rng . getlength ( ) ) ; <nl>
public class demangledfunction extends demangledobject { <nl> / / sure that the context is correctly set before that happens . also , be sure to apply <nl> / / the function to the correct address . <nl>  <nl> - <nl> - / / be moved into the psuedodisassembler ? ? ? <nl> - if ( ! address . isexternaladdress ( ) ) { <nl> + if ( address . ismemoryaddress ( ) ) { <nl> address = pseudodisassembler . settargecontextfordisassembly ( program , address ) ; <nl> } <nl>  <nl> mmm a / ghidra / framework / softwaremodeling / src / main / java / ghidra / app / util / pseudodisassembler . java <nl> ppp b / ghidra / framework / softwaremodeling / src / main / java / ghidra / app / util / pseudodisassembler . java <nl>
mem : segwide ^ addr32_64 is $ ( longmode_on ) & addrsize = 1 & segwide ; addr32_64 { <nl> mem : segwide ^ addr32_64 is $ ( longmode_on ) & addrsize = 1 & segwide & highseg = 1 ; addr32_64 { tmp : 8 = segwide + addr32_64 ; export tmp ; } <nl> mem : segwide ^ addr64 is $ ( longmode_on ) & addrsize = 2 & segwide ; addr64 { export addr64 ; } <nl> mem : segwide ^ addr64 is $ ( longmode_on ) & addrsize = 2 & segwide & highseg = 1 ; addr64 { tmp : $ ( size ) = segwide + addr64 ; export tmp ; } <nl> - @ endif <nl> - # <nl> mem : segwide ^ addr32 is $ ( longmode_off ) & addrsize = 1 & segwide ; addr32 { tmp : $ ( size ) = zext ( addr32 ) ; export tmp ; } <nl> + @ else <nl> + mem : segwide ^ addr32 is $ ( longmode_off ) & addrsize = 1 & segwide ; addr32 { export addr32 ; } <nl> + @ endif <nl> mem : segwide ^ addr32 is $ ( longmode_off ) & addrsize = 1 & segwide & highseg = 1 ; addr32 { tmp : $ ( size ) = segwide + zext ( addr32 ) ; export tmp ; } <nl>  <nl> rel8 : reloc is simm8 [ reloc = inst_next + simm8 ; ] { export * [ ram ] : $ ( size ) reloc ; }
public class rttiwindowsclassrecoverer extends rtticlassrecoverer { <nl> @ override <nl> public list < recoveredclass > createrecoveredclasses ( ) { <nl>  <nl> - <nl> - <nl> list < symbol > vftablesymbols ; <nl> try { <nl> vftablesymbols = getlistofvftablesymbols ( ) ; <nl>
public class graphactiontest extends abstractghidraheadedintegrationtest { <nl>  <nl> } <nl>  <nl> - <nl> + @ test <nl> public void testselectnodethatisdoublegrouped ( ) { <nl> select ( a , b , c ) ; <nl> collapse ( ) ; <nl>
public class graphactiontest extends abstractghidraheadedintegrationtest { <nl> asserttrue ( vertex instanceof groupvertex ) ; <nl> } <nl>  <nl> - <nl> + @ test <nl> public void testfocusnodethatisdoublegrouped ( ) { <nl> select ( a , b , c ) ; <nl> collapse ( ) ; <nl>
public class graphactiontest extends abstractghidraheadedintegrationtest { <nl> asserttrue ( graphspy . isfocused ( a ) ) ; <nl> } <nl>  <nl> - <nl> + @ test <nl> public void testlistenernotificatinwhendoublegroupednodefocused ( ) { <nl> select ( a , b , c ) ; <nl> collapse ( ) ; <nl>
public class graphactiontest extends abstractghidraheadedintegrationtest { <nl> asserttrue ( graphspy . isselected ( a , b , c ) ) ; <nl> } <nl>  <nl> - <nl> + @ test <nl> public void testselectnotificatinwhendoublegroupednodefocused ( ) { <nl> select ( a , b , c ) ; <nl> collapse ( ) ;
public class debuggercallbackreorderertest implements debuggermodeltestutils { <nl>  <nl> assertequals ( toa1 , waiton ( listener . get ( pathutils . parse ( " a [ 1 ] " ) ) ) ) ; <nl> assertequals ( tob2 , waiton ( listener . get ( pathutils . parse ( " b [ 2 ] " ) ) ) ) ; <nl> - <nl> - / / e . g . , will toa always precede tob , just because it was listed first ? <nl> - assertequals ( list . of ( root , toa , tob , toa1 , tob2 ) , listener . getadded ( ) ) ; <nl> + <nl> + / / note the order is not unique , but there are constraints . <nl> + / / it ' s similar to a topological sort . <nl> + list < targetobject > order = list . copyof ( listener . getadded ( ) ) ; <nl> + assertequals ( 0 , order . indexof ( root ) ) ; <nl> + asserttrue ( order . indexof ( root ) < order . indexof ( toa ) ) ; <nl> + asserttrue ( order . indexof ( root ) < order . indexof ( tob ) ) ; <nl> + asserttrue ( order . indexof ( toa ) < order . indexof ( toa1 ) ) ; <nl> + asserttrue ( order . indexof ( tob ) < order . indexof ( tob2 ) ) ; <nl> } <nl>  <nl> @ test
idx_h : d , rr4_3 is xb7_5 = 0b111 & rr4_3 & xb2_0 = 0b110 & d <nl> # <nl> # num rr0zs imm8 <nl> # <nl> - # constant offset ( 9 - bit signed , positive ) <nl> - idx_i : imm8 , rr4_3 is xb7_5 = 0b111 & rr4_3 & xb2_2 = 0 & z1_1 = 0 & s0_0 = 0 ; imm8 <nl> - { address : 2 = rr4_3 + imm8 ; export address ; } <nl> - <nl> - # constant offset ( 9 - bit signed , negative ) <nl> - # <nl> - idx_j : - neg , rr4_3 is xb7_5 = 0b111 & rr4_3 & xb2_2 = 0 & z1_1 = 0 & s0_0 = 1 ; imm8 [ neg = - imm8 ; ] <nl> - { address : 2 = rr4_3 - neg ; export address ; } <nl> - <nl> + # constant offset ( 9 - bit signed ) <nl> + idx_i : opr9 , rr4_3 is xb7_5 = 0b111 & rr4_3 & xb2_2 = 0 & z1_1 = 0 & ss0_0 ; imm8 [ opr9 = ( ss0_0 < < num ) | imm8 ; ] <nl> + { address : 2 = rr4_3 + opr9 ; export address ; } <nl>  <nl> # * * * * * * * * * * <nl> # idx2 <nl>
public class tracepcodeemulatortest extends abstractghidraheadlessintegrationtes <nl> @ test <nl> public void testbrds ( ) throws throwable { <nl> try ( toydbtracebuilder tb = new toydbtracebuilder ( " test " , " toy : be : 64 : default " ) ) { <nl> - <nl> - / / assemble to the side and just write bytes in until that ' s fixed <nl> assembler asm = assemblers . getassembler ( tb . trace . getfixedprogramview ( 0 ) ) ; <nl> tracethread thread = inittrace ( tb , <nl> list . of ( <nl> " pc = num x00400000 ; " , <nl> " sp = num x00110000 ; " ) , <nl> - list . of ( ) ) ; <nl> - <nl> - try ( undoabletransaction tid = tb . starttransaction ( ) ) { <nl> - tb . trace . getmemorymanager ( ) <nl> - . putbytes ( 0 , tb . addr ( 0x00400000 ) , bytebuffer . wrap ( <nl> - asm . assembleline ( tb . addr ( 0x00400000 ) , " brds num x00400006 " ) ) ) ; <nl> - tb . trace . getmemorymanager ( ) <nl> - . putbytes ( 0 , tb . addr ( 0x00400002 ) , bytebuffer . wrap ( <nl> - asm . assembleline ( tb . addr ( 0x00400002 ) , " imm r0 , # 1234 " ) ) ) ; / / decimal <nl> - tb . trace . getmemorymanager ( ) <nl> - . putbytes ( 0 , tb . addr ( 0x00400004 ) , bytebuffer . wrap ( <nl> - asm . assembleline ( tb . addr ( 0x00400004 ) , " imm r0 , # 2020 " ) ) ) ; <nl> - tb . trace . getmemorymanager ( ) <nl> - . putbytes ( 0 , tb . addr ( 0x00400006 ) , bytebuffer . wrap ( <nl> - asm . assembleline ( tb . addr ( 0x00400006 ) , " imm r1 , # 2021 " ) ) ) ; <nl> - } <nl> + list . of ( <nl> + " brds num x00400006 " , <nl> + " imm r0 , # 1234 " , / / decimal <nl> + " imm r0 , # 2020 " , <nl> + " imm r1 , # 2021 " ) ) ; <nl>  <nl> tracepcodeemulator emu = new tracepcodeemulator ( tb . trace , num ) ; <nl> pcodethread < byte [ ] > emuthread = emu . newthread ( thread . getpath ( ) ) ;
public abstract class abstractgraphalgorithmstest extends abstractgenerictest { <nl> return id ; <nl> } <nl>  <nl> - <nl> - / / <nl> - / / @ override <nl> - / / public int hashcode ( ) { <nl> - / / final int prime = num ; <nl> - / / int result = num ; <nl> - / / result = prime * result + ( ( id = = null ) ? num : id . hashcode ( ) ) ; <nl> - / / return result ; <nl> - / / } <nl> - / / <nl> - / / @ override <nl> - / / public boolean equals ( object obj ) { <nl> - / / if ( this = = obj ) { <nl> - / / return true ; <nl> - / / } <nl> - / / if ( obj = = null ) { <nl> - / / return false ; <nl> - / / } <nl> - / / if ( getclass ( ) ! = obj . getclass ( ) ) { <nl> - / / return false ; <nl> - / / } <nl> - / / <nl> - / / testv other = ( testv ) obj ; <nl> - / / if ( ! objects . equals ( id , other . id ) ) { <nl> - / / return false ; <nl> - / / } <nl> - / / return true ; <nl> - / / } <nl> + @ override <nl> + public int hashcode ( ) { <nl> + final int prime = num ; <nl> + int result = num ; <nl> + result = prime * result + ( ( id = = null ) ? num : id . hashcode ( ) ) ; <nl> + return result ; <nl> + } <nl> + <nl> + @ override <nl> + public boolean equals ( object obj ) { <nl> + if ( this = = obj ) { <nl> + return true ; <nl> + } <nl> + if ( obj = = null ) { <nl> + return false ; <nl> + } <nl> + if ( getclass ( ) ! = obj . getclass ( ) ) { <nl> + return false ; <nl> + } <nl> + <nl> + testv other = ( testv ) obj ; <nl> + if ( ! objects . equals ( id , other . id ) ) { <nl> + return false ; <nl> + } <nl> + return true ; <nl> + } <nl> } <nl>  <nl> protected static class teste extends defaultgedge < testv > { <nl> mmm a / ghidra / framework / graph / src / test / java / ghidra / graph / graphalgorithmstest . java <nl> ppp b / ghidra / framework / graph / src / test / java / ghidra / graph / graphalgorithmstest . java <nl>
def inittestjvm ( task task , string rootdirname ) { <nl> mkdir testoutputdir <nl> } <nl> / / if false , testing will halt when an error is found . <nl> - <nl> - / / here can cause sub - project builds to proceed even when tests fail . <nl> - / / if test report not generated that task could be changed to always <nl> - / / run even on failure ( e . g . , options . failonerror ( false ) ) <nl> - / / task . ignorefailures true <nl> - task . failfast false <nl> + task . ignorefailures true <nl>  <nl> / / if false , then tests are re - run every time , even if no code has changed . <nl> task . outputs . uptodatewhen { false }
public class debuggerinterpreterplugintest extends abstractghidraheadeddebuggerg <nl> interpretercomponentprovider interpreter = <nl> waitforcomponentprovider ( interpretercomponentprovider . class ) ; <nl>  <nl> - <nl> - assertequals ( " test debugger " , interpreter . gettitle ( ) ) ; <nl> + assertequals ( " test debugger " , interpreter . getsubtitle ( ) ) ; <nl> asserttrue ( interpreter . isvisible ( ) ) ; <nl> } <nl>  <nl>
public class debuggerinterpreterplugintest extends abstractghidraheadeddebuggerg <nl> } <nl>  <nl> @ test <nl> - public void testdisplaychangeupdatestitle ( ) throws exception { <nl> + public void testdisplaychangeupdatestitle ( ) throws throwable { <nl> createtestmodel ( ) ; <nl> interpreterplugin . showconsole ( mb . testmodel . session . interpreter ) ; <nl> interpretercomponentprovider interpreter = <nl> waitforcomponentprovider ( interpretercomponentprovider . class ) ; <nl>  <nl> mb . testmodel . session . interpreter . setdisplay ( " test debugger x . 0 " ) ; <nl> + waiton ( mb . testmodel . flushevents ( ) ) ; <nl> waitforswing ( ) ; <nl>  <nl> - <nl> - assertequals ( " test debugger x . 0 " , interpreter . gettitle ( ) ) ; <nl> + assertequals ( " test debugger x . 0 " , interpreter . getsubtitle ( ) ) ; <nl> } <nl>  <nl> @ test <nl> mmm a / ghidra / debug / debugger / src / test / java / ghidra / app / plugin / core / debug / service / breakpoint / debuggerlogicalbreakpointservicetest . java <nl> ppp b / ghidra / debug / debugger / src / test / java / ghidra / app / plugin / core / debug / service / breakpoint / debuggerlogicalbreakpointservicetest . java <nl>
e2w : ( d32 ) " . l " is savmod2 = 7 & regsan = 1 ; d32 { export * : 2 d32 ; } <nl> e2w : " # " ^ d16 is savmod2 = 7 & regsan = 4 ; d16 { export * [ const ] : 2 d16 ; } <nl>  <nl> # size = byte <nl> - # nb - <nl> + # nb - manual says that if in predecrement or postincrement mode and the res is the sp , then must inc / dec by num , not by num <nl> e2b : regsdnb is savmod2 = 0 & regsdnb { export regsdnb ; } <nl> e2b : regsanb is savmod2 = 1 & regsanb { export regsanb ; } <nl> e2b : ( regsan ) is savmod2 = 2 & regsan { export * : 1 regsan ; } <nl> + e2b : ( regsan ) + is savmod2 = 3 & regsan & regsan = 7 { local tmp = regsan ; regsan = regsan + num ; export * : 1 tmp ; } <nl> e2b : ( regsan ) + is savmod2 = 3 & regsan { local tmp = regsan ; regsan = regsan + num ; export * : 1 tmp ; } <nl> + e2b : - ( regsan ) is savmod2 = 4 & regsan & regsan = 7 { regsan = regsan - num ; export * : 1 regsan ; } <nl> e2b : - ( regsan ) is savmod2 = 4 & regsan { regsan = regsan - num ; export * : 1 regsan ; } <nl> e2b : ( d16 , regsan ) is savmod2 = 5 & regsan ; d16 { local tmp = regsan + d16 ; export * : 1 tmp ; } <nl> e2b : ( extw ) is savmod2 = 6 ; extw [ pcmode = 0 ; eanum = 1 ; ] { build extw ; export * : 1 extw ; }
public class localsymbolmap { <nl> continue ; / / found a duplicate , skip it <nl> } <nl> eqsymbol = newequatesymbol ( 0 , displayname , eqvalue , hash [ i ] , defaddr ) ; <nl> - equatesymbollist . add ( eqsymbol ) ; <nl> + symbolmap . put ( eqsymbol . getid ( ) , eqsymbol ) ; <nl> } <nl> } <nl> } <nl> - <nl> - <nl> - / / - - for each datatype reference within the scope of the function <nl> - / / mappedvarkey key = new mappedvarkey ( addressspace . hash_space . getaddress ( hash ) , defaddr ) ; <nl> - / / dynamicsymbol sym = constantsymbolmap . get ( key ) ; <nl> - / / string name = sym ! = null ? sym . getname ( ) : null ; <nl> - / / sym = new dynamicsymbol ( name , dt , dt . getlength ( ) , hash , defaddr , func , num ) ; / / format ? ? <nl> - / / if ( name ! = null ) { <nl> - / / sym . settypelock ( true ) ; <nl> - / / } <nl> - / / sym . settypelock ( true ) ; <nl> - / / sym . setreadonly ( true ) ; <nl> - / / <nl> - <nl> - / / add constant dynamic symbols to map <nl> - if ( equatesymbollist ! = null ) { <nl> - for ( highsymbol sym : equatesymbollist ) { <nl> - symbolmap . put ( sym . getid ( ) , sym ) ; <nl> - } <nl> - } <nl> } <nl>  <nl> private void grabmerges ( arraylist < string > mergenames ) {
public class symbolpathparser { <nl> throw new illegalargumentexception ( <nl> " symbol list must contain at least one symbol name ! " ) ; <nl> } <nl> - / / if ( name . indexof ( namespace . delimiter ) = = - 1 ) { <nl> - <nl> - / / this particular test for starting with the open parenthesis is to work around a type <nl> - / / seen in " rust . " <nl> - if ( name . startswith ( " ( " ) | | name . indexof ( namespace . delimiter ) = = - 1 ) { <nl> + <nl> + if ( skipparsing ( name ) ) { <nl> list < string > list = new arraylist < > ( ) ; <nl> list . add ( name ) ; <nl> return list ; <nl>
public class pcodeopemitter { <nl> oplist . add ( op ) ; <nl> } <nl>  <nl> + / * * <nl> + * appends the pcode to assign a register to the result of a pcode op call with arguments args <nl> + * @ param register <nl> + * @ param pcodeop <nl> + * @ param args <nl> + * / <nl> public void emitassignregisterfrompcodeopcall ( stringbuilder pcode , string register , <nl> string pcodeop , string . . . args ) { <nl> - <nl> + symbol useropsym = language . getsymboltable ( ) . findglobalsymbol ( pcodeop ) ; <nl> + varnode out = findregister ( register ) ; <nl> + varnode [ ] in ; <nl> + int opcode ; <nl> + if ( useropsym instanceof useropsymbol ) { <nl> + in = new varnode [ args . length + num ] ; <nl> + in [ 0 ] = getconstant ( ( ( useropsymbol ) useropsym ) . getindex ( ) , num ) ; <nl> + for ( int i = num ; i < args . length ; + + i ) { <nl> + in [ i + num ] = constantorregister ( args [ i ] ) ; <nl> + } <nl> + opcode = pcodeop . callother ; <nl> + } <nl> + else { <nl> + in = new varnode [ args . length ] ; <nl> + for ( int i = num ; i < args . length ; + + i ) { <nl> + in [ i ] = constantorregister ( args [ i ] ) ; <nl> + } <nl> + opcode = findopcode ( pcodeop ) ; <nl> + } <nl> + pcodeop op = new pcodeop ( opaddress , seqnum + + , opcode , in , out ) ; <nl> + oplist . add ( op ) ; <nl> } <nl>  <nl> / * * <nl> mmm a / ghidra / processors / jvm / src / test / java / ghidra / app / util / pcodeinject / referencemethodstest . java <nl> ppp b / ghidra / processors / jvm / src / test / java / ghidra / app / util / pcodeinject / referencemethodstest . java <nl>
import ghidra . util . exception . multiplecauses ; <nl>  <nl> public class dockingerrordisplaytest extends abstractdockingtest { <nl>  <nl> - public dockingerrordisplaytest ( ) { <nl> - super ( ) ; <nl> - <nl> - } <nl> - <nl> private static final string test_title = " test title " ; <nl>  <nl> @ test <nl> mmm a / ghidra / framework / generic / src / main / java / generic / test / concurrenttestexceptionstatement . java <nl> ppp b / ghidra / framework / generic / src / main / java / generic / test / concurrenttestexceptionstatement . java <nl>
void transformvar : : createreplacement ( funcdata * fd ) <nl> replacement = fd - > newvarnode ( bytesize , addr ) ; <nl> else <nl> replacement = fd - > newvarnodeout ( bytesize , addr , def - > replacement ) ; <nl> - <nl> + fd - > transfervarnodeproperties ( vn , replacement , bytepos ) ; <nl> break ; <nl> } <nl> case transformvar : : constant_iop :
public class dyldcacheprogrambuilder extends machoprogrambuilder { <nl> continue ; <nl> } <nl> if ( pageentry = = dyld_cache_slide_page_attr_extra ) { <nl> - continue ; <nl> + int extraindex = ( pageentry & chain_offset_mask ) ; <nl> + do { <nl> + pageentry = ( ( int ) extraentries [ extraindex ] ) & num xffff ; <nl> + long pageoffset = ( pageentry & chain_offset_mask ) * bytes_per_chain_offset ; <nl> + <nl> + fixedaddresses . addall ( processpointerchain ( page , pageoffset , deltamask , deltashift , valueadd ) ) ; <nl> + extraindex + + ; <nl> + } while ( ( pageentry & dyld_cache_slide_page_attr_extra ) = = num ) ; <nl> } <nl> else { <nl> long pageoffset = ( pageentry & chain_offset_mask ) * bytes_per_chain_offset ; <nl>  <nl> - address chainhead = memory . getprogram ( ) . getimagebase ( ) ; <nl> - chainhead = chainhead . getnewaddress ( page ) ; <nl> - <nl> - fixedaddresses . addall ( processpointerchain ( chainhead , pageoffset , deltamask , deltashift , valueadd ) ) ; <nl> + fixedaddresses . addall ( processpointerchain ( page , pageoffset , deltamask , deltashift , valueadd ) ) ; <nl> } <nl> } <nl>  <nl>
xaddr8 : [ x + simm8 ] is x & simm8 & sign = 0 { ptr : 1 = x + simm8 ; export * [ ram ] : 1 <nl> xaddr8 : [ x + simm8 ] is x & simm8 & sign = 1 { ptr : 1 = x - ~ simm8 ; export * [ ram ] : 1 ptr ; } <nl> addr8incr : [ addr8 ] " + + " is addr8 { export addr8 ; } <nl>  <nl> - # <nl> - # raddr8 : addr8 is addr8 { export * [ bank0 ] : 1 addr8 ; } <nl> raddr8 : addr8 is addr8 & regbank = 0 { export * [ bank0 ] : 1 addr8 ; } <nl> raddr8 : addr8 is addr8 & regbank = 1 { export * [ bank1 ] : 1 addr8 ; } <nl> - rxaddr8 : [ x + simm8 ] is x & simm8 { ptr : 1 = x + simm8 ; export * [ bank0 ] : 1 ptr ; } <nl> + rxaddr8 : [ x + simm8 ] is x & simm8 & regbank = 0 { ptr : 1 = x + simm8 ; export * [ bank0 ] : 1 ptr ; } <nl> + rxaddr8 : [ x + simm8 ] is x & simm8 & regbank = 1 { ptr : 1 = x + simm8 ; export * [ bank1 ] : 1 ptr ; } <nl>  <nl> imm8 : " # " imm8 is imm8 { export * [ const ] : 1 imm8 ; } <nl>  <nl>
indexaddr : indexaddr is srel12 [ indexaddr = inst_start + num + srel12 ; ] { ex <nl> xaddr8 = tmp ; <nl> } <nl>  <nl> - # <nl> - <nl> : or raddr8 , imm8 is op8 = 0x43 ; raddr8 ; imm8 <nl> { <nl> tmp : 1 = raddr8 | imm8 ; <nl>
indexaddr : indexaddr is srel12 [ indexaddr = inst_start + num + srel12 ; ] { ex <nl> xaddr8 = tmp ; <nl> } <nl>  <nl> - # <nl> - <nl> : xor raddr8 , imm8 is op8 = 0x45 ; raddr8 ; imm8 <nl> { <nl> tmp : 1 = raddr8 ^ imm8 ; <nl>
<nl> * * <nl> * gradle - - init - script gradle / init . gradle < any_task > * <nl> * * <nl> - * note : running this script multiple times will cause the config * <nl> - * file to be recreated and all dependencies re - downloaded . * <nl> - * * <nl> - * note : all files are downloaded to a the standard java temporary folder * <nl> - * location , in a sub - folder called ' ghidra . this is cleaned up and * <nl> - * removed when the script completes . * <nl> - * <nl> - * if the script fails at some point * <nl> + * note : when running the script , files will only be downloaded if * <nl> + * necessary ( eg : they are not already in the downloads / folder ) . * * <nl> * * <nl> * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * / <nl>  <nl>
public class datatypechooserdialog extends dialogcomponentprovider { <nl> tree . setfiltertext ( filtertext ) ; <nl> } <nl> seteditable ( editable ) ; <nl> - setmessagelabel ( ) ; <nl> } <nl>  <nl> public void setselectedpath ( treepath selectedpath ) { <nl> tree . setselectednodebypathname ( selectedpath ) ; <nl> } <nl>  <nl> - private void setmessagelabel ( ) { <nl> - string message = " choose the data type you wish to use . " ; <nl> - <nl> - <nl> - / / then we need to be able to set them . <nl> - / / if ( ! iseditable ) { <nl> - / / message = <nl> - / / " multiple data types exist named \ " " + <nl> - / / ( ( filtertextfield ) tree . getfilterfield ( ) ) . gettext ( ) + " \ " . \n " + message ; <nl> - / / } <nl> - messagelabel . settext ( htmlutilities . wrapashtml ( message ) ) ; <nl> - } <nl> - <nl> @ override <nl> public component getfocuscomponent ( ) { <nl> return tree . getfilterfield ( ) ;
public class frontendtool extends plugintool implements optionschangelistener { <nl> options . addoptionschangelistener ( this ) ; <nl> } <nl>  <nl> - / / a place to clear options that are specific to the frontendtool and should be reset between <nl> - / / opening projects <nl> - private void clearfrontendoptions ( ) { <nl> - <nl> - / / to have the ' auto save ' setting be different for different projects - - no sir , i don ' like it <nl> - tooloptions options = getoptions ( " tool " ) ; <nl> - options . removeoptionschangelistener ( this ) ; <nl> - options . removeoption ( automatically_save_tools ) ; <nl> - } <nl> - <nl> @ override <nl> public void optionschanged ( tooloptions options , string optionname , object oldvalue , <nl> object newvalue ) { <nl>
public class parserconfig { <nl> try { <nl> return asmdeserializerfactory . getinstance ( ) . createfielddeserializer ( mapping , clazz , fieldinfo ) ; <nl> } catch ( throwable e ) { <nl> - <nl> - e . printstacktrace ( ) ; <nl> + / / skip <nl> } <nl>  <nl> return createfielddeserializerwithoutasm ( mapping , clazz , fieldinfo ) ;
public class defaultjsonparser extends abstractjsonparser { <nl> if ( lexer . isblankinput ( ) ) { <nl> return null ; <nl> } <nl> + throw new jsonexception ( " unterminated json string , pos " + lexer . getbufferposition ( ) ) ; <nl> + case error : <nl> default : <nl> - throw new jsonexception ( " <nl> + throw new jsonexception ( " syntax error , pos " + lexer . getbufferposition ( ) ) ; <nl> } <nl> } <nl>  <nl> mmm a / src / main / java / com / alibaba / fastjson / parser / jsonlexer . java <nl> ppp b / src / main / java / com / alibaba / fastjson / parser / jsonlexer . java <nl>
<nl> < js . version > 21 . 2 . 0 < / js . version > <nl> < objenesis . version > 3 . 2 < / objenesis . version > <nl> < paged - data . version > 0 . 2 . 0 < / paged - data . version > <nl> - < procyon . version > 0 . 5 . 36 < / procyon . version > <nl> - < ! - - <nl> - < procyon - snapshot . version > bea9e8c < / procyon - snapshot . version > <nl> + < procyon . version > 0 . 6 . 0 < / procyon . version > <nl> < rsyntaxtextarea . version > 3 . 1 . 6 < / rsyntaxtextarea . version > <nl> < semantic - version . version > 2 . 1 . 1 < / semantic - version . version > <nl> < slf4j . version > 1 . 7 . 36 < / slf4j . version > <nl>
<nl> < artifactid > paged_data < / artifactid > <nl> < version > $ { paged - data . version } < / version > <nl> < / dependency > <nl> - < ! - - <nl> < dependency > <nl> < groupid > org . bitbucket . mstrobel < / groupid > <nl> < artifactid > procyon - core < / artifactid > <nl>
<nl> < id > local - maven - repo < / id > <nl> < url > file : / / / $ { project . basedir } / libs < / url > <nl> < / repository > <nl> - < repository > <nl> - < id > sonatype - snapshots < / id > <nl> - < url > https : / / oss . sonatype . org / content / repositories / snapshots < / url > <nl> - < / repository > < ! - - <nl> < repository > <nl> < id > jitpack . io < / id > <nl> < url > https : / / jitpack . io < / url > <nl>
public class importresource implements runnable <nl> final string fn = filenameutils . getname ( file . getname ( ) ) . tolowercase ( ) ; <nl> final string extension = fn . contains ( " : " ) ? null : filenameutils . getextension ( fn ) ; <nl>  <nl> - switch ( extension ) <nl> - { <nl> - / / check for zip archives <nl> - case " jar " : <nl> - case " zip " : <nl> - case " war " : <nl> - case " ear " : <nl> - import . zip . getimporter ( ) . open ( file ) ; <nl> - break ; <nl> - <nl> - / / check for xapks <nl> - case " xapk " : <nl> - import . xapk . getimporter ( ) . open ( file ) ; <nl> - break ; <nl> - <nl> - / / check for apks <nl> - case " apk " : <nl> - import . apk . getimporter ( ) . open ( file ) ; <nl> - break ; <nl> - <nl> - / / check for dex <nl> - case " dex " : <nl> - import . dex . getimporter ( ) . open ( file ) ; <nl> - break ; <nl> - <nl> - default : <nl> - return false ; <nl> - } <nl> + import imp = import . extensionmap . get ( extension ) ; <nl> + <nl> + if ( imp = = null ) <nl> + return false ; <nl> + <nl> + / / import / decode the file using the file specific importer <nl> + imp . getimporter ( ) . open ( file ) ; <nl>  <nl> return true ; <nl> }
public class externalresources <nl> try <nl> { <nl> bytecodeviewer . sm . pauseblocking ( ) ; <nl> - <nl> processbuilder pb = new processbuilder ( " java " , " - version " ) ; <nl> - pb . start ( ) ; <nl> + process p = pb . start ( ) ; <nl> + p . waitfor ( ) ; <nl>  <nl> - configuration . java = " java " ; / / java is set <nl> - return configuration . java ; <nl> + if ( readprocess ( p ) . tolowercase ( ) . contains ( " java version " ) ) <nl> + { <nl> + configuration . java = " java " ; / / java is set <nl> + return configuration . java ; <nl> + } <nl> } <nl> catch ( exception e ) { } / / ignore <nl> finally
<nl> package the . bytecode . club . bytecodeviewer . gui . resourcelist ; <nl>  <nl> - <nl> - import com . sun . java . swing . plaf . windows . windowstreeui ; <nl> import java . awt . borderlayout ; <nl> import java . awt . color ; <nl> import java . awt . event . actionevent ; <nl>
public class resourcelistpane extends translatedvisiblecomponent implements file <nl>  <nl> rightclickmenu . add ( new resourcelistrightclickremove ( this , x , y , tree ) ) ; <nl>  <nl> - <nl> - / / you can replace this with any icon loaded from disk , <nl> - / / they could be re - used for the plus and minus symbols on the resource list too <nl> - rightclickmenu . add ( new abstractaction ( " expand " , windowstreeui . expandedicon . createexpandedicon ( ) ) { <nl> + rightclickmenu . add ( new abstractaction ( " expand " , iconresources . collapsedicon . createcollapsedicon ( ) ) { <nl> @ override <nl> public void actionperformed ( actionevent e ) { <nl> treepath selpath = resourcelistpane . this . tree . getpathforlocation ( x , y ) ; <nl> expandall ( tree , objects . requirenonnull ( selpath ) , true ) ; <nl> } <nl> } ) ; <nl> - rightclickmenu . add ( new abstractaction ( " collapse " , windowstreeui . collapsedicon . createcollapsedicon ( ) ) { <nl> + rightclickmenu . add ( new abstractaction ( " collapse " , iconresources . expandedicon . createexpandedicon ( ) ) { <nl> @ override <nl> public void actionperformed ( actionevent e ) { <nl> treepath selpath = resourcelistpane . this . tree . getpathforlocation ( x , y ) ; <nl> mmm a / src / main / java / the / bytecode / club / bytecodeviewer / resources / iconresources . java <nl> ppp b / src / main / java / the / bytecode / club / bytecodeviewer / resources / iconresources . java <nl>
<nl> - # # # <nl> - <nl> - * more unit tests <nl> - * add metrics support
public class hikaridatasource extends hikariconfig implements datasource <nl>  <nl> / * * { @ inheritdoc } * / <nl> @ override <nl> + @ suppresswarnings ( " unchecked " ) <nl> public < t > t unwrap ( class < t > iface ) throws sqlexception <nl> { <nl> - <nl> - return null ; <nl> + if ( pool ! = null & & iface . isinstance ( pool . datasource ) ) <nl> + { <nl> + return ( t ) pool . datasource ; <nl> + } <nl> + <nl> + throw new sqlexception ( " wrapped connection is not an instance of " + iface ) ; <nl> } <nl>  <nl> / * * { @ inheritdoc } * /
public final class hikaripool implements hikaripoolmbean <nl>  <nl> void shutdown ( ) <nl> { <nl> - <nl> + shutdown = true ; <nl> + housekeepingtimer . cancel ( ) ; <nl> + <nl> + while ( true ) <nl> + { <nl> + ihikariconnectionproxy connection = idleconnections . poll ( ) ; <nl> + if ( connection = = null ) <nl> + { <nl> + break ; <nl> + } <nl> + closeconnection ( connection ) ; <nl> + } <nl> } <nl>  <nl> / / * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * <nl>
public final class hikaripool implements hikaripoolmbean <nl>  <nl> void shutdown ( ) <nl> { <nl> - <nl> + shutdown = true ; <nl> + housekeepingtimer . cancel ( ) ; <nl> + <nl> + while ( true ) <nl> + { <nl> + ihikariconnectionproxy connection = idleconnections . poll ( ) ; <nl> + if ( connection = = null ) <nl> + { <nl> + break ; <nl> + } <nl> + closeconnection ( connection ) ; <nl> + } <nl> } <nl>  <nl> / / * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * <nl>
import java . lang . reflect . wildcardtype ; <nl>  <nl> public class typeparameterresolver { <nl>  <nl> - public static type [ ] resolveparamtypes ( method method , type mapper ) { <nl> - type [ ] paramtypes = method . getgenericparametertypes ( ) ; <nl> - class < ? > declaringclass = method . getdeclaringclass ( ) ; <nl> - type [ ] result = new type [ paramtypes . length ] ; <nl> - for ( int i = num ; i < paramtypes . length ; i + + ) { <nl> - if ( paramtypes [ i ] instanceof class ) { <nl> - result [ i ] = paramtypes [ i ] ; <nl> - } else if ( paramtypes [ i ] instanceof typevariable ) { <nl> - result [ i ] = resolvetypevar ( ( typevariable < ? > ) paramtypes [ i ] , mapper , declaringclass ) ; <nl> - } else if ( paramtypes [ i ] instanceof parameterizedtype ) { <nl> - result [ i ] = resolveparameterizedtype ( ( parameterizedtype ) paramtypes [ i ] , mapper , declaringclass ) ; <nl> - } else { <nl> - <nl> - } <nl> - } <nl> - return result ; <nl> - } <nl> - <nl> public static type resolvereturntype ( method method , type mapper ) { <nl> type returntype = method . getgenericreturntype ( ) ; <nl> class < ? > declaringclass = method . getdeclaringclass ( ) ; <nl> mmm a / src / test / java / org / apache / ibatis / reflection / typeparameterresolvertest . java <nl> ppp b / src / test / java / org / apache / ibatis / reflection / typeparameterresolvertest . java <nl>
<nl> - / * <nl> - * copyright num - 2012 the mybatis team <nl> - * <nl> - * licensed under the apache license , version num . 0 ( the " license " ) ; <nl> - * you may not use this file except in compliance with the license . <nl> - * you may obtain a copy of the license at <nl> - * <nl> - * http : / / www . apache . org / licenses / license - 2 . 0 <nl> - * <nl> - * unless required by applicable law or agreed to in writing , software <nl> - * distributed under the license is distributed on an " as is " basis , <nl> - * without warranties or conditions of any kind , either express or implied . <nl> - * see the license for the specific language governing permissions and <nl> - * limitations under the license . <nl> - * / <nl> - package org . apache . ibatis . jdbc ; <nl> - <nl> - import static java . util . arrays . aslist ; <nl> - <nl> - import java . sql . connection ; <nl> - import java . sql . databasemetadata ; <nl> - import java . sql . sqlexception ; <nl> - import java . util . collection ; <nl> - import java . util . hashmap ; <nl> - import java . util . map ; <nl> - <nl> - import javax . sql . datasource ; <nl> - <nl> - public class datasourceutils { <nl> - <nl> - / * <nl> - * for each type , the supported databaseproductnames <nl> - * <nl> - * <nl> - * / <nl> - private static map < string , collection < string > > type_name = new hashmap < string , collection < string > > ( ) ; <nl> - <nl> - / * <nl> - * for each databaseproductname , the related type <nl> - * / <nl> - private static map < string , string > name_type = new hashmap < string , string > ( ) ; <nl> - <nl> - static { <nl> - register ( " cache " , " cache " ) ; <nl> - register ( " db2 " , " db2 " , <nl> - " db2 ( datadirect ) " ) ; <nl> - register ( " generic " , " db2 for as / 400 ( jtopen ) " , <nl> - " jdbc / odbc bridge " , " mckoi " ) ; <nl> - register ( " firebird " , " firebird " ) ; <nl> - register ( " frontbase " , " frontbase " ) ; <nl> - register ( " neoview " , " hp neoview " ) ; <nl> - register ( " hsql " , " hsqldb server " , <nl> - " hsqldb embedded " ) ; <nl> - register ( " h2 " , " h2 server " , <nl> - " h2 embedded " ) ; <nl> - register ( " informix " , " informix " , <nl> - " informix ( datadirect ) " ) ; <nl> - register ( " derby " , " javadb / derby server " , <nl> - " javadb / derby embedded " ) ; <nl> - register ( " jdatastore " , " jdatastore " ) ; <nl> - register ( " maxdb " , " maxdb " ) ; <nl> - register ( " mimer " , " mimer " ) ; <nl> - register ( " mysql " , " mysql " ) ; <nl> - register ( " netezza " , " netezza " ) ; <nl> - register ( " oracle " , " oracle thin " , <nl> - " oracle oci " , <nl> - " oracle ( datadirect ) " ) ; <nl> - register ( " pervasive " , " pervasive " ) ; <nl> - register ( " postgresql " , " postgresql " ) ; <nl> - register ( " progress " , " progress " ) ; <nl> - register ( " sqlite " , " sqlite " ) ; <nl> - register ( " sqlserver " , " sql server ( datadirect ) " , <nl> - " sql server ( jtds ) " , <nl> - " sql server ( microsoft jdbc driver ) " , <nl> - " sql server num ( microsoft jdbc driver ) " ) ; <nl> - register ( " sybase - ase " , " sybase ase ( jtds ) " , <nl> - " sybase ase ( jconnect ) " , <nl> - " sybase sql anywhere ( jconnect ) " ) ; <nl> - register ( " sybase " , " sybase ( datadirect ) " ) ; <nl> - } <nl> - <nl> - private static void register ( string type , string . . . databaseproductnames ) { <nl> - type_name . put ( type , aslist ( databaseproductnames ) ) ; <nl> - <nl> - for ( string databaseproductname : databaseproductnames ) { <nl> - name_type . put ( databaseproductname , type ) ; <nl> - } <nl> - } <nl> - <nl> - public static string getdatabasename ( datasource datasource ) { <nl> - connection con = null ; <nl> - try { <nl> - con = datasource . getconnection ( ) ; <nl> - if ( con = = null ) { <nl> - throw new runtimeexception ( " connection returned by datasource [ " + datasource + " ] was null " ) ; <nl> - } <nl> - <nl> - databasemetadata metadata = con . getmetadata ( ) ; <nl> - if ( metadata = = null ) { <nl> - throw new runtimeexception ( " databasemetadata returned by connection [ " + con + " ] was null " ) ; <nl> - } <nl> - <nl> - string productname = metadata . getdatabaseproductname ( ) ; <nl> - return name_type . get ( productname ) ; <nl> - } catch ( sqlexception e ) { <nl> - throw new runtimeexception ( " could not get database product name " , e ) ; <nl> - } finally { <nl> - if ( con ! = null ) { <nl> - try { <nl> - con . close ( ) ; <nl> - } catch ( sqlexception e ) { <nl> - / / ignored <nl> - } <nl> - } <nl> - } <nl> - } <nl> - <nl> - }
public class xmllanguagedriver implements languagedriver { <nl> } <nl>  <nl> public sqlsource createsqlsource ( configuration configuration , string script , class < ? > parametertype ) { <nl> - <nl> - arraylist < sqlnode > contents = new arraylist < sqlnode > ( ) ; <nl> - contents . add ( new textsqlnode ( script . tostring ( ) ) ) ; <nl> - mixedsqlnode rootsqlnode = new mixedsqlnode ( contents ) ; <nl> - return new dynamicsqlsource ( configuration , rootsqlnode ) ; <nl> + xmlscriptbuilder builder = new xmlscriptbuilder ( configuration , script ) ; <nl> + return builder . parsescriptnode ( ) ; <nl> } <nl> + <nl> } <nl> mmm a / src / main / java / org / apache / ibatis / scripting / xmltags / xmlscriptbuilder . java <nl> ppp b / src / main / java / org / apache / ibatis / scripting / xmltags / xmlscriptbuilder . java <nl>
public class bindingtest { <nl> } <nl> } <nl>  <nl> - @ ignore <nl> @ test <nl> public void shouldselectblogwithaparamnamedvalue ( ) { <nl> sqlsession session = sqlsessionfactory . opensession ( ) ;
import org . apache . ibatis . session . sqlsession ; <nl> import org . apache . ibatis . session . sqlsessionfactory ; <nl> import org . apache . ibatis . session . sqlsessionfactorybuilder ; <nl> import org . junit . before ; <nl> - import org . junit . ignore ; <nl> import org . junit . test ; <nl>  <nl> - @ ignore <nl> public class cachetest { <nl>  <nl> private static sqlsessionfactory sqlsessionfactory ;
public abstract class basebuilder { <nl> if ( alias = = null ) return null ; <nl> class < ? > type = resolveclass ( alias ) ; <nl> if ( ! typehandler . class . isassignablefrom ( type ) ) { <nl> - <nl> + throw new builderexception ( " type " + type . getname ( ) + " is not a valid typehandler because it does not implement typehandler interface " ) ; <nl> } <nl> @ suppresswarnings ( " unchecked " ) / / already verified it is a typehandler <nl> class < ? extends typehandler < ? > > handlertype = ( class < ? extends typehandler < ? > > ) type ;
public class baseexecutortest extends basedatatest { <nl> } <nl> } <nl>  <nl> - @ test ( expected = executorexception . class ) <nl> + @ test <nl> public void shouldselectauthorviaoutparams ( ) throws exception { <nl> datasource ds = createblogdatasource ( ) ; <nl> connection connection = ds . getconnection ( ) ; <nl>
public class fastresultsethandler implements resultsethandler { <nl> final resultmap resultmap = configuration . getresultmap ( resultmapid ) ; <nl> final defaultresulthandler resulthandler = new defaultresulthandler ( configuration . getdefaultlistresulthandlertype ( ) ) ; <nl> resultcolumncache resultcolumncache = new resultcolumncache ( cs . getmetadata ( ) , configuration ) ; <nl> - handlerowvalues ( rs , resultmap , resulthandler , new rowbounds ( ) , resultcolumncache ) ; <nl> + handlerowvalues ( rs , resultmap , resulthandler , new rowbounds ( ) , resultcolumncache ) ; <nl> metaparam . setvalue ( parametermapping . getproperty ( ) , resulthandler . getresultlist ( ) ) ; <nl> } else { <nl> throw new executorexception ( " parameter requires resultmap for output types of java . sql . resultset " ) ;
public class bindingtest { <nl> } <nl> } <nl>  <nl> - <nl> - @ ignore <nl> @ test ( expected = exception . class ) <nl> public void shouldfailwhenselectingoneblogwithnonexistentparam ( ) { <nl> sqlsession session = sqlsessionfactory . opensession ( ) ; <nl>
public class bindingtest { <nl> } <nl> } <nl>  <nl> - @ ignore <nl> @ test ( expected = exception . class ) <nl> public void shouldfailwhenselectingoneblogwithnullparam ( ) { <nl> sqlsession session = sqlsessionfactory . opensession ( ) ; <nl>
public class bindingtest { <nl> session . close ( ) ; <nl> } <nl> } <nl> - <nl> - @ ignore <nl> + <nl> + @ ignore / / decided that maps are dynamic so no existent params do not fail <nl> @ test ( expected = persistenceexception . class ) <nl> public void shouldfailwhenselectingoneblogwithnonexistentnestedparam ( ) { <nl> sqlsession session = sqlsessionfactory . opensession ( ) ;
public class scriptrunner { <nl> } catch ( exception e ) { <nl> / / ignore to workaround a bug in some connection pools <nl> } <nl> - commitconnection ( ) ; <nl> } <nl>  <nl> private void printresults ( statement statement , boolean hasresults ) {
try { <nl> def instrumentationtesttarget = " connectedandroidtest " <nl> def deviceserial = " " <nl>  <nl> - <nl> - / / if ( ! releasebranches . contains ( currentbranch ) ) { <nl> if ( ! releasebranches . contains ( currentbranch ) ) { <nl> / / build development branch <nl> useemulator = true <nl> mmm a / dependencies . list <nl> ppp b / dependencies . list <nl>
public class tableindexanddistincttest extends testcase { <nl> assertequals ( 7 , table . size ( ) ) ; <nl> } <nl>  <nl> - / / fixme : check or delete this . <nl> - <nl> - / * * / / * * <nl> - * should throw exception if trying to get distinct on columns where <nl> - * @ param index <nl> - * / / * <nl> - <nl> - @ test ( expectedexceptions = unsupportedoperationexception . class , dataprovider = " columnindex " ) <nl> - public void shouldtestdistincterrorwhennoindex ( long index ) { <nl> - <nl> - / / get a table with all available column types <nl> - table t = testhelper . gettablewithallcolumntypes ( ) ; <nl> - <nl> - tableview view = table . getdistinctview ( 1 ) ; <nl> - } * / <nl> - <nl> / * * <nl> * check that index can be set on multiple columns , with the string <nl> * @ param <nl> mmm a / realm / realm - library / src / main / cpp / util . hpp <nl> ppp b / realm / realm - library / src / main / cpp / util . hpp <nl>
public class realmobjectschematests { <nl> schema . renamefield ( fieldname , " bar " ) ; <nl> asserttrue ( schema . hasprimarykey ( ) ) ; <nl>  <nl> - <nl> - / / assertequals ( " bar " , schema . getprimarykey ( ) ) ; <nl> - assertequals ( " bar " , schema . table . getcolumnname ( schema . table . getprimarykey ( ) ) ) ; <nl> + assertequals ( " bar " , schema . getprimarykey ( ) ) ; <nl> } <nl>  <nl> @ test <nl> mmm a / realm / realm - library / src / androidtest / java / io / realm / realmschematests . java <nl> ppp b / realm / realm - library / src / androidtest / java / io / realm / realmschematests . java <nl>
public class realmquerytest extends androidtestcase { <nl> testhelper . populatepartialnullrowsfornumerictesting ( testrealm ) ; <nl> realmquery < nulltypes > query = testrealm . where ( nulltypes . class ) ; <nl>  <nl> - <nl> - assertequals ( ( 7 / ( double ) 3 ) / * should be num . 5 * / , query . average ( nulltypes . field_integer_null ) , num d ) ; <nl> - assertequals ( 3 . 0 / * should be num . 5 * / , query . average ( nulltypes . field_float_null ) , num f ) ; <nl> - assertequals ( 3 . 666 / * should be num . 5 * / , query . average ( nulltypes . field_double_null ) , num . 001d ) ; <nl> + assertequals ( 3 . 5 , query . average ( nulltypes . field_integer_null ) , num d ) ; <nl> + assertequals ( 4 . 5 , query . average ( nulltypes . field_float_null ) , num d ) ; <nl> + assertequals ( 5 . 5 , query . average ( nulltypes . field_double_null ) , num d ) ; <nl> } <nl>  <nl> / / test sum on empty columns <nl> mmm a / realm / realm - library / src / androidtest / java / io / realm / realmresultstest . java <nl> ppp b / realm / realm - library / src / androidtest / java / io / realm / realmresultstest . java <nl>
public class realmtest extends androidtestcase { <nl> realm . deleterealm ( realmconfig ) ; <nl> realm realm = realm . getinstance ( realmconfig ) ; <nl> realm . close ( ) ; <nl> - <nl> - try { <nl> - asserttrue ( realm . compactrealm ( realmconfig ) ) ; <nl> - fail ( ) ; <nl> - } catch ( illegalargumentexception expected ) { <nl> - } <nl> + asserttrue ( realm . compactrealm ( realmconfig ) ) ; <nl> + realm = realm . getinstance ( realmconfig ) ; <nl> + assertfalse ( realm . isclosed ( ) ) ; <nl> + realm . close ( ) ; <nl> } <nl>  <nl> public void testcompactencryptedpopulatedrealmfile ( ) { <nl>
public class realmtest extends androidtestcase { <nl>  <nl> populatetestrealm ( realm , num ) ; <nl> realm . close ( ) ; <nl> - <nl> - try { <nl> - asserttrue ( realm . compactrealm ( realmconfig ) ) ; <nl> - fail ( ) ; <nl> - } catch ( illegalargumentexception expected ) { <nl> - } <nl> + <nl> + asserttrue ( realm . compactrealm ( realmconfig ) ) ; <nl> + <nl> + realm = realm . getinstance ( realmconfig ) ; <nl> + assertfalse ( realm . isclosed ( ) ) ; <nl> + assertequals ( 100 , realm . allobjects ( alltypes . class ) . size ( ) ) ; <nl> + realm . close ( ) ; <nl> } <nl>  <nl> public void testcompactemptyrealmfile ( ) throws ioexception { <nl> mmm a / realm / realm - library / src / main / java / io / realm / baserealm . java <nl> ppp b / realm / realm - library / src / main / java / io / realm / baserealm . java <nl>
public class realmquerytest extends androidtestcase { <nl> testhelper . populateallnonnullrowsfornumerictesting ( testrealm ) ; <nl> realmquery < nulltypes > query = testrealm . where ( nulltypes . class ) ; <nl>  <nl> - <nl> - assertequals ( 43 . 0 / * should be num . 0 * / , query . average ( nulltypes . field_integer_null ) , num d ) ; <nl> + assertequals ( 2 . 0 , query . average ( nulltypes . field_integer_null ) , num d ) ; <nl> assertequals ( 7 . 0 / num , query . average ( nulltypes . field_float_null ) , num . 001d ) ; <nl> assertequals ( 8 . 0 / num , query . average ( nulltypes . field_double_null ) , num . 001d ) ; <nl> } <nl>
public class realmtest extends androidtestcase { <nl>  <nl> populatetestrealm ( realm , num ) ; <nl> realm . close ( ) ; <nl> - <nl> - try { <nl> - asserttrue ( realm . compactrealm ( realmconfig ) ) ; <nl> - fail ( ) ; <nl> - } catch ( illegalargumentexception expected ) { <nl> - } <nl> + asserttrue ( realm . isclosed ( ) ) ; <nl> + <nl> + asserttrue ( realm . compactrealm ( realmconfig ) ) ; <nl> + <nl> + realm = realm . getinstance ( realmconfig ) ; <nl> + assertequals ( 100 , realm . allobjects ( alltypes . class ) . size ( ) ) ; <nl> + realm . close ( ) ; <nl> } <nl>  <nl> public void testcompactemptyrealmfile ( ) throws ioexception { <nl> mmm a / realm / src / main / java / io / realm / baserealm . java <nl> ppp b / realm / src / main / java / io / realm / baserealm . java <nl>
import java . lang . annotation . target ; <nl> * they now has the option of adding the library project classes to their schema using <nl> * { @ code realmconfiguration . addmodule ( ) } . <nl> * <nl> - * @ see < a href = " " > <nl> + * @ see < a href = " https : / / github . com / realm / realm - java / tree / master / examples / realmmoduleappexample " > example of a project using modules < / a > <nl> * / <nl> @ retention ( retentionpolicy . runtime ) <nl> @ target ( elementtype . type ) <nl> mmm a / realm / src / main / java / io / realm / realm . java <nl> ppp b / realm / src / main / java / io / realm / realm . java <nl>
public class realmtest extends androidtestcase { <nl> byte [ ] key = new byte [ 64 ] ; <nl> random . nextbytes ( key ) ; <nl> realm realm = realm . getinstance ( getcontext ( ) , realm_name , key ) ; / / create starting realm with key1 <nl> - realm . executetransaction ( new realm . transaction ( ) { <nl> - @ override <nl> - public void execute ( realm realm ) { <nl> - realm . createobject ( alltypes . class ) ; <nl> - } <nl> - } ) ; <nl> realm . close ( ) ; <nl> random . nextbytes ( key ) ; <nl> try {
public class realmtest extends androidtestcase { <nl> } <nl> } <nl>  <nl> - <nl> - public void disabletestwriteencryptedcopy ( ) throws exception { <nl> + public void testwriteencryptedcopy ( ) throws exception { <nl> populatetestrealm ( ) ; <nl> long before = testrealm . where ( alltypes . class ) . count ( ) ; <nl> assertequals ( test_data_size , before ) ; <nl> mmm a / realm / src / main / java / io / realm / realm . java <nl> ppp b / realm / src / main / java / io / realm / realm . java <nl>
public class realmresultstest extends androidtestcase { <nl> / / average = sum / n = b + ( n - 1 ) / 2 <nl> assertequals ( 1 . 234567 + num . 5 * ( n - num . 0 ) , resultlist . average ( field_float ) , num . 0001 ) ; <nl> } <nl> - <nl> - public void disabledtestremove ( ) { <nl> + <nl> + public void testremove ( ) { <nl> realmresults < alltypes > resultlist = testrealm . where ( alltypes . class ) . findall ( ) ; <nl> testrealm . begintransaction ( ) ; <nl> resultlist . remove ( 0 ) ; <nl>
public class realmresultstest extends androidtestcase { <nl> assertequals ( 1 , alltypes . getcolumnlong ( ) ) ; <nl> } <nl>  <nl> - <nl> - public void disabledtestremovelast ( ) { <nl> + public void testremovelast ( ) { <nl> realmresults < alltypes > resultlist = testrealm . where ( alltypes . class ) . findall ( ) ; <nl> - <nl> testrealm . begintransaction ( ) ; <nl> - <nl> resultlist . removelast ( ) ; <nl> - <nl> testrealm . committransaction ( ) ; <nl>  <nl> assertequals ( " resultlist . removelast did not remove record " , test_data_size - num , resultlist . size ( ) ) ; <nl>
public class realmversionchecker { <nl>  <nl> public static final string realm_android_download_url = " http : / / static . realm . io / downloads / java / latest " ; <nl> private static final string version_url = " http : / / static . realm . io / update / java ? " ; <nl> - private static final string realm_version = " 0 . 78 . 0 " ; <nl> + private static final string realm_version = version . version ; <nl> private static final int read_timeout = num ; <nl> private static final int connect_timeout = num ; <nl>  <nl> mmm / dev / null <nl> ppp b / realm - annotations - processor / src / main / templates / version . java <nl>
public class realmlist < e extends realmobject > extends abstractlist < e > { <nl> @ override <nl> public e remove ( int location ) { <nl> if ( managedmode ) { <nl> + e removeditem = get ( location ) ; <nl> view . remove ( location ) ; <nl> - return null ; <nl> + return removeditem ; <nl> } else { <nl> return nonmanagedlist . remove ( location ) ; <nl> }
function check_clean_repo ( ) { <nl> # fast forward repository master to newest version or fails if it is not possible <nl> function update_master ( ) { <nl> git checkout master <nl> - git pull # <nl> - <nl> - # local = $ ( git rev - parse @ ) <nl> - # remote = $ ( git rev - parse @ { u } ) <nl> - # base = $ ( git merge - base @ @ { u } ) <nl> - # <nl> - # if [ $ local = $ remote ] ; then <nl> - # echo " up - to - date " <nl> - # elif [ $ local = $ base ] ; then <nl> - # echo " need to pull " <nl> - # elif [ $ remote = $ base ] ; then <nl> - # echo " need to push " <nl> - # else <nl> - # echo " diverged " <nl> - # fi <nl> + <nl> + local = $ ( git rev - parse @ ) <nl> + remote = $ ( git rev - parse @ { u } ) <nl> + base = $ ( git merge - base @ @ { u } ) <nl> + <nl> + if [ $ local = $ remote ] ; then <nl> + echo " up - to - date " <nl> + elif [ $ local = $ base ] ; then <nl> + echo " need to pull " <nl> + git pull <nl> + else <nl> + echo " cannot continue automatically . manually make sure that master is up - to - date . then run script again . " <nl> + fi <nl> } <nl>  <nl> # cleanup branches from a previous release of the same version that failed for some reason <nl>
public class realm { <nl> try { <nl> obj . populateusingjsonobject ( json . getjsonobject ( i ) ) ; <nl> } catch ( exception e ) { <nl> - <nl> throw new realmexception ( " could not map json " , e ) ; <nl> } <nl> } <nl> } <nl>  <nl> - <nl> / * * <nl> * add a json inputstream to the realm as new objects . this must be done inside a transaction . <nl> * <nl>
public abstract class realmbaseadapter < t extends realmobject > extends baseadapte <nl> } <nl>  <nl> @ override <nl> + @ deprecated <nl> public long getitemid ( int i ) { <nl> - return realmresults . get ( i ) . realmgetrow ( ) . getindex ( ) ; <nl> + throw new unsupportedoperationexception ( " realms are unordered , hence its objects don ' t have an immutable id " ) ; <nl> } <nl>  <nl> / * *
public class realmresults < e extends realmobject > extends abstractlist < e > { <nl> * @ return the minimum value . <nl> * / <nl> public number min ( string fieldname ) { <nl> - <nl> long columnindex = table . getcolumnindex ( fieldname ) ; <nl> switch ( table . getcolumntype ( columnindex ) ) { <nl> case integer : <nl>
public class realmresults < e extends realmobject > extends abstractlist < e > { <nl> * @ return the maximum value . <nl> * / <nl> public number max ( string fieldname ) { <nl> - <nl> long columnindex = table . getcolumnindex ( fieldname ) ; <nl> switch ( table . getcolumntype ( columnindex ) ) { <nl> case integer : <nl>
public class group { <nl> public group ( string filepath , openmode mode ) { <nl> if ( mode . equals ( openmode . read_only ) ) <nl> this . immutable = true ; / / group immutable <nl> - <nl> this . nativeptr = createnative ( filepath , mode . value ) ; <nl> checknativeptr ( ) ; <nl> }
public class tableview implements tableorview { <nl>  <nl> protected native byte [ ] nativegetbytearray ( long nativeptr , long columnindex , long rowindex ) ; <nl>  <nl> - <nl> @ override <nl> public columntype getmixedtype ( long columnindex , long rowindex ) { <nl> return columntype . fromnativevalue ( nativegetmixedtype ( nativeptr , columnindex , rowindex ) ) ; <nl>
public class tableview implements tableorview { <nl> * @ param columnindex column <nl> * @ param value <nl> * / <nl> - <nl> @ override <nl> public void addlong ( long columnindex , long value ) { <nl> if ( immutable ) throwimmutable ( ) ; <nl>
public class tableview implements tableorview { <nl>  <nl> protected native long nativefindfirstint ( long nativetableviewptr , long columnindex , long value ) ; <nl>  <nl> - <nl> @ override <nl> public long findfirstboolean ( long columnindex , boolean value ) { <nl> return nativefindfirstbool ( nativeptr , columnindex , value ) ; <nl>
public class tableview implements tableorview { <nl>  <nl> protected native long nativefindfirstbool ( long nativeptr , long columnindex , boolean value ) ; <nl>  <nl> - <nl> @ override <nl> public long findfirstfloat ( long columnindex , float value ) { <nl> return nativefindfirstfloat ( nativeptr , columnindex , value ) ; <nl>
public class tableview implements tableorview { <nl>  <nl> protected native long nativefindfirstfloat ( long nativeptr , long columnindex , float value ) ; <nl>  <nl> - <nl> @ override <nl> public long findfirstdouble ( long columnindex , double value ) { <nl> return nativefindfirstdouble ( nativeptr , columnindex , value ) ; <nl>
public class tableview implements tableorview { <nl>  <nl> protected native long nativefindfirstdouble ( long nativeptr , long columnindex , double value ) ; <nl>  <nl> - <nl> @ override <nl> public long findfirstdate ( long columnindex , date date ) { <nl> return nativefindfirstdate ( nativeptr , columnindex , date . gettime ( ) / 1000 ) ; <nl>
public class tableview implements tableorview { <nl>  <nl> protected native long nativefindallint ( long nativeptr , long columnindex , long value ) ; <nl>  <nl> - <nl> @ override <nl> public tableview findallboolean ( long columnindex , boolean value ) { <nl> return new tableview ( this , nativefindallbool ( nativeptr , columnindex , value ) , immutable ) ; <nl>
public class tableview implements tableorview { <nl>  <nl> protected native long nativefindallbool ( long nativeptr , long columnindex , boolean value ) ; <nl>  <nl> - <nl> @ override <nl> public tableview findallfloat ( long columnindex , float value ) { <nl> return new tableview ( this , nativefindallfloat ( nativeptr , columnindex , value ) , immutable ) ; <nl>
public class tableview implements tableorview { <nl>  <nl> protected native long nativefindallfloat ( long nativeptr , long columnindex , float value ) ; <nl>  <nl> - <nl> @ override <nl> public tableview findalldouble ( long columnindex , double value ) { <nl> return new tableview ( this , nativefindalldouble ( nativeptr , columnindex , value ) , immutable ) ; <nl>
public class tableview implements tableorview { <nl>  <nl> protected native long nativefindalldouble ( long nativeptr , long columnindex , double value ) ; <nl>  <nl> - <nl> @ override <nl> public tableview findalldate ( long columnindex , date date ) { <nl> return new tableview ( this , nativefindalldate ( nativeptr , columnindex , date . gettime ( ) / 1000 ) , immutable ) ;
public class groupexamples { <nl> / / e . g send byte array through output stream <nl> try { <nl> outputstream . write ( array ) ; <nl> - } catch ( ioexception e ) { <nl> - <nl> + } catch ( exception e ) { <nl> e . printstacktrace ( ) ; <nl> } <nl> / /
public class jnitransactions { <nl> clear ( ) ; <nl> } <nl>  <nl> - <nl> - @ test ( enabled = false ) <nl> + @ test ( ) <nl> public void mustallowdoublecommitandrollback ( ) { <nl> - writetransaction trans = db . beginwrite ( ) ; <nl> - table tbl = trans . gettable ( " employeetable " ) ; <nl> - tbl . addcolumn ( columntype . columntypestring , " name " ) ; <nl> - tbl . addcolumn ( columntype . columntypeint , " number " ) ; <nl> - <nl> - / / allow commit before any changes <nl> - trans . commit ( ) ; <nl> - <nl> - tbl . add ( " hi " , num ) ; <nl> - assertequals ( 1 , tbl . size ( ) ) ; <nl> - <nl> - / / allow double commit ( ) <nl> - trans . commit ( ) ; <nl> - trans . commit ( ) ; <nl> - <nl> - / / allow double rollback <nl> - tbl . add ( " hello " , num ) ; <nl> - assertequals ( 2 , tbl . size ( ) ) ; <nl> - trans . rollback ( ) ; <nl> - trans . rollback ( ) ; <nl> - assertequals ( 1 , tbl . size ( ) ) ; <nl> - <nl> - clear ( ) ; <nl> + { <nl> + writetransaction trans = db . beginwrite ( ) ; <nl> + table tbl = trans . gettable ( " employeetable " ) ; <nl> + tbl . addcolumn ( columntype . columntypestring , " name " ) ; <nl> + tbl . addcolumn ( columntype . columntypeint , " number " ) ; <nl> + <nl> + / / allow commit before any changes <nl> + assertequals ( 0 , tbl . size ( ) ) ; <nl> + tbl . add ( " hello " , num ) ; <nl> + trans . commit ( ) ; <nl> + } <nl> + { <nl> + writetransaction trans = db . beginwrite ( ) ; <nl> + table tbl = trans . gettable ( " employeetable " ) ; <nl> + / / allow double rollback <nl> + tbl . add ( " hello " , num ) ; <nl> + assertequals ( 2 , tbl . size ( ) ) ; <nl> + trans . rollback ( ) ; <nl> + trans . rollback ( ) ; <nl> + trans . rollback ( ) ; <nl> + trans . rollback ( ) ; <nl> + } <nl> + { <nl> + readtransaction trans = db . beginread ( ) ; <nl> + table tbl = trans . gettable ( " employeetable " ) ; <nl> + assertequals ( 1 , tbl . size ( ) ) ; <nl> + trans . endread ( ) ; <nl> + } <nl> + <nl> + clear ( ) ; <nl> } <nl>  <nl> / / test : exception at all mutable methods in tablebase , tableview ,
public class readtransaction extends group { <nl> } <nl>  <nl> / / @ override <nl> + @ deprecated <nl> public void close ( ) <nl> { <nl> / / system . out . println ( " read - close " ) ; <nl> - <nl> db . endread ( ) ; <nl> } <nl>  <nl> mmm a / tightdb - java - core / src / main / java / com / tightdb / writetransaction . java <nl> ppp b / tightdb - java - core / src / main / java / com / tightdb / writetransaction . java <nl>
public class columntypeviewtest { <nl>  <nl> v = t . where ( ) . findall ( ) ; <nl> } <nl> - <nl> - / * <nl> + <nl> / / on date column________________________________ <nl> @ test ( expectedexceptions = illegalargumentexception . class ) <nl> public void getstringondatecolumn ( ) { <nl>
public class table implements tableorview { <nl> } <nl>  <nl> protected native long nativeaddemptyrow ( long nativetableptr , long rows ) ; <nl> - <nl> - public void add ( object . . . values ) { <nl> - insert ( size ( ) , values ) ; <nl> + <nl> + public long add ( object . . . values ) { <nl> + long rowindex = size ( ) ; <nl> + insert ( rowindex , values ) ; <nl> + return rowindex ; <nl> } <nl>  <nl>  <nl> mmm a / tightdb - java - test / src / test / java / com / tightdb / jnitableinserttest . java <nl> ppp b / tightdb - java - test / src / test / java / com / tightdb / jnitableinserttest . java <nl>
public class tablequerytest extends abstracttest { <nl> assertequals ( 1 , employees . firstname . endswith ( " hny " ) . findall ( ) . size ( ) ) ; <nl> assertequals ( 2 , employees . firstname . contains ( " ohn " ) . findall ( ) . size ( ) ) ; <nl>  <nl> - if ( tightdb . osiswindows ( ) ) { <nl> - <nl> - assertequals ( 1 , employees . firstname . eq ( " john " , false ) . findall ( ) . size ( ) ) ; <nl> - assertequals ( 1 , employees . firstname . equal ( " john " , false ) . findall ( ) . size ( ) ) ; <nl> - assertequals ( 2 , employees . firstname . startswith ( " j " , false ) . findall ( ) . size ( ) ) ; <nl> - assertequals ( 1 , employees . firstname . endswith ( " hny " , false ) . findall ( ) . size ( ) ) ; <nl> - assertequals ( 2 , employees . firstname . contains ( " ohn " , false ) . findall ( ) . size ( ) ) ; <nl> - } <nl> + assertequals ( 1 , employees . firstname . eq ( " john " , false ) . findall ( ) . size ( ) ) ; <nl> + assertequals ( 1 , employees . firstname . equal ( " john " , false ) . findall ( ) . size ( ) ) ; <nl> + assertequals ( 2 , employees . firstname . startswith ( " j " , false ) . findall ( ) . size ( ) ) ; <nl> + assertequals ( 1 , employees . firstname . endswith ( " hny " , false ) . findall ( ) . size ( ) ) ; <nl> + assertequals ( 2 , employees . firstname . contains ( " ohn " , false ) . findall ( ) . size ( ) ) ; <nl> } <nl>  <nl> @ test <nl> mmm a / tightdb_jni / src / com_tightdb_table . cpp <nl> ppp b / tightdb_jni / src / com_tightdb_table . cpp <nl>
jniexport void jnicall java_com_tightdb_table_nativemovelastover <nl> ( jnienv * env , jobject , jlong nativetableptr , jlong rowindex ) <nl> { <nl> if ( ! row_index_valid_offset ( env , tbl ( nativetableptr ) , rowindex , - 1 ) ) return ; <nl> - # if num <nl> tbl ( nativetableptr ) - > move_last_over ( s ( rowindex ) ) ; <nl> - # endif <nl> } <nl>  <nl>  <nl>
public class tablequerytest extends abstracttest { <nl> assertequals ( 40000 , results . salary . sum ( 0 , util . infinite ) ) ; / / both <nl>  <nl> assertequals ( 20000 . 0 , results . salary . average ( ) ) ; <nl> - <nl> assertequals ( 30000 . 0 , results . salary . average ( 1 , num ) ) ; / / second <nl> assertequals ( 20000 . 0 , results . salary . average ( 0 , util . infinite ) ) ; / / both <nl> - <nl> - <nl> - / / assertequals ( 10000 . 0 , results . salary . average ( 0 , num ) ) ; / / first <nl> + assertequals ( 10000 . 0 , results . salary . average ( 0 , num ) ) ; / / first <nl> } <nl>  <nl> @ test ( expectedexceptions = arrayindexoutofboundsexception . class )
jniexport jobject jnicall java_com_tightdb_tableviewbase_nativegetmixed ( <nl> return createjmixedfrommixed ( env , value ) ; <nl> } <nl>  <nl> + jniexport jlong jnicall java_com_tightdb_tableviewbase_nativegetsubtablesize ( <nl> + jnienv * env , jobject jtable , jlong nativeviewptr , jlong columnindex , jlong rowindex ) <nl> + { <nl> + if ( ! index_and_type_valid ( env , tv ( nativeviewptr ) , columnindex , rowindex , column_type_table ) ) return num ; <nl>  <nl> - <nl> + return tv ( nativeviewptr ) - > get_subtable_size ( s ( columnindex ) , s ( rowindex ) ) ; <nl> + } <nl>  <nl> jniexport jlong jnicall java_com_tightdb_tableviewbase_nativegetsubtable ( <nl> jnienv * env , jobject jtableview , jlong nativeviewptr , jlong columnindex , jlong rowindex ) <nl> binary files a / tightdb_jni32 . dll and b / tightdb_jni32 . dll differ
jniexport jlong jnicall java_com_tightdb_group_createnative___3b ( <nl> jniexport jlong jnicall java_com_tightdb_group_createnative__ljava_nio_bytebuffer_2 ( <nl> jnienv * env , jobject jtablebase , jobject jbytebuffer ) <nl> { <nl> - <nl> - group * pgroup = new group ( static_cast < const char * > ( env - > getdirectbufferaddress ( jbytebuffer ) ) , <nl> - s ( env - > getdirectbuffercapacity ( jbytebuffer ) ) ) ; <nl> + binarydata data ; <nl> + if ( ! getbinarydata ( env , jbytebuffer , data ) ) <nl> + return num ; <nl> + <nl> + group * pgroup = new group ( data . pointer , data . len ) ; <nl> if ( ! ( pgroup - > is_valid ( ) ) ) { <nl> delete pgroup ; <nl> throwexception ( env , illegalargument , " data is not a valid tightdb database " ) ; <nl> - return null ; <nl> + return num ; <nl> } <nl> return reinterpret_cast < jlong > ( pgroup ) ; <nl> }
jniexport jboolean jnicall java_com_tightdb_group_nativeisvalid ( <nl> return g ( nativegroupptr ) - > is_valid ( ) ; <nl> } <nl>  <nl> - <nl> - jniexport jint jnicall java_com_tightdb_group_nativegettablecount ( <nl> + jniexport jlong jnicall java_com_tightdb_group_nativegettablecount ( <nl> jnienv * env , jobject jgroup , jlong nativegroupptr ) <nl> { <nl> - return g ( nativegroupptr ) - > get_table_count ( ) ; <nl> + return static_cast < jlong > ( g ( nativegroupptr ) - > get_table_count ( ) ) ; <nl> } <nl>  <nl> jniexport jboolean jnicall java_com_tightdb_group_nativehastable ( <nl>
import java . util . scanner ; <nl>  <nl> public class util { <nl>  <nl> - / / add version check <nl> - <nl> - <nl> public static long getnativememusage ( ) { <nl> return nativegetmemusage ( ) ; <nl> } <nl> static native long nativegetmemusage ( ) ; <nl>  <nl> + public static boolean versioncompatible ( ) { <nl> + return ( nativegetversion ( ) = = num ) ; <nl> + } <nl> + <nl> + static native int nativegetversion ( ) ; <nl> + <nl> / / set to level = 1 to get some trace from jni native part . <nl> public static void setdebuglevel ( int level ) { <nl> nativesetdebuglevel ( level ) ; <nl> } <nl> static native void nativesetdebuglevel ( int level ) ; <nl>  <nl> - <nl> static void javaprint ( string txt ) { <nl> system . out . print ( txt ) ; <nl> } <nl> mmm a / tightdb_jni / src / com_tightdb_util . cpp <nl> ppp b / tightdb_jni / src / com_tightdb_util . cpp <nl>
public class mixed { <nl> mixed = new mixed ( ( bytebuffer ) value ) ; <nl> } else if ( value instanceof byte [ ] ) { <nl> mixed = new mixed ( ( byte [ ] ) value ) ; <nl> - <nl> - / / mixed = new mixed ( bytebuffer . wrap ( ( byte [ ] ) value ) ) ; <nl> - / * <nl> - * byte [ ] array = ( byte [ ] ) value ; bytebuffer buffer = <nl> - * bytebuffer . allocatedirect ( array . length ) ; buffer . put ( array ) ; mixed <nl> - * = new mixed ( buffer ) ; <nl> - * / <nl> } else { <nl> throw new illegalargumentexception ( " the value is of unsupported type : " + value . getclass ( ) ) ; <nl> } <nl> mmm a / src / test / java / com / tightdb / jnimixedtypetest . java <nl> ppp b / src / test / java / com / tightdb / jnimixedtypetest . java <nl>
class nativeimagevm ( graalvm ) : <nl> pgo_args = [ ' - - pgo = ' + config . latest_profile_path ] <nl> pgo_args + = [ ' - h : ' + ( ' + ' if self . pgo_context_sensitive else ' - ' ) + ' pgocontextsensitivityenabled ' ] <nl> pgo_args + = [ ' - h : + aotinliner ' ] if self . pgo_aot_inline else [ ' - h : - aotinliner ' ] <nl> - # <nl> - instrument_args = [ ' - - pgo - instrument ' , ' - - pgo - sampling ' ] + ( [ ] if i = = num else pgo_args ) <nl> + # gr - 40154 - - pgo - sampling does not work with g1 for some reason <nl> + if self . gc = = ' g1 ' : <nl> + instrument_args = [ ' - - pgo - instrument ' ] + ( [ ] if i = = num else pgo_args ) <nl> + else : <nl> + instrument_args = [ ' - - pgo - instrument ' , ' - - pgo - sampling ' ] + ( [ ] if i = = num else pgo_args ) <nl> if self . jdk_profiles_collect : <nl> instrument_args + = [ ' - h : + profilingenabled ' , ' - h : + aotpriorityinline ' , ' - h : profilingpackageprefixes = { } ' . format ( self . generate_profiling_package_prefixes ( ) ) ]
class basegraalvmlayoutdistribution ( _with_metaclass ( abcmeta , mx . layoutdistributi <nl> check_versions ( _src_jdk , graalvm_version_regex = graalvm_version_regex , expect_graalvm = false , check_jvmci = false ) <nl>  <nl> # add base jdk <nl> - # <nl> - exclude_base = _src_jdk_dir <nl> - exclusion_list = [ ] <nl> - if src_jdk_base ! = ' . ' : <nl> - exclude_base = join ( exclude_base , src_jdk_base ) <nl> if mx . get_os ( ) = = ' darwin ' : <nl> # since on darwin the jimage is added to ` contents / home ` , ` incl_list ` must contain ` contents / macos ` and ` contents / info . plist ` <nl> incl_list = _patch_darwin_jdk ( ) <nl>
local repo_config = import ' . . / . . / . . / repo - configuration . libsonnet ' ; <nl> name : ' daily - bench - vm - ' + vm . vm_setup . short_name + ' - agentscript - js - java17 - linux - amd64 ' , <nl> } , <nl>  <nl> - # <nl> - # vm_common . gate_vm_linux_amd64 + self . vm_bench_polybenchmarks_linux_common ( is_gate = true ) + { name : ' gate - vm - ' + vm . vm_setup . short_name + ' - polybenchmarks - linux - amd64 ' } , <nl> + vm_common . gate_vm_linux_amd64 + self . vm_bench_polybenchmarks_linux_common ( is_gate = true ) + { name : ' gate - vm - ' + vm . vm_setup . short_name + ' - polybenchmarks - linux - amd64 ' } , <nl> vm_common . gate_vm_linux_amd64 + self . vm_gate_polybench_linux + { name : ' gate - vm - ' + vm . vm_setup . short_name + ' - polybench - linux - amd64 ' } , <nl> ] ,
local repo_config = import ' . . / . . / . . / repo - configuration . libsonnet ' ; <nl> name : ' daily - bench - vm - ' + vm . vm_setup . short_name + ' - agentscript - js - java17 - linux - amd64 ' , <nl> } , <nl>  <nl> - # <nl> - # vm_common . gate_vm_linux_amd64 + self . vm_bench_polybenchmarks_linux_common ( is_gate = true ) + { name : ' gate - vm - ' + vm . vm_setup . short_name + ' - polybenchmarks - linux - amd64 ' } , <nl> + vm_common . gate_vm_linux_amd64 + self . vm_bench_polybenchmarks_linux_common ( is_gate = true ) + { name : ' gate - vm - ' + vm . vm_setup . short_name + ' - polybenchmarks - linux - amd64 ' } , <nl> vm_common . gate_vm_linux_amd64 + self . vm_gate_polybench_linux + { name : ' gate - vm - ' + vm . vm_setup . short_name + ' - polybench - linux - amd64 ' } , <nl> ] ,
public final class hotspotoptimizedcalltarget extends optimizedcalltarget { <nl> return ; <nl> } <nl>  <nl> - <nl> - / / if ( oldcode ! = invalid_code & & invalidateinstalledcode ! = null ) { <nl> - / / try { <nl> - / / invalidateinstalledcode . invoke ( oldcode , false ) ; <nl> - / / } catch ( error e ) { <nl> - / / throw e ; <nl> - / / } catch ( throwable throwable ) { <nl> - / / throw new internalerror ( throwable ) ; <nl> - / / } <nl> - / / } <nl> + if ( oldcode ! = invalid_code & & invalidateinstalledcode ! = null ) { <nl> + try { <nl> + invalidateinstalledcode . invoke ( oldcode , false ) ; <nl> + } catch ( error e ) { <nl> + throw e ; <nl> + } catch ( throwable throwable ) { <nl> + throw new internalerror ( throwable ) ; <nl> + } <nl> + } <nl>  <nl> / / a default nmethod can be called from entry points in the vm ( e . g . , method : : _code ) <nl> / / and so allowing it to be installed here would invalidate the truth of
local sc = ( import " ci_common / sulong - common . jsonnet " ) ; <nl>  <nl> sc . gate + $ . sulong + sc . labsjdk_ce_17 + sc . linux_aarch64 + sc . llvmbundled + sc . requiregmp + sc . gatetags ( basictagsnonwcc ) + { name : " gate - sulong - basic - llvm - jdk17 - linux - aarch64 " , timelimit : " 30 : 00 " } , <nl>  <nl> - # gr - 40713 <nl> - # <nl> sc . gate + $ . sulong + sc . labsjdk_ce_17 + sc . darwin_aarch64 + sc . llvmbundled + sc . requiregmpdarwinaarch64 + sc . gatetags ( basictagsnonwcc ) + { name : " gate - sulong - basic - jdk17 - darwin - aarch64 " , timelimit : " 30 : 00 " } , <nl>  <nl> sc . weekly + $ . sulong + sc . labsjdk_ce_17 + sc . linux_amd64 + sc . llvmbundled + sc . requiregmp + sc . requiregcc + $ . sulong_coverage { name : " weekly - sulong - coverage - jdk17 - linux - amd64 " } , <nl> mmm a / sulong / projects / com . oracle . truffle . llvm . parser . factories / src / com / oracle / truffle / llvm / parser / factories / basicnodefactory . java <nl> ppp b / sulong / projects / com . oracle . truffle . llvm . parser . factories / src / com / oracle / truffle / llvm / parser / factories / basicnodefactory . java <nl>
public class basicnodefactory implements nodefactory { <nl> } <nl>  <nl> if ( intrinsicname . startswith ( " llvm . aarch64 . neon " ) ) { <nl> - <nl> string op = intrinsicname . substring ( " llvm . aarch64 . neon . " . length ( ) ) ; <nl> switch ( op ) { <nl> case " ld1x2 . v16i8 . p0i8 " :
<nl> " gate - compiler - benchmarktest - labsjdk - 11 - linux - amd64 " : { } , <nl> " gate - compiler - benchmarktest - labsjdk - 17 - linux - amd64 " : { } , <nl>  <nl> - " gate - compiler - truffle_xcomp - labsjdk - 17 - linux - amd64 " : t ( " 1 : 30 : 00 " ) + { capabilities + : [ " ! s3_16_32 " ] } , # <nl> + " gate - compiler - truffle_xcomp - labsjdk - 17 - linux - amd64 " : t ( " 1 : 30 : 00 " ) , <nl>  <nl> " gate - compiler - bootstrap_lite - labsjdk - 11 - darwin - amd64 " : t ( " 1 : 00 : 00 " ) + c . mach5_target , <nl> " gate - compiler - bootstrap_lite - labsjdk - 17 - darwin - amd64 " : t ( " 1 : 00 : 00 " ) + c . mach5_target ,
<nl> " gate - compiler - benchmarktest - labsjdk - 11 - linux - amd64 " : { } , <nl> " gate - compiler - benchmarktest - labsjdk - 17 - linux - amd64 " : { } , <nl>  <nl> - " gate - compiler - truffle_xcomp - labsjdk - 17 - linux - amd64 " : t ( " 1 : 30 : 00 " ) + { capabilities + : [ " ! s3_16_32 " ] } , # <nl> + " gate - compiler - truffle_xcomp - labsjdk - 17 - linux - amd64 " : t ( " 1 : 30 : 00 " ) , <nl>  <nl> " gate - compiler - bootstrap_lite - labsjdk - 11 - darwin - amd64 " : t ( " 1 : 00 : 00 " ) + c . mach5_target , <nl> " gate - compiler - bootstrap_lite - labsjdk - 17 - darwin - amd64 " : t ( " 1 : 00 : 00 " ) + c . mach5_target ,
public final class hostedmethod implements sharedmethod , wrappedjavamethod , grap <nl> private final localvariabletable localvariabletable ; <nl>  <nl> private final string name ; <nl> - <nl> final string uniqueshortname ; <nl>  <nl> public static hostedmethod create ( hosteduniverse universe , analysismethod wrapped , hostedtype holder , signature signature , <nl>
public abstract class optimizedcalltarget implements compilabletruffleast , rootc <nl>  <nl> @ truffleboundary <nl> private boolean lasttiercompile ( ) { <nl> - maybesubmitcallerforcompilation ( ) ; <nl> + maybesubmitcallerforcompilation ( this , rootnode . getparentframedescriptor ( ) ) ; <nl> return compile ( true ) ; <nl> } <nl>  <nl> - private void maybesubmitcallerforcompilation ( ) { <nl> - if ( ! polyglotcompileroptions . propagatehotnesstosinglecaller . getvalue ( getoptionvalues ( ) ) ) { <nl> - return ; <nl> - } <nl> - framedescriptor parentframedescriptor = rootnode . getparentframedescriptor ( ) ; <nl> - if ( parentframedescriptor = = null ) { <nl> - return ; <nl> - } <nl> - maybesubmitcallerforcompilation ( this , parentframedescriptor ) ; <nl> - } <nl> private static boolean maybesubmitcallerforcompilation ( optimizedcalltarget current , framedescriptor parentframedescriptor ) { <nl> - if ( current . singlecallnode = = no_call | | current . singlecallnode = = multiple_calls ) { <nl> + if ( ! polyglotcompileroptions . submitlexicalsinglecaller . getvalue ( current . getoptionvalues ( ) ) | | <nl> + parentframedescriptor = = null | | <nl> + current . singlecallnode = = no_call | | <nl> + current . singlecallnode = = multiple_calls ) { <nl> return false ; <nl> } <nl> - optimizeddirectcallnode optimizeddirectcallnode = current . singlecallnode . get ( ) ; <nl> - assert optimizeddirectcallnode ! = null ; <nl> - rootnode callerrootnode = optimizeddirectcallnode . getrootnode ( ) ; <nl> + optimizeddirectcallnode callercallnode = current . singlecallnode . get ( ) ; <nl> + assert callercallnode ! = null ; <nl> + rootnode callerrootnode = callercallnode . getrootnode ( ) ; <nl> if ( callerrootnode = = null ) { <nl> return false ; <nl> } <nl> - optimizedcalltarget onlycaller = ( optimizedcalltarget ) callerrootnode . getcalltarget ( ) ; <nl> - boolean submitted ; <nl> - if ( callerrootnode . getframedescriptor ( ) . equals ( parentframedescriptor ) ) { <nl> - onlycaller . forcecompilesomehow ( ) ; <nl> - submitted = true ; <nl> - } else { <nl> - submitted = maybesubmitcallerforcompilation ( onlycaller , parentframedescriptor ) ; <nl> - } <nl> - if ( submitted ) { <nl> - optimizeddirectcallnode . forceinlining ( ) ; <nl> + optimizedcalltarget callercalltarget = ( optimizedcalltarget ) callerrootnode . getcalltarget ( ) ; <nl> + if ( callerrootnode . getframedescriptor ( ) . equals ( parentframedescriptor ) | | maybesubmitcallerforcompilation ( callercalltarget , parentframedescriptor ) ) { <nl> + callercallnode . forceinlining ( ) ; <nl> + callercalltarget . lasttiercompile ( ) ; <nl> + return true ; <nl> } <nl> - return submitted ; <nl> - } <nl> - <nl> - private void forcecompilesomehow ( ) { <nl> - <nl> + return false ; <nl> } <nl>  <nl> private object executerootnode ( virtualframe frame , compilationstate tier ) {
public final class target_java_lang_thread { <nl> / * injected target_java_lang_thread instance field initialization . * / <nl> this . threaddata = new threaddata ( ) ; <nl>  <nl> - <nl> - boolean inheritthreadlocals = false ; <nl> - / * initialize the rest of the thread object , ignoring ` characteristics ` . * / <nl> + boolean inheritthreadlocals = ( characteristics & no_inherit_thread_locals ) = = num ; <nl> + / * <nl> + * initialize the rest of the thread object , ignoring ` characteristics ` except for inherit <nl> + * thread locals . <nl> + * / <nl> string namelocal = ( name ! = null ) ? name : genthreadname ( ) ; <nl> javathreads . initializenewthread ( this , g , target , namelocal , stacksize , acc , inheritthreadlocals ) ; <nl> }
public final class compilationalarm implements autocloseable { <nl> @ option ( help = " time limit in seconds before a compilation expires ( 0 to disable the limit ) . " + <nl> " a non - zero value for this option is doubled if assertions are enabled and quadrupled if detailedasserts is true . " , <nl> type = optiontype . debug ) <nl> - <nl> - public static final optionkey < integer > compilationexpirationperiod = new optionkey < > ( 0 ) ; <nl> + public static final optionkey < integer > compilationexpirationperiod = new optionkey < > ( 300 ) ; <nl> / / @ formatter : on <nl> }
public class callstackframemethodinfo { <nl> private int entersafepointcheckobject = initial_method_id ; <nl>  <nl> public void addmethodinfo ( resolvedjavamethod method , int methodid ) { <nl> - sampledmethods . put ( methodid , method . format ( " % h . % n " ) ) ; <nl> - <nl> - if ( entersafepointcheckid = = initial_method_id & & method . format ( " % h . % n " ) . contains ( enter_safepoint_method_name ) ) { <nl> + string formattedmethod = method . format ( " % h . % n " ) ; <nl> + sampledmethods . put ( methodid , formattedmethod ) ; <nl> + if ( entersafepointcheckid = = initial_method_id & & formattedmethod . equals ( formatted ( safepoint . enter_slow_path_safepoint_check ) ) ) { <nl> entersafepointcheckid = methodid ; <nl> } <nl> - if ( entersafepointfromnativeid = = initial_method_id & & method . format ( " % h . % n " ) . contains ( enter_safepoint_from_native_method_name ) ) { <nl> + if ( entersafepointfromnativeid = = initial_method_id & & formattedmethod . equals ( formatted ( safepoint . enter_slow_path_transition_from_native_to_new_status ) ) ) { <nl> entersafepointfromnativeid = methodid ; <nl> } <nl> - if ( entersafepointcheckobject = = initial_method_id & & method . format ( " % h . % n " ) . contains ( enter_safepoint_check_object_method_name ) ) { <nl> + if ( entersafepointcheckobject = = initial_method_id & & formattedmethod . contains ( enter_safepoint_check_object_method_name ) ) { <nl> entersafepointcheckobject = methodid ; <nl> } <nl> } <nl>  <nl> + private static string formatted ( snippetruntime . substrateforeigncalldescriptor enterslowpathsafepointcheck ) { <nl> + return string . format ( " % s . % s " , <nl> + enterslowpathsafepointcheck . getdeclaringclass ( ) . getcanonicalname ( ) , <nl> + enterslowpathsafepointcheck . getname ( ) ) ; <nl> + } <nl> + <nl> public string methodfor ( int methodid ) { <nl> return sampledmethods . get ( methodid ) ; <nl> } <nl> mmm a / substratevm / src / com . oracle . svm . core / src / com / oracle / svm / core / thread / safepoint . java <nl> ppp b / substratevm / src / com . oracle . svm . core / src / com / oracle / svm / core / thread / safepoint . java <nl>
import com . oracle . truffle . api . profiles . intvalueprofile ; <nl> * @ since num . 1 <nl> * / <nl> public final class trufflestring extends abstracttrufflestring { <nl> - <nl> - / * <nl> - * <nl> - * / <nl> - private static final atomicreferencefieldupdater < trufflestring , trufflestring > next_updater = initializenextupdater ( ) ; <nl> + private static final varhandle next_updater = initializenextupdater ( ) ; <nl>  <nl> @ truffleboundary <nl> - private static atomicreferencefieldupdater < trufflestring , trufflestring > initializenextupdater ( ) { <nl> - return atomicreferencefieldupdater . newupdater ( trufflestring . class , trufflestring . class , " next " ) ; <nl> + private static varhandle initializenextupdater ( ) { <nl> + try { <nl> + return methodhandles . lookup ( ) . findvarhandle ( trufflestring . class , " next " , trufflestring . class ) ; <nl> + } catch ( nosuchfieldexception | illegalaccessexception e ) { <nl> + throw new runtimeexception ( e ) ; <nl> + } <nl> } <nl>  <nl> private static final byte flag_cache_head = ( byte ) num x80 ; <nl>  <nl> private final int codepointlength ; <nl> private final byte coderange ; <nl> - private volatile trufflestring next ; <nl> + private trufflestring next ; <nl>  <nl> private trufflestring ( object data , int offset , int length , int stride , int encoding , int codepointlength , int coderange ) { <nl> this ( data , offset , length , stride , encoding , codepointlength , coderange , true ) ;
public class canonicalizerphase extends basephase < coreproviders > { <nl>  <nl> @ override <nl> public int hashcode ( ) { <nl> - <nl> - / / getclass ( ) . getname ( ) . remove getclass ( ) . getname ( ) once the experiments across vm <nl> - / / executions are over . <nl> - <nl> if ( customsimplification = = null ) { <nl> return objects . hash ( this . getclass ( ) . getname ( ) , features . tostring ( ) ) ; <nl> } <nl> mmm a / compiler / src / org . graalvm . compiler . phases . common / src / org / graalvm / compiler / phases / common / iterativeconditionaleliminationphase . java <nl> ppp b / compiler / src / org . graalvm . compiler . phases . common / src / org / graalvm / compiler / phases / common / iterativeconditionaleliminationphase . java <nl>
public class iterativeconditionaleliminationphase extends basephase < coreprovider <nl>  <nl> @ override <nl> public int hashcode ( ) { <nl> - <nl> - / / getclass ( ) . getname ( ) . remove getclass ( ) . getname ( ) once the experiments across vm <nl> - / / executions are over . <nl> return objects . hash ( this . getclass ( ) . getname ( ) , fullschedule , canonicalizer ) ; <nl> } <nl>  <nl> mmm a / compiler / src / org . graalvm . compiler . phases / src / org / graalvm / compiler / phases / basephase . java <nl> ppp b / compiler / src / org . graalvm . compiler . phases / src / org / graalvm / compiler / phases / basephase . java <nl>
public abstract class basephase < c > implements phasesizecontract { <nl> / * * <nl> * hashing a phase is used to implement and test phase plan serialization . hashing a phase <nl> * should take into account any fields that configure a phase . this will be done properly once a <nl> - * { @ code phaseinfo } annotation is introduced ( c . f . { @ link nodeinfo } ) . <nl> + * { @ code phaseinfo } annotation is introduced ( c . f . { @ link nodeinfo } ) . the hash code returned <nl> + * needs to be stable across vm executions . <nl> * / <nl> @ override <nl> public int hashcode ( ) { <nl> - <nl> - / / getclass ( ) . getname ( ) . remove getclass ( ) . getname ( ) once the experiments across vm <nl> - / / executions are over . <nl> return this . getclass ( ) . getname ( ) . hashcode ( ) ; <nl> }
public class substrateamd64backend extends substratebackend implements lirgenera <nl> allocatablevalue targetaddress = targetregister . asvalue ( frameaccess . getwordstamp ( ) . getlirkind ( getlirgeneratortool ( ) . getlirkindtool ( ) ) ) ; <nl> gen . emitmove ( targetaddress , operand ( calltarget . computedaddress ( ) ) ) ; <nl> resolvedjavamethod targetmethod = calltarget . targetmethod ( ) ; <nl> - <nl> vzeroupperbeforecall ( getlirgeneratortool ( ) , parameters , callstate ) ; <nl> append ( new substrateamd64indirectcallop ( getruntimeconfiguration ( ) , targetmethod , result , parameters , temps , targetaddress , callstate , <nl> setupjavaframeanchor ( calltarget ) , setupjavaframeanchortemp ( calltarget ) , getnewthreadstatus ( calltarget ) ,
local jdks = common_json . jdks ; <nl> vm_common . deploy_vm_base_java17_darwin_amd64 + { publishartifacts : [ { name : ' daily - deploy - vm - base - java17 - darwin - amd64 ' , patterns : [ ' daily - deploy - vm - base - java17 - darwin - amd64 ' ] } ] } , <nl> vm_common . deploy_vm_installable_java17_darwin_amd64 + { publishartifacts : [ { name : ' daily - deploy - vm - installable - java17 - darwin - amd64 ' , patterns : [ ' daily - deploy - vm - installable - java17 - darwin - amd64 ' ] } ] } , <nl>  <nl> - # <nl> # darwin / aarch64 <nl> vm_common . deploy_vm_base_java11_darwin_aarch64 + { publishartifacts : [ { name : ' daily - deploy - vm - base - java11 - darwin - aarch64 ' , patterns : [ ' daily - deploy - vm - base - java11 - darwin - aarch64 ' ] } ] } , <nl> vm_common . deploy_vm_installable_java11_darwin_aarch64 + { publishartifacts : [ { name : ' daily - deploy - vm - installable - java11 - darwin - aarch64 ' , patterns : [ ' daily - deploy - vm - installable - java11 - darwin - aarch64 ' ] } ] } ,
public final class unimplementedgraalintrinsics { <nl>  <nl> / / to be investigated intrinsics <nl> add ( tobeinvestigated , <nl> - <nl> - " java / lang / characterdatalatin1 . islowercase ( i ) z " , <nl> - " java / lang / characterdatalatin1 . isuppercase ( i ) z " , <nl> - " java / lang / characterdatalatin1 . iswhitespace ( i ) z " , <nl> / / similar to addexact <nl> " java / lang / math . negateexact ( i ) i " , <nl> / / similar to addexact
public class substratetrufflecompilerimpl extends trufflecompilerimpl implements <nl> @ platforms ( platform . hosted_only . class ) <nl> public substratetrufflecompilerimpl ( trufflecompilerconfiguration config ) { <nl> super ( config ) ; <nl> - <nl> compilerconfigurationname = graalconfiguration . runtimeinstance ( ) . getcompilerconfigurationname ( ) ; <nl> }
public final class resources { <nl> } <nl>  <nl> public static byte [ ] inputstreamtobytearray ( inputstream is ) { <nl> - <nl> - byte [ ] arr = new byte [ 4096 ] ; <nl> - int pos = num ; <nl> try { <nl> - for ( ; ; ) { <nl> - if ( pos = = arr . length ) { <nl> - byte [ ] tmp = new byte [ arr . length * num ] ; <nl> - system . arraycopy ( arr , num , tmp , num , arr . length ) ; <nl> - arr = tmp ; <nl> - } <nl> - int len = is . read ( arr , pos , arr . length - pos ) ; <nl> - if ( len = = - 1 ) { <nl> - break ; <nl> - } <nl> - pos + = len ; <nl> - } <nl> + return is . readallbytes ( ) ; <nl> } catch ( ioexception ex ) { <nl> throw vmerror . shouldnotreachhere ( ex ) ; <nl> } <nl> - <nl> - byte [ ] data = new byte [ pos ] ; <nl> - system . arraycopy ( arr , num , data , num , pos ) ; <nl> - return data ; <nl> } <nl>  <nl> private static void addentry ( string modulename , string resourcename , boolean isdirectory , byte [ ] data ) {
public abstract class languagelauncherbase extends launcher { <nl> final boolean all = helpargis ( " all " ) ; <nl> boolean printed = false ; <nl> if ( all | | helpargis ( " languages " ) ) { <nl> - printed = true ; <nl> - printlanguageoptions ( gettempengine ( ) , helpinternal , null ) ; <nl> + printed = printlanguageoptions ( gettempengine ( ) , helpinternal , null ) ; <nl> } <nl> if ( all | | helpargis ( " tools " ) ) { <nl> - printed = true ; <nl> - printinstrumentoptions ( gettempengine ( ) , helpinternal , null ) ; <nl> + printed = printinstrumentoptions ( gettempengine ( ) , helpinternal , null ) ; <nl> } <nl> if ( all | | helpargis ( " engine " ) ) { <nl> - printed = true ; <nl> - printengineoptions ( gettempengine ( ) , helpinternal ) ; <nl> + printed = printengineoptions ( gettempengine ( ) , helpinternal ) ; <nl> } <nl> if ( printed ) { <nl> return ; <nl> } <nl> - <nl> - printlanguageoptions ( gettempengine ( ) , helpinternal , helparg ) ; <nl> - printinstrumentoptions ( gettempengine ( ) , helpinternal , helparg ) ; <nl> + printed = printlanguageoptions ( gettempengine ( ) , helpinternal , helparg ) ; <nl> + printed | = printinstrumentoptions ( gettempengine ( ) , helpinternal , helparg ) ; <nl> + if ( ! printed ) { <nl> + printdefaulthelp ( optioncategory . user ) ; <nl> + } <nl> } <nl>  <nl> / * * <nl>
public final class target_com_oracle_truffle_espresso_polyglot_polyglot { <nl> } <nl> } <nl>  <nl> - <nl> - @ suppresswarnings ( " deprecation " ) <nl> @ substitution <nl> public static @ javatype ( object . class ) staticobject eval ( @ javatype ( string . class ) staticobject language , @ javatype ( string . class ) staticobject code , @ inject meta meta ) { <nl> string languageid = meta . tohoststring ( language ) ; <nl>
public class hostedmethod implements sharedmethod , wrappedjavamethod , graphprovi <nl>  <nl> @ override <nl> public boolean isinvirtualmethodtable ( resolvedjavatype resolved ) { <nl> - if ( ! hasvtableindex ( ) ) { <nl> - return false ; <nl> - } <nl> - final architecture arch = imagesingletons . lookup ( substratetargetdescription . class ) . arch ; <nl> - final boolean usellvmbackend = substrateoptions . usellvmbackend ( ) ; <nl> - if ( arch instanceof amd64 & & ! usellvmbackend ) { <nl> - return isinvtable ( ( hostedtype ) resolved ) ; <nl> - } <nl> - return false ; <nl> - } <nl> - <nl> - private boolean isinvtable ( hostedtype type ) { <nl> - <nl> - for ( hostedtype subtype : type . subtypes ) { <nl> - boolean result = isinvtable ( subtype ) ; <nl> - if ( result ) { <nl> - return true ; <nl> - } <nl> - } <nl> - if ( ! type . isinstantiated ( ) ) { <nl> - return false ; <nl> - } <nl> - return vtableindex < type . getvtable ( ) . length & & type . getvtable ( ) [ vtableindex ] ! = null ; <nl> + return hasvtableindex ( ) ; <nl> } <nl>  <nl> @ override
<nl> - / * <nl> - * copyright ( c ) num , num , oracle and / or its affiliates . all rights reserved . <nl> - * do not alter or remove copyright notices or this file header . <nl> - * <nl> - * this code is free software ; you can redistribute it and / or modify it <nl> - * under the terms of the gnu general public license version num only , as <nl> - * published by the free software foundation . oracle designates this <nl> - * particular file as subject to the " classpath " exception as provided <nl> - * by oracle in the license file that accompanied this code . <nl> - * <nl> - * this code is distributed in the hope that it will be useful , but without <nl> - * any warranty ; without even the implied warranty of merchantability or <nl> - * fitness for a particular purpose . see the gnu general public license <nl> - * version num for more details ( a copy is included in the license file that <nl> - * accompanied this code ) . <nl> - * <nl> - * you should have received a copy of the gnu general public license version <nl> - * num along with this work ; if not , write to the free software foundation , <nl> - * inc . , num franklin st , fifth floor , boston , ma num - 1301 usa . <nl> - * <nl> - * please contact oracle , num oracle parkway , redwood shores , ca num usa <nl> - * or visit www . oracle . com if you need additional information or have any <nl> - * questions . <nl> - * / <nl> - package com . oracle . svm . hosted ; <nl> - <nl> - import java . lang . invoke . methodhandles ; <nl> - import java . lang . invoke . varhandle ; <nl> - <nl> - / * <nl> - public class stringaccess { <nl> - <nl> - private static final varhandle string_value ; <nl> - static { <nl> - try { <nl> - methodhandles . lookup privatelookup = methodhandles . privatelookupin ( string . class , methodhandles . lookup ( ) ) ; <nl> - string_value = privatelookup . unreflectvarhandle ( string . class . getdeclaredfield ( " value " ) ) ; <nl> - } catch ( reflectiveoperationexception e ) { <nl> - throw new exceptionininitializererror ( e ) ; <nl> - } <nl> - } <nl> - <nl> - public static int getinternalbytearraylength ( string string ) { <nl> - return ( ( byte [ ] ) string_value . get ( string ) ) . length ; <nl> - } <nl> - }
public final class progressreporterchelper { <nl> } <nl>  <nl> private static void loadchelperlibrary ( ) { <nl> - if ( javaversionutil . java_spec < = num ) { <nl> - return ; <nl> - } <nl> + path javahome = paths . get ( system . getproperty ( " java . home " ) ) ; <nl> string libname = system . maplibraryname ( " reporterchelper " ) ; <nl> - path librsshelperpath = paths . get ( system . getproperty ( " java . home " ) , " lib " , " svm " , " builder " , " lib " , libname ) ; <nl> + path librsshelperpath = javahome . resolve ( paths . get ( " lib " , " svm " , " builder " , " lib " , libname ) ) ; <nl> if ( files . exists ( librsshelperpath ) ) { <nl> system . load ( librsshelperpath . tostring ( ) ) ; <nl> } else {
<nl> * / <nl> package org . graalvm . tools . lsp . server . utils ; <nl>  <nl> - import com . oracle . truffle . api . calltarget ; <nl> import com . oracle . truffle . api . source . source ; <nl>  <nl> public final class sourcewrapper { <nl> private source source ; <nl> private boolean parsingsuccessful = false ; <nl> - / * * <nl> - * needed to have a strong reference to the rootnode so that it and its children will not be <nl> - * garbage collected . <nl> - * / <nl> - <nl> - @ suppresswarnings ( " unused " ) private calltarget calltarget ; <nl>  <nl> public sourcewrapper ( source source ) { <nl> this . setsource ( source ) ; <nl>
<nl> * / <nl> package org . graalvm . tools . lsp . server . utils ; <nl>  <nl> - import com . oracle . truffle . api . calltarget ; <nl> import com . oracle . truffle . api . source . source ; <nl>  <nl> public final class sourcewrapper { <nl> private source source ; <nl> private boolean parsingsuccessful = false ; <nl> - / * * <nl> - * needed to have a strong reference to the rootnode so that it and its children will not be <nl> - * garbage collected . <nl> - * / <nl> - <nl> - @ suppresswarnings ( " unused " ) private calltarget calltarget ; <nl>  <nl> public sourcewrapper ( source source ) { <nl> this . setsource ( source ) ; <nl>
import com . oracle . svm . core . util . vmerror ; <nl> * design : there shouldn ' t be tests for a locked heap on the allocation fast - path , so the key is <nl> * that creating one of these sets top to end in the young space , so allocation attempts fail over <nl> * to the slow - path , and there can be a test for a locked heap on the slow path . <nl> - * <nl> - * <nl> - * thread . that could be done by setting the thread ' s tlab to null , which should force it on to the <nl> - * slow - path to allocation a new tlab . <nl> * / <nl> public class noallocationverifier implements autocloseable { <nl>  <nl> mmm a / substratevm / src / com . oracle . svm . core / src / com / oracle / svm / core / thread / vmthreads . java <nl> ppp b / substratevm / src / com . oracle . svm . core / src / com / oracle / svm / core / thread / vmthreads . java <nl>
public final class method extends member < signature > implements truffleobject , co <nl> initrefkind ( ) ; <nl> this . proxy = null ; <nl>  <nl> - if ( getdeclaringklass ( ) . isinterface ( ) | | isabstract ( ) ) { <nl> - / * <nl> - * <nl> - * methods . <nl> - * <nl> - * also disabled for abstract methods to reduce footprint . <nl> - * / <nl> + if ( isabstract ( ) ) { <nl> + / / disabled for abstract methods to reduce footprint . <nl> this . isleaf = nevervalidassumption . instance ; <nl> } else if ( isstatic ( ) | | isprivate ( ) | | isfinalflagset ( ) | | getdeclaringklass ( ) . isfinalflagset ( ) ) { <nl> / / nothing to assume , spare an assumption .
public final class method extends member < signature > implements truffleobject , co <nl> initrefkind ( ) ; <nl> this . proxy = null ; <nl>  <nl> - if ( getdeclaringklass ( ) . isinterface ( ) | | isabstract ( ) ) { <nl> - / * <nl> - * <nl> - * methods . <nl> - * <nl> - * also disabled for abstract methods to reduce footprint . <nl> - * / <nl> + if ( isabstract ( ) ) { <nl> + / / disabled for abstract methods to reduce footprint . <nl> this . isleaf = nevervalidassumption . instance ; <nl> } else if ( isstatic ( ) | | isprivate ( ) | | isfinalflagset ( ) | | getdeclaringklass ( ) . isfinalflagset ( ) ) { <nl> / / nothing to assume , spare an assumption .
final class heapchunkprovider { <nl> * / <nl> void consumealignedchunks ( alignedheader firstchunk ) { <nl> assert heapchunk . getprevious ( firstchunk ) . isnull ( ) : " prev must be null " ; <nl> - alignedheader cur = firstchunk ; <nl>  <nl> - unsignedword unusedbytes = getbytesinunusedchunks ( ) ; <nl> - unsignedword reserved = gcimpl . getpolicy ( ) . getmaximumfreereservedsize ( ) ; <nl> - if ( reserved . abovethan ( unusedbytes ) ) { <nl> - unsignedword chunkstokeep = reserved . subtract ( unusedbytes ) . unsigneddivide ( heapparameters . getalignedheapchunksize ( ) ) ; <nl> + unsignedword freelistbytes = getbytesinunusedchunks ( ) ; <nl> + unsignedword reservebytes = gcimpl . getpolicy ( ) . getmaximumfreereservedsize ( ) ; <nl> + <nl> + alignedheader cur = firstchunk ; <nl> + if ( freelistbytes . belowthan ( reservebytes ) ) { <nl> + / / retain some of the chunks in the free list for quicker allocation <nl> + unsignedword chunkstokeep = reservebytes . subtract ( freelistbytes ) <nl> + . unsigneddivide ( heapparameters . getalignedheapchunksize ( ) ) ; <nl> while ( cur . isnonnull ( ) & & chunkstokeep . abovethan ( 0 ) ) { <nl> alignedheader next = heapchunk . getnext ( cur ) ; <nl> cleanalignedchunk ( cur ) ; <nl> pushunusedalignedchunk ( cur ) ; <nl> + <nl> chunkstokeep = chunkstokeep . subtract ( 1 ) ; <nl> cur = next ; <nl> } <nl> } <nl> - <nl> - <nl> freealignedchunklist ( cur ) ; <nl> + <nl> + if ( freelistbytes . abovethan ( reservebytes ) ) { <nl> + / * <nl> + * release chunks from the free list to the operating system . this can be necessary <nl> + * after eden shrinks or if too many chunks were allocated during a collection . <nl> + * / <nl> + unsignedword unusedchunkstofree = freelistbytes . subtract ( reservebytes ) <nl> + . unsigneddivide ( heapparameters . getalignedheapchunksize ( ) ) ; <nl> + freeunusedalignedchunksatsafepoint ( unusedchunkstofree ) ; <nl> + } <nl> } <nl>  <nl> private static void cleanalignedchunk ( alignedheader alignedchunk ) { <nl>
public final class target_java_lang_invoke_methodhandlenatives { <nl> @ cached branchprofile isinvokevirtualorspecialprofile , <nl> @ cached branchprofile ishandlemethodprofile ) { <nl> meta meta = context . getmeta ( ) ; <nl> - <nl> if ( meta . hidden_vmtarget . gethiddenobject ( membername ) ! = null ) { <nl> return membername ; / / already planted <nl> } <nl>
public class valueassert { <nl> break ; <nl> case instantiable : <nl> assertfalse ( value . caninstantiate ( ) ) ; <nl> - <nl> - / / assertfails ( ( ) - > value . newinstance ( ) , unsupportedoperationexception . class ) ; <nl> + assertfails ( ( ) - > value . newinstance ( ) , unsupportedoperationexception . class ) ; <nl> if ( value . isnull ( ) ) { <nl> assertnull ( value . as ( function . class ) ) ; <nl> assertnull ( value . as ( isfunctionalinterfacevarargs . class ) ) ; <nl>
public class valueassert { <nl> assertequals ( ( byte ) intvalue = = intvalue , value . fitsinbyte ( ) ) ; <nl> assertequals ( ( short ) intvalue = = intvalue , value . fitsinshort ( ) ) ; <nl> } else { <nl> - <nl> - assertfails ( ( ) - > value . asint ( ) , classcastexception . class , polyglotexception . class ) ; <nl> + assertfails ( ( ) - > value . asint ( ) , classcastexception . class ) ; <nl> } <nl>  <nl> if ( value . fitsinlong ( ) ) { <nl>
public final class cpusampler implements closeable { <nl> continue ; <nl> } <nl> map < thread , profilernode < payload > > nodes = activecontexts . get ( context ) ; <nl> - <nl> if ( nodes = = null ) { <nl> continue ; <nl> } <nl>
public class onstackreplaceablenodetest extends testwithsynchronouscompiling { <nl> @ override <nl> void checkstacktrace ( int index ) { <nl> if ( compilerdirectives . incompiledcode ( ) & & ! hasdeoptimizedyet ) { <nl> - <nl> + / / which ensures this branch is taken . <nl> boundarycall ( ) ; <nl> compilerdirectives . transfertointerpreterandinvalidate ( ) ; <nl> hasdeoptimizedyet = true ;
public abstract class optimizedcalltarget implements compilabletruffleast , rootc <nl> if ( ! osrenabled ) { <nl> return null ; <nl> } <nl> - <nl> if ( ! incrementandcheck ( ) ) { <nl> return null ; <nl> } <nl> - <nl> - <nl> optimizedcalltarget osrtarget = osrcompilations . get ( target ) ; <nl> if ( osrtarget = = null ) { <nl> synchronized ( this ) { <nl>
public abstract class optimizedcalltarget implements compilabletruffleast , rootc <nl> } <nl> } <nl> if ( osrtarget ! = null & & ! osrtarget . iscompiling ( ) ) { <nl> - <nl> - / / if this happens ? ) <nl> if ( osrtarget . isvalid ( ) ) { <nl> - return osrtarget . call ( parentframe ) ; <nl> + if ( ! graalruntimeaccessor . frame . getmaterializecalled ( parentframe . getframedescriptor ( ) ) ) { <nl> + return osrtarget . call ( parentframe ) ; <nl> + } <nl> + / / we cannot perform osr if the frame is materialized . the original and osr frames could get <nl> + / / out of sync , which could lead to inconsistent views of the program state . <nl> + return null ; <nl> } <nl> invalidateosrtarget ( target , " osr compilation failed or cancelled " ) ; <nl> } <nl> return null ; <nl> } <nl>  <nl> - / / increment back - edge count and check whether the new count exceeds the threshold . <nl> private boolean incrementandcheck ( ) { <nl> + / * <nl> + * increment back edge count . once the compilation threshold is reached , return true after every <nl> + * osr_poll_interval back - edges ( polling compilation rather than checking after every loop iteration ) . <nl> + * <nl> + * this method is thread - safe , but could under - count . <nl> + * / <nl> int newbackedgecount = backedgecount ; <nl> newbackedgecount = ( newbackedgecount = = integer . max_value ) ? newbackedgecount : newbackedgecount + 1 ; <nl> backedgecount = newbackedgecount ; <nl> - return newbackedgecount > = osrthreshold ; <nl> + return newbackedgecount > = osrthreshold & & ( newbackedgecount & ( osr_poll_interval - num ) ) = = num ; <nl> } <nl>  <nl> private synchronized optimizedcalltarget requestosr ( trufflelanguage < ? > language , onstackreplaceablenode osrnode , int target ) {
public final class bytecodenode extends espressomethodnode implements replaceobs <nl> atomic ( ( ) - > { <nl> optimizedcalltarget target = osrtargets [ bci ] ; <nl> if ( target ! = null ) { <nl> - <nl> - / / for some reason the deoptimization listener does not get hit . <nl> - / / if ( target . iscompilationfailed ( ) ) { <nl> + if ( target . iscompilationfailed ( ) ) { <nl> cancompile = false ; <nl> - / / } <nl> + } <nl> target . invalidate ( reason ) ; <nl> } <nl> osrtargets [ bci ] = null ;
public final class llvmparser { <nl> } <nl>  <nl> private void defineexpressionsymbol ( string aliasname , boolean isaliasexported , getelementpointerconstant elementpointerconstant , datalayout targetdatalayout ) { <nl> - symbolimpl base = elementpointerconstant . getbasepointer ( ) ; <nl> - <nl> - llvmsymbol basesymbol = runtime . getfilescope ( ) . get ( base . tostring ( ) ) ; <nl> + llvmsymbol basesymbol = runtime . getfilescope ( ) . get ( elementpointerconstant . getbasepointer ( ) . tostring ( ) ) ; <nl> llvmgetelementptrnode elementptrnode = ( llvmgetelementptrnode ) elementpointerconstant . createnode ( runtime , targetdatalayout , getstackspacefactory . createallocafactory ( ) ) ; <nl> llvmelemptrsymbol expressionsymbol = new llvmelemptrsymbol ( aliasname , runtime . getbitcodeid ( ) , - 1 , isaliasexported , <nl> elementpointerconstant . gettype ( ) , basesymbol , elementptrnode ) ; <nl> runtime . getfilescope ( ) . register ( expressionsymbol ) ; <nl> - <nl> } <nl>  <nl> private void definealias ( string existingname , string newname , boolean newexported ) { <nl> mmm a / sulong / projects / com . oracle . truffle . llvm . parser / src / com / oracle / truffle / llvm / parser / model / symbols / globals / globalalias . java <nl> ppp b / sulong / projects / com . oracle . truffle . llvm . parser / src / com / oracle / truffle / llvm / parser / model / symbols / globals / globalalias . java <nl>
public final class sourcesectionfilter { <nl> } <nl>  <nl> / * * <nl> - * <nl> + * <nl> + * checks if the filter includes the given root node , i . e . do the properties of the given source <nl> + * section meet the conditions set by the filter . the given root node is treated as a node with <nl> + * an implicit { @ link standardtags . roottag } . <nl> + * <nl> + * @ param node the root node to be checked against the filter . <nl> + * @ param sourcesection the source section of the node to be checked against the filter . <nl> + * @ return { @ code true } if the filter includes the source section and node . { @ code false } <nl> + * otherwise . <nl> + * @ since num . 3 . 0 <nl> + * <nl> + * / <nl> + public boolean includes ( rootnode node , sourcesection sourcesection ) { <nl> + set < class < ? > > tags = node ! = null ? getprovidedtags ( node ) : collections . emptyset ( ) ; <nl> + if ( ! tags . contains ( standardtags . roottag . class ) ) { <nl> + return false ; <nl> + } <nl> + for ( eventfilterexpression exp : expressions ) { <nl> + if ( ! exp . isincluded ( tags , providesroottagnode . instance , sourcesection ) ) { <nl> + return false ; <nl> + } <nl> + } <nl> + return true ; <nl> + } <nl> + <nl> + / * <nl> + * since root nodes themselves cannot be instrumented , this node is used by the { @ link <nl> + * # includes ( rootnode , sourcesection ) } method as a substitute node to check the tags <nl> * / <nl> private static final class providesroottagnode extends node implements instrumentablenode { <nl>  <nl>
final class safepointstack { <nl> calltarget target = targets [ i ] ; <nl> rootnode root = ( ( rootcalltarget ) target ) . getrootnode ( ) ; <nl> sourcesection sourcesection = root . getsourcesection ( ) ; <nl> - <nl> - if ( sourcesection ! = null / * & & filter . includes ( root , sourcesection ) * / ) { <nl> + if ( sourcesection ! = null & & filter . includes ( root , sourcesection ) ) { <nl> entries . add ( new stacktraceentry ( tags , sourcesection , root , root , states [ i ] ) ) ; <nl> } <nl> } <nl> mmm a / truffle / src / com . oracle . truffle . api . instrumentation / src / com / oracle / truffle / api / instrumentation / sourcesectionfilter . java <nl> ppp b / truffle / src / com . oracle . truffle . api . instrumentation / src / com / oracle / truffle / api / instrumentation / sourcesectionfilter . java <nl>
public final class cpusampler implements closeable { <nl> if ( delaysamplinguntilnoninternallanginit & & ! noninternallanguagecontextinitialized ) { <nl> return collections . emptymap ( ) ; <nl> } <nl> + if ( activecontexts . isempty ( ) ) { <nl> + return collections . emptymap ( ) ; <nl> + } <nl> map < thread , list < stacktraceentry > > stacks = new hashmap < > ( ) ; <nl> - <nl> - return collections . unmodifiablemap ( stacks ) ; <nl> - } <nl> - <nl> - static map < thread , stacktraceelement [ ] > tostacktraceelement ( map < thread , list < stacktraceentry > > sample ) { <nl> - map < thread , stacktraceelement [ ] > converted = new hashmap < > ( ) ; <nl> - for ( entry < thread , list < stacktraceentry > > entry : sample . entryset ( ) ) { <nl> - converted . put ( entry . getkey ( ) , ( stacktraceelement [ ] ) entry . getvalue ( ) . stream ( ) . map ( ( e ) - > e . tostacktraceelement ( ) ) . toarray ( ) ) ; <nl> + trufflecontext context = activecontexts . keyset ( ) . iterator ( ) . next ( ) ; <nl> + list < stacksample > sample = safepointstack . sample ( env , context ) ; <nl> + for ( stacksample stacksample : sample ) { <nl> + stacks . put ( stacksample . thread , stacksample . stack ) ; <nl> } <nl> - return converted ; <nl> + return collections . unmodifiablemap ( stacks ) ; <nl> } <nl>  <nl> private void resetsampling ( ) {
public final class target_java_lang_object { <nl> } <nl> } <nl>  <nl> - <nl> - / / cloned objects . remove once gr - 19247 is resolved . <nl> @ substitution ( hasreceiver = true ) <nl> @ throws ( clonenotsupportedexception . class ) <nl> public static @ host ( object . class ) staticobject clone ( @ host ( object . class ) staticobject self , <nl> mmm a / espresso / src / com . oracle . truffle . espresso / src / com / oracle / truffle / espresso / vm / framecookie . java <nl> ppp b / espresso / src / com . oracle . truffle . espresso / src / com / oracle / truffle / espresso / vm / framecookie . java <nl>
public final class enginedata { <nl> if ( multitier ) { <nl> return options . get ( firsttiercompilationthreshold ) ; <nl> } else { <nl> - <nl> - if ( options . hasbeenset ( compilationthreshold ) ) { <nl> - return options . get ( compilationthreshold ) ; <nl> - } <nl> return options . get ( singletiercompilationthreshold ) ; <nl> } <nl> } <nl>
public final class enginedata { <nl> if ( compileimmediately ) { <nl> return num ; <nl> } <nl> - <nl> - if ( options . hasbeenset ( compilationthreshold ) ) { <nl> - return options . get ( compilationthreshold ) ; <nl> - } <nl> return options . get ( lasttiercompilationthreshold ) ; <nl> }
public final class llvmpthreadcontext { <nl> private final object threadlock ; <nl>  <nl> / * * <nl> - * <nl> - * return values . <nl> + * at pthread_join , return values shall be cleared from this map of return values . <nl> * / <nl> private final concurrentmap < long , object > threadreturnvaluestorage ; <nl>  <nl>
public class inflation extends bigbang { <nl> * type fields of type c can be of any type compatible with their declared type . <nl> * / <nl>  <nl> - if ( svmhost . isunknownclass ( type ) ) { <nl> - return false ; <nl> - } <nl> - <nl> - if ( type . isarray ( ) & & svmhost . isunknownclass ( type . getcomponenttype ( ) ) ) { <nl> - <nl> - throw jvmcierror . unimplemented ( ) ; <nl> - } <nl> - <nl> - return true ; <nl> + return ! svmhost . isunknownclass ( type ) ; <nl> } <nl>  <nl> / * *
public class inflation extends bigbang { <nl> * type fields of type c can be of any type compatible with their declared type . <nl> * / <nl>  <nl> - if ( svmhost . isunknownclass ( type ) ) { <nl> - return false ; <nl> - } <nl> - <nl> - if ( type . isarray ( ) & & svmhost . isunknownclass ( type . getcomponenttype ( ) ) ) { <nl> - <nl> - throw jvmcierror . unimplemented ( ) ; <nl> - } <nl> - <nl> - return true ; <nl> + return ! svmhost . isunknownclass ( type ) ; <nl> } <nl>  <nl> / * *
public class range { <nl> * / <nl> private range ( string symbolname , stringtable stringtable , methodentry methodentry , fileentry fileentry , int lo , int hi , int line , <nl> range primary ) { <nl> - this . fileentry = fileentry ; <nl> + this . fileentry = fileentry ; <nl> if ( fileentry ! = null ) { <nl> stringtable . uniquedebugstring ( fileentry . getfilename ( ) ) ; <nl> stringtable . uniquedebugstring ( fileentry . getpathname ( ) ) ;
public final class jdwpcontextimpl implements jdwpcontext { <nl> / / while rerunning class initializers <nl> / / in the guest , some anomalies are to <nl> / / be expected . treat those as non - fatal <nl> - <nl> + jdwplogger . log ( " exception caught while re - running < clinit > " , jdwplogger . loglevel . redefine ) ; <nl> } <nl> } <nl> }
public class jfrsymbolrepository implements jfrrepository { <nl> int hashcode = ( int ) ( rawpointervalue ^ ( rawpointervalue > > > num ) ) ; <nl> symbol . sethash ( hashcode ) ; <nl>  <nl> - return table . add ( symbol ) ; <nl> + return gettable ( ) . add ( symbol ) ; <nl> } <nl>  <nl> @ override <nl> public void write ( jfrchunkwriter writer ) throws ioexception { <nl> - <nl> - / / writing outside of a safepoint . however symbols can be <nl> - / / marked in use directly by native events so the symbol <nl> - / / repository probably needs to be epoch based as well <nl> - assert vmoperation . isinprogressatsafepoint ( ) ; <nl> + jfrsymbolhashtable table = gettable ( true ) ; <nl> writer . writecompressedlong ( jfrtypes . symbol . getid ( ) ) ; <nl> writer . writecompressedlong ( table . getsize ( ) ) ; <nl>  <nl>
<nl> # include " common . h " <nl>  <nl> # ifdef _win32 <nl> - # error " <nl> + # include < windows . h > <nl> # else <nl> # include < pthread . h > <nl> # endif <nl>
fastr_linux : $ { fastr } { <nl> } <nl> downloads : { <nl> blas_lapack_dir : { name : " fastr - 403 - blas - lapack - gcc " , version : " 4 . 8 . 5 " , platformspecific : true } , <nl> - # <nl> - fastr_recommended_binary : { name : " fastr - recommended - pkgs " , version : " 10 " , platformspecific : true } , <nl> } <nl> }
fastr : { <nl> } <nl> downloads : { <nl> f2c_binary : { name : " f2c - binary " , version : " 7 " , platformspecific : true } , <nl> - # <nl> - # fastr_recommended_binary : { name : " fastr - recommended - pkgs " , version : " 8 " , platformspecific : true } , <nl> } <nl> } <nl>  <nl>
public final class vm extends nativeenv implements contextaccess { <nl>  <nl> @ vmimpl <nl> @ truffleboundary <nl> - public void jvm_unloadlibrary ( @ suppresswarnings ( " unused " ) @ pointer truffleobject handle ) { <nl> - <nl> - getlogger ( ) . severe ( string . format ( " jvm_unloadlibrary : % x was not unloaded ! " , nativeutils . interopaspointer ( handle ) ) ) ; <nl> + public void jvm_unloadlibrary ( @ pointer truffleobject libraryptr ) { <nl> + long nativelibraryptr = nativeutils . interopaspointer ( libraryptr ) ; <nl> + truffleobject library = handle2lib . get ( nativelibraryptr ) ; <nl> + if ( library = = null ) { <nl> + getlogger ( ) . severe ( " jvm_unloadlibrary with unknown library ( not loaded through jvm_loadlibrary ? ) : " + libraryptr + " / " + long . tohexstring ( nativelibraryptr ) ) ; <nl> + } else { <nl> + getnativeaccess ( ) . unloadlibrary ( library ) ; <nl> + } <nl> } <nl>  <nl> @ vmimpl
public final class espressocontext { <nl>  <nl> / / spawn jni first , then the vm . <nl> try ( debugcloseable vminit = vm_init . scope ( timers ) ) { <nl> - <nl> - boolean dlmopen = getenv ( ) . getoptions ( ) . get ( espressooptions . usetrufflenfiisolatednamespace ) ; <nl> - this . nativeaccess = dlmopen <nl> - ? new nfiisolatednativeaccess ( this ) <nl> - : new nfinativeaccess ( this ) ; <nl> + this . nativeaccess = spawnnativeaccess ( ) ; <nl> this . vm = vm . create ( getjni ( ) ) ; / / mokapot is loaded <nl> vm . attachthread ( thread . currentthread ( ) ) ; <nl> } <nl>
public abstract class espressoprocessor extends abstractprocessor { <nl> static final string tab_3 = tab_2 + tab_1 ; <nl> static final string tab_4 = tab_3 + tab_1 ; <nl>  <nl> - private static final map < string , nativetype > classtonative = buildclasstonative ( ) ; <nl> - <nl> - static map < string , nativetype > buildclasstonative ( ) { <nl> - map < string , nativetype > map = new hashmap < > ( ) ; <nl> - map . put ( " boolean " , nativetype . boolean ) ; <nl> - map . put ( " byte " , nativetype . byte ) ; <nl> - map . put ( " short " , nativetype . short ) ; <nl> - map . put ( " char " , nativetype . char ) ; <nl> - map . put ( " int " , nativetype . int ) ; <nl> - map . put ( " float " , nativetype . float ) ; <nl> - map . put ( " long " , nativetype . long ) ; <nl> - map . put ( " double " , nativetype . double ) ; <nl> - map . put ( " void " , nativetype . void ) ; <nl> - return collections . unmodifiablemap ( map ) ; <nl> - } <nl> - <nl> public static nativetype classtotype ( string clazz ) { <nl> - <nl> - return classtonative . getordefault ( clazz , nativetype . long ) ; <nl> + / / @ formatter : off <nl> + switch ( clazz ) { <nl> + case " boolean " : return nativetype . boolean ; <nl> + case " byte " : return nativetype . byte ; <nl> + case " short " : return nativetype . short ; <nl> + case " char " : return nativetype . char ; <nl> + case " int " : return nativetype . int ; <nl> + case " float " : return nativetype . float ; <nl> + case " long " : return nativetype . long ; <nl> + case " double " : return nativetype . double ; <nl> + case " void " : return nativetype . void ; <nl> + default : <nl> + return nativetype . object ; <nl> + } <nl> + / / @ formatter : on <nl> } <nl>  <nl> @ override <nl> mmm a / espresso / src / com . oracle . truffle . espresso . processor / src / com / oracle / truffle / espresso / processor / intrinsicsprocessor . java <nl> ppp b / espresso / src / com . oracle . truffle . espresso . processor / src / com / oracle / truffle / espresso / processor / intrinsicsprocessor . java <nl>
import com . oracle . truffle . nfi . spi . types . nativesimpletype ; <nl>  <nl> public final class utils { <nl>  <nl> - public static nativesimpletype kindtotype ( javakind kind ) { <nl> - switch ( kind ) { <nl> - case boolean : <nl> - return nativesimpletype . sint8 ; / / ? <nl> - case short : <nl> - return nativesimpletype . sint16 ; <nl> - case char : <nl> - return nativesimpletype . sint16 ; <nl> - case long : <nl> - return nativesimpletype . sint64 ; <nl> - case float : <nl> - return nativesimpletype . float ; <nl> - case double : <nl> - return nativesimpletype . double ; <nl> - case int : <nl> - return nativesimpletype . sint32 ; <nl> - case byte : <nl> - return nativesimpletype . sint8 ; <nl> - case void : <nl> - return nativesimpletype . void ; <nl> - case object : <nl> - <nl> - / / null instead . <nl> - return nativeenv . word ( ) ; <nl> - default : <nl> - throw espressoerror . shouldnotreachhere ( ) ; <nl> - } <nl> - } <nl> - <nl> public static list < path > parsepaths ( string paths ) { <nl> list < path > list = new arraylist < > ( ) ; <nl> for ( string p : paths . split ( file . pathseparator ) ) { <nl> mmm a / espresso / src / com . oracle . truffle . espresso / src / com / oracle / truffle / espresso / jni / nativelibrary . java <nl> ppp b / espresso / src / com . oracle . truffle . espresso / src / com / oracle / truffle / espresso / jni / nativelibrary . java <nl>
public class target_java_lang_ref_reference { <nl> } <nl> } <nl>  <nl> - <nl> - / / substitute . <nl> - <nl> - / / replicates the behavior of guest reference . enqueue ( ) <nl> - if ( meta . getjavaversion ( ) . java9orlater ( ) ) { <nl> - meta . java_lang_ref_reference_referent . set ( self , staticobject . null ) ; <nl> - } <nl> - staticobject queue = ( staticobject ) meta . java_lang_ref_reference_queue . get ( self ) ; <nl> - method m = queue . getklass ( ) . vtablelookup ( meta . java_lang_ref_referencequeue_enqueue . getvtableindex ( ) ) ; <nl> - return ( boolean ) m . invokedirect ( queue , self ) ; <nl> + return ( boolean ) enqueue . call ( self ) ; <nl> } <nl> }
public class interopassertionstest extends interoplibrarybasetest { <nl> iteratortest . next = null ; <nl> assertfails ( ( ) - > iteratorlib . getiteratornextelement ( iteratortest ) , assertionerror . class ) ; <nl>  <nl> - <nl> - / / iteratortest . next = ( ) - > null ; <nl> - / / assertfails ( ( ) - > iteratorlib . getiteratornextelement ( iteratortest ) , assertionerror . class ) ; <nl> - / / iteratortest . hasnext = ( ) - > false ; <nl> - / / iteratortest . next = ( ) - > num ; <nl> - / / assertfails ( ( ) - > iteratorlib . getiteratornextelement ( iteratortest ) , assertionerror . class ) ; <nl> + iteratortest . next = ( ) - > null ; <nl> + assertfails ( ( ) - > iteratorlib . getiteratornextelement ( iteratortest ) , assertionerror . class ) ; <nl> + iteratortest . hasnext = ( ) - > false ; <nl> + iteratortest . next = ( ) - > num ; <nl> + assertfails ( ( ) - > iteratorlib . getiteratornextelement ( iteratortest ) , assertionerror . class ) ; <nl>  <nl> iteratortest . hasnext = ( ) - > true ; <nl> iteratortest . next = object : : new ;
final class target_java_lang_invoke_methodhandlenatives { <nl> @ targetelement ( onlywith = jdk16orlater . class ) <nl> static target_java_lang_invoke_membername resolve ( target_java_lang_invoke_membername self , class < ? > caller , int lookupmode , boolean speculativeresolve ) <nl> throws linkageerror , classnotfoundexception { <nl> - <nl> return util_java_lang_invoke_methodhandlenatives . resolve ( self , caller , speculativeresolve ) ; <nl> } <nl> }
import com . oracle . truffle . llvm . runtime . llvmlanguage ; <nl> import com . oracle . truffle . llvm . runtime . interop . access . llvminteroptype ; <nl> import com . oracle . truffle . llvm . runtime . interop . convert . foreigntollvm ; <nl> import com . oracle . truffle . llvm . runtime . nodes . api . llvmexpressionnode ; <nl> + import com . oracle . truffle . llvm . runtime . types . functiontype ; <nl> import com . oracle . truffle . llvm . runtime . types . type ; <nl>  <nl> public class llvmforeignintrinsiccallnode extends rootnode { <nl>  <nl> - public static llvmforeignintrinsiccallnode create ( llvmlanguage language , intrinsic intrinsic , llvminteroptype . function type ) { <nl> - int argcount = type . getnumberofparameters ( ) + num ; <nl> + public static llvmforeignintrinsiccallnode create ( llvmlanguage language , intrinsic intrinsic , functiontype type , llvminteroptype . function interoptype ) { <nl> + int argcount = interoptype . getnumberofparameters ( ) + num ; <nl> llvmexpressionnode [ ] args = new llvmexpressionnode [ argcount ] ; <nl> - type . typearraybuilder argtypes = new type . typearraybuilder ( argcount ) ; <nl>  <nl> / / intrinsics shouldn ' t need the stack argument <nl> args [ 0 ] = null ; <nl> - argtypes . set ( 0 , null ) ; <nl>  <nl> for ( int i = num ; i < argcount ; i + + ) { <nl> - llvminteroptype . value argtype = ( llvminteroptype . value ) type . getparameter ( i - num ) ; <nl> - <nl> + llvminteroptype . value argtype = ( llvminteroptype . value ) interoptype . getparameter ( i - num ) ; <nl> args [ i ] = new foreignintrinsicargnode ( i - num , argtype ) ; <nl> } <nl>  <nl> - llvmexpressionnode intrinsicnode = intrinsic . createintrinsicnode ( args , type . getrawtypearray ( argtypes ) ) ; <nl> - return new llvmforeignintrinsiccallnode ( language , intrinsicnode , ( llvminteroptype . value ) type . getreturntype ( ) ) ; <nl> + llvmexpressionnode intrinsicnode = intrinsic . createintrinsicnode ( args , type . getargumenttypes ( ) . toarray ( type . empty_array ) ) ; <nl> + return new llvmforeignintrinsiccallnode ( language , intrinsicnode , ( llvminteroptype . value ) interoptype . getreturntype ( ) ) ; <nl> } <nl>  <nl> @ child llvmexpressionnode intrinsicnode ;
public final class arguments { <nl> string value = optionstring . substring ( " - agentlib : jdwp = " . length ( ) ) ; <nl> builder . option ( " java . jdwpoptions " , value ) ; <nl> } else if ( optionstring . startswith ( " - d " ) ) { <nl> - <nl> - / / properties <nl> - / / with a reserved flag ) <nl> string key = optionstring . substring ( " - d " . length ( ) ) ; <nl> int splitat = key . indexof ( " = " ) ; <nl> string value = " " ; <nl>
public final class arguments { <nl> } else if ( optionstring . equals ( " - xx : - ignoreunrecognizedvmoptions " ) ) { <nl> ignoreunrecognized = false ; <nl> } else if ( optionstring . startswith ( " - - vm . " ) ) { <nl> - <nl> - / / org . graalvm . launcher . launcher . native . setnativeoption ) <nl> - int eqix = optionstring . indexof ( ' = ' ) ; <nl> - if ( eqix > num ) { <nl> - string key = optionstring . substring ( " - - vm . " . length ( ) , eqix ) ; <nl> - string value = optionstring . substring ( eqix + num ) ; <nl> - runtimeoptions . set ( key , value ) ; <nl> - } else { <nl> - string key = optionstring . substring ( " - - vm . " . length ( ) ) ; <nl> - runtimeoptions . set ( key , null ) ; <nl> - } <nl> + handlevmarg ( builder , optionstring , experimentaloptions ) ; <nl> + } else if ( optionstring . startswith ( " - xx : " ) ) { <nl> + handlexxarg ( builder , optionstring , experimentaloptions ) ; <nl> } else if ( isexperimentalflag ( optionstring ) ) { <nl> / / skip : previously handled <nl> } else if ( optionstring . equals ( " - - polyglot " ) ) { <nl>
public final class method extends member < signature > implements truffleobject , co <nl> return calltarget ; <nl> } <nl>  <nl> - <nl> - / / the boot class loader . <nl> - espressorootnode redirectedmethod = getsubstitutions ( ) . get ( getmethod ( ) ) ; <nl> - if ( redirectedmethod ! = null ) { <nl> - calltarget = truffle . getruntime ( ) . createcalltarget ( redirectedmethod ) ; <nl> + / / substitutions only apply for classes on the boot class loader . <nl> + staticobject loader = getmethod ( ) . getdeclaringklass ( ) . getdefiningclassloader ( ) ; <nl> + if ( staticobject . isnull ( loader ) ) { <nl> + espressorootnode redirectedmethod = getsubstitutions ( ) . get ( getmethod ( ) ) ; <nl> + if ( redirectedmethod ! = null ) { <nl> + calltarget = truffle . getruntime ( ) . createcalltarget ( redirectedmethod ) ; <nl> + } <nl> } <nl>  <nl> if ( calltarget = = null ) {
public final class vm extends nativeenv implements contextaccess { <nl> * returns jni_eversion . otherwise , sets * env to the appropriate interface , and returns <nl> * jni_ok . <nl> * / <nl> - @ suppresswarnings ( " unused " ) <nl> @ vmimpl <nl> @ truffleboundary <nl> public int getenv ( @ pointer truffleobject vmptr_ , @ pointer truffleobject envptr , int version ) { <nl> - <nl> assert interopaspointer ( getjavavm ( ) ) = = interopaspointer ( vmptr_ ) ; <nl> + staticobject currentthread = getcontext ( ) . getguestthreadfromhost ( thread . currentthread ( ) ) ; <nl> + if ( currentthread = = null ) { <nl> + return jni_edetached ; <nl> + } <nl> if ( jniversion . issupported ( version , getcontext ( ) . getjavaversion ( ) ) ) { <nl> longbuffer buf = directbytebuffer ( envptr , num , javakind . long ) . aslongbuffer ( ) ; <nl> buf . put ( interopaspointer ( jnienv . getnativepointer ( ) ) ) ;
public final class vm extends nativeenv implements contextaccess { <nl> string name = null ; <nl> if ( jniversion . issupported ( version , getcontext ( ) . getjavaversion ( ) ) ) { <nl> group = gethandles ( ) . get ( math . tointexact ( grouphandle ) ) ; <nl> - <nl> + name = fromutf8ptr ( nameptr ) ; <nl> + } else { <nl> + getlogger ( ) . warning ( string . format ( " attachcurrentthread with unsupported javavmattachargs version : num x % 08x " , version ) ) ; <nl> } <nl> staticobject thread = getcontext ( ) . createthread ( thread . currentthread ( ) , group , name ) ; <nl> if ( daemon ) { <nl>
public final class target_java_lang_thread { <nl> self . getklass ( ) . vtablelookup ( meta . java_lang_thread_run . getvtableindex ( ) ) . invokedirect ( self ) ; <nl> checkdeprecatedstate ( meta , self ) ; <nl> } catch ( espressoexception uncaught ) { <nl> - <nl> meta . java_lang_thread_dispatchuncaughtexception . invokedirect ( self , uncaught . getexceptionobject ( ) ) ; <nl> } <nl> } catch ( espressoexitexception exit ) {
public final class truffletreedumper { <nl>  <nl> private static void dumpinlinedasts ( truffledebugcontext debug , set < compilabletruffleast > inlinedtargets , trufflenodesources nodesources ) throws ioexception { <nl> final graphoutput < ast , ? > astoutput = debug . buildoutput ( graphoutput . newbuilder ( ast_dump_structure ) . blocks ( ast_dump_structure ) ) ; <nl> - <nl> - astoutput . endgroup ( ) ; <nl> astoutput . begingroup ( null , " inlined " , " inlined " , null , num , debug . getversionproperties ( ) ) ; <nl> for ( compilabletruffleast target : inlinedtargets ) { <nl> ast ast = new ast ( ( rootcalltarget ) target , nodesources ) ;
public class flatnodegenfactory { <nl> } <nl>  <nl> private boolean needsaotreset ( ) { <nl> - <nl> - return node . isgenerateaot ( ) & & node . needsrewrites ( context ) ; <nl> + return node . isgenerateaot ( ) & & needsrewrites ( ) ; <nl> } <nl>  <nl> private boolean hasmultiplenodes ( ) {
bench - llvm - sulong - graalvm - ce : $ { bench_vm_ce_linux_base } $ { bench - llvm - sulong - comm <nl> ] <nl> run : [ <nl> [ mx , - - dynamicimport , sulong - benchmarks , - - env , ce , benchmark , - - results - file , $ { bench_vm_ce_linux_base . resultfile } , " csuite : * " , - - , - - native - vm , sulong , - - native - vm - config , default , - - jvm , graalvm - ce , - - jvm - config , " $ { jvm_config } " ] <nl> - # <nl> - [ mx , - - dynamicimport , sulong - benchmarks , - - env , ce - llimul , benchmark , - - results - file , $ { bench_vm_ce_linux_base . resultfile } , " csuite : * " , - - , - - native - vm , sulong - multi , - - native - vm - config , default , - - jvm , graalvm - ce , - - jvm - config , " $ { jvm_config } " , " - - multi - context - runs = 3 " , " - - engine . compilationfailureaction = silent " , " - - engine . treatperformancewarningsaserrors = none " ] <nl> + ] <nl> + timelimit : " 10 : 00 : 01 " <nl> + } <nl> + <nl> + bench - llvm - sulong - graalvm - ce - llimul : $ { bench_vm_ce_linux_base } $ { bench - llvm - sulong - common } $ { sulong - weekly - notifications } { <nl> + environment : { <nl> + vm_dist : ce - llimul <nl> + } <nl> + setup : $ { bench_vm_ce_linux_base . setup } [ <nl> + [ git , clone , - - depth , " 1 " , $ { repobase } " $ { bench_repo_name } . git " , " . . / . . / $ { bench_repo_name } " ] <nl> + ] <nl> + run : [ <nl> + [ mx , - - dynamicimport , sulong - benchmarks , - - env , ce - llimul , benchmark , - - results - file , $ { bench_vm_ce_linux_base . resultfile } , " csuite : * " , - - , - - native - vm , sulong - multi , - - native - vm - config , default , - - jvm , graalvm - ce , - - jvm - config , " $ { jvm_config } " , " - - multi - context - runs = 3 " ] <nl> ] <nl> timelimit : " 10 : 00 : 01 " <nl> } <nl>
import com . oracle . truffle . llvm . runtime . pointer . llvmpointer ; <nl>  <nl> @ generateuncached <nl> public abstract class llvminteropvtableaccessnode extends llvmnode { <nl> - abstract object execute ( object vtablepointer , long virtualindex , object [ ] arguments ) throws unsupportedtypeexception , arityexception , unsupportedmessageexception ; <nl> + abstract object execute ( object vtablepointer , llvminteroptype . method method , long virtualindex , object [ ] arguments ) throws unsupportedtypeexception , arityexception , unsupportedmessageexception ; <nl>  <nl> public static llvminteropvtableaccessnode create ( ) { <nl> return llvminteropvtableaccessnodegen . create ( ) ; <nl> } <nl>  <nl> @ specialization <nl> - object dopointer ( llvmpointer vtablepointer , long virtualindex , object [ ] arguments , @ cachedlibrary ( limit = " 5 " ) interoplibrary interop ) <nl> + object dopointer ( llvmpointer vtablepointer , llvminteroptype . method method , long virtualindex , object [ ] arguments , @ cachedlibrary ( limit = " 5 " ) interoplibrary interop ) <nl> throws unsupportedtypeexception , arityexception , unsupportedmessageexception { <nl> llvmmemory memory = llvmlanguage . getlanguage ( ) . getllvmmemory ( ) ; <nl> - / / ' target ' calculation <nl> - llvmpointer vtableelementpointer = vtablepointer . increment ( virtualindex ) ; <nl> - final long methodaddress = memory . geti64 ( this , llvmnativepointer . cast ( vtableelementpointer ) ) ; <nl> - llvmpointer methodpointer = llvmnativepointer . create ( methodaddress ) ; <nl>  <nl> - <nl> - long vtableaddress = llvmnativepointer . cast ( vtablepointer ) . asnative ( ) ; <nl> - final long methodaddressbylong = memory . geti64 ( null , vtableaddress + virtualindex * num ) ; <nl> - llvmpointer methodpointerbylong = llvmnativepointer . create ( methodaddressbylong ) ; <nl> + llvmpointer vtableelementpointer = vtablepointer . increment ( virtualindex * num ) ; <nl> + llvmnativepointer mapointer = llvmnativepointer . cast ( vtableelementpointer ) ; <nl> + final long methodaddress = memory . geti64 ( this , mapointer ) ; <nl> + llvminteroptype methodpointertype = llvminteroptype . value . pointer ( method , num ) ; <nl> + llvmpointer methodpointer = llvmnativepointer . create ( methodaddress ) . export ( methodpointertype ) ; <nl>  <nl> - return interop . execute ( methodpointerbylong , arguments ) ; <nl> + return interop . execute ( methodpointer , arguments ) ; <nl> } <nl>  <nl> }
final class ditypeextractor implements metadatavisitor { <nl>  <nl> @ override <nl> public void visit ( mdsubprogram mdsubprogram ) { <nl> - llvmsourcetype llvmsourcetype ; <nl> + / / ' this ' parameter of thunk methods is missing in the debug info , thus fix here . <nl> + llvmsourcetype llvmsourcetype = resolve ( mdsubprogram . gettype ( ) ) ; <nl> if ( flags . thunk . issetin ( mdsubprogram . getflags ( ) ) ) { <nl> - mdvalue mdvalue = ( mdvalue ) mdsubprogram . getfunction ( ) ; <nl> - functiondefinition function = ( functiondefinition ) mdvalue . getvalue ( ) ; <nl> - list < llvmsourcetype > typelist = new arraylist < > ( ) ; <nl> - typelist . add ( llvmsourcetype . void ) ; / / return type <nl> - for ( functionparameter fp : function . getparameters ( ) ) { <nl> - <nl> - typelist . add ( unknown ) ; <nl> + symbolimpl symbol = mdvalue . getifinstance ( mdsubprogram . getfunction ( ) ) ; <nl> + if ( symbol ! = null & & symbol instanceof functiondefinition ) { <nl> + functiondefinition function = ( functiondefinition ) symbol ; <nl> + final datalayout datalayout = llvmlanguage . getcontext ( ) . getlibsulongdatalayout ( ) ; <nl> + llvmsourcetype llvmsourcereturntype = llvmsourcetypefactory . resolvetype ( function . gettype ( ) . getreturntype ( ) , datalayout ) ; <nl> + list < llvmsourcetype > typelist = new arraylist < > ( ) ; <nl> + typelist . add ( llvmsourcereturntype ) ; <nl> + for ( functionparameter fp : function . getparameters ( ) ) { <nl> + llvmsourcetype parametersourcetype = llvmsourcetypefactory . resolvetype ( fp . gettype ( ) , <nl> + datalayout ) ; <nl> + typelist . add ( parametersourcetype ) ; <nl> + } <nl> + llvmsourcetype = new llvmsourcefunctiontype ( typelist ) ; <nl> } <nl> - llvmsourcetype = new llvmsourcefunctiontype ( typelist ) ; <nl> - } else { <nl> - llvmsourcetype = resolve ( mdsubprogram . gettype ( ) ) ; <nl> } <nl> parsedtypes . put ( mdsubprogram , llvmsourcetype ) ; <nl> }
public final class bytecodenode extends espressomethodnode { <nl> / / region local accessors <nl>  <nl> public static void freelocal ( long [ ] primitives , object [ ] refs , int slot ) { <nl> - <nl> - espressoframe . putlong ( primitives , primitives . length - num - slot , num ) ; <nl> - espressoframe . putrawobject ( refs , refs . length - num - slot , null ) ; <nl> + assert primitives . length = = refs . length ; <nl> + espressoframe . clear ( primitives , refs , primitives . length - num - slot ) ; <nl> } <nl>  <nl> public static void setlocalobject ( object [ ] refs , int slot , staticobject value ) {
suite = { <nl> " jacoco " : " include " , <nl> } , <nl>  <nl> - " com . oracle . truffle . llvm . legacy " : { <nl> - # <nl> - " subdir " : " projects " , <nl> - " sourcedirs " : [ " src " ] , <nl> - " dependencies " : [ <nl> - ] , <nl> - " checkstyle " : " com . oracle . truffle . llvm . runtime " , <nl> - " javacompliance " : " 1 . 8 + " , <nl> - " workingsets " : " truffle , llvm " , <nl> - " license " : " bsd - new " , <nl> - " jacoco " : " include " , <nl> - } , <nl> - <nl> " com . oracle . truffle . llvm . nativemode " : { <nl> " subdir " : " projects " , <nl> " sourcedirs " : [ " src " ] , <nl>
suite = { <nl> } , <nl>  <nl> " distributions " : { <nl> - " sulong " : { <nl> - # <nl> - " subdir " : " projects " , <nl> - " dependencies " : [ <nl> - " com . oracle . truffle . llvm . legacy " , <nl> - ] , <nl> - " distdependencies " : [ <nl> - " sulong_core " , <nl> - " sulong_native " , <nl> - ] , <nl> - " license " : " bsd - new " , <nl> - } , <nl> " sulong_core " : { <nl> " description " : " sulong core functionality ( parser , execution engine , launcher ) " , <nl> " subdir " : " projects " , <nl> mmm a / sulong / projects / com . oracle . truffle . llvm . legacy / src / com / oracle / truffle / llvm / legacy / package - info . java <nl> ppp / dev / null <nl>
<nl> - / * <nl> - * copyright ( c ) num , oracle and / or its affiliates . <nl> - * <nl> - * all rights reserved . <nl> - * <nl> - * redistribution and use in source and binary forms , with or without modification , are <nl> - * permitted provided that the following conditions are met : <nl> - * <nl> - * num . redistributions of source code must retain the above copyright notice , this list of <nl> - * conditions and the following disclaimer . <nl> - * <nl> - * num . redistributions in binary form must reproduce the above copyright notice , this list of <nl> - * conditions and the following disclaimer in the documentation and / or other materials provided <nl> - * with the distribution . <nl> - * <nl> - * num . neither the name of the copyright holder nor the names of its contributors may be used to <nl> - * endorse or promote products derived from this software without specific prior written <nl> - * permission . <nl> - * <nl> - * this software is provided by the copyright holders and contributors " as is " and any express <nl> - * or implied warranties , including , but not limited to , the implied warranties of <nl> - * merchantability and fitness for a particular purpose are disclaimed . in no event shall the <nl> - * copyright holder or contributors be liable for any direct , indirect , incidental , special , <nl> - * exemplary , or consequential damages ( including , but not limited to , procurement of substitute <nl> - * goods or services ; loss of use , data , or profits ; or business interruption ) however caused <nl> - * and on any theory of liability , whether in contract , strict liability , or tort ( including <nl> - * negligence or otherwise ) arising in any way out of the use of this software , even if advised <nl> - * of the possibility of such damage . <nl> - * / <nl> - / * * <nl> - * <nl> - * / <nl> - package com . oracle . truffle . llvm . legacy ;
public final class rubyflavorprocessor implements regexflavorprocessor { <nl> if ( lookbehinddepth > num ) { <nl> throw syntaxerror ( " invalid pattern in look - behind " ) ; <nl> } <nl> - if ( groupnumber > groupindex ) { <nl> - / / forward reference <nl> - if ( groupnumber > = num ) { <nl> - / / forward references > = num are interpreted as octal escapes instead <nl> - position = restoreposition ; <nl> - return false ; <nl> - } <nl> - <nl> - / / { @ code / ( ? : ( \ 2 ) | ( . ) ) + / . match ( " aa " ) } <nl> - bailout ( " forward references are not supported " ) ; <nl> + if ( groupnumber > groupindex & & groupnumber > = num ) { <nl> + / / forward references > = num are interpreted as octal escapes instead <nl> + position = restoreposition ; <nl> + return false ; <nl> } <nl> emitbackreference ( groupnumber ) ; <nl> return true ;
public final class rubyflavorprocessor implements regexflavorprocessor { <nl> while ( ! atend ( ) ) { <nl> switch ( consumechar ( ) ) { <nl> case ' \ \ ' : <nl> - / / skip escaped char <nl> - switch ( consumechar ( ) ) { <nl> - case ' c ' : <nl> - / / skip control character in \ \ c ( <nl> - advance ( ) ; <nl> - break ; <nl> - case ' c ' : <nl> - / / \ \ c - ( <nl> + / / skip control escape sequences , \ \ cx , \ \ c - x or \ \ m - x , which can be nested <nl> + while ( curchar ( ) = = ' c ' | | curchar ( ) = = ' c ' | | curchar ( ) = = ' m ' ) { <nl> + if ( curchar ( ) = = ' c ' ) { <nl> + advance ( 1 ) ; <nl> + } else { <nl> advance ( 2 ) ; <nl> - break ; <nl> - <nl> + } <nl> + } <nl> + / / skip escaped char ; if it includes a group name , skip that too <nl> + switch ( consumechar ( ) ) { <nl> case ' k ' : <nl> case ' g ' : <nl> / / skip contents of group name ( which might contain syntax chars ) <nl>
public final class rubyflavorprocessor implements regexflavorprocessor { <nl> c = silentcharacterescape ( ) ; <nl> } <nl> return c & num x9f ; <nl> - <nl> + } <nl> + case ' m ' : { <nl> + if ( atend ( ) ) { <nl> + syntaxerror ( " end pattern at meta " ) ; <nl> + } <nl> + if ( ! match ( " - " ) ) { <nl> + syntaxerror ( " invalid meta - code syntax " ) ; <nl> + } <nl> + if ( atend ( ) ) { <nl> + syntaxerror ( " end pattern at meta " ) ; <nl> + } <nl> + int c = consumechar ( ) ; <nl> + if ( c = = ' \ \ ' ) { <nl> + c = silentcharacterescape ( ) ; <nl> + } <nl> + return ( c & num xff ) | num x80 ; <nl> } <nl> case ' x ' : { <nl> string code = getupto ( 2 , rubyflavorprocessor : : ishexdigit ) ;
public final class rubyflavorprocessor implements regexflavorprocessor { <nl> if ( match ( " ? " ) ) { <nl> emitsnippet ( " ? " ) ; <nl> } <nl> - if ( match ( " + " ) ) { <nl> + else if ( ch ! = ' { ' & & match ( " + " ) ) { <nl> bailout ( " possessive quantifiers not supported " ) ; <nl> - <nl> } <nl> lastterm = termcategory . quantifier ; <nl> }
public final class compilationtask implements trufflecompilationtask , callable < v <nl> } <nl>  <nl> / * * <nl> - * <nl> + * since { @ link backgroundcompilequeue } uses a { @ link java . util . concurrent . threadpoolexecutor } <nl> + * to run compilations , and since the executor expects each { @ link callable } ( in our case , the <nl> + * { @ link compilationtask } ) to be converted into a { @ link futuretask } we use this wrapper around <nl> + * the { @ link compilationtask } just for compatibility with the executor . <nl> * / <nl> static class executorservicewrapper extends futuretask < void > implements comparable < executorservicewrapper > { <nl> final compilationtask compiletask ;
public final class coveragetracker implements autocloseable { <nl> } <nl>  <nl> / * * <nl> - * <nl> + * destructive read of the coverage data thus far ( i . e . since beginning execution or or last <nl> + * reset ) <nl> * <nl> - * @ return the coverage gathered thus far . <nl> - * @ since num . 3 . 0 <nl> + * @ return the coverage gathered since last reset or beginning of execution . <nl> + * @ since num . 3 . 0 <nl> * / <nl> public synchronized sourcecoverage [ ] resetcoverage ( ) { <nl> sourcecoverage [ ] coverages = sourcecoverage ( mapping ( true ) ) ;
public final class bytecodenode extends espressomethodnode { <nl>  <nl> / / region misc . checks <nl>  <nl> + private void enterimplicitexception ( ) { <nl> + if ( ! implicitexceptionseen ) { <nl> + compilerdirectives . transfertointerpreterandinvalidate ( ) ; <nl> + implicitexceptionseen = true ; <nl> + } <nl> + } <nl> + <nl> private staticobject nullcheck ( staticobject value ) { <nl> if ( staticobject . isnull ( value ) ) { <nl> - <nl> + enterimplicitexception ( ) ; <nl> throw getmeta ( ) . thrownullpointerexception ( ) ; <nl> } <nl> return value ; <nl>
public final class objectklass extends klass { <nl>  <nl> private void flushreflectioncaches ( ) { <nl> / / increment the redefine count on the class instance to flush reflection caches <nl> - if ( redefinitioncountfield = = null ) { <nl> - for ( field f : mirror ( ) . getklass ( ) . getdeclaredfields ( ) ) { <nl> - <nl> - if ( " classredefinedcount " . equals ( f . getnameasstring ( ) ) ) { <nl> - redefinitioncountfield = f ; <nl> - break ; <nl> - } <nl> - } <nl> - } <nl> - int value = interpretertovm . getfieldint ( mirror ( ) , redefinitioncountfield ) ; <nl> - interpretertovm . setfieldint ( + + value , mirror ( ) , redefinitioncountfield ) ; <nl> + int value = interpretertovm . getfieldint ( mirror ( ) , getmeta ( ) . java_lang_class_classredefinedcount ) ; <nl> + interpretertovm . setfieldint ( + + value , mirror ( ) , getmeta ( ) . java_lang_class_classredefinedcount ) ; <nl> } <nl>  <nl> private static method findmethod ( parsermethod changedmethod , method [ ] declaredmethods ) { <nl> mmm a / src / com . oracle . truffle . espresso / src / com / oracle / truffle / espresso / meta / meta . java <nl> ppp b / src / com . oracle . truffle . espresso / src / com / oracle / truffle / espresso / meta / meta . java <nl>
public final class llvmglobal extends llvmsymbol { <nl> return type . getpointeetype ( ) ; <nl> } <nl>  <nl> - / * <nl> - * public void define ( trufflefile file ) { define ( type , file ) ; } <nl> - * / <nl> - <nl> - <nl> - / / c + + code <nl> - / * <nl> - * public void define ( pointertype newtype , trufflefile file ) { assert newtype ! = null & & file ! = <nl> - * null ; if ( ! isdefined ( ) ) { this . type = newtype ; setfile ( file ) ; } else { <nl> - * compilerdirectives . transfertointerpreter ( ) ; throw new assertionerror ( <nl> - * " found multiple definitions of global " + getname ( ) + " . " ) ; } } <nl> - * / <nl> - <nl> public boolean isreadonly ( ) { <nl> return readonly ; <nl> }
public abstract class arraylengthnode extends quicknode { <nl>  <nl> abstract int executegetlength ( staticobject array ) ; <nl>  <nl> - @ specialization ( guards = " array . isforeignobject ( ) " , limit = " 3 " ) <nl> - int doforeign ( staticobject array , @ cachedlibrary ( " array . rawforeignobject ( ) " ) interoplibrary interop , @ cachedcontext ( espressolanguage . class ) espressocontext context , <nl> + @ specialization ( guards = " array . isforeignobject ( ) " ) <nl> + int doforeign ( staticobject array , <nl> + @ cachedlibrary ( limit = " limit " ) interoplibrary interop , <nl> + @ cachedcontext ( espressolanguage . class ) espressocontext context , <nl> @ cached branchprofile exceptionprofile ) { <nl> try { <nl> - <nl> - return ( int ) interop . getarraysize ( array . rawforeignobject ( ) ) ; <nl> + long arraylength = interop . getarraysize ( array . rawforeignobject ( ) ) ; <nl> + if ( arraylength > integer . max_value ) { <nl> + exceptionprofile . enter ( ) ; <nl> + throw meta . throwexceptionwithmessage ( context . getmeta ( ) . java_lang_classcastexception , " the foreign array length does not fit in int " ) ; <nl> + } <nl> + return ( int ) arraylength ; <nl> } catch ( unsupportedmessageexception e ) { <nl> exceptionprofile . enter ( ) ; <nl> throw meta . throwexceptionwithmessage ( context . getmeta ( ) . java_lang_illegalargumentexception , " called ' length ' on a non - array object " ) ;
public abstract class toespressonode extends node { <nl> return staticobject . createforeignnull ( value ) ; <nl> } <nl>  <nl> - <nl> - @ suppresswarnings ( " unused " ) <nl> - @ specialization ( guards = { " ! isstaticobject ( value ) " , " ! interop . isnull ( value ) " , " isstringarray ( klass ) " } ) <nl> - object doarray ( object value , <nl> - arrayklass klass , <nl> - @ cached toespressonode toespressonode , <nl> - @ cachedlibrary ( limit = " limit " ) interoplibrary interop , <nl> - @ cached branchprofile exceptionprofile ) <nl> - throws unsupportedtypeexception { <nl> - int length = num ; <nl> - try { <nl> - length = ( int ) interop . getarraysize ( value ) ; <nl> - } catch ( unsupportedmessageexception e ) { <nl> - exceptionprofile . enter ( ) ; <nl> - throw unsupportedtypeexception . create ( new object [ ] { value } , " casting a non - array foreign object to an array " ) ; <nl> - } <nl> - final klass jlstring = klass . getcomponenttype ( ) ; <nl> - return jlstring . allocatereferencearray ( length , new intfunction < staticobject > ( ) { <nl> - @ override <nl> - public staticobject apply ( int index ) { <nl> - if ( interop . isarrayelementreadable ( value , index ) ) { <nl> - try { <nl> - object elem = interop . readarrayelement ( value , index ) ; <nl> - return ( staticobject ) toespressonode . execute ( elem , jlstring ) ; <nl> - } catch ( unsupportedmessageexception | invalidarrayindexexception e ) { <nl> - rethrow ( unsupportedtypeexception . create ( new object [ ] { value } , klass . gettypeasstring ( ) ) ) ; <nl> - } catch ( unsupportedtypeexception e ) { <nl> - rethrow ( e ) ; <nl> - } <nl> - } <nl> - rethrow ( unsupportedtypeexception . create ( new object [ ] { value } , klass . gettypeasstring ( ) ) ) ; <nl> - throw espressoerror . shouldnotreachhere ( ) ; <nl> - } <nl> - } ) ; <nl> - } <nl> - <nl> @ specialization ( guards = { " ! isstaticobject ( value ) " , " ! interop . isnull ( value ) " , " isstring ( klass ) " } ) <nl> object dostring ( object value , <nl> objectklass klass , <nl>
public abstract class toespressonode extends node { <nl> throw unsupportedtypeexception . create ( new object [ ] { value } , klass . gettypeasstring ( ) ) ; <nl> } <nl>  <nl> - <nl> - @ specialization ( guards = { " ! isstaticobject ( value ) " , " ! interop . isnull ( value ) " , " ! isstringarray ( klass ) " } ) <nl> + @ specialization ( guards = { " ! isstaticobject ( value ) " , " ! interop . isnull ( value ) " } ) <nl> object doforeignarray ( object value , arrayklass klass , <nl> @ suppresswarnings ( " unused " ) @ cachedlibrary ( limit = " limit " ) interoplibrary interop ) throws unsupportedtypeexception { <nl> if ( ! interop . hasarrayelements ( value ) ) { <nl>
final class target_org_jline_builtins_nano_buffer { <nl> @ alias list < string > lines ; <nl> @ alias private charset charset ; <nl>  <nl> + / * * <nl> + * this is a slightly modified version of the original { @ linkplain nano # read <nl> + * https : / / github . com / jline / jline3 / blob / <commit_id> / builtins / src / main / java / org / jline / builtins / nano . java # l257 } <nl> + * method . the modification is the removal of the attempt to detect the charset using an <nl> + * optional dependency ( universaldetector ) which , when not on the classpath would break the <nl> + * native - image build . the original source code is provided under the bsd licence . <nl> + * / <nl> @ substitute <nl> void read ( inputstream fis ) throws ioexception { <nl> - <nl> - / / https : / / github . com / jline / jline3 / blob / master / builtins / src / main / java / org / jline / builtins / nano . java # l267 <nl> bytearrayoutputstream bos = new bytearrayoutputstream ( ) ; <nl> byte [ ] buffer = new byte [ 4096 ] ; <nl>  <nl>
public class runtimestate { <nl>  <nl> void setglobaladdress ( int globalindex , int address ) { <nl> ensureglobalscapacity ( globalindex ) ; <nl> - <nl> + checknotlinked ( ) ; <nl> globaladdresses [ globalindex ] = address ; <nl> } <nl>  <nl>
public class runtimestate { <nl> } <nl>  <nl> void settable ( wasmtable table ) { <nl> - <nl> + checknotlinked ( ) ; <nl> this . table = table ; <nl> } <nl>  <nl>
public class runtimestate { <nl> } <nl>  <nl> public void setmemory ( wasmmemory memory ) { <nl> - <nl> + checknotlinked ( ) ; <nl> this . memory = memory ; <nl> } <nl> }
public abstract class klass implements modifiersprovider , contextaccess , klassre <nl>  <nl> @ specialization ( guards = " isobjectklass ( receiver ) " ) <nl> static boolean doobject ( klass receiver ) { <nl> - <nl> - return receiver . isconcrete ( ) ; <nl> + if ( receiver . isabstract ( ) ) { <nl> + return false ; <nl> + } <nl> + / * <nl> + * check that the class has a public constructor <nl> + * / <nl> + for ( method m : receiver . getdeclaredmethods ( ) ) { <nl> + if ( m . ispublic ( ) & & ! m . isstatic ( ) & & m . getname ( ) . equals ( name . _init_ ) ) { <nl> + return true ; <nl> + } <nl> + } <nl> + return false ; <nl> } <nl>  <nl> @ specialization ( guards = " receiver . isarray ( ) " )
public class nodedata extends template implements comparable < nodedata > { <nl>  <nl> private typemirror frametype ; <nl> private boolean generateintrospection ; <nl> - private boolean generatestatistics ; <nl> + private boolean generatestatistics ; <nl>  <nl> private boolean reportpolymorphism ; <nl> private boolean isuncachable ;
public final class polyglot { <nl> return targetclass . cast ( value ) ; <nl> } <nl>  <nl> - <nl> / * * <nl> * evaluates the given code in the given language . <nl> * <nl> * @ param languageid the id of one of the truffle languages <nl> * @ param sourcecode the source code in the { @ code language } <nl> * <nl> - * @ return the result of the evaluation as { @ link object } . to access members of the underlying <nl> - * foreign object , write a corresponding class or interface stub in java and cast the <nl> - * eval result to it using { @ link # cast polyglot . cast } . <nl> + * @ return the result of the evaluation as { @ link object } . <nl> + * <nl> + * @ throws illegalargumentexception <nl> + * < ul > <nl> + * < li > if the language is not available <nl> + * < li > if parsing of the code fails <nl> + * < / ul > <nl> + * <nl> + * @ apinote to access members of the foreign object , write a corresponding class or interface <nl> + * stub in java and cast the eval result to it using { @ link # cast polyglot . cast } . <nl> * / <nl> @ suppresswarnings ( " unused " ) <nl> public static object eval ( string languageid , string sourcecode ) { <nl>
final class truffletolibgraalentrypoints { <nl> } <nl> } <nl>  <nl> - / * * <nl> - * trace the " could not initialize class java . lang . processenvironment " the first call that <nl> - * triggers a class initialization has the full stack trace of what is wrong . the subsequent <nl> - * class initialization just throws the noclassdeffounderror . print the first stack trace . <nl> - * remove when the gr - 24487 is fixed . <nl> - * / <nl> - private static void tracegr24487 ( ) { <nl> - try { <nl> - system . getenv ( " jni_libgraal_trace_level " ) ; <nl> - } catch ( throwable t ) { <nl> - t . printstacktrace ( ) ; <nl> - throw t ; <nl> - } <nl> - } <nl> - <nl> @ truffletolibgraal ( newcompiler ) <nl> @ suppresswarnings ( { " unused " , " try " } ) <nl> @ centrypoint ( name = " java_org_graalvm_compiler_truffle_runtime_hotspot_libgraal_truffletolibgraalcalls_newcompiler " ) <nl> mmm a / compiler / src / org . graalvm . libgraal . jni / src / org / graalvm / libgraal / jni / jniutil . java <nl> ppp b / compiler / src / org . graalvm . libgraal . jni / src / org / graalvm / libgraal / jni / jniutil . java <nl>
final class truffletolibgraalentrypoints { <nl> } <nl> } <nl>  <nl> - / * * <nl> - * trace the " could not initialize class java . lang . processenvironment " the first call that <nl> - * triggers a class initialization has the full stack trace of what is wrong . the subsequent <nl> - * class initialization just throws the noclassdeffounderror . print the first stack trace . <nl> - * remove when the gr - 24487 is fixed . <nl> - * / <nl> - private static void tracegr24487 ( ) { <nl> - try { <nl> - system . getenv ( " jni_libgraal_trace_level " ) ; <nl> - } catch ( throwable t ) { <nl> - t . printstacktrace ( ) ; <nl> - throw t ; <nl> - } <nl> - } <nl> - <nl> @ truffletolibgraal ( newcompiler ) <nl> @ suppresswarnings ( { " unused " , " try " } ) <nl> @ centrypoint ( name = " java_org_graalvm_compiler_truffle_runtime_hotspot_libgraal_truffletolibgraalcalls_newcompiler " ) <nl> mmm a / compiler / src / org . graalvm . libgraal . jni / src / org / graalvm / libgraal / jni / jniutil . java <nl> ppp b / compiler / src / org . graalvm . libgraal . jni / src / org / graalvm / libgraal / jni / jniutil . java <nl>
public final class wasmblocknode extends wasmnode implements repeatingnode { <nl> } <nl>  <nl> @ explodeloop <nl> - private void unwindstack ( virtualframe frame , int initstackpointer , int initialcontinuationstackpointer , int targetblockreturnlength ) { <nl> - <nl> - / / values . <nl> - / / the spec seems to imply that the operand stack should not be inverted . <nl> - compilerasserts . partialevaluationconstant ( targetblockreturnlength ) ; <nl> - int stackpointer = initstackpointer ; <nl> - int continuationstackpointer = initialcontinuationstackpointer ; <nl> - for ( int i = num ; i ! = targetblockreturnlength ; i + + ) { <nl> - stackpointer - - ; <nl> - long value = pop ( frame , stackpointer ) ; <nl> - push ( frame , continuationstackpointer , value ) ; <nl> - continuationstackpointer + + ; <nl> + private void unwindstack ( virtualframe frame , int stackpointer , int continuationstackpointer , int returnlength ) { <nl> + compilerasserts . partialevaluationconstant ( stackpointer ) ; <nl> + compilerasserts . partialevaluationconstant ( returnlength ) ; <nl> + for ( int i = num ; i < returnlength ; + + i ) { <nl> + long value = pop ( frame , stackpointer + i - num ) ; <nl> + push ( frame , continuationstackpointer + i , value ) ; <nl> + } <nl> + if ( compilerdirectives . ispartialevaluationconstant ( continuationstackpointer ) ) { <nl> + for ( int i = continuationstackpointer + returnlength ; i < stackpointer ; + + i ) { <nl> + pop ( frame , i ) ; <nl> + } <nl> } <nl> } <nl>  <nl> mmm a / wasm / src / org . graalvm . wasm / src / org / graalvm / wasm / nodes / wasmnodeinterface . java <nl> ppp b / wasm / src / org . graalvm . wasm / src / org / graalvm / wasm / nodes / wasmnodeinterface . java <nl>
public final class wasmblocknode extends wasmnode implements repeatingnode { <nl> } <nl>  <nl> @ explodeloop <nl> - private void unwindstack ( virtualframe frame , int initstackpointer , int initialcontinuationstackpointer , int targetblockreturnlength ) { <nl> - <nl> - / / values . <nl> - / / the spec seems to imply that the operand stack should not be inverted . <nl> - compilerasserts . partialevaluationconstant ( targetblockreturnlength ) ; <nl> - int stackpointer = initstackpointer ; <nl> - int continuationstackpointer = initialcontinuationstackpointer ; <nl> - for ( int i = num ; i ! = targetblockreturnlength ; i + + ) { <nl> - stackpointer - - ; <nl> - long value = pop ( frame , stackpointer ) ; <nl> - push ( frame , continuationstackpointer , value ) ; <nl> - continuationstackpointer + + ; <nl> + private void unwindstack ( virtualframe frame , int stackpointer , int continuationstackpointer , int returnlength ) { <nl> + compilerasserts . partialevaluationconstant ( returnlength ) ; <nl> + for ( int i = num ; i ! = returnlength ; + + i ) { <nl> + long value = pop ( frame , stackpointer + i - num ) ; <nl> + push ( frame , continuationstackpointer + i , value ) ; <nl> + } <nl> + for ( int i = continuationstackpointer + returnlength ; i ! = stackpointer ; + + i ) { <nl> + pop ( frame , i ) ; <nl> } <nl> } <nl>  <nl> mmm a / wasm / src / org . graalvm . wasm / src / org / graalvm / wasm / nodes / wasmnodeinterface . java <nl> ppp b / wasm / src / org . graalvm . wasm / src / org / graalvm / wasm / nodes / wasmnodeinterface . java <nl>
class jimagelibrary extends nativeenv implements contextaccess { <nl> charsetencoder encoder = standardcharsets . utf_8 . newencoder ( ) ; <nl> int length = ( ( int ) ( name . length ( ) * encoder . averagebytesperchar ( ) ) ) + num ; <nl> for ( ; ; ) { <nl> + if ( length < = num ) { <nl> + throw espressoerror . shouldnotreachhere ( ) ; <nl> + } <nl> / / be super safe with the size of the buffer . <nl> bytebuffer bb = allocatedirect ( length ) ; <nl> encoder . reset ( ) ; <nl> coderresult result = encoder . encode ( charbuffer . wrap ( name ) , bb , true ) ; <nl> - if ( result . isunderflow ( ) & & ( bb . position ( ) < bb . capacity ( ) ) ) { <nl> - / / encoder encoded entire string , and we have one byte of leeway . <nl> - bb . put ( ( byte ) num ) ; <nl> - return bytebufferpointer ( bb ) ; <nl> - } <nl> - / / buffer was not big enough , retry with a bigger one . <nl> - length < < = num ; <nl> - if ( length = = num ) { <nl> + if ( result . isoverflow ( ) ) { <nl> + / / not enough space in the buffer <nl> + length < < = num ; <nl> + } else if ( result . isunderflow ( ) ) { <nl> + result = encoder . flush ( bb ) ; <nl> + if ( result . isunderflow ( ) & & ( bb . position ( ) < bb . capacity ( ) ) ) { <nl> + / / encoder encoded entire string , and we have one byte of leeway . <nl> + bb . put ( ( byte ) num ) ; <nl> + return bytebufferpointer ( bb ) ; <nl> + } <nl> + if ( result . isoverflow ( ) | | result . isunderflow ( ) ) { <nl> + length + = num ; <nl> + } else { <nl> + throw espressoerror . shouldnotreachhere ( ) ; <nl> + } <nl> + } else { <nl> throw espressoerror . shouldnotreachhere ( ) ; <nl> } <nl> - <nl> - / / for now , expect shouldnotreachhere if the length would be close to max_int <nl> } <nl> }
import com . oracle . truffle . api . instrumentation . executioneventnode ; <nl> class warmupestimatornode extends executioneventnode { <nl>  <nl> private final list < long > times ; <nl> - <nl> private frameslot startslot ; <nl>  <nl> warmupestimatornode ( list < long > times ) {
public final class callnode extends node implements comparable < callnode > { <nl> getcalltree ( ) . expanded + + ; <nl> assert state = = state . expanded ; <nl> assert ir = = null ; <nl> - <nl> - graphmanager . entry entry = getcalltree ( ) . getgraphmanager ( ) . pe ( truffleast ) ; <nl> + graphmanager . entry entry ; <nl> + try { <nl> + entry = getcalltree ( ) . getgraphmanager ( ) . pe ( truffleast ) ; <nl> + } catch ( bailoutexception e ) { <nl> + state = state . bailedout ; <nl> + return ; <nl> + } <nl> ir = copygraphandaddchildren ( entry ) ; <nl> addindirectchildren ( entry ) ; <nl> getpolicy ( ) . afterexpand ( this ) ; <nl>
the following interop messages were changed : <nl> read , write , remove , has_size , get_size , has_keys , keys <nl> ` ` ` <nl>  <nl> - the updated protocol with separate member and array namespace in [ interoplibrary ] ( <nl> + the updated protocol with separate member and array namespace in [ interoplibrary ] ( http : / / www . graalvm . org / truffle / javadoc / com / oracle / truffle / api / interop / interoplibrary . html ) looks like this : <nl>  <nl> # # # # object namespace : <nl>  <nl> mmm a / truffle / docs / readme . md <nl> ppp b / truffle / docs / readme . md <nl>
<nl> * / <nl> package com . oracle . truffle . llvm . runtime . interop ; <nl>  <nl> - import com . oracle . truffle . api . dsl . cached ; <nl> + import com . oracle . truffle . api . dsl . fallback ; <nl> import com . oracle . truffle . api . dsl . generateuncached ; <nl> import com . oracle . truffle . api . dsl . nodechild ; <nl> import com . oracle . truffle . api . dsl . nodefield ; <nl> import com . oracle . truffle . api . dsl . specialization ; <nl> import com . oracle . truffle . api . frame . virtualframe ; <nl> - import com . oracle . truffle . api . profiles . branchprofile ; <nl> - import com . oracle . truffle . api . profiles . conditionprofile ; <nl> - import com . oracle . truffle . api . profiles . valueprofile ; <nl> + import com . oracle . truffle . api . library . cachedlibrary ; <nl> import com . oracle . truffle . llvm . runtime . except . llvmpolyglotexception ; <nl> + import com . oracle . truffle . llvm . runtime . library . internal . llvmasforeignlibrary ; <nl> import com . oracle . truffle . llvm . runtime . nodes . api . llvmexpressionnode ; <nl> import com . oracle . truffle . llvm . runtime . nodes . api . llvmnode ; <nl> import com . oracle . truffle . llvm . runtime . pointer . llvmmanagedpointer ; <nl> - import com . oracle . truffle . llvm . runtime . pointer . llvmpointer ; <nl>  <nl> @ generateuncached <nl> @ nodechild ( type = llvmexpressionnode . class ) <nl> @ nodefield ( name = " allownonforeign " , type = boolean . class ) <nl> - <nl> public abstract class llvmasforeignnode extends llvmnode { <nl> public abstract object execute ( virtualframe frame ) ; <nl>  <nl>
the following interop messages were changed : <nl> read , write , remove , has_size , get_size , has_keys , keys <nl> ` ` ` <nl>  <nl> - the updated protocol with separate member and array namespace in [ interoplibrary ] ( <nl> + the updated protocol with separate member and array namespace in [ interoplibrary ] ( http : / / www . graalvm . org / truffle / javadoc / com / oracle / truffle / api / interop / interoplibrary . html ) looks like this : <nl>  <nl> # # # # object namespace : <nl>  <nl> mmm a / truffle / docs / readme . md <nl> ppp b / truffle / docs / readme . md <nl>
fastr_linux : $ { fastr } { <nl> pkg_include_flags_override : " - i / cm / shared / apps / zlib / 1 . 2 . 11 / include - i / cm / shared / apps / bzip2 / 1 . 0 . 6 / include - i / cm / shared / apps / xz / 5 . 2 . 2 / include - i / cm / shared / apps / pcre / 8 . 43 / include - i / cm / shared / apps / curl / 7 . 50 . 1 / include " <nl> pkg_ldflags_override : " - l / cm / shared / apps / zlib / 1 . 2 . 11 / lib - l / cm / shared / apps / bzip2 / 1 . 0 . 6 / lib - l / cm / shared / apps / xz / 5 . 2 . 2 / lib - l / cm / shared / apps / pcre / 8 . 43 / lib - l / cm / shared / apps / curl / 7 . 50 . 1 / lib - l / cm / shared / apps / gcc / 4 . 8 . 5 / lib64 " <nl> gnur_home_binary : " / cm / shared / apps / gnur / 3 . 6 . 1 - gcc4 . 8 . 5 / lib64 / r " , <nl> - fc : " / cm / shared / apps / gcc / 4 . 8 . 5 / bin / gfortran " <nl> - ff : " / cm / shared / apps / gcc / 4 . 8 . 5 / bin / gfortran " <nl> + fastr_fc : " / cm / shared / apps / gcc / 4 . 8 . 5 / bin / gfortran " <nl> } <nl> } <nl>  <nl> fastr_darwin : $ { fastr } { <nl> packages : { <nl> - " pcre " : " = = 8 . 43 " <nl> - " gnur " : " = = 3 . 6 . 1 " <nl> + " pcre " : " = = 8 . 43 " <nl> } <nl> environment : { <nl> - # <nl> path : " / usr / local / bin : $ java_home / bin : $ path " <nl> - fc : " / usr / local / bin / gfortran - 4 . 9 " <nl> + fastr_fc : " / cm / shared / apps / gcc / 8 . 3 . 0 / bin / gfortran " <nl> tzdir : " / usr / share / zoneinfo " <nl> fastr_libz_ver : " 1 . 2 . 11 " <nl> - gnur_home_binary : " / cm / shared / apps / gnur / 3 . 6 . 1 / lib / r " <nl> + gnur_home_binary : " / cm / shared / apps / gnur / 3 . 6 . 1 . 8 . 3 . 0 / lib / r / " <nl> + pkg_include_flags_override : " - i / cm / shared / apps / pcre / 8 . 43 / include - i / cm / shared / apps / bzip2 / 1 . 0 . 6 / include - i / cm / shared / apps / xz / 5 . 2 . 2 / include - i / cm / shared / apps / curl / 7 . 50 . 1 / include " <nl> + pkg_ldflags_override : " - l / cm / shared / apps / bzip2 / 1 . 0 . 6 / lib - l / cm / shared / apps / xz / 5 . 2 . 2 / lib - l / cm / shared / apps / pcre / 8 . 43 / lib - l / cm / shared / apps / curl / 7 . 50 . 1 / lib - l / cm / shared / apps / gcc / 8 . 3 . 0 / lib - l / usr / lib " <nl> } <nl> } <nl>  <nl> mmm a / vm / mx . vm / suite . py <nl> ppp b / vm / mx . vm / suite . py <nl>
fastr_linux : $ { fastr } { <nl>  <nl> fastr_darwin : $ { fastr } { <nl> packages : { <nl> - " gcc " : " = = 8 . 3 . 0 " <nl> " pcre " : " = = 8 . 43 " <nl> - " gnur " : " = = 3 . 6 . 1 . 8 . 3 . 0 " <nl> } <nl> environment : { <nl> - # <nl> path : " / usr / local / bin : $ java_home / bin : $ path " <nl> fc : " / cm / shared / apps / gcc / 8 . 3 . 0 / bin / gfortran " <nl> ff : " / cm / shared / apps / gcc / 8 . 3 . 0 / bin / gfortran " <nl> tzdir : " / usr / share / zoneinfo " <nl> fastr_libz_ver : " 1 . 2 . 11 " <nl> gnur_home_binary : " / cm / shared / apps / gnur / 3 . 6 . 1 . 8 . 3 . 0 / lib / r / " <nl> - pkg_include_flags_override : " - i / cm / shared / apps / pcre / 8 . 43 / include - i / cm / shared / apps / bzip2 / 1 . 0 . 6 / include - i / cm / shared / apps / xz / 5 . 2 . 2 / include - i / cm / shared / apps / curl / 7 . 50 . 1 / include " <nl> + pkg_include_flags_override : " - i / cm / shared / apps / pcre / 8 . 43 / include - i / cm / shared / apps / bzip2 / 1 . 0 . 6 / include - i / cm / shared / apps / xz / 5 . 2 . 2 / include - i / cm / shared / apps / curl / 7 . 50 . 1 / include " <nl> pkg_ldflags_override : " - l / cm / shared / apps / bzip2 / 1 . 0 . 6 / lib - l / cm / shared / apps / xz / 5 . 2 . 2 / lib - l / cm / shared / apps / pcre / 8 . 43 / lib - l / cm / shared / apps / curl / 7 . 50 . 1 / lib - l / cm / shared / apps / gcc / 8 . 3 . 0 / lib - l / usr / lib " <nl> } <nl> }
import jdk . vm . ci . meta . speculationlog ; <nl> public abstract class optimizedcalltarget implements compilabletruffleast , rootcalltarget , replaceobserver { <nl>  <nl> private static final string node_rewriting_assumption_name = " noderewritingassumption " ; <nl> - <nl> - static final string call_boundary_method_name = " executerootnode " ; <nl> - static final string call_inlined_method_name = " call " ; <nl> + static final string execute_root_node_method_name = " executerootnode " ; <nl> private static final atomicreferencefieldupdater < optimizedcalltarget , speculationlog > speculation_log_updater = atomicreferencefieldupdater . newupdater ( optimizedcalltarget . class , <nl> speculationlog . class , " speculationlog " ) ; <nl> private static final atomicreferencefieldupdater < optimizedcalltarget , assumption > node_rewriting_assumption_updater = atomicreferencefieldupdater . newupdater ( optimizedcalltarget . class , <nl>
public final class bciblockmapping implements javamethodcontext { <nl> return lasthandler ; <nl> } <nl>  <nl> - private boolean loopchanges ; <nl> - <nl> private void computeblockorder ( bciblock [ ] blockmap ) { <nl> int maxblocks = blocksnotyetassignedid ; <nl> this . blocks = new bciblock [ blocksnotyetassignedid ] ; <nl> computeblockorder ( blockmap [ 0 ] ) ; <nl> - <nl> - / / - - - - - <nl> - loopchanges = false ; <nl> - for ( bciblock b : blocks ) { <nl> - if ( b ! = null ) { <nl> - b . visited = false ; <nl> - } <nl> - } <nl> - graalerror . guarantee ( fixloopbits ( blockmap [ 0 ] ) = = num , " fixloopbits should not find irreducible loops " ) ; <nl> - graalerror . guarantee ( ! loopchanges , " fixloopbits should not find things to change " ) ; <nl> - / / - - - - - <nl> int duplicatedblocks = newduplicateblocks + duplicateblocks ; <nl> if ( duplicatedblocks > num ) { <nl> debug . log ( debugcontext . info_level , " duplicated % d blocks . original block count : % d " , duplicatedblocks , postjsrblockcount ) ; <nl>
public final class nficontextextension implements contextextension { <nl> if ( filename . startswith ( " libc . " ) | | filename . startswith ( " libsystem . " ) ) { <nl> / / nothing to do , since libsulong . so already links against libc . so / libsystem . b . dylib <nl> return true ; <nl> - } else if ( filename . startswith ( " libpolyglot - mock . " ) ) { <nl> - / / special mock library for polyglot intrinsics <nl> - <nl> - return true ; <nl> } else { <nl> return false ; <nl> }
public final class loadklassnode extends rootnode { <nl> @ override <nl> public object execute ( virtualframe frame ) { <nl> assert frame . getarguments ( ) . length = = num ; <nl> - <nl> string classname = null ; <nl> try { <nl> - classname = interoplibrary . getfactory ( ) . getuncached ( ) . asstring ( targetclassname ) ; <nl> + classname = uncached . asstring ( targetclassname ) ; <nl> } catch ( unsupportedmessageexception e ) { <nl> - throw new runtimeexception ( e ) ; <nl> + compilerdirectives . transfertointerpreter ( ) ; <nl> + throw new illegalargumentexception ( e ) ; <nl> } <nl> espressocontext context = espressolanguage . getcurrentcontext ( ) ; <nl> meta meta = context . getmeta ( ) ; <nl> staticobject appclassloader = ( staticobject ) meta . java_lang_classloader_getsystemclassloader . invokedirect ( null ) ; <nl> - staticobject guestclass = ( staticobject ) meta . java_lang_class . lookupdeclaredmethod ( name . forname , signature . class_string_boolean_classloader ) . invokedirect ( null , <nl> - meta . togueststring ( classname ) , false , appclassloader ) ; <nl>  <nl> - return guestclass . getmirrorklass ( ) ; <nl> + try { <nl> + staticobject guestclass = ( staticobject ) meta . java_lang_class_forname_string_boolean_classloader . invokedirect ( null , meta . togueststring ( classname ) , false , appclassloader ) ; <nl> + return guestclass . getmirrorklass ( ) ; <nl> + } catch ( espressoexception e ) { <nl> + if ( interpretertovm . instanceof ( e . getexceptionobject ( ) , meta . java_lang_classnotfoundexception ) ) { <nl> + return staticobject . null ; <nl> + } <nl> + throw e ; <nl> + } <nl> } <nl> }
public abstract class klass implements modifiersprovider , contextaccess , klassre <nl> return new keysarray ( members . toarray ( new string [ members . size ( ) ] ) ) ; <nl> } <nl>  <nl> - @ exportmessage <nl> - static class isinstantiable { <nl> - <nl> - @ specialization ( guards = " receiver . isarray ( ) " ) <nl> - static boolean doarray ( @ suppresswarnings ( " unused " ) klass receiver ) { <nl> - return true ; <nl> - } <nl> - <nl> - @ specialization ( replaces = " doarray " ) <nl> - static boolean doconstructor ( klass receiver ) { <nl> - if ( receiver . isabstract ( ) ) { <nl> - return false ; <nl> - } <nl> - for ( method m : receiver . getdeclaredmethods ( ) ) { <nl> - if ( m . ispublic ( ) & & name . _init_ . equals ( m . getname ( ) ) ) { <nl> - return true ; <nl> - } <nl> - } <nl> - return false ; <nl> - } <nl> - } <nl> - <nl> - @ exportmessage <nl> - static class instantiate { <nl> - <nl> - @ specialization ( guards = " receiver . isarray ( ) " ) <nl> - static object doarray ( klass receiver , object [ ] args , <nl> - @ cachedlibrary ( limit = " 1 " ) interoplibrary indexes ) throws unsupportedmessageexception , unsupportedtypeexception , arityexception { <nl> - if ( args . length ! = num ) { <nl> - throw arityexception . create ( 1 , args . length ) ; <nl> - } <nl> - object arg0 = args [ 0 ] ; <nl> - int length ; <nl> - if ( indexes . fitsinint ( arg0 ) ) { <nl> - length = indexes . asint ( arg0 ) ; <nl> - } else { <nl> - throw unsupportedtypeexception . create ( args ) ; <nl> - } <nl> - klass component = receiver . getcomponenttype ( ) ; <nl> - <nl> - if ( component . isprimitive ( ) ) { <nl> - byte jvmprimitivetype = ( byte ) component . getjavakind ( ) . getbasictype ( ) ; <nl> - return interpretertovm . allocateprimitivearray ( jvmprimitivetype , length ) ; <nl> - } <nl> - return component . allocatereferencearray ( length ) ; <nl> - } <nl> - <nl> - @ specialization <nl> - static object doconstructor ( klass receiver , object [ ] arguments , <nl> - @ exclusive @ cached invokeespressonode invoke ) throws unsupportedmessageexception , unsupportedtypeexception , arityexception { <nl> - for ( method m : receiver . getdeclaredmethods ( ) ) { <nl> - if ( m . ispublic ( ) & & name . _init_ . equals ( m . getname ( ) ) & & m . getparametercount ( ) = = arguments . length ) { <nl> - staticobject instance = receiver . allocateinstance ( ) ; <nl> - invoke . execute ( m , instance , arguments ) ; <nl> - return instance ; <nl> - } <nl> - } <nl> - throw unsupportedmessageexception . create ( ) ; <nl> - } <nl> - } <nl> - <nl> / / endregion interop <nl>  <nl> static final comparator < klass > klass_id_comparator = new comparator < klass > ( ) {
final class runner { <nl> } <nl>  <nl> / * * <nl> - * <nl> + * allocates global storage for a module and initializes the global table . <nl> + * <nl> + * @ see initializeglobalnode <nl> + * @ see initializemodulenode <nl> * / <nl> private static final class initializesymbolsnode extends llvmnode { <nl>  <nl>
final class runner { <nl> } <nl>  <nl> / * * <nl> - * <nl> + * initializes the memory , allocated by { @ link initializesymbolsnode } , for a module and protects <nl> + * the read only section . <nl> + * <nl> + * @ see initializesymbolsnode <nl> + * @ see initializemodulenode <nl> * / <nl> private static final class initializeglobalnode extends llvmnode implements llvmhasdatalayoutnode { <nl>  <nl>
final class runner { <nl> } <nl>  <nl> / * * <nl> - * <nl> + * registers the destructor and executes the constructor of a module . this happens after <nl> + * < emph > all < / emph > globals have been initialized by { @ link initializeglobalnode } . <nl> + * <nl> + * @ see initializesymbolsnode <nl> + * @ see initializeglobalnode <nl> * / <nl> private static final class initializemodulenode extends llvmnode implements llvmhasdatalayoutnode {
final class jdwp { <nl> if ( classloader = = null ) { <nl> return new commandresult ( reply ) ; <nl> } <nl> - <nl> - <nl> - / / initiating loader <nl> - / / tracked by / browse / gr - 19820 <nl> klassref [ ] klasses = context . getinitiatedclasses ( classloader ) ; <nl>  <nl> reply . writeint ( klasses . length ) ;
public final class vm extends nativeenv implements contextaccess { <nl> return false ; <nl> } <nl>  <nl> + / * * <nl> + * returns the caller frame , ' depth ' levels up . if securitystackwalk is true , some espresso <nl> + * frames are skipped according to { @ link # isignoredbysecuritystackwalk } . <nl> + * / <nl> private static frameinstance getcallerframe ( int depth , boolean securitystackwalk ) { <nl> - <nl> - / / non - espresso frames ( e . g trufflenfi ) are ignored . <nl> - / / the call stack should look like this : <nl> - / / num : the @ callersensitive annotated method . <nl> - / / . . . : skipped non - espresso frames . <nl> - / / num : getcallerclass method . <nl> - / / . . . : <nl> - / / num : the callee . <nl> - / / <nl> - / / jvm_caller_depth = > the caller . <nl> - int callerdepth = ( depth = = jvm_caller_depth ) ? num : depth + num ; <nl> + if ( depth = = jvm_caller_depth ) { <nl> + return getcallerframe ( 1 , securitystackwalk ) ; <nl> + } <nl> + assert depth > = num ; <nl>  <nl> - final int [ ] depthcounter = new int [ ] { callerdepth } ; <nl> - frameinstance target = truffle . getruntime ( ) . iterateframes ( <nl> + / / ignores non - espresso frames . <nl> + / / <nl> + / / the call stack at this point looks something like this : <nl> + / / <nl> + / / [ 0 ] [ current frame e . g . accesscontroller . doprivileged , reflection . getcallerclass ] <nl> + / / [ . ] [ ( skipped intermediate frames ) ] <nl> + / / . . . <nl> + / / [ n ] [ caller ] <nl> + frameinstance callerframe = truffle . getruntime ( ) . iterateframes ( <nl> new frameinstancevisitor < frameinstance > ( ) { <nl> + private int n ; <nl> + <nl> @ override <nl> public frameinstance visitframe ( frameinstance frameinstance ) { <nl> method m = getmethodfromframe ( frameinstance ) ; <nl> if ( m ! = null ) { <nl> if ( ! securitystackwalk | | ! isignoredbysecuritystackwalk ( m , m . getmeta ( ) ) ) { <nl> - if ( - - depthcounter [ 0 ] < num ) { <nl> + if ( n = = depth ) { <nl> return frameinstance ; <nl> } <nl> + + + n ; <nl> } <nl> } <nl> return null ; <nl> } <nl> } ) ; <nl> - if ( target ! = null ) { <nl> - return target ; <nl> + <nl> + if ( callerframe ! = null ) { <nl> + return callerframe ; <nl> } <nl> - throw espressoerror . shouldnotreachhere ( ) ; <nl> + <nl> + throw espressoerror . shouldnotreachhere ( string . format ( " caller frame not found at depth % d " , depth ) ) ; <nl> } <nl>  <nl> private static espressorootnode getespressorootfromframe ( frameinstance frameinstance ) { <nl>
public class amd64assembler extends amd64baseassembler { <nl> public final int immediatesize ( operandsize size ) { <nl> if ( immisbyte ) { <nl> return num ; <nl> - } else if ( size = = qword ) { <nl> - <nl> - return num ; <nl> } else { <nl> - return size . getbytes ( ) ; <nl> + return size . immediatesize ( ) ; <nl> } <nl> } <nl> }
public class binaryparser extends binarystreamparser { <nl> break ; <nl> } <nl> case instructions . return : { <nl> + / / pop the stack values used as the return values . <nl> + for ( int i = num ; i < codeentry . function ( ) . returntypelength ( ) ; i + + ) { <nl> + state . pop ( ) ; <nl> + } <nl> state . uselongconstant ( state . stackstatecount ( ) ) ; <nl> state . useintconstant ( state . getrootblockreturnlength ( ) ) ; <nl> - <nl> + if ( ( peek1 ( ) & num xff ) = = instructions . end ) { <nl> + final int targetstacksize = state . getstackstate ( 0 ) ; <nl> + final int continuationreturnlength = state . getcontinuationreturnlength ( 0 ) ; <nl> + while ( state . stacksize ( ) > targetstacksize + continuationreturnlength ) { <nl> + state . pop ( ) ; <nl> + } <nl> + } <nl> break ; <nl> } <nl> case instructions . call : {
public class binaryparser extends binarystreamparser { <nl> } <nl> } <nl> branchtable [ 0 ] = returnlength ; <nl> - <nl> - state . pop ( ) ; <nl> / / the offset to the branch table . <nl> state . savebranchtable ( branchtable ) ; <nl> break ;
public final class espressocontext { <nl> return threadmanager . getmainthread ( ) ; <nl> } <nl>  <nl> - @ suppresswarnings ( " static - method " ) <nl> - public boolean isvalidthreadgroup ( @ suppresswarnings ( " unused " ) object threadgroup ) { <nl> - <nl> - return true ; <nl> - } <nl> - <nl> public staticobject getmainthreadgroup ( ) { <nl> return mainthreadgroup ; <nl> } <nl> mmm a / src / com . oracle . truffle . espresso / src / com / oracle / truffle / espresso / runtime / jdwpcontextimpl . java <nl> ppp b / src / com . oracle . truffle . espresso / src / com / oracle / truffle / espresso / runtime / jdwpcontextimpl . java <nl>
final class jdwp { <nl> } <nl> } <nl>  <nl> - <nl> - / / tracked by / browse / gr - 19817 <nl> - / / enabling causes the netbeans debugger to send wrong stepping <nl> - / / events for step into / over so disabled for now . perhaps the bytecode <nl> - / / returned from method . getcode ( ) is incorrect ? <nl> static class bytecodes { <nl> public static final int id = num ;
final class jdwp { <nl> reply . writebyte ( typetag . getkind ( klass ) ) ; <nl> reply . writelong ( context . getids ( ) . getidaslong ( klass ) ) ; <nl> reply . writestring ( klass . gettypeasstring ( ) ) ; <nl> - <nl> - / / tracked by / browse / gr - 19818 <nl> - reply . writestring ( " " ) ; <nl> + reply . writestring ( klass . getgenerictypeasstring ( ) ) ; <nl> reply . writeint ( klass . getstatus ( ) ) ; <nl> }
final class jdwp { <nl> } <nl>  <nl> reply . writestring ( klass . gettypeasstring ( ) ) ; <nl> - <nl> - / / tracked by / browse / gr - 19818 <nl> - reply . writestring ( " " ) ; <nl> + reply . writestring ( klass . getgenerictypeasstring ( ) ) ; <nl> return new commandresult ( reply ) ; <nl> } <nl> } <nl> mmm a / src / com . oracle . truffle . espresso / src / com / oracle / truffle / espresso / impl / klass . java <nl> ppp b / src / com . oracle . truffle . espresso / src / com / oracle / truffle / espresso / impl / klass . java <nl>
final class jdwp { <nl> reply . writelong ( context . getids ( ) . getidaslong ( method ) ) ; <nl> reply . writestring ( method . getnameasstring ( ) ) ; <nl> reply . writestring ( method . getsignatureasstring ( ) ) ; <nl> - <nl> - / / tracked by / browse / gr - 19818 <nl> - reply . writestring ( " " ) ; <nl> + reply . writestring ( method . getgenericsignatureasstring ( ) ) ; <nl> int modbits = checksyntheticflag ( method . getmodifiers ( ) ) ; <nl> reply . writeint ( modbits ) ; <nl> } <nl> mmm a / src / com . oracle . truffle . espresso / src / com / oracle / truffle / espresso / impl / method . java <nl> ppp b / src / com . oracle . truffle . espresso / src / com / oracle / truffle / espresso / impl / method . java <nl>
final class jdwp { <nl> reply . writebyte ( typetag . getkind ( klass ) ) ; <nl> reply . writelong ( context . getids ( ) . getidaslong ( klass ) ) ; <nl> reply . writestring ( klass . gettypeasstring ( ) ) ; <nl> - <nl> - / / tracked by / browse / gr - 19818 <nl> - reply . writestring ( " " ) ; <nl> + reply . writestring ( klass . getgenerictypeasstring ( ) ) ; <nl> reply . writeint ( klass . getstatus ( ) ) ; <nl> }
public class delegatorclassloader extends secureclassloader { <nl> @ override <nl> public class < ? > loadclass ( string name ) throws classnotfoundexception { <nl> classloader cl = delegate ! = null ? delegate : getparent ( ) ; <nl> - / / system . out . println ( " loading class " + name + " with " + cl ) ; <nl> return cl . loadclass ( name ) ; <nl> } <nl>  <nl> - @ suppresswarnings ( " all " ) <nl> + @ suppresswarnings ( " unused " ) <nl> public void appendtoclasspathforinstrumentation ( string filepath ) { <nl> - <nl> + try { <nl> + method method = reflectionutil . lookupmethod ( getparent ( ) . getclass ( ) , " appendtoclasspathforinstrumentation " , string . class ) ; <nl> + method . invoke ( getparent ( ) , filepath ) ; <nl> + } catch ( reflectiveoperationexception e ) { <nl> + string message = string . format ( " warning : can not add jar : % s to class path . due to % s " , filepath , e ) ; <nl> + system . err . println ( message ) ; <nl> + } <nl> } <nl> }
final class jdwp { <nl> } <nl>  <nl> reply . writestring ( klass . gettypeasstring ( ) ) ; <nl> - <nl> - / / tracked by / browse / gr - 19818 <nl> - reply . writestring ( " " ) ; <nl> + reply . writestring ( klass . getgenerictypeasstring ( ) ) ; <nl> return new commandresult ( reply ) ; <nl> } <nl> } <nl> mmm a / src / com . oracle . truffle . espresso / src / com / oracle / truffle / espresso / impl / klass . java <nl> ppp b / src / com . oracle . truffle . espresso / src / com / oracle / truffle / espresso / impl / klass . java <nl>
final class jdwp { <nl> reply . writelong ( context . getids ( ) . getidaslong ( method ) ) ; <nl> reply . writestring ( method . getnameasstring ( ) ) ; <nl> reply . writestring ( method . getsignatureasstring ( ) ) ; <nl> - <nl> - / / tracked by / browse / gr - 19818 <nl> - reply . writestring ( " " ) ; <nl> + reply . writestring ( method . getgenericsignatureasstring ( ) ) ; <nl> int modbits = checksyntheticflag ( method . getmodifiers ( ) ) ; <nl> reply . writeint ( modbits ) ; <nl> } <nl> mmm a / src / com . oracle . truffle . espresso / src / com / oracle / truffle / espresso / impl / method . java <nl> ppp b / src / com . oracle . truffle . espresso / src / com / oracle / truffle / espresso / impl / method . java <nl>
<nl> - / * <nl> - * copyright ( c ) num , num , oracle and / or its affiliates . all rights reserved . <nl> - * do not alter or remove copyright notices or this file header . <nl> - * <nl> - * this code is free software ; you can redistribute it and / or modify it <nl> - * under the terms of the gnu general public license version num only , as <nl> - * published by the free software foundation . <nl> - * <nl> - * this code is distributed in the hope that it will be useful , but without <nl> - * any warranty ; without even the implied warranty of merchantability or <nl> - * fitness for a particular purpose . see the gnu general public license <nl> - * version num for more details ( a copy is included in the license file that <nl> - * accompanied this code ) . <nl> - * <nl> - * you should have received a copy of the gnu general public license version <nl> - * num along with this work ; if not , write to the free software foundation , <nl> - * inc . , num franklin st , fifth floor , boston , ma num - 1301 usa . <nl> - * <nl> - * please contact oracle , num oracle parkway , redwood shores , ca num usa <nl> - * or visit www . oracle . com if you need additional information or have any <nl> - * questions . <nl> - * / <nl> - package com . oracle . truffle . espresso . jdwp . impl ; <nl> - <nl> - public final class classnameutils { <nl> - <nl> - public static string frominternalobjectnametoslashname ( string internalobjectname ) { <nl> - <nl> - string temp = internalobjectname . substring ( 1 , internalobjectname . length ( ) - num ) ; <nl> - return temp ; <nl> - } <nl> - } <nl> mmm a / src / com . oracle . truffle . espresso . jdwp / src / com / oracle / truffle / espresso / jdwp / impl / jdwp . java <nl> ppp b / src / com . oracle . truffle . espresso . jdwp / src / com / oracle / truffle / espresso / jdwp / impl / jdwp . java <nl>
public final class callnode extends node { <nl> getcalltree ( ) . inlined + + ; <nl> } <nl>  <nl> - <nl> private static void handleisattachedinlinednode ( invoke invoke ) { <nl> final nodeinputlist < valuenode > arguments = invoke . calltarget ( ) . arguments ( ) ; <nl> final valuenode argument = arguments . get ( 1 ) ; <nl>
public class jdwpdebuggercontroller { <nl>  <nl> if ( ! isstepping ( thread ) ) { <nl> if ( ! sessionclosed ) { <nl> - <nl> try { <nl> jdwplogger . log ( " calling underlying resume method for thread : " + getthreadname ( thread ) , jdwplogger . loglevel . thread ) ; <nl> - <nl> - resumemethod . invoke ( debuggersession , getcontext ( ) . getguest2hostthread ( thread ) ) ; <nl> + debuggersession . resume ( getcontext ( ) . getguest2hostthread ( thread ) ) ; <nl> } catch ( exception e ) { <nl> throw new runtimeexception ( " failed to resume thread : " + getthreadname ( thread ) , e ) ; <nl> } <nl>
public class jdwpdebuggercontroller { <nl> } <nl>  <nl> try { <nl> + jdwplogger . log ( " state : " + getcontext ( ) . getguest2hostthread ( thread ) . getstate ( ) , jdwplogger . loglevel . thread ) ; <nl> jdwplogger . log ( " calling underlying suspend method for thread : " + getthreadname ( thread ) , jdwplogger . loglevel . thread ) ; <nl> - thread . state threadstate = getcontext ( ) . getguest2hostthread ( thread ) . getstate ( ) ; <nl> - jdwplogger . log ( " state : " + threadstate , jdwplogger . loglevel . thread ) ; <nl> - <nl> - <nl> - suspendmethod . invoke ( debuggersession , getcontext ( ) . getguest2hostthread ( thread ) ) ; <nl> + debuggersession . suspend ( getcontext ( ) . getguest2hostthread ( thread ) ) ; <nl>  <nl> boolean suspended = threadsuspension . getsuspensioncount ( thread ) ! = num ; <nl> jdwplogger . log ( " suspend success : " + suspended , jdwplogger . loglevel . thread ) ;
public final class llvmbitcodeinstructionvisitor implements symbolvisitor { <nl> result = nodefactory . createallocaarray ( type , num , alignment ) ; <nl> } <nl>  <nl> - <nl> / / we never want to step on allocations , only to actual assignments in the source <nl> final sourceinstrumentationstrategy intention ; <nl> if ( context . getenv ( ) . getoptions ( ) . get ( sulongengineoption . ll_debug ) ) {
class jdwp { <nl> return new jdwpresult ( reply ) ; <nl> } <nl>  <nl> - reply . writestring ( " threadgroup - 1 " ) ; <nl> + reply . writestring ( " main " ) ; <nl> return new jdwpresult ( reply ) ; <nl> } <nl> }
public final class wasmlanguage extends trufflelanguage < wasmcontext > { <nl> final binaryparser reader = new binaryparser ( this , module , data ) ; <nl> reader . readmodule ( ) ; <nl> context . registermodule ( module ) ; <nl> - <nl> - return truffle . getruntime ( ) . createcalltarget ( new wasmundefinedfunctionrootnode ( this ) ) ; <nl> + final wasmfunction startfunction = module . symboltable ( ) . startfunction ( ) ; <nl> + if ( startfunction ! = null ) { <nl> + return startfunction . resolvecalltarget ( ) ; <nl> + } else { <nl> + return truffle . getruntime ( ) . createcalltarget ( new wasmundefinedfunctionrootnode ( this ) ) ; <nl> + } <nl> } <nl>  <nl> @ override
public abstract class wasmbenchmarksuitebase { <nl>  <nl> @ setup ( level . iteration ) <nl> public void setupiteration ( ) { <nl> - <nl> - / / capturedstdout = new bytearrayoutputstream ( ) ; <nl> - / / system . setout ( new printstream ( capturedstdout ) ) ; <nl> - <nl> / / reset result . <nl> result = null ; <nl>  <nl>
public class globals { <nl> / / are compiled with assumptions on what this field points to . <nl> / / such an assumption can be invalidated if the late - linking causes this array <nl> / / to be replaced with a larger array . <nl> - <nl> @ compilationfinal ( dimensions = num ) private long [ ] globals ; <nl> private int numglobals ;
public abstract class classregistry implements contextaccess { <nl> return classes . get ( type ) ; <nl> } <nl>  <nl> - / * * <nl> - * <nl> - * different classes . ideally , parsing should be extracted out from the synchronized block and <nl> - * synchronization left entirely to the concurrent map . <nl> - * / <nl> - public synchronized objectklass defineklass ( symbol < type > typeornull , final byte [ ] bytes ) { <nl> + public objectklass defineklass ( symbol < type > typeornull , final byte [ ] bytes ) { <nl> meta meta = getmeta ( ) ; <nl> string strtype = typeornull = = null ? null : typeornull . tostring ( ) ; <nl> parserklass parserklass = getparserklass ( bytes , strtype ) ; <nl>
<nl> - / * <nl> - * copyright ( c ) num , oracle and / or its affiliates . <nl> - * <nl> - * all rights reserved . <nl> - * <nl> - * redistribution and use in source and binary forms , with or without modification , are <nl> - * permitted provided that the following conditions are met : <nl> - * <nl> - * num . redistributions of source code must retain the above copyright notice , this list of <nl> - * conditions and the following disclaimer . <nl> - * <nl> - * num . redistributions in binary form must reproduce the above copyright notice , this list of <nl> - * conditions and the following disclaimer in the documentation and / or other materials provided <nl> - * with the distribution . <nl> - * <nl> - * num . neither the name of the copyright holder nor the names of its contributors may be used to <nl> - * endorse or promote products derived from this software without specific prior written <nl> - * permission . <nl> - * <nl> - * this software is provided by the copyright holders and contributors " as is " and any express <nl> - * or implied warranties , including , but not limited to , the implied warranties of <nl> - * merchantability and fitness for a particular purpose are disclaimed . in no event shall the <nl> - * copyright holder or contributors be liable for any direct , indirect , incidental , special , <nl> - * exemplary , or consequential damages ( including , but not limited to , procurement of substitute <nl> - * goods or services ; loss of use , data , or profits ; or business interruption ) however caused <nl> - * and on any theory of liability , whether in contract , strict liability , or tort ( including <nl> - * negligence or otherwise ) arising in any way out of the use of this software , even if advised <nl> - * of the possibility of such damage . <nl> - * / <nl> - package com . oracle . truffle . wasm . testcases . test ; <nl> - <nl> - import org . junit . test ; <nl> - <nl> - public final class resourcetest { <nl> - @ test <nl> - public void test ( ) { <nl> - <nl> - } <nl> - }
<nl> * / <nl> package com . oracle . truffle . espresso . debugger ; <nl>  <nl> - import com . oracle . truffle . api . debug . breakpoint ; <nl> + import com . oracle . truffle . api . compilerdirectives ; <nl> import com . oracle . truffle . espresso . impl . objectklass ; <nl>  <nl> - import java . util . hashset ; <nl>  <nl> public class vmeventlisteners { <nl>  <nl> private static final vmeventlisteners default = new vmeventlisteners ( ) ; <nl>  <nl> - <nl> - private hashset < vmeventlistener > listeners = new hashset < > ( ) ; <nl> + @ compilerdirectives . compilationfinal ( dimensions = num ) <nl> + private vmeventlistener [ ] listeners = new vmeventlistener [ 1 ] ; <nl>  <nl> vmeventlisteners ( ) { <nl>  <nl>
public class wasmmodule implements truffleobject { <nl> this . data = data ; <nl> } <nl>  <nl> - / / static final class table { <nl> - / / / * * <nl> - / / * a table is an array of u32 values , indexing the module functions ( imported or defined ) . <nl> - / / * / <nl> - / / @ compilationfinal ( dimensions = num ) private int [ ] functionindices ; <nl> - / / private int maxsize ; <nl> - / / private boolean initialized = false ; <nl> - / / <nl> - / / private table ( ) { <nl> - / / } <nl> - / / <nl> - / / public void initialize ( int initsize ) { <nl> - / / this . initialize ( initsize , integer . max_value ) ; <nl> - / / } <nl> - / / <nl> - / / public void initialize ( int initsize , int maxsize ) { <nl> - / / if ( initialized ) { <nl> - / / throw new wasmexception ( " table has already been initialized . " ) ; <nl> - / / } <nl> - / / this . functionindices = new int [ initsize ] ; <nl> - / / this . maxsize = maxsize ; <nl> - / / initialized = true ; <nl> - / / } <nl> - / / <nl> - / / public boolean validateindex ( int index ) { <nl> - / / <nl> - / / return <nl> - / / } <nl> - / / <nl> - / / public void initializecontents ( int offset , int [ ] contents ) { <nl> - / / system . arraycopy ( contents , num , functionindices , offset , contents . length ) ; <nl> - / / } <nl> - / / <nl> - / / public int functionindex ( int index ) { <nl> - / / return functionindices [ index ] ; <nl> - / / } <nl> - / / } <nl> - <nl> public symboltable symboltable ( ) { <nl> return symboltable ; <nl> }
public abstract class espressomethodnode extends espressoinstrumentablenode impl <nl> @ truffleboundary <nl> @ override <nl> public final sourcesection getsourcesection ( ) { <nl> - <nl> - / / also this should be cached , at least not create a new source every time . <nl> + linenumbertable linenumbertable = method . getcodeattribute ( ) . getlinenumbertable ( ) ; <nl> source s = getsource ( ) ; <nl> if ( s = = null ) { <nl> return null ; <nl> } <nl> + <nl> + if ( linenumbertable ! = linenumbertable . empty ) { <nl> + linenumbertable . entry [ ] entries = linenumbertable . getentries ( ) ; <nl> + int startline = entries [ 0 ] . getlinenumber ( ) ; <nl> + int endline = entries [ entries . length - num ] . getlinenumber ( ) ; <nl> + <nl> + return s . createsection ( startline , num , endline , num ) ; <nl> + } <nl> + / / also this should be cached , at least not create a new source every time . <nl> return s . createsection ( 1 ) ; <nl> }
public final class bytecodesnode extends espressomethodnode implements customnod <nl> } <nl> if ( table ! = null ) { <nl> linenumbertable . entry [ ] entries = table . getentries ( ) ; <nl> - this . statementnodes = new espressoinstrumentablenode [ entries . length ] ; <nl> - int maxbci = num ; <nl> - for ( int i = num ; i < entries . length ; i + + ) { <nl> - maxbci = math . max ( entries [ i ] . getbci ( ) , maxbci ) ; <nl> - } <nl> - / * <nl> - * <nl> - * maxbci . this should probably be implemented with a binary search when the node is <nl> - * looked up . we should make the binary search lookup to partially evaluate to a <nl> - * constant . it is still an open question whether the binary search lookup is fast <nl> - * enough in the interpreter . maybe we can do better by remembering something in the <nl> - * interpreter loop ? <nl> - * / <nl> - this . bcitoline = new int [ maxbci ] ; <nl> - int prevbci = num ; <nl> + statementnodes = new espressoinstrumentablenode [ entries . length ] ; <nl> + hookbcitonodeindex = new hashmap < > ( entries . length ) ; <nl> + <nl> for ( int i = num ; i < entries . length ; i + + ) { <nl> linenumbertable . entry entry = entries [ i ] ; <nl> - this . statementnodes [ i ] = new espressostatementnode ( prevbci , entries [ i ] ) ; <nl> - for ( int j = prevbci ; j < entry . getbci ( ) ; j + + ) { <nl> - bcitoline [ j ] = entry . getlinenumber ( ) ; <nl> - } <nl> - prevbci = entry . getbci ( ) ; <nl> + statementnodes [ i ] = new espressostatementnode ( entry . getbci ( ) , entry ) ; <nl> + hookbcitonodeindex . put ( entry . getbci ( ) , i ) ; <nl> } <nl> } else { <nl> - this . bcitoline = null ; <nl> this . statementnodes = null ; <nl> } <nl> } <nl>
public abstract class partialevaluator { <nl> inlineinvokeplugins = new inlineinvokeplugin [ ] { replacements , inlineinvokeplugin } ; <nl> } <nl>  <nl> - <nl> sourcelanguagepositionprovider sourcelanguageposition = new trufflesourcelanguagepositionprovider ( inliningdecision ) ; <nl> pegraphdecoder decoder = creategraphdecoder ( graph , tiercontext , loopexplosionplugin , decodinginvocationplugins , inlineinvokeplugins , parameterplugin , nodeplugins , <nl> sourcelanguageposition , graphcache ) ; <nl> mmm a / compiler / src / org . graalvm . compiler . truffle . compiler / src / org / graalvm / compiler / truffle / compiler / phases / inlining / callnode . java <nl> ppp b / compiler / src / org . graalvm . compiler . truffle . compiler / src / org / graalvm / compiler / truffle / compiler / phases / inlining / callnode . java <nl>
public final class callnode extends node { <nl> assert ir ! = null & & getparent ( ) ! = null ; <nl> final invoke invoke = getinvoke ( ) ; <nl> if ( ! invoke . isalive ( ) ) { <nl> - <nl> state = state . removed ; <nl> return ; <nl> } <nl> mmm a / compiler / src / org . graalvm . compiler . truffle . compiler / src / org / graalvm / compiler / truffle / compiler / phases / inlining / graphmanager . java <nl> ppp b / compiler / src / org . graalvm . compiler . truffle . compiler / src / org / graalvm / compiler / truffle / compiler / phases / inlining / graphmanager . java <nl>
final class graphmanager { <nl> public void notifynotinlined ( graphbuildercontext b , resolvedjavamethod original , invoke invoke ) { <nl> if ( original . equals ( callboundary ) ) { <nl> if ( lastdirectcallnode = = null ) { <nl> - <nl> return ; <nl> } <nl> trufflecallnode trufflecallnode = callnodeprovider . findcallnode ( lastdirectcallnode ) ;
public class calltree extends graph { <nl> } <nl>  <nl> public void trace ( ) { <nl> - if ( trufflecompileroptions . getvalue ( sharedtrufflecompileroptions . tracetruffleinlining ) ) { <nl> + final boolean details = trufflecompileroptions . getvalue ( sharedtrufflecompileroptions . tracetruffleinliningdetails ) ; <nl> + if ( trufflecompileroptions . getvalue ( sharedtrufflecompileroptions . tracetruffleinlining ) | | details ) { <nl> runtime . logevent ( 0 , " inline start " , root . getname ( ) , root . getstringproperties ( ) ) ; <nl> - tracerecursive ( root , num ) ; <nl> + tracerecursive ( root , details , num ) ; <nl> runtime . logevent ( 0 , " inline done " , root . getname ( ) , root . getstringproperties ( ) ) ; <nl> } <nl> } <nl>  <nl> - private void tracerecursive ( callnode node , int depth ) { <nl> + private void tracerecursive ( callnode node , boolean details , int depth ) { <nl> if ( depth ! = num ) { <nl> runtime . logevent ( depth , node . getstate ( ) . tostring ( ) , node . getname ( ) , node . getstringproperties ( ) ) ; <nl> } <nl> - <nl> - / / if ( node . getstate ( ) = = callnode . state . inlined ) { <nl> - for ( callnode child : node . getchildren ( ) ) { <nl> - tracerecursive ( child , depth + num ) ; <nl> + if ( node . getstate ( ) = = callnode . state . inlined | | details ) { <nl> + for ( callnode child : node . getchildren ( ) ) { <nl> + tracerecursive ( child , details , depth + num ) ; <nl> + } <nl> } <nl> }
public class wasmrootnode extends rootnode implements wasmnodeinterface { <nl> * / <nl> initializelocals ( frame ) ; <nl>  <nl> - <nl> - body . execute ( wasmcontext . getcurrent ( ) , frame ) ; <nl> + body . execute ( lookupcontextreference ( wasmlanguage . class ) . get ( ) , frame ) ; <nl>  <nl> long returnvalue = pop ( frame , num ) ; <nl> switch ( body . returntypeid ( ) ) {
public final class methodverifier implements contextaccess { <nl> } <nl> } <nl>  <nl> - <nl> - / / finding fixed points . <nl> - <nl> - private class workingqueue { <nl> + private static class workingqueue { <nl> queueelement first ; <nl> queueelement last ; <nl>  <nl>
public abstract class loopnode extends node { <nl> * <nl> * @ param frame the current execution frame or null if the repeating node does not require a <nl> * frame <nl> + * @ return the loop exit status - this is useful for languages that need to return some information <nl> + * when exiting out of a loop ( e . g . webassembly ) . <nl> * @ since num . 8 or earlier <nl> * / <nl> public abstract int executeloopwithstatus ( virtualframe frame ) ; <nl>  <nl> - <nl> + / * * <nl> + * same as { @ link # executeloopwithstatus ( virtualframe ) } , but ignores the loop exit status . <nl> + * provides backwards compatibility with language implementations that already depend on this method . <nl> + * <nl> + * @ param frame the current execution frame or null if the repeating node does not require a <nl> + * frame <nl> + * / <nl> public void executeloop ( virtualframe frame ) { <nl> executeloopwithstatus ( frame ) ; <nl> }
jlong jvm_maxmemory ( void ) { <nl> } <nl>  <nl> jint jvm_activeprocessorcount ( void ) { <nl> - native ( jvm_activeprocessorcount ) ; <nl> - <nl> - return sysconf ( _sc_nprocessors_onln ) ; <nl> + implemented ( jvm_activeprocessorcount ) ; <nl> + return ( * getenv ( ) ) - > jvm_activeprocessorcount ( ) ; <nl> } <nl>  <nl> void * jvm_loadlibrary ( const char * name ) { <nl> mmm a / src / com . oracle . truffle . espresso / src / com / oracle / truffle / espresso / vm / vm . java <nl> ppp b / src / com . oracle . truffle . espresso / src / com / oracle / truffle / espresso / vm / vm . java <nl>
class coveragenode extends executioneventnode { <nl> if ( ! covered ) { <nl> compilerdirectives . transfertointerpreterandinvalidate ( ) ; <nl> covered = true ; <nl> - final source source = instrumentedsourcesection . getsource ( ) ; <nl> - <nl> - if ( ! source . isinternal ( ) ) { <nl> - simplecoverageinstrument . addcovered ( instrumentedsourcesection ) ; <nl> - } <nl> + simplecoverageinstrument . addcovered ( instrumentedsourcesection ) ; <nl> } <nl> } <nl>  <nl> mmm a / truffle / src / com . oracle . truffle . st / src / com / oracle / truffle / st / gathersourcesectionslistener . java <nl> ppp b / truffle / src / com . oracle . truffle . st / src / com / oracle / truffle / st / gathersourcesectionslistener . java <nl>
class gathersourcesectionslistener implements loadsourcesectionlistener { <nl> @ override <nl> public void onload ( loadsourcesectionevent event ) { <nl> final sourcesection sourcesection = event . getsourcesection ( ) ; <nl> - <nl> - if ( ! sourcesection . getsource ( ) . isinternal ( ) ) { <nl> - simplecoverageinstrument . addloaded ( sourcesection ) ; <nl> - } <nl> + simplecoverageinstrument . addloaded ( sourcesection ) ; <nl> } <nl> - <nl> }
public class wasmblocknode extends wasmnode implements repeatingnode { <nl>  <nl> @ override <nl> public boolean executerepeating ( virtualframe frame ) { <nl> - wasmcontext context = null ; <nl> - return execute ( context , frame ) ! = - 1 ; <nl> + return execute ( wasmcontext . getcurrent ( ) , frame ) ! = - 1 ; <nl> } <nl>  <nl> @ override <nl> mmm a / wasm / src / com . oracle . truffle . wasm / src / com / oracle / truffle / wasm / binary / wasmcontext . java <nl> ppp b / wasm / src / com . oracle . truffle . wasm / src / com / oracle / truffle / wasm / binary / wasmcontext . java <nl>
public class wasmrootnode extends rootnode implements wasmnodeinterface { <nl> * / <nl> argumentstolocals ( frame ) ; <nl>  <nl> - wasmcontext context = null ; <nl> - body . execute ( context , frame ) ; <nl> - <nl> + body . execute ( wasmcontext . getcurrent ( ) , frame ) ; <nl> long returnvalue = pop ( frame , num ) ; <nl> switch ( body . returntypeid ( ) ) { <nl> case num x00 :
public class binaryreader extends binarystreamreader { <nl> currentblock . setbytelength ( offset ( ) - startoffset ) ; <nl> currentblock . setbyteconstantlength ( state . byteconstantoffset ( ) - startbyteconstantoffset ) ; <nl> currentblock . setintconstantlength ( state . intconstantoffset ( ) - startintconstantoffset ) ; <nl> - <nl> - / / checkvalidstateonblockexit ( returntypeid , state , startstacksize ) ; <nl> + checkvalidstateonblockexit ( returntypeid , state , startstacksize ) ; <nl> return currentblock ; <nl> }
class fieldtable { <nl> } <nl> } <nl>  <nl> - <nl> - <nl> / * * <nl> * greedily tries to fill the space between a parent ' s fields and its child . <nl> * <nl>
public final class vm extends nativeenv implements contextaccess { <nl> @ vmimpl <nl> @ jniimpl <nl> public @ host ( class . class ) staticobject jvm_defineclass ( string name , @ host ( classloader . class ) staticobject loader , long bufptr , int len , <nl> - @ suppresswarnings ( " unused " ) @ host ( protectiondomain . class ) staticobject pd ) { <nl> - <nl> + @ host ( protectiondomain . class ) staticobject pd ) { <nl> bytebuffer buf = jnienv . directbytebuffer ( bufptr , len , javakind . byte ) ; <nl> final byte [ ] bytes = new byte [ len ] ; <nl> buf . get ( bytes ) ;
public abstract class amd64lirgenerator extends lirgenerator { <nl> } else if ( isfloatcomparison ) { <nl> append ( new floatcondmoveop ( result , finalcondition , unorderedistrue , load ( finaltruevalue ) , load ( finalfalsevalue ) ) ) ; <nl> } else { <nl> - <nl> - append ( new condmoveop ( result , finalcondition , load ( finaltruevalue ) , loadnonconst ( finalfalsevalue ) ) ) ; <nl> + if ( isnarrowoop ( finalfalsevalue ) ) { <nl> + finalfalsevalue = emitmove ( finalfalsevalue ) ; <nl> + } else { <nl> + finalfalsevalue = loadnonconst ( finalfalsevalue ) ; <nl> + } <nl> + append ( new condmoveop ( result , finalcondition , load ( finaltruevalue ) , finalfalsevalue ) ) ; <nl> } <nl> return result ; <nl> } <nl>  <nl> + private static boolean isnarrowoop ( value value ) { <nl> + if ( isconstantvalue ( value ) ) { <nl> + constant c = asconstant ( value ) ; <nl> + if ( c instanceof javaconstant & & ( ( javaconstant ) c ) . getjavakind ( ) = = javakind . object & & value . getplatformkind ( ) . getsizeinbytes ( ) ! = num ) { <nl> + return true ; <nl> + } <nl> + } <nl> + return false ; <nl> + } <nl> + <nl> @ override <nl> public variable emitintegertestmove ( value left , value right , value truevalue , value falsevalue ) { <nl> emitintegertest ( left , right ) ;
public class binaryreader extends binarystreamreader { <nl> case local_tee : { <nl> int localindex = readlocalindex ( bytesconsumed ) ; <nl> state . usebyteconstant ( bytesconsumed [ 0 ] ) ; <nl> - <nl> - codeentry . localslot ( localindex ) ; <nl> + / / assert localindex exists . <nl> + assert . assertless ( localindex , codeentry . numlocals ( ) , " invalid local <nl> / / assert there is a value on the top of the stack . <nl> assert . assertlarger ( state . stacksize ( ) , num , " local . tee requires at least one element in the stack " ) ; <nl> state . push ( ) ; <nl> mmm a / wasm / src / com . oracle . truffle . wasm / src / com / oracle / truffle / wasm / binary / wasmcodeentry . java <nl> ppp b / wasm / src / com . oracle . truffle . wasm / src / com / oracle / truffle / wasm / binary / wasmcodeentry . java <nl>
public class binaryreader { <nl> return ( x0 < < num ) | ( x1 < < num ) | ( x2 < < num ) | x3 ; <nl> } <nl>  <nl> - <nl> public int readsignedleb128 ( ) { <nl> - throw new runtimeexception ( ) ; <nl> + int result = num ; <nl> + int shift = num ; <nl> + byte b ; <nl> + do { <nl> + b = read1 ( ) ; <nl> + result | = ( ( b & num x7f ) < < shift ) ; <nl> + shift + = num ; <nl> + } while ( ( b & num x80 ) ! = num ) ; <nl> + <nl> + if ( ( shift < num ) & & ( b & num x40 ) = = num ) { <nl> + result | = ( ~ 0 < < shift ) ; <nl> + } <nl> + return result ; <nl> } <nl>  <nl> public int peakunsignedleb128 ( int ahead ) { <nl> - int number = num ; <nl> + int result = num ; <nl> + int shift = num ; <nl> int i = num ; <nl> do { <nl> byte b = peak1 ( i + ahead ) ; <nl> - number | = ( b & num x7f ) < < ( 7 * i ) ; <nl> + result | = ( b & num x7f ) < < shift ; <nl> if ( ( b & num x80 ) = = num ) { <nl> break ; <nl> } <nl> + shift + = num ; <nl> i + + ; <nl> - } while ( i < num ) ; <nl> - if ( i = = num ) { <nl> + } while ( shift < num ) ; <nl> + if ( shift = = num ) { <nl> assert . fail ( " unsigned leb128 overflow " ) ; <nl> } <nl> - return number ; <nl> + return result ; <nl> } <nl>  <nl> / / this is used for indices , so we don ' t expect values larger than num ^ 31 . <nl> public int readunsignedleb128 ( ) { <nl> - int number = num ; <nl> - int i = num ; <nl> + int result = num ; <nl> + int shift = num ; <nl> do { <nl> byte b = read1 ( ) ; <nl> - number | = ( b & num x7f ) < < ( 7 * i ) ; <nl> + result | = ( b & num x7f ) < < shift ; <nl> if ( ( b & num x80 ) = = num ) { <nl> break ; <nl> } <nl> - i + + ; <nl> - } while ( i < num ) ; <nl> - if ( i = = num ) { <nl> + shift + = num ; <nl> + } while ( shift < num ) ; <nl> + if ( shift = = num ) { <nl> assert . fail ( " unsigned leb128 overflow " ) ; <nl> } <nl> - return number ; <nl> + return result ; <nl> } <nl>  <nl> public int readvectorlength ( ) {
public final class context implements autocloseable { <nl>  <nl> polyglotaccess polyglotaccess = this . polylgotaccess ; <nl> if ( polyglotaccess = = null ) { <nl> - <nl> - / / polyglotaccess = this . allowallaccess ? polyglotaccess . all : polyglotaccess . none ; <nl> - polyglotaccess = polyglotaccess . all ; <nl> + polyglotaccess = this . allowallaccess ? polyglotaccess . all : polyglotaccess . none ; <nl> } <nl>  <nl> if ( localhostlookupfilter = = unset_host_lookup ) {
class virtualizertoolimpl implements virtualizertool , canonicalizertool { <nl> public boolean setvirtualentry ( virtualobjectnode virtual , int index , valuenode value , javakind theaccesskind , long offset ) { <nl> objectstate obj = state . getobjectstate ( virtual ) ; <nl> assert obj . isvirtual ( ) : " not virtual : " + obj ; <nl> - valuenode newvalue ; <nl> javakind entrykind = virtual . entrykind ( index ) ; <nl> javakind accesskind = theaccesskind ! = null ? theaccesskind : entrykind ; <nl> - if ( value = = null ) { <nl> - newvalue = null ; <nl> - } else { <nl> - newvalue = closure . getaliasandresolve ( state , value ) ; <nl> - } <nl> + valuenode newvalue = closure . getaliasandresolve ( state , value ) ; <nl> getdebug ( ) . log ( debugcontext . detailed_level , " setting entry % d in virtual object % s % s results in % s " , index , virtual . getobjectid ( ) , virtual , state . getobjectstate ( virtual . getobjectid ( ) ) ) ; <nl> valuenode oldvalue = getentry ( virtual , index ) ; <nl> boolean canvirtualize = entrykind = = accesskind | | ( entrykind = = accesskind . getstackkind ( ) & & virtual instanceof virtualinstancenode ) ; <nl> if ( ! canvirtualize ) { <nl> - <nl> + assert entrykind ! = javakind . long | | newvalue ! = null ; <nl> if ( entrykind = = javakind . long & & oldvalue . getstackkind ( ) = = newvalue . getstackkind ( ) & & oldvalue . getstackkind ( ) . isprimitive ( ) ) { <nl> / * <nl> * special case : if the entrykind is long , allow arbitrary kinds as long as a value
public class graphdecoder { <nl> registernode ( outerscope , proxyorderid , phiinput , true , false ) ; <nl> replacement = phiinput ; <nl>  <nl> - } else if ( ! merge . isphiatmerge ( existing ) ) { <nl> - / * now we have two different values , so we need to create a phi node . * / <nl> - phinode phi ; <nl> - if ( proxy instanceof valueproxynode ) { <nl> - phi = graph . addwithoutunique ( new valuephinode ( proxy . stamp ( nodeview . default ) , merge ) ) ; <nl> - } else if ( proxy instanceof guardproxynode ) { <nl> - phi = graph . addwithoutunique ( new guardphinode ( merge ) ) ; <nl> + } else { <nl> + / / fortify : suppress null dereference false positive <nl> + assert merge ! = null ; <nl> + <nl> + if ( ! merge . isphiatmerge ( existing ) ) { <nl> + / * now we have two different values , so we need to create a phi node . * / <nl> + phinode phi ; <nl> + if ( proxy instanceof valueproxynode ) { <nl> + phi = graph . addwithoutunique ( new valuephinode ( proxy . stamp ( nodeview . default ) , merge ) ) ; <nl> + } else if ( proxy instanceof guardproxynode ) { <nl> + phi = graph . addwithoutunique ( new guardphinode ( merge ) ) ; <nl> + } else { <nl> + throw graalerror . shouldnotreachhere ( ) ; <nl> + } <nl> + / * add the inputs from all previous exits . * / <nl> + for ( int j = num ; j < merge . phipredecessorcount ( ) - num ; j + + ) { <nl> + phi . addinput ( existing ) ; <nl> + } <nl> + / * add the input from this exit . * / <nl> + phi . addinput ( phiinput ) ; <nl> + registernode ( outerscope , proxyorderid , phi , true , false ) ; <nl> + replacement = phi ; <nl> + phicreated = true ; <nl> + <nl> } else { <nl> - throw graalerror . shouldnotreachhere ( ) ; <nl> - } <nl> - / * add the inputs from all previous exits . * / <nl> - for ( int j = num ; j < merge . phipredecessorcount ( ) - num ; j + + ) { <nl> - phi . addinput ( existing ) ; <nl> + / * phi node has been created before , so just add the new input . * / <nl> + phinode phi = ( phinode ) existing ; <nl> + phi . addinput ( phiinput ) ; <nl> + replacement = phi ; <nl> } <nl> - / * add the input from this exit . * / <nl> - phi . addinput ( phiinput ) ; <nl> - registernode ( outerscope , proxyorderid , phi , true , false ) ; <nl> - replacement = phi ; <nl> - phicreated = true ; <nl> - <nl> - } else { <nl> - / * phi node has been created before , so just add the new input . * / <nl> - phinode phi = ( phinode ) existing ; <nl> - phi . addinput ( phiinput ) ; <nl> - replacement = phi ; <nl> } <nl> - <nl> proxy . replaceatusagesanddelete ( replacement ) ; <nl> }
class linearscanwalker extends intervalwalker { <nl> break ; <nl> } <nl>  <nl> - <nl> + assert reg ! = null ; <nl> + <nl> boolean needsplit = blockpos [ reg . number ] < = intervalto ; <nl>  <nl> int splitpos = blockpos [ reg . number ] ;
public abstract class invokevirtualnode extends quicknode { <nl>  <nl> @ truffleboundary <nl> static method methodlookup ( staticobject receiver , int vtableindex ) { <nl> - <nl> klass clazz = receiver . getklass ( ) ; <nl> method m = clazz . lookupmethod ( vtableindex ) ; <nl> / / suprisingly , invokevirtuals can try to invoke interface methods , even non - default
import com . oracle . truffle . espresso . runtime . staticobjectimpl ; <nl>  <nl> public class mhinvokebasicnode extends espressobasenode { <nl>  <nl> - <nl> @ child basicnode node ; <nl>  <nl> public mhinvokebasicnode ( method method ) { <nl>
public final class target_java_lang_invoke_methodhandlenatives { <nl>  <nl> klass targetklass = ref . getklass ( ) ; <nl>  <nl> - <nl> if ( targetklass . gettype ( ) = = type . method ) { <nl> / / actual planting <nl> method target = method . gethostreflectivemethodroot ( ref ) ;
<nl>  <nl> # # getting started <nl>  <nl> - this tutorial provides a trace through a use - case on how to use truffle libraries . the full api documentation can be found in the [ javadoc ] ( <nl> + this tutorial provides a trace through a use - case on how to use truffle libraries . the full api documentation can be found in the [ javadoc ] ( http : / / www . graalvm . org / truffle / javadoc / com / oracle / truffle / api / library / package - summary . html ) . this document assumes prior knowledge of truffle apis and the use of ` @ specialization ` with the ` @ cached ` annotation . <nl>  <nl> # # motivating example
import com . oracle . truffle . api . library . library ; <nl> import com . oracle . truffle . api . library . libraryfactory ; <nl>  <nl> / * * <nl> - * subclasses of this class represent guest language interoperability libraries . this class is only <nl> - * a marker base class used for documentation purposes . <nl> + * represents the library that specifies the interoperability message protocol between truffle <nl> + * languages , tools and embedders . every method represents one message specified by the protocol . in <nl> + * the following text we will abbreviate interoperability with interop . <nl> * < p > <nl> - * with interop libraries only certain values are allowed to be passed . the following java types are <nl> - * allowed to be passed as receiver or argument value : <nl> + * the interop api differentiates between the source and the target language . the source language <nl> + * represents the language that implements / exports the message implementations . the implementations <nl> + * map types of the source language to the interop protocol as it is specified by the protocol . for <nl> + * example , language values that represent arrays or array like structures should implement the <nl> + * messages for { @ link # hasarrayelements ( object ) array based access } . this allows the target <nl> + * language to use / call the protocol without knowledge of the concrete source language . the target <nl> + * language embeds the interop protocol semantics as part of their existing language semantics . for <nl> + * example , language operations that access array elements in the target language should call <nl> + * { @ link # hasarrayelements ( object ) array access } messages for interop values . <nl> + * < p > <nl> + * the interop protocol only allows < i > interop values < / i > to be used as receivers , return values or <nl> + * parameters of messages . allowed java types of interop values are : <nl> * < ul > <nl> + * < li > { @ link truffleobject } : any subclass of { @ link truffleobject } is interpreted depending on the <nl> + * interop messages it { @ link exportlibrary exports } . truffle objects are expected but not required <nl> + * to export interop library messages . <nl> * < li > { @ link string } and { @ link character } are interpreted as { @ link stringlibrary # isstring ( object ) <nl> * string } value . <nl> * < li > { @ link boolean } is interpreted as { @ link booleanlibrary # isboolean ( object ) boolean } value . <nl> * < li > { @ link byte } , { @ link short } , { @ link integer } , { @ link long } , { @ link float } and { @ link double } <nl> * are interpreted as { @ link numberlibrary # isnumber ( object ) number } values . <nl> - * < li > { @ link truffleobject } : a value that optionally exports implementations of some of the interop <nl> - * libraries . any value , even if not implementing any libraries is allowed to be passed . <nl> * < / ul > <nl> + * < p > <nl> + * the interop library receiver must be an interop value . <nl> + * <nl> * values are only verified if assertions are enabled . no other values are allowed to be passed in <nl> * order to allow the introduction of new types in future revisions of interop . <nl> * < p > <nl> - * across interop libraries checked exceptions are thrown to indicate error states . the interop <nl> - * caller is supposed to catch those exceptions directly and translate them into guest language <nl> - * errors of the target language . interop errors include : <nl> - * <nl> - * <nl> + * across interop message invocations { @ link interopexception checked exceptions } are thrown to <nl> + * indicate error states . the target language is supposed to catch those exceptions directly and <nl> + * translate them into guest language errors of the target language . interop errors include : <nl> * <nl> - * < h3 > implementing < / h3 > <nl> * <nl> + * @ see com . oracle . truffle . api . library reference documentation on truffle libraries . <nl> + * @ see for a tutorial on migration from the old interop api . <nl> * @ since num . 0 <nl> * / <nl> @ generatelibrary ( assertions = asserts . class , receivertype = truffleobject . class )
<nl> - <nl> - # interop with truffle libraries <nl> - <nl> - the truffle interop api consists <nl> - <nl> - with version <nl> - <nl> - [ 1 ] link to trufflelibraries . md <nl> - <nl> - # # motivation <nl> - <nl> - the current interop apis are mature and well tested and already adopted by languages and tools . so why change it ? here is a list of problems that the current interop api suffers from which we intent to fix by migrating to truffle libraries . some of these could be solved by evolving the current api , but it would require many small changes in order to evolve it in a compatible way . <nl> - <nl> - # # # call complexity <nl> - # # # boxing <nl> - # # # extensibility <nl> - # # # manual cached dispatch <nl> - # # # uncached dispatch <nl> - # # # efficient exports / message resolution <nl> - # # # error prone <nl> - <nl> - # # usage migration <nl> - <nl> - # # # overview <nl> - <nl> - <nl> - with the changes the <nl> - it is recommended to read the documentation on truffle libraries first . <nl> - <nl> - # # # calling interop messages <nl> - <nl> - # # # exporting interop messages <nl> - <nl> - # # interface changes <nl> - <nl> - # # # booleans , strings and numbers instead of box / unbox <nl> - <nl> - the probably biggest <nl> - <nl> - # # # members namespace instead of keys <nl> - <nl> - # # # array namespace instead of has_size <nl> - <nl> - # # # tonative <nl> - <nl> - # # compatiblity <nl> - <nl> - the old interop libraries remain compatible <nl> - <nl> - there are some incompatible changes that will be <nl> - <nl> - <nl> - # # mapping <nl> - <nl> mmm a / truffle / docs / truffleinterop . md <nl> ppp / dev / null <nl>
public abstract class espressorootnode extends rootnode implements contextaccess <nl>  <nl> @ override <nl> public string getname ( ) { <nl> - <nl> - return getclass ( ) . getsimplename ( ) + " < " + getmethod ( ) . getdeclaringklass ( ) . gettype ( ) + " . " + getmethod ( ) . getname ( ) + getmethod ( ) . getrawsignature ( ) + " > " ; <nl> + return getmethod ( ) . getdeclaringklass ( ) . gettype ( ) + " . " + getmethod ( ) . getname ( ) + getmethod ( ) . getrawsignature ( ) ; <nl> } <nl> }
public final class interpretertovm implements contextaccess { <nl> @ truffleboundary <nl> public staticobject newmultiarray ( klass component , int . . . dimensions ) { <nl> meta meta = getmeta ( ) ; <nl> - <nl> - <nl> - <nl> if ( component = = meta . _void ) { <nl> throw meta . throwex ( meta . illegalargumentexception ) ; <nl> } <nl> - int finaldimensions = dimensions = = null ? num : dimensions . length ; <nl> - if ( component . isarray ( ) ) { <nl> - finaldimensions + = types . getarraydimensions ( component . gettype ( ) ) ; <nl> - } <nl> - if ( finaldimensions > num ) { <nl> - throw meta . throwex ( meta . illegalargumentexception ) ; <nl> - } <nl> for ( int d : dimensions ) { <nl> if ( d < num ) { <nl> throw meta . throwex ( meta . negativearraysizeexception ) ; <nl>
public class espressorootnode extends rootnode implements linkednode { <nl> stack . pushobject ( vm . getfieldobject ( receiver , field ) ) ; <nl> break ; <nl> default : <nl> - assert false : " unexpected kind " ; <nl> - } <nl> - } <nl> - <nl> - @ explodeloop <nl> - private static object [ ] poparguments ( operandstack stack , boolean hasreceiver , signaturedescriptor signature ) { <nl> - <nl> - int argcount = signature . getparametercount ( false ) ; <nl> - <nl> - int extraparam = hasreceiver ? num : num ; <nl> - object [ ] arguments = new object [ argcount + extraparam ] ; <nl> - <nl> - compilerasserts . partialevaluationconstant ( argcount ) ; <nl> - compilerasserts . partialevaluationconstant ( signature ) ; <nl> - compilerasserts . partialevaluationconstant ( hasreceiver ) ; <nl> - <nl> - for ( int i = argcount - num ; i > = num ; - - i ) { <nl> - javakind expectedkind = signature . getparameterkind ( i ) ; <nl> - switch ( expectedkind ) { <nl> - case boolean : <nl> - int b = stack . popint ( ) ; <nl> - assert b = = num | | b = = num ; <nl> - arguments [ i + extraparam ] = ( b ! = num ) ; <nl> - break ; <nl> - case byte : <nl> - arguments [ i + extraparam ] = ( byte ) stack . popint ( ) ; <nl> - break ; <nl> - case short : <nl> - arguments [ i + extraparam ] = ( short ) stack . popint ( ) ; <nl> - break ; <nl> - case char : <nl> - arguments [ i + extraparam ] = ( char ) stack . popint ( ) ; <nl> - break ; <nl> - case int : <nl> - arguments [ i + extraparam ] = stack . popint ( ) ; <nl> - break ; <nl> - case float : <nl> - arguments [ i + extraparam ] = stack . popfloat ( ) ; <nl> - break ; <nl> - case long : <nl> - arguments [ i + extraparam ] = stack . poplong ( ) ; <nl> - break ; <nl> - case double : <nl> - arguments [ i + extraparam ] = stack . popdouble ( ) ; <nl> - break ; <nl> - case object : <nl> - arguments [ i + extraparam ] = stack . popobject ( ) ; <nl> - break ; <nl> - case void : <nl> - case illegal : <nl> - throw espressoerror . shouldnotreachhere ( ) ; <nl> - } <nl> - } <nl> - if ( hasreceiver ) { <nl> - arguments [ 0 ] = stack . popobject ( ) ; <nl> - } <nl> - return arguments ; <nl> - } <nl> - <nl> - / / this follows bytecode types , everything < int is pushed as int . <nl> - / / the may not be spec compliant , but the spec is not soft <nl> - private static void pushkind ( operandstack stack , object returnvalue , javakind kind ) { <nl> - switch ( kind ) { <nl> - case boolean : <nl> - stack . pushint ( ( ( boolean ) returnvalue ) ? num : num ) ; <nl> - break ; <nl> - case byte : <nl> - stack . pushint ( ( byte ) returnvalue ) ; <nl> - break ; <nl> - case short : <nl> - stack . pushint ( ( short ) returnvalue ) ; <nl> - break ; <nl> - case char : <nl> - stack . pushint ( ( char ) returnvalue ) ; <nl> - break ; <nl> - case int : <nl> - stack . pushint ( ( int ) returnvalue ) ; <nl> - break ; <nl> - case float : <nl> - stack . pushfloat ( ( float ) returnvalue ) ; <nl> - break ; <nl> - case long : <nl> - stack . pushlong ( ( long ) returnvalue ) ; <nl> - break ; <nl> - case double : <nl> - stack . pushdouble ( ( double ) returnvalue ) ; <nl> - break ; <nl> - case object : <nl> - stack . pushobject ( returnvalue ) ; <nl> - break ; <nl> - case void : <nl> - / / do not push <nl> - break ; <nl> - case illegal : <nl> - throw espressoerror . shouldnotreachhere ( ) ; <nl> + compilerdirectives . transfertointerpreter ( ) ; <nl> + throw espressoerror . shouldnotreachhere ( " unexpected kind " ) ; <nl> } <nl> }
import com . oracle . truffle . espresso . runtime . staticobjectarray ; <nl>  <nl> @ espressointrinsics <nl> public class target_java_lang_system { <nl> - <nl> - @ intrinsic <nl> - public static void exit ( int status ) { <nl> - <nl> - <nl> - system . exit ( status ) ; <nl> - } <nl> - <nl> @ intrinsic <nl> public static @ type ( properties . class ) staticobject initproperties ( @ type ( properties . class ) staticobject props ) { <nl> espressocontext context = espressolanguage . getcurrentcontext ( ) ; <nl>
public class espressorootnode extends rootnode { <nl> @ override <nl> @ explodeloop ( kind = explodeloop . loopexplosionkind . merge_explode ) <nl> public object execute ( virtualframe frame ) { <nl> - <nl> int curbci = num ; <nl> - <nl> - / / slots = locals . . . + stack <nl> final operandstack stack = new dualstack ( method . getmaxstacksize ( ) ) ; <nl> initarguments ( frame ) ; <nl>  <nl>
public class espressorootnode extends rootnode { <nl> compilerdirectives . transfertointerpreter ( ) ; <nl> throw new espressoexception ( ( staticobject ) nullcheck ( stack . popobject ( ) ) ) ; <nl> case checkcast : <nl> - <nl> stack . pushobject ( checkcast ( stack . popobject ( ) , resolvetype ( bs . currentbc ( curbci ) , bs . readcpi ( curbci ) ) ) ) ; <nl> break ; <nl> case instanceof :
public final class pythonflavorprocessor implements regexflavorprocessor { <nl> * @ return { @ code true } iff a category escape was found <nl> * / <nl> private boolean categoryescape ( boolean incharclass ) { <nl> - <nl> - / / once case folding is implemented . <nl> switch ( curchar ( ) ) { <nl> case ' d ' : <nl> case ' d ' :
public class target_java_lang_system { <nl> assert dest . getclass ( ) . isarray ( ) ; <nl> system . arraycopy ( src , srcpos , dest , destpos , length ) ; <nl> } <nl> - } catch ( throwable e ) { <nl> - <nl> - throw e ; <nl> + } catch ( exception e ) { <nl> + throw espressolanguage . getcurrentcontext ( ) . getmeta ( ) . throwex ( e . getclass ( ) , e . getmessage ( ) ) ; <nl> } <nl> }
public class interpretertovm { <nl> } <nl> } <nl>  <nl> - public void setarrayobject ( object value , int index , object arr ) { <nl> - <nl> - if ( value ! = staticobject . null & & ! instanceof ( value , ( ( staticobjectarray ) arr ) . getklass ( ) . getcomponenttype ( ) ) ) { <nl> - throw espressolanguage . getcurrentcontext ( ) . getmeta ( ) . throwex ( arraystoreexception . class ) ; <nl> + public void setarrayobject ( object value , int index , staticobjectarray wrapper ) { <nl> + object [ ] array = wrapper . getwrapped ( ) ; <nl> + if ( <nl> + array [ index ] = arraystoreexcheck ( value , wrapper . getklass ( ) . getcomponenttype ( ) ) ; <nl> + } else { <nl> + throw espressolanguage . getcurrentcontext ( ) . getmeta ( ) . throwex ( arrayindexoutofboundsexception . class ) ; <nl> } <nl> - try { <nl> - ( ( staticobjectarray ) arr ) . getwrapped ( ) [ index ] = value ; <nl> - } catch ( arrayindexoutofboundsexception e ) { <nl> - throw espressolanguage . getcurrentcontext ( ) . getmeta ( ) . throwex ( arrayindexoutofboundsexception . class , e . getmessage ( ) ) ; <nl> + } <nl> + <nl> + private object arraystoreexcheck ( object value , klass componenttype ) { <nl> + if ( value = = staticobject . null | | instanceof ( value , componenttype ) ) { <nl> + return value ; <nl> + } else { <nl> + throw espressolanguage . getcurrentcontext ( ) . getmeta ( ) . throwex ( arraystoreexception . class ) ; <nl> } <nl> } <nl> + <nl> / / endregion <nl>  <nl> / / region monitor enter / exit <nl> mmm a / src / com . oracle . truffle . espresso / src / com / oracle / truffle / espresso / nodes / espressorootnode . java <nl> ppp b / src / com . oracle . truffle . espresso / src / com / oracle / truffle / espresso / nodes / espressorootnode . java <nl>
public class target_java_lang_system { <nl> " file . encoding " , <nl> " java . library . path " , <nl> " sun . boot . library . path " , <nl> - <nl> - " playground . library " <nl> + / / fixme ( peterssen ) : only needed by some tests / examples . remove once <nl> + / / dictionary - like options are merged . <nl> + " playground . library " , <nl> + " native . test . lib " <nl> } ; <nl>  <nl> meta . method . withinstance setproperty = meta ( props ) . method ( " setproperty " , object . class , string . class , string . class ) ;
import com . oracle . truffle . tools . profiler . impl . heapallocationmonitorinstrument ; <nl> import com . oracle . truffle . tools . profiler . impl . profilertoolfactory ; <nl>  <nl> / * * <nl> - * <nl> - * <nl> - * @ author tomas hurka <nl> + * implementation of a heap allocation monitor for <nl> + * { @ linkplain com . oracle . truffle . api . trufflelanguage truffle languages } built on top of the <nl> + * { @ linkplain truffleinstrument truffle instrumentation framework } . <nl> + * < p > <nl> + * the monitor tracks object allocations as reported by the language as well as the reclaiming of <nl> + * said objects by the garbage collector and offers { @ link heapallocationmonitor # snapshot api } to <nl> + * get a summary of the current state of the heap . <nl> + * <nl> + * < p > <nl> + * usage example : { @ codesnippet heapallocationmonitorsnippets # example } <nl> + * <nl> + * @ since num . 0 <nl> * / <nl> public class heapallocationmonitor implements closeable { <nl>  <nl>
import com . oracle . truffle . api . instrumentation . truffleinstrument ; <nl> import com . oracle . truffle . tools . profiler . heapallocationmonitor ; <nl>  <nl> / * * <nl> - * <nl> - * <nl> - * @ author tomas hurka <nl> + * the { @ link truffleinstrument } for the heap allocation monitor . <nl> + * <nl> + * @ since num . 0 <nl> * / <nl> @ truffleinstrument . registration ( id = heapallocationmonitorinstrument . id , name = " heap allocation monitor " , version = heapallocationmonitorinstrument . version , services = { heapallocationmonitor . class } ) <nl> public class heapallocationmonitorinstrument extends truffleinstrument {
public class substratetrufflecompiler extends trufflecompilerimpl { <nl>  <nl> @ platforms ( platform . hosted_only . class ) <nl> public substratetrufflecompiler ( trufflecompilerruntime runtime , plugins plugins , suites suites , lirsuites lirsuites , backend backend , snippetreflectionprovider snippetreflection ) { <nl> - <nl> super ( runtime , plugins , suites , lirsuites , backend , null , null , null , snippetreflection ) ; <nl> }
public final class espressolanguage extends trufflelanguage < espressocontext > { <nl>  <nl> assert context . isinitialized ( ) ; <nl>  <nl> - object classloader = null ; <nl> string classname = source . getname ( ) ; <nl> - <nl> - string classdescriptor = metautil . tointernalname ( classname ) ; <nl> - <nl> - <nl> - <nl> assert context . getappclassloader ( ) ! = null & & context . getappclassloader ( ) ! = staticobject . null ; <nl>  <nl> klass mainclass = loadmainclass ( context , launchmode . lm_class , classname ) . getmirror ( ) ; <nl>  <nl> espressoerror . guarantee ( mainclass ! = null , " error : could not find or load main class % s " , classname ) ; <nl>  <nl> - methodinfo mainmethod = mainclass . finddeclaredmethod ( " main " , void . class , string [ ] . class ) ; <nl> + meta . method mainmethod = meta . meta ( mainclass ) . method ( " main " , void . class , string [ ] . class ) ; <nl>  <nl> espressoerror . guarantee ( mainmethod ! = null , <nl> " error : main method not found in class % s , please define the main method as : \n " + <nl>
public class specializationmethodparser extends nodemethodparser < specializationd <nl> list < string > replacesdefs = new arraylist < > ( ) ; <nl> replacesdefs . addall ( elementutils . getannotationvaluelist ( string . class , specialization . getmarkerannotation ( ) , " replaces " ) ) ; <nl>  <nl> - <nl> - replacesdefs . addall ( elementutils . getannotationvaluelist ( string . class , specialization . getmarkerannotation ( ) , " contains " ) ) ; <nl> set < string > containsnames = specialization . getreplacesnames ( ) ; <nl> containsnames . clear ( ) ; <nl> if ( replacesdefs ! = null ) { <nl>
public class specializationmethodparser extends nodemethodparser < specializationd <nl> specialization . getreplacesnames ( ) . add ( include ) ; <nl> } else { <nl> annotationvalue value = elementutils . getannotationvalue ( specialization . getmarkerannotation ( ) , " replaces " ) ; <nl> - if ( value = = null ) { <nl> - <nl> - value = elementutils . getannotationvalue ( specialization . getmarkerannotation ( ) , " contains " ) ; <nl> - } <nl> specialization . adderror ( value , " duplicate replace declaration ' % s ' . " , include ) ; <nl> } <nl> }
public class valuehostconversiontest extends abstractpolyglottest { <nl> } <nl> } ) ; <nl> } <nl> - <nl> - @ override <nl> - protected object findmetaobject ( languagecontext ctx , object value ) { <nl> - <nl> - if ( value instanceof truffleobject ) { <nl> - try { <nl> - return foreignaccess . sendinvoke ( message . createinvoke ( 0 ) . createnode ( ) , ( truffleobject ) value , " getclass " ) ; <nl> - } catch ( unknownidentifierexception | unsupportedmessageexception | unsupportedtypeexception | arityexception e ) { <nl> - } <nl> - try { <nl> - object instanceclass = foreignaccess . sendread ( message . read . createnode ( ) , ( truffleobject ) value , " class " ) ; <nl> - return foreignaccess . sendinvoke ( message . createinvoke ( 0 ) . createnode ( ) , ( truffleobject ) instanceclass , " getclass " ) ; <nl> - } catch ( unknownidentifierexception | unsupportedmessageexception | unsupportedtypeexception | arityexception e ) { <nl> - } <nl> - } <nl> - return " " ; <nl> - } <nl> } ) ; <nl> return context . asvalue ( context . eval ( proxylanguage . id , clazz . getname ( ) ) ) ; <nl> }
public class space { <nl> final pointer copymemory = allocatememory ( copysize ) ; <nl> trace . string ( " copymemory : " ) . hex ( copymemory ) ; <nl> if ( copymemory . isnull ( ) ) { <nl> - / * <nl> final log failurelog = log . log ( ) . string ( " [ ! spaceimpl . copyalignedobject : " ) ; <nl> failurelog . string ( " failure to allocate " ) . unsigned ( copysize ) . string ( " bytes " ) . string ( " ! ] " ) . newline ( ) ; <nl> - return null ; <nl> + throw vmerror . shouldnotreachhere ( " promotion failure " ) ; <nl> } <nl> / * - copy the object . * / <nl> final pointer originalmemory = word . objecttountrackedpointer ( originalobj ) ;
public final class sourcesectionfilter { <nl> return b . tostring ( ) ; <nl> } <nl>  <nl> - <nl> + / * * <nl> + * checks if the filter includes the given node , i . e . do the properties of the node ' s source <nl> + * section meet the conditions set by the filter . <nl> + * <nl> + * @ param node the node to check . <nl> + * @ return true of the filter includes the node , false otherwise . <nl> + * @ since num . 0 . 0 . rc4 <nl> + * / <nl> public boolean includes ( node node ) { <nl> if ( ! instrumentationhandler . isinstrumentablenode ( node , node . getsourcesection ( ) ) ) { <nl> return false ;
<nl> - typedef int vec4 __attribute__ ( ( vector_size ( 16 ) ) ) ; <nl> - <nl> - int main ( ) { <nl> - # ifdef __clang__ <nl> - volatile vec4 v1 = { - 1 , num , num , - 5 } ; <nl> - <nl> - volatile vec4 v3 = __builtin_shufflevector ( v1 , v1 , num , num , num , num ) ; <nl> - if ( v3 [ 0 ] ! = - 5 | | v3 [ 1 ] ! = num | | v3 [ 2 ] ! = num | | v3 [ 3 ] ! = - 1 ) { <nl> - return num ; <nl> - } <nl> - <nl> - volatile vec4 v4 = __builtin_shufflevector ( v1 , v1 , num , num , num , num ) ; <nl> - if ( v4 [ 0 ] ! = - 1 | | v4 [ 1 ] ! = - 1 | | v4 [ 2 ] ! = - 1 | | v4 [ 3 ] ! = - 1 ) { <nl> - return num ; <nl> - } <nl> - # endif <nl> - return num ; <nl> - } <nl> mmm / dev / null <nl> ppp b / tests / com . oracle . truffle . llvm . tests . sulongavx / avx / avx2fallback . h <nl>
class sparksqlperfbenchmarksuite ( mx_benchmark . javabenchmarksuite , averagingbench <nl>  <nl> def run ( self , benchmarks , bmsuiteargs ) : <nl> runretval = self . runandreturnstdout ( benchmarks , bmsuiteargs ) <nl> - dims = { } <nl> - if len ( runretval ) = = num : <nl> - retcode , out , retdims = runretval <nl> - dims = retdims <nl> - self . validatestdoutwithdimensions ( <nl> - out , benchmarks , bmsuiteargs , retcode = retcode , dims = dims ) <nl> - else : <nl> - # <nl> - retcode , out = runretval <nl> - self . validatestdout ( out , benchmarks , bmsuiteargs , retcode = retcode ) <nl> + retcode , out , dims = runretval <nl> + self . validatestdoutwithdimensions ( <nl> + out , benchmarks , bmsuiteargs , retcode = retcode , dims = dims ) <nl> perf_dir = next ( file for file in os . listdir ( self . workdir + " / performance / " ) ) <nl> experiment_dir = self . workdir + " / performance / " + perf_dir + " / " <nl> results_filename = next ( file for file in os . listdir ( experiment_dir ) if file . endswith ( " json " ) ) <nl> with open ( experiment_dir + results_filename , " r " ) as results_file : <nl> - content = results_file . read ( ) <nl> + content = results_file . read ( ) <nl> results = [ ] <nl> iteration = num <nl> for part in self . decodestackedjson ( content ) : <nl> - for result in part [ " results " ] : <nl> - if " queryexecution " in result : <nl> - datapoint = { <nl> - " benchmark " : result [ " name " ] . replace ( " " , " - " ) , <nl> - " vm " : " jvmci " , <nl> - " config . name " : " default " , <nl> - " metric . name " : " warmup " , <nl> - " metric . value " : result [ " executiontime " ] , <nl> - " metric . unit " : " ms " , <nl> - " metric . type " : " numeric " , <nl> - " metric . score - function " : " id " , <nl> - " metric . better " : " lower " , <nl> - " metric . iteration " : iteration , <nl> - } <nl> - datapoint . update ( dims ) <nl> - results . append ( datapoint ) <nl> - iteration + = num <nl> + for result in part [ " results " ] : <nl> + if " queryexecution " in result : <nl> + datapoint = { <nl> + " benchmark " : result [ " name " ] . replace ( " " , " - " ) , <nl> + " vm " : " jvmci " , <nl> + " config . name " : " default " , <nl> + " metric . name " : " warmup " , <nl> + " metric . value " : result [ " executiontime " ] , <nl> + " metric . unit " : " ms " , <nl> + " metric . type " : " numeric " , <nl> + " metric . score - function " : " id " , <nl> + " metric . better " : " lower " , <nl> + " metric . iteration " : iteration , <nl> + } <nl> + datapoint . update ( dims ) <nl> + results . append ( datapoint ) <nl> + iteration + = num <nl> self . addaverageacrosslatestresults ( results ) <nl> return results <nl>  <nl>  <nl> - mx_benchmark . add_bm_suite ( sparksqlperfbenchmarksuite ( ) ) <nl> \ no newline at end of file <nl> + mx_benchmark . add_bm_suite ( sparksqlperfbenchmarksuite ( ) )
public class inlineablegraph implements inlineable { <nl> private fixednodeprobabilitycache probabilites = new fixednodeprobabilitycache ( ) ; <nl>  <nl> public inlineablegraph ( final resolvedjavamethod method , final invoke invoke , final hightiercontext context , canonicalizerphase canonicalizer , boolean tracknodesourceposition ) { <nl> - structuredgraph original = getoriginalgraph ( method , context , canonicalizer , invoke . asnode ( ) . graph ( ) , invoke . bci ( ) , tracknodesourceposition ) ; <nl> - <nl> - this . graph = ( structuredgraph ) original . copy ( invoke . asnode ( ) . getdebug ( ) ) ; <nl> - specializegraphtoarguments ( invoke , context , canonicalizer ) ; <nl> - } <nl> - <nl> - / * * <nl> - * this method looks up in a cache the graph for the argument , if not found bytecode is parsed . <nl> - * the graph thus obtained is returned , ie the caller is responsible for cloning before <nl> - * modification . <nl> - * / <nl> - private static structuredgraph getoriginalgraph ( final resolvedjavamethod method , final hightiercontext context , canonicalizerphase canonicalizer , structuredgraph caller , int callerbci , <nl> - boolean tracknodesourceposition ) { <nl> - structuredgraph result = inliningutil . getintrinsicgraph ( context . getreplacements ( ) , method , callerbci , tracknodesourceposition , null ) ; <nl> - if ( result ! = null ) { <nl> - return result ; <nl> + structuredgraph original = inliningutil . getintrinsicgraph ( context . getreplacements ( ) , method , invoke . bci ( ) , tracknodesourceposition , null ) ; <nl> + if ( original = = null ) { <nl> + original = parsebytecodes ( method , context , canonicalizer , invoke . asnode ( ) . graph ( ) , tracknodesourceposition ) ; <nl> + } else if ( original . isfrozen ( ) ) { <nl> + / / graph may be modified by specializegraphtoarguments so defensively <nl> + / / make a copy . we rely on the frozen state of a graph to denote <nl> + / / whether it is shared . <nl> + original = ( structuredgraph ) original . copy ( invoke . asnode ( ) . getdebug ( ) ) ; <nl> } <nl> - return parsebytecodes ( method , context , canonicalizer , caller , tracknodesourceposition ) ; <nl> + this . graph = original ; <nl> + specializegraphtoarguments ( invoke , context , canonicalizer ) ; <nl> } <nl>  <nl> / * *
public final class probenode extends node { <nl> int <nl> if ( <nl> / / not found . a child got replaced ? <nl> - <nl> - / / we should not continue with an out of bounds child index . <nl> - assert false ; <nl> + / / probe should have been notified about this with notifyinserted <nl> + assert throwillegalastassertion ( parentchain , parentcontext , binding , rootnode , providedtags , index ) ; <nl> return null ; <nl> } <nl> probenode probe = parent . findprobe ( ) ; <nl> return new inputvaluechainnode ( binding , probe , context , index ) ; <nl> } <nl>  <nl> + @ suppresswarnings ( " deprecation " ) <nl> + private static boolean throwillegalastassertion ( eventproviderwithinputchainnode parentchain , eventcontext parentcontext , eventbinding . source < ? > binding , rootnode rootnode , <nl> + set < class < ? > > providedtags , int index ) { <nl> + stringbuilder msg = new stringbuilder ( ) ; <nl> + try { <nl> + / / number of additional children that will be looked up from the current index <nl> + / / might not be enough depending on the violation . <nl> + final int lookupchildrencount = num ; <nl> + <nl> + sourcesection parentsourcesection = parentcontext . getinstrumentedsourcesection ( ) ; <nl> + eventcontext [ ] contexts = findchildcontexts ( binding , rootnode , providedtags , parentcontext . getinstrumentednode ( ) , parentcontext . getinstrumentedsourcesection ( ) , <nl> + math . max ( parentchain . inputcount , <nl> + <nl> + int contextcount = num ; <nl> + for ( int i = num ; i < contexts . length ; i + + ) { <nl> + eventcontext eventcontext = contexts [ i ] ; <nl> + if ( eventcontext ! = null ) { <nl> + contextcount + + ; <nl> + } <nl> + } <nl> + <nl> + msg . append ( " stable ast assumption violated . " + parentchain . inputcount + " children expected got " + contextcount ) ; <nl> + msg . append ( " \n parent : " + parentsourcesection ) ; <nl> + <nl> + for ( int i = num ; i < contexts . length ; i + + ) { <nl> + eventcontext eventcontext = contexts [ i ] ; <nl> + if ( eventcontext = = null ) { <nl> + continue ; <nl> + } <nl> + msg . append ( " \nchild [ " + i + " ] = " + eventcontext . getinstrumentedsourcesection ( ) ) ; <nl> + node node = eventcontext . getinstrumentednode ( ) ; <nl> + string indent = " " ; <nl> + while ( node ! = null ) { <nl> + msg . append ( " \n " ) ; <nl> + msg . append ( indent ) ; <nl> + if ( node = = parentcontext . getinstrumentednode ( ) ) { <nl> + msg . append ( " parent " ) ; <nl> + break ; <nl> + } <nl> + if ( node . getparent ( ) = = null ) { <nl> + msg . append ( " null parent = " ) ; <nl> + } else { <nl> + string fieldname = nodeutil . findchildfield ( node . getparent ( ) , node ) . getname ( ) ; <nl> + msg . append ( node . getparent ( ) . getclass ( ) . getsimplename ( ) + " . " + fieldname + " = " ) ; <nl> + } <nl> + <nl> + msg . append ( node . getclass ( ) . getsimplename ( ) + " # " + system . identityhashcode ( node ) ) ; <nl> + indent + = " " ; <nl> + node = node . getparent ( ) ; <nl> + } <nl> + } <nl> + <nl> + } catch ( throwable e ) { <nl> + / / if assertion computation fails we need to fallback to some simplerm essage <nl> + assertionerror error = new assertionerror ( " stable ast assumption violated " ) ; <nl> + error . addsuppressed ( e ) ; <nl> + throw error ; <nl> + } <nl> + throw new assertionerror ( msg . tostring ( ) ) ; <nl> + } <nl> + <nl> probenode . eventchainnode createeventchaincallback ( virtualframe frame , eventbinding . source < ? > binding , rootnode rootnode , set < class < ? > > providedtags , node instrumentednode , <nl> sourcesection instrumentednodesourcesection ) { <nl> probenode . eventchainnode next ;
public final class probenode extends node { <nl> int <nl> if ( <nl> / / not found . a child got replaced ? <nl> - <nl> - / / we should not continue with an out of bounds child index . <nl> - assert false ; <nl> + / / probe should have been notified about this with notifyinserted <nl> + assert throwillegalastassertion ( parentchain , parentcontext , binding , rootnode , providedtags , index ) ; <nl> return null ; <nl> } <nl> probenode probe = parent . findprobe ( ) ; <nl> return new inputvaluechainnode ( binding , probe , context , index ) ; <nl> } <nl>  <nl> + @ suppresswarnings ( " deprecation " ) <nl> + private static boolean throwillegalastassertion ( eventproviderwithinputchainnode parentchain , eventcontext parentcontext , eventbinding . source < ? > binding , rootnode rootnode , <nl> + set < class < ? > > providedtags , int index ) { <nl> + stringbuilder msg = new stringbuilder ( ) ; <nl> + try { <nl> + / / number of additional children that will be looked up from the current index <nl> + / / might not be enough depending on the violation . <nl> + final int lookupchildrencount = num ; <nl> + <nl> + sourcesection parentsourcesection = parentcontext . getinstrumentedsourcesection ( ) ; <nl> + eventcontext [ ] contexts = findchildcontexts ( binding , rootnode , providedtags , parentcontext . getinstrumentednode ( ) , parentcontext . getinstrumentedsourcesection ( ) , <nl> + math . max ( parentchain . inputcount , <nl> + <nl> + int contextcount = num ; <nl> + for ( int i = num ; i < contexts . length ; i + + ) { <nl> + eventcontext eventcontext = contexts [ i ] ; <nl> + if ( eventcontext ! = null ) { <nl> + contextcount + + ; <nl> + } <nl> + } <nl> + <nl> + msg . append ( " stable ast assumption violated . " + parentchain . inputcount + " children expected got " + contextcount ) ; <nl> + msg . append ( " \n parent : " + parentsourcesection ) ; <nl> + <nl> + for ( int i = num ; i < contexts . length ; i + + ) { <nl> + eventcontext eventcontext = contexts [ i ] ; <nl> + if ( eventcontext = = null ) { <nl> + continue ; <nl> + } <nl> + msg . append ( " \nchild [ " + i + " ] = " + eventcontext . getinstrumentedsourcesection ( ) ) ; <nl> + node node = eventcontext . getinstrumentednode ( ) ; <nl> + string indent = " " ; <nl> + while ( node ! = null ) { <nl> + msg . append ( " \n " ) ; <nl> + msg . append ( indent ) ; <nl> + if ( node = = parentcontext . getinstrumentednode ( ) ) { <nl> + msg . append ( " parent " ) ; <nl> + break ; <nl> + } <nl> + if ( node . getparent ( ) = = null ) { <nl> + msg . append ( " null parent = " ) ; <nl> + } else { <nl> + string fieldname = nodeutil . findchildfield ( node . getparent ( ) , node ) . getname ( ) ; <nl> + msg . append ( node . getparent ( ) . getclass ( ) . getsimplename ( ) + " . " + fieldname + " = " ) ; <nl> + } <nl> + <nl> + msg . append ( node . getclass ( ) . getsimplename ( ) + " # " + system . identityhashcode ( node ) ) ; <nl> + indent + = " " ; <nl> + node = node . getparent ( ) ; <nl> + } <nl> + } <nl> + <nl> + } catch ( throwable e ) { <nl> + / / if assertion computation fails we need to fallback to some simplerm essage <nl> + assertionerror error = new assertionerror ( " stable ast assumption violated " ) ; <nl> + error . addsuppressed ( e ) ; <nl> + throw error ; <nl> + } <nl> + throw new assertionerror ( msg . tostring ( ) ) ; <nl> + } <nl> + <nl> probenode . eventchainnode createeventchaincallback ( virtualframe frame , eventbinding . source < ? > binding , rootnode rootnode , set < class < ? > > providedtags , node instrumentednode , <nl> sourcesection instrumentednodesourcesection ) { <nl> probenode . eventchainnode next ;
public final class llvmmemory { <nl> } <nl>  <nl> public void free ( long address ) { <nl> - if ( address < = kernel_space_start & & address > kernel_space_end ) { <nl> - <nl> + if ( address < = deref_handle_space_start & & address > deref_handle_space_end ) { <nl> + assert isallocated ( address ) : " double - free of " + long . tohexstring ( address ) ; <nl> freelist = new freelistnode ( address , freelist ) ; <nl> } else { <nl> try { <nl>
final class macrooption { <nl> } <nl>  <nl> static macrooptionkind fromstring ( string kindname ) { <nl> - / * <nl> - string kindnamelowercase = kindname . tolowercase ( ) ; <nl> - <nl> for ( macrooptionkind kind : macrooptionkind . values ( ) ) { <nl> - if ( kind . tostring ( ) . equals ( kindnamelowercase ) ) { <nl> + if ( kind . tostring ( ) . equals ( kindname ) ) { <nl> return kind ; <nl> } <nl> }
public class valueassert { <nl> case host_object : <nl> asserttrue ( msg , value . ishostobject ( ) ) ; <nl> object hostobject = value . ashostobject ( ) ; <nl> - <nl> - / / asserttrue ( ! ( hostobject instanceof proxy ) ) ; <nl> - if ( ! value . isproxyobject ( ) ) { <nl> - if ( hostobject ! = null & & ! java . lang . reflect . proxy . isproxyclass ( hostobject . getclass ( ) ) ) { <nl> - if ( hostobject instanceof class ) { <nl> - boolean isinstanceclass = value . hasmember ( " isinterface " ) ; <nl> - if ( isinstanceclass ) { <nl> - assertclassmembers ( value , class . class , false ) ; <nl> - } else { <nl> - assertclassmembers ( value , ( class < ? > ) hostobject , true ) ; <nl> - } <nl> + assertfalse ( hostobject instanceof proxy ) ; <nl> + if ( hostobject ! = null & & ! java . lang . reflect . proxy . isproxyclass ( hostobject . getclass ( ) ) ) { <nl> + if ( hostobject instanceof class ) { <nl> + boolean isinstanceclass = value . hasmember ( " isinterface " ) ; <nl> + if ( isinstanceclass ) { <nl> + assertclassmembers ( value , class . class , false ) ; <nl> } else { <nl> - assertclassmembers ( value , hostobject . getclass ( ) , false ) ; <nl> + assertclassmembers ( value , ( class < ? > ) hostobject , true ) ; <nl> } <nl> + } else { <nl> + assertclassmembers ( value , hostobject . getclass ( ) , false ) ; <nl> } <nl> } <nl> break ; <nl>
public class valueassert { <nl> } <nl> break ; <nl> case host_object : <nl> - <nl> - if ( ! value . isproxyobject ( ) ) { <nl> - assertfalse ( value . ishostobject ( ) ) ; <nl> - assertfails ( ( ) - > value . ashostobject ( ) , classcastexception . class ) ; <nl> - } <nl> + assertfalse ( value . ishostobject ( ) ) ; <nl> + assertfails ( ( ) - > value . ashostobject ( ) , classcastexception . class ) ; <nl> break ; <nl> case proxy_object : <nl> assertfalse ( value . isproxyobject ( ) ) ; <nl>
abstract class polyglotvalue extends abstractvalueimpl { <nl>  <nl> @ override <nl> public boolean ishostobject ( object receiver ) { <nl> - <nl> - return isjava | | isproxy ; <nl> + return isjava ; <nl> } <nl>  <nl> @ override <nl>
abstract class polyglotvalue extends abstractvalueimpl { <nl>  <nl> @ override <nl> public object ashostobject ( object receiver ) { <nl> - <nl> - if ( isproxy ) { <nl> - return polyglotproxy . toproxyhostobject ( ( truffleobject ) receiver ) ; <nl> - } else if ( isjava ) { <nl> + if ( isjava ) { <nl> return vmaccessor . javainterop . ashostobject ( receiver ) ; <nl> } else { <nl> return super . ashostobject ( receiver ) ;
public class valueassert { <nl> case host_object : <nl> asserttrue ( msg , value . ishostobject ( ) ) ; <nl> object hostobject = value . ashostobject ( ) ; <nl> - <nl> - / / asserttrue ( ! ( hostobject instanceof proxy ) ) ; <nl> - if ( ! value . isproxyobject ( ) ) { <nl> - if ( hostobject ! = null & & ! java . lang . reflect . proxy . isproxyclass ( hostobject . getclass ( ) ) ) { <nl> - if ( hostobject instanceof class ) { <nl> - boolean isinstanceclass = value . hasmember ( " isinterface " ) ; <nl> - if ( isinstanceclass ) { <nl> - assertclassmembers ( value , class . class , false ) ; <nl> - } else { <nl> - assertclassmembers ( value , ( class < ? > ) hostobject , true ) ; <nl> - } <nl> + assertfalse ( hostobject instanceof proxy ) ; <nl> + if ( hostobject ! = null & & ! java . lang . reflect . proxy . isproxyclass ( hostobject . getclass ( ) ) ) { <nl> + if ( hostobject instanceof class ) { <nl> + boolean isinstanceclass = value . hasmember ( " isinterface " ) ; <nl> + if ( isinstanceclass ) { <nl> + assertclassmembers ( value , class . class , false ) ; <nl> } else { <nl> - assertclassmembers ( value , hostobject . getclass ( ) , false ) ; <nl> + assertclassmembers ( value , ( class < ? > ) hostobject , true ) ; <nl> } <nl> + } else { <nl> + assertclassmembers ( value , hostobject . getclass ( ) , false ) ; <nl> } <nl> } <nl> break ; <nl>
public class valueassert { <nl> } <nl> break ; <nl> case host_object : <nl> - <nl> - if ( ! value . isproxyobject ( ) ) { <nl> - assertfalse ( value . ishostobject ( ) ) ; <nl> - assertfails ( ( ) - > value . ashostobject ( ) , classcastexception . class ) ; <nl> - } <nl> + assertfalse ( value . ishostobject ( ) ) ; <nl> + assertfails ( ( ) - > value . ashostobject ( ) , classcastexception . class ) ; <nl> break ; <nl> case proxy_object : <nl> assertfalse ( value . isproxyobject ( ) ) ; <nl>
abstract class polyglotvalue extends abstractvalueimpl { <nl>  <nl> @ override <nl> public boolean ishostobject ( object receiver ) { <nl> - <nl> - return isjava | | isproxy ; <nl> + return isjava ; <nl> } <nl>  <nl> @ override <nl>
abstract class polyglotvalue extends abstractvalueimpl { <nl>  <nl> @ override <nl> public object ashostobject ( object receiver ) { <nl> - <nl> - if ( isproxy ) { <nl> - return polyglotproxy . toproxyhostobject ( ( truffleobject ) receiver ) ; <nl> - } else if ( isjava ) { <nl> + if ( isjava ) { <nl> return vmaccessor . javainterop . ashostobject ( receiver ) ; <nl> } else { <nl> return super . ashostobject ( receiver ) ;
class flatnodegenfactory { <nl> } <nl>  <nl> private void generatesaveoldpolymorphismstate ( codetreebuilder builder , framestate framestate ) { <nl> - <nl> builder . declaration ( state . bitsettype , old_state , state . createmaskedreference ( framestate , reachablespecializations . toarray ( ) ) ) ; <nl> if ( requiresexclude ( ) ) { <nl> builder . declaration ( exclude . bitsettype , old_exclude , " exclude " ) ;
final class trufflesplittingstrategy { <nl> return false ; <nl> } <nl> optimizedcalltarget calltarget = call . getcurrentcalltarget ( ) ; <nl> - <nl> - if ( calltarget . getnontrivialnodecount ( ) > trufflecompileroptions . getvalue ( trufflesplittingmaxcalleesize ) ) { <nl> + if ( calltarget . getuninitializednodecount ( ) > trufflecompileroptions . getvalue ( trufflesplittingmaxcalleesize ) ) { <nl> return false ; <nl> } <nl> return true ;
final class trufflesplittingstrategy { <nl> if ( calltarget . getnontrivialnodecount ( ) > trufflecompileroptions . getvalue ( trufflesplittingmaxcalleesize ) ) { <nl> return false ; <nl> } <nl> - <nl> - if ( calltarget . isvalid ( ) ) { <nl> - return false ; <nl> - } <nl> return true ; <nl> }
public abstract class node implements nodeinterface , cloneable { <nl> } <nl>  <nl> / * * <nl> - * <nl> + * notifies the runtime that this node specialized to a polymorphic state . this includes <nl> + * specializations that increase " level " of polymorphism ( e . g . adding another element to an <nl> + * existing inline cache ) . <nl> + * <nl> + * @ since num . 33 <nl> * / <nl> protected void reportpolymorphicspecialize ( ) { <nl> compilerasserts . neverpartofcompilation ( ) ;
public abstract class optimizedcalltarget implements compilabletruffleast , rootc <nl> void addknowncallnode ( optimizeddirectcallnode directcallnode ) { <nl> / / keeping all the known call sites can be too much to handle in some cases <nl> / / so we are limiting to a num call sites for now <nl> - <nl> if ( knowncallnodes . size ( ) < num ) { <nl> knowncallnodes . add ( directcallnode ) ; <nl> } <nl>
public abstract class optimizedcalltarget implements compilabletruffleast , rootc <nl> } <nl>  <nl> private void polluteprofile ( int depth , list < rootcalltarget > topollute , list < node > todump ) { <nl> - <nl> if ( depth > trufflecompileroptions . getvalue ( trufflesplittingmaxpollutiondepth ) | | profilepolluted | | knowncallnodes . size ( ) = = num | | <nl> compilationprofile . getinterpretercallcount ( ) = = num | | topollute . containsall ( arrays . aslist ( this , this ) ) ) { <nl> return ; <nl> mmm a / truffle / src / com . oracle . truffle . api . dsl / src / com / oracle / truffle / api / dsl / reportpolymorphism . java <nl> ppp b / truffle / src / com . oracle . truffle . api . dsl / src / com / oracle / truffle / api / dsl / reportpolymorphism . java <nl>
class trufflemap < k , v > extends abstractmap < k , v > { <nl> public entry < k , v > next ( ) { <nl> if ( hasnext ( ) ) { <nl> number key ; <nl> - if ( cache . keyclass = = long . class ) { <nl> - key = ( long ) index ; <nl> + if ( cache . keyclass = = integer . class ) { <nl> + key = ( int ) index ; <nl> } else { <nl> key = index ; <nl> } <nl> - <nl> index + + ; <nl> return new truffleentry ( ( k ) cache . keyclass . cast ( key ) ) ; <nl> } else { <nl> mmm a / truffle / src / com . oracle . truffle . api . test / src / com / oracle / truffle / api / test / polyglot / valueapitest . java <nl> ppp b / truffle / src / com . oracle . truffle . api . test / src / com / oracle / truffle / api / test / polyglot / valueapitest . java <nl>
public class inlininglog { <nl> public final callsite parent ; <nl> public final list < string > decisions ; <nl> public final list < callsite > children ; <nl> - public node originalinvoke ; <nl> + public invokable originalinvoke ; <nl>  <nl> - callsite ( callsite parent , node originalinvoke ) { <nl> + callsite ( callsite parent , invokable originalinvoke ) { <nl> this . parent = parent ; <nl> this . decisions = new arraylist < > ( ) ; <nl> this . children = new arraylist < > ( ) ; <nl> this . originalinvoke = originalinvoke ; <nl> } <nl> + <nl> + public callsite addchild ( invokable childinvoke ) { <nl> + callsite child = new callsite ( this , childinvoke ) ; <nl> + children . add ( child ) ; <nl> + return child ; <nl> + } <nl> } <nl>  <nl> private final callsite root ; <nl> - private final economicmap < node , callsite > leaves ; <nl> + private final economicmap < invokable , callsite > leaves ; <nl>  <nl> public inlininglog ( ) { <nl> this . root = new callsite ( null , null ) ; <nl> this . leaves = economicmap . create ( ) ; <nl> } <nl>  <nl> - public void adddecision ( boolean positive , string reason , string phase , node invoke , inlininglog calleelog ) { <nl> + public void adddecision ( invokable invoke , boolean positive , string reason , string phase , map < node , node > duplicationmap , inlininglog calleelog ) { <nl> assert leaves . containskey ( invoke ) ; <nl> - decision decision = new decision ( positive , reason , phase , getcalltarget ( invoke ) . targetmethod ( ) ) ; <nl> - } <nl> - <nl> - private calltargetnode getcalltarget ( node invoke ) { <nl> - if ( invoke instanceof invoke ) { <nl> - return ( ( invoke ) invoke ) . calltarget ( ) ; <nl> - } <nl> - <nl> - return null ; <nl> - } <nl> - <nl> - public void tracknewcallsite ( node sibling , node newinvoke ) { <nl> + decision decision = new decision ( positive , reason , phase , invoke . gettargetmethod ( ) ) ; <nl> } <nl>  <nl> - public void updatecallsite ( node previousinvoke , node newinvoke ) { <nl> + public void tracknewcallsite ( invokable sibling , invokable newinvoke ) { <nl> + callsite siblingcallsite = leaves . get ( sibling ) ; <nl> + callsite parentcallsite = siblingcallsite . parent ; <nl> + callsite callsite = parentcallsite . addchild ( newinvoke ) ; <nl> + leaves . put ( newinvoke , callsite ) ; <nl> } <nl>  <nl> - public void inlinecallsite ( node invoke , map < node , node > duplicationmap ) { <nl> + public void updatecallsite ( invokable previousinvoke , invokable newinvoke ) { <nl> + callsite callsite = leaves . get ( previousinvoke ) ; <nl> + leaves . removekey ( previousinvoke ) ; <nl> + leaves . put ( newinvoke , callsite ) ; <nl> + callsite . originalinvoke = newinvoke ; <nl> } <nl> }
public final class llvminteroptest { <nl> } <nl>  <nl> @ test <nl> - @ ignore <nl> public void testvirtualmalloccompare1 ( ) throws exception { <nl> runner runner = new runner ( " virtualmalloccompare1 " ) ; <nl> runner . load ( ) ;
class cpusamplercli extends profilercli { <nl>  <nl> @ option ( name = " " , help = " enable the cpu sampler . " , category = optioncategory . user ) static final optionkey < boolean > enabled = new optionkey < > ( false ) ; <nl>  <nl> - static final string modehelp = " describes level of sampling detail . note : increased detail can lead to reduced accuracy . modes : " + system . lineseparator ( ) + <nl> - " ' compiled ' - samples roots excluding inlined functions ( default ) " + system . lineseparator ( ) + " ' roots ' - samples roots including inlined functions " + <nl> - system . lineseparator ( ) + " ' statements ' - samples all statements . " ; <nl> - <nl> - @ option ( name = " mode " , help = " <nl> + @ option ( name = " mode " , help = " describes level of sampling detail . note : increased detail can lead to reduced accuracy . modes : ' compiled ' - samples roots excluding inlined functions ( default ) , ' roots ' - samples roots including inlined functions , ' statements ' - samples all statements . " , category = optioncategory . user ) static final optionkey < cpusampler . mode > mode = new optionkey < > ( <nl> + cpusampler . mode . compiled , cli_mode_type ) ; <nl>  <nl> @ option ( name = " period " , help = " period in milliseconds to sample the stack . " , category = optioncategory . user ) static final optionkey < long > sample_period = new optionkey < > ( 1l ) ; <nl>  <nl> @ option ( name = " delay " , help = " delay the sampling for this many milliseconds ( default : num ) . " , category = optioncategory . user ) static final optionkey < long > delay_period = new optionkey < > ( 0l ) ; <nl> + <nl> @ option ( name = " stacklimit " , help = " maximum number of maximum stack elements . " , category = optioncategory . user ) static final optionkey < integer > stack_limit = new optionkey < > ( 10000 ) ; <nl>  <nl> @ option ( name = " output " , help = " print a ' histogram ' or ' calltree ' as output ( default : histogram ) . " , category = optioncategory . user ) static final optionkey < output > output = new optionkey < > (
public final class runner { <nl>  <nl> private final nodefactory nodefactory ; <nl>  <nl> + static final class nomain implements truffleobject { <nl> + <nl> + private nomain ( ) { <nl> + } <nl> + <nl> + @ override <nl> + public foreignaccess getforeignaccess ( ) { <nl> + return nomainmessageresolutionforeign . access ; <nl> + } <nl> + } <nl> + <nl> + @ messageresolution ( receivertype = nomain . class ) <nl> + abstract static class nomainmessageresolution { <nl> + <nl> + @ resolve ( message = " is_null " ) <nl> + abstract static class isnullnode extends node { <nl> + <nl> + @ suppresswarnings ( " unused " ) <nl> + object access ( nomain boxed ) { <nl> + return true ; <nl> + } <nl> + } <nl> + <nl> + @ canresolve <nl> + abstract static class canresolvnomain extends node { <nl> + <nl> + boolean test ( truffleobject object ) { <nl> + return object instanceof nomain ; <nl> + } <nl> + } <nl> + } <nl> + <nl> public runner ( nodefactory nodefactory ) { <nl> this . nodefactory = nodefactory ; <nl> } <nl>  <nl> public calltarget parse ( llvmlanguage language , llvmcontext context , source code ) throws ioexception { <nl> try { <nl> - / * <nl> - * <nl> - * not able to link external variables which were defined in those libraries . <nl> - * / <nl> parsedynamicbitcodelibraries ( language , context ) ; <nl>  <nl> calltarget mainfunction = null ; <nl>
class polyglotsource extends abstractsourceimpl { <nl> return impl . equals ( otherimpl ) ; <nl> } <nl>  <nl> + @ suppresswarnings ( " unchecked " ) <nl> @ override <nl> - public source build ( string language , object origin , uri uri , string name , string content , boolean interactive , boolean internal ) { <nl> + public source build ( string language , object origin , uri uri , string name , charsequence content , boolean interactive , boolean internal ) throws ioexception { <nl> assert language ! = null ; <nl> com . oracle . truffle . api . source . source . builder < ? , ? , ? > builder ; <nl> boolean needsname = false ; <nl> if ( origin instanceof file ) { <nl> builder = com . oracle . truffle . api . source . source . newbuilder ( ( file ) origin ) ; <nl> } else if ( origin instanceof charsequence ) { <nl> - <nl> builder = com . oracle . truffle . api . source . source . newbuilder ( ( ( charsequence ) origin ) ) ; <nl> needsname = true ; <nl> } else if ( origin instanceof reader ) { <nl>
public abstract class launcher { <nl> } <nl>  <nl> void setgraalvmproperties ( ) { <nl> - if ( graalvm_version = = null ) { <nl> - <nl> - throw new error ( graalvm_version_property + " should have been set " ) ; <nl> - } <nl> + assert graalvm_version ! = null ; <nl> system . setproperty ( graalvm_version_property , graalvm_version ) ; <nl> - system . setproperty ( " graalvm . home " , getgraalvmhome ( ) . tostring ( ) ) ; <nl> + system . setproperty ( alt_graalvm_version_property , graalvm_version ) ; <nl> + string home = getgraalvmhome ( ) . tostring ( ) ; <nl> + system . setproperty ( " graalvm . home " , home ) ; <nl> + system . setproperty ( " org . graalvm . home " , home ) ; <nl> } <nl>  <nl> private path getgraalvmbinarypath ( string binaryname ) { <nl> mmm a / sdk / src / org . graalvm . launcher / src / org / graalvm / launcher / multilanguageshell . java <nl> ppp b / sdk / src / org . graalvm . launcher / src / org / graalvm / launcher / multilanguageshell . java <nl>
public abstract class launcher { <nl> } <nl>  <nl> private void printjvmhelp ( ) { <nl> - system . out . println ( " <nl> + system . out . print ( " jvm options : " ) ; <nl> + printoption ( " - - jvm . classpath < . . . > " , " a " + file . pathseparator + " separated list of classpath entries that will be added to the jvm ' s classpath " ) ; <nl> + printoption ( " - - jvm . d < name > = < value > " , " set a system property " ) ; <nl> + printoption ( " - - jvm . esa " , " enable system assertions " ) ; <nl> + printoption ( " - - jvm . ea [ : < packagename > . . . | : < classname > ] " , " enable assertions with specified granularity " ) ; <nl> + printoption ( " - - jvm . agentlib : < libname > [ = < options > ] " , " load native agent library < libname > " ) ; <nl> + printoption ( " - - jvm . agentpath : < pathname > [ = < options > ] " , " load native agent library by full pathname " ) ; <nl> + printoption ( " - - jvm . javaagent : < jarpath > [ = < options > ] " , " load java programming language agent " ) ; <nl> + printoption ( " - - jvm . xbootclasspath / a : < . . . > " , " a " + file . pathseparator + " separated list of classpath entries that will be added to the jvm ' s boot classpath " ) ; <nl> + printoption ( " - - jvm . xmx < size > " , " set maximum java heap size " ) ; <nl> + printoption ( " - - jvm . xms < size > " , " set initial java heap size " ) ; <nl> + printoption ( " - - jvm . xss < size > " , " set java thread stack size " ) ; <nl> } <nl>  <nl> private void printnativehelp ( ) { <nl>
final class llvmcomparisonfactory { <nl> throw new assertionerror ( llvmtype ) ; <nl> } <nl> } else if ( llvmtype instanceof vectortype & & ( ( vectortype ) llvmtype ) . getelementtype ( ) instanceof pointertype ) { <nl> - <nl> return visitaddressvectorcomparison ( left , right , condition ) ; <nl> } else { <nl> throw new assertionerror ( llvmtype ) ; <nl> mmm a / projects / com . oracle . truffle . llvm . parser / src / com / oracle / truffle / llvm / parser / listeners / types . java <nl> ppp b / projects / com . oracle . truffle . llvm . parser / src / com / oracle / truffle / llvm / parser / listeners / types . java <nl>
public abstract class llvmto80bitfloatingnode extends llvmexpressionnode { <nl>  <nl> @ specialization <nl> public llvm80bitfloat executellvm80bitfloatnode ( float from ) { <nl> - <nl> - throw new assertionerror ( from ) ; <nl> + return llvm80bitfloat . fromfloat ( from ) ; <nl> } <nl>  <nl> @ specialization <nl>
public abstract class llvmto80bitfloatingnode extends llvmexpressionnode { <nl>  <nl> @ specialization <nl> public llvm80bitfloat executellvm80bitfloatnode ( float from ) { <nl> - <nl> - throw new assertionerror ( from ) ; <nl> + return llvm80bitfloat . fromfloat ( from ) ; <nl> } <nl>  <nl> @ specialization <nl> mmm a / projects / com . oracle . truffle . llvm . runtime / src / com / oracle / truffle / llvm / runtime / floating / floathelper . java <nl> ppp b / projects / com . oracle . truffle . llvm . runtime / src / com / oracle / truffle / llvm / runtime / floating / floathelper . java <nl>
public class aarch64optimizedcalltargetinstumentationfactory extends optimizedca <nl> masm . dmb ( load_load ) ; <nl> masm . dmb ( load_store ) ; <nl> masm . cbz ( 64 , spillregister , doprolog ) ; <nl> - <nl> - if ( trufflecompiler . options . aarch64entrypointtagging . getvalue ( options ) ) { <nl> - masm . tbz ( spillregister , num , doprolog ) ; <nl> - masm . eor ( 64 , spillregister , spillregister , num ) ; <nl> - } <nl> + masm . tbz ( spillregister , num , doprolog ) ; <nl> + masm . eor ( 64 , spillregister , spillregister , num ) ; <nl> masm . jmp ( spillregister ) ; <nl> masm . nop ( ) ; <nl> masm . bind ( doprolog ) ; <nl> mmm a / compiler / src / org . graalvm . compiler . truffle / src / org / graalvm / compiler / truffle / trufflecompiler . java <nl> ppp b / compiler / src / org . graalvm . compiler . truffle / src / org / graalvm / compiler / truffle / trufflecompiler . java <nl>
public class polyglotengineprofiletest { <nl> assertequals ( store1 , get ( profile ) ) ; <nl> leave ( profile , prev ) ; <nl>  <nl> - <nl> - / / leaving for constant profiles . <nl> - / / assertnull ( get ( profile ) ) ; <nl> - assertnotnull ( get ( profile ) ) ; <nl> + assertnull ( get ( profile ) ) ; <nl>  <nl> prev = enter ( profile , store1 ) ; <nl> assertequals ( store1 , get ( profile ) ) ; <nl> mmm a / truffle / src / com . oracle . truffle . api . vm / src / com / oracle / truffle / api / vm / polyglotengineprofile . java <nl> ppp b / truffle / src / com . oracle . truffle . api . vm / src / com / oracle / truffle / api / vm / polyglotengineprofile . java <nl>
final class polyglotengineprofile { <nl> if ( constantstoreassumption . isvalid ( ) ) { <nl> / / we can skip the constantentered check in compiled code , because we are assume we are <nl> / / always entered in such cases . <nl> - <nl> - / / store = ( compilerdirectives . incompiledcode ( ) | | constantentered ) ? <nl> - / / constantstore . get ( ) : null ; <nl> - store = constantstore . get ( ) ; <nl> + store = ( compilerdirectives . incompiledcode ( ) | | constantentered ) ? constantstore . get ( ) : null ; <nl> } else if ( dynamicstoreassumption . isvalid ( ) ) { <nl> / / multiple context single thread <nl> store = dynamicstore ;
abstract class polyglotrootnode extends rootnode { <nl> engineobject . assertengine ( engine ) ; <nl> args [ i ] = engineobject . getdelegate ( ) ; <nl> } <nl> - <nl> - args [ i ] = javainterop . astrufflevalue ( args [ i ] ) ; <nl> + if ( args [ i ] ! = null & & ! isprimitivetype ( args [ i ] . getclass ( ) ) ) { <nl> + args [ i ] = javainterop . astruffleobject ( args [ i ] ) ; <nl> + } <nl> } <nl> }
public class readnode extends floatableaccessnode implements lirlowerableaccess , <nl> if ( locationidentity . equals ( array_length_location ) ) { <nl> valuenode length = graphutil . arraylength ( object ) ; <nl> if ( length ! = null ) { <nl> - <nl> return length ; <nl> } <nl> }
public enum linkage { <nl> available_externally ( " available_externally " , num l ) , <nl> linker_private ( " linker_private " , num l ) , <nl> linker_private_weak ( " linker_private_weak " , num l ) , <nl> - link_once_odr_auto_hide ( " linkonce_odr_auto_hide " , num l ) , <nl> - unknown ( " " , - 1 ) ; <nl> + link_once_odr_auto_hide ( " linkonce_odr_auto_hide " , num l ) ; <nl>  <nl> private final string irstring ; <nl>  <nl>
public enum linkage { <nl> } <nl>  <nl> public static linkage decode ( long value ) { <nl> - if ( value = = unknown . getencodedvalue ( ) ) { <nl> - <nl> - return external ; <nl> - } <nl> for ( linkage linkage : values ( ) ) { <nl> if ( linkage . getencodedvalue ( ) = = value ) { <nl> return linkage ; <nl>
public final class llvmscanner { <nl>  <nl> case abbrevrecordid . blob : <nl> operandscanners . add ( ( ) - > { <nl> - <nl> - final long bloblength = read ( primitive . user_operand_blob_length ) ; <nl> + long bloblength = read ( primitive . user_operand_blob_length ) ; <nl> + alignint ( ) ; <nl> + final long maxblobpartlength = long . size / primitive . user_operand_literal . getbits ( ) ; <nl> + while ( bloblength > num ) { <nl> + final long l = bloblength < = maxblobpartlength ? bloblength : maxblobpartlength ; <nl> + final long blobvalue = read ( ( int ) ( primitive . user_operand_literal . getbits ( ) * l ) ) ; <nl> + recordbuffer . addopwithcheck ( blobvalue ) ; <nl> + bloblength - = l ; <nl> + } <nl> alignint ( ) ; <nl> - final long blobvalue = read ( ( int ) ( primitive . user_operand_literal . getbits ( ) * bloblength ) ) ; <nl> - recordbuffer . addopwithcheck ( blobvalue ) ; <nl> } ) ; <nl> break ;
public final class lifetimeanalysissuite { <nl> return collecttestcases ( gcc_config_dir , gcc_suite_dir , gcc_lta_dir , gcc_lta_gen_dir ) ; <nl> } <nl>  <nl> - <nl> - / / see issue # 598 <nl> - / / fix issue and remove this this hard - coded ignore list . <nl> - private static final string [ ] ignore = new string [ ] { <nl> - " gcc - 5 . 2 . 0 / gcc / testsuite / g + + . dg / torture / pr49644 . c " , <nl> - " gcc - 5 . 2 . 0 / gcc / testsuite / g + + . dg / opt / nrv14 . c " , <nl> - " gcc - 5 . 2 . 0 / gcc / testsuite / g + + . dg / template / sfinae17 . c " , <nl> - " gcc - 5 . 2 . 0 / gcc / testsuite / g + + . dg / torture / pr49039 . c " , <nl> - " gcc - 5 . 2 . 0 / gcc / testsuite / g + + . dg / template / condition1 . c " , <nl> - " gcc - 5 . 2 . 0 / gcc / testsuite / g + + . dg / torture / pr37922 . c " , <nl> - " gcc - 5 . 2 . 0 / gcc / testsuite / g + + . dg / opt / pr6713 . c " , <nl> - " gcc - 5 . 2 . 0 / gcc / testsuite / g + + . dg / torture / pr42462 . c " , <nl> - " gcc - 5 . 2 . 0 / gcc / testsuite / g + + . dg / opt / pr36187 . c " , <nl> - " gcc - 5 . 2 . 0 / gcc / testsuite / g + + . dg / torture / pr40924 . c " , <nl> - " gcc - 5 . 2 . 0 / gcc / testsuite / g + + . dg / opt / nrv6 . c " , <nl> - " gcc - 5 . 2 . 0 / gcc / testsuite / g + + . dg / opt / pr16372 - 1 . c " , <nl> - " gcc - 5 . 2 . 0 / gcc / testsuite / g + + . dg / opt / expect1 . c " , <nl> - " gcc - 5 . 2 . 0 / gcc / testsuite / g + + . dg / template / array25 . c " , <nl> - " gcc - 5 . 2 . 0 / gcc / testsuite / g + + . dg / torture / pr40335 . c " , <nl> - " gcc - 5 . 2 . 0 / gcc / testsuite / g + + . dg / torture / pr44069 . c " , <nl> - " gcc - 5 . 2 . 0 / gcc / testsuite / g + + . dg / opt / range - test - 2 . c " , <nl> - " gcc - 5 . 2 . 0 / gcc / testsuite / g + + . dg / template / partial10 . c " , <nl> - " gcc - 5 . 2 . 0 / gcc / testsuite / g + + . dg / opt / pr7503 - 1 . c " , <nl> - " gcc - 5 . 2 . 0 / gcc / testsuite / g + + . dg / opt / cond1 . c " , <nl> - " gcc - 5 . 2 . 0 / gcc / testsuite / g + + . dg / torture / pr56837 . c " , <nl> - " gcc - 5 . 2 . 0 / gcc / testsuite / g + + . dg / torture / pr30567 . c " , <nl> - " gcc - 5 . 2 . 0 / gcc / testsuite / g + + . dg / torture / pr50189 . c " , <nl> - " gcc - 5 . 2 . 0 / gcc / testsuite / g + + . dg / opt / strength - reduce . c " , <nl> - " gcc - 5 . 2 . 0 / gcc / testsuite / g + + . dg / opt / range - test - 1 . c " , <nl> - " gcc - 5 . 2 . 0 / gcc / testsuite / g + + . dg / torture / pr35634 . c " , <nl> - " gcc - 5 . 2 . 0 / gcc / testsuite / g + + . dg / torture / pr59163 . c " , <nl> - " gcc - 5 . 2 . 0 / gcc / testsuite / g + + . dg / torture / 20100825 . c " , <nl> - " gcc - 5 . 2 . 0 / gcc / testsuite / g + + . dg / opt / fold2 . c " , <nl> - " gcc - 5 . 2 . 0 / gcc / testsuite / g + + . dg / opt / pr14029 . c " , <nl> - " gcc - 5 . 2 . 0 / gcc / testsuite / g + + . dg / opt / dtor4 . c " , <nl> - " gcc - 5 . 2 . 0 / gcc / testsuite / g + + . dg / opt / dtor1 . c " , <nl> - " gcc - 5 . 2 . 0 / gcc / testsuite / g + + . dg / template / explicit - args4 . c " , <nl> - " gcc - 5 . 2 . 0 / gcc / testsuite / g + + . dg / template / repo9 . c " , <nl> - " gcc - 5 . 2 . 0 / gcc / testsuite / g + + . dg / opt / nrv13 . c " , <nl> - " gcc - 5 . 2 . 0 / gcc / testsuite / g + + . dg / opt / bool1 . c " , <nl> - " gcc - 5 . 2 . 0 / gcc / testsuite / g + + . dg / opt / pr30590 . c " , <nl> - " gcc - 5 . 2 . 0 / gcc / testsuite / g + + . dg / torture / pr37146 - 2 . c " , <nl> - " gcc - 5 . 2 . 0 / gcc / testsuite / gfortran . fortran - torture / execute / integer_select . f90 " , <nl> - " gcc - 5 . 2 . 0 / gcc / testsuite / g + + . dg / template / pretty1 . c " , <nl> - " gcc - 5 . 2 . 0 / gcc / testsuite / gfortran . fortran - torture / execute / transfer2 . f90 " } ; <nl> - private final list < string > ignorelist = arrays . aslist ( ignore ) ; <nl> - <nl> @ test <nl> public void test ( ) throws exception { <nl> try { <nl> - if ( ignorelist . contains ( testname ) ) { <nl> - return ; <nl> - } <nl> lifetimeanalysistest . test ( bcfile , ltafile , ltagenfile ) ; <nl> } catch ( throwable e ) { <nl> throw new assertionerror ( e ) ;
def mdlcheck ( args = none ) : <nl> if error : <nl> exit ( - 1 ) <nl>  <nl> - def getbitcodelibrariesoption ( ) : <nl> + def getbitcodelibrariesoption ( * args ) : <nl> libraries = [ ] <nl> if ' sulong_no_library ' not in os . environ : <nl> - for path , _ , files in os . walk ( _libpath ) : <nl> + libpath = join ( mx . project ( ' com . oracle . truffle . llvm . libraries ' ) . getoutput ( ) , ' bin ' ) <nl> + for path , _ , files in os . walk ( libpath ) : <nl> for f in files : <nl> - # <nl> - if f . endswith ( ' . c ' ) : <nl> - bitcodefile = f . rsplit ( " . " , num ) [ 0 ] + ' . bc ' <nl> - absbitcodefile = path + ' / ' + bitcodefile <nl> - if not os . path . isfile ( absbitcodefile ) : <nl> - compilewithclangopt ( path + ' / ' + f , absbitcodefile ) <nl> - libraries . append ( absbitcodefile ) <nl> + if f . endswith ( ' . bc ' ) : <nl> + libraries . append ( join ( path , f ) ) <nl> return [ ' - dsulong . dynamicbitcodelibraries = ' + ' : ' . join ( libraries ) ] if libraries else [ ] <nl>  <nl> def clangformatcheck ( args = none ) : <nl> mmm a / mx . sulong / suite . py <nl> ppp b / mx . sulong / suite . py <nl>
public final class javainterop { <nl> if ( ! type . isinterface ( ) | | type = = truffleobject . class ) { <nl> return false ; <nl> } <nl> - for ( annotation annotation : type . getannotations ( ) ) { <nl> - <nl> - / / fix once truffle uses jdk8 <nl> - if ( annotation . tostring ( ) . equals ( " @ java . lang . functionalinterface ( ) " ) ) { <nl> - return true ; <nl> - } <nl> - } <nl> - if ( type . getmethods ( ) . length = = num ) { <nl> + if ( type . getannotation ( functionalinterface . class ) ! = null ) { <nl> return true ; <nl> } <nl> - return false ; <nl> + return type . getmethods ( ) . length = = num ; <nl> } <nl>  <nl> }
import jdk . vm . ci . meta . platformkind ; <nl> import jdk . vm . ci . meta . value ; <nl>  <nl> / * * <nl> - * <nl> + * allocates registers within a trace in a greedy , bottom - up fashion . the liveness information is <nl> + * computed on the fly as the instructions are traversed . a separate liveness information is not <nl> + * required . the goal of this allocator is to provide a simple and fast algorithm for situations <nl> + * where code quality is not the primary target . <nl> * <nl> + * this implementation does not ( yet ) exploit hinting information and might introduce multiple spill <nl> + * moves to the same stack slot ( which are likely to be remove by { @ link redundantmoveelimination } . <nl> + * <nl> + * the current implementation cannot deal with { @ link abstractblockbase blocks } with edges to <nl> + * compiled exception handlers since it might introduce spill code after the { @ link lirinstruction <nl> + * instruction } that triggers the exception . <nl> * / <nl> public final class bottomupallocator extends traceallocationphase < traceallocationcontext > { <nl> private final targetdescription target ;
public class metadata implements parserlistener { <nl> enumerator node = new enumerator ( ) ; <nl>  <nl> / / long distinct = args [ 0 ] ; <nl> - node . setvalue ( args [ 1 ] ) ; <nl> + node . setvalue ( unrotatesign ( args [ 1 ] ) ) ; <nl> node . setname ( metadata . getreference ( args [ 2 ] ) ) ; <nl>  <nl> metadata . add ( node ) ;
public class llvm { <nl> mainfunction [ 0 ] = parserresult . getmainfunction ( ) ; <nl> handleparserresult ( context , parserresult ) ; <nl> } else if ( code . getmimetype ( ) . equals ( llvmlanguage . llvm_bitcode_mime_type ) ) { <nl> - <nl> + list < string > resolvedvariables = getallresolvedglobalvariables ( code ) ; <nl> + context . setresolvedvariablenames ( resolvedvariables ) ; <nl> llvmparserresult parserresult = parsebitcodefile ( code , context ) ; <nl> mainfunction [ 0 ] = parserresult . getmainfunction ( ) ; <nl> handleparserresult ( context , parserresult ) ;
public final class suspendedevent { <nl> debugger . preparestepover ( stepcount ) ; <nl> } <nl>  <nl> - <nl> / * * <nl> * evaluates given code snippet in the context of currently suspended execution . <nl> * <nl> * @ param code the snippet to evaluate <nl> - * @ param frame the frame in which to evaluate the code ; { means the current frame at the halted <nl> - * location . <nl> + * @ param frame the frame in which to evaluate the code ; { @ code null } means the current frame at <nl> + * the halted location . <nl> * @ return the computed value <nl> * @ throws ioexception in case an evaluation goes wrong <nl> * @ throws killexception if the evaluation is killed by the debugger
public final class debugger { <nl> / * * counter for externally requested step actions . * / <nl> private static int nextactionid = num ; <nl>  <nl> - <nl> / * * <nl> * describes where an execution is halted relative to the instrumented node . <nl> * / <nl>
public abstract class llvmtofunctionnode extends llvmfunctionnode { <nl>  <nl> @ specialization <nl> public llvmfunctiondescriptor executei64 ( llvmaddress from ) { <nl> - <nl> - throw new assertionerror ( from ) ; <nl> + return llvmfunctiondescriptor . create ( ( int ) from . getval ( ) ) ; <nl> } <nl> }
public abstract class llvmtofunctionnode extends llvmfunctionnode { <nl>  <nl> @ specialization <nl> public llvmfunctiondescriptor executei64 ( long from ) { <nl> - <nl> - throw new assertionerror ( from ) ; <nl> + return llvmfunctiondescriptor . create ( ( int ) from ) ; <nl> } <nl> }
package com . oracle . graal . microbenchmarks . lir . trace ; <nl> import org . openjdk . jmh . annotations . level ; <nl> import org . openjdk . jmh . annotations . setup ; <nl>  <nl> + import com . oracle . graal . lir . lir ; <nl> import com . oracle . graal . microbenchmarks . lir . graalcompilerstate ; <nl> import com . oracle . graal . nodes . cfg . controlflowgraph ; <nl>  <nl> / * * <nl> - * <nl> - * <nl> + * state class for working with { @ link controlflowgraph } and { @ link lir } . <nl> * / <nl> public abstract class controlflowgraphstate extends graalcompilerstate { <nl>  <nl>
public final class llvmlanguage extends trufflelanguage < llvmcontext > { <nl> throw new assertionerror ( ) ; <nl> } <nl>  <nl> - @ suppresswarnings ( " deprecation " ) <nl> - @ override <nl> - protected visualizer getvisualizer ( ) { <nl> - <nl> - return null ; <nl> - } <nl> - <nl> }
final class tracelinearscanlifetimeanalysisphase extends tracelinearscanallocati <nl>  <nl> list < lirinstruction > instructions = allocator . getlir ( ) . getlirforblock ( block ) ; <nl>  <nl> - / / number first instruction in the block as it is needed <nl> - <nl> - numberinstruction ( block , instructions . get ( 0 ) , instructionindex - instructions . size ( ) ) ; <nl> / * <nl> * iterate all instructions of the block in reverse order . definitions of <nl> * intervals are processed before uses .
public class nullabilitytest { <nl> assert . assertequals ( " baz " , layout . getnotnullable ( object ) ) ; <nl> } <nl>  <nl> - @ test <nl> - public void testsetnonnullabletonull ( ) { <nl> - <nl> - final dynamicobject object = layout . createnullabilitytest ( " foo " , " bar " ) ; <nl> - assert . assertnotnull ( object ) ; <nl> - assert . assertequals ( " foo " , layout . getnotnullable ( object ) ) ; <nl> - layout . setnotnullable ( object , null ) ; <nl> - } <nl> - <nl> @ test <nl> public void testsetnullabletonull ( ) { <nl> final dynamicobject object = layout . createnullabilitytest ( " foo " , " bar " ) ;
public class defaultlooppolicies implements looppolicies { <nl> @ option ( help = " " , type = optiontype . expert ) public static final optionvalue < integer > fullunrollmaxiterations = new optionvalue < > ( 600 ) ; <nl> @ option ( help = " " , type = optiontype . expert ) public static final optionvalue < integer > exactfullunrollmaxnodes = new optionvalue < > ( 1200 ) ; <nl>  <nl> - <nl> @ override <nl> public boolean shouldpeel ( loopex loop , controlflowgraph cfg ) { <nl> - if ( loop . detectcounted ( ) ) { <nl> - return false ; <nl> - } <nl> loopbeginnode loopbegin = loop . loopbegin ( ) ; <nl> double entryprobability = cfg . blockfor ( loopbegin . forwardend ( ) ) . probability ( ) ; <nl> if ( entryprobability > minimumpeelprobability . getvalue ( ) & & loop . size ( ) + loopbegin . graph ( ) . getnodecount ( ) < maximumdesiredsize . getvalue ( ) ) {
public final class sllanguage extends trufflelanguage < slcontext > { <nl> public slcontext findcontext0 ( node contextnode ) { <nl> return findcontext ( contextnode ) ; <nl> } <nl> - <nl> - <nl> - private static void setuptooldemos ( ) { <nl> - / / if ( nodeexeccounts ) { <nl> - / / nodeexeccounter = new nodeexeccounter ( ) ; <nl> - / / nodeexeccounter . install ( ) ; <nl> - / / } <nl> - / / <nl> - / / if ( statementcounts ) { <nl> - / / statementexeccounter = new nodeexeccounter ( standardsyntaxtag . statement ) ; <nl> - / / statementexeccounter . install ( ) ; <nl> - / / } <nl> - / / <nl> - / / if ( coverage ) { <nl> - / / coveragetracker = new coveragetracker ( ) ; <nl> - / / coveragetracker . install ( ) ; <nl> - / / } <nl> - } <nl> - <nl> - private static void reporttooldemos ( ) { <nl> - / / if ( nodeexeccounter ! = null ) { <nl> - / / nodeexeccounter . print ( system . out ) ; <nl> - / / nodeexeccounter . dispose ( ) ; <nl> - / / } <nl> - / / if ( statementexeccounter ! = null ) { <nl> - / / statementexeccounter . print ( system . out ) ; <nl> - / / statementexeccounter . dispose ( ) ; <nl> - / / } <nl> - / / if ( coveragetracker ! = null ) { <nl> - / / coveragetracker . print ( system . out ) ; <nl> - / / coveragetracker . dispose ( ) ; <nl> - / / } <nl> - } <nl> - <nl> }
<nl> - / * <nl> - * copyright ( c ) num , oracle and / or its affiliates . all rights reserved . <nl> - * do not alter or remove copyright notices or this file header . <nl> - * <nl> - * this code is free software ; you can redistribute it and / or modify it <nl> - * under the terms of the gnu general public license version num only , as <nl> - * published by the free software foundation . oracle designates this <nl> - * particular file as subject to the " classpath " exception as provided <nl> - * by oracle in the license file that accompanied this code . <nl> - * <nl> - * this code is distributed in the hope that it will be useful , but without <nl> - * any warranty ; without even the implied warranty of merchantability or <nl> - * fitness for a particular purpose . see the gnu general public license <nl> - * version num for more details ( a copy is included in the license file that <nl> - * accompanied this code ) . <nl> - * <nl> - * you should have received a copy of the gnu general public license version <nl> - * num along with this work ; if not , write to the free software foundation , <nl> - * inc . , num franklin st , fifth floor , boston , ma num - 1301 usa . <nl> - * <nl> - * please contact oracle , num oracle parkway , redwood shores , ca num usa <nl> - * or visit www . oracle . com if you need additional information or have any <nl> - * questions . <nl> - * / <nl> - package com . oracle . truffle . api . script ; <nl> - <nl> - import javax . script . scriptengine ; <nl> - import javax . script . scriptenginefactory ; <nl> - <nl> - @ deprecated <nl> - / * * <nl> - * tool access to the creation of truffle execution engines . <nl> - * @ deprecated no longer needed and will be removed <nl> - * / <nl> - public abstract class trufflescriptenginefactory implements scriptenginefactory { <nl> - <nl> - <nl> - / * * <nl> - * to be called by each concrete factory just after each engine instance is created , presenting <nl> - * an opportunity for an ide to interrupt in a language - independent way . <nl> - * <nl> - * @ param engine a just - created engine <nl> - * / <nl> - protected final void enginecreated ( scriptengine engine ) { <nl> - } <nl> - <nl> - } <nl> mmm a / truffle / com . oracle . truffle . api / src / com / oracle / truffle / api / script / package - info . java <nl> ppp / dev / null <nl>
public final class sllanguage extends trufflelanguage < slcontext > { <nl> return context ; <nl> } <nl>  <nl> - <nl> - / * enables demonstration of per - type tabulation of node execution counts * / <nl> - private static boolean nodeexeccounts = false ; <nl> - / * enables demonstration of per - line tabulation of statement node execution counts * / <nl> - private static boolean statementcounts = false ; <nl> - / * enables demonstration of per - line tabulation of statement coverage * / <nl> - private static boolean coverage = false ; <nl> - <nl> / * small tools that can be installed for demonstration * / <nl> / / private static nodeexeccounter nodeexeccounter = null ; <nl> / / private static nodeexeccounter statementexeccounter = null ;
final class tracelinearscanwalker extends traceintervalwalker { <nl> } <nl>  <nl> / / safety check that there is really no register available <nl> - <nl> - / / assert ! allocfreeregister ( interval ) : " found a register for this interval " ; <nl> + assert ! allocfreeregister ( interval ) : " found a register for this interval " ; <nl> return true ; <nl> } <nl> }
final class shadowedregistervalue extends compositevalue { <nl> } <nl>  <nl> @ override <nl> - public value foreachcomponent ( lirinstruction inst , operandmode mode , instructionvalueprocedure proc ) { <nl> - / * <nl> - return proc . dovalue ( inst , this , mode , flags ) ; <nl> + public compositevalue foreachcomponent ( lirinstruction inst , operandmode mode , instructionvalueprocedure proc ) { <nl> + registervalue newregister = ( registervalue ) proc . dovalue ( inst , register , mode , registerflags ) ; <nl> + stackslotvalue newstackslot = ( stackslotvalue ) proc . dovalue ( inst , stackslot , mode , stackslotflags ) ; <nl> + if ( register . equals ( newregister ) | | stackslot . equals ( newstackslot ) ) { <nl> + return this ; <nl> + } <nl> + return new shadowedregistervalue ( newregister , newstackslot ) ; <nl> } <nl>  <nl> @ override
import com . oracle . graal . lir . standardop . blockendop ; <nl> import com . oracle . graal . lir . alloc . lsra . * ; <nl>  <nl> / * * <nl> - * <nl> + * specialization of { @ link linearscanassignlocationsphase } that inserts <nl> + * { @ link shadowedregistervalue } s to describe { @ link registervalue } s that are also available on the <nl> + * { @ link stackslotvalue stack } . <nl> * / <nl> class tracelinearscanassignlocationsphase extends linearscanassignlocationsphase {
public class sparcloadconstanttablebaseop extends sparclirinstruction { <nl> @ override <nl> public void emitcode ( compilationresultbuilder crb , sparcmacroassembler masm ) { <nl> register baseregister = asregister ( base ) ; <nl> - datasectionreference ref = new datasectionreference ( ) ; <nl> - ref . setoffset ( 0 ) ; <nl> - crb . compilationresult . recorddatapatch ( masm . position ( ) , ref ) ; <nl> - <nl> - new sparcmacroassembler . setx ( 0 , baseregister , true ) . emit ( masm ) ; <nl> - / * * <nl> - * place the base register into the center of the reachable num k range . this bias is reflected <nl> - * in codeinstaller : : pd_patch_datasectionreference ( jvmcicodeinstaller_sparc . cpp ) <nl> - * / <nl> - masm . sub ( baseregister , - 1 & ~ ( ( 1 < < num ) - num ) , baseregister ) ; <nl> + int beforeposition = masm . position ( ) ; <nl> + masm . rdpc ( baseregister ) ; <nl> + masm . sub ( baseregister , beforeposition , baseregister ) ; <nl> } <nl>  <nl> public allocatablevalue getresult ( ) {
public class amd64hotspotlirgenerator extends amd64lirgenerator implements hotsp <nl> } <nl>  <nl> variable result ; <nl> - <nl> lirframestate deoptinfo = null ; <nl> if ( hotspotlinkage . candeoptimize ( ) ) { <nl> deoptinfo = state ; <nl> mmm a / graal / com . oracle . graal . hotspot . sparc / src / com / oracle / graal / hotspot / sparc / sparchotspotlirgenerator . java <nl> ppp b / graal / com . oracle . graal . hotspot . sparc / src / com / oracle / graal / hotspot / sparc / sparchotspotlirgenerator . java <nl>
public class sparchotspotlirgenerator extends sparclirgenerator implements hotsp <nl> public variable emitforeigncall ( foreigncalllinkage linkage , lirframestate state , value . . . args ) { <nl> hotspotforeigncalllinkage hotspotlinkage = ( hotspotforeigncalllinkage ) linkage ; <nl> variable result ; <nl> - <nl> lirframestate deoptinfo = null ; <nl> if ( hotspotlinkage . candeoptimize ( ) ) { <nl> deoptinfo = state ;
final class ssaverifier { <nl> visited . set ( block . getid ( ) ) ; <nl> for ( lirinstruction op : lir . getlirforblock ( block ) ) { <nl> op . visiteachalive ( this : : useconsumer ) ; <nl> - / * <nl> - * <nl> - * eliminated stacklockvalue . ( the slot is not defined but we can ' t tell that the lock <nl> - * is eliminated . ) <nl> - * / <nl> - / / op . visiteachstate ( this : : useconsumer ) ; <nl> + op . visiteachstate ( this : : useconsumer ) ; <nl> op . visiteachinput ( this : : useconsumer ) ; <nl>  <nl> op . visiteachtemp ( this : : defconsumer ) ; <nl>
public class loopex { <nl> private final loop < block > loop ; <nl> private loopfragmentinside inside ; <nl> private loopfragmentwhole whole ; <nl> - private countedloopinfo counted ; <nl> + private countedloopinfo counted ; <nl> private loopsdata data ; <nl> private map < node , inductionvariable > ivs ; <nl>  <nl>
public class inliningutil { <nl> if ( calltarget . targetmethod ( ) = = null ) { <nl> return " target method is null " ; <nl> } <nl> - if ( invoke . stateafter ( ) = = null ) { <nl> - <nl> - return " the invoke has no after state " ; <nl> - } <nl> + assert invoke . stateafter ( ) ! = null ; <nl> if ( ! invoke . useforinlining ( ) ) { <nl> return " the invoke is marked to be not used for inlining " ; <nl> }
public class sparchotspotbackendfactory implements hotspotbackendfactory { <nl>  <nl> @ suppresswarnings ( " unused " ) <nl> private static value [ ] createnativeabicallersaveregisters ( hotspotvmconfig config , registerconfig regconfig ) { <nl> - list < register > callersaveregisters = new arraylist < > ( ) ; <nl> - collections . addall ( callersaveregisters , regconfig . getcallersaveregisters ( ) ) ; <nl> - <nl> - / / not work without ; needs further investigation <nl> - collections . addall ( callersaveregisters , regconfig . getcalleesavelayout ( ) . registers ) ; <nl> - value [ ] nativeabicallersaveregisters = new value [ callersaveregisters . size ( ) ] ; <nl> - for ( int i = num ; i < callersaveregisters . size ( ) ; i + + ) { <nl> - nativeabicallersaveregisters [ i ] = callersaveregisters . get ( i ) . asvalue ( ) ; <nl> + set < register > callersavedregisters = new hashset < > ( ) ; <nl> + collections . addall ( callersavedregisters , regconfig . getcalleesavelayout ( ) . registers ) ; <nl> + collections . addall ( callersavedregisters , sparc . fpuregisters ) ; <nl> + value [ ] nativeabicallersaveregisters = new value [ callersavedregisters . size ( ) ] ; <nl> + int i = num ; <nl> + for ( register reg : callersavedregisters ) { <nl> + nativeabicallersaveregisters [ i ] = reg . asvalue ( ) ; <nl> + i + + ; <nl> } <nl> return nativeabicallersaveregisters ; <nl> }
public class graphbuilderphase extends basephase < hightiercontext > { <nl> currentblock = blockmap . startblock ; <nl> blockmap . startblock . entrystate = framestate ; <nl> if ( blockmap . startblock . isloopheader ) { <nl> - / * <nl> - * <nl> - * since it expects currentblock , etc . to be set up correctly . a better <nl> - * solution to this problem of start blocks that are loop headers would be <nl> - * to create a dummy block in bciblockmapping . <nl> - * / <nl> appendgoto ( createtarget ( blockmap . startblock , framestate ) ) ; <nl> } else { <nl> blockmap . startblock . firstinstruction = lastinstr ;
import com . oracle . truffle . api . frame . * ; <nl> * / <nl> public abstract class loopnode extends node { <nl>  <nl> - / * <nl> - * <nl> - * / <nl> - @ child protected node repeatingnode ; <nl> + @ child protected repeatingnode repeatingnode ; <nl>  <nl> public loopnode ( repeatingnode repeatingnode ) { <nl> - this . repeatingnode = ( node ) repeatingnode ; <nl> + this . repeatingnode = repeatingnode ; <nl> } <nl>  <nl> public abstract void executeloop ( virtualframe frame ) ; <nl>
<nl> - / * <nl> - * copyright ( c ) num , num , oracle and / or its affiliates . all rights reserved . <nl> - * do not alter or remove copyright notices or this file header . <nl> - * <nl> - * this code is free software ; you can redistribute it and / or modify it <nl> - * under the terms of the gnu general public license version num only , as <nl> - * published by the free software foundation . <nl> - * <nl> - * this code is distributed in the hope that it will be useful , but without <nl> - * any warranty ; without even the implied warranty of merchantability or <nl> - * fitness for a particular purpose . see the gnu general public license <nl> - * version num for more details ( a copy is included in the license file that <nl> - * accompanied this code ) . <nl> - * <nl> - * you should have received a copy of the gnu general public license version <nl> - * num along with this work ; if not , write to the free software foundation , <nl> - * inc . , num franklin st , fifth floor , boston , ma num - 1301 usa . <nl> - * <nl> - * please contact oracle , num oracle parkway , redwood shores , ca num usa <nl> - * or visit www . oracle . com if you need additional information or have any <nl> - * questions . <nl> - * / <nl> - / * * <nl> - * < p > this package contains basic tests of the truffle - source - code - generation ( short codegen ) api and serves at the same <nl> - * time as an introduction to the codegen api for language implementors . every test gives an example on how to use the construct explained in the class description . < / p > <nl> - * <nl> - * < p > <nl> - * this api relies heavily on the concepts described in com . oracle . truffle . api . test . we assume that the <nl> - * reader is already familiarized with those concepts . <nl> - * < / p > <nl> - * <nl> - * < p > <nl> - * <nl> - * < / p > <nl> - * <nl> - * < p > <nl> - * this introduction to codegen contains items in the following recommended order : <nl> - * <nl> - * prerequisites : <nl> - * <nl> - * <nl> - * < ul > <nl> - * < li > what do i need to get started ? { @ link com . oracle . truffle . api . dsl . test . typesystemtest } < / li > <nl> - * < / ul > <nl> - * <nl> - * / <nl> - package com . oracle . truffle . api . dsl . test ; <nl> -
public class methodcalltargetnode extends calltargetnode implements iterablenode <nl> } <nl> } <nl> resolvedjavatype declaredreceivertype = targetmethod ( ) . getdeclaringclass ( ) ; <nl> - if ( declaredreceivertype . isinterface ( ) ) { <nl> + / * <nl> + * we need to check the invoke kind to avoid recursive simplification for default <nl> + * methods calls . <nl> + * / <nl> + if ( declaredreceivertype . isinterface ( ) & & ! invokekind ( ) . equals ( invokekind . virtual ) ) { <nl> resolvedjavatype singleimplementor = declaredreceivertype . getsingleimplementor ( ) ; <nl> if ( singleimplementor ! = null & & ! singleimplementor . equals ( declaredreceivertype ) ) { <nl> resolvedjavamethod singleimplementormethod = singleimplementor . resolvemethod ( targetmethod ( ) , invoke ( ) . getcontexttype ( ) , true ) ; <nl> - <nl> - if ( singleimplementormethod ! = null & & ! singleimplementormethod . isdefault ( ) ) { <nl> + if ( singleimplementormethod ! = null ) { <nl> logicnode condition = graph ( ) . unique ( instanceofnode . create ( singleimplementor , receiver , getprofile ( ) ) ) ; <nl> assert graph ( ) . getguardsstage ( ) . ordinal ( ) < structuredgraph . guardsstage . fixed_deopts . ordinal ( ) : " graph already fixed ! " ; <nl> guardnode guard = graph ( ) . unique (
public class nodeparser extends abstractparser < nodedata > { <nl> specializationdata next = i + num < specializations . size ( ) ? specializations . get ( i + num ) : null ; <nl>  <nl> if ( ! cur . iscontainedby ( next ) ) { <nl> - / / error should be able to contain <nl> next . adderror ( " this specialiation is not a valid exceptional rewrite target for % s . to fix this make % s compatible to % s or remove the exceptional rewrite . " , <nl> - cur . createreferencename ( ) , next . createreferencename ( ) , cur . createreferencename ( ) ) ; <nl> + cur . createreferencename ( ) , next ! = null ? next . createreferencename ( ) : " - " , cur . createreferencename ( ) ) ; <nl> continue ; <nl> } <nl> - if ( ! next . getcontains ( ) . contains ( cur ) ) { <nl> - next . getcontains ( ) . add ( cur ) ; <nl> - <nl> + set < specializationdata > nextcontains = next ! = null ? next . getcontains ( ) : collections . < specializationdata > emptyset ( ) ; <nl> + if ( ! nextcontains . contains ( cur ) ) { <nl> + nextcontains . add ( cur ) ; <nl> } <nl> }
final class nullconstant extends abstractconstant { <nl> assert o = = this | | ! ( o instanceof nullconstant ) : " null constant is a singleton " ; <nl> return o = = this ; <nl> } <nl> - <nl> - public object asboxedprimitive ( ) { <nl> - <nl> - return null ; <nl> - } <nl> }
package com . oracle . graal . hotspot ; <nl>  <nl> import java . lang . annotation . * ; <nl>  <nl> - <nl> + / * * <nl> + * this annotation functions as an alias for the sun . invoke . stable annotation within graal code . it <nl> + * is specially recognized during class file parsing in the same way as that annotation . <nl> + * / <nl>  <nl> @ target ( elementtype . field ) <nl> @ retention ( retentionpolicy . runtime )
public abstract class sparcnodelirbuilder extends nodelirbuilder { <nl>  <nl> @ override <nl> public void visitinfopointnode ( infopointnode i ) { <nl> - <nl> - throw graalinternalerror . unimplemented ( ) ; <nl> + append ( new infopointop ( statefor ( i . getstate ( ) ) , i . reason ) ) ; <nl> } <nl> } <nl> mmm a / graal / com . oracle . graal . hotspot . sparc / src / com / oracle / graal / hotspot / sparc / sparchotspotnodelirbuilder . java <nl> ppp b / graal / com . oracle . graal . hotspot . sparc / src / com / oracle / graal / hotspot / sparc / sparchotspotnodelirbuilder . java <nl>
public class inlineablegraph implements inlineable { <nl> return null ; <nl> } <nl>  <nl> + / * * <nl> + * this method looks up in a cache the graph for the argument , if not found bytecode is parsed . <nl> + * the graph thus obtained is returned , ie the caller is responsible for cloning before <nl> + * modification . <nl> + * / <nl> private static structuredgraph buildgraph ( final resolvedjavamethod method , final hightiercontext context , canonicalizerphase canonicalizer ) { <nl> - structuredgraph newgraph = getoriginalgraph ( method , context ) ; <nl> - if ( newgraph = = null ) { <nl> - newgraph = parsebytecodes ( method , context , canonicalizer ) ; <nl> + structuredgraph result = getoriginalgraph ( method , context ) ; <nl> + if ( result = = null ) { <nl> + result = parsebytecodes ( method , context , canonicalizer ) ; <nl> } <nl> - <nl> - / / any invokes <nl> - return newgraph . copy ( ) ; <nl> + return result ; <nl> } <nl>  <nl> / * *
public class baselinebytecodeparser extends abstractbytecodeparser < value , baseli <nl>  <nl> @ override <nl> protected void emitnullcheck ( value receiver ) { <nl> - <nl> - throw graalinternalerror . unimplemented ( " auto - generated method stub " ) ; <nl> + gen . emitnullcheck ( receiver , createframestate ( framestate ) ) ; <nl> } <nl>  <nl> @ override <nl>
public class baselinebytecodeparser extends abstractbytecodeparser < value , baseli <nl> } <nl>  <nl> @ override <nl> - protected value genarraylength ( value x ) { <nl> - <nl> + protected value genarraylength ( value array ) { <nl> + emitnullcheck ( array ) ; <nl> + long displacement = lirbuilder . getarraylengthoffset ( ) ; <nl> + value address = gen . emitaddress ( array , displacement , value . illegal , num ) ; <nl> + platformkind readkind = gen . getplatformkind ( stampfactory . forkind ( kind . int ) ) ; <nl> + lirframestate state = null ; <nl> + gen . emitload ( readkind , address , state ) ; <nl> throw graalinternalerror . unimplemented ( " auto - generated method stub " ) ; <nl> }
public final class state extends mergeablestate < state > implements cloneable { <nl> } else { <nl> trackio ( object , instanceof . type ( ) , anchor ) ; <nl> } <nl> - } else { <nl> - if ( knowntoconform ( object , instanceof . type ( ) ) ) { <nl> - impossiblepath ( ) ; <nl> - return ; <nl> - } <nl> - if ( instanceof . type ( ) . isinterface ( ) ) { <nl> - if ( ! knownnottoconform ( object , instanceof . type ( ) ) ) { <nl> - addfactprimordial ( instanceof , falsefacts , anchor ) ; <nl> - } <nl> - } <nl> } <nl> }
public abstract class checkcastreduction extends guardingpireduction { <nl> objectstamp subjectstamp = ( objectstamp ) subject . stamp ( ) ; <nl> resolvedjavatype subjecttype = subjectstamp . type ( ) ; <nl>  <nl> - <nl> - assert ! precisionloss ( checkcast . object ( ) , subject ) ; <nl> - <nl> / * <nl> * at this point , two sources of ( partial ) information : the witness and the stamp of <nl> * subject . the latter might be more precise than the witness ( eg , subject might be <nl> mmm a / graal / com . oracle . graal . phases . common / src / com / oracle / graal / phases / common / cfs / equationalreasoner . java <nl> ppp b / graal / com . oracle . graal . phases . common / src / com / oracle / graal / phases / common / cfs / equationalreasoner . java <nl>
public final class schedulephase extends phase { <nl>  <nl> private void processkilllocation ( block b , node node , locationidentity identity , list < schedulednode > sortedinstructions , nodebitmap visited , list < floatingreadnode > reads , <nl> nodebitmap beforelastlocation ) { <nl> - for ( floatingreadnode frn : new arraylist < > ( reads ) ) { <nl> + for ( floatingreadnode frn : new arraylist < > ( reads ) ) { <nl> locationidentity readlocation = frn . location ( ) . getlocationidentity ( ) ; <nl> assert readlocation ! = final_location ; <nl> if ( frn . getlastlocationaccess ( ) = = node ) { <nl>
public class hsailhotspotlirgenerator extends hsaillirgenerator implements hotsp <nl> return result ; <nl> } <nl>  <nl> - public value emitatomicreadandwrite ( value address , value newvalue ) { <nl> - <nl> - throw graalinternalerror . unimplemented ( ) ; <nl> - } <nl> - <nl> @ override <nl> public void emitdeoptimize ( value actionandreason , value failedspeculation , deoptimizingnode deopting ) { <nl> emitdeoptimizeinner ( actionandreason , state ( deopting ) , " emitdeoptimize " ) ; <nl> mmm a / graal / com . oracle . graal . hotspot . sparc / src / com / oracle / graal / hotspot / sparc / sparchotspotlirgenerator . java <nl> ppp b / graal / com . oracle . graal . hotspot . sparc / src / com / oracle / graal / hotspot / sparc / sparchotspotlirgenerator . java <nl>
public final class graphorder { <nl> if ( input instanceof framestate & & node instanceof statesplit & & input = = ( ( statesplit ) node ) . stateafter ( ) ) { <nl> / / nothing to do - after frame states are known , allowed cycles <nl> } else { <nl> - / * <nl> - * <nl> - * notdataflow inputs ) <nl> - * <nl> - * assert false : " unexpected cycle detected at input " + node + " - > " <nl> - * + input ; <nl> - * / <nl> + assert false : " unexpected cycle detected at input " + node + " - > " + input ; <nl> } <nl> } <nl> }
public class baselinebytecodeparser extends abstractbytecodeparser < value , lirfra <nl> throw graalinternalerror . unimplemented ( " auto - generated method stub " ) ; <nl> } <nl>  <nl> - @ override <nl> - protected value createblocktarget ( double probability , bciblock bciblock , lirframestatebuilder stateafter ) { <nl> - <nl> - throw graalinternalerror . unimplemented ( " auto - generated method stub " ) ; <nl> - } <nl> - <nl> @ override <nl> protected void processblock ( bciblock block ) { <nl> iteratebytecodesforblock ( block ) ; <nl> mmm a / graal / com . oracle . graal . java / src / com / oracle / graal / java / abstractbytecodeparser . java <nl> ppp b / graal / com . oracle . graal . java / src / com / oracle / graal / java / abstractbytecodeparser . java <nl>
public class baselinecompiler { <nl>  <nl> @ override <nl> protected value genintegeradd ( kind kind , value x , value y ) { <nl> - <nl> - throw graalinternalerror . unimplemented ( " auto - generated method stub " ) ; <nl> + return lirgen . emitadd ( x , y ) ; <nl> } <nl>  <nl> @ override <nl>
public class baselinecompiler { <nl>  <nl> @ override <nl> protected void genreturn ( value x ) { <nl> - <nl> - throw graalinternalerror . unimplemented ( " auto - generated method stub " ) ; <nl> + lirgen . emitreturn ( x ) ; <nl> } <nl>  <nl> @ override <nl>
public class baselinecompiler { <nl>  <nl> @ override <nl> protected value append ( value v ) { <nl> - <nl> - throw graalinternalerror . unimplemented ( " auto - generated method stub " ) ; <nl> + return v ; <nl> } <nl>  <nl> @ override
public class snippetcounter implements comparable < snippetcounter > { <nl> * / <nl> public void inc ( ) { <nl> if ( group ! = null ) { <nl> - <nl> - / / use the location for the field " value " . <nl> - directobjectstorenode . storelong ( this , countoffset ( ) , num , value + num , locationidentity . any_location ) ; <nl> + directobjectstorenode . storelong ( this , countoffset ( ) , num , value + num , snippet_counter_location ) ; <nl> } <nl> }
package com . oracle . truffle . api . debug ; <nl>  <nl> import com . oracle . truffle . api . nodes . * ; <nl>  <nl> - <nl> / * * <nl> * controls breaking out of an execution context , such as a shell or eval . <nl> * / <nl> mmm a / graal / com . oracle . truffle . api / src / com / oracle / truffle / api / debug / quitexception . java <nl> ppp b / graal / com . oracle . truffle . api / src / com / oracle / truffle / api / debug / quitexception . java <nl>
package com . oracle . truffle . api . debug ; <nl>  <nl> import com . oracle . truffle . api . nodes . * ; <nl>  <nl> - <nl> / * * <nl> * controls breaking out of all executions and ending truffle execution . <nl> * /
public class lir { <nl>  <nl> public final controlflowgraph cfg ; <nl>  <nl> - / * * <nl> - * the nodes for the blocks . <nl> - * next - pointer . <nl> - * / <nl> - private final blockmap < list < schedulednode > > blocktonodesmap ; <nl> - <nl> / * * <nl> * the linear - scan ordered list of blocks . <nl> * / <nl>
public class fixnumliteralnode extends rubynode { <nl> return value ; <nl> } <nl>  <nl> - <nl> public int getvalue ( ) { <nl> return value ; <nl> } <nl> mmm a / graal / com . oracle . truffle . ruby . nodes / src / com / oracle / truffle / ruby / nodes / methods / methoddefinitionnode . java <nl> ppp b / graal / com . oracle . truffle . ruby . nodes / src / com / oracle / truffle / ruby / nodes / methods / methoddefinitionnode . java <nl>
public class amd64hotspotsafepointop extends amd64lirinstruction { <nl> * / <nl> private static boolean ispollingpagefar ( hotspotvmconfig config ) { <nl> final long pollingpageaddress = config . safepointpollingaddress ; <nl> - <nl> - return ! numutil . isint ( pollingpageaddress - config . codecachelowboundary ( ) ) | | ! numutil . isint ( pollingpageaddress - config . codecachehighboundary ( ) ) ; <nl> + return config . forceunreachable | | ! isint ( pollingpageaddress - config . codecachelowboundary ( ) ) | | ! isint ( pollingpageaddress - config . codecachehighboundary ( ) ) ; <nl> } <nl>  <nl> public static void emitcode ( compilationresultbuilder crb , amd64macroassembler asm , hotspotvmconfig config , boolean atreturn , lirframestate state , register scratch ) { <nl> mmm a / graal / com . oracle . graal . hotspot / src / com / oracle / graal / hotspot / hotspotvmconfig . java <nl> ppp b / graal / com . oracle . graal . hotspot / src / com / oracle / graal / hotspot / hotspotvmconfig . java <nl>
public final class linearscan { <nl> printlir ( " after register number assignment " , true ) ; <nl> edgemoveoptimizer . optimize ( ir ) ; <nl> controlflowoptimizer . optimize ( ir ) ; <nl> - <nl> - / * <nl> - * temporarily disabled because of problem in specjvm2008 . <nl> - * re - enable it . <nl> - * <nl> - * redundantmoveelimination . optimize ( ir , framemap , gen . getgraph ( ) . method ( ) ) ; <nl> - * / <nl> - <nl> + redundantmoveelimination . optimize ( ir , framemap , gen . getgraph ( ) . method ( ) ) ; <nl> nullcheckoptimizer . optimize ( ir , target . implicitnullchecklimit ) ; <nl> printlir ( " after control flow optimization " , false ) ; <nl> } catch ( throwable e ) { <nl> mmm a / graal / com . oracle . graal . lir / src / com / oracle / graal / lir / redundantmoveelimination . java <nl> ppp b / graal / com . oracle . graal . lir / src / com / oracle / graal / lir / redundantmoveelimination . java <nl>
public final class monitorexitnode extends accessmonitornode implements virtuali <nl>  <nl> @ override <nl> public void virtualize ( virtualizertool tool ) { <nl> - / * <nl> - * the last monitorexitnode of a synchronized method cannot be removed anyway , and we need <nl> - * it to materialize the return value . <nl> - * <nl> - * <nl> - * / <nl> - if ( stateafter ( ) . bci ! = framestate . after_bci ) { <nl> - setescapedreturnvalue ( null ) ; <nl> - state state = tool . getobjectstate ( object ( ) ) ; <nl> - if ( state ! = null & & state . getstate ( ) = = escapestate . virtual & & state . getvirtualobject ( ) . hasidentity ( ) ) { <nl> - int removedlock = state . removelock ( ) ; <nl> - assert removedlock = = getlockdepth ( ) ; <nl> - tool . delete ( ) ; <nl> - } <nl> + state state = tool . getobjectstate ( object ( ) ) ; <nl> + / / the monitor exit for a synchronized method should never be virtualized <nl> + assert stateafter ( ) . bci ! = framestate . after_bci | | state = = null ; <nl> + if ( state ! = null & & state . getstate ( ) = = escapestate . virtual & & state . getvirtualobject ( ) . hasidentity ( ) ) { <nl> + int removedlock = state . removelock ( ) ; <nl> + assert removedlock = = getlockdepth ( ) ; <nl> + tool . delete ( ) ; <nl> } <nl> } <nl> }
public class snippettemplate { <nl> } <nl> for ( node usage : newnode . usages ( ) . snapshot ( ) ) { <nl> if ( usage instanceof floatingreadnode & & ( ( floatingreadnode ) usage ) . lastlocationaccess ( ) = = newnode ) { <nl> - <nl> - assert newnode . graph ( ) . getguardsstage ( ) . ordinal ( ) > = structuredgraph . guardsstage . fixed_deopts . ordinal ( ) ; <nl> + assert newnode . graph ( ) . isafterfloatingreadphase ( ) ; <nl>  <nl> / / lastlocationaccess points into the snippet graph . find a proper <nl> / / memorycheckpoint inside the snippet graph
public final class schedulephase extends phase { <nl> * all inputs . this means that a node is added to the list after all its inputs have been <nl> * processed . <nl> * / <nl> - private list < schedulednode > sortnodeswithinblocklatest ( block b , nodebitmap visited ) { <nl> + private list < schedulednode > sortnodeswithinblocklatest ( block b , nodebitmap visited , nodebitmap beforelastlocation ) { <nl> list < schedulednode > instructions = blocktonodesmap . get ( b ) ; <nl> list < schedulednode > sortedinstructions = new arraylist < > ( blocktonodesmap . get ( b ) . size ( ) + num ) ; <nl> list < floatingreadnode > reads = new arraylist < > ( ) ; <nl> - <nl> - nodebitmap beforelastlocation = cfg . graph . createnodebitmap ( ) ; <nl>  <nl> if ( memsched = = memoryscheduling . optimal ) { <nl> / *
public class graphprintvisitor { <nl>  <nl> setnodeproperty ( node , " name " , node . getclass ( ) . getsimplename ( ) . replacefirst ( " node $ " , " " ) ) ; <nl> nodeinfo nodeinfo = node . getclass ( ) . getannotation ( nodeinfo . class ) ; <nl> - if ( nodeinfo ! = null & & ! nodeinfo . shortname ( ) . isempty ( ) ) { <nl> - setnodeproperty ( node , " shortname " , nodeinfo . shortname ( ) ) ; <nl> + if ( nodeinfo ! = null ) { <nl> + setnodeproperty ( node , " kind " , nodeinfo . kind ( ) ) ; <nl> + if ( ! nodeinfo . shortname ( ) . isempty ( ) ) { <nl> + setnodeproperty ( node , " shortname " , nodeinfo . shortname ( ) ) ; <nl> + } <nl> } <nl> - setnodeproperty ( node , " nodetype " , ( node . class . isassignablefrom ( node . getclass ( ) ) ? node . class . getsimplename ( ) : " other " ) ) ; <nl> - setnodeproperty ( node , " nodeclass " , node . getclass ( ) . getsimplename ( ) ) ; <nl> - copydebugproperties ( node ) ; <nl> + setnodeproperty ( node , " class " , node . getclass ( ) . getsimplename ( ) ) ; <nl> readnodeproperties ( ( node ) node ) ; <nl> + copydebugproperties ( node ) ; <nl> } <nl> } <nl>  <nl> mmm a / graal / com . oracle . truffle . api / src / com / oracle / truffle / api / nodes / node . java <nl> ppp b / graal / com . oracle . truffle . api / src / com / oracle / truffle / api / nodes / node . java <nl>
import com . oracle . graal . nodes . util . * ; <nl> * < li > { @ link propagateloopfrequency } propagates the loop frequencies and multiplies each <nl> * { @ link fixednode } ' s probability with its loop frequency . < / li > <nl> * < / ol > <nl> - * <nl> * / <nl> public class computeprobabilityclosure { <nl>  <nl>
public abstract class stub extends abstracttemplates implements snippets { <nl> * / <nl> public static object verifyobject ( object object ) { <nl> if ( verifyoops ( ) ) { <nl> - <nl> - / / word verifyoopcounter = word . unsigned ( verifyoopcounteraddress ( ) ) ; <nl> - / / verifyoopcounter . writeint ( 0 , verifyoopcounter . readint ( 0 ) + num ) ; <nl> + word verifyoopcounter = word . unsigned ( verifyoopcounteraddress ( ) ) ; <nl> + verifyoopcounter . writeint ( 0 , verifyoopcounter . readint ( 0 ) + num ) ; <nl>  <nl> pointer oop = word . fromobject ( object ) ; <nl> if ( object ! = null ) {
public class wordtyperewriterphase extends phase { <nl> if ( node . stamp ( ) = = stampfactory . forword ( ) ) { <nl> return true ; <nl> } <nl> - if ( node instanceof loadindexednode ) { <nl> - valuenode array = ( ( loadindexednode ) node ) . array ( ) ; <nl> - if ( array . objectstamp ( ) . type ( ) = = null ) { <nl> - / / there are cases where the array does not have a known type yet . assume it is not <nl> - / / a word type . <nl> - <nl> - return false ; <nl> - } <nl> - return isword ( array . objectstamp ( ) . type ( ) . getcomponenttype ( ) ) ; <nl> - } <nl> if ( node . kind ( ) = = kind . object ) { <nl> return isword ( node . objectstamp ( ) . type ( ) ) ; <nl> }
public class nodeparser extends templateparser < nodedata > { <nl> } <nl>  <nl> annotationmirror methodnodes = utils . findannotationmirror ( processingenv , templatetype , nodeclass . class ) ; <nl> - <nl> if ( methodnodes = = null & & ! utils . isassignable ( templatetype . astype ( ) , context . gettruffletypes ( ) . getnode ( ) ) ) { <nl> return null ; / / not a node <nl> } <nl>  <nl> - if ( templatetype . getmodifiers ( ) . contains ( modifier . private ) ) { <nl> - <nl> - return null ; / / not visible , not a node <nl> - } <nl> - <nl> list < typeelement > lookuptypes = findsuperclasses ( new arraylist < typeelement > ( ) , templatetype ) ; <nl> collections . reverse ( lookuptypes ) ;
public class tailduplicationphase extends phase { <nl> assert replacements = = null | | replacements . size ( ) = = merge . forwardendcount ( ) ; <nl> fixednode fixed = merge ; <nl> int fixedcount = num ; <nl> - boolean containsmonitor = false ; <nl> while ( fixed instanceof fixedwithnextnode ) { <nl> - if ( fixed instanceof monitorenternode | | fixed instanceof monitorexitnode ) { <nl> - containsmonitor = true ; <nl> - } <nl> fixed = ( ( fixedwithnextnode ) fixed ) . next ( ) ; <nl> fixedcount + + ; <nl> } <nl> - if ( containsmonitor ) { <nl> - / / cannot currently be handled <nl> - <nl> - / / the lir generator <nl> - metricduplicationmonitors . increment ( ) ; <nl> - } else if ( fixedcount > num ) { <nl> + if ( fixedcount > num ) { <nl> if ( fixed instanceof endnode & & ! ( ( ( endnode ) fixed ) . merge ( ) instanceof loopbeginnode ) ) { <nl> metricduplicationend . increment ( ) ; <nl> if ( decision . dotransform ( merge , fixedcount ) ) {
public class graphbuilderphase extends phase { <nl> valuenode x = returnkind = = kind . void ? null : framestate . pop ( returnkind ) ; <nl> assert framestate . stacksize ( ) = = num ; <nl>  <nl> - <nl> if ( modifier . issynchronized ( method . getmodifiers ( ) ) ) { <nl> - append ( currentgraph . add ( new valueanchornode ( x ) ) ) ; <nl> + append ( currentgraph . add ( new valueanchornode ( true , x ) ) ) ; <nl> assert ! framestate . rethrowexception ( ) ; <nl> } <nl>  <nl> mmm a / graal / com . oracle . graal . nodes / src / com / oracle / graal / nodes / extended / valueanchornode . java <nl> ppp b / graal / com . oracle . graal . nodes / src / com / oracle / graal / nodes / extended / valueanchornode . java <nl>
package com . oracle . graal . jtt . bytecode ; <nl> import com . oracle . graal . jtt . * ; <nl> import org . junit . * ; <nl>  <nl> - / * <nl> - * <nl> - * / <nl> public class bc_l2i extends jtttest { <nl>  <nl> public static int test ( long a ) { <nl> mmm a / graal / com . oracle . graal . lir / src / com / oracle / graal / lir / standardop . java <nl> ppp b / graal / com . oracle . graal . lir / src / com / oracle / graal / lir / standardop . java <nl>
public class standardop { <nl> * lir operation that is an unconditional jump to { @ link # destination ( ) } . when the lir is <nl> * constructed , the last operation of every block must implement this interface . after register <nl> * allocation , unnecessary jumps can be deleted . <nl> - * <nl> - * <nl> * / <nl> public static class jumpop extends lirinstruction { <nl>  <nl> mmm a / graal / com . oracle . graal . nodes / src / com / oracle / graal / nodes / calc / shiftnode . java <nl> ppp b / graal / com . oracle . graal . nodes / src / com / oracle / graal / nodes / calc / shiftnode . java <nl>
public abstract class shiftnode extends binarynode { <nl> * / <nl> public shiftnode ( kind kind , valuenode x , valuenode s ) { <nl> super ( kind , x , s ) ; <nl> - <nl> - assert x = = null | | x . kind ( ) = = kind ; <nl> } <nl> }
import com . oracle . graal . nodes . * ; <nl> import com . oracle . graal . phases . * ; <nl> import com . oracle . graal . phases . common . * ; <nl>  <nl> - <nl> @ suppresswarnings ( " unused " ) <nl> public class inliningtest extends graalcompilertest { <nl>  <nl> mmm a / graal / com . oracle . graal . hotspot / src / com / oracle / graal / hotspot / nodes / tailcallnode . java <nl> ppp b / graal / com . oracle . graal . hotspot / src / com / oracle / graal / hotspot / nodes / tailcallnode . java <nl>
public class tailcallnode extends fixedwithnextnode implements lirlowerable { <nl>  <nl> javatype [ ] signature = metautil . signaturetotypes ( method . getsignature ( ) , isstatic ? null : method . getdeclaringclass ( ) ) ; <nl> callingconvention cc = gen . framemap ( ) . registerconfig . getcallingconvention ( callingconvention . type . javacall , null , signature , gen . target ( ) , false ) ; <nl> - gen . framemap ( ) . callsmethod ( cc ) ; <nl> list < valuenode > parameters = new arraylist < > ( ) ; <nl> for ( int i = num , slot = num ; i < cc . getargumentcount ( ) ; i + + , slot + = framestatebuilder . stackslots ( framestate . localat ( slot ) . kind ( ) ) ) { <nl> parameters . add ( framestate . localat ( slot ) ) ;
public final class nodemap < t > { <nl> return node . id ( ) > = size ; <nl> } <nl>  <nl> - public void grow ( node upto ) { <nl> - if ( isnew ( upto ) ) { <nl> - size = upto . id ( ) + num ; <nl> - if ( values . length < size ) { <nl> - values = arrays . copyof ( values , size + num ) ; <nl> - } <nl> - } <nl> - } <nl> - <nl> private void check ( node node ) { <nl> assert node . graph ( ) = = graph : " this node is not part of the graph " ; <nl> assert ! isnew ( node ) : " this node was added to the graph after creating the node map : " + node ;
public abstract class node implements cloneable , formattable { <nl> return nodeclass ; <nl> } <nl>  <nl> - <nl> private boolean checkreplacewith ( node other ) { <nl> assert assertfalse ( other = = this , " cannot replace a node with itself " ) ; <nl> assert assertfalse ( isdeleted ( ) , " cannot replace deleted node " ) ; <nl> - / / assert asserttrue ( other ! = null , " cannot replace with null node " ) ; <nl> assert asserttrue ( other = = null | | ! other . isdeleted ( ) , " cannot replace with deleted node % s " , other ) ; <nl> assert asserttrue ( other = = null | | other . graph ( ) = = graph , " cannot replace with node in different graph : % s " , other = = null ? null : other . graph ( ) ) ; <nl> return true ;
public abstract class amd64lirgenerator extends lirgenerator { <nl> public lirinstruction createmove ( value result , value input ) { <nl> return new spillmoveop ( result , input ) ; <nl> } <nl> - <nl> - @ override <nl> - public lirinstruction createexchange ( value input1 , value input2 ) { <nl> - <nl> - return null ; <nl> - } <nl> } <nl>  <nl> public amd64lirgenerator ( structuredgraph graph , codecacheprovider runtime , targetdescription target , framemap framemap , resolvedjavamethod method , lir lir ) { <nl> mmm a / graal / com . oracle . graal . compiler / src / com / oracle / graal / compiler / gen / lirgenerator . java <nl> ppp b / graal / com . oracle . graal . compiler / src / com / oracle / graal / compiler / gen / lirgenerator . java <nl>
public class amd64deoptimizationstub extends amd64code { <nl>  <nl> @ override <nl> public void emitcode ( targetmethodassembler tasm , amd64macroassembler masm ) { <nl> - <nl> register scratch = tasm . framemap . registerconfig . getscratchregister ( ) ; <nl>  <nl> masm . bind ( label ) ; <nl>
public class amd64call { <nl> / / offset might not fit a num - bit immediate , generate an <nl> / / indirect call with a num - bit immediate <nl> register scratch = tasm . framemap . registerconfig . getscratchregister ( ) ; <nl> - <nl> masm . movq ( scratch , num l ) ; <nl> masm . call ( scratch ) ; <nl> } else {
public final class linearscan { <nl> changespilldefinitionpos ( interval , defpos ) ; <nl> if ( registerpriority = = registerpriority . none & & interval . spillstate ( ) . ordinal ( ) < = spillstate . startinmemory . ordinal ( ) ) { <nl> / / detection of method - parameters and roundfp - results <nl> - <nl> interval . setspillstate ( spillstate . startinmemory ) ; <nl> } <nl> } <nl> mmm a / graal / com . oracle . graal . compiler / src / com / oracle / graal / compiler / gen / lirgenerator . java <nl> ppp b / graal / com . oracle . graal . compiler / src / com / oracle / graal / compiler / gen / lirgenerator . java <nl>
public final class assumptions implements serializable , iterable < assumptions . ass <nl> * otherwise <nl> * / <nl> public boolean recordnofinalizablesubclassassumption ( resolvedjavatype receivertype ) { <nl> - <nl> assert useoptimisticassumptions ; <nl> return false ; <nl> } <nl> mmm a / graal / com . oracle . graal . api . code / src / com / oracle / graal / api / code / targetdescription . java <nl> ppp b / graal / com . oracle . graal . api . code / src / com / oracle / graal / api / code / targetdescription . java <nl>
public class targetdescription { <nl> * / <nl> public final boolean debuginfodoublewordsinsecondslot ; <nl>  <nl> - public targetdescription ( architecture arch , boolean ismp , int stackalignment , int pagesize , int cachealignment , boolean inlineobjects , boolean debuginfodoublewordsinsecondslot ) { <nl> + public targetdescription ( architecture arch , boolean ismp , int stackalignment , int stackbias , int pagesize , int cachealignment , boolean inlineobjects , boolean debuginfodoublewordsinsecondslot ) { <nl> this . arch = arch ; <nl> this . pagesize = pagesize ; <nl> this . ismp = ismp ; <nl> this . wordsize = arch . getwordsize ( ) ; <nl> - if ( wordsize = = num ) { <nl> - this . wordkind = kind . long ; <nl> - } else { <nl> - this . wordkind = kind . int ; <nl> - } <nl> + this . wordkind = kind . fromwordsize ( wordsize ) ; <nl> this . stackalignment = stackalignment ; <nl> - this . stackbias = num ; <nl> + this . stackbias = stackbias ; <nl> this . cachealignment = cachealignment ; <nl> this . inlineobjects = inlineobjects ; <nl> this . debuginfodoublewordsinsecondslot = debuginfodoublewordsinsecondslot ; <nl> mmm a / graal / com . oracle . graal . api . meta / src / com / oracle / graal / api / meta / kind . java <nl> ppp b / graal / com . oracle . graal . api . meta / src / com / oracle / graal / api / meta / kind . java <nl>
public final class graaloptions { <nl> public static boolean intrinsifythreadmethods = true ; <nl> public static boolean intrinsifyunsafemethods = true ; <nl> public static boolean intrinsifymathmethods = true ; <nl> - public static boolean intrinsifyaescryptmethods = false ; <nl> + public static boolean intrinsifyaescryptmethods = true ; <nl>  <nl> / * * <nl> * counts the various paths taken through snippets .
public class newarraystub extends stub { <nl> log ( log , " newarray : calling new_array_slow " , num l ) ; <nl> return verifyoop ( newarrayslowstubcall . call ( hub , length ) ) ; <nl> } <nl> - <nl> - @ fold <nl> - private static boolean forceslowpath ( ) { <nl> - <nl> - return " true " . equalsignorecase ( system . getproperty ( " graal . newarraystub . forceslowpath " , " true " ) ) ; <nl> - } <nl> }
public final class ifnode extends controlsplitnode implements simplifiable , lirl <nl> return false ; <nl> } <nl>  <nl> - if ( merge . stateafter ( ) ! = null ) { <nl> - <nl> - / / command to reproduce : mx dacapo num eclipse - esa - g : + dumponerror <nl> - return false ; <nl> - } <nl> - <nl> / / only consider merges with a single usage that is both a phi and an operand of the comparison <nl> nodeusageslist mergeusages = merge . usages ( ) ; <nl> if ( mergeusages . count ( ) ! = num ) { <nl>
public class beginnode extends fixedwithnextnode implements statesplit , lirlower <nl> } <nl>  <nl> public void preparedelete ( fixednode evacuatefrom ) { <nl> - <nl> removeproxies ( ) ; <nl> evacuateguards ( evacuatefrom ) ; <nl> } <nl> mmm a / graal / com . oracle . graal . nodes / src / com / oracle / graal / nodes / ifnode . java <nl> ppp b / graal / com . oracle . graal . nodes / src / com / oracle / graal / nodes / ifnode . java <nl>
public class targetdescription { <nl> * / <nl> public final boolean debuginfodoublewordsinsecondslot ; <nl>  <nl> - / * * <nl> - * temporary flag to distinguish between the semantics necessary for hotspot and maxine . <nl> - * / <nl> - <nl> - public final boolean invokesnippetafterarguments ; <nl> - <nl> public targetdescription ( architecture arch , <nl> boolean ismp , <nl> int stackalignment , <nl> int pagesize , <nl> int cachealignment , <nl> boolean inlineobjects , <nl> - boolean debuginfodoublewordsinsecondslot , <nl> - boolean invokesnippetafterarguments ) { <nl> + boolean debuginfodoublewordsinsecondslot ) { <nl> this . arch = arch ; <nl> this . pagesize = pagesize ; <nl> this . ismp = ismp ; <nl>
public class hotspotruntime implements graalcodecacheprovider { <nl> * / <nl> @ override <nl> public int getcustomstackareasize ( ) { <nl> - <nl> - return num ; <nl> + return graalruntime . gettarget ( ) . wordsize ; <nl> } <nl>  <nl> @ override
public abstract class looppolicies { <nl> return size * exacttrips < = maxnodes ; <nl> } <nl>  <nl> - public static boolean shouldtryunswitch ( @ suppresswarnings ( " unused " ) loopex loop ) { <nl> - <nl> - return true ; <nl> + public static boolean shouldtryunswitch ( loopex loop ) { <nl> + return loop . loopbegin ( ) . unswitches ( ) < = graaloptions . loopmaxunswitch ; <nl> } <nl>  <nl> public static boolean shouldunswitch ( loopex loop , ifnode ifnode ) { <nl> mmm a / graal / com . oracle . graal . compiler / src / com / oracle / graal / compiler / loop / looptransformations . java <nl> ppp b / graal / com . oracle . graal . compiler / src / com / oracle / graal / compiler / loop / looptransformations . java <nl>
public class hp_series { <nl> return ( 0 . 0 ) ; <nl> } <nl>  <nl> - <nl> - / / @ test <nl> + / * this test is sensible to the implementation of math . pow , cos and sin . <nl> + * since for these functions , the specs says " the computed result must be within num ulp of the exact result " , <nl> + * different implementation may return different results . <nl> + * the num ulp delta allowed for test ( 100 ) tries to account for that but is not guaranteed to work forever . <nl> + * / <nl> + @ test <nl> public void run0 ( ) throws throwable { <nl> - assert . assertequals ( 0 . 6248571921291398d , test ( 100 ) , num ) ; <nl> + double expected = num . 6248571921291398d ; <nl> + assert . assertequals ( expected , test ( 100 ) , num * math . ulp ( expected ) ) ; <nl> } <nl>  <nl> }
public final class graaloptions { <nl> public static boolean optlooptransform = true ; <nl> public static boolean optsafepointelimination = true ; <nl>  <nl> - / / loops <nl> - public static boolean reassociateinvariants = true ; <nl> - public static boolean fullunroll = true ; <nl> - public static int fullunrollmaxnodes = num ; <nl> - <nl> / * * <nl> * insert a counter in the method prologue to track the most frequently called methods that were compiled by graal . <nl> * / <nl> mmm / dev / null <nl> ppp b / graal / com . oracle . graal . jtt / src / com / oracle / graal / jtt / bytecode / bc_ldiv3 . java <nl>
public abstract class lirgenerator extends lirgeneratortool { <nl>  <nl> @ override <nl> public void emitruntimecall ( runtimecallnode x ) { <nl> - <nl> - <nl> value resultoperand = resultoperandfor ( x . kind ( ) ) ; <nl> callingconvention cc = framemap . registerconfig . getcallingconvention ( runtimecall , x . call ( ) . arguments , target ( ) , false ) ; <nl> framemap . callsmethod ( cc , runtimecall ) ; <nl>
public final class virtualobject extends value { <nl> } <nl> return false ; <nl> } <nl> - <nl> - / * * <nl> - * this is a helper class used to create virtual objects for a number of different jdk classes . <nl> - * / <nl> - public static class civirtualobjectfactory { <nl> - private int nextid = num ; <nl> - private final codecacheprovider runtime ; <nl> - <nl> - public civirtualobjectfactory ( codecacheprovider runtime ) { <nl> - this . runtime = runtime ; <nl> - } <nl> - <nl> - public virtualobject constantproxy ( kind kind , value objectvalue , value primitivevalue ) { <nl> - constant ckind = constant . forobject ( kind ) ; <nl> - <nl> - return new virtualobject ( runtime . getresolvedjavatype ( constant . class ) , new value [ ] { ckind , primitivevalue , value . illegalvalue , objectvalue } , nextid + + ) ; <nl> - } <nl> - <nl> - public value proxy ( value civalue ) { <nl> - switch ( civalue . kind ) { <nl> - case boolean : <nl> - return new virtualobject ( runtime . getresolvedjavatype ( boolean . class ) , new value [ ] { civalue } , nextid + + ) ; <nl> - case byte : <nl> - return new virtualobject ( runtime . getresolvedjavatype ( byte . class ) , new value [ ] { civalue } , nextid + + ) ; <nl> - case char : <nl> - return new virtualobject ( runtime . getresolvedjavatype ( character . class ) , new value [ ] { civalue } , nextid + + ) ; <nl> - case double : <nl> - return new virtualobject ( runtime . getresolvedjavatype ( double . class ) , new value [ ] { civalue , value . illegalvalue } , nextid + + ) ; <nl> - case float : <nl> - return new virtualobject ( runtime . getresolvedjavatype ( float . class ) , new value [ ] { civalue } , nextid + + ) ; <nl> - case int : <nl> - return new virtualobject ( runtime . getresolvedjavatype ( integer . class ) , new value [ ] { civalue } , nextid + + ) ; <nl> - case long : <nl> - return new virtualobject ( runtime . getresolvedjavatype ( long . class ) , new value [ ] { civalue , value . illegalvalue } , nextid + + ) ; <nl> - case object : <nl> - return civalue ; <nl> - case short : <nl> - return new virtualobject ( runtime . getresolvedjavatype ( short . class ) , new value [ ] { civalue } , nextid + + ) ; <nl> - default : <nl> - assert false : civalue . kind ; <nl> - return null ; <nl> - } <nl> - } <nl> - <nl> - public virtualobject arrayproxy ( javatype arraytype , value [ ] values ) { <nl> - return new virtualobject ( arraytype , values , nextid + + ) ; <nl> - } <nl> - <nl> - } <nl> }
public class loweringphase extends phase { <nl> } <nl> } <nl>  <nl> - protected void run0 ( final structuredgraph graph ) { <nl> - controlflowgraph cfg = controlflowgraph . compute ( graph , true , false , true , true ) ; <nl> - <nl> - nodebitmap processed = graph . createnodebitmap ( ) ; <nl> - nodebitmap activeguards = graph . createnodebitmap ( ) ; <nl> - processblock ( cfg . getstartblock ( ) , activeguards , processed , null ) ; <nl> - <nl> - processed . negate ( ) ; <nl> - final ciloweringtool loweringtool = new loweringtoolbase ( ) ; <nl> - for ( node node : processed ) { <nl> - if ( node instanceof checkcastnode ) { <nl> - / / this is a checkcast that was created while lowering some other node ( e . g . storeindexed ) . <nl> - / / this checkcast must now be lir lowered . <nl> - <nl> - } else if ( node instanceof lowerable ) { <nl> - assert ! ( node instanceof fixednode ) | | node . predecessor ( ) = = null : node ; <nl> - ( ( lowerable ) node ) . lower ( loweringtool ) ; <nl> - } <nl> - } <nl> - } <nl> - <nl> private void processblock ( block block , nodebitmap activeguards , nodebitmap processed , fixednode parentanchor ) { <nl>  <nl> fixednode anchor = parentanchor ;
public class ciutil { <nl> return sb . tostring ( ) ; <nl> } <nl>  <nl> - / * * <nl> - * gets a stack trace element for a given method and bytecode index . <nl> - * / <nl> - public static stacktraceelement tostacktraceelement ( rimethod method , @ suppresswarnings ( " unused " ) int bci ) { <nl> - <nl> - return new stacktraceelement ( ciutil . tojavaname ( method . holder ( ) ) , method . name ( ) , null , - 1 ) ; <nl> - } <nl> - <nl> / * * <nl> * converts a java source - language class name into the internal form . <nl> *
public class inliningutil { <nl> framestate . replaceanddelete ( stateafter ) ; <nl> } else if ( framestate . bci = = framestate . after_exception_bci ) { <nl> if ( framestate . isalive ( ) ) { <nl> - <nl> assert stateatexceptionedge ! = null ; <nl> framestate . replaceanddelete ( stateatexceptionedge ) ; <nl> } else {
public final class hotspotmethoddata extends compilerobject { <nl> public int getexecutioncount ( hotspotmethoddata data , int position ) { <nl> return - 1 ; <nl> } <nl> - <nl> - @ override <nl> - protected long gettypesnotrecordedexecutioncount ( hotspotmethoddata data , int position ) { <nl> - <nl> - return num ; <nl> - } <nl> } <nl>  <nl> private static class virtualcalldata extends abstracttypedata { <nl>
public class amd64tailcallop extends amd64lirinstruction { <nl>  <nl> @ override <nl> public void emitcode ( targetmethodassembler tasm , amd64macroassembler masm ) { <nl> - / / move all parameters to the correct positions , according to the calling convention <nl> - <nl> - for ( int i = num ; i < inputs . length - num ; i + + ) { <nl> - assert inputs [ i ] . kind = = cikind . object | | inputs [ i ] . kind = = cikind . int | | inputs [ i ] . kind = = cikind . long : " only object , int and long supported for now " ; <nl> - assert isregister ( temps [ i ] ) : " too many parameters " ; <nl> - if ( isregister ( inputs [ i ] ) ) { <nl> - if ( inputs [ i ] ! = temps [ i ] ) { <nl> - masm . movq ( asregister ( temps [ i ] ) , asregister ( inputs [ i ] ) ) ; <nl> - } <nl> - } else { <nl> - masm . movq ( asregister ( temps [ i ] ) , tasm . asaddress ( inputs [ i ] ) ) ; <nl> - } <nl> - } <nl> / / destroy the current frame ( now the return address is the top of stack ) <nl> masm . leave ( ) ; <nl>  <nl>
<nl> - / * <nl> - * copyright ( c ) num , num , oracle and / or its affiliates . all rights reserved . <nl> - * do not alter or remove copyright notices or this file header . <nl> - * <nl> - * this code is free software ; you can redistribute it and / or modify it <nl> - * under the terms of the gnu general public license version num only , as <nl> - * published by the free software foundation . <nl> - * <nl> - * this code is distributed in the hope that it will be useful , but without <nl> - * any warranty ; without even the implied warranty of merchantability or <nl> - * fitness for a particular purpose . see the gnu general public license <nl> - * version num for more details ( a copy is included in the license file that <nl> - * accompanied this code ) . <nl> - * <nl> - * you should have received a copy of the gnu general public license version <nl> - * num along with this work ; if not , write to the free software foundation , <nl> - * inc . , num franklin st , fifth floor , boston , ma num - 1301 usa . <nl> - * <nl> - * please contact oracle , num oracle parkway , redwood shores , ca num usa <nl> - * or visit www . oracle . com if you need additional information or have any <nl> - * questions . <nl> - * / <nl> - package com . oracle . max . graal . hotspot ; <nl> - <nl> - import com . sun . cri . ci . * ; <nl> - <nl> - / * * <nl> - * hotspot - specific citarget . <nl> - * <nl> - * / <nl> - public class hotspottarget extends citarget { <nl> - <nl> - public hotspottarget ( ciarchitecture arch , boolean ismp , int stackalignment , int pagesize , int cachealignment , boolean inlineobjects ) { <nl> - super ( arch , ismp , stackalignment , pagesize , cachealignment , inlineobjects , true , true ) ; <nl> - } <nl> - }
public final class if extends controlsplit implements canonicalizable { <nl> endnode trueend = ( endnode ) truesuccessor ( ) ; <nl> endnode falseend = ( endnode ) falsesuccessor ( ) ; <nl> merge merge = trueend . merge ( ) ; <nl> - if ( merge = = falseend . merge ( ) & & merge . phis ( ) . size ( ) = = num ) { <nl> + if ( merge = = falseend . merge ( ) & & merge . phis ( ) . size ( ) = = num & & merge . endcount ( ) = = num ) { <nl> fixednode next = merge . next ( ) ; <nl> merge . setnext ( null ) ; / / disconnect to avoid next from having num preds <nl> - if ( compare ( ) . usages ( ) . size ( ) = = num & & / * ifnode . compare ( ) . hassideeffets ( ) * / true ) { <nl> - if ( graaloptions . tracecanonicalizer ) { <nl> - tty . println ( " > useless if with side effects canon ' ed to guard " ) ; <nl> - } <nl> - valueanchor anchor = new valueanchor ( compare ( ) , graph ( ) ) ; <nl> - anchor . setnext ( next ) ; <nl> - return anchor ; <nl> - } else { <nl> - if ( graaloptions . tracecanonicalizer ) { <nl> - tty . println ( " > useless if canon ' ed away " ) ; <nl> - } <nl> - return next ; <nl> - } <nl> + return next ; <nl> } <nl> } <nl> return this ; <nl> mmm a / graal / com . oracle . max . graal . compiler / src / com / oracle / max / graal / compiler / phases / canonicalizerphase . java <nl> ppp b / graal / com . oracle . max . graal . compiler / src / com / oracle / max / graal / compiler / phases / canonicalizerphase . java <nl>
public final class floatsub extends floatarithmetic { <nl> } <nl> return new floatadd ( kind , x , constant . fordouble ( - c , graph ) , sub . isstrictfp ( ) , graph ) ; <nl> } <nl> - } else if ( x . isconstant ( ) ) { <nl> - <nl> - if ( kind = = cikind . float ) { <nl> - float c = x . asconstant ( ) . asfloat ( ) ; <nl> - if ( c = = num . 0f ) { <nl> - return new negate ( y , graph ) ; <nl> - } <nl> - } else { <nl> - assert kind = = cikind . double ; <nl> - double c = x . asconstant ( ) . asdouble ( ) ; <nl> - if ( c = = num . 0 ) { <nl> - return new negate ( y , graph ) ; <nl> - } <nl> - } <nl> } <nl> return sub ; <nl> } <nl> mmm a / graal / com . oracle . max . graal . compiler / src / com / oracle / max / graal / compiler / ir / negate . java <nl> ppp b / graal / com . oracle . max . graal . compiler / src / com / oracle / max / graal / compiler / ir / negate . java <nl>
public abstract class lirgenerator extends valuevisitor { <nl>  <nl> @ override <nl> public void visitunwind ( unwind x ) { <nl> - <nl> - civalue operand = resultoperandfor ( x . kind ) ; <nl> - civalue result = force ( x . exception ( ) , operand ) ; <nl> - arraylist < civalue > args = new arraylist < civalue > ( 1 ) ; <nl> - args . add ( result ) ; <nl> + / / move exception oop into fixed register <nl> + cicallingconvention callingconvention = compilation . framemap ( ) . getcallingconvention ( new cikind [ ] { cikind . object } , runtimecall ) ; <nl> + civalue argumentoperand = callingconvention . locations [ 0 ] ; <nl> + lir . move ( makeoperand ( x . exception ( ) ) , argumentoperand ) ; <nl> + list < civalue > args = new arraylist < civalue > ( 1 ) ; <nl> lir . callruntime ( ciruntimecall . unwindexception , civalue . illegalvalue , args , null ) ; <nl> setnoresult ( x ) ; <nl> } <nl> mmm a / graal / graalcompiler / src / com / sun / c1x / graph / graphbuilder . java <nl> ppp b / graal / graalcompiler / src / com / sun / c1x / graph / graphbuilder . java <nl>
public final class c1xcompilation { <nl> } <nl>  <nl> if ( compiler . isobserved ( ) ) { <nl> - <nl> - / / compiler . firecompilationevent ( new compilationevent ( this , " after code generation " , hir . startblock , false , true , targetmethod ) ) ; <nl> + compiler . firecompilationevent ( new compilationevent ( this , " after code generation " , hir . gethirstartblock ( ) , false , true , targetmethod ) ) ; <nl> } <nl>  <nl> if ( c1xoptions . printtimers ) { <nl> mmm a / graal / graalcompiler / src / com / sun / c1x / alloc / linearscan . java <nl> ppp b / graal / graalcompiler / src / com / sun / c1x / alloc / linearscan . java <nl>
public final class linearscan { <nl> } <nl>  <nl> if ( compilation . compiler . isobserved ( ) ) { <nl> - <nl> - / / compilation . compiler . firecompilationevent ( new compilationevent ( compilation , label , compilation . hir ( ) . startblock , hirvalid , true ) ) ; <nl> + compilation . compiler . firecompilationevent ( new compilationevent ( compilation , label , compilation . hir ( ) . gethirstartblock ( ) , hirvalid , true ) ) ; <nl> } <nl> } <nl>  <nl> mmm a / graal / graalcompiler / src / com / sun / c1x / debug / cfgprinter . java <nl> ppp b / graal / graalcompiler / src / com / sun / c1x / debug / cfgprinter . java <nl>
public class ir { <nl> } <nl>  <nl> if ( compilation . compiler . isobserved ( ) ) { <nl> - <nl> - / / compilation . compiler . firecompilationevent ( new compilationevent ( compilation , phase , startblock , true , false ) ) ; <nl> + compilation . compiler . firecompilationevent ( new compilationevent ( compilation , phase , gethirstartblock ( ) , true , false ) ) ; <nl> } <nl> } <nl>  <nl> mmm a / graal / graalcompiler / src / com / sun / c1x / ir / blockbegin . java <nl> ppp b / graal / graalcompiler / src / com / sun / c1x / ir / blockbegin . java <nl>
public abstract class lirgenerator extends valuevisitor { <nl>  <nl> @ override <nl> public void visitnullcheck ( nullcheck x ) { <nl> - <nl> civalue value = load ( x . object ( ) ) ; <nl> - if ( x . cantrap ( ) ) { <nl> - lirdebuginfo info = statefor ( x ) ; <nl> - lir . nullcheck ( value , info ) ; <nl> - } <nl> - x . setoperand ( value ) ; <nl> + lirdebuginfo info = statefor ( x ) ; <nl> + lir . nullcheck ( value , info ) ; <nl> } <nl>  <nl> @ override <nl>
<nl> - / * <nl> - * copyright ( c ) num , oracle and / or its affiliates . all rights reserved . <nl> - * do not alter or remove copyright notices or this file header . <nl> - * <nl> - * this code is free software ; you can redistribute it and / or modify it <nl> - * under the terms of the gnu general public license version num only , as <nl> - * published by the free software foundation . <nl> - * <nl> - * this code is distributed in the hope that it will be useful , but without <nl> - * any warranty ; without even the implied warranty of merchantability or <nl> - * fitness for a particular purpose . see the gnu general public license <nl> - * version num for more details ( a copy is included in the license file that <nl> - * accompanied this code ) . <nl> - * <nl> - * you should have received a copy of the gnu general public license version <nl> - * num along with this work ; if not , write to the free software foundation , <nl> - * inc . , num franklin st , fifth floor , boston , ma num - 1301 usa . <nl> - * <nl> - * please contact oracle , num oracle parkway , redwood shores , ca num usa <nl> - * or visit www . oracle . com if you need additional information or have any <nl> - * questions . <nl> - * / <nl> - package com . sun . c1x ; <nl> - <nl> - import com . sun . c1x . graph . * ; <nl> - <nl> - / * * <nl> - * mechanism for extending c1x with extra transformations , analysis , optimizations . <nl> - * <nl> - * <nl> - * <nl> - * @ author doug simon <nl> - * / <nl> - public class c1xcompilerextension { <nl> - <nl> - public final void run ( ir ir ) { <nl> - process ( ir ) ; <nl> - } <nl> - <nl> - protected void process ( ir ir ) { <nl> - } <nl> - } <nl> mmm a / graal / graalcompiler / src / com / sun / c1x / graph / ir . java <nl> ppp b / graal / graalcompiler / src / com / sun / c1x / graph / ir . java <nl>
<nl> - apply plugin : " org . shipkit . shipkit - changelog " <nl> - apply plugin : " org . shipkit . shipkit - github - release " <nl> + apply plugin : ' org . shipkit . shipkit - auto - version ' <nl> + apply plugin : ' org . shipkit . shipkit - changelog ' <nl> + apply plugin : ' org . shipkit . shipkit - github - release ' <nl>  <nl> - tasks . named ( " generatechangelog " ) { <nl> - previousrevision = ' head ' <nl> - githubtoken = system . getenv ( " github_token " ) <nl> - repository = " mockito / mockito " <nl> + tasks . named ( ' generatechangelog ' ) { <nl> + previousrevision = project . ext . ' shipkit - auto - version . previous - tag ' <nl> + githubtoken = system . getenv ( ' github_token ' ) <nl> + repository = ' mockito / mockito ' <nl> } <nl>  <nl> tasks . named ( " githubrelease " ) {
jobs : <nl> with : <nl> java - version : $ { { matrix . java } } <nl>  <nl> - # <nl> + - name : num . validate gradle wrapper <nl> + if : matrix . java = = num & & matrix . mock - maker = = ' mock - maker - default ' # single - matrix - job <nl> + uses : gradle / wrapper - validation - action @ v1 # https : / / github . com / gradle / wrapper - validation - action <nl>  <nl> - - name : num . build and check reproducibility of artifacts ( single job only ) <nl> - # run on a single job , with the version of java used for releases <nl> - if : matrix . java = = num & & matrix . mock - maker = = ' mock - maker - default ' <nl> + - name : num . build and check reproducibility of artifacts ( single job only ) <nl> + if : matrix . java = = num & & matrix . mock - maker = = ' mock - maker - default ' # single - matrix - job <nl> run : . / check_reproducibility . sh <nl>  <nl> - - name : num . spotless check ( single job only ) . run ' . / gradlew spotlessapply ' locally if this job fails . <nl> - # run on a single job , with java version compatible with spotless <nl> - if : matrix . java = = num & & matrix . mock - maker = = ' mock - maker - default ' <nl> + - name : num . spotless check ( single job only ) . run ' . / gradlew spotlessapply ' locally if this job fails . <nl> + if : matrix . java = = num & & matrix . mock - maker = = ' mock - maker - default ' # single - matrix - job <nl> run : . / gradlew spotlesscheck <nl>  <nl> - - name : num . build on java $ { { matrix . java } } with $ { { matrix . mock - maker } } <nl> + - name : num . build on java $ { { matrix . java } } with $ { { matrix . mock - maker } } <nl> run : . / gradlew build bintrayupload idea - - scan - pbintraydryrun <nl> env : <nl> mock_maker : $ { { matrix . mock - maker } } <nl>  <nl> - - name : num . upload coverage report <nl> + - name : num . upload coverage report <nl> run : | <nl> . / gradlew coveragereport - s - - scan & & cp build / reports / jacoco / mockitocoverage / mockitocoverage . xml jacoco . xml | | echo " code coverage failed " <nl> bash < ( curl - s https : / / codecov . io / bash ) | | echo " codecov did not collect coverage reports " <nl>  <nl> # <nl> - # release job , only for pushes to the main branch <nl> + # release job , only for pushes to the main development branch <nl> # <nl> release : <nl> runs - on : ubuntu - latest
jobs : <nl> java - version : num <nl>  <nl> - name : build and publish <nl> - run : . / gradlew bintrayupload githubrelease - - scan - m # <nl> + run : . / gradlew bintrayupload githubrelease - - scan <nl> env : <nl> gh_write_token : $ { { secrets . gh_write_token } } <nl> bintray_api_key : $ { { secrets . bintray_api_key } } <nl> mmm / dev / null <nl> ppp b / . travis . yml <nl>
shipkit { <nl> ' docs ' : ' documentation ' <nl> ] <nl>  <nl> - <nl> - git . releasablebranchregex = " release / 2 . x " / / ' release / 2 . x ' , ' release / 3 . x ' , etc . <nl> + git . releasablebranchregex = " release / . + " / / ' release / 2 . x ' , ' release / 3 . x ' , etc . <nl>  <nl> def buildno = system . getenv ( " travis_build_number " ) <nl> git . commitmessagepostfix = buildno ? " by ci build $ buildno\n\n [ ci skip - release ] " : " by local build\n\n [ ci skip - release ] " <nl> mmm a / version . properties <nl> ppp b / version . properties <nl>
public class locationimpl implements location , serializable { <nl>  <nl> @ override <nl> public string tostring ( ) { <nl> - <nl> - stacktraceelement [ ] filtered = stacktracefilter . filter ( stacktraceholder . getstacktrace ( ) , false ) ; <nl> + return stacktraceline ; <nl> + } <nl> + <nl> + / * * <nl> + * eagerly compute the stacktrace line from the stacktraceholder . storing the throwable is <nl> + * memory - intensive for tests that have large stacktraces and have a lot of invocations on mocks . <nl> + * / <nl> + private static string computestacktraceline ( <nl> + stacktracefilter stacktracefilter , throwable stacktraceholder ) { <nl> + stacktraceelement [ ] filtered = <nl> + stacktracefilter . filter ( stacktraceholder . getstacktrace ( ) , false ) ; <nl> if ( filtered . length = = num ) { <nl> return " - > at < < unknown line > > " ; <nl> }
public class creationsettings < t > implements mockcreationsettings < t > , serializabl <nl> protected serializablemode serializablemode = serializablemode . none ; <nl> protected list < invocationlistener > invocationlisteners = new arraylist < invocationlistener > ( ) ; <nl>  <nl> - <nl> - protected list < stubbinglookuplistener > stubbinglookuplisteners = new arraylist < stubbinglookuplistener > ( ) ; <nl> + / / other listeners in this class may also need concurrency - safe implementation <nl> + / / however , no issue was reported yet , so we only protect stubbing lookup listeners ( new code ) <nl> + protected list < stubbinglookuplistener > stubbinglookuplisteners = new copyonwritearraylist < stubbinglookuplistener > ( ) ; <nl>  <nl> protected list < verificationstartedlistener > verificationstartedlisteners = new linkedlist < verificationstartedlistener > ( ) ; <nl> protected boolean stubonly ; <nl> mmm a / src / main / java / org / mockito / mock / mockcreationsettings . java <nl> ppp b / src / main / java / org / mockito / mock / mockcreationsettings . java <nl>
public class mocksettingsimpl < t > extends creationsettings < t > implements mocksett <nl> return this ; <nl> } <nl>  <nl> - <nl> - private static < t > void addlisteners ( t [ ] listeners , list < t > container , string method ) { <nl> + static < t > void addlisteners ( t [ ] listeners , list < t > container , string method ) { <nl> if ( listeners = = null ) { <nl> throw methoddoesnotacceptparameter ( method , " null vararg array . " ) ; <nl> } <nl> mmm a / src / test / java / org / mockito / internal / creation / mocksettingsimpltest . java <nl> ppp b / src / test / java / org / mockito / internal / creation / mocksettingsimpltest . java <nl>
public class stubbinglookuplistenercallbacktest extends testbase { <nl> fail ( ) ; <nl> } catch ( nowater e ) { <nl> / / then <nl> - verify ( listener1 ) . onstubbinglookup ( any ( stubbinglookupevent . class ) ) ; <nl> + verify ( listener ) . onstubbinglookup ( any ( stubbinglookupevent . class ) ) ; <nl> verify ( listener2 ) . onstubbinglookup ( any ( stubbinglookupevent . class ) ) ; <nl> } <nl> } <nl>  <nl> - <nl> + @ test <nl> + public void should_delete_listener ( ) { <nl> + / / given <nl> + foo mock = mock ( foo . class , withsettings ( ) . stubbinglookuplisteners ( listener , listener2 ) ) ; <nl> + <nl> + / / when <nl> + mock . dosomething ( " 1 " ) ; <nl> + mockingdetails ( mock ) . getmockcreationsettings ( ) . getstubbinglookuplisteners ( ) . remove ( listener2 ) ; <nl> + mock . dosomething ( " 2 " ) ; <nl> + <nl> + / / then <nl> + verify ( listener , times ( 2 ) ) . onstubbinglookup ( any ( stubbinglookupevent . class ) ) ; <nl> + verify ( listener2 , times ( 1 ) ) . onstubbinglookup ( any ( stubbinglookupevent . class ) ) ; <nl> + } <nl> + <nl> + @ test <nl> + public void should_clear_listeners ( ) { <nl> + / / given <nl> + foo mock = mock ( foo . class , withsettings ( ) . stubbinglookuplisteners ( listener , listener2 ) ) ; <nl> + <nl> + / / when <nl> + mockingdetails ( mock ) . getmockcreationsettings ( ) . getstubbinglookuplisteners ( ) . clear ( ) ; <nl> + mock . dosomething ( " foo " ) ; <nl> + <nl> + / / then <nl> + verifyzerointeractions ( listener , listener2 ) ; <nl> + } <nl>  <nl> private static class nowater extends runtimeexception { } <nl> }
public class stubbinglookupnotifier { <nl> if ( listeners . isempty ( ) ) { <nl> return ; <nl> } <nl> - <nl> - / / stubbingfound is currently being used in defaultstubbinglookuplistener . <nl> stubbinglookupevent event = new event ( invocation , stubbingfound , allstubbings , creationsettings ) ; <nl> for ( stubbinglookuplistener listener : listeners ) { <nl> listener . onstubbinglookup ( event ) ;
public class verificationwithaftertest { <nl> async . cleanup ( ) ; <nl> } <nl>  <nl> - / * * <nl> - <nl> - <nl> - <nl> - - nothing + fail <nl> - - times ( 2 ) + fail <nl> - - atleastonce , atleast ( 2 ) , fail <nl> - - atmost , fail <nl> - - never , fail <nl> - - only , fail <nl> - <nl> - * / <nl> - <nl> @ test <nl> public void should_verify_with_after ( ) { <nl> / / given
<nl> - / * <nl> - * copyright ( c ) num mockito contributors <nl> - * this program is made available under the terms of the mit license . <nl> - * / <nl> - package org . mockitousage . verification ; <nl> - <nl> - import java . util . concurrent . scheduledexecutorservice ; <nl> - import java . util . concurrent . threadfactory ; <nl> - import java . util . concurrent . timeunit ; <nl> - <nl> - import static java . lang . system . currenttimemillis ; <nl> - import static java . lang . thread . max_priority ; <nl> - import static java . util . concurrent . executors . newscheduledthreadpool ; <nl> - import static java . util . concurrent . timeunit . seconds ; <nl> - import static java . util . concurrent . locks . locksupport . parkuntil ; <nl> - <nl> - / * * <nl> - * <nl> - * / <nl> - class delayedexecution { <nl> - private static final int core_pool_size = num ; <nl> - / * * <nl> - * defines the number of milliseconds we expecting a thread might need to unpark , we use this to avoid " oversleeping " while awaiting the deadline for <nl> - * / <nl> - private static final long max_expected_oversleep_millis = num ; <nl> - <nl> - private final scheduledexecutorservice executor ; <nl> - <nl> - public delayedexecution ( ) { <nl> - this . executor = newscheduledthreadpool ( core_pool_size , maxpriothreadfactory ( ) ) ; <nl> - } <nl> - <nl> - public void callasync ( long delay , timeunit timeunit , runnable r ) { <nl> - long deadline = timeunit . tomillis ( delay ) + currenttimemillis ( ) ; <nl> - <nl> - executor . submit ( delayedexecution ( r , deadline ) ) ; <nl> - } <nl> - <nl> - public void close ( ) throws interruptedexception { <nl> - executor . shutdownnow ( ) ; <nl> - <nl> - if ( ! executor . awaittermination ( 5 , seconds ) ) { <nl> - throw new illegalstateexception ( " this delayed execution did not terminated after num seconds " ) ; <nl> - } <nl> - } <nl> - <nl> - private static runnable delayedexecution ( final runnable r , final long deadline ) { <nl> - return new runnable ( ) { <nl> - @ override <nl> - public void run ( ) { <nl> - / / we park the current thread till num ms before we want to execute the runnable <nl> - parkuntil ( deadline - max_expected_oversleep_millis ) ; <nl> - / / now we closing to the deadline by burning cpu - time in a loop <nl> - burnremaining ( deadline ) ; <nl> - <nl> - system . out . println ( " [ delayedexecution ] exec delay = " + ( currenttimemillis ( ) - deadline ) + " ms " ) ; <nl> - <nl> - r . run ( ) ; <nl> - } <nl> - <nl> - / * * <nl> - * loop in tight cycles until we reach the dead line . we do this cause sleep or park is very not precise , <nl> - * this can causes a thread to under - or oversleep , sometimes by + 50ms . <nl> - * / <nl> - private void burnremaining ( final long deadline ) { <nl> - long remaining ; <nl> - do { <nl> - remaining = deadline - currenttimemillis ( ) ; <nl> - } while ( remaining > num ) ; <nl> - } <nl> - } ; <nl> - } <nl> - <nl> - private static threadfactory maxpriothreadfactory ( ) { <nl> - return new threadfactory ( ) { <nl> - @ override <nl> - public thread newthread ( runnable r ) { <nl> - thread t = new thread ( r ) ; <nl> - t . setdaemon ( true ) ; / / allows the jvm to exit when clients forget to call delayedexecution . close ( ) <nl> - t . setpriority ( max_priority ) ; <nl> - return t ; <nl> - } <nl> - } ; <nl> - } <nl> - }
import org . mockito . mock . mockcreationsettings ; <nl> import org . mockito . quality . strictness ; <nl> import org . mockito . stubbing . stubbing ; <nl>  <nl> + / * * <nl> + * helps determining the actual strictness given that it can be configured in multiple ways ( at mock , at stubbing , in rule ) <nl> + * / <nl> public class strictnessselector { <nl>  <nl> - <nl> - public static strictness determinestrictness ( strictness currentstrictness , mockcreationsettings mocksettings , stubbing stubbing ) { <nl> + / * * <nl> + * determines the actual strictness in the following importance order : <nl> + * num st - strictness configured when declaring stubbing ; <nl> + * num nd - strictness configured at mock level ; <nl> + * num rd - strictness configured at test level ( rule , mockito session ) <nl> + * <nl> + * @ param stubbing stubbing to check for strictness . null permitted . <nl> + * @ param mocksettings settings of the mock object , may or may not have strictness configured . must not be null . <nl> + * @ param testlevelstrictness strictness configured using the test - level configuration ( rule , mockito session ) . null permitted . <nl> + * <nl> + * @ return actual strictness , can be null . <nl> + * / <nl> + public static strictness determinestrictness ( stubbing stubbing , mockcreationsettings mocksettings , strictness testlevelstrictness ) { <nl> if ( stubbing ! = null & & stubbing . getstrictness ( ) ! = null ) { <nl> return stubbing . getstrictness ( ) ; <nl> } <nl>
class defaultstubbinglookuplistener implements stubbinglookuplistener { <nl> collection < stubbing > stubbings = mockingdetails ( invocation . getmock ( ) ) . getstubbings ( ) ; <nl> for ( stubbing s : stubbings ) { <nl> if ( ! s . wasused ( ) & & s . getinvocation ( ) . getmethod ( ) . getname ( ) . equals ( invocation . getmethod ( ) . getname ( ) ) <nl> - <nl> + / / we don ' t want to report lenient stubbing as potential arg mismatch <nl> & & s . getstrictness ( ) ! = strictness . lenient ) { <nl> matchingstubbings . add ( s . getinvocation ( ) ) ; <nl> }
class defaultstubbinglookuplistener implements stubbinglookuplistener { <nl> } <nl>  <nl> public void onstubbinglookup ( invocation invocation , stubbing stubbingfound , mockcreationsettings mocksettings ) { <nl> - <nl> - if ( currentstrictness ! = strictness . strict_stubs ) { <nl> - return ; <nl> - } <nl> + strictness actualstrictness = strictnessselector . determinestrictness ( currentstrictness , mocksettings , stubbingfound ) ; <nl>  <nl> - if ( mocksettings . getstrictness ( ) = = strictness . lenient | | mocksettings . getstrictness ( ) = = strictness . warn ) { <nl> - / / strictness explicitly relaxed at the mock level <nl> + if ( actualstrictness ! = strictness . strict_stubs ) { <nl> return ; <nl> } <nl>  <nl>
public class unusedstubbingsfinder { <nl>  <nl> list < stubbing > unused = filter ( stubbings , new filter < stubbing > ( ) { <nl> public boolean isout ( stubbing s ) { <nl> - <nl> return s . wasused ( ) | | s . getstrictness ( ) = = strictness . lenient ; <nl> } <nl> } ) ; <nl> mmm a / src / main / java / org / mockito / internal / stubbing / ongoingstubbingimpl . java <nl> ppp b / src / main / java / org / mockito / internal / stubbing / ongoingstubbingimpl . java <nl>
public class ongoingstubbingimpl < t > extends basestubbing < t > { <nl>  <nl> @ override <nl> public ongoingstubbing < t > thenanswer ( answer < ? > answer ) { <nl> - <nl> if ( ! invocationcontainer . hasinvocationforpotentialstubbing ( ) ) { <nl> throw incorrectuseofapi ( ) ; <nl> }
public class strictnessperstubbingtest { <nl> } <nl>  <nl> @ test <nl> - @ ignore ( " <nl> public void verify_no_more_invocations ( ) { <nl> / / when <nl> when ( mock . simplemethod ( " 1 " ) ) . thenreturn ( " 1 " ) ; <nl>
public class strictnessperstubbingtest { <nl> } <nl>  <nl> @ test <nl> - @ ignore ( " <nl> public void unnecessary_stubbing ( ) { <nl> / / when <nl> when ( mock . simplemethod ( " 1 " ) ) . thenreturn ( " 1 " ) ;
public abstract class basestubbing < t > implements ongoingstubbing < t > { <nl> public ongoingstubbing < t > thenreturn ( t value , t . . . values ) { <nl> ongoingstubbing < t > stubbing = thenreturn ( value ) ; <nl> if ( values = = null ) { <nl> - <nl> return stubbing . thenreturn ( null ) ; <nl> } <nl> for ( t v : values ) { <nl>
apply from : " $ rootdir / gradle / dependencies . gradle " <nl> apply plugin : ' java ' <nl> description = " end - to - end tests for deprecated mockito plugins . " <nl>  <nl> - / / so that we can depend on locally published mockito <nl> - / / and test end - to - end mockito jar resolution ( for example , flesh out missing dependencies in pom file ) <nl> - [ compiletestjava , ideamodule ] . each { <nl> - it . dependson " : publishtomavenlocal " <nl> - } <nl> - <nl> - repositories { <nl> - mavenlocal ( ) / / we depend on locally published mockito <nl> - } <nl> - <nl> dependencies { <nl> - testcompile " org . mockito : mockito - core : $ version " <nl> - testcompile project ( path : ' : ' , configuration : ' testutil ' ) <nl> + testcompile project ( " : " ) <nl> testcompile libraries . junit4 <nl> - testcompile libraries . assertj <nl> - } <nl> - <nl> - configurations . all { <nl> - <nl> - / / let ' s make those tests not use hamcrest <nl> - / / exclude group : ' org . hamcrest ' , module : ' hamcrest - core ' <nl> }
import org . mockito . incubating ; <nl> * it allows to replace the mock object for verification . <nl> * this api is not needed for regular mockito users who want to write beautiful and clean tests . <nl> * it is only needed for advanced framework integrations where there are multiple layers of proxying . <nl> - * an example framework that leverages this api is < a href = " <nl> + * an example framework that leverages this api is < a href = " https : / / projects . spring . io / spring - boot / " > spring boot < / a > . <nl> * for details about the use case see < a href = " https : / / github . com / mockito / mockito / issues / 1191 " > issue num < / a > . <nl> * for sample code see { @ code verificationstartedlistenertest } class . <nl> * mockito is open source so feel free to dive into the code !
import org . mockito . verification . verificationwithtimeout ; <nl> * < a href = " # 39 " > 39 . mocking final types , enums and final methods ( since num . 1 . 0 ) < / a > < br / > <nl> * < a href = " # 40 " > 40 . ( * new * ) improved productivity and cleaner tests with " stricter " mockito ( since num . + ) < / a > < br / > <nl> * < a href = " # 41 " > 41 . ( * * new * * ) advanced public api for framework integrations ( since num . 10 . + ) < / a > < br / > <nl> - * < a href = " # 42 " > 42 . ( * * new * * ) new api for integrations : verificationstartedlistener ( since num . 11 . + ) <nl> + * < a href = " # 42 " > 42 . ( * * new * * ) new api for integrations : listening on verification start events ( since num . 11 . + ) < / a > < br / > <nl> * < / b > <nl> * <nl> * < h3 id = " 0 " > 0 . < a class = " meaningful_link " href = " # mockito2 " name = " mockito2 " > migrating to mockito num < / a > < / h3 > <nl>
public class verificationstartednotifier { <nl> } <nl> mockitomock mockitomock = mockutil . getmockitomock ( mock ) ; <nl> if ( ! mockitomock . ismock ( ) ) { <nl> - throw reporter . methoddoesnotacceptparameter ( " verificationstartedevent . setmock " , " parameter which is not a mockito mock . " ) ; <nl> - <nl> - / / if the user passed wrong argument , lets show him what argument was passed to streamline debugging <nl> + throw reporter . methoddoesnotacceptparameter ( " verificationstartedevent . setmock " , " parameter which is not a mockito mock . \n " + <nl> + " received parameter : " + valueprinter . print ( mock ) + " . \n " ) ; <nl> } <nl> mockcreationsettings originalmocksettings = this . originalmock . gethandler ( ) . getmocksettings ( ) ; <nl> assertcompatibletypes ( mock , originalmocksettings ) ; <nl> mmm a / src / test / java / org / mockito / internal / listeners / verificationstartednotifiertest . java <nl> ppp b / src / test / java / org / mockito / internal / listeners / verificationstartednotifiertest . java <nl>
public class mockitocore { <nl> } <nl> mockhandler handler = mockitomock . gethandler ( ) ; <nl>  <nl> - <nl> mock = ( t ) verificationstartednotifier . notifyverificationstarted ( <nl> handler . getmocksettings ( ) . getverificationstartedlisteners ( ) , mock ) ; <nl>  <nl> mmm a / src / main / java / org / mockito / internal / listeners / verificationstartednotifier . java <nl> ppp b / src / main / java / org / mockito / internal / listeners / verificationstartednotifier . java <nl>
public interface mocksettings extends serializable { <nl> * the order , in which the listeners are added , is not guaranteed to be the <nl> * order in which the listeners are notified . <nl> * <nl> - * <nl> - * this means that we allow the same object to be added multiple times . <nl> - * <nl> * example : <nl> * < pre class = " code " > < code class = " java " > <nl> * list mockwithlistener = mock ( list . class , withsettings ( ) . invocationlisteners ( new yourinvocationlistener ( ) ) ) ;
import org . mockito . verification . verificationwithtimeout ; <nl> * < h3 id = " 41 " > 41 . < a class = " meaningful_link " href = " # framework_integrations_api " name = " framework_integrations_api " > <nl> * ( * * new * * ) advanced public api for framework integrations ( since num . 10 . + ) < / h3 > <nl> * <nl> - * <nl> * in summer num we decided that mockito <nl> * < a href = " https : / / www . linkedin . com / pulse / mockito - vs - powermock - opinionated - dogmatic - static - mocking - faber " > <nl> * should offer better api <nl>
public interface mockitoframework { <nl> * <nl> * @ since num . 10 . 0 <nl> * / <nl> + @ incubating <nl> mockitoplugins getplugins ( ) ; <nl>  <nl> / * * <nl> - * returns an object that allows creating instances of { @ link org . mockito . invocation . invocation } . <nl> - * it is useful for framework integrations , like powermock . <nl> + * returns a factory that can create instances of { @ link invocation } . <nl> + * it is useful for framework integrations , because { @ link invocation } is { @ link notextensible } . <nl> * <nl> - * <nl> + * @ since num . 10 . 0 <nl> * / <nl> + @ incubating <nl> invocationfactory getinvocationfactory ( ) ; <nl> }
public interface mocksettings extends serializable { <nl>  <nl> / * * <nl> * creates immutable view of mock settings used later by mockito . <nl> - * framework integrators can use this method to create instances of creation settings . <nl> + * framework integrators can use this method to create instances of creation settings <nl> + * and use them in advanced use cases . <nl> + * since { @ link mockcreationsettings } is { @ link notextensible } this method is needed to create instances . <nl> * <nl> * @ param typetomock class to mock <nl> * @ param < t > type to mock <nl> * @ return immutable view of mock settings <nl> - * @ since <nl> + * @ since num . 10 . 0 <nl> * / <nl> < t > mockcreationsettings < t > build ( class < t > typetomock ) ; <nl> } <nl> mmm a / src / main / java / org / mockito / mock / mockcreationsettings . java <nl> ppp b / src / main / java / org / mockito / mock / mockcreationsettings . java <nl>
public interface mockingdetails { <nl> string printinvocations ( ) ; <nl>  <nl> / * * <nl> - * <nl> + * returns the { @ link mockhandler } associated with this mock object . <nl> + * the handler is the core of mockito mock object method handling . <nl> + * this method is useful for framework integrators . <nl> + * for example , other frameworks may use mock handler to simulate method calls on the mock object . <nl> + * <nl> + * @ return mock handler instance of this mock <nl> + * @ since num . 10 . 0 <nl> * / <nl> mockhandler getmockhandler ( ) ; <nl> }
public interface mockitoframework { <nl> * an example plugin is { @ link org . mockito . plugins . mockmaker } . <nl> * for information why and how to use this method see { @ link mockitoplugins } . <nl> * <nl> - * <nl> + * @ since num . 10 . 0 <nl> * / <nl> mockitoplugins getplugins ( ) ; <nl>  <nl> mmm a / src / main / java / org / mockito / plugins / mockitoplugins . java <nl> ppp b / src / main / java / org / mockito / plugins / mockitoplugins . java <nl>
import org . mockito . mockitoframework ; <nl>  <nl> / * * <nl> * instance of this interface is available via { @ link mockitoframework # getplugins ( ) } . <nl> + * this object enables framework integrators to get access to default mockito plugins . <nl> + * < p > <nl> + * example use case : one needs to implement custom { @ link mockmaker } <nl> + * and delegate some behavior to the default mockito implementation . <nl> + * the interface was introduced to help framework integrations like powermock . <nl> * <nl> - * <nl> + * @ since num . 10 . 0 <nl> * / <nl> public interface mockitoplugins { <nl>  <nl>
<nl> shipkit { <nl> github . repository = " mockito / mockito " <nl> github . readonlyauthtoken = " <commit_id> " <nl> - <nl> - github . writeauthuser = " szczepiq " <nl> - github . writeauthtoken = system . getenv ( " gh_write_token " ) <nl>  <nl> releasenotes . file = " doc / release - notes / official . md " <nl> releasenotes . labelmapping = [ <nl>
ext { <nl> ' docs ' : ' documentation ' <nl> ] <nl>  <nl> - git_genericuser = " mockito release tools " <nl> - git_genericemail = " < mockito . release . tools @ gmail . com > " <nl> + git . user = " mockito release tools " <nl> + git . email = " < mockito . release . tools @ gmail . com > " <nl> + / / git . releasablebranchregex = " master | release / . + " / / matches ' master ' , ' release / 2 . x ' , ' release / 3 . x ' , etc . <nl> + git . releasablebranchregex = " release / . + " / / ' release / 2 . x ' , ' release / 3 . x ' , etc . <nl>  <nl> - <nl> - / / git_releasablebranchregex = " master | release / . + " / / matches ' master ' , ' release / 2 . x ' , ' release / 3 . x ' , etc . <nl> - git_releasablebranchregex = " release / . + " / / ' release / 2 . x ' , ' release / 3 . x ' , etc . <nl> - <nl> - pom_developers = [ ' szczepiq : szczepan faber ' , ' bric3 : brice dutheil ' , ' raphw : rafael winterhalter ' , ' timvdlippe : tim van der lippe ' ] <nl> - pom_contributors = [ ] <nl> + team . developers = [ ' szczepiq : szczepan faber ' , ' bric3 : brice dutheil ' , ' raphw : rafael winterhalter ' , ' timvdlippe : tim van der lippe ' ] <nl> + team . contributors = [ ] <nl> } <nl>  <nl> allprojects { <nl> plugins . withid ( " org . mockito . mockito - release - tools . bintray " ) { <nl> bintray { <nl> + key = system . getenv ( " bintray_api_key " ) <nl> pkg { <nl> repo = ' maven ' / / https : / / bintray . com / mockito / maven <nl> user = ' szczepiq ' / / https : / / bintray . com / szczepiq
allprojects { <nl> name = ' mockito ' <nl> licenses = [ ' mit ' ] <nl> labels = [ ' mocks ' , ' tdd ' , ' unit tests ' ] <nl> - publish = false <nl> + publish = true / / can be changed to ' false ' for testing <nl> + <nl> + / / see our bintray packages at https : / / bintray . com / mockito / maven <nl> name = rootproject . ext . has ( ' release_notable ' ) ? " mockito " : " mockito - development " <nl>  <nl> version {
<nl> - / * <nl> - * copyright ( c ) num mockito contributors <nl> - * this program is made available under the terms of the mit license . <nl> - * / <nl> - <nl> - package org . mockito . internal . util ; <nl> - <nl> - import java . util . regex . matcher ; <nl> - import java . util . regex . pattern ; <nl> - <nl> - <nl> - public class decamelizer { <nl> - <nl> - private static final pattern caps = pattern . compile ( " ( [ a - z \ \ d ] [ ^ a - z \ \ d ] * ) " ) ; <nl> - <nl> - public static string decamelizematcher ( string classname ) { <nl> - if ( classname . length ( ) = = num ) { <nl> - return " < custom argument matcher > " ; <nl> - } <nl> - <nl> - string decamelized = decamelizeclassname ( classname ) ; <nl> - <nl> - if ( decamelized . length ( ) = = num ) { <nl> - return " < " + classname + " > " ; <nl> - } <nl> - <nl> - return " < " + decamelized + " > " ; <nl> - } <nl> - <nl> - private static string decamelizeclassname ( string classname ) { <nl> - matcher match = caps . matcher ( classname ) ; <nl> - stringbuilder decameled = new stringbuilder ( ) ; <nl> - while ( match . find ( ) ) { <nl> - if ( decameled . length ( ) = = num ) { <nl> - decameled . append ( match . group ( ) ) ; <nl> - } else { <nl> - decameled . append ( " " ) ; <nl> - decameled . append ( match . group ( ) . tolowercase ( ) ) ; <nl> - } <nl> - } <nl> - return decameled . tostring ( ) ; <nl> - } <nl> - } <nl> mmm a / src / main / java / org / mockito / internal / verification / checkers / numberofinvocationsinorderchecker . java <nl> ppp / dev / null <nl>
<nl> apply plugin : " org . mockito . mockito - release - tools . continuous - delivery " <nl>  <nl> ext { <nl> - gh_repository = " mockito / mockito - release - tools - example " <nl> + gh_repository = " mockito / mockito " <nl> gh_user = " szczepiq " <nl> gh_readonlyauthtoken = " <commit_id> " <nl> - <nl> - gh_writeauthtokenenvname = " gh_write_token " <nl>  <nl> releasenotes_file = " doc / release - notes / official . md " <nl> releasenotes_notablefile = " docs / release - notes / notable . md " <nl>
<nl> - dependencies { <nl> - / / needed by javadocexclude <nl> - <nl> - compile files ( " $ { system . properties [ ' java . home ' ] } / . . / lib / tools . jar " ) <nl> - } <nl> \ no newline at end of file
class defaultstubbinglookuplistener implements stubbinglookuplistener { <nl> list < invocation > argmismatchstubbings = potentialargmismatches ( invocation ) ; <nl> if ( ! argmismatchstubbings . isempty ( ) ) { <nl> mismatchesreported = true ; <nl> - <nl> reporter . potentialstubbingproblem ( invocation , argmismatchstubbings ) ; <nl> } <nl> } else {
import org . junit . runner . notification . runnotifier ; <nl> / * * <nl> * i ' m using this surrogate interface to hide internal runner implementations . <nl> * surrogate cannot be used with & # 064 ; runwith therefore it is less likely clients will use interal runners . <nl> - * <nl> - * <nl> * / <nl> public interface internalrunner extends filterable {
def licensefiles = copyspec { <nl> from ( " . " ) { include ' license ' } <nl> } <nl>  <nl> - <nl> jar { <nl> - from ( sourcesets . main . allsource ) <nl> with licensefiles <nl> - <nl> } <nl>  <nl> task sourcesjar ( type : jar ) { <nl> mmm a / version . properties <nl> ppp b / version . properties <nl>
import org . mockito . mockitoannotations ; <nl> import org . mockito . internal . junit . mockitotestlistener ; <nl> import org . mockito . internal . util . supplier ; <nl>  <nl> - <nl> - public class silentjunitrunner implements internalrunner { <nl> + public class defaultinternalrunner implements internalrunner { <nl>  <nl> private final blockjunit4classrunner runner ; <nl>  <nl> - public silentjunitrunner ( class < ? > testclass , final supplier < mockitotestlistener > listenersupplier ) throws initializationerror { <nl> + public defaultinternalrunner ( class < ? > testclass , final supplier < mockitotestlistener > listenersupplier ) throws initializationerror { <nl> runner = new blockjunit4classrunner ( testclass ) { <nl>  <nl> public object target ; <nl> mmm a / src / main / java / org / mockito / internal / runners / runnerfactory . java <nl> ppp b / src / main / java / org / mockito / internal / runners / runnerfactory . java <nl>
import org . junit . runners . model . statement ; <nl> / * * <nl> * junit rule for testing exception handling other junit rules , like mockito junit rules . <nl> * makes it easy to assert on expected exceptions triggered by the rule under test . <nl> - * <nl> - * <nl> * / <nl> public class safejunitrule implements methodrule {
public class junitrule implements mockitorule { <nl>  <nl> public enum strictness { silent , warn , strict_stubs ; } <nl> private final mockitologger logger ; <nl> - private mockitotestlistener listener ; <nl> - / * * <nl> - * @ param logger target for the stubbing warnings <nl> - * @ param silent whether the rule emits warnings <nl> - * / <nl> - public junitrule ( mockitologger logger , boolean silent ) { <nl> - <nl> - this ( logger , silent ? strictness . silent : strictness . warn ) ; <nl> - } <nl> + private final mockitotestlistener listener ; <nl>  <nl> / * * <nl> * @ param logger target for the stubbing warnings <nl>
class strictstubstestlistener implements mockitotestlistener { <nl>  <nl> / / it is not ideal that we modify the state of mockcreationsettings object <nl> / / mockcreationsettings is intended to be an immutable view of the creation settings <nl> - <nl> settings . getstubbinglookuplisteners ( ) . add ( new stubbinglookuplistener ( ) { <nl> public void onstubbinglookup ( invocation invocation , matchableinvocation stubbingfound ) { <nl> if ( stubbingfound = = null ) { <nl> mmm a / src / main / java / org / mockito / listeners / stubbinglookuplistener . java <nl> ppp b / src / main / java / org / mockito / listeners / stubbinglookuplistener . java <nl>
public class junitrule implements mockitorule { <nl> testfailure = evaluatesafely ( base ) ; <nl> } finally { <nl> for ( mockitotestlistener listener : listeners ) { <nl> - <nl> mockito . framework ( ) . removelistener ( listener ) ; <nl> } <nl> }
public class strictjunitruletest extends testbase { <nl> } <nl> } <nl>  <nl> - <nl> - @ ignore @ test public void verify_no_more_interactions_ignores_stubs ( ) throws throwable { <nl> + @ test public void verify_no_more_interactions_ignores_stubs ( ) throws throwable { <nl> / / when <nl> run ( new mockitostatement ( ) { <nl> public void evaluate ( imethods mock , imethods mock2 ) throws throwable { <nl>
public class releaseworkflowextension implements releaseworkflow { <nl> task . onlyif ( new specadapter ( allower ) ) ; <nl> } <nl>  <nl> - if ( config . isempty ( ) ) { <nl> + stepconfiguration stepconfig = new stepconfiguration ( config ) ; <nl> + <nl> + if ( stepconfig . isempty ( ) ) { <nl> return ; / / no rollback / cleanup configured <nl> } <nl>  <nl> - <nl> - task rollback = config . get ( " rollback " ) ; <nl> + task rollback = stepconfig . getrollback ( ) ; <nl> if ( rollback ! = null ) { <nl> / / rollbacks only run when one of the steps fails , by default we assume they don ' t fail <nl> if ( ! project . hasproperty ( " dryrun " ) ) { / / accommodate testing <nl> rollback . setenabled ( false ) ; <nl> } <nl> } else { <nl> - rollback = config . get ( " cleanup " ) ; <nl> + rollback = stepconfig . getcleanup ( ) ; <nl> / / cleanups run even if the release is successful <nl> } <nl>  <nl> mmm / dev / null <nl> ppp b / buildsrc / src / main / groovy / org / mockito / workflow / gradle / internal / stepconfiguration . java <nl>
releasesteps { <nl> . rollback { run " git " , " tag " , " - d " , " v $ { currentversion } " . tostring ( ) } <nl>  <nl> step ( " commit incremented version on $ system . env . travis_branch " ) { commitincrementedversion ( currentversion , buildinfo , project . versionfile ) } <nl> - <nl> . rollback { run " git " , " reset " , " - - hard " , " head ~ 1 " } <nl>  <nl> step ( " push changes to all involved branches " ) {
public interface mockingdetails { <nl> * < p > <nl> * this method throws meaningful exception when object wrapped by mockingdetails is not a mock . <nl> * <nl> - * @ since <nl> + * @ since num . 2 . 4 <nl> * / <nl> string printinvocations ( ) ; <nl> }
<nl> package org . mockito . internal . invocation ; <nl>  <nl> + import org . mockito . mockingdetails ; <nl> import org . mockito . invocation . invocation ; <nl>  <nl> / * * <nl> - * <nl> + * stubbing declared on the mock object . <nl> + * see detailed description including sample code and use cases see javadoc for { @ link mockingdetails # getstubbings ( ) } . <nl> + * <nl> + * @ since num . 2 . 0 <nl> * / <nl> public interface stubbing { <nl>  <nl> + / * * <nl> + * returns the method invocation that is stubbed . <nl> + * e . g . in the example stubbing < code > when ( mock . foo ( ) ) . thenreturn ( true ) < / code > <nl> + * the invocation is < code > mock . foo ( ) < / code > . <nl> + * < p > <nl> + * the invocation instance is mutable . <nl> + * it is not recommended to modify the state of invocation because it will influence mock behavior . <nl> + * < p > <nl> + * to understand how this method is useful , see the description at { @ link mockingdetails # getstubbings ( ) } . <nl> + * <nl> + * @ since num . 2 . 0 <nl> + * / <nl> invocation getinvocation ( ) ; <nl>  <nl> + / * * <nl> + * informs if the stubbing was used <nl> + * < p > <nl> + * what does it mean ' used stubbing ' ? <nl> + * stubbing like < code > when ( mock . foo ( ) ) . thenreturn ( true ) < / code > is considered used <nl> + * when the method < code > mock . foo ( ) < / code > is actually invoked during the execution of code under test . <nl> + * < p > <nl> + * this method is used internally by mockito to report and detect unused stubbings . <nl> + * unused stubbings are dead code and should be deleted to increase clarity of tests ( see { @ link org . mockito . quality . mockitohint } . <nl> + * < p > <nl> + * to understand how this method is useful , see the description at { @ link mockingdetails # getstubbings ( ) } . <nl> + * <nl> + * @ since num . 2 . 0 <nl> + * / <nl> boolean wasused ( ) ; <nl> } <nl> mmm a / src / main / java / org / mockito / internal / util / defaultmockingdetails . java <nl> ppp b / src / main / java / org / mockito / internal / util / defaultmockingdetails . java <nl>
public class defaultmockingdetails implements mockingdetails { <nl>  <nl> @ override <nl> public collection < stubbing > getstubbings ( ) { <nl> - <nl> list < ? extends stubbing > stubbings = mockhandler ( ) . getinvocationcontainer ( ) . getstubbedinvocations ( ) ; <nl> treeset < stubbing > out = new treeset < stubbing > ( new stubbingcomparator ( ) ) ; <nl> out . addall ( stubbings ) ; <nl> mmm a / src / test / java / org / mockito / internal / util / defaultmockingdetailstest . java <nl> ppp b / src / test / java / org / mockito / internal / util / defaultmockingdetailstest . java <nl>
public interface mockingdetails { <nl> mockcreationsettings < ? > getmockcreationsettings ( ) ; <nl>  <nl> / * * <nl> - * <nl> + * returns stubbings declared on this mock object . <nl> + * < pre class = " code " > < code class = " java " > <nl> + * mockito . mockingdetails ( mock ) . getstubbings ( ) <nl> + * < / code > < / pre > <nl> + * what is ' stubbing ' ? <nl> + * stubbing is your when ( x ) . then ( y ) declaration , e . g . configuring the mock to behave in a specific way , <nl> + * when specific method with specific arguments is invoked on a mock . <nl> + * typically stubbing is configuring mock to return x when method y is invoked . <nl> + * < p > <nl> + * why do you need to access stubbings of a mock ? <nl> + * in a normal workflow of creation clean tests , there is no need for this api . <nl> + * however , it is useful for advanced users , edge cases or framework integrators . <nl> + * for example , mockito internally uses this api to report and detect unused stubbings <nl> + * that should be removed from test . unused stubbings are dead code that needs to be removed <nl> + * ( see { @ link mockitohint } ) . <nl> + * < p > <nl> + * manipulating the collection ( e . g . by removing , adding elements ) is safe and has no effect on the mock . <nl> + * < p > <nl> + * this method throws meaningful exception when object wrapped by mockingdetails is not a mock . <nl> + * <nl> + * @ since num . 2 . 0 <nl> * / <nl> collection < stubbing > getstubbings ( ) ; <nl> } <nl> mmm a / src / test / java / org / mockito / internal / util / defaultmockingdetailstest . java <nl> ppp b / src / test / java / org / mockito / internal / util / defaultmockingdetailstest . java <nl>
public class defaultmockingdetailstest { <nl> assertequals ( " [ mock . simplemethod ( 1 ) ; stubbed with : [ returns : num ] , mock . othermethod ( ) ; stubbed with : [ returns : num ] ] " , stubbings . tostring ( ) ) ; <nl> } <nl>  <nl> - <nl> - / / let ' s make it consistent with getinvocations ( ) , e . g . the user can manipulate the stubbings if needed <nl> - / / this way it is num ) consistent num ) more flexible num ) more risky if the user does not know what he is doing : ) <nl> @ test <nl> public void manipulating_stubbings_explicitly_is_safe ( ) { <nl> when ( mock . simplemethod ( 1 ) ) . thenreturn ( " 1 " ) ;
import org . mockito . junit . * ; <nl> * < a href = " # 35 " > 35 . ( new ) custom verification failure message ( since num . 1 . 0 ) < / a > < br / > <nl> * < a href = " # 36 " > 36 . ( new ) java num lambda matcher support ( since num . 1 . 0 ) < / a > < br / > <nl> * < a href = " # 37 " > 37 . ( new ) java num custom answer support ( since num . 1 . 0 ) < / a > < br / > <nl> - * <nl> * < / b > <nl> * <nl> - * < h3 id = " 0 " > 0 . < a class = " meaningful_link " href = " # verification " > migrating to num . 1 . 0 < / a > < / h3 > <nl> + * < h3 id = " 0 " > 0 . < a class = " meaningful_link " href = " # verification " > migrating to mockito num < / a > < / h3 > <nl> * <nl> * in order to continue improving mockito and further improve the unit testing experience , we want you to upgrade to num . 1 . 0 ! <nl> * mockito follows < a href = " http : / / semver . org / " > semantic versioning < / a > <nl> * and contains breaking changes only on major version upgrades . <nl> * in the lifecycle of a library , breaking changes are necessary <nl> * to roll out a set of brand new features that alter the existing behavior or even change the api . <nl> - * we hope that you enjoy mockito num . 1 . 0 ! <nl> - * < p > <nl> - * list of breaking changes : <nl> - * < ul > <nl> - * < li > mockito is decoupled from hamcrest and custom matchers api has changed , see { @ link argumentmatcher } <nl> - * for rationale and migration guide . < / li > <nl> - * < li > stubbing api has been tweaked to avoid unavoidable compilation warnings that appeared on jdk7 + platform . <nl> - * this will only affect binary compatibility , compilation compatibility remains unaffected . < / li > <nl> - * < / ul > <nl> + * for comprehensive information about the new release including incompatible changes , <nl> + * see ' < a href = " https : / / github . com / mockito / mockito / wiki / what % 27s - new - in - mockito - 2 " > what ' s new in mockito num < / a > ' wiki page . <nl> + * we hope that you enjoy mockito num ! <nl> + * <nl> + * < h3 id = " 1 " > 1 . < a class = " meaningful_link " href = " # verification " > let ' s verify some behaviour ! < / a > < / h3 > <nl> * <nl> - * < p > <nl> * the following examples mock a list , because most people are familiar with the interface ( such as the <nl> * < code > add ( ) < / code > , < code > get ( ) < / code > , < code > clear ( ) < / code > methods ) . < br > <nl> * in reality , please don ' t mock the list class . use a real instance instead . <nl> * <nl> - * <nl> - * <nl> - * <nl> - * < h3 id = " 1 " > 1 . < a class = " meaningful_link " href = " # verification " > let ' s verify some behaviour ! < / a > < / h3 > <nl> - * <nl> * < pre class = " code " > < code class = " java " > <nl> * / / let ' s import mockito statically so that the code looks clearer <nl> * import static org . mockito . mockito . * ;
<nl> - / * <nl> - * copyright ( c ) num mockito contributors <nl> - * this program is made available under the terms of the mit license . <nl> - * / <nl> - package org . mockito . internal . creation . util ; <nl> - <nl> - import static java . lang . thread . * ; <nl> - <nl> - import java . util . arraylist ; <nl> - import java . util . list ; <nl> - <nl> - / * * <nl> - * inspired on jmock ( thanks jmock guys ! ! ! ) <nl> - * / <nl> - public class searchingclassloader extends classloader { <nl> - <nl> - <nl> - <nl> - private final classloader nexttosearch ; <nl> - <nl> - public searchingclassloader ( classloader parent , classloader nexttosearch ) { <nl> - super ( parent ) ; <nl> - this . nexttosearch = nexttosearch ; <nl> - } <nl> - <nl> - public static classloader combineloadersof ( class < ? > . . . classes ) { <nl> - return combineloadersof ( classes [ 0 ] , classes ) ; <nl> - } <nl> - <nl> - private static classloader combineloadersof ( class < ? > first , class < ? > . . . others ) { <nl> - list < classloader > loaders = new arraylist < classloader > ( ) ; <nl> - <nl> - addifnewelement ( loaders , first . getclassloader ( ) ) ; <nl> - for ( class < ? > c : others ) { <nl> - addifnewelement ( loaders , c . getclassloader ( ) ) ; <nl> - } <nl> - <nl> - / / to support eclipse plug - in tests . <nl> - / / in an eclipse plug - in , we will not be on the system class loader <nl> - / / but in the class loader of the plug - in . <nl> - / / <nl> - / / note : i ' ve been unable to reproduce the error in the test suite . <nl> - addifnewelement ( loaders , searchingclassloader . class . getclassloader ( ) ) ; <nl> - <nl> - / / to support the maven surefire plugin . <nl> - / / note : i ' ve been unable to reproduce the error in the test suite . <nl> - addifnewelement ( loaders , currentthread ( ) . getcontextclassloader ( ) ) ; <nl> - <nl> - / / had to comment that out because it didn ' t work with in - container spring tests <nl> - / / addifnewelement ( loaders , classloader . getsystemclassloader ( ) ) ; <nl> - <nl> - return combine ( loaders ) ; <nl> - } <nl> - <nl> - private static classloader combine ( list < classloader > parentloaders ) { <nl> - classloader loader = parentloaders . get ( parentloaders . size ( ) - 1 ) ; <nl> - <nl> - for ( int i = parentloaders . size ( ) - 2 ; i > = num ; i - - ) { <nl> - loader = new searchingclassloader ( parentloaders . get ( i ) , loader ) ; <nl> - } <nl> - <nl> - return loader ; <nl> - } <nl> - <nl> - private static void addifnewelement ( list < classloader > loaders , classloader c ) { <nl> - if ( c ! = null & & ! loaders . contains ( c ) ) { <nl> - loaders . add ( c ) ; <nl> - } <nl> - } <nl> - <nl> - @ override <nl> - protected class < ? > findclass ( string name ) throws classnotfoundexception { <nl> - if ( nexttosearch ! = null ) { <nl> - return nexttosearch . loadclass ( name ) ; <nl> - } else { <nl> - return super . findclass ( name ) ; / / will throw classnotfoundexception <nl> - } <nl> - } <nl> - } <nl> \ no newline at end of file
import org . mockito . junit . * ; <nl> * return input1 + input2 ; <nl> * } } ) ) . when ( mock ) . execute ( anystring ( ) , anystring ( ) ) ; <nl> * < / code > < / pre > <nl> - * <nl> - * <nl> - * <nl> * / <nl> @ suppresswarnings ( " unchecked " ) <nl> public class mockito extends argumentmatchers { <nl>
public class mockito extends argumentmatchers { <nl> } <nl>  <nl> / * * <nl> - * <nl> + * this api will move soon to a different place . <nl> + * see < a href = " https : / / github . com / mockito / mockito / issues / 577 " > issue num < / a > . <nl> * / <nl> @ deprecated <nl> static mockitodebugger debug ( ) {
class stubbingargmismatches { <nl> } <nl>  <nl> stubbinghint hint = new stubbinghint ( testname ) ; <nl> - <nl> int x = num ; <nl> for ( map . entry < invocation , set < invocation > > m : mismatches . entryset ( ) ) { <nl> hint . appendline ( x + + , " . unused . . . " , m . getkey ( ) . getlocation ( ) ) ; <nl> mmm a / src / main / java / org / mockito / internal / junit / unusedstubbings . java <nl> ppp b / src / main / java / org / mockito / internal / junit / unusedstubbings . java <nl>
class unusedstubbings { <nl> return ; <nl> } <nl>  <nl> - <nl> stubbinghint hint = new stubbinghint ( testname ) ; <nl> int x = num ; <nl> for ( stubbing candidate : unused ) {
public class mockingdetailstest extends testbase { <nl> } <nl>  <nl> @ test <nl> - public void should_handle_null_input ( ) { <nl> - <nl> - / / asserttrue ( new mockitocore ( ) . mockingdetails ( null ) . getinvocations ( ) . isempty ( ) ) ; <nl> + public void getting_interactions_when_input_mock_is_null ( ) { <nl> + try { <nl> + mockingdetails ( null ) <nl> + . getinvocations ( ) ; <nl> + fail ( ) ; <nl> + } catch ( notamockexception e ) { <nl> + assertequals ( " argument passed to mockito . mockingdetails ( ) should be a mock , but is null ! " , e . getmessage ( ) ) ; <nl> + } <nl> + } <nl> + <nl> + @ test <nl> + public void getting_interactions_when_input_mock_is_not_mock ( ) { <nl> + try { <nl> + mockingdetails ( new object ( ) ) <nl> + . getinvocations ( ) ; <nl> + fail ( ) ; <nl> + } catch ( notamockexception e ) { <nl> + assertequals ( " argument passed to mockito . mockingdetails ( ) should be a mock , but is an instance of class java . lang . object ! " , e . getmessage ( ) ) ; <nl> + } <nl> } <nl> }
import static org . junit . assert . fail ; <nl> import static org . mockito . matchers . eq ; <nl> import static org . mockito . mockito . when ; <nl>  <nl> - <nl> - / / @ runwith ( mockitojunitrunner . class ) <nl> + @ runwith ( mockitojunitrunner . silent . class ) <nl> public class invaliduseofmatcherstest { <nl>  <nl> private imethods mock = mockito . mock ( imethods . class ) ;
<nl> - package org . mockito . internal . runners ; <nl> - <nl> - import org . junit . runner . description ; <nl> - import org . junit . runner . manipulation . filter ; <nl> - import org . junit . runner . manipulation . notestsremainexception ; <nl> - import org . junit . runner . notification . runnotifier ; <nl> - <nl> - / * * <nl> - * created by sfaber on num / 22 / 16 . <nl> - * / <nl> - public class verboserunner implements runnerimpl { <nl> - <nl> - <nl> - public verboserunner ( runnerimpl runner ) { <nl> - } <nl> - <nl> - public void run ( runnotifier notifier ) { <nl> - <nl> - } <nl> - <nl> - public description getdescription ( ) { <nl> - return null ; <nl> - } <nl> - <nl> - public void filter ( filter filter ) throws notestsremainexception { <nl> - <nl> - } <nl> - } <nl> mmm a / src / main / java / org / mockito / runners / mockitojunitrunner . java <nl> ppp b / src / main / java / org / mockito / runners / mockitojunitrunner . java <nl>
public class mockitojunitrunner extends runner implements filterable { <nl> } <nl> } <nl>  <nl> - <nl> - public static class verbose extends mockitojunitrunner { <nl> - public verbose ( class < ? > klass ) throws invocationtargetexception { <nl> - super ( new verboserunner ( new runnerfactory ( ) . create ( klass ) ) ) ; <nl> - } <nl> - } <nl> - <nl> private final runnerimpl runner ; <nl>  <nl> public mockitojunitrunner ( class < ? > klass ) throws invocationtargetexception {
import org . mockito . internal . runners . util . testmethodsfinder ; <nl>  <nl> import java . lang . reflect . invocationtargetexception ; <nl>  <nl> + / * * <nl> + * creates instances of mockito junit runner in a safe way , e . g . detecting inadequate version of junit , etc . <nl> + * / <nl> public class runnerfactory { <nl>  <nl> - private final runnerprovider runnerprovider ; <nl> - <nl> - runnerfactory ( runnerprovider runnerprovider ) { <nl> - this . runnerprovider = runnerprovider ; <nl> - } <nl> - <nl> - public runnerfactory ( ) { <nl> - this ( new runnerprovider ( ) ) ; <nl> - } <nl> - <nl> public runnerimpl create ( class < ? > klass ) throws invocationtargetexception { <nl> try { <nl> - <nl> - return runnerprovider . newinstance ( " org . mockito . internal . runners . junit45andhigherrunnerimpl " , klass ) ; <nl> + return new runnerprovider ( ) . newinstance ( " org . mockito . internal . runners . junit45andhigherrunnerimpl " , klass ) ; <nl> } catch ( invocationtargetexception e ) { <nl> if ( ! new testmethodsfinder ( ) . hastestmethods ( klass ) ) { <nl> throw new mockitoexception (
import org . mockito . internal . runners . util . testmethodsfinder ; <nl>  <nl> import java . lang . reflect . invocationtargetexception ; <nl>  <nl> + / * * <nl> + * creates instances of mockito junit runner in a safe way , e . g . detecting inadequate version of junit , etc . <nl> + * / <nl> public class runnerfactory { <nl>  <nl> - private final runnerprovider runnerprovider ; <nl> - <nl> - runnerfactory ( runnerprovider runnerprovider ) { <nl> - this . runnerprovider = runnerprovider ; <nl> - } <nl> - <nl> - public runnerfactory ( ) { <nl> - this ( new runnerprovider ( ) ) ; <nl> - } <nl> - <nl> public runnerimpl create ( class < ? > klass ) throws invocationtargetexception { <nl> try { <nl> - <nl> - return runnerprovider . newinstance ( " org . mockito . internal . runners . junit45andhigherrunnerimpl " , klass ) ; <nl> + return new runnerprovider ( ) . newinstance ( " org . mockito . internal . runners . junit45andhigherrunnerimpl " , klass ) ; <nl> } catch ( invocationtargetexception e ) { <nl> if ( ! new testmethodsfinder ( ) . hastestmethods ( klass ) ) { <nl> throw new mockitoexception (
test { <nl> } <nl> } <nl>  <nl> - <nl> dependencies { <nl> compile ' net . bytebuddy : byte - buddy : 0 . 6 . 11 ' <nl>  <nl>
<nl> - pick num bab8bf in progress of decoupling mockito from hamcrest <nl> - pick num daa963 removed commented out code <nl> - pick a813d42 deprecated the current argumentmatcher <nl> - pick f2b3655 made the current api delegate to the new api <nl> - pick ed20c0e added a <nl> \ no newline at end of file <nl> binary files a / lib / build / bnd - 0 . 0 . 313 . jar and / dev / null differ
<nl> apply plugin : ' osgi ' <nl>  <nl> - / * <nl> afterevaluate { <nl> tasks . matching { it . name = = ' jar ' } . all { jar - > <nl> jar . manifest { <nl>
import org . mockito . argumentmatcher ; <nl> * that have impacted our users in past . mockito offers a dedicated api to match arguments <nl> * via { @ link argumentmatcher } . <nl> * hamcrest integration is provided so that users can take advantage of existing hamcrest matchers . <nl> - * < p > <nl> - * <nl> - * argumentmatcher ? ? ? <nl> * <nl> * example : <nl> * < pre >
public interface argumentmatcher < t > { <nl> * the argument is not using generic type in order to force explicit casting in the implementation . <nl> * this way it is easier to debug when incompatible arguments are passed to the matchers . <nl> * you have to trust us on this one . <nl> - * <nl> * < p > <nl> * see the example in the top level javadoc for { @ link argumentmatcher } <nl> *
<nl>  <nl> package org . mockitousage . matchers ; <nl>  <nl> + import org . hamcrest . basematcher ; <nl> + import org . hamcrest . description ; <nl> + import org . junit . test ; <nl> + import org . mockito . mock ; <nl> + import org . mockito . exceptions . verification . junit . argumentsaredifferent ; <nl> + import org . mockitousage . imethods ; <nl> import org . mockitoutil . testbase ; <nl>  <nl> - public class hamcrestmatcherstest extends testbase { <nl> + import static org . mockito . mockito . * ; <nl> + import static org . mockito . hamcrest . mockitohamcrest . argthat ; <nl>  <nl> - <nl> + public class hamcrestmatcherstest extends testbase { <nl>  <nl> - / * <nl> private final class containsx extends basematcher < string > { <nl> public boolean matches ( object o ) { <nl> return ( ( string ) o ) . contains ( " x " ) ; <nl>
public class returnsemptyvalues implements answer < object > , serializable { <nl> } else if ( type = = linkedhashmap . class ) { <nl> return new linkedhashmap < object , object > ( ) ; <nl> } <nl> - <nl> - <nl> / / let ' s not care about the rest of collections . <nl> return null ; <nl> } <nl>  <nl> - } <nl> \ no newline at end of file <nl> + } <nl> mmm a / test / org / mockito / internal / stubbing / defaultanswers / returnsemptyvaluestest . java <nl> ppp b / test / org / mockito / internal / stubbing / defaultanswers / returnsemptyvaluestest . java <nl>
public interface releasestep extends operation { <nl>  <nl> void performrollback ( ) ; <nl>  <nl> - / * * <nl> - * may return null . <nl> - * / <nl> - operation getcleanup ( ) ; <nl> + void performcleanup ( ) ; <nl> }
class pluginloader { <nl> throw new mockitoexception ( " failed to load " + service , e ) ; <nl> } <nl>  <nl> - <nl> - list < t > result = new arraylist < t > ( ) ; <nl> try { <nl> string foundpluginclass = new pluginfinder ( pluginswitch ) . findpluginclass ( iterables . toiterable ( resources ) ) ; <nl> if ( foundpluginclass ! = null ) { <nl> class < ? > pluginclass = loader . loadclass ( foundpluginclass ) ; <nl> object plugin = pluginclass . newinstance ( ) ; <nl> - result . add ( service . cast ( plugin ) ) ; <nl> + return service . cast ( plugin ) ; <nl> } <nl> - return result ; <nl> + return null ; <nl> } catch ( exception e ) { <nl> throw new mockitoconfigurationexception ( <nl> " failed to load " + service + " implementation declared in " + resources , e ) ;
import java . util . list ; <nl>  <nl> import static java . util . arrays . aslist ; <nl> import static org . junit . assert . assertequals ; <nl> + import static org . junit . assert . fail ; <nl> import static org . mockito . mockito . mock ; <nl>  <nl> - <nl> - / / that validates that switcher can disable a plugin <nl> public class pluginswitchertest { <nl>  <nl> @ test <nl> public void plugin_switcher_is_used ( ) { <nl> mock ( list . class ) ; <nl> - assertequals ( mypluginswitcher . invokedfor , aslist ( mystacktracecleanerprovider . class . getname ( ) ) ) ; <nl> + assertequals ( mypluginswitcher . invokedfor , aslist ( mymockmaker . class . getname ( ) , mystacktracecleanerprovider . class . getname ( ) ) ) ; <nl> + } <nl> + <nl> + @ test <nl> + public void uses_custom_mock_maker ( ) { <nl> + / / when <nl> + mymockmaker . explosive . set ( new object ( ) ) ; <nl> + <nl> + / / when <nl> + try { <nl> + mock ( list . class ) ; <nl> + fail ( ) ; <nl> + } catch ( exception e ) { } <nl> + } <nl> + <nl> + @ after <nl> + public void after ( ) { <nl> + mymockmaker . explosive . remove ( ) ; <nl> } <nl> } <nl> mmm / dev / null <nl> ppp b / subprojects / exttest / src / test / resources / mockito - extensions / org . mockito . plugins . mockmaker <nl>
public class mockutil { <nl> } <nl>  <nl> public boolean isspy ( object mock ) { <nl> - <nl> - return ismockitomock ( mock ) & & <nl> - ( getmocksettings ( mock ) . getspiedinstance ( ) ! = null <nl> - | | getmocksettings ( mock ) . isusingconstructor ( ) ) ; <nl> + return ismockitomock ( mock ) & & getmocksettings ( mock ) . getdefaultanswer ( ) = = mockito . calls_real_methods ; <nl> } <nl>  <nl> private < t > boolean ismockitomock ( t mock ) { <nl> mmm a / test / org / mockito / internal / util / mockutiltest . java <nl> ppp b / test / org / mockito / internal / util / mockutiltest . java <nl>
public class spyannotationengine implements annotationengine { <nl> class < ? > enclosing = type . getenclosingclass ( ) ; <nl> if ( enclosing ! = null ) { <nl> if ( ! enclosing . isinstance ( testinstance ) ) { <nl> - throw new mockitoexception ( " if you are mocking an inner class please ensure the instance of the outer class is supplied via withsettings ( ) . outerinstance ( ) " <nl> - + " \nthe outer class is : ' " + enclosing . getsimplename ( ) + " ' " ) ; <nl> + throw new mockitoexception ( " @ spy annotation can only initialize inner classes declared in the test . " <nl> + + " inner class : ' " + type . getsimplename ( ) + " ' , " <nl> + + " outer class : ' " + enclosing . getsimplename ( ) + " ' . " ) ; <nl> } <nl> - <nl> - / / if ( modifier . isprivate ( type . getdeclaredconstructor ( enclosing ) . getmodifiers ( ) ) ) { <nl> - / / throw new assertionerror ( ) ; <nl> - / / throw new mockitoexception ( " unable to initialize @ spy annotated field ' " + field . getname ( ) + " ' . " <nl> - / / + " cannot spy inner type ' " + type . getsimplename ( ) + " ' because it has private constructor . " ) ; <nl> - / / } <nl> return mockito . mock ( type , settings <nl> . useconstructor ( ) <nl> . outerinstance ( testinstance ) ) ; <nl> mmm a / test / org / mockito / internal / creation / instance / constructorinstantiatortest . java <nl> ppp b / test / org / mockito / internal / creation / instance / constructorinstantiatortest . java <nl>
import java . util . set ; <nl> import java . util . zip . zipentry ; <nl> import java . util . zip . zipfile ; <nl>  <nl> - <nl> + import static java . lang . string . format ; <nl> + <nl> class zipcompare { <nl>  <nl> + private final static logger log = loggerfactory . getlogger ( zipcompare . class ) ; <nl> + <nl> boolean comparezips ( string filepath1 , string filepath2 ) { <nl> zipfile file1 ; <nl> try { <nl>
package org . mockito . release . notes . util ; <nl>  <nl> import java . io . * ; <nl>  <nl> - <nl> + / * * <nl> + * io utils . a bit of reinventing the wheel but we don ' t want extra dependencies at this stage and we want to be java . <nl> + * / <nl> public class ioutil { <nl>  <nl> - public static string readstream ( inputstream is ) { <nl> + / * * <nl> + * reads string from the stream and closes it <nl> + * / <nl> + public static string readfully ( inputstream stream ) { <nl> bufferedreader r = null ; <nl> try { <nl> - r = new bufferedreader ( new inputstreamreader ( is ) ) ; <nl> - return readnow ( is ) ; <nl> + r = new bufferedreader ( new inputstreamreader ( stream ) ) ; <nl> + return readnow ( stream ) ; <nl> } catch ( exception e ) { <nl> throw new runtimeexception ( " problems reading stream " , e ) ; <nl> } finally { <nl>
import java . util . list ; <nl> * contribution of given author <nl> * / <nl> class contribution { <nl> - string email ; / / identifies the contributor <nl> - string author ; <nl> - list < gitcommit > commits = new linkedlist < gitcommit > ( ) ; <nl> + / / email identifies the contributor , author alias not necessarily <nl> + final string email ; <nl> + final string author ; <nl> + final list < gitcommit > commits = new linkedlist < gitcommit > ( ) ; <nl> + <nl> + contribution ( gitcommit commit ) { <nl> + email = commit . email ; <nl> + author = commit . author ; <nl> + commits . add ( commit ) ; <nl> + } <nl>  <nl> void add ( gitcommit commit ) { <nl> - if ( email = = null ) { <nl> - email = commit . email ; <nl> - author = commit . author ; <nl> - <nl> - / / we could base on existence of space ( this hints that it ' s a proper first name + surname ) <nl> - } <nl> - / / email identifies the contributor , author alias not necessarily <nl> assert email . equals ( commit . email ) ; <nl> commits . add ( commit ) ; <nl> } <nl>
<nl> - package org . mockito . release . notes ; <nl> - <nl> - class contribution { <nl> - string email / / identifies the contributor <nl> - string author <nl> - collection < gitcommit > commits = new linkedlist < gitcommit > ( ) / / the commits <nl> - void add ( gitcommit commit ) { <nl> - if ( email = = null ) { <nl> - email = commit . email <nl> - author = commit . author <nl> - <nl> - / / we could base on existence of space ( this hints that it ' s a proper first name + surname ) <nl> - } <nl> - assert email = = commit . email / / email identifies the contributor , author alias not necessarily <nl> - commits < < commit <nl> - } <nl> - string tostring ( ) { <nl> - " $ author : $ { commits . size ( ) } " <nl> - } <nl> - } <nl> mmm / dev / null <nl> ppp b / buildsrc / src / main / groovy / org / mockito / release / notes / contribution . java <nl>
public class creatingmockswithconstructortest extends testbase { <nl> } <nl>  <nl> @ test <nl> - @ ignore <nl> public void prevents_across_jvm_serialization_with_constructor ( ) { <nl> - fail ( ) ; <nl> + try { <nl> + / / when <nl> + mock ( abstractmessage . class , withsettings ( ) . useconstructor ( ) . serializable ( serializablemode . across_classloaders ) ) ; <nl> + / / then <nl> + fail ( ) ; <nl> + } catch ( mockitoexception e ) { <nl> + assertequals ( " mocks instantiated with constructor cannot be combined with " + serializablemode . across_classloaders + " serialization mode . " , e . getmessage ( ) ) ; <nl> + } <nl> } <nl> }
public class creatingmockswithconstructortest extends testbase { <nl> } <nl>  <nl> @ test <nl> - @ ignore <nl> - public void prevents_mocking_interfaces_with_constructor ( ) { <nl> - try { <nl> - / / when <nl> - mock ( imethods . class , withsettings ( ) . useconstructor ( ) ) ; <nl> - / / then <nl> - fail ( ) ; <nl> - } catch ( mockitoexception e ) { } <nl> + public void mocking_interfaces_with_constructor ( ) { <nl> + / / at the moment this is allowed however we can be more strict if needed <nl> + / / there is not much sense in creating a spy of an interface <nl> + mock ( imethods . class , withsettings ( ) . useconstructor ( ) ) ; <nl> + spy ( imethods . class ) ; <nl> } <nl>  <nl> @ test
public class creatingmockswithconstructortest extends testbase { <nl> } <nl>  <nl> @ test <nl> - @ ignore <nl> public void mocking_inner_classes_with_wrong_outer_instance ( ) { <nl> - fail ( ) ; <nl> + try { <nl> + / / when <nl> + mock ( innerclass . class , withsettings ( ) . useconstructor ( ) . outerinstance ( " foo " ) . defaultanswer ( calls_real_methods ) ) ; <nl> + / / then <nl> + fail ( ) ; <nl> + } catch ( mockitoexception e ) { <nl> + assertequals ( " unable to create mock instance of type ' innerclass ' " , e . getmessage ( ) ) ; <nl> + assertcontains ( " please ensure that the outer instance has correct type and that the target class has parameter - less constructor " , e . getcause ( ) . getmessage ( ) ) ; <nl> + } <nl> } <nl>  <nl> @ test
$ improvements <nl> def issue = new issue . smart ( i ) <nl> if ( issue . exists ( ) & & ! issue . isopen ( ) ) { <nl> out < < new improvement ( id : issue . number ( ) , title : issue . title ( ) , url : issue . htmlurl ( ) , <nl> - labels : iterabletolist ( issue . labels ( ) . iterate ( ) ) . collect { label label - > label . name ( ) } ) <nl> + labels : issue . labels ( ) . iterate ( ) . collect { label label - > label . name ( ) } ) <nl> } <nl> } <nl> / / new onecategoryimprovementset ( improvements : out , ignorepattern : ignorepattern ) <nl> new labelledimprovementset ( out , ignorepattern , improvementsprinter ) <nl> } <nl>  <nl> - <nl> - private static < t > list < t > iterabletolist ( iterable < t > iterable ) { <nl> - def list = [ ] <nl> - def iterator = iterable . iterator ( ) <nl> - while ( iterator . hasnext ( ) ) { <nl> - list . add ( iterator . next ( ) ) <nl> - } <nl> - list <nl> - } <nl> - <nl> string getpreviousversion ( file notesfile ) { <nl> println " attempting to figure out the previous version from the release notes file " <nl> return notesfile . withreader {
bintrayupload { <nl> } <nl> } <nl>  <nl> - <nl> - / / any of the jars are different than the previous version : <nl> - / / core jar , core javadoc jar , core sources jar , core pom file <nl> - / / all jar , all javadoc jar , all sources jar , all pom fil <nl> task ( " release " ) { <nl> dependson bintrayupload , releaseneeded <nl> onlyif { releaseneeded . needed } <nl>
private void commitreleasenotes ( string buildinfo ) { <nl> run " git " , " commit " , " - m " , ' " update release notes ' + buildinfo + ' " ' , " $ notesfile " as string <nl> } <nl>  <nl> - private void pushtag ( string currentversion , string buildinfo , maskedarg pushtarget ) { <nl> + private void createtag ( string currentversion , string buildinfo ) { <nl> string tag = " v $ { currentversion } " <nl> string tagmessage = " create tag $ tag $ { buildinfo } " <nl> run " git " , " tag " , " - a " , tag , " - m " , " $ tagmessage " as string <nl> - run " git " , " push " , pushtarget , tag <nl> } <nl>  <nl> private void configuregit ( ) { <nl> - run " git " , " config " , " user . email " , " szczepiq @ gmail . com " <nl> - run " git " , " config " , " user . name " , " szczepan faber " <nl> + run " git " , " config " , " user . email " , " continuous . delivery . drone @ gmail . com " <nl> + run " git " , " config " , " user . name " , " continuous delivery drone " <nl> } <nl>  <nl> private void commitincrementedversion ( string currentversion , string buildinfo ) { <nl> - run " . / gradlew " , " incrementversion " <nl> - string nextversion = project . ext . loadversion ( ) <nl> + string nextversion = project . incrementversion ( ) <nl> string message = " increment version ' $ currentversion ' - > ' $ nextversion ' $ buildinfo " <nl> run " git " , " commit " , " - m " , " $ message " as string , " version . properties " <nl> } <nl>
logger . lifecycle " version : $ project . version " <nl> task incrementversion { <nl> description " increments version in ' version . properties ' file . " <nl> dolast { <nl> - try { <nl> - list numbers = project . version . split ( ' \ \ . ' ) <nl> - <nl> - int micro = numbers . pop ( ) as integer <nl> - numbers < < micro + num <nl> - def newversion = numbers . join ( ' . ' ) <nl> - def updatedcontent = versionfile . text . replaceall ( " ( ? s ) version = ( . * ? ) \n " , " version = $ newversion\n " ) <nl> - versionfile . text = updatedcontent <nl> - logger . lifecycle ( " current content of ' { } ' : \n - - - - - - - - - - \n { } \n - - - - - - - - - - " , versionfile . name , updatedcontent ) <nl> - } catch ( exception e ) { <nl> - throw new gradleexception ( " unable to increment minor version . " , e ) <nl> - } <nl> + incrementversion ( ) <nl> + } <nl> + } <nl> + <nl> + ext . incrementversion = { <nl> + try { <nl> + list numbers = project . version . split ( ' \ \ . ' ) <nl> + int micro = numbers . pop ( ) as integer <nl> + numbers < < micro + num <nl> + def newversion = numbers . join ( ' . ' ) <nl> + def updatedcontent = versionfile . text . replaceall ( " ( ? s ) version = ( . * ? ) \n " , " version = $ newversion\n " ) <nl> + versionfile . text = updatedcontent <nl> + logger . lifecycle ( " current content of ' { } ' : \n - - - - - - - - - - \n { } \n - - - - - - - - - - " , versionfile . name , updatedcontent ) <nl> + return newversion <nl> + } catch ( exception e ) { <nl> + throw new gradleexception ( " unable to increment minor version . " , e ) <nl> } <nl> } <nl> \ no newline at end of file
public class parentclassnotpublicveryweirdbugtest extends testbase { <nl> / / mockito thinks that we ' re stubbing void ' clear ' method here and reports that boolean value cannot stub void method <nl> when ( clazzmock . isvalid ( ) ) . thenreturn ( true ) ; <nl> fail ( ) ; <nl> - } catch ( mockitoexception e ) { <nl> + } catch ( cannotstubvoidmethodwithreturnvalue e ) { <nl> assertions . assertthat ( e . getmessage ( ) ) <nl> . contains ( mockitolimitations . non_public_parent ) ; <nl> }
task ( release ) { <nl> maskedarg pushtarget = new maskedarg ( value : " https : / / szczepiq : $ { system . env . gh_token } @ github . com / mockito / mockito . git " ) <nl>  <nl> / / release process . should * not * run concurrently . <nl> - <nl> run " . / gradlew " , " bintrayupload " <nl> configuregit ( ) <nl> run " git " , " pull " , " - - depth " , " 500 " / / we need good chunk of recent commits to build release notes correctly <nl>
task ( release ) { <nl> / / release process . should * not * run concurrently . <nl> run " . / gradlew " , " bintrayupload " <nl> configuregit ( ) <nl> - / / updatereleasenotes ( ) <nl> - / / commitreleasenotes ( buildinfo ) <nl> + run " git " , " pull " , " - - depth " , " 500 " / / we need good chunk of recent commits to build release notes correctly <nl> + updatereleasenotes ( ) <nl> + commitreleasenotes ( buildinfo ) <nl> pushtag ( currentversion , buildinfo , pushtarget ) <nl> commitupdatedjavadoc ( buildinfo ) <nl>  <nl>
task ( release ) { <nl> / / release process . should * not * run concurrently . <nl> run " . / gradlew " , " bintrayupload " <nl> configuregit ( ) <nl> - <nl> + updatereleasenotes ( ) <nl> + commitreleasenotes ( buildinfo ) <nl> pushtag ( currentversion , buildinfo , pushtarget ) <nl> commitupdatedjavadoc ( buildinfo ) <nl>  <nl>
publishing . publications . all { <nl>  <nl> def license = root . appendnode ( ' licenses ' ) . appendnode ( ' license ' ) <nl> license . appendnode ( ' name ' , ' the mit license ' ) <nl> - <nl> - license . appendnode ( ' url ' , ' http : / / code . google . com / p / mockito / wiki / license ' ) <nl> + license . appendnode ( ' url ' , ' http : / / github . com / mockito / mockito / blob / master / license ' ) <nl> license . appendnode ( ' distribution ' , ' repo ' ) <nl>  <nl> root . appendnode ( ' scm ' ) . appendnode ( ' url ' , ' http : / / github . com / mockito / mockito ' )
buildscript { <nl> } <nl> } <nl>  <nl> + apply plugin : ' maven - publish ' <nl> + <nl> apply from : ' gradle / version . gradle ' <nl> apply from : " gradle / ide . gradle " <nl> + apply from : ' gradle / release . gradle ' <nl> + apply from : ' gradle / coverage . gradle ' <nl>  <nl> - group = ' org . mockito ' <nl> - description = ' core api and implementation . ' <nl> - <nl> - <nl> allprojects { <nl> - apply plugin : ' java ' <nl> - <nl> repositories { <nl> jcenter ( ) <nl> } <nl> } <nl>  <nl> - apply plugin : ' maven - publish ' <nl> - apply from : ' gradle / release . gradle ' <nl> - <nl> + group = ' org . mockito ' <nl> + description = ' core api and implementation . ' <nl> sourcecompatibility = num . 5 <nl> targetcompatibility = num . 5 <nl>  <nl>
dependencies { <nl> testutil sourcesets . test . output <nl> } <nl>  <nl> - <nl> - / / experimental : coverage <nl> - / / configure code coverage <nl> - apply plugin : ' cobertura ' <nl> - apply plugin : ' coveralls ' <nl> - cobertura . coverageformats = [ ' html ' , ' xml ' ] / / coveralls plugin depends on xml format report <nl> - / / cobertura . coverageignoretrivial = true <nl> - <nl> def commonjarcontent = copyspec { <nl> / / source <nl> from ( sourcesets . main . allsource ) <nl> mmm / dev / null <nl> ppp b / gradle / coverage . gradle <nl>
<nl> import org . apache . xalan . xsltc . cmdline . compile <nl>  <nl> - version = ' 1 . 9 . 8 ' <nl> + properties props = new properties ( ) <nl> + props . load ( new fileinputstream ( " $ { rootproject . projectdir } / version . properties " ) ) <nl> + <nl> + version = props . version <nl> group = ' org . mockito ' <nl> description = ' core api and implementation . ' <nl>  <nl>
<nl> description = " mockito for testng " <nl>  <nl> + properties props = new properties ( ) <nl> + props . load ( new fileinputstream ( " $ { rootproject . projectdir } / version . properties " ) ) <nl> + <nl> group = ' org . mockito ' <nl> archivesbasename = ' mockito - testng ' <nl> - version = ' 1 . 0 ' <nl> + version = props [ ' mockito . testng . version ' ] <nl>  <nl> repositories { <nl> mavencentral ( ) <nl> } <nl>  <nl> + jar { <nl> + manifest . attributes [ " created - by " ] = <nl> + " $ { system . getproperty ( " java . version " ) } ( $ { system . getproperty ( " java . specification . vendor " ) } ) " <nl> + manifest . attributes [ " implementation - title " ] = project . name <nl> + manifest . attributes [ " implementation - version " ] = project . version <nl> + <nl> + from ( " $ { rootproject . projectdir } " ) { <nl> + include " license " <nl> + include " notice " <nl> + into " meta - inf " <nl> + expand ( copyright : new date ( ) . format ( " yyyy " ) , version : project . version ) <nl> + } <nl> + <nl> + } <nl> + <nl> + task sourcesjar ( type : jar , dependson : classes ) { <nl> + classifier = " sources " <nl> + from sourcesets . main . alljava . srcdirs <nl> + include " * * / * . java " , " * * / * . aj " <nl> + } <nl> + <nl> + artifacts { <nl> + archives sourcesjar <nl> + } <nl> + <nl> + uploadarchives { <nl> + repositories { <nl> + mavendeployer { <nl> + repository ( url : " file : / / $ { rootproject . projectdir } / target / maven / repository " ) <nl> + } <nl> + } <nl> + } <nl> + <nl> dependencies { <nl> compile project . rootproject <nl> - / / compile ' org . mockito : mockito - core : 1 . 9 . 5 ' <nl> compile ' org . testng : testng : 6 . 3 . 1 ' <nl> - <nl> testcompile ' org . easytesting : fest - assert : 1 . 4 ' <nl> } <nl>  <nl> mmm a / version . properties <nl> ppp b / version . properties <nl>
public class acrossjvmserializationfeature implements serializable { <nl> * @ return the marker if this is a mockito proxy class , otherwise returns a void marker . <nl> * / <nl> private string mockitoproxyclassmarker ( class < ? > cl ) { <nl> - <nl> - if ( factory . class . isassignablefrom ( cl ) ) { <nl> + if ( mockutil . ismock ( cl ) ) { <nl> return " mockitoproxymarker " ; <nl> } else { <nl> return " " ; <nl> mmm a / src / org / mockito / internal / util / mockutil . java <nl> ppp b / src / org / mockito / internal / util / mockutil . java <nl>
public class basicstubbingtest extends testbase { <nl> try { <nl> verify ( localmock , atleastonce ( ) ) . objectreturningmethod ( eq ( 200 ) ) ; <nl> fail ( ) ; <nl> - <nl> - } catch ( notamockexception e ) { } <nl> - <nl> + } catch ( cannotverifystubonlymock e ) { } <nl> } <nl> - <nl> }
import org . mockito . internal . progress . mockingprogressimpl ; <nl> import org . mockito . internal . stubbing . answers . returns ; <nl> import org . mockito . internal . stubbing . answers . throwsexception ; <nl> import org . mockito . invocation . invocation ; <nl> - import org . mockito . mock . mockcreationsettings ; <nl> import org . mockitoutil . testbase ; <nl>  <nl> - <nl> - public class mockitostubbertest extends testbase { <nl> + public class invocationcontainerimplstubbingtest extends testbase { <nl>  <nl> private invocationcontainerimpl invocationcontainerimpl ; <nl> private invocationcontainerimpl invocationcontainerimplstubonly ; <nl> mmm a / test / org / mockito / internal / stubbing / defaultanswers / returnsmockstest . java <nl> ppp b / test / org / mockito / internal / stubbing / defaultanswers / returnsmockstest . java <nl>
public class returnsmockstest extends testbase { <nl> } <nl>  <nl> @ test <nl> - <nl> public void should_return_mock_value_for_interface ( ) throws exception { <nl> object interfacemock = values . returnvaluefor ( foointerface . class ) ; <nl> asserttrue ( new mockutil ( ) . ismock ( interfacemock ) ) ;
<nl> - / * <nl> - * copyright ( c ) num mockito contributors <nl> - * this program is made available under the terms of the mit license . <nl> - * / <nl> - <nl> - package org . mockito . internal . verification ; <nl> - <nl> - import org . mockito . internal . util . collections . listutil ; <nl> - import org . mockito . invocation . invocation ; <nl> - <nl> - import java . io . serializable ; <nl> - import java . util . collections ; <nl> - import java . util . list ; <nl> - import org . mockito . internal . util . objectmethodsguru ; <nl> - import org . mockito . internal . util . collections . listutil . filter ; <nl> - <nl> - <nl> - public class registeredinvocationsstubonly implements registeredinvocations , serializable { <nl> - <nl> - private static final long serialversionuid = - 2674402327380736235l ; <nl> - <nl> - private final threadlocal < invocation > lastinvocation = new threadlocal < invocation > ( ) ; <nl> - <nl> - public void add ( invocation invocation ) { <nl> - this . lastinvocation . set ( invocation ) ; <nl> - } <nl> - <nl> - public void removelast ( ) { <nl> - this . lastinvocation . remove ( ) ; <nl> - } <nl> - <nl> - public list < invocation > getall ( ) { <nl> - if ( this . lastinvocation . get ( ) = = null ) { <nl> - return collections . emptylist ( ) ; <nl> - } <nl> - <nl> - list < invocation > copiedlist = collections . singletonlist ( this . lastinvocation . get ( ) ) ; <nl> - return listutil . filter ( copiedlist , new removetostring ( ) ) ; <nl> - } <nl> - <nl> - public boolean isempty ( ) { <nl> - return ( this . lastinvocation . get ( ) = = null ) ; <nl> - } <nl> - <nl> - private static class removetostring implements filter < invocation > { <nl> - public boolean isout ( invocation invocation ) { <nl> - return new objectmethodsguru ( ) . istostring ( invocation . getmethod ( ) ) ; <nl> - } <nl> - } <nl> - <nl> - } <nl> mmm / dev / null <nl> ppp b / src / org / mockito / internal / verification / singleregisteredinvocation . java <nl>
public abstract class fields { <nl> this . instancefields = instancefields ; <nl> } <nl>  <nl> - <nl> public instancefields filter ( filter < instancefield > withfilter ) { <nl> return new instancefields ( instance , listutil . filter ( instancefields , withfilter ) ) ; <nl> } <nl> mmm a / subprojects / testng / src / main / java / org / mockito / testng / mockitobeforetestngmethod . java <nl> ppp b / subprojects / testng / src / main / java / org / mockito / testng / mockitobeforetestngmethod . java <nl>
public class mockitobeforetestngmethod { <nl> } <nl>  <nl> private void initializecaptors ( object instance ) { <nl> - / * <nl> - * <nl> - * / <nl> + list < instancefield > instancefields = fields . allfieldsinhierarchy ( instance ) . filter ( notannotatedby ( captor . class ) ) . instancefields ( ) ; <nl> + for ( instancefield instancefield : instancefields ) { <nl> + new captorannotationprocessor ( ) . process ( instancefield . annotation ( captor . class ) , instancefield . jdkfield ( ) ) ; <nl> + } <nl> } <nl>  <nl> private void markasinitialized ( object instance ) {
import org . mockito . exceptions . printableinvocation ; <nl> public interface invocationlistener { <nl>  <nl> / * * <nl> - * called when a method on the listener ' s mock is invoked . <nl> + * called when a method on the listener ' s mock was invoked and returned normally . <nl> * <nl> * exceptions during this callback are treated as fatal errors . <nl> * <nl> - * <nl> - * <nl> - * @ param invocation information on the happening method call , never { @ code null } . <nl> + * @ param invocation information on the happening method call , never { @ code null } <nl> + * @ param returnvalue whatever it was that the method returned , may be { @ code null } <nl> + * @ param locationofstubbing indicates where the method was stubbed , and { @ code null } if it was not <nl> * @ throws runtimeexception on fatal errors <nl> * / <nl> void invokingwithreturnvalue ( printableinvocation invocation , object returnvalue , string locationofstubbing ) ; <nl>  <nl> + / * * <nl> + * called when a method on the listener ' s mock was invoked and threw an exception . <nl> + * <nl> + * errors are not reported , as they usually indicate some severe vm error , that ought <nl> + * to be propagated and is typically not thrown by your code to begin with . <nl> + * <nl> + * note that the exception is not necessarily caused by stubbing the method with it , but may also <nl> + * be the result of incorrect usage of the mockito api or even a bug inside mockito . <nl> + * <nl> + * exceptions during this callback are treated as fatal errors . <nl> + * <nl> + * @ param invocation information on the happening method call , never { @ code null } <nl> + * @ param exception the exception that was thrown <nl> + * @ param locationofstubbing indicates where the method was stubbed , and { @ code null } if it was not <nl> + * @ throws runtimeexception on fatal errors <nl> + * / <nl> void invokingwithexception ( printableinvocation invocation , exception exception , string locationofstubbing ) ; <nl> - <nl> }
public class returnssmartnullstest extends testbase { <nl> assertequals ( 0 , answer . answer ( invocationof ( hasprimitivemethods . class , " floatmethod " ) ) ) ; <nl> assertequals ( 0 , answer . answer ( invocationof ( hasprimitivemethods . class , " doublemethod " ) ) ) ; <nl> } <nl> - <nl> + <nl> interface foo { <nl> foo get ( ) ; <nl> + foo withargs ( string onearg , string otherarg ) ; <nl> } <nl> - <nl> + <nl> @ test <nl> public void shouldreturnanobjectthatfailsonanymethodinvocationfornonprimitives ( ) throws throwable { <nl> answer < object > answer = new returnssmartnulls ( ) ; <nl> - <nl> + <nl> foo smartnull = ( foo ) answer . answer ( invocationof ( foo . class , " get " ) ) ; <nl> - <nl> + <nl> try { <nl> smartnull . get ( ) ; <nl> fail ( ) ; <nl> } catch ( smartnullpointerexception expected ) { } <nl> } <nl> - <nl> + <nl> @ test <nl> public void shouldreturnanobjectthatallowsobjectmethods ( ) throws throwable { <nl> answer < object > answer = new returnssmartnulls ( ) ; <nl> - <nl> + <nl> foo smartnull = ( foo ) answer . answer ( invocationof ( foo . class , " get " ) ) ; <nl> - <nl> - <nl> + <nl> assertequals ( " smartnull returned by unstubbed get ( ) method on mock " , smartnull + " " ) ; <nl> } <nl> + <nl> + @ test <nl> + public void shouldprinttheparameterswhencallingamethodwithargs ( ) throws throwable { <nl> + answer < object > answer = new returnssmartnulls ( ) ; <nl> + <nl> + foo smartnull = ( foo ) answer . answer ( invocationof ( foo . class , " withargs " , " oompa " , " lumpa " ) ) ; <nl> + <nl> + assertequals ( " smartnull returned by unstubbed withargs ( oompa , lumpa ) method on mock " , smartnull + " " ) ; <nl> + } <nl> }
public class scenarioprintertest extends testbase { <nl> / / then <nl> assertcontains ( " 1 . - > at " , out ) ; <nl> assertcontains ( " 2 . [ ? ] - > at " , out ) ; <nl> - <nl> + } <nl> + <nl> + @ test <nl> + public void shouldnotprintinvocationswhensingleunwanted ( ) { <nl> + / / given <nl> + invocation unverified = new invocationbuilder ( ) . differentmethod ( ) . toinvocation ( ) ; <nl> + <nl> + / / when <nl> + string out = sp . print ( ( list ) aslist ( unverified ) ) ; <nl> + <nl> + / / then <nl> + assertcontains ( " actually , above is the only interaction with this mock . " , out ) ; <nl> } <nl> } <nl> \ no newline at end of file <nl> mmm a / test / org / mockitousage / verification / nomoreinteractionsverificationtest . java <nl> ppp b / test / org / mockitousage / verification / nomoreinteractionsverificationtest . java <nl>
public class verbosemockitojunitrunner extends runner implements filterable { <nl>  <nl> private runnerimpl runner ; <nl>  <nl> - <nl> public verbosemockitojunitrunner ( class < ? > klass ) throws invocationtargetexception { <nl> this ( new runnerfactory ( ) . create ( klass ) ) ; <nl> }
<nl> - / * <nl> - * copyright ( c ) num mockito contributors <nl> - * this program is made available under the terms of the mit license . <nl> - * / <nl> - package org . mockitousage . stubbing ; <nl> - <nl> - import org . junit . test ; <nl> - import org . mockitoutil . testbase ; <nl> - <nl> - <nl> - public class returningmockvaluestest extends testbase { <nl> - <nl> - @ test <nl> - public void should ( ) throws exception { <nl> - <nl> - } <nl> - }
public class captorannotationtest extends testbase { <nl> } catch ( mockitoexception e ) { } <nl> } <nl>  <nl> - <nl> - / / public static class wrongwildcardgenerics { <nl> - / / @ captor <nl> - / / argumentcaptor < ? extends list > wrongtype ; <nl> - / / } <nl> - / / <nl> - / / @ test <nl> - / / public void shouldscreamwhenwildcardgenericsareusedwrong ( ) { <nl> - / / mockitoannotations . initmocks ( new wrongwildcardgenerics ( ) ) ; <nl> - / / } <nl> - <nl> public static class tomanyannotations { <nl> @ captor <nl> @ mock
import static java . lang . annotation . elementtype . field ; <nl> @ documented <nl> @ target ( { field } ) <nl> @ retention ( retentionpolicy . runtime ) <nl> - public @ interface injectmock { <nl> - <nl> - } <nl> + public @ interface injectmock { }
import org . mockito . spy ; <nl> import org . mockito . exceptions . base . mockitoexception ; <nl> import org . mockitoutil . testbase ; <nl>  <nl> - @ suppresswarnings ( " unchecked " ) <nl> + @ suppresswarnings ( { " unchecked " , " unused " } ) <nl> public class wrongsetofannotationstest extends testbase { <nl> - <nl> - <nl>  <nl> @ test ( expected = mockitoexception . class ) <nl> public void shouldnotallowmockandspy ( ) throws exception { <nl>
import org . mockito . stubbing . answer ; <nl> / * * <nl> * enumeration of pre - configured mock answers <nl> * / <nl> - <nl> public enum answers { <nl>  <nl> returns_defaults ( new globallyconfiguredanswer ( ) ) ,
public class covariantoverridetest extends testbase { <nl> assertequals ( " foo " , mock . callme ( ) ) ; / / passes <nl> } <nl>  <nl> - @ ignore <nl> + @ ignore / / we don ' t know how to implement it - covariant override <nl> @ test <nl> public void returnfoo4 ( ) { <nl> returnsstring mock = mock ( returnsstring . class ) ;
public class mockito extends matchers { <nl> } <nl>  <nl> / * <nl> - * helps debugging failing tests . <nl> - * < p > <nl> - * <nl> + * helps debugging failing tests . not yet ready . <nl> * / <nl> - public static mockitodebugger debug ( ) { <nl> + static mockitodebugger debug ( ) { <nl> return new mockitodebuggerimpl ( ) ; <nl> } <nl> }
public class consolespammingmockitojunitrunner extends runner { <nl> progress . setlistener ( new collectcreatedmocks ( createdmocks ) ) ; <nl>  <nl> runlistener listener = new runlistener ( ) { <nl> - @ override public void testfailure ( failure failure ) throws exception { <nl> - / / debugginginfo . printwarnings ( logger ) ; <nl> - / / print warnings here ! <nl> + @ override public void testfailure ( failure failure ) throws exception { <nl> list < invocation > unused = new unusedstubsfinder ( ) . find ( createdmocks ) ; <nl> list < invocation > all = new allinvocationsfinder ( ) . find ( createdmocks ) ; <nl> list < invocationmatcher > allmatchers = invocationmatcher . createfrom ( all ) ; <nl> - <nl> + <nl> new warningsprinterimpl ( unused , allmatchers , false ) . print ( logger ) ; <nl> } <nl> } ; <nl> mmm a / src / org / mockito / runners / verbosemockitojunitrunner . java <nl> ppp b / src / org / mockito / runners / verbosemockitojunitrunner . java <nl>
public class verbosemockitojunitrunner extends runner { <nl>  <nl> list < invocation > unused = new unusedstubsfinder ( ) . find ( createdmocks ) ; <nl> list < invocation > all = new allinvocationsfinder ( ) . find ( createdmocks ) ; <nl> - list < invocationmatcher > allmatchers = invocationmatcher . createfrom ( all ) ; <nl> + list < invocationmatcher > allinvocationmatchers = invocationmatcher . createfrom ( all ) ; <nl>  <nl> - <nl> - string warnings = new warningsprinterimpl ( unused , allmatchers , false ) . print ( ) ; <nl> + string warnings = new warningsprinterimpl ( unused , allinvocationmatchers , false ) . print ( ) ; <nl>  <nl> string newmessage = throwable . getmessage ( ) ; <nl> newmessage + = warnings + " \n * * * the actual failure is because of : * * * \n " ;
package org . mockito . internal . listeners ; <nl>  <nl> import org . mockito . mocksettings ; <nl>  <nl> - <nl> public interface mockingstartedlistener extends mockingprogresslistener { <nl> void mockingstarted ( object mock , class classtomock , mocksettings mocksettings ) ; <nl> }
<nl> # this script is not really portable . it ' s just to automate some manual steps i usually do when releasing . <nl> # it might evolve into someting more robust but for now it ' s ok for me . <nl>  <nl> - raise " <nl> - <nl> import os <nl>  <nl> def run ( cmd ) : <nl>
public interface mocksettings extends serializable { <nl> @ suppresswarnings ( " unchecked " ) <nl> mocksettings defaultanswer ( answer defaultanswer ) ; <nl>  <nl> - <nl> + / * * <nl> + * mocks can be made serializable . with this feature you can use a mock in a place that requires dependencies to be serializable . <nl> + * < p > <nl> + * warning : this should be rarely used in unit testing . <nl> + * < p > <nl> + * the behaviour was implemented for a specific use case of a bdd spec that had an unreliable external dependency . this <nl> + * was in a web environment and the objects from the external dependency were being serialized to pass between layers . <nl> + * < p > <nl> + * example : <nl> + * < pre > <nl> + * list serializablemock = mock ( list . class , withsettings ( ) . serializable ( ) ) ; <nl> + * < / pre > <nl> + * <nl> + * @ return settings instance so that you can fluently specify other settings <nl> + * / <nl> mocksettings serializable ( ) ; <nl> - <nl> } <nl> \ no newline at end of file <nl> mmm a / src / org / mockito / mockito . java <nl> ppp b / src / org / mockito / mockito . java <nl>
import org . mockito . stubbing . * ; <nl> * <nl> * < h3 id = " 20 " > 20 . ( * * new * * ) serializable mocks < / h3 > <nl> * <nl> - * with this feature you can use a mock in a place that requires dependencies to be serializable . <nl> + * mocks can be made serializable . with this feature you can use a mock in a place that requires dependencies to be serializable . <nl> * < p > <nl> - * <nl> - * warning : this should rarely be used . if you are unit testing it should be rare that you need this behaviour . <nl> + * warning : this should be rarely used in unit testing . <nl> * < p > <nl> * the behaviour was implemented for a specific use case of a bdd spec that had an unreliable external dependency . this <nl> * was in a web environment and the objects from the external dependency were being serialized to pass between layers . <nl> * < p > <nl> - * to create a mock that can be serialized the interface or class must implement the serializable interface or use the <nl> - * { @ link # withsettings ( ) . extrainterfaces ( serializable . class ) } . when creating the mock for the interface or class use the <nl> - * withsettings ( ) . serializable ( ) { @ link org . mockito . mocksettings } . <nl> - * <nl> + * to create serializable mock use { @ link # withsettings ( ) . serializable ( ) } : <nl> * < pre > <nl> - * yourclass mock = mock ( yourclass . class , withsettings ( ) . extrainterfaces ( serializable . class ) . serializable ( ) ) ; <nl> + * list serializablemock = mock ( list . class , withsettings ( ) . serializable ( ) ) ; <nl> * < / pre > <nl> - * <nl> - * in the above example the first mocksettings that is added is the serialiable interface . if your class or interface <nl> - * implements serializable this is not needed . the second mocksettings , . serializable ( ) , tells mockito to use internal <nl> - * classes that can be serialized . <nl> * < p > <nl> - * the above mock can be serialized assuming all the normal < a href = ' http : / / www . uni - muenster . de / ziv . bennosueselbeck / java / jdk1 . 5 . 0_01 / docs / api / java / io / serializable . html ' > <nl> - * serialization requirements < / a > are met by the interface or class . <nl> + * the mock can be serialized assuming all the normal < a href = ' http : / / java . sun . com / j2se / 1 . 5 . 0 / docs / api / java / io / serializable . html ' > <nl> + * serialization requirements < / a > are met by the class . <nl> * < p > <nl> * making a real object spy serializable is a bit more effort as the spy ( . . . ) method does not have an overloaded version <nl> - * which accepts mocksettings . but no worries you simply use the same mocksettings that the spy ( . . . ) method uses plus the <nl> - * serializable setting . <nl> + * which accepts mocksettings . no worries , you will hardly ever use it . <nl> * <nl> * < pre > <nl> * list < object > list = new arraylist < object > ( ) ; <nl>
public class additionalmatchers { <nl> * the given array . <nl> * @ return < code > null < / code > . <nl> * / <nl> - <nl> public static short [ ] aryeq ( short [ ] value ) { <nl> return reportmatcher ( new arrayequals ( value ) ) . returnnull ( ) ; <nl> }
import org . junit . runner . runwith ; <nl> import org . mockito . runners . mockitojunitrunner ; <nl> import org . mockitoutil . testbase ; <nl>  <nl> - <nl> - @ ignore <nl> @ runwith ( mockitojunitrunner . class ) <nl> - public class mockitorunnerbreakswhennotestmethodstest extends testbase { } <nl> \ no newline at end of file <nl> + @ ignore ( " for demo only . this test cannot be enabled as it fails : ) " ) <nl> + public class mockitorunnerbreakswhennotestmethodstest extends testbase { <nl> + public void notatestmethod ( ) { } <nl> + } <nl> \ no newline at end of file
<nl> - import os <nl> - os . system ( ' svn ps - r svn : mime - type text / html . . / javadoc / * ' ) <nl> - os . system ( ' svn ps - r svn : mime - type text / css . . / javadoc / stylesheet . css ' ) <nl> - <nl> - # <nl> \ no newline at end of file <nl> mmm / dev / null <nl> ppp b / releasing / release - maven . py <nl>
package org . mockito . stubbing ; <nl> import org . mockito . mockito ; <nl> import org . mockito . internal . progress . iongoingstubbing ; <nl>  <nl> - <nl> / * * <nl> * simply put : " < b > when < / b > the x method is called < b > then < / b > return y " . e . g : <nl> *
public class bddmockito extends mockito { <nl>  <nl> public static class bddongoingstubbingimpl < t > implements bddmyongoingstubbing < t > { <nl>  <nl> - <nl> private final ongoingstubbing < t > mockitoongoingstubbing ; <nl>  <nl> public bddongoingstubbingimpl ( ongoingstubbing < t > ongoingstubbing ) { <nl> mmm a / src / org / mockito / mockito . java <nl> ppp b / src / org / mockito / mockito . java <nl>
public class mockito extends matchers { <nl> * @ return deprecatedongoingstubbing object to set stubbed value / exception <nl> * / <nl> @ deprecated <nl> - <nl> public static < t > deprecatedongoingstubbing < t > stub ( t methodcall ) { <nl> return mockito_core . stub ( methodcall ) ; <nl> } <nl>
public class mockito extends matchers { <nl> * @ param tobethrown to be thrown when the stubbed method is called <nl> * @ return stubber - to select a method for stubbing <nl> * / <nl> - <nl> public static stubber dothrow ( throwable tobethrown ) { <nl> return mockito_core . doanswer ( new throwsexception ( tobethrown ) ) ; <nl> } <nl> mmm a / src / org / mockito / stubbing / ongoingstubbing . java <nl> ppp b / src / org / mockito / stubbing / ongoingstubbing . java <nl>
import org . mockito . mockito ; <nl> * <nl> * see examples in javadoc for { @ link mockito # stubvoid } <nl> * / <nl> - <nl> public interface voidmethodstubbable < t > { <nl>  <nl> / * * <nl> mmm a / test / org / mockito / internal / debugging / warningsprintertest . java <nl> ppp b / test / org / mockito / internal / debugging / warningsprintertest . java <nl>
public class warningsprintertest extends testbase { <nl> assertnotcontains ( " stub was not used " , logger . getloggedinfo ( ) ) ; <nl> assertnotcontains ( " was not stubbed " , logger . getloggedinfo ( ) ) ; <nl> } <nl> - <nl> - <nl> - / / class that has any final methods <nl> } <nl> \ no newline at end of file <nl> mmm a / test / org / mockito / internal / matchers / matcherstostringtest . java <nl> ppp b / test / org / mockito / internal / matchers / matcherstostringtest . java <nl>
public class equalstest extends testbase { <nl> containsextratypeinformation equals = new equals ( 10 ) ; <nl>  <nl> / / then <nl> - <nl> asserttrue ( equals . typematches ( 10 ) ) ; <nl> assertfalse ( equals . typematches ( 10l ) ) ; <nl> } <nl> + <nl> + @ test <nl> + public void shouldmatchtypessafelywhenactualisnull ( ) throws exception { <nl> + / / when <nl> + containsextratypeinformation equals = new equals ( null ) ; <nl> + <nl> + / / then <nl> + assertfalse ( equals . typematches ( 10 ) ) ; <nl> + } <nl> + <nl> + @ test <nl> + public void shouldmatchtypessafelywhengivenisnull ( ) throws exception { <nl> + / / when <nl> + containsextratypeinformation equals = new equals ( 10 ) ; <nl> + <nl> + / / then <nl> + assertfalse ( equals . typematches ( null ) ) ; <nl> + } <nl> }
public class mockito extends matchers { <nl> / * * <nl> * use docallrealmethod ( ) when you want to call the real implementation of a method . <nl> * < p > <nl> - * <nl> + * * as usual you are going to read the partial mock warning : <nl> + * object oriented programming is more less tackling complexity by dividing the complexity and placing it in separate , specific objects . <nl> + * partial mock is a sign that the code is not well designed . <nl> + * it usually means that the complexity has been moved to a different method on the same object . <nl> + * partial mocks are useful when dealing with code you cannot change easily ( 3rd party interfaces , interim refactoring of legacy code etc . ) <nl> + * i wouldn ' t use them for new code . <nl> + <nl> * < p > <nl> * example : <nl> * < pre > <nl> mmm a / test / org / mockitousage / customization / bddmockitotest . java <nl> ppp b / test / org / mockitousage / customization / bddmockitotest . java <nl>
public class mockito extends matchers { <nl> mockito_core . validatemockitousage ( ) ; <nl> } <nl>  <nl> - <nl> + / * * <nl> + * allows mock creation with additional mock settings . <nl> + * < p > <nl> + * don ' t use it too often . <nl> + * consider writing simple tests that use simple mocks . <nl> + * repeat after me : simple tests push simple , kissy , readable & maintainable code . <nl> + * if you cannot write a test in a simple way - refactor the code under test . <nl> + * < p > <nl> + * examples of mock settings : <nl> + * < pre > <nl> + * / / creates mock with different default answer & name <nl> + * foo mock = mock ( foo . class , withsettings ( ) <nl> + * . defaultanswer ( returns_smart_nulls ) <nl> + * . name ( " cool mockie " ) ) ; <nl> + * <nl> + * / / creates mock with different default answer , descriptive name and extra interfaces <nl> + * foo mock = mock ( foo . class , withsettings ( ) <nl> + * . defaultanswer ( returns_smart_nulls ) <nl> + * . name ( " cool mockie " ) <nl> + * . extrainterfaces ( bar . class ) ) ; <nl> + * < / pre > <nl> + * { @ link mocksettings } has been introduced for two reasons . <nl> + * firstly , to make it easy to add another mock settings when the demand comes . <nl> + * secondly , to enable combining different mock settings without introducing zillions of overloaded mock ( ) methods . <nl> + * < p > <nl> + * see javadoc for { @ link mocksettings } to learn about possible mock settings . <nl> + * < p > <nl> + * <nl> + * @ return mock settings instance with defaults . <nl> + * / <nl> public static mocksettings withsettings ( ) { <nl> return new mocksettingsimpl ( ) . defaultanswer ( returns_defaults ) ; <nl> }
public class invocation implements printableinvocation , invocationonmock , canpri <nl> return this . rawarguments ; <nl> } <nl>  <nl> - <nl> - public object invokesuper ( ) throws throwable { <nl> + public object callrealmethod ( ) throws throwable { <nl> return methodproxy . invokesuper ( mock , arguments ) ; <nl> } <nl> } <nl> mmm a / src / org / mockito / internal / stubbing / answers / callsrealmethods . java <nl> ppp b / src / org / mockito / internal / stubbing / answers / callsrealmethods . java <nl>
public class mockito extends matchers { <nl> * @ return mock object <nl> * / <nl> public static < t > t mock ( class < t > classtomock , returnvalues returnvalues ) { <nl> - return mockito_core . mock ( classtomock , withsettings ( ) . defaultbehavior ( returnvalues ) ) ; <nl> + return mock ( classtomock , withsettings ( ) . defaultbehavior ( returnvalues ) ) ; <nl> } <nl>  <nl> - <nl> + <nl> + / * * <nl> + * creates a mock with some non - standard settings . <nl> + * < p > <nl> + * the number of configuration points for a mock grows <nl> + * so we need a fluent way to introduce new configuration without adding more and more overloaded mockito . mock ( ) methods . <nl> + * hence { @ link mocksettings } . <nl> + * < pre > <nl> + * listener mock = mock ( listener . class , withsettings ( ) <nl> + * . name ( " firstlistner " ) . defaultbehavior ( returns_smart_nulls ) ; <nl> + * ) ; <nl> + * < / pre > <nl> + * < b > use it carefully and occasionally < / b > . what might be reason your test needs non - standard mocks ? <nl> + * is the code under test so complicated that it requires non - standard mocks ? <nl> + * wouldn ' t you prefer to refactor the code under test so it is testable in a simple way ? <nl> + * < p > <nl> + * see also { @ link mockito # withsettings ( ) } <nl> + * < p > <nl> + * see examples in javadoc for { @ link mockito } class <nl> + * <nl> + * @ param classtomock class or interface to mock <nl> + * @ param mocksettings additional mock settings <nl> + * @ return mock object <nl> + * / <nl> public static < t > t mock ( class < t > classtomock , mocksettings mocksettings ) { <nl> return mockito_core . mock ( classtomock , mocksettings ) ; <nl> }
public class classimposterizer { <nl> } <nl>  <nl> try { <nl> - <nl> - / / 1 . validate it and throw early <nl> - / / 2 . catch and rethrow as mockitoexception <nl> return enhancer . createclass ( ) ; <nl> } catch ( codegenerationexception e ) { <nl> if ( modifier . isprivate ( mockedtype . getmodifiers ( ) ) ) { <nl> mmm a / src / org / mockito / internal / util / mockutil . java <nl> ppp b / src / org / mockito / internal / util / mockutil . java <nl>
import org . junit . runners . model . statement ; <nl> import org . mockito . mockitoannotations ; <nl> import org . mockito . internal . runners . util . frameworkusagevalidator ; <nl>  <nl> - <nl> public class junit45andhigherrunnerimpl implements runnerimpl { <nl>  <nl> private runner runner ;
package org . mockitousage . matchers ; <nl>  <nl> import static org . mockito . mockito . * ; <nl>  <nl> - import java . util . linkedlist ; <nl> import java . util . list ; <nl>  <nl> import org . junit . test ; <nl> - import org . mockito . argumentmatcher ; <nl> - import org . mockito . mockito ; <nl> + import org . mockito . argument ; <nl> + import org . mockito . exceptions . base . mockitoexception ; <nl> import org . mockitoutil . testbase ; <nl>  <nl> @ suppresswarnings ( " unchecked " ) <nl> public class argumentcaptortest extends testbase { <nl>  <nl> - public class argument < t > extends argumentmatcher < t > { <nl> - private linkedlist < object > arguments = new linkedlist < object > ( ) ; <nl> - <nl> - public boolean matches ( object argument ) { <nl> - this . arguments . add ( argument ) ; <nl> - return true ; <nl> - } <nl> - <nl> - public t capture ( ) { <nl> - mockito . argthat ( this ) ; <nl> - return null ; <nl> - } <nl> - <nl> - public t value ( ) { <nl> - if ( arguments . isempty ( ) ) { <nl> - assert false ; <nl> - } else { <nl> - <nl> - return ( t ) arguments . getlast ( ) ; <nl> - } <nl> - return ( t ) arguments ; <nl> - } <nl> - <nl> - public t getlastvalue ( ) { <nl> - return value ( ) ; <nl> - } <nl> - <nl> - public list < t > allvalues ( ) { <nl> - return ( list ) arguments ; <nl> - } <nl> - } <nl> - <nl> class person { <nl>  <nl> private final integer age ; <nl>
public class descriptivemessageswhenverificationfailstest extends testbase { <nl> verify ( mock ) . twoargumentmethod ( 2 , num ) ; <nl> fail ( ) ; <nl> } catch ( argumentsaredifferent e ) { <nl> - <nl> assertcontains ( " ( 2 , num ) " , e . getmessage ( ) ) ; <nl> assertcontains ( " ( 2 , num ) " , e . getmessage ( ) ) ; <nl> }
public class testbase extends assert { <nl> } <nl>  <nl> public void makestacktracesclean ( ) { <nl> - <nl> configurationaccess . getconfig ( ) . overridecleansstacktrace ( true ) ; <nl> }
public class mockitocore { <nl> mocking_progress . validatestate ( ) ; <nl> mocking_progress . reset ( ) ; <nl> mocking_progress . resetongoingstubbing ( ) ; <nl> - <nl>  <nl> for ( t m : mocks ) { <nl> - mockutil . resetmock ( m , mocking_progress , mockito . returns_defaults ) ; <nl> + mockutil . resetmock ( m , mocking_progress ) ; <nl> } <nl> } <nl>  <nl> mmm a / src / org / mockito / internal / util / mockutil . java <nl> ppp b / src / org / mockito / internal / util / mockutil . java <nl>
public class throwsexception implements answer < object > { <nl> } <nl>  <nl> public object answer ( invocationonmock invocation ) throws throwable { <nl> - <nl> if ( mockutil . ismock ( throwable ) ) { <nl> throw throwable ; <nl> }
public class argumentmatcherstorageimpl implements argumentmatcherstorage { <nl> / * ( non - javadoc ) <nl> * @ see org . mockito . internal . progress . argumentmatcherstorage # pullmatchers ( ) <nl> * / <nl> - <nl> public list < matcher > pullmatchers ( ) { <nl> if ( matcherstack . isempty ( ) ) { <nl> - return null ; <nl> + return collections . emptylist ( ) ; <nl> } <nl>  <nl> list < localizedmatcher > matchers = new arraylist < localizedmatcher > ( matcherstack ) ;
import org . junit . test ; <nl> import org . mockitousage . imethods ; <nl> import org . mockitoutil . testbase ; <nl>  <nl> - <nl> - / / this test exposes the problem at least once in num runs <nl> public class threadsshareamocktest extends testbase { <nl>  <nl> private imethods mock ;
public class moreemptyreturnvalues implements returnvalues { <nl> } else if ( type = = object . class ) { <nl> return new object ( ) ; <nl> } else if ( type . isarray ( ) ) { <nl> - <nl> - return null ; <nl> - / / system . out . println ( type . getconstructors ( ) [ 0 ] . getparametertypes ( ) ) ; <nl> - / / try { <nl> - / / return type . newinstance ( ) ; <nl> - / / } catch ( exception e ) { <nl> - / / throw new runtimeexception ( e ) ; <nl> - / / } <nl> + class < ? > componenettype = type . getcomponenttype ( ) ; <nl> + return array . newinstance ( componenettype , num ) ; <nl> } <nl> return null ; <nl> } <nl> mmm a / test / org / mockito / internal / returnvalues / moreemptyreturnvaluestest . java <nl> ppp b / test / org / mockito / internal / returnvalues / moreemptyreturnvaluestest . java <nl>
public class stubbedinvocationmatcher extends invocationmatcher implements answe <nl> } <nl>  <nl> public object answer ( invocationonmock invocation ) throws throwable { <nl> - <nl> synchronized ( answers ) { <nl> return answers . size ( ) = = num ? answers . peek ( ) . answer ( invocation ) : answers . poll ( ) . answer ( invocation ) ; <nl> } <nl> mmm a / test / org / concurrentmockito / threadssharegenerouslystubbedmocktest . java <nl> ppp b / test / org / concurrentmockito / threadssharegenerouslystubbedmocktest . java <nl>
public class invocation implements printableinvocation , invocationonmock , canpri <nl> protected string tostring ( list < matcher > matchers , boolean forcemultiline ) { <nl> string method = qualifiedmethodname ( ) ; <nl> string invocation = method + getargumentsline ( matchers ) ; <nl> - <nl> if ( forcemultiline | | ( ! matchers . isempty ( ) & & invocation . length ( ) > max_line_length ) ) { <nl> return method + getargumentsblock ( matchers ) ; <nl> } else {
public class globalconfiguration { <nl>  <nl> public static imockitoconfiguration getconfig ( ) { <nl> if ( ! initialized ) { <nl> - <nl> throw new illegalstateexception ( " something went wrong . globalconfiguration should be initialised by now . \n " + <nl> " please report issue at http : / / mockito . org or write an email to mockito @ googlegroups . com " ) ; <nl> } <nl> mmm a / src / org / mockito / internal / debugging / warningsprinter . java <nl> ppp b / src / org / mockito / internal / debugging / warningsprinter . java <nl>
import org . mockito . runners . mockitojunitrunner ; <nl> / * * <nl> * uses < b > junit num . 5 < / b > runner { @ link blockjunit4classrunner } . <nl> * < p > <nl> - * does what { @ link mockitojunitrunner } does plus warns when stubbing <nl> - * <nl> + * this runner does exactly what { @ link mockitojunitrunner } does but also <nl> + * prints useful warnings that can be helpful for debugging failed tests . <nl> + * < p > <nl> + * sometimes when the test fails , the underlying reason is that stubbed method was called with wrong arguments . <nl> + * sometimes it fails because one forgets to stub a method or forgets to call a stubbed method . <nl> + * all above problems are not immediately obvious . <nl> + * < p > <nl> + * one way of approaching this problem is full - blown ' expect ' api . <nl> + * however it means the ' expectations upfront ' business which is not in line with core mockito concepts . <nl> + * after all , one of the key points of mockito are < b > explicit assertions < / b > that are always placed at the < b > bottom of the test < / b > method . <nl> + * < p > <nl> + * let ' s look at different ways of addressing the issue . <nl> + * here ' s the experiment : a warning is printed to the standard output if the test fails . <nl> + * also , you get a clickabe link to the line of code . you can immediately jump to the place in code where the potential problem is . <nl> + * < p > <nl> + * let ' s say your test fails on assertion . <nl> + * let ' s say the underlying reason is a stubbed method that was called with different arguments : <nl> + * < pre > <nl> + * / / test : <nl> + * when ( translator . translate ( " mockito " ) ) . thenreturn ( " cool framework " ) ; <nl> + * string translated = dictionary . search ( " mockito " ) ; <nl> + * assertequals ( " cool framework " , translated ) ; <nl> + * <nl> + * / / code : <nl> + * public string search ( string word ) { <nl> + * . . . <nl> + * return translator . translate ( " oups " ) ; <nl> + * <nl> + * < / pre > <nl> + * on standard output you ' ll see something like that : <nl> + * < pre > <nl> + * [ mockito ] warning - stubbed method called with different arguments . <nl> + * stubbed this way : <nl> + * translator . translate ( " mockito " ) ; <nl> + * org . dictionary . smartdictionarytest . shouldfindtranslation ( smartdictionarytest . java : 27 ) <nl> + * <nl> + * but called with different arguments : <nl> + * translator . translate ( " oups " ) ; <nl> + * org . dictionary . smartdictionary . search ( smartdictionary . java : 15 ) <nl> + * < / pre > <nl> + * < p > <nl> + * note that it is just a warning , not an assertion . <nl> + * the test fails on assertion because it ' s the assertion ' s task to document what the test stands for and what behavior it proves . <nl> + * warnings just helps debugging tests . <nl> + * < p > <nl> + * note that code links printed to the console are clickable in any decent ide ( e . g . eclipse ) . <nl> + * < p > <nl> + * so far i identified num cases when warnings are printed : <nl> + * < li > unstubbed method < / li > <nl> + * < li > unsued stub < / li > <nl> + * < li > stubbed method but called with different arguments < / li > <nl> + * < p > <nl> + * < br / > <nl> + * do you think it is useful or not ? drop us an email at mockito @ googlegroups . com <nl> * / <nl> public class experimentalmockitojunitrunner extends mockitojunitrunner {
public class experimentalmockitojunitrunnertest extends testbase { <nl> runner . run ( notifier , new junittestbody ( ) { <nl> public void run ( runnotifier notifier ) { <nl> somestubbing ( ) ; <nl> - <nl> - / / callstubbedmethodcorrectly ( ) ; <nl> callstubbedmethodwithdifferentargs ( ) ; <nl> notifier . firetestfailure ( null ) ; <nl>  <nl>
public class smartnullreturnvalues implements returnvalues { <nl> class < ? > type = invocation . getmethod ( ) . getreturntype ( ) ; <nl> if ( classimposterizer . instance . canimposterise ( type ) ) { <nl> return classimposterizer . instance . imposterise ( new methodinterceptor ( ) { <nl> - <nl> - <nl> - exception whencreated = new undesiredinvocation ( " unstubbed method was invoked here " ) ; <nl> + exception whencreated = new becausethismethodwasnotstubbed ( " \nbecause this method was not stubbed : " ) ; <nl> public object intercept ( object obj , method method , object [ ] args , methodproxy proxy ) throws throwable { <nl> - throw new smartnullpointerexception ( " oops " , whencreated ) ; <nl> + throw new smartnullpointerexception ( " \nyou have a nullpointerexception here : " , whencreated ) ; <nl> } } , type ) ; <nl> } <nl> return null ; <nl> } <nl> - } <nl> + } <nl> \ no newline at end of file
public class mockingprogressimpl implements mockingprogress { <nl>  <nl> public void stubbingstarted ( ) { <nl> validatestate ( ) ; <nl> - <nl> stubbinginprogress = true ; <nl> }
public class stacktracefilter { <nl> list < stacktraceelement > filtered = unfilteredstacktrace . sublist ( lasttoremove + num , unfilteredstacktrace . size ( ) ) ; <nl> hasstacktrace . setstacktrace ( filtered . toarray ( new stacktraceelement [ ] { } ) ) ; <nl> } <nl> - <nl> - <nl> - public void removerunner ( hasstacktrace hasstacktrace ) { <nl> - stacktraceelement [ ] stacktrace = hasstacktrace . getstacktrace ( ) ; <nl> - list < stacktraceelement > filtered = new linkedlist < stacktraceelement > ( ) ; <nl> - for ( stacktraceelement trace : stacktrace ) { <nl> - boolean isrunner = trace . getclassname ( ) . startswith ( " org . mockito . runners . " ) ; <nl> - if ( ! isrunner ) { <nl> - filtered . add ( trace ) ; <nl> - } <nl> - } <nl> - hasstacktrace . setstacktrace ( filtered . toarray ( new stacktraceelement [ ] { } ) ) ; <nl> - } <nl> } <nl> \ no newline at end of file
public class methodinterceptorfilter < t extends mockawareinterceptor > implements <nl>  <nl> public object intercept ( object proxy , method method , object [ ] args , methodproxy methodproxy ) <nl> throws throwable { <nl> - <nl> - if ( method . isbridge ( ) ) { <nl> - return methodproxy . invokesuper ( proxy , args ) ; <nl> - } <nl> - <nl> if ( equalsmethod . equals ( method ) ) { <nl> return boolean . valueof ( proxy = = args [ 0 ] ) ; <nl> } else if ( hashcodemethod . equals ( method ) ) { <nl> mmm a / test / org / mockitousage / puzzlers / bridgemethodpuzzletest . java <nl> ppp b / test / org / mockitousage / puzzlers / bridgemethodpuzzletest . java <nl>
import org . mockitoutil . testbase ; <nl> public class numberofinvocationscheckertest extends testbase { <nl>  <nl> private numberofinvocationschecker checker ; <nl> - <nl> private reporterstub reporterstub ; <nl> private invocationmatcher wanted ; <nl> private linkedlist < invocation > invocations ; <nl>
public class numberofinvocationscheckertest extends testbase { <nl> assertequals ( invocation . getstacktrace ( ) , reporterstub . stacktrace ) ; <nl> } <nl>  <nl> - <nl> - / / @ test <nl> - / / public void shouldmarkinvocationsasverified ( ) throws exception { <nl> - / / invocation invocation = new invocationbuilder ( ) . toinvocation ( ) ; <nl> - / / finderstub . actualtoreturn . add ( invocation ) ; <nl> - / / assertfalse ( invocation . isverified ( ) ) ; <nl> - / / <nl> - / / checker . verify ( invocations , wanted , verificationmodefactory . atleastonce ( ) ) ; <nl> - / / <nl> - / / asserttrue ( invocation . isverified ( ) ) ; <nl> - / / } <nl> + @ test <nl> + public void shouldmarkinvocationsasverified ( ) throws exception { <nl> + invocation invocation = new invocationbuilder ( ) . toinvocation ( ) ; <nl> + finderstub . actualtoreturn . add ( invocation ) ; <nl> + assertfalse ( invocation . isverified ( ) ) ; <nl> + <nl> + checker . check ( invocations , wanted , num ) ; <nl> + <nl> + asserttrue ( invocation . isverified ( ) ) ; <nl> + } <nl>  <nl> class reporterstub extends reporter { <nl> private int wantedcount ;
public class atleastxnumberofinvocationschecker { <nl> private final reporter reporter = new reporter ( ) ; <nl> private final invocationsfinder finder = new invocationsfinder ( ) ; <nl>  <nl> - <nl> public void check ( list < invocation > invocations , invocationmatcher wanted , int wantedcount ) { <nl> list < invocation > actualinvocations = finder . findinvocations ( invocations , wanted ) ; <nl>  <nl> mmm a / src / org / mockito / internal / verification / checkers / numberofinvocationsinorderchecker . java <nl> ppp b / src / org / mockito / internal / verification / checkers / numberofinvocationsinorderchecker . java <nl>
<nl> - package org . mockito . internal . verification ; <nl> - <nl> - <nl> - <nl> - public class verificationmodedecoder { <nl> - <nl> - private final times mode ; <nl> - <nl> - public verificationmodedecoder ( times mode ) { <nl> - this . mode = mode ; <nl> - } <nl> - <nl> - public boolean neverwanted ( ) { <nl> - return mode . wantedcount ( ) = = num ; <nl> - } <nl> - <nl> - public boolean neverwantedbutinvoked ( int actualcount ) { <nl> - return neverwanted ( ) & & actualcount > num ; <nl> - } <nl> - } <nl> \ no newline at end of file <nl> mmm a / test / org / mockito / internal / verification / verificationmodedecodertest . java <nl> ppp / dev / null <nl>
<nl> - / * <nl> - * copyright ( c ) num mockito contributors <nl> - * this program is made available under the terms of the mit license . <nl> - * / <nl> - package org . mockito . internal . verification ; <nl> - <nl> - import org . junit . ignore ; <nl> - import org . mockitoutil . testbase ; <nl> - <nl> - @ ignore <nl> - public class nomoreinvocationsverifiertest extends testbase { <nl> - <nl> - <nl> - <nl> - / / private nomoreinteractionsmode mode ; <nl> - / / private invocationsfinderstub finder ; <nl> - / / private reporterstub reporterstub ; <nl> - / / <nl> - / / @ before <nl> - / / public void setup ( ) { <nl> - / / finder = new invocationsfinderstub ( ) ; <nl> - / / reporterstub = new reporterstub ( ) ; <nl> - / / mode = new nomoreinteractionsmode ( finder , reporterstub ) ; <nl> - / / } <nl> - <nl> - / / @ test <nl> - / / public void shouldpassverification ( ) throws exception { <nl> - / / finder . firstunverifiedtoreturn = null ; <nl> - / / verifier . verify ( null , null , mockitoverificationmode . nomoreinteractions ( ) ) ; <nl> - / / } <nl> - / / <nl> - / / @ test <nl> - / / public void shouldreporterror ( ) throws exception { <nl> - / / invocation firstunverified = new invocationbuilder ( ) . toinvocation ( ) ; <nl> - / / finder . firstunverifiedtoreturn = firstunverified ; <nl> - / / list < invocation > invocations = aslist ( new invocationbuilder ( ) . toinvocation ( ) ) ; <nl> - / / <nl> - / / verifier . verify ( invocations , null , mockitoverificationmode . nomoreinteractions ( ) ) ; <nl> - / / <nl> - / / assertsame ( invocations , finder . invocations ) ; <nl> - / / <nl> - / / assertequals ( firstunverified , reporterstub . undesired ) ; <nl> - / / assertsame ( firstunverified . getstacktrace ( ) , reporterstub . actualinvocationstacktrace ) ; <nl> - / / } <nl> - / / <nl> - / / class reporterstub extends reporter { <nl> - / / private printableinvocation undesired ; <nl> - / / private hasstacktrace actualinvocationstacktrace ; <nl> - / / @ override public void nomoreinteractionswanted ( printableinvocation undesired , hasstacktrace actualinvocationstacktrace ) { <nl> - / / this . undesired = undesired ; <nl> - / / this . actualinvocationstacktrace = actualinvocationstacktrace ; <nl> - / / } <nl> - / / } <nl> - }
package org . mockito . internal . progress ; <nl>  <nl>  <nl> import org . mockito . internal . verification . mockitoverificationmode ; <nl> - import org . mockito . internal . verification . mockitoverificationmode . verification ; <nl> + import org . mockito . internal . verification . verificationmodefactory ; <nl>  <nl> public class verificationmodebuilder { <nl>  <nl> private integer times = num ; <nl>  <nl> public mockitoverificationmode inorder ( ) { <nl> - <nl> - return new mockitoverificationmode ( times , verification . explicit ) ; <nl> + return verificationmodefactory . times ( times ) ; <nl> } <nl>  <nl> public verificationmodebuilder times ( int times ) {
package org . mockito . internal . verification ; <nl> import java . util . list ; <nl>  <nl> import org . mockito . internal . invocation . invocation ; <nl> - import org . mockito . internal . invocation . invocationmatcher ; <nl> - import org . mockito . internal . verification . api . verificationmode ; <nl>  <nl> - <nl> public class verifyingrecorder { <nl>  <nl> private registeredinvocations registeredinvocations = new registeredinvocations ( ) ; <nl>
import org . mockito . internal . verification . api . verificationmode ; <nl> * / <nl> public class mockitoverificationmode implements verificationinordermode , verificationmode { <nl>  <nl> - <nl> - public enum verification { explicit , no_more_wanted , at_least } ; <nl> + public enum verification { explicit , at_least } ; <nl>  <nl> - private list < object > mockstobeverifiedinorder ; <nl> - <nl> final int wantedinvocationcount ; <nl> final verification verification ; <nl>  <nl>
public class mockitoverificationmode implements verificationinordermode , verific <nl> } <nl>  <nl> public void verify ( verificationdata data ) { <nl> - if ( mockstobeverifiedinorder ! = null ) { <nl> - verifyinorder ( data ) ; <nl> - return ; <nl> - } <nl> - <nl> missinginvocationchecker missinginvocation = new missinginvocationchecker ( ) ; <nl> numberofinvocationschecker numberofinvocations = new numberofinvocationschecker ( ) ; <nl>  <nl> - <nl> if ( wantedinvocationcount > num | | ( verification = = verification . at_least & & wantedinvocationcount = = num ) ) { <nl> missinginvocation . verify ( data . getallinvocations ( ) , data . getwanted ( ) ) ; <nl> } <nl>
public class mockito extends matchers { <nl>  <nl> / * * <nl> * < b > deprecated < / b > <nl> - * <nl> * <nl> * < pre > <nl> * / / instead of : <nl>
import org . mockito . exceptions . base . mockitoexception ; <nl> * } <nl> * < / pre > <nl> * <nl> - * <nl> * < b > < code > mockitoannotations . initmocks ( this ) < / code > < / b > method has to called to initialize annotated mocks . <nl> * < p > <nl> * in above example , < code > initmocks ( ) < / code > is called in & # 064 ; before ( junit4 ) method of test ' s base class . <nl> - * you can also put it in your junit4 runner ( & # 064 ; runwith ) . <nl> * for junit3 < code > initmocks ( ) < / code > can go to < code > setup ( ) < / code > method of a base class . <nl> - * < p > <nl> - * how to implement mockito junit runner ? see examples from mockito / test / org / mockitousage / examples / junitrunner subpackage . <nl> - * you may want to check out the project from svn repository to easily browse mockito ' s test code . <nl> + * you can also use put it in your junit4 runner ( & # 064 ; runwith ) or use built - in runners : { @ link mockitojunit4runner } , { @ link mockitojunit45runner } <nl> * / <nl> public class mockitoannotations {
import org . mockito . exceptions . base . mockitoexception ; <nl> public class mockitoannotations { <nl>  <nl> / * * <nl> - * <nl> - * < b > deprecated < / b > use { @ link mock } annotation instead <nl> + * < b > deprecated < / b > <nl> + * use top - level { @ link org . mockito . mock } annotation instead <nl> * < p > <nl> - * annotation is now a top - level class so that ides are not confused . <nl> + * when & # 064 ; mock annotation was implemented as an inner class then users experienced problems with autocomplete features in ides . <nl> + * hence & # 064 ; mock was made a top - level class . <nl> * < p > <nl> - * allows shorthand mock creation , see examples in javadoc for { @ link mockitoannotations } class . <nl> + * how to fix deprecation warnings ? <nl> + * typically , you can just < b > search : < / b > import org . mockito . mockitoannotations . mock ; < b > and replace with : < / b > import org . mockito . mock ; <nl> * < p > <nl> - * to fix deprecation warnings just search & replace : <nl> - * search : <nl> - * import org . mockito . mockitoannotations . mock ; <nl> - * < p > <nl> - * with : <nl> - * < p > <nl> - * import org . mockito . mock ; <nl> - * <nl> - * @ deprecated use { @ link mock } annotation instead <nl> + * sorry for making your code littered with deprecation warnings but this change was required to make mockito better . hope you still love your little spying framework . . . <nl> * <nl> + * @ deprecated use { @ link org . mockito . mock } annotation instead <nl> * / <nl> @ target ( { field } ) <nl> @ retention ( retentionpolicy . runtime )
public class mockito extends matchers { <nl> * <nl> * see examples in javadoc for { @ link mockito } class <nl> * <nl> - * <nl> * @ param minnumberofinvocations minimum number of invocations <nl> * <nl> * @ return verification mode <nl> mmm a / test / org / mockitousage / annotationstest . java <nl> ppp b / test / org / mockitousage / annotationstest . java <nl>
public class annotationstest extends testbase { <nl>  <nl> @ mock list list ; <nl> @ mock final map map = new hashmap ( ) ; <nl> - <nl>  <nl> @ before <nl> public void setup ( ) {
public class verificationmodeimpltest extends testbase { <nl> } <nl>  <nl> @ test <nl> - public void toolittleactualinvocationsshouldnotapplytoatleastmode ( ) throws exception { <nl> - <nl> + public void shouldatleastmodeignoretoolittleactualinvocations ( ) throws exception { <nl> assertfalse ( atleast ( 10 ) . toolittleactualinvocations ( 5 ) ) ; <nl> assertfalse ( atleast ( 10 ) . toolittleactualinvocations ( 15 ) ) ; <nl> assertfalse ( atleastonce ( ) . toolittleactualinvocations ( 10 ) ) ; <nl>
public class verificationmodeimpltest extends testbase { <nl>  <nl> @ test <nl> public void shouldknowiftoolittleactualinvocationsinatleastmode ( ) throws exception { <nl> - <nl> asserttrue ( atleast ( 3 ) . toolittleactualinvocationsinatleastmode ( 2 ) ) ; <nl> asserttrue ( atleast ( 3 ) . toolittleactualinvocationsinatleastmode ( 1 ) ) ; <nl> asserttrue ( atleast ( 3 ) . toolittleactualinvocationsinatleastmode ( 0 ) ) ; <nl>
public class verificationmodeimpltest extends testbase { <nl> } <nl>  <nl> @ test <nl> - public void toolittleactualinvocationsinatleastmodeshouldnotapplytoothermodes ( ) throws exception { <nl> - <nl> + public void shouldtoolittleactualinvocationsinatleastmodeignoreothermodes ( ) throws exception { <nl> assertfalse ( times ( 10 ) . toolittleactualinvocationsinatleastmode ( 5 ) ) ; <nl> assertfalse ( times ( 10 ) . toolittleactualinvocationsinatleastmode ( 15 ) ) ; <nl> }
public class mockfactory < t > { <nl>  <nl> / / this is required to make ( cglib + eclipse plugins testing ) happy <nl> / / see issue # 11 <nl> - <nl> - enhancer . setclassloader ( mockfactory . class . getclassloader ( ) ) ; <nl> + enhancer . setclassloader ( searchingclassloader . combineloadersof ( tomock ) ) ; <nl>  <nl> return enhancer ; <nl> } <nl> mmm / dev / null <nl> ppp b / src / org / mockito / internal / creation / searchingclassloader . java <nl>
import org . mockito . internal . progress . mockingprogress ; <nl>  <nl> public class mockutil { <nl>  <nl> - <nl> - public static < t > t createmock ( class < t > classtomock , string mockname , mockingprogress progress , t optionalinstance ) { <nl> - if ( mockname = = null ) { <nl> - mockname = toinstancename ( classtomock ) ; <nl> + public static < t > t createmock ( class < t > classtomock , mockingprogress progress , string optionalmockname , t optionalinstance ) { <nl> + if ( optionalmockname = = null ) { <nl> + optionalmockname = toinstancename ( classtomock ) ; <nl> } <nl> mockfactory < t > proxyfactory = new mockfactory < t > ( ) ; <nl> - mockhandler < t > mockhandler = new mockhandler < t > ( mockname , progress , new matchersbinder ( ) ) ; <nl> + mockhandler < t > mockhandler = new mockhandler < t > ( optionalmockname , progress , new matchersbinder ( ) ) ; <nl> methodinterceptorfilter < mockhandler < t > > filter = new methodinterceptorfilter < mockhandler < t > > ( classtomock , mockhandler ) ; <nl> return proxyfactory . createmock ( classtomock , filter , optionalinstance ) ; <nl> }
<nl> - / * <nl> - * copyright ( c ) num mockito contributors <nl> - * this program is made available under the terms of the mit license . <nl> - * / <nl> - package org . mockito . internal . stubbing ; <nl> - <nl> - import org . mockito . invocation . invocationonmock ; <nl> - <nl> - / * * <nl> - * used to answer expected calls . <nl> - * <nl> - * @ param < t > the type to return . <nl> - * / <nl> - public interface answer < t > { <nl> - <nl> - <nl> - / * * <nl> - * @ param invocation the invocation on the mock . <nl> - * <nl> - * @ return the value to be returned <nl> - * <nl> - * @ throws throwable the throwable to be thrown <nl> - * / <nl> - t answer ( invocationonmock invocation ) throws throwable ; <nl> - } <nl> \ no newline at end of file
import org . mockito . internal . matchers . apachecommons . reflectionequals ; <nl> import org . mockito . internal . progress . emptyreturnvalues ; <nl> import org . mockito . internal . progress . lastarguments ; <nl>  <nl> - <nl> - <nl> / * * <nl> * allow flexible verification or stubbing . see also { @ link additionalmatchers } . <nl> * < p > <nl>
<nl> - / * <nl> - * copyright ( c ) num mockito contributors <nl> - * this program is made available under the terms of the mit license . <nl> - * / <nl> - package org . mockito . internal . stubbing ; <nl> - <nl> - import org . mockito . mockito ; <nl> - <nl> - <nl> - / * * <nl> - * chooses void method for stubbing with throwable . e . g : <nl> - * <nl> - * < pre > <nl> - * stubvoid ( mock ) . tothrow ( new runtimeexception ( ) ) . on ( ) . somemethod ( " some arg " ) ; <nl> - * < / pre > <nl> - * <nl> - * see examples in javadoc for { @ link mockito # stubvoid } <nl> - * / <nl> - public interface stubbedmethodselector < t > { <nl> - <nl> - / * * <nl> - * choose void method for stubbing with throwable . e . g : <nl> - * <nl> - * < pre > <nl> - * stubvoid ( mock ) . tothrow ( new runtimeexception ( ) ) . on ( ) . somemethod ( " some arg " ) ; <nl> - * < / pre > <nl> - * <nl> - * if throwable is a checked exception then it has to match one of the <nl> - * checked exceptions of method signature . <nl> - * < p > <nl> - * see examples in javadoc for { @ link mockito # stubvoid } <nl> - * <nl> - * @ return mock object itself <nl> - * / <nl> - t on ( ) ; <nl> - } <nl> \ no newline at end of file <nl> mmm a / src / org / mockito / internal / stubbing / voidmethodstubbable . java <nl> ppp b / src / org / mockito / internal / stubbing / voidmethodstubbable . java <nl>
public class mockfactory < t > { <nl> enhancer enhancer = createenhancer ( tomock ) ; <nl> enhancer . setcallbacktype ( filter . getclass ( ) ) ; <nl>  <nl> + / / this is required but i could not figure out the way to test it <nl> + / / see issue # 11 <nl> if ( tomock . getsigners ( ) ! = null ) { <nl> - <nl> enhancer . setnamingpolicy ( allows_mocking_classes_in_signed_packages ) ; <nl> }
package org . mockito . internal . stubbing ; <nl> import org . mockito . exceptions . base . hasstacktracethrowablewrapper ; <nl> import org . mockito . exceptions . base . stacktracefilter ; <nl>  <nl> - <nl> @ suppresswarnings ( " unchecked " ) <nl> - public class result implements ianswer { <nl> + public class result implements answer { <nl>  <nl> - private ianswer value ; <nl> + private answer value ; <nl>  <nl> - private result ( ianswer value ) { <nl> + private result ( answer value ) { <nl> this . value = value ; <nl> } <nl>  <nl> public static result createthrowresult ( final throwable throwable , final stacktracefilter filter ) { <nl> - return new result ( new ianswer < object > ( ) { <nl> + return new result ( new answer < object > ( ) { <nl> public object answer ( ) throws throwable { <nl> throwable filtered = throwable . fillinstacktrace ( ) ; <nl> filter . filterstacktrace ( new hasstacktracethrowablewrapper ( filtered ) ) ; <nl>
public class stubber { <nl> } <nl>  <nl> public void addconsecutivethrowable ( throwable throwable ) { <nl> - <nl> + validatethrowable ( throwable ) ; <nl> + stubbed . getfirst ( ) . addresult ( result . createthrowresult ( throwable , new stacktracefilter ( ) ) ) ; <nl> } <nl>  <nl> public object resultfor ( invocation invocation ) throws throwable { <nl> mmm / dev / null <nl> ppp b / test / org / mockitousage / stubbing / stubbingconsecutivereturnvaluestest . java <nl>
import org . mockito . internal . stubbing . voidmethodstubbable ; <nl> * <nl> * read more here : { @ link mockitoannotations } <nl> * / <nl> - <nl> public class mockito extends matchers { <nl>  <nl> private static final reporter reporter = new reporter ( ) ; <nl> mmm a / src / org / mockito / mockitoannotations . java <nl> ppp b / src / org / mockito / mockitoannotations . java <nl>
<nl> < / example > <nl> < / rule > <nl>  <nl> - < ! - - <nl> < rule name = " testclassshouldextendtestbase " <nl> message = " test class should extend testbase to detect invalid state problems quickly " <nl> class = " net . sourceforge . pmd . rules . xpathrule " > <nl>
import org . mockito . exceptions . verification . wantedbutnotinvoked ; <nl> * / <nl> public class reporter { <nl>  <nl> - <nl> private string pluralize ( int number ) { <nl> return number = = num ? " 1 time " : number + " times " ; <nl> } <nl> mmm a / test / org / mockitousage / verification / descriptivemessageswhenverificationfailstest . java <nl> ppp b / test / org / mockitousage / verification / descriptivemessageswhenverificationfailstest . java <nl>
public class matchers { <nl> } <nl>  <nl> / * * <nl> - * <nl> * any object argument . <nl> * < p > <nl> * see examples in javadoc for { @ link matchers } class <nl> * <nl> * @ return < code > null < / code > . <nl> * / <nl> - public static object anyobject ( ) { <nl> + public static < t > t anyobject ( ) { <nl> return reportmatcher ( any . any ) . returnnull ( ) ; <nl> }
import org . mockito . exceptions . reporter ; <nl> public class mockfactory < t > { <nl>  <nl> @ suppresswarnings ( " unchecked " ) <nl> - <nl> public t createmock ( class < t > tomock , final methodinterceptorfilter filter ) { <nl> validateclass ( tomock ) ; <nl> enhancer enhancer = createenhancer ( tomock ) ;
public class custommatcherstest extends testbase { <nl> verify ( mock ) . simplemethod ( containstest ( ) ) ; <nl> fail ( ) ; <nl> } catch ( argumentsaredifferentexception e ) { <nl> - <nl> assertthat ( e , messagecontains ( " 1st : string that contains xxx " ) ) ; <nl> assertthat ( e , causemessagecontains ( " 1st : \ " foo \ " " ) ) ; <nl> }
public class extramatchers extends corematchers { <nl> } ; <nl> } <nl>  <nl> - <nl> public static < t > matcher < collection > collectionhas ( final t . . . elements ) { <nl> return new basematcher < collection > ( ) { <nl>  <nl>
public class stacktrackechangingtest extends testbase { <nl> verifysimplemethodonamock ( ) ; <nl> fail ( ) ; <nl> } catch ( argumentsaredifferentexception e ) { <nl> - <nl> assertthat ( e , hasmethodinstacktraceat ( 0 , " verifysimplemethodonamock " ) ) ; <nl> assertthat ( e , hasmethodinstacktraceat ( 1 , " shouldshowactualinvocationasexceptioncause " ) ) ; <nl> assertthat ( e . getcause ( ) , hasmethodinstacktraceat ( 0 , " simplemethodonamock " ) ) ;
public class invocation implements printableinvocation { <nl> list < matcher > matchers = new arraylist < matcher > ( arguments . length ) ; <nl> for ( object arg : arguments ) { <nl> if ( arg ! = null & & arg . getclass ( ) . isarray ( ) ) { <nl> - <nl> matchers . add ( new arrayequals ( arg ) ) ; <nl> } else { <nl> matchers . add ( new equals ( arg ) ) ; <nl> mmm a / test / org / mockito / internal / invocation / invocationtest . java <nl> ppp b / test / org / mockito / internal / invocation / invocationtest . java <nl>
public class invocation implements printableinvocation { <nl> } <nl>  <nl> protected string getargs ( list < matcher > matchers ) { <nl> - <nl> if ( matchers . isempty ( ) ) { <nl> return tab + " < no arguments > " ; <nl> } <nl>
public class invocation implements printable { <nl> } <nl>  <nl> public string tostring ( list < matcher > matchers ) { <nl> - string mockname = mocknamer . nameformock ( mock ) ; <nl> - string methodname = method . getname ( ) ; <nl> - string arguments = getargumentsstring ( matchers ) ; <nl> - <nl> - return mockname + " . " + methodname + arguments ; <nl> - } <nl> - <nl> - public string tostringwithargumenttypes ( ) { <nl> - stringbuilder result = new stringbuilder ( ) ; <nl> - result . append ( ( mocknamer . nameformock ( mock ) + " . " + method . getname ( ) ) ) ; <nl> - result . append ( " ( " ) ; <nl> - for ( class < ? > paramtype : getmethod ( ) . getparametertypes ( ) ) { <nl> - result . append ( paramtype ) ; <nl> - result . append ( " , " ) ; <nl> - } <nl> - return result . tostring ( ) . replacefirst ( " , $ " , " " ) . concat ( " ) " ) ; <nl> - } <nl> - <nl> - private string getargumentsstring ( list < matcher > matchers ) { <nl> - description result = new stringdescription ( ) ; <nl> - result . appendlist ( " ( " , " , " , " ) " , matchers ) ; <nl> - return result . tostring ( ) ; <nl> - } <nl> - <nl> - private list < matcher > argumentstomatchers ( ) { <nl> - list < matcher > matchers = new arraylist < matcher > ( arguments . length ) ; <nl> - for ( object arg : arguments ) { <nl> - if ( arg ! = null & & arg . getclass ( ) . isarray ( ) ) { <nl> - matchers . add ( new arrayequals ( arg ) ) ; <nl> - } else { <nl> - matchers . add ( new equals ( arg ) ) ; <nl> - } <nl> - } <nl> - return matchers ; <nl> + return qualifiedmethodname ( ) + getargumentsstring ( matchers ) ; <nl> } <nl>  <nl> public string getmethodname ( ) { <nl> - <nl> - return mocknamer . nameformock ( mock ) + " . " + method . getname ( ) + " ( . . . ) " ; <nl> + return qualifiedmethodname ( ) + " ( . . . ) " ; <nl> } <nl>  <nl> public string gettypedargs ( ) { <nl>
public class arrayequals extends equals { <nl>  <nl> public boolean matches ( object actual ) { <nl> object wanted = getwanted ( ) ; <nl> - <nl> if ( wanted = = null ) { <nl> return super . matches ( actual ) ; <nl> } else if ( wanted instanceof boolean [ ] <nl> mmm a / src / org / mockito / internal / matchers / equals . java <nl> ppp b / src / org / mockito / internal / matchers / equals . java <nl>
public class equals extends argumentmatcher < object > { <nl> description . appendtext ( wanted . tostring ( ) ) ; <nl> } <nl> appendquoting ( description ) ; <nl> - <nl> } <nl>  <nl> private void appendquoting ( description description ) {
public class descriptivemessagesonverificationinordererrorstest extends testbase <nl> } <nl> } <nl>  <nl> - @ ignore ( " <nl> + @ ignore ( " i don ' t know how to implement it nicely . . . yet : ) " ) <nl> @ test <nl> public void shouldprintverificationinordererrorandshowwantedandactual ( ) { <nl> try {
public class invocationsfinder { <nl> return firstchunk ; <nl> } <nl>  <nl> - <nl> public invocation findsimilarinvocation ( list < invocation > invocations , invocationmatcher wanted , verificationmodeimpl mode ) { <nl> for ( invocation invocation : invocations ) { <nl> string wantedmethodname = wanted . getmethod ( ) . getname ( ) ; <nl>
public class invalidusagetest extends requiresvalidstate { <nl> mock ( finalclass . class ) ; <nl> } <nl>  <nl> - <nl> + interface objectlikeinterface { <nl> + boolean equals ( object o ) ; <nl> + string tostring ( ) ; <nl> + int hashcode ( ) ; <nl> + } <nl> + <nl> + @ test <nl> + public void shouldnotmockobjectmethodsoninterface ( ) throws exception { <nl> + objectlikeinterface inter = mock ( objectlikeinterface . class ) ; <nl> + <nl> + inter . equals ( null ) ; <nl> + inter . tostring ( ) ; <nl> + inter . hashcode ( ) ; <nl> + <nl> + verifyzerointeractions ( inter ) ; <nl> + } <nl> + <nl> + public void shouldnotmockobjectmethodsonclass ( ) throws exception { <nl> + object clazz = mock ( objectlikeinterface . class ) ; <nl> + <nl> + clazz . equals ( null ) ; <nl> + clazz . tostring ( ) ; <nl> + clazz . hashcode ( ) ; <nl> + <nl> + verifyzerointeractions ( clazz ) ; <nl> + } <nl> } <nl> \ no newline at end of file
public class strictlynumberofinvocationsverifier implements verifier { <nl> this . reporter = reporter ; <nl> } <nl>  <nl> - <nl> public void verify ( list < invocation > invocations , invocationmatcher wanted , verificationmodeimpl mode ) { <nl> if ( ! mode . strictmode ( ) ) { <nl> return ; <nl> mmm a / test / org / mockito / internal / verification / invocationsfinderstub . java <nl> ppp b / test / org / mockito / internal / verification / invocationsfinderstub . java <nl>
import org . mockito . exceptions . base . mockitoexception ; <nl> * verify ( mock , atleastonce ( ) ) . somemethod ( " should be called at least once " ) ; <nl> * < / pre > <nl> * <nl> - * see examples { @ link mockito } <nl> + * see examples { @ link mockito # verify ( object , verificationmode ) } <nl> * / <nl> - public class verificationmode { <nl> - <nl> - enum verification { explicit , no_more_wanted } ; <nl> - <nl> - private final integer wantedinvocationcount ; <nl> - private final list < object > mockstobeverifiedinsequence ; <nl> - private final verification verification ; <nl> - <nl> - private verificationmode ( integer wantednumberofinvocations , list < object > mockstobeverifiedinsequence , verification verification ) { <nl> - if ( wantednumberofinvocations ! = null & & wantednumberofinvocations . intvalue ( ) < num ) { <nl> - throw new mockitoexception ( " negative value is not allowed here " ) ; <nl> - } <nl> - assert mockstobeverifiedinsequence ! = null ; <nl> - this . wantedinvocationcount = wantednumberofinvocations ; <nl> - this . mockstobeverifiedinsequence = mockstobeverifiedinsequence ; <nl> - this . verification = verification ; <nl> - } <nl> - <nl> - / * * <nl> - * <nl> - * don ' t use verificationmode class directly . <nl> - * < p > <nl> - * use mockito . atleastonce ( ) and mockito . times ( ) <nl> - * / <nl> - public static void dont_use_this_class_directly_instead_use_static_methods_on_mockito ( ) { } <nl> - <nl> - public static verificationmode atleastonce ( ) { <nl> - return new verificationmode ( null , collections . emptylist ( ) , verification . explicit ) ; <nl> - } <nl> - <nl> - public static verificationmode times ( int wantednumberofinvocations ) { <nl> - return new verificationmode ( wantednumberofinvocations , collections . emptylist ( ) , verification . explicit ) ; <nl> - } <nl> - <nl> - public static verificationmode strict ( integer wantednumberofinvocations , list < object > mockstobeverifiedstrictly ) { <nl> - assert ! mockstobeverifiedstrictly . isempty ( ) ; <nl> - return new verificationmode ( wantednumberofinvocations , mockstobeverifiedstrictly , verification . explicit ) ; <nl> - } <nl> - <nl> - public static verificationmode nomoreinteractions ( ) { <nl> - return new verificationmode ( null , collections . emptylist ( ) , verification . no_more_wanted ) ; <nl> - } <nl> - <nl> - public integer wantedcount ( ) { <nl> - return wantedinvocationcount ; <nl> - } <nl> - <nl> - public list < object > getallmockstobeverifiedinsequence ( ) { <nl> - return mockstobeverifiedinsequence ; <nl> - } <nl> - <nl> - public boolean wantedcountiszero ( ) { <nl> - return wantedinvocationcount ! = null & & wantedinvocationcount = = num ; <nl> - } <nl> - <nl> - public boolean atleastoncemode ( ) { <nl> - return wantedinvocationcount = = null & & verification = = verification . explicit ; <nl> - } <nl> - <nl> - public boolean strictmode ( ) { <nl> - return ! mockstobeverifiedinsequence . isempty ( ) ; <nl> - } <nl> - <nl> - public boolean explicitmode ( ) { <nl> - return verification = = verification . explicit ; <nl> - } <nl> - <nl> - public boolean missingmethodmode ( ) { <nl> - return explicitmode ( ) & & ( atleastoncemode ( ) | | wantedinvocationcount = = num ) ; <nl> - } <nl> - <nl> - public boolean exactnumberofinvocationsmode ( ) { <nl> - return ! atleastoncemode ( ) & & explicitmode ( ) ; <nl> - } <nl> - <nl> - @ override <nl> - public string tostring ( ) { <nl> - return " wanted invocations count : " + wantedinvocationcount + " , mocks to verify in order : " + mockstobeverifiedinsequence ; <nl> - } <nl> - } <nl> \ no newline at end of file <nl> + public interface verificationmode { } <nl> \ no newline at end of file
public class numberofinvocationsverifiertest extends requiresvalidstate { <nl> } <nl>  <nl> @ test <nl> - public void shouldneververifywhenatleastonceverification ( ) throws exception { <nl> + public void shouldneververifywhennotmodeisnotexactnumberofinvocationsmode ( ) throws exception { <nl> verifier . verify ( null , null , atleastonce ( ) ) ; <nl> } <nl>  <nl> - @ test <nl> - public void shouldverifyonlywhenmodeisexplicit ( ) { <nl> - <nl> - verifier . verify ( null , null , verificationmode . nomoreinteractions ( ) ) ; <nl> - } <nl> - <nl> @ test <nl> public void shouldcountactualinvocations ( ) throws exception { <nl> verifier . verify ( invocations , wanted , times ( 4 ) ) ;
public class mockitobehavior < t > { <nl> } <nl>  <nl> public void verifynomoreinteractions ( ) { <nl> - verifynomoreinteractions ( " no more interactions wanted " ) ; <nl> + invocation unverified = registeredinvocations . getfirstunverified ( ) ; <nl> + if ( unverified ! = null ) { <nl> + exceptions . nomoreinteractionswanted ( unverified . tostring ( ) , unverified . getstacktrace ( ) ) ; <nl> + } <nl> } <nl>  <nl> public void verifyzerointeractions ( ) { <nl> - <nl> - verifynomoreinteractions ( " zero interactions wanted " ) ; <nl> - } <nl> - <nl> - private void verifynomoreinteractions ( string message ) { <nl> invocation unverified = registeredinvocations . getfirstunverified ( ) ; <nl> if ( unverified ! = null ) { <nl> - exceptions . nomoreinteractionswanted ( unverified . tostring ( ) , message , unverified . tostring ( ) , unverified . getstacktrace ( ) ) ; <nl> + exceptions . zerointeractionswanted ( unverified . tostring ( ) , unverified . getstacktrace ( ) ) ; <nl> } <nl> } <nl> - <nl> + <nl> public object resultfor ( invocation wanted ) throws throwable { <nl> for ( stubbedinvocation s : stubbed ) { <nl> if ( s . matches ( wanted ) ) {
public class invocation { <nl> private list < iargumentmatcher > argumentstomatchers ( ) { <nl> list < iargumentmatcher > matchers = new linkedlist < iargumentmatcher > ( ) ; <nl> for ( object arg : this . arguments ) { <nl> - <nl> if ( arg ! = null & & arg . getclass ( ) . isarray ( ) ) { <nl> matchers . add ( new arrayequals ( arg ) ) ; <nl> } else { <nl> mmm a / test / org / mockito / invocationtest . java <nl> ppp b / test / org / mockito / invocationtest . java <nl>
public class invocation { <nl> return getmockandmethodname ( ) + getargumentsstring ( matchers ) ; <nl> } <nl>  <nl> - <nl> private string getargumentsstring ( list < iargumentmatcher > matchers ) { <nl> stringbuilder result = new stringbuilder ( ) ; <nl> result . append ( " ( " ) ;
public class nicemessageswhenverificationfailstest { <nl> assertequals ( expectedmessage , actualmessage ) ; <nl> } <nl> } <nl> - <nl> - <nl> }
public class mockfactory < t > { <nl> public object intercept ( object obj , method method , object [ ] args , <nl> methodproxy proxy ) throws throwable { <nl> if ( method . isbridge ( ) ) { <nl> - <nl> return proxy . invokesuper ( obj , args ) ; <nl> } <nl> return handler . invoke ( obj , method , args ) ; <nl> mmm a / test / org / mockito / usage / binding / bridgemethodpuzzletest . java <nl> ppp b / test / org / mockito / usage / binding / bridgemethodpuzzletest . java <nl>
public class stacktrackefilteringtest { <nl> fail ( ) ; <nl> } catch ( verificationassertionerror expected ) { <nl> assertthat ( expected , firstmethodonstackequalsto ( " shouldfilterstacktraceonverify " ) ) ; <nl> - <nl> - <nl> - stacktraceelement [ ] unfilteredstacktrace = expected . getunfilteredstacktrace ( ) ; <nl> - assertequals ( " reportmissinginvocationerror " , unfilteredstacktrace [ 0 ] . getmethodname ( ) ) ; <nl> } <nl> } <nl>  <nl>
public class mockcontrol < t > implements mockawareinvocationhandler < t > , mockitoexp <nl> expectedinvocation expectedinvocation = new expectedinvocation ( invocation , processedmatchers ) ; <nl>  <nl> if ( verifyingmode ! = null ) { <nl> - <nl> behavior . verify ( expectedinvocation , verifyingmode ) ; <nl> return totypemappings . emptyreturnvaluefor ( method . getreturntype ( ) ) ; <nl> } <nl> mmm a / test / org / mockito / internal / invocationbuilder . java <nl> ppp b / test / org / mockito / internal / invocationbuilder . java <nl>
public class invocationbuilder { <nl> private object [ ] args = new object [ ] { } ; <nl> private object mock = " mock " ; <nl>  <nl> - <nl> public invocation toinvocation ( ) { <nl> method method ; <nl> list < class > argtypes = new linkedlist < class > ( ) ; <nl> mmm a / test / org / mockito / internal / mockitobehaviortest . java <nl> ppp b / test / org / mockito / internal / mockitobehaviortest . java <nl>
public class expectedinvocation { <nl> private final list < iargumentmatcher > matchers ; <nl>  <nl> public expectedinvocation ( invocation invocation , list < iargumentmatcher > matchers ) { <nl> - <nl> + if ( matchers = = null ) { <nl> + throw new illegalargumentexception ( " matchers cannot be null " ) ; <nl> + } <nl> this . invocation = invocation ; <nl> this . matchers = matchers ; <nl> } <nl>
public class valuetaglet extends basetaglet { <nl> } <nl> return writer . valuetagoutput ( field , <nl> text , <nl> - <nl> - / / in the j . l . m world , equals will not be accurate <nl> - / / ! field . equals ( tag . holder ( ) ) <nl> - ! utils . elementsequal ( field , holder ) <nl> - ) ; <nl> + ! field . equals ( holder ) ) ; <nl> } else { <nl> / / referenced field is not a constant . <nl> messages . warning ( holder , <nl> mmm a / src / jdk . javadoc / share / classes / jdk / javadoc / internal / doclets / toolkit / util / utils . java <nl> ppp b / src / jdk . javadoc / share / classes / jdk / javadoc / internal / doclets / toolkit / util / utils . java <nl>
inline oop shenandoahbarrierset : : load_reference_barrier ( oop obj ) { <nl> _heap - > in_collection_set ( obj ) ) { / / subsumes null - check <nl> assert ( obj ! = null , " cset check must have subsumed null - check " ) ; <nl> oop fwd = resolve_forwarded_not_null ( obj ) ; <nl> - <nl> - / / we do it for mark - compact , which may have forwarded objects , <nl> - / / and objects in cset and gets here via runtime barriers . <nl> - / / we can probably fix this as soon as mark - compact has its own <nl> - / / marking phase . <nl> if ( obj = = fwd & & _heap - > is_evacuation_in_progress ( ) ) { <nl> - thread * t = thread : : current ( ) ; <nl> + thread * t = thread : : current ( ) ; <nl> shenandoahevacoomscope oom_evac_scope ( t ) ; <nl> return _heap - > evacuate_object ( obj , t ) ; <nl> }
void * decode_instructions_virtual ( uintptr_t start_va , uintptr_t end_va , <nl> return null ; <nl> } <nl>  <nl> - <nl> - cs_option ( cs_handle , cs_opt_syntax , cs_opt_syntax_att ) ; <nl> + options ops = parse_options ( options , printf_callback , printf_stream ) ; <nl> + cs_option ( cs_handle , cs_opt_syntax , ops . intel_syntax ? cs_opt_syntax_intel : cs_opt_syntax_att ) ; <nl>  <nl> cs_insn * insn ; <nl> size_t count = cs_disasm ( cs_handle , buffer , length , ( uintptr_t ) buffer , num , & insn ) ;
jint os : : init_2 ( void ) { <nl> return jni_err ; <nl> } <nl>  <nl> - size_t actual_reserve_size = javathread : : stack_size_at_create ( ) ; <nl> - if ( actual_reserve_size = = num ) { <nl> - / / - xss or - xx : threadstacksize were not given , use the current stack size . <nl> - actual_reserve_size = current_stack_size ( ) ; <nl> - } <nl> - <nl> - / / calculate theoretical max . size of threads to guard against artificial <nl> - / / out - of - memory situations , where all available address - space has been <nl> - / / reserved by thread stacks . <nl> - assert ( actual_reserve_size ! = num , " must have a stack " ) ; <nl> - <nl> - / / calculate the thread limit when we should start doing virtual memory <nl> - / / banging . currently when the threads will have used all but num mb of space . <nl> - / / <nl> - <nl> - / / as reserve size , since on a num - bit platform we ' ll run into that more <nl> - / / often than running out of virtual memory space . we can use the <nl> - / / lower value of the two calculations as the os_thread_limit . <nl> - size_t max_address_space = ( ( size_t ) 1 < < ( bitsperword - num ) ) - ( 200 * k * k ) ; <nl> - win32 : : _os_thread_limit = ( intx ) ( max_address_space / actual_reserve_size ) ; <nl> - <nl> / / at exit methods are called in the reverse order of their registration . <nl> / / there is no limit to the number of functions registered . atexit does <nl> / / not set errno . <nl> mmm a / src / hotspot / os / windows / os_windows . hpp <nl> ppp b / src / hotspot / os / windows / os_windows . hpp <nl>
public class treeinfo { <nl> return s . result ; <nl> } <nl>  <nl> - public static env < attrcontext > scopefor ( jctree node , jccompilationunit unit ) { <nl> - return scopefor ( pathfor ( node , unit ) ) ; <nl> - } <nl> - <nl> - public static env < attrcontext > scopefor ( list < jctree > path ) { <nl> - <nl> - throw new unsupportedoperationexception ( " not implemented yet " ) ; <nl> - } <nl> - <nl> - public static list < jctree > pathfor ( final jctree node , final jccompilationunit unit ) { <nl> - class result extends error { <nl> - static final long serialversionuid = - 5942088234594905625l ; <nl> - @ suppresswarnings ( " serial " ) / / list not statically serilizable <nl> - list < jctree > path ; <nl> - result ( list < jctree > path ) { <nl> - this . path = path ; <nl> - } <nl> - } <nl> - class pathfinder extends treescanner { <nl> - list < jctree > path = list . nil ( ) ; <nl> - public void scan ( jctree tree ) { <nl> - if ( tree ! = null ) { <nl> - path = path . prepend ( tree ) ; <nl> - if ( tree = = node ) <nl> - throw new result ( path ) ; <nl> - super . scan ( tree ) ; <nl> - path = path . tail ; <nl> - } <nl> - } <nl> - } <nl> - try { <nl> - new pathfinder ( ) . scan ( unit ) ; <nl> - } catch ( result result ) { <nl> - return result . path ; <nl> - } <nl> - return list . nil ( ) ; <nl> - } <nl> - <nl> / * * return the statement referenced by a label . <nl> * if the label refers to a loop or switch , return that switch <nl> * otherwise return the labelled statement itself
net_getfiledescriptorid ( jnienv * env ) <nl>  <nl> jint ipv4_supported ( ) <nl> { <nl> - / * <nl> + socket s = socket ( af_inet , sock_stream , num ) ; <nl> + if ( s = = invalid_socket ) { <nl> + return jni_false ; <nl> + } <nl> + closesocket ( s ) ; <nl> + <nl> return jni_true ; <nl> }
<nl> / * <nl> * @ test <nl> * @ summary test that cds still works when the jdk is moved to a new directory <nl> + * @ bug num <nl> * @ requires vm . cds <nl> - * @ requires os . family = = " linux " <nl> + * @ comment this test doesn ' t work on windows because it depends on symlinks <nl> + * @ requires os . family ! = " windows " <nl> * @ library / test / lib <nl> * @ compile test - classes / hello . java <nl> * @ run driver movejdktest <nl> * / <nl>  <nl> - / / this test works only on linux because it depends on symlinks and the name of the hotspot dll ( libjvm . so ) . <nl> - / / it probably doesn ' t work on windows . <nl> - <nl> - <nl> import java . io . file ; <nl> import java . nio . file . files ; <nl> import java . nio . file . path ; <nl>
public class macosflags { <nl> propertystate metalstate = getbooleanprop ( " sun . java2d . metal " , propertystate . unspecified ) ; <nl>  <nl> / / handle invalid combinations to use the default rendering pipeline <nl> - / / current default rendering pipeline is metal <nl> - / / ( the default can be changed to opengl in future just by toggling two states in this if condition block ) <nl> - / / - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - <nl> - <nl> - / / - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - <nl> + / / current default rendering pipeline is opengl <nl> + / / ( the default can be changed to metal in future just by toggling two states in this if condition block ) <nl> if ( ( oglstate = = propertystate . unspecified & & metalstate = = propertystate . unspecified ) | | <nl> ( oglstate = = propertystate . disabled & & metalstate = = propertystate . disabled ) | | <nl> ( oglstate = = propertystate . enabled & & metalstate = = propertystate . enabled ) ) { <nl> - metalstate = propertystate . enabled ; / / enable default pipeline <nl> - oglstate = propertystate . disabled ; / / disable non - default pipeline <nl> + oglstate = propertystate . enabled ; / / enable default pipeline <nl> + metalstate = propertystate . disabled ; / / disable non - default pipeline <nl> } <nl>  <nl> if ( metalstate = = propertystate . unspecified ) {
<nl> / / the underlying platformmutex may support recursive locking but this is not exposed <nl> / / and we account for that possibility in try_lock . <nl>  <nl> - / / the default length of mutex name was originally chosen to be num to avoid <nl> - / / false sharing . now , paddedmutex and paddedmonitor are available for this purpose . <nl> - <nl> - static const int mutex_name_len = num ; <nl> - <nl> class mutex : public cheapobj < mtsynchronizer > { <nl>  <nl> public : <nl>
bool matcher : : const_oop_prefer_decode ( ) { <nl> } <nl>  <nl> bool matcher : : const_klass_prefer_decode ( ) { <nl> - <nl> - / / or condisider the following : <nl> - / / prefer connklass + decodenklass over conp in simple compressed klass mode . <nl> - / / return compressedklasspointers : : base ( ) = = null ; <nl> + / / prefer conp over connklass + decodenklass . <nl> return true ; <nl> }
public : <nl> void add_region ( shenandoahheapregion * r ) ; <nl> bool add_region_check_for_duplicates ( shenandoahheapregion * r ) ; <nl>  <nl> - / / bring per - region statuses to consistency with this collection . <nl> - <nl> - / / region statuses and this collection . should go away after we merge them . <nl> - void update_region_status ( ) ; <nl> - <nl> / / remove region from collection set <nl> void remove_region ( shenandoahheapregion * r ) ; <nl>  <nl> mmm a / src / hotspot / share / gc / shenandoah / shenandoahheuristics . cpp <nl> ppp b / src / hotspot / share / gc / shenandoah / shenandoahheuristics . cpp <nl>
public class flowtest extends abstractrandomtest { <nl> sslengine engineclient = ctx . createsslengine ( ) ; <nl> sslparameters params = ctx . getsupportedsslparameters ( ) ; <nl> params . setapplicationprotocols ( new string [ ] { " proto1 " , " proto2 " } ) ; / / server will choose proto2 <nl> - params . setprotocols ( new string [ ] { " tlsv1 . 2 " } ) ; <nl> engineclient . setsslparameters ( params ) ; <nl> engineclient . setuseclientmode ( true ) ; <nl> completion = new completablefuture < > ( ) ;
fi <nl> installjtreg ( ) <nl> { <nl> # install jtreg if missing <nl> - if [ ! - f " $ jtreg_jar " ] ; then <nl> - exec_command mkdir - p " $ workdir " <nl> - # <nl> - # to $ workdir / jtreg / lib / jtreg . jar <nl> - fatal " error : all tests disabled until locating jtreg . jar implemented . " <nl> + if [ - z " $ jt_home " ] ; then <nl> + if [ ! - f " $ jtreg_jar " ] ; then <nl> + exec_command mkdir - p " $ workdir " <nl> + if [ [ $ { jtreg_bundle : - 7 } = = " . tar . gz " ] ] ; then <nl> + exec_command " ( " cd " $ workdir " " & & " wget " $ jtreg_bundle " " & & " tar - xzf " $ ( basename $ jtreg_bundle ) " " ; " rm - f " $ ( basename $ jtreg_bundle ) " " ) " <nl> + else <nl> + if [ [ $ { jtreg_bundle : - 4 } = = " . zip " ] ] ; then <nl> + exec_command " ( " cd " $ workdir " " & & " wget " $ jtreg_bundle " " & & " unzip " $ ( basename $ jtreg_bundle ) " " ; " rm - f " $ ( basename $ jtreg_bundle ) " " ) " <nl> + else <nl> + fatal ' unsupported extension of jreg bundle [ ' $ jt_bundle_url ' ] . only * . zip or * . tar . gz is supported . ' <nl> + fi <nl> + fi <nl> + fi <nl> + else <nl> + # use jtreg provided via jt_home <nl> + jtreg_jar = $ jt_home / lib / jtreg . jar <nl> fi <nl> + <nl> + echo ' jtreg jar file : ' $ jtreg_jar <nl> }
fi <nl> installjtreg ( ) <nl> { <nl> # install jtreg if missing <nl> - if [ ! - f " $ jtreg_jar " ] ; then <nl> - exec_command mkdir - p " $ workdir " <nl> - # <nl> - # to $ workdir / jtreg / lib / jtreg . jar <nl> - fatal " error : all tests disabled until locating jtreg . jar implemented . " <nl> + if [ - z " $ jtreg_home " ] ; then <nl> + if [ ! - f " $ jtreg_jar " ] ; then <nl> + exec_command mkdir - p " $ workdir " <nl> + if [ [ $ { jtreg_bundle : - 7 } = = " . tar . gz " ] ] ; then <nl> + exec_command " ( " cd " $ workdir " " & & " wget " $ jtreg_bundle " " & & " tar - xzf " $ ( basename $ jtreg_bundle ) " " ; " rm - f " $ ( basename $ jtreg_bundle ) " " ) " <nl> + else <nl> + if [ [ $ { jtreg_bundle : - 4 } = = " . zip " ] ] ; then <nl> + exec_command " ( " cd " $ workdir " " & & " wget " $ jtreg_bundle " " & & " unzip " $ ( basename $ jtreg_bundle ) " " ; " rm - f " $ ( basename $ jtreg_bundle ) " " ) " <nl> + else <nl> + fatal ' unsupported extension of jreg bundle [ ' $ jtreg_bundle_url ' ] . only * . zip or * . tar . gz is supported . ' <nl> + fi <nl> + fi <nl> + fi <nl> + else <nl> + # use jtreg provided via jtreg_home <nl> + jtreg_jar = $ jtreg_home / lib / jtreg . jar <nl> fi <nl> + <nl> + echo ' jtreg jar file : ' $ jtreg_jar <nl> }
class stringtable : public cheapobj < mtsymbol > { <nl> / / strings to this method . <nl> static void inc_dead_counter ( size_t ndead ) { add_items_to_clean ( ndead ) ; } <nl>  <nl> - / / serially invoke " f - > do_oop " on the locations of all oops in the table . <nl> - <nl> - / / the weakprocessor . <nl> - static void oops_do ( oopclosure * f ) ; <nl> - <nl> / / probing <nl> static oop lookup ( symbol * symbol ) ; <nl> static oop lookup ( const jchar * chars , int length ) ; <nl> mmm a / src / hotspot / share / jfr / leakprofiler / chains / rootsetclosure . cpp <nl> ppp b / src / hotspot / share / jfr / leakprofiler / chains / rootsetclosure . cpp <nl>
bool macroassembler : : needs_explicit_null_check ( intptr_t offset ) { <nl> / / with - 1 . another example is graphbuilder : : access_field ( . . . ) which uses - 1 as placeholder <nl> / / for offsets to be patched in later . the - 1 there means the offset is not yet known <nl> / / and may lie outside of the zero - trapping page , and thus we need to ensure we ' re forcing <nl> - / / an explicit null check for - 1 , even if it may otherwise be in the range <nl> - / / [ - cell_header_size , os : : vm_page_size ) . <nl> - <nl> - if ( offset = = - 1 ) return true ; <nl> + / / an explicit null check for - 1 . <nl>  <nl> - / / check if offset is outside of [ - cell_header_size , os : : vm_page_size ) <nl> - return offset < - universe : : heap ( ) - > cell_header_size ( ) | | <nl> - offset > = os : : vm_page_size ( ) ; <nl> + / / check if offset is outside of [ 0 , os : : vm_page_size ( ) ] <nl> + return offset < num | | offset > = os : : vm_page_size ( ) ; <nl> } <nl> mmm a / src / hotspot / share / gc / shared / collectedheap . hpp <nl> ppp b / src / hotspot / share / gc / shared / collectedheap . hpp <nl>
public class gatherdiagnosticinfoobserver implements harness . observer { <nl> * / <nl> @ override <nl> public void startingtestrun ( parameters params ) { <nl> - <nl> - interviewparameters rp = ( interviewparameters ) params ; <nl> - map < string , string > map = new hashmap < > ( ) ; <nl> - rp . save ( map ) ; <nl> - compilejdk = map . get ( " regtest . compilejdk " ) ; <nl> - testjdk = map . get ( " regtest . testjdk " ) ; <nl> + regressionparameters rp = ( regressionparameters ) params ; <nl> + compilejdk = rp . getcompilejdk ( ) . getabsolutefile ( ) . topath ( ) ; <nl> + testjdk = rp . gettestjdk ( ) . getabsolutefile ( ) . topath ( ) ; <nl> } <nl>  <nl> @ override
public : <nl> void do_oop ( oop * p ) { do_oop_work ( p ) ; } <nl> } ; <nl>  <nl> - class shenandoahtraversalweakupdateclosure : public oopclosure { <nl> - private : <nl> - template < class t > <nl> - inline void do_oop_work ( t * p ) { <nl> - / / cannot call maybe_update_with_forwarded , because on traversal - degen <nl> - / / path the collection set is already dropped . instead , do the unguarded store . <nl> - <nl> - t o = rawaccess < > : : oop_load ( p ) ; <nl> - if ( ! compressedoops : : is_null ( o ) ) { <nl> - oop obj = compressedoops : : decode_not_null ( o ) ; <nl> - obj = shenandoahbarrierset : : resolve_forwarded_not_null ( obj ) ; <nl> - shenandoah_assert_marked ( p , obj ) ; <nl> - rawaccess < is_not_null > : : oop_store ( p , obj ) ; <nl> - } <nl> - } <nl> - <nl> - public : <nl> - shenandoahtraversalweakupdateclosure ( ) { } <nl> - <nl> - void do_oop ( narrowoop * p ) { do_oop_work ( p ) ; } <nl> - void do_oop ( oop * p ) { do_oop_work ( p ) ; } <nl> - } ; <nl> - <nl> class shenandoahtraversalkeepaliveupdatedegenclosure : public oopclosure { <nl> private : <nl> shenandoahobjtoscanqueue * _queue ; <nl>
void scavengablenmethods : : verify_nmethod ( nmethod * nm ) { <nl> # endif / / product <nl> } <nl>  <nl> - void scavengablenmethods : : flush_nmethod ( nmethod * nm ) { <nl> - assert_locked_or_safepoint ( codecache_lock ) ; <nl> - <nl> - <nl> - if ( gc_data ( nm ) . on_list ( ) ) { <nl> - codecache : : print_trace ( " flush_nmethod " , nm ) ; <nl> - nmethod * prev = null ; <nl> - for ( nmethod * cur = _head ; cur ! = null ; cur = gc_data ( cur ) . next ( ) ) { <nl> - if ( cur = = nm ) { <nl> - unlist_nmethod ( cur , prev ) ; <nl> - return ; <nl> - } <nl> - prev = cur ; <nl> - } <nl> - } <nl> - } <nl> - <nl> class hasscavengableoops : public oopclosure { <nl> boolobjectclosure * _is_scavengable ; <nl> bool _found ; <nl> mmm a / src / hotspot / share / gc / shared / scavengablenmethods . hpp <nl> ppp b / src / hotspot / share / gc / shared / scavengablenmethods . hpp <nl>
void vm_version : : initialize ( ) { <nl> flag_set_default ( useaesctrintrinsics , false ) ; <nl> } <nl>  <nl> - <nl> - if ( useghashintrinsics ) { <nl> + if ( flag_is_default ( useghashintrinsics ) & & has_crypto_ghash ( ) ) { <nl> + flag_set_default ( useghashintrinsics , true ) ; <nl> + } <nl> + if ( useghashintrinsics & & ! has_crypto_ghash ( ) ) { <nl> warning ( " ghash intrinsics are not available on this cpu " ) ; <nl> flag_set_default ( useghashintrinsics , false ) ; <nl> }
final class sslconfiguration implements cloneable { <nl> static final boolean acknowledgeclosenotify = utilities . getbooleanproperty ( <nl> " jdk . tls . acknowledgeclosenotify " , false ) ; <nl>  <nl> - <nl> - / / delete me <nl> - static int tls13vn ; <nl> - <nl> / / is the extended_master_secret extension supported ? <nl> static { <nl> boolean supportextendedmastersecret = utilities . getbooleanproperty ( <nl>
public class settingsframe extends http2frame { <nl> } <nl> } <nl>  <nl> - public static final int default_initial_window_size = num * k - 1 ; <nl> + / / the initial value is num , 096 octets . <nl> public static final int default_header_table_size = num * k ; <nl> - public static final int default_max_concurrent_streams = num ; <nl> + / / the initial value is num , which indicates that server push is permitted . <nl> + public static final int default_enable_push = num ; <nl> + / / initially , there is no limit to this value . this limit is directional . <nl> + public static final int default_max_concurrent_streams = integer . max_value ; <nl> + / / the initial value is num ^ 16 - 1 ( 65 , 535 ) octets . <nl> + public static final int default_initial_window_size = num * k - 1 ; <nl> + / / the initial value is num ^ 14 ( 16 , 384 ) octets . <nl> public static final int default_max_frame_size = num * k ; <nl>  <nl> - public static settingsframe getdefaultsettings ( ) { <nl> + public static settingsframe defaultrfcsettings ( ) { <nl> settingsframe f = new settingsframe ( ) ; <nl> - <nl> - f . setparameter ( enable_push , num ) ; <nl> + f . setparameter ( enable_push , default_enable_push ) ; <nl> f . setparameter ( header_table_size , default_header_table_size ) ; <nl> f . setparameter ( max_concurrent_streams , default_max_concurrent_streams ) ; <nl> f . setparameter ( initial_window_size , default_initial_window_size ) ; <nl> mmm a / test / jdk / java / net / httpclient / http2 / server / http2testserverconnection . java <nl> ppp b / test / jdk / java / net / httpclient / http2 / server / http2testserverconnection . java <nl>
<nl> - # <nl> - exclusiveaccess . dirs = . <nl> -
public class testbadlinkoption extends javadoctester { <nl> string out = " out " ; <nl> javadoc ( " - d " , out , <nl> " - sourcepath " , testsrc , <nl> - " - link " , out , <nl> + " - link " , " a - non - existent - link " , <nl> " pkg " ) ; <nl> - checkexit ( exit . ok ) ; <nl> + checkexit ( exit . error ) ; <nl>  <nl> - <nl> checkoutput ( output . out , true , <nl> " error reading file : " ) ; <nl> } <nl> mmm a / test / langtools / jdk / javadoc / doclet / testlinkoption / testnewlineinlink . java <nl> ppp b / test / langtools / jdk / javadoc / doclet / testlinkoption / testnewlineinlink . java <nl>
import org . testng . annotations . listeners ; <nl> @ listeners ( guitestlistener . class ) <nl> public class buttondemoscreenshottest { <nl>  <nl> - private static final int button_count = num ; <nl> + private static final int [ ] buttons = { 0 , num , num , num , num , num } ; / / " open browser " buttons ( 6 , num ) open a browser , so ignore <nl> + private static strictimagecomparator scomparator = null ; <nl> + <nl> + @ beforeclass <nl> + public void init ( ) { <nl> + scomparator = new strictimagecomparator ( ) ; <nl> + } <nl>  <nl> @ test <nl> public void test ( ) throws exception { <nl>
package javax . lang . model . element ; <nl> import java . util . list ; <nl>  <nl> / * * <nl> - * represents a module program element . provides access to information <nl> - * about the module and its members . <nl> + * represents a module program element . provides access to <nl> + * information about the module , its directives , and its members . <nl> * <nl> * @ see javax . lang . model . util . elements # getmoduleof <nl> * @ since num <nl> + * @ jls num . 7 module declarations <nl> * @ spec jpms <nl> - * / <nl> + * / <nl> public interface moduleelement extends element , qualifiednameable { <nl>  <nl> / * * <nl>
public interface moduleelement extends element , qualifiednameable { <nl> } ; <nl>  <nl> / * * <nl> - * represents a " module statement " within the declaration of this module . <nl> + * represents a directive within the declaration of this <nl> + * module . the directives of a module declaration configure the <nl> + * module in the java platform module system . <nl> * <nl> * @ since num <nl> * @ spec jpms <nl> - * <nl> - * / <nl> + * / <nl> interface directive { <nl> / * * <nl> * returns the { @ code kind } of this directive .
const bool matcher : : pass_original_key_for_aes ( ) { <nl> return true ; <nl> } <nl>  <nl> - / * note : all currently supported sparc hw provides fast conversion . <nl> - * <nl> - * <nl> - * / <nl> - const bool matcher : : convl2fsupported ( void ) { <nl> - return vm_version : : has_fast_fxtof ( ) ; <nl> - } <nl> + / / note : all currently supported sparc hw provides fast conversion . <nl> + const bool matcher : : convl2fsupported ( void ) { return true ; } <nl>  <nl> / / is this branch offset short enough that a short branch can be used ? <nl> / / <nl>
public class printingprocessor extends abstractprocessor { <nl> defaultaction ( e , false ) ; <nl>  <nl> if ( ! e . isunnamed ( ) ) { <nl> - <nl> - / / by the language model api , but should be printed <nl> - / / here once available . <nl> + if ( e . isopen ( ) ) { <nl> + writer . print ( " open " ) ; <nl> + } <nl> writer . println ( " module " + e . getqualifiedname ( ) + " { " ) ; <nl> indentation + + ; <nl> for ( moduleelement . directive directive : e . getdirectives ( ) ) {
src_subdirs + = share / classes <nl>  <nl> # find all module - info . java files for the current build target platform and <nl> # configuration . <nl> - # <nl> - # imported module - info . java in jake due to a change in format . remove once <nl> - # new format is standard in jdk num and javafx delivers just that . <nl> # param num - module to find for , set to * for finding all <nl> findallmoduleinfos = \ <nl> $ ( wildcard \ <nl> $ ( foreach sub , $ ( src_subdirs ) , \ <nl> $ ( patsubst % , % / $ ( strip $ 1 ) / $ ( sub ) / module - info . java , $ ( top_src_dirs ) ) ) \ <nl> - $ ( patsubst % , % / $ ( strip $ 1 ) / module - info . java , $ ( firstword $ ( import_modules_src ) ) ) ) <nl> + $ ( patsubst % , % / $ ( strip $ 1 ) / module - info . java , $ ( import_modules_src ) ) ) <nl>  <nl> # find module - info . java files in the specific source dir <nl> # param num - src dir to find module - info . java files in
$ ( eval $ ( call setupjavadocgeneration , jdknet , \ <nl>  <nl> targets + = $ ( jdknet ) <nl>  <nl> - # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # <nl> - <nl> - # <nl> - # this target is temporarily added for internal use for now . <nl> - $ ( eval $ ( call setupjavadocgeneration , jlinkplugins , \ <nl> - modules : = jdk . jlink , \ <nl> - packages : = jdk . tools . jlink . plugin , \ <nl> - api_root : = jdk , \ <nl> - dest_dir : = jlink , \ <nl> - title : = jlink plugin api - experimental , \ <nl> - first_copyright_year : = num , \ <nl> - disabled_doclint : = html missing syntax , \ <nl> - ) ) <nl> - <nl> - targets + = $ ( jlinkplugins ) <nl> - <nl> # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # <nl> # copy jdwp html file
public abstract class editortestbase extends repltooltesting { <nl> ) ; <nl> } <nl>  <nl> - @ test ( enabled = false ) <nl> public void testeditclass1 ( ) { <nl> testeditor ( <nl> a - > assertclass ( a , " class a { } " , " class " , " a " ) , <nl>
public abstract class editortestbase extends repltooltesting { <nl> ) ; <nl> } <nl>  <nl> - @ test ( enabled = false ) <nl> public void testeditmethod1 ( ) { <nl> testeditor ( <nl> a - > assertmethod ( a , " void f ( ) { } " , " ( ) void " , " f " ) , <nl>
protected : <nl> # if include_jvmci <nl> / / description of the different counters <nl> / / receivertypedata for instanceof / checkcast / aastore : <nl> - / / c1 / c2 : count is incremented on type overflow and decremented for failed type checks <nl> - / / jvmci : count decremented for failed type checks and nonprofiled_count is incremented on type overflow <nl> - <nl> + / / jvmci only : nonprofiled_count is incremented on type overflow <nl> / / virtualcalldata for invokevirtual / invokeinterface : <nl> - / / c1 / c2 : count is incremented on type overflow <nl> - / / jvmci : count is incremented on type overflow , nonprofiled_count is incremented on method overflow <nl> + / / count is incremented on type overflow <nl> + / / jvmci only : nonprofiled_count is incremented on method overflow <nl>  <nl> / / jvmci is interested in knowing the percentage of type checks involving a type not explicitly in the profile <nl> nonprofiled_count_off_set = counter_cell_count ,
public class idgeneratortest { <nl> } <nl> } <nl>  <nl> - @ test ( enabled = false ) <nl> public void testidinexception ( ) { <nl> jshell . builder builder = getbuilder ( ) . idgenerator ( ( ( snippet , id ) - > " custom " + id ) ) ; <nl> try ( jshell jshell = builder . build ( ) ) { <nl> evalexception evalexception = ( evalexception ) jshell . eval ( " throw new error ( ) ; " ) . get ( 0 ) . exception ( ) ; <nl> for ( stacktraceelement ste : evalexception . getstacktrace ( ) ) { <nl> - asserttrue ( ste . getfilename ( ) . startswith ( " custom " ) , " not started with \ " custom \ " : " <nl> + asserttrue ( ste . getfilename ( ) . startswith ( " # custom " ) , " not started with \ " # custom \ " : " <nl> + ste . getfilename ( ) ) ; <nl> } <nl> jshell . eval ( " void f ( ) { g ( ) ; } " ) ; <nl> unresolvedreferenceexception unresolvedexception = ( unresolvedreferenceexception ) jshell . eval ( " f ( ) ; " ) . get ( 0 ) . exception ( ) ; <nl> for ( stacktraceelement ste : unresolvedexception . getstacktrace ( ) ) { <nl> - asserttrue ( ste . getfilename ( ) . startswith ( " custom " ) , " not started with \ " custom \ " : " <nl> + asserttrue ( ste . getfilename ( ) . startswith ( " # custom " ) , " not started with \ " # custom \ " : " <nl> + ste . getfilename ( ) ) ; <nl> } <nl> }
public class toolsimpletest extends repltooltesting { <nl> ) ; <nl> } <nl>  <nl> - @ test ( enabled = false ) <nl> public void defineunresolvedvar ( ) { <nl> test ( <nl> ( a ) - > assertcommand ( a , " undefined x " ,
public class beanpropertytest { <nl> / / enums <nl>  <nl> class < ? > enumcases [ ] = { <nl> - <nl> - <nl> - / / e . class , e . two . getclass ( ) , eb . class <nl> + e . class , e . two . getclass ( ) , eb . class <nl> } ; <nl>  <nl> int ne = num ; <nl>
endif <nl> # add dependencies on other jmod files . only java . base needs access to other <nl> # jmods . <nl> ifeq ( $ ( module ) , java . base ) <nl> + all_upgradeable_modules = $ ( call findallupgradeablemodules ) <nl> # when creating a buildjdk , we don ' t need to add hashes to java . base <nl> ifneq ( $ ( creating_buildjdk ) , true ) <nl> deps + = $ ( patsubst % , $ ( jmods_dir ) / % . jmod , \ <nl> - $ ( filter - out java . base , $ ( call findallmodules ) ) ) <nl> - <nl> - # <nl> - # modules <nl> - exclude_hash_modules : = $ ( upgradeable_modules ) \ <nl> - java . se . ee \ <nl> - jdk . rmic \ <nl> - jdk . xml . bind \ <nl> - jdk . xml . ws \ <nl> - # <nl> - <nl> - exclude_pattern : = $ ( strip $ ( subst $ ( space ) , | , $ ( strip $ ( exclude_hash_modules ) ) ) ) <nl> + $ ( filter - out java . base $ ( all_upgradeable_modules ) , $ ( call findallmodules ) ) ) <nl> + <nl> + exclude_pattern : = $ ( strip $ ( subst $ ( space ) , | , $ ( strip $ ( all_upgradeable_modules ) ) ) ) <nl>  <nl> jmod_flags + = - - modulepath $ ( jmods_dir ) \ <nl> - - hash - modules ' ^ ( ? ! $ ( exclude_pattern ) ) ' <nl> mmm a / make / main . gmk <nl> ppp b / make / main . gmk <nl>
class eval { <nl>  <nl> private list < snippetevent > declare ( snippet si , diaglist generateddiagnostics ) { <nl> unit c = new unit ( state , si , null , generateddiagnostics ) ; <nl> - <nl> - / / ignores duplicates <nl> - <nl> - if ( c . isredundant ( ) ) { <nl> - return collections . emptylist ( ) ; <nl> - } <nl> - <nl> set < unit > ins = new linkedhashset < > ( ) ; <nl> ins . add ( c ) ; <nl> set < unit > outs = compileandload ( ins ) ; <nl> mmm a / langtools / src / jdk . jshell / share / classes / jdk / jshell / snippet . java <nl> ppp b / langtools / src / jdk . jshell / share / classes / jdk / jshell / snippet . java <nl>
public class limitmodstest { <nl> public void testwithaddmods ( ) throws exception { <nl> int exitvalue ; <nl>  <nl> - / / java - limitmods java . base - addmods java . logging , jdk . unsupported - listmods <nl> + / / java - limitmods java . base - addmods java . logging - listmods <nl> exitvalue = executetestjava ( " - limitmods " , " java . base " , <nl> - " - addmods " , <nl> - " java . logging , jdk . unsupported " , <nl> + " - addmods " , " java . logging " , <nl> " - listmods " ) <nl> . outputto ( system . out ) <nl> . errorto ( system . out )
public class droptest extends kullatesting { <nl> assertactivekeys ( ) ; <nl> } <nl>  <nl> - @ test ( enabled = false ) <nl> public void testdropimport ( ) { <nl> persistentsnippet imp = importkey ( asserteval ( " import java . util . * ; " ) ) ; <nl> persistentsnippet decl = varkey ( <nl> mmm a / langtools / test / jdk / jshell / methodstest . java <nl> ppp b / langtools / test / jdk / jshell / methodstest . java <nl>
public abstract class phantomcleanable < t > extends phantomreference < t > <nl> this . list = cleanerimpl . getcleanerimpl ( cleaner ) . phantomcleanablelist ; <nl> insert ( ) ; <nl>  <nl> - <nl> - cleaner . getclass ( ) ; <nl> - referent . getclass ( ) ; <nl> + / / ensure referent and cleaner remain accessible <nl> + reference . reachabilityfence ( referent ) ; <nl> + reference . reachabilityfence ( cleaner ) ; <nl> } <nl>  <nl> / * * <nl> mmm a / jdk / src / java . base / share / classes / jdk / internal / ref / softcleanable . java <nl> ppp b / jdk / src / java . base / share / classes / jdk / internal / ref / softcleanable . java <nl>
public abstract class softcleanable < t > extends softreference < t > <nl> list = cleanerimpl . getcleanerimpl ( cleaner ) . softcleanablelist ; <nl> insert ( ) ; <nl>  <nl> - <nl> - cleaner . getclass ( ) ; <nl> - referent . getclass ( ) ; <nl> + / / ensure referent and cleaner remain accessible <nl> + reference . reachabilityfence ( referent ) ; <nl> + reference . reachabilityfence ( cleaner ) ; <nl> } <nl>  <nl> / * * <nl> mmm a / jdk / src / java . base / share / classes / jdk / internal / ref / weakcleanable . java <nl> ppp b / jdk / src / java . base / share / classes / jdk / internal / ref / weakcleanable . java <nl>
public abstract class weakcleanable < t > extends weakreference < t > <nl> list = cleanerimpl . getcleanerimpl ( cleaner ) . weakcleanablelist ; <nl> insert ( ) ; <nl>  <nl> - <nl> - cleaner . getclass ( ) ; <nl> - referent . getclass ( ) ; <nl> + / / ensure referent and cleaner remain accessible <nl> + reference . reachabilityfence ( referent ) ; <nl> + reference . reachabilityfence ( cleaner ) ; <nl> + <nl> } <nl>  <nl> / * *
public final class nashorncallsitedescriptor extends callsitedescriptor { <nl> * / <nl> public static nashorncallsitedescriptor get ( final methodhandles . lookup lookup , final string name , <nl> final methodtype methodtype , final int flags ) { <nl> - final operation baseop = operations [ flags & operation_mask ] ; <nl> + final int opindex = flags & operation_mask ; <nl> + final operation baseop = operations [ opindex ] ; <nl> final string decodedname = namecodec . decode ( name ) ; <nl> - <nl> - final operation op = decodedname . isempty ( ) ? baseop : new namedoperation ( baseop , decodedname ) ; <nl> + final operation op = decodedname . isempty ( ) ? baseop : getnamedoperation ( decodedname , opindex , baseop ) ; <nl> return get ( lookup , op , methodtype , flags ) ; <nl> } <nl>  <nl> + private static namedoperation getnamedoperation ( final string name , final int opindex , final operation baseop ) { <nl> + final map < string , reference < namedoperation > > namedops = named_operations [ opindex ] ; <nl> + final reference < namedoperation > ref = namedops . get ( name ) ; <nl> + if ( ref ! = null ) { <nl> + final namedoperation existing = ref . get ( ) ; <nl> + if ( existing ! = null ) { <nl> + return existing ; <nl> + } <nl> + } <nl> + final namedoperation newop = new namedoperation ( baseop , name ) ; <nl> + namedops . put ( name , new weakreference < > ( newop ) ) ; <nl> + return newop ; <nl> + } <nl> + <nl> private static nashorncallsitedescriptor get ( final methodhandles . lookup lookup , final operation operation , final methodtype methodtype , final int flags ) { <nl> final nashorncallsitedescriptor csd = new nashorncallsitedescriptor ( lookup , operation , methodtype , flags ) ; <nl> / / many of these call site descriptors are identical ( e . g . every getter for a property color will be <nl> - / / " get_property : color ( object ) object " , so it makes sense canonicalizing them . <nl> - final concurrentmap < nashorncallsitedescriptor , nashorncallsitedescriptor > classcanonicals = canonicals . get ( lookup . lookupclass ( ) ) ; <nl> - final nashorncallsitedescriptor canonical = classcanonicals . putifabsent ( csd , csd ) ; <nl> + / / " get_property : color ( object ) object " , so it makes sense canonicalizing them . make an exception for <nl> + / / optimistic call site descriptors , as they also carry a program point making them unique . <nl> + if ( csd . isoptimistic ( ) ) { <nl> + return csd ; <nl> + } <nl> + final nashorncallsitedescriptor canonical = canonicals . get ( lookup . lookupclass ( ) ) . putifabsent ( csd , csd ) ; <nl> return canonical ! = null ? canonical : csd ; <nl> }
$ ( eval $ ( call setuplauncher , rmid , \ <nl>  <nl> $ ( eval $ ( call setuplauncher , rmiregistry , \ <nl> - djava_args = ' { " - j - ms8m " $ ( comma ) " sun . rmi . registry . registryimpl " $ ( comma ) } ' ) ) <nl> - <nl> - # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # <nl> - <nl> - # <nl> - # the java - rmi . cgi script in bin / only gets delivered in certain situations <nl> - # <nl> - java_rmi_cgi : = $ ( support_outputdir ) / modules_cmds / $ ( module ) / java - rmi . cgi <nl> - ifeq ( $ ( openjdk_target_os ) , linux ) <nl> - targets + = $ ( java_rmi_cgi ) <nl> - endif <nl> - ifeq ( $ ( openjdk_target_os ) , solaris ) <nl> - targets + = $ ( java_rmi_cgi ) <nl> - endif <nl> - <nl> - # <nl> - # on windows java - rmi . cgi shouldn ' t be bundled since java num . 2 , but has been built all <nl> - # this time anyway . since jdk6 , it has been built from the wrong source and resulted <nl> - # in a ( almost ) copy of the standard java launcher named " java - rmi . exe " ending up in <nl> - # the final images bin dir . this weird behavior is mimicked here in the converted <nl> - # makefiles for now . should probably just be deleted . <nl> - # http : / / bugs . sun . com / bugdatabase / view_bug . do ? bug_id = 6512052 <nl> - ifeq ( $ ( openjdk_target_os ) , windows ) <nl> - $ ( eval $ ( call setuplauncher , java - rmi , , \ <nl> - $ ( call set_shared_library_mapfile , $ ( jdk_topdir ) / make / java / main / java / mapfile - $ ( openjdk_target_cpu ) ) , , , , , , , , , rmi ) ) <nl> - else <nl> - $ ( java_rmi_cgi ) : $ ( jdk_topdir ) / src / java . rmi / unix / bin / java - rmi . cgi . sh <nl> - $ ( call install - file ) <nl> - $ ( chmod ) a + x $ @ <nl> - endif <nl> - <nl> - # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # <nl> mmm a / jdk / src / java . rmi / unix / bin / java - rmi . cgi . sh <nl> ppp / dev / null <nl>
void vm_version : : determine_section_size ( ) { <nl>  <nl> void vm_version : : determine_features ( ) { <nl> # if defined ( abi_elfv2 ) <nl> - const int code_size = ( num_features + 1 + 2 * 7 ) * bytesperinstword ; <nl> + const int code_size = ( num_features + 1 + 2 * 1 ) * bytesperinstword ; <nl> # else <nl> / / num instwords for each call ( function descriptor + blr instruction ) . <nl> const int code_size = ( num_features + 1 + 2 * 7 ) * bytesperinstword ; <nl>
fi <nl> - r $ openwin_home / lib $ openjdk_target_cpu_isadir " <nl> fi <nl>  <nl> - # <nl> - # weird sol10 something check . . . <nl> - # <nl> - if test " x $ { openjdk_target_os } " = xsolaris ; then <nl> - if test " ` uname - r ` " = " 5 . 10 " ; then <nl> - if test " ` $ { egrep } - c xlineargradient $ { openwin_home } / share / include / x11 / extensions / xrender . h ` " = " 0 " ; then <nl> - x_cflags = " $ { x_cflags } - dsolaris10_no_xrender_structs " <nl> - fi <nl> - fi <nl> - fi <nl> - <nl> ac_ext = c <nl> ac_cpp = ' $ cpp $ cppflags ' <nl> ac_compile = ' $ cc - c $ cflags $ cppflags conftest . $ ac_ext > & 5 ' <nl>
ac_defun_once ( [ lib_setup_x11 ] , <nl> - r $ openwin_home / lib $ openjdk_target_cpu_isadir " <nl> fi <nl>  <nl> - # <nl> - # weird sol10 something check . . . <nl> - # <nl> - if test " x $ { openjdk_target_os } " = xsolaris ; then <nl> - if test " ` uname - r ` " = " 5 . 10 " ; then <nl> - if test " ` $ { egrep } - c xlineargradient $ { openwin_home } / share / include / x11 / extensions / xrender . h ` " = " 0 " ; then <nl> - x_cflags = " $ { x_cflags } - dsolaris10_no_xrender_structs " <nl> - fi <nl> - fi <nl> - fi <nl> - <nl> ac_lang_push ( c ) <nl> old_cflags = " $ cflags " <nl> - cflags = " $ cflags $ x_cflags " <nl> + cflags = " $ cflags $ sysroot_cflags $ x_cflags " <nl>  <nl> # need to include xlib . h and xutil . h to avoid " present but cannot be compiled " warnings on solaris num <nl> ac_check_headers ( [ x11 / extensions / shape . h x11 / extensions / xrender . h x11 / extensions / xtest . h x11 / intrinsic . h ] , <nl>
java_sun_font_freetypefontscaler_getfontmetricsnative ( <nl> so , we have to do adust them explicitly and stay consistent with what <nl> freetype does to outlines . * / <nl>  <nl> - / * for bolding glyphs are not just widened . height is also changed <nl> - ( see ftsynth . c ) . <nl> - <nl> - <nl> - proportionally to glyoh shape . * / <nl> - if ( context - > dobold ) { <nl> - bmodifier = ft_mulfix ( <nl> - scalerinfo - > face - > units_per_em , <nl> - scalerinfo - > face - > size - > metrics . y_scale ) / 24 ; <nl> - } <nl> - <nl>  <nl> / * * * * note : only some metrics are affected by styling * * * / <nl>  <nl> + / * see https : / / bugs . debian . org / cgi - bin / bugreport . cgi ? bug = 657854 * / <nl> + # define ft_mulfixfloatshift6 ( a , b ) ( ( ( float ) ( a ) ) * ( ( float ) ( b ) ) / num . 0 / num . 0 ) <nl> + <nl> + / * <nl> + * see freetype source code : src / base / ftobjs . c ft_recompute_scaled_metrics ( ) <nl> + * http : / / icedtea . classpath . org / bugzilla / show_bug . cgi ? id = 1659 <nl> + * / <nl> / * ascent * / <nl> ax = num ; <nl> - ay = - ( jfloat ) ft26dot6tofloat ( ft_mulfix ( <nl> - ( ( jlong ) scalerinfo - > face - > ascender + bmodifier / 2 ) , <nl> + ay = - ( jfloat ) ( ft_mulfixfloatshift6 ( <nl> + ( ( jlong ) scalerinfo - > face - > ascender ) , <nl> ( jlong ) scalerinfo - > face - > size - > metrics . y_scale ) ) ; <nl> / * descent * / <nl> dx = num ; <nl> - dy = - ( jfloat ) ft26dot6tofloat ( ft_mulfix ( <nl> - ( ( jlong ) scalerinfo - > face - > descender + bmodifier / 2 ) , <nl> + dy = - ( jfloat ) ( ft_mulfixfloatshift6 ( <nl> + ( ( jlong ) scalerinfo - > face - > descender ) , <nl> ( jlong ) scalerinfo - > face - > size - > metrics . y_scale ) ) ; <nl> / * baseline * / <nl> bx = by = num ; <nl>  <nl> / * leading * / <nl> lx = num ; <nl> - ly = ( jfloat ) ft26dot6tofloat ( ft_mulfix ( <nl> - ( jlong ) scalerinfo - > face - > height + bmodifier , <nl> + ly = ( jfloat ) ( ft_mulfixfloatshift6 ( <nl> + ( jlong ) scalerinfo - > face - > height , <nl> ( jlong ) scalerinfo - > face - > size - > metrics . y_scale ) ) <nl> + ay - dy ; <nl> / * max advance * / <nl> mx = ( jfloat ) ft26dot6tofloat ( <nl> scalerinfo - > face - > size - > metrics . max_advance + <nl> - num * bmodifier + <nl> oblique_modifier ( scalerinfo - > face - > size - > metrics . height ) ) ; <nl> my = num ;
final class codegenerator extends nodeoperatorvisitor < codegeneratorlexicalcontex <nl> return false ; <nl> } <nl>  <nl> - <nl> - if ( isrestof ( ) ) { <nl> - return false ; <nl> - } <nl> - <nl> / / make sure that undefined has not been overridden or scoped as a local var <nl> / / between us and global <nl> if ( ! compiler . isglobalsymbol ( lc . getcurrentfunction ( ) , " undefined " ) ) {
jniexport jdouble jnicall <nl> java_sun_awt_cgraphicsdevice_nativegetxresolution <nl> ( jnienv * env , jclass class , jint displayid ) <nl> { <nl> - <nl> - / / to use nsscreen api instead . . . <nl> + / / cgdisplayscreensize can return num if displayid is invalid <nl> cgsize size = cgdisplayscreensize ( displayid ) ; <nl> cgrect rect = cgdisplaybounds ( displayid ) ; <nl> / / num inch = = num . 4 mm <nl> jfloat inches = size . width / num . 4f ; <nl> - jfloat dpi = rect . size . width / inches ; <nl> - return dpi ; <nl> + return inches > num ? rect . size . width / inches : num ; <nl> } <nl>  <nl> / * <nl>
jniexport jdouble jnicall <nl> java_sun_awt_cgraphicsdevice_nativegetyresolution <nl> ( jnienv * env , jclass class , jint displayid ) <nl> { <nl> - <nl> - / / to use nsscreen api instead . . . <nl> + / / cgdisplayscreensize can return num if displayid is invalid <nl> cgsize size = cgdisplayscreensize ( displayid ) ; <nl> cgrect rect = cgdisplaybounds ( displayid ) ; <nl> / / num inch = = num . 4 mm <nl> jfloat inches = size . height / num . 4f ; <nl> - jfloat dpi = rect . size . height / inches ; <nl> - return dpi ; <nl> + return inches > num ? rect . size . height / inches : num ; <nl> } <nl>  <nl> / *
public final class lwctoolkit extends lwtoolkit { <nl>  <nl> @ override <nl> public void sync ( ) { <nl> - <nl> + oglrenderqueue . sync ( ) ; <nl> + / / setneedsdisplay ( ) selector was sent to the appropriate calayer so now <nl> + / / we have to flush the native selectors queue . <nl> + flushnativeselectors ( ) ; <nl> } <nl>  <nl> @ override <nl>
public class attr extends jctree . visitor { <nl>  <nl> listbuffer < attribute . typecompound > buf = new listbuffer < > ( ) ; <nl> for ( jcannotation anno : annotations ) { <nl> - if ( anno . attribute ! = null ) { <nl> - <nl> - / / ordering issue , where annotate . flush is called when <nl> - / / the attribute is not set yet . for an example failure <nl> - / / try the referenceinfos / nestedtypes . java test . <nl> - / / any better solutions ? <nl> - buf . append ( ( attribute . typecompound ) anno . attribute ) ; <nl> - } <nl> - / / eventually we will want to throw an exception here , but <nl> - / / we can ' t do that just yet , because it gets triggered <nl> - / / when attempting to attach an annotation that isn ' t <nl> - / / defined . <nl> + assert . checknonnull ( anno . attribute ) ; <nl> + buf . append ( ( attribute . typecompound ) anno . attribute ) ; <nl> } <nl> return buf . tolist ( ) ; <nl> }
bool dependencies : : is_concrete_method ( method * m ) { <nl>  <nl> / / we could also return false if m does not yet appear to be <nl> / / executed , if the vm version supports this distinction also . <nl> + / / default methods are considered " concrete " as well . <nl> return ! m - > is_abstract ( ) & & <nl> - ! instanceklass : : cast ( m - > method_holder ( ) ) - > is_interface ( ) ; <nl> - <nl> - / / considered as " concrete " in this situation . for now they <nl> - / / are not . <nl> + ! m - > is_overpass ( ) ; / / error functions aren ' t concrete <nl> } <nl>  <nl>  <nl> mmm / dev / null <nl> ppp b / hotspot / test / compiler / inlining / defaultandconcretemethodscha . java <nl>
public class code { <nl> } <nl>  <nl> private int findexceptionindex ( int catchtype ) { <nl> - if ( catchtype = = integer . min_value ) { <nl> - / / we didn ' t set the catch type <nl> - / / this shouldn ' t happen . <nl> - <nl> - return - 1 ; <nl> - } <nl> list < char [ ] > iter = catchinfo . tolist ( ) ; <nl> int len = catchinfo . length ( ) ; <nl> for ( int i = num ; i < len ; + + i ) {
public final class integer extends number implements comparable < integer > { <nl> / / jit case the dispatch overhead doesn ' t exist and the <nl> / / " trick " is considerably faster than the classic code . <nl> / / <nl> - <nl> - / / sequence . <nl> - / / <nl> / / re : division by invariant integers using multiplication <nl> / / t gralund , p montgomery <nl> / / acm pldi num
<nl> # questions . <nl> # <nl>  <nl> - # <nl> - # <nl> - # and add them to configure <nl> - # <nl> + # openwin is defined on solaris . <nl> openwin_lib : = $ ( openwin_home ) / lib <nl>  <nl> win_awt_lib : = $ ( jdk_outputdir ) / objs / libawt / awt . lib <nl>
void nmethodsweeper : : sweep_code_cache ( ) { <nl> event . set_endtime ( sweep_end_counter ) ; <nl> event . set_sweepindex ( _traversals ) ; <nl> event . set_sweepfractionindex ( nmethodsweepfraction - _invocations + num ) ; <nl> - event . set_sweptcount ( <nl> + event . set_sweptcount ( swept_count ) ; <nl> event . set_flushedcount ( _flushed_count ) ; <nl> event . set_markedcount ( _marked_count ) ; <nl> event . set_zombifiedcount ( _zombified_count ) ;
build_libraries + = $ ( build_libj2pkcs11 ) <nl>  <nl> # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # <nl>  <nl> - ifndef disable_intree_ec <nl> - # <nl> - # <nl> - # is not present <nl> - # <nl> + ifeq ( $ ( enable_intree_ec ) , yes ) <nl> + <nl> build_libsunec_flags : = - i $ ( jdk_topdir ) / src / share / native / sun / security / ec \ <nl> - i $ ( jdk_topdir ) / src / share / native / sun / security / ec / impl
default : all <nl> include makebase . gmk <nl> include javacompilation . gmk <nl>  <nl> - # <nl> - javac_jars ? = " - xbootclasspath / p : $ ( langtools_outputdir ) / dist / bootstrap / lib / javac . jar " \ <nl> - - jar $ ( langtools_outputdir ) / dist / bootstrap / lib / javac . jar <nl> - <nl> jdk_classes : = $ ( jdk_outputdir ) / classes <nl>  <nl> nashorn_jar : = $ ( nashorn_dist ) / nashorn . jar <nl>
javac_jars ? = " - xbootclasspath / p : $ ( langtools_outputdir ) / dist / bootstrap / lib / javac <nl> - jar $ ( langtools_outputdir ) / dist / bootstrap / lib / javac . jar <nl>  <nl> jdk_classes : = $ ( jdk_outputdir ) / classes <nl> - # <nl> - dynalink_jar : = $ ( nashorn_topdir ) / build / dynalink / dynalink . jar <nl>  <nl> nashorn_jar : = $ ( nashorn_dist ) / nashorn . jar <nl> nashorn_version : = $ ( jdk_version ) <nl>
public class cdatatransferer extends datatransferer { <nl>  <nl> @ override <nl> protected bytearrayoutputstream convertfilelisttobytes ( arraylist < string > filelist ) throws ioexception { <nl> - <nl> - return null ; <nl> + bytearrayoutputstream bos = new bytearrayoutputstream ( ) ; <nl> + for ( int i = num ; i < filelist . size ( ) ; i + + ) <nl> + { <nl> + byte [ ] bytes = filelist . get ( i ) . getbytes ( ) ; <nl> + bos . write ( bytes , num , bytes . length ) ; <nl> + bos . write ( 0 ) ; <nl> + } <nl> + return bos ; <nl> + } <nl> + <nl> + @ override <nl> + protected boolean isurilistformat ( long format ) { <nl> + string nat = getnativeforformat ( format ) ; <nl> + if ( nat = = null ) { <nl> + return false ; <nl> + } <nl> + try { <nl> + dataflavor df = new dataflavor ( nat ) ; <nl> + if ( df . getprimarytype ( ) . equals ( " text " ) & & df . getsubtype ( ) . equals ( " uri - list " ) ) { <nl> + return true ; <nl> + } <nl> + } catch ( exception e ) { <nl> + / / not a mime format . <nl> + } <nl> + return false ; <nl> } <nl> }
$ ( install_libraries_here ) / server / % . debuginfo : $ ( install_libraries_here ) / % . debug <nl> $ ( install_libraries_here ) / server / % . diz : $ ( install_libraries_here ) / % . diz <nl> $ ( mkdir ) - p $ ( @ d ) <nl> $ ( rm ) $ @ <nl> - ifeq ( really_weird , 1 ) <nl> - $ ( ln ) - s . . / $ ( @ f ) $ @ <nl> - else <nl> - # <nl> - # <nl> - # <nl> $ ( rm ) $ @ . tmp $ ( basename $ @ ) . debuginfo <nl> $ ( ln ) - s . . / $ ( basename $ ( @ f ) ) . debuginfo $ ( basename $ @ ) . debuginfo <nl> - $ ( zip ) - q - y $ @ . tmp $ ( basename $ @ ) . debuginfo <nl> + $ ( cd ) $ ( @ d ) & & $ ( zip ) - q - y $ @ . tmp $ ( basename $ ( @ f ) ) . debuginfo <nl> $ ( rm ) $ ( basename $ @ ) . debuginfo <nl> $ ( mv ) $ @ . tmp $ @ <nl> - endif <nl>  <nl> $ ( install_libraries_here ) / client / % $ ( shared_library_suffix ) : $ ( install_libraries_here ) / % $ ( shared_library_suffix ) <nl> $ ( mkdir ) - p $ ( @ d ) <nl>
$ ( install_libraries_here ) / client / % . debuginfo : $ ( install_libraries_here ) / % . debug <nl> $ ( install_libraries_here ) / client / % . diz : $ ( install_libraries_here ) / % . diz <nl> $ ( mkdir ) - p $ ( @ d ) <nl> $ ( rm ) $ @ <nl> - ifeq ( really_weird , 1 ) <nl> - $ ( ln ) - s . . / $ ( @ f ) $ @ <nl> - else <nl> - # <nl> - # <nl> - # <nl> $ ( rm ) $ @ . tmp $ ( basename $ @ ) . debuginfo <nl> $ ( ln ) - s . . / $ ( basename $ ( @ f ) ) . debuginfo $ ( basename $ @ ) . debuginfo <nl> - $ ( zip ) - q - y $ @ . tmp $ ( basename $ @ ) . debuginfo <nl> + $ ( cd ) $ ( @ d ) & & $ ( zip ) - q - y $ @ . tmp $ ( basename $ ( @ f ) ) . debuginfo <nl> $ ( rm ) $ ( basename $ @ ) . debuginfo <nl> $ ( mv ) $ @ . tmp $ @ <nl> - endif <nl>  <nl> # # # # # # #
endif <nl> exfiles + = - linux - arm . java \ <nl> - linux - ppc . java <nl>  <nl> - # <nl> ifeq ( $ ( openjdk_target_os ) , windows ) <nl> exfiles + = sun / nio / ch / abstractpollselectorimpl . java \ <nl> - sun / nio / ch / devpollarraywrapper . java \ <nl> - sun / nio / ch / devpollselectorimpl . java \ <nl> - sun / nio / ch / devpollselectorprovider . java \ <nl> - sun / nio / ch / inheritedchannel . java \ <nl> sun / nio / ch / pollselectorprovider . java \ <nl> - sun / nio / ch / pollselectorimpl . java \ <nl> - sun / nio / ch / port . java \ <nl> - sun / nio / ch / simpleasynchronousfilechannelimpl . java \ <nl> - sun / nio / ch / solarisasynchronouschannelprovider . java \ <nl> - sun / nio / ch / solariseventport . java \ <nl> - sun / nio / ch / unixasynchronousserversocketchannelimpl . java \ <nl> - sun / nio / ch / unixasynchronoussocketchannelimpl . java <nl> - exfiles + = sun / net / sdp / sdpprovider . java <nl> - else <nl> - exfiles + = sun / net / www / protocol / http / ntlm / ntlmauthsequence . java <nl> + sun / nio / ch / simpleasynchronousfilechannelimpl . java <nl> endif <nl>  <nl> # exclude nimbus files from rt . jar <nl> mmm a / jdk / makefiles / compilenativelibraries . gmk <nl> ppp b / jdk / makefiles / compilenativelibraries . gmk <nl>
public class xrdrawimage extends drawimage { <nl> surfacedata srcdata = dstdata . getsourcesurfacedata ( img , <nl> sungraphics2d . transform_generic , sg . imagecomp , bgcolor ) ; <nl>  <nl> - if ( srcdata ! = null & & ! isbgoperation ( srcdata , bgcolor ) ) { <nl> - / / & & srcdata instanceof xrsurfacedata ) { <nl> + if ( srcdata ! = null & & ! isbgoperation ( srcdata , bgcolor ) <nl> + & & interptype < = affinetransformop . type_bilinear ) { <nl> surfacetype srctype = srcdata . getsurfacetype ( ) ; <nl> surfacetype dsttype = dstdata . getsurfacetype ( ) ;
public abstract class lwcomponentpeer < t extends component , d extends jcomponent > <nl>  <nl> @ override <nl> public image createimage ( int w , int h ) { <nl> - <nl> - return getgraphicsconfiguration ( ) . createcompatibleimage ( w , h ) ; <nl> + cgraphicsconfig gc = ( cgraphicsconfig ) getgraphicsconfiguration ( ) ; <nl> + return gc . createacceleratedimage ( gettarget ( ) , w , h ) ; <nl> } <nl>  <nl> @ override
public abstract class lwcursormanager { <nl> } else { <nl> cursor = ( c ! = null ) ? c . getcursor ( ) : null ; <nl> } <nl> - <nl> setcursor ( cursor ) ; <nl> } <nl>  <nl> / * * <nl> * returns the first visible , enabled and showing component under cursor . <nl> + * returns null for modal blocked windows . <nl> * <nl> * @ param cursorpos current cursor position . <nl> - * @ return component <nl> + * @ return component or null . <nl> * / <nl> private static final component findcomponent ( final point cursorpos ) { <nl> final lwcomponentpeer < ? , ? > peer = lwwindowpeer . getpeerundercursor ( ) ; <nl> component c = null ; <nl> - if ( peer ! = null ) { <nl> + if ( peer ! = null & & peer . getwindowpeerorself ( ) . getblocker ( ) = = null ) { <nl> c = peer . gettarget ( ) ; <nl> if ( c instanceof container ) { <nl> final point p = peer . getlocationonscreen ( ) ;
package sun . lwawt . macosx ; <nl>  <nl> import sun . awt . datatransfer . toolkitthreadblockedhandler ; <nl>  <nl> - <nl> - <nl> final class ctoolkitthreadblockedhandler implements toolkitthreadblockedhandler { <nl> + private final lwctoolkit toolkit = ( lwctoolkit ) java . awt . toolkit . getdefaulttoolkit ( ) ; <nl> + <nl> public void lock ( ) { <nl> } <nl>  <nl>
void connectiongraph : : find_init_values ( node * alloc , vectorset * visited , phasetra <nl> node * store = ini - > find_captured_store ( offset , type2aelembytes ( ft ) , phase ) ; <nl> if ( store ! = null & & store - > is_store ( ) ) { <nl> value = store - > in ( memnode : : valuein ) ; <nl> - } else if ( ptn - > edge_count ( ) > num ) { / / are there oop stores ? <nl> - / / check for a store which follows allocation without branches . <nl> + } else { <nl> + / / there could be initializing stores which follow allocation . <nl> / / for example , a volatile field store is not collected <nl> - <nl> - / / <nl> - / / search all references to the same field which use different <nl> - / / addp nodes , for example , in the next case : <nl> - / / <nl> - / / point p [ ] = new point [ 1 ] ; <nl> - / / if ( x ) { p [ 0 ] = new point ( ) ; p [ 0 ] . x = x ; } <nl> - / / if ( p [ 0 ] ! = null ) { y = p [ 0 ] . x ; } / / has castpp <nl> + / / by initialize node . <nl> / / <nl> - for ( uint next = ei ; ( next < ae_cnt ) & & ( value = = null ) ; next + + ) { <nl> - uint fpi = pta - > edge_target ( next ) ; / / field ( addp ) <nl> - pointstonode * ptf = ptnode_adr ( fpi ) ; <nl> - if ( ptf - > offset ( ) = = offset ) { <nl> - node * nf = ptf - > _node ; <nl> - for ( duiterator_fast imax , i = nf - > fast_outs ( imax ) ; i < imax ; i + + ) { <nl> - store = nf - > fast_out ( i ) ; <nl> - if ( store - > is_store ( ) & & store - > in ( 0 ) ! = null ) { <nl> - node * ctrl = store - > in ( 0 ) ; <nl> - while ( ! ( ctrl = = ini | | ctrl = = alloc | | ctrl = = null | | <nl> - ctrl = = c - > root ( ) | | ctrl = = c - > top ( ) | | ctrl - > is_region ( ) | | <nl> - ctrl - > is_iftrue ( ) | | ctrl - > is_iffalse ( ) ) ) { <nl> - ctrl = ctrl - > in ( 0 ) ; <nl> - } <nl> - if ( ctrl = = ini | | ctrl = = alloc ) { <nl> - value = store - > in ( memnode : : valuein ) ; <nl> - break ; <nl> - } <nl> - } <nl> - } <nl> - } <nl> - } <nl> + / / need to check for dependent loads to separate such stores from <nl> + / / stores which follow loads . for now , add initial value null so <nl> + / / that compare pointers optimization works correctly . <nl> } <nl> } <nl> if ( value = = null | | value ! = ptnode_adr ( value - > _idx ) - > _node ) {
protected : <nl>  <nl> enum { <nl> / / amd <nl> - cpu_family_amd_11h = num , <nl> + cpu_family_amd_11h = num x11 , <nl> / / intel <nl> cpu_family_intel_core = num , <nl> - cpu_model_nehalem_ep = num , <nl> - cpu_model_westmere_ep = num , <nl> - <nl> - cpu_model_sandybridge_ep = num <nl> + cpu_model_nehalem = num x1e , <nl> + cpu_model_nehalem_ep = num x1a , <nl> + cpu_model_nehalem_ex = num x2e , <nl> + cpu_model_westmere = num x25 , <nl> + cpu_model_westmere_ep = num x2c , <nl> + cpu_model_westmere_ex = num x2f , <nl> + cpu_model_sandybridge = num x2a , <nl> + cpu_model_sandybridge_ep = num x2d , <nl> + cpu_model_ivybridge_ep = num x3a <nl> } cpuextendedfamily ; <nl>  <nl> / / cpuid information block . all info derived from executing cpuid with <nl>
public : <nl> static bool is_intel_tsc_synched_at_init ( ) { <nl> if ( is_intel_family_core ( ) ) { <nl> uint32_t ext_model = extended_cpu_model ( ) ; <nl> - if ( ext_model = = cpu_model_nehalem_ep | | <nl> - ext_model = = cpu_model_westmere_ep | | <nl> - <nl> - ext_model = = cpu_model_sandybridge_ep ) { <nl> - / / num - socket invtsc support . ex versions with num sockets are not <nl> - / / guaranteed to synchronize tscs at initialization via a double <nl> - / / handshake . the tscs can be explicitly set in software . code <nl> - / / that uses tsc values must be prepared for them to arbitrarily <nl> - / / jump backward or forward . <nl> + if ( ext_model = = cpu_model_nehalem_ep | | <nl> + ext_model = = cpu_model_westmere_ep | | <nl> + ext_model = = cpu_model_sandybridge_ep | | <nl> + ext_model = = cpu_model_ivybridge_ep ) { <nl> + / / < = num - socket invariant tsc support . ex versions are usually used <nl> + / / in > num - socket systems and likely don ' t synchronize tscs at <nl> + / / initialization . <nl> + / / code that uses tsc values must be prepared for them to arbitrarily <nl> + / / jump forward or backward . <nl> return true ; <nl> } <nl> }
lresult awtframe : : proxywindowproc ( uint message , wparam wparam , lparam lparam , ms <nl> setimetargetcomponent ( null ) ; <nl> } <nl> break ; <nl> - <nl> - / / the list wm_mousewheel messages come to the poxy , not to the list . why ? <nl> - case wm_mousewheel : <nl> - focusowner = awtcomponent : : getcomponent ( sm_focusowner ) ; <nl> - if ( focusowner ! = null & & <nl> - focusowner ! = this ) / / avoid recursive calls <nl> - { <nl> - retvalue = focusowner - > windowproc ( message , wparam , lparam ) ; <nl> - mr = mrconsume ; <nl> - } <nl> - break ; <nl> case wm_setfocus : <nl> if ( sm_insynthesizefocus ) break ; / / pass it up the windowproc chain
public abstract class xrsurfacedata extends xsurfacedata { <nl> if ( xrpipe = = null ) { <nl> try { <nl> suntoolkit . awtlock ( ) ; <nl> - xgc = renderqueue . creategc ( xid ) ; <nl> - / / clean up ? <nl> + xgc = xcreategc ( getnativeops ( ) ) ; <nl>  <nl> xrpipe = new xrrenderer ( maskbuffer . getmaskbuffer ( ) ) ; <nl> xrtxpipe = new pixeltoshapeconverter ( xrpipe ) ;
jint arguments : : parse ( const javavminitargs * args ) { <nl> } <nl> scavengerootsincode = num ; <nl> } <nl> - # ifdef compiler2 <nl> - if ( enableinvokedynamic & & doescapeanalysis ) { <nl> - <nl> - / / simply disable ea by default . <nl> - if ( flag_is_default ( doescapeanalysis ) ) { <nl> - doescapeanalysis = false ; <nl> - } <nl> - } <nl> - # endif <nl>  <nl> if ( printgcdetails ) { <nl> / / turn on - verbose : gc options as well
import javax . swing . jpanel ; <nl>  <nl> public class test4903007 extends abstracttest < jpanel > { <nl> public static void main ( string [ ] args ) throws exception { <nl> - new test4903007 ( ) . test ( false ) ; <nl> + new test4903007 ( ) . test ( true ) ; <nl> } <nl>  <nl> protected jpanel getobject ( ) { <nl> mmm a / jdk / test / java / beans / xmlencoder / javax_swing_jlayeredpane . java <nl> ppp b / jdk / test / java / beans / xmlencoder / javax_swing_jlayeredpane . java <nl>
import javax . swing . jpanel ; <nl>  <nl> public final class javax_swing_jlayeredpane extends abstracttest < jlayeredpane > { <nl> public static void main ( string [ ] args ) { <nl> - new javax_swing_jlayeredpane ( ) . test ( false ) ; <nl> + new javax_swing_jlayeredpane ( ) . test ( true ) ; <nl> } <nl>  <nl> private static void init ( jlayeredpane pane , int layer , int x , int y , int w , int h , color color ) {
public class dispatcherhandlersmappingdescriptionprovider implements mappingdesc <nl>  <nl> @ override <nl> public void attributes ( map < string , object > attributes ) { <nl> - <nl> - throw new unsupportedoperationexception ( " auto - generated method stub " ) ; <nl> } <nl>  <nl> @ override <nl> mmm a / spring - boot - project / spring - boot - actuator / src / test / java / org / springframework / boot / actuate / web / mappings / mappingsendpointtests . java <nl> ppp b / spring - boot - project / spring - boot - actuator / src / test / java / org / springframework / boot / actuate / web / mappings / mappingsendpointtests . java <nl>
public class webfluxendpointcorsintegrationtests { <nl> . header ( " origin " , " spring . example . org " ) <nl> . header ( httpheaders . access_control_request_method , " get " ) <nl> . exchange ( ) <nl> - . expectstatus ( ) . isforbidden ( ) ; <nl> - <nl> + . expectstatus ( ) . isforbidden ( ) <nl> + . expectheader ( ) . doesnotexist ( httpheaders . access_control_allow_origin ) ; <nl> } <nl>  <nl> @ test <nl>
public class webfluxendpointcorsintegrationtests { <nl> . of ( " management . endpoints . web . cors . allowed - origins : spring . example . org " , <nl> " management . endpoints . web . cors . allow - credentials : false " ) <nl> . applyto ( this . context ) ; <nl> - performacceptedcorsrequest ( " / actuator / beans " ) ; <nl> - <nl> + performacceptedcorsrequest ( " / actuator / beans " ) <nl> + . expectheader ( ) . doesnotexist ( httpheaders . access_control_allow_credentials ) ; <nl> }
public class flywayautoconfiguration { <nl> else { <nl> flyway . setdatasource ( this . datasource ) ; <nl> } <nl> - <nl> flyway . setlocations ( this . properties . getlocations ( ) . toarray ( new string [ 0 ] ) ) ; <nl> - <nl> return flyway ; <nl> }
public class configurationpropertiesbindingpostprocessor <nl> propertysourcesplaceholderconfigurer configurer = getsinglepropertysourcesplaceholderconfigurer ( ) ; <nl> if ( configurer ! = null ) { <nl> / / flatten the sources into a single list so they can be iterated <nl> - <nl> return new flatpropertysources ( configurer . getappliedpropertysources ( ) ) ; <nl> } <nl> if ( this . environment instanceof configurableenvironment ) {
<nl> < / plugins > <nl> < / pluginmanagement > <nl> < / build > <nl> - < repositories > <nl> - < ! - - <nl> - < repository > <nl> - < id > spring - milestones < / id > <nl> - < name > spring milestones < / name > <nl> - < url > http : / / repo . spring . io / milestone < / url > <nl> - < snapshots > <nl> - < enabled > false < / enabled > <nl> - < / snapshots > <nl> - < / repository > <nl> - < / repositories > <nl> < / project >
import org . springframework . jmx . export . mbeanexporter ; <nl> @ conditionalonexpression ( " $ { endpoints . jmx . enabled : true } " ) <nl> class endpointmbeanexportautoconfiguration { <nl>  <nl> + private relaxedpropertyresolver environment ; <nl> + <nl> + @ autowired <nl> + public void setenvironment ( environment environment ) { <nl> + this . environment = new relaxedpropertyresolver ( environment ) ; <nl> + } <nl> + <nl> @ bean <nl> public endpointmbeanexporter endpointmbeanexporter ( ) { <nl> - <nl> - return new endpointmbeanexporter ( ) ; <nl> + endpointmbeanexporter mbeanexporter = new endpointmbeanexporter ( ) ; <nl> + string domainname = this . environment . getproperty ( " endpoints . jmx . domain_name " ) ; <nl> + if ( stringutils . hastext ( domainname ) ) { <nl> + mbeanexporter . setdomainname ( domainname ) ; <nl> + } <nl> + string key = this . environment . getproperty ( " endpoints . jmx . key " ) ; <nl> + if ( stringutils . hastext ( key ) ) { <nl> + mbeanexporter . setkey ( key ) ; <nl> + } <nl> + return mbeanexporter ; <nl> } <nl> - <nl> } <nl> \ no newline at end of file
public class authenticationmanagerconfiguration { <nl> + user . getpassword ( ) + " \n\n " ) ; <nl> } <nl>  <nl> - <nl> set < string > roles = new linkedhashset < string > ( user . getrole ( ) ) ; <nl>  <nl> builder . withuser ( user . getname ( ) ) . password ( user . getpassword ( ) )
public class basicerrorcontrollerspecialintegrationtests { <nl> } <nl>  <nl> @ configuration <nl> - <nl> - @ enableautoconfiguration ( exclude = serverpropertiesautoconfiguration . class ) <nl> + @ enableautoconfiguration <nl> protected static class parentconfiguration { <nl>  <nl> } <nl> mmm a / spring - boot - autoconfigure / src / main / java / org / springframework / boot / autoconfigure / web / serverpropertiesautoconfiguration . java <nl> ppp b / spring - boot - autoconfigure / src / main / java / org / springframework / boot / autoconfigure / web / serverpropertiesautoconfiguration . java <nl>
public class simplejsonparser implements jsonparser { <nl> if ( json . startswith ( " \ " " ) ) { <nl> return trimtrailingcharacter ( trimleadingcharacter ( json , ' " ' ) , ' " ' ) ; <nl> } <nl> - return json ; <nl> + return json ; <nl> } <nl>  <nl> private static string trimtrailingcharacter ( string string , char c ) {
public class cleancommand extends abstractcommand { <nl> } <nl>  <nl> file grapes = new file ( home , " grapes " ) ; <nl> - <nl> - string [ ] packages = new string [ ] { " org . springframework . bootstrap " } ; <nl> - for ( string pkg : packages ) { <nl> - file file = new file ( grapes , pkg ) ; <nl> + arraylist < string > specs = new arraylist < string > ( options . nonoptionarguments ( ) ) ; <nl> + if ( ! specs . contains ( " org . springframework . bootstrap " ) ) { <nl> + specs . add ( 0 , " org . springframework . bootstrap " ) ; <nl> + } <nl> + for ( string spec : specs ) { <nl> + string group = spec ; <nl> + string module = null ; <nl> + if ( spec . contains ( " : " ) ) { <nl> + group = spec . substring ( 0 , spec . indexof ( " : " ) ) ; <nl> + module = spec . substring ( spec . indexof ( " : " ) + num ) ; <nl> + } <nl> + file file = module = = null ? new file ( grapes , group ) : new file ( new file ( <nl> + grapes , group ) , module ) ; <nl> if ( file . exists ( ) ) { <nl> - fileutil . forcedelete ( file ) ; <nl> + if ( options . has ( this . alloption ) <nl> + | | group . equals ( " org . springframework . bootstrap " ) ) { <nl> + fileutil . forcedelete ( file ) ; <nl> + } else { <nl> + for ( object obj : fileutil . listall ( file , collections . emptylist ( ) ) ) { <nl> + file candidate = ( file ) obj ; <nl> + if ( candidate . getname ( ) . contains ( " snapshot " ) ) { <nl> + fileutil . forcedelete ( candidate ) ; <nl> + } <nl> + } <nl> + } <nl> } <nl> } <nl>  <nl> mmm a / spring - bootstrap - cli / src / main / java / org / springframework / bootstrap / cli / springbootstrapcli . java <nl> ppp b / spring - bootstrap - cli / src / main / java / org / springframework / bootstrap / cli / springbootstrapcli . java <nl>
