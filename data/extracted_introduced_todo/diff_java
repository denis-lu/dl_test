int catclientinitwithconfig ( const char * appkey , catclientconfig * config ) { <nl> if ( ! initcatserverconnmanager ( ) ) { <nl> g_cat_init = num ; <nl> g_cat_enabledflag = num ; <nl> - inner_log ( clog_error , " failed to initialize cat : error occurred while getting router from cat - server . " ) ; <nl> + inner_log ( clog_error , " failed to initialize cat : error occurred while getting router from remote server . " ) ; <nl> return num ; <nl> } <nl>  <nl> + <nl> + <nl> initcataggregatorthread ( ) ; <nl> initcatsenderthread ( ) ; <nl> initcatmonitorthread ( ) ;
public class testbusinessmessage { <nl>  <nl> private static final string payorder = " payorder " ; <nl>  <nl> + @ test <nl> + public void testmutilthead ( ) throws exception { <nl> + int total = num ; <nl> + countdownlatch latch = new countdownlatch ( total ) ; <nl> + <nl> + for ( int i = num ; i < num ; i + + ) { <nl> + threads . forgroup ( " cat " ) . start ( new catthread ( latch , i ) ) ; <nl> + } <nl> + <nl> + thread . sleep ( 10000 ) ; <nl> + } <nl> + <nl> + public class catthread implements task { <nl> + <nl> + private countdownlatch m_latch ; <nl> + <nl> + private int m_count ; <nl> + <nl> + public catthread ( countdownlatch latch , int count ) { <nl> + m_latch = latch ; <nl> + m_count = count ; <nl> + } <nl> + <nl> + @ override <nl> + public void run ( ) { <nl> + m_latch . countdown ( ) ; <nl> + try { <nl> + m_latch . await ( ) ; <nl> + } catch ( interruptedexception e ) { <nl> + <nl> + e . printstacktrace ( ) ; <nl> + } <nl> + <nl> + for ( int i = num ; i < num ; i + + ) { <nl> + transaction transaction = cat . newtransaction ( " test " , " test " + m_count ) ; <nl> + <nl> + transaction . setstatus ( message . success ) ; <nl> + transaction . complete ( ) ; <nl> + } <nl> + } <nl> + <nl> + @ override <nl> + public string getname ( ) { <nl> + return " cat - test - thread " ; <nl> + } <nl> + <nl> + @ override <nl> + public void shutdown ( ) { <nl> + } <nl> + <nl> + } <nl> + <nl> @ test <nl> public void testevent ( ) throws exception { <nl> for ( int i = num ; i < num ; i + + ) { <nl> cat . logerror ( new nullpointerexception ( ) ) ; <nl> } <nl> - <nl> + <nl> thread . sleep ( 10000 ) ; <nl> } <nl> - <nl> + <nl> @ test <nl> public void test ( ) throws exception { <nl> while ( true ) { <nl>
public class localmessagebucketmanager extends containerholder implements messag <nl> if ( min > num ) { <nl> moveoldmessages ( ) ; <nl> } <nl> + } else { <nl> + <nl> } <nl> } catch ( throwable e ) { <nl> m_logger . error ( e . getmessage ( ) , e ) ;
<nl> + package com . dianping . cat . report . alert ; <nl> + <nl> + import com . dianping . cat . cat ; <nl> + <nl> + public class exceptionbuilder { <nl> + public static void main ( string [ ] args ) { <nl> + while ( true ) { <nl> + cat . logevent ( " error " , " http : / / www . dianping . com / shop / { shopid } " , " error " , null ) ; <nl> + try { <nl> + thread . sleep ( 50000 ) ; <nl> + system . out . println ( " log error " ) ; <nl> + } catch ( interruptedexception e ) { <nl> + <nl> + e . printstacktrace ( ) ; <nl> + } <nl> + } <nl> + } <nl> + }
public class transactionanalyzer extends abstractmessageanalyzer < transactionrepo <nl> protected void processtransaction ( transactionreport report , messagetree tree , transaction t ) { <nl> if ( m_serverconfigmanager . discardtransaction ( t ) ) { <nl> return ; <nl> + <nl> + } else if ( " abtest " . equals ( t . gettype ( ) ) ) { <nl> + return ; <nl> } else { <nl> string ip = tree . getipaddress ( ) ; <nl> transactiontype type = report . findorcreatemachine ( ip ) . findorcreatetype ( t . gettype ( ) ) ;
public class defaultproblemhandler extends problemhandler { <nl> if ( message instanceof transaction ) { <nl> string type = message . gettype ( ) ; <nl>  <nl> + <nl> if ( ! " abtest " . equals ( type ) ) { <nl> processtransaction ( machine , ( transaction ) message , tree ) ; <nl> } <nl> mmm a / cat - consumer / src / main / java / com / dianping / cat / consumer / transaction / transactionanalyzer . java <nl> ppp b / cat - consumer / src / main / java / com / dianping / cat / consumer / transaction / transactionanalyzer . java <nl>
public class transactionanalyzer extends abstractmessageanalyzer < transactionrepo <nl>  <nl> if ( message instanceof transaction ) { <nl> transaction root = ( transaction ) message ; <nl> + <nl> + <nl> + string type = message . gettype ( ) ; <nl>  <nl> - processtransaction ( report , tree , root ) ; <nl> + if ( ! " abtest " . equals ( type ) ) { <nl> + processtransaction ( report , tree , root ) ; <nl> + } <nl> } <nl> } <nl>  <nl> mmm a / cat - home / src / main / webapp / jsp / report / home / releasenotes . jsp <nl> ppp b / cat - home / src / main / webapp / jsp / report / home / releasenotes . jsp <nl>
<nl> + package com . dianping . cat . home . abtest . report ; <nl> + <nl> + import java . util . list ; <nl> + import java . util . map ; <nl> + <nl> + import org . junit . before ; <nl> + import org . junit . test ; <nl> + import org . unidal . dal . jdbc . dalexception ; <nl> + import org . unidal . lookup . componenttestcase ; <nl> + <nl> + import com . dianping . cat . consumer . advanced . dal . businessreport ; <nl> + import com . dianping . cat . consumer . advanced . dal . businessreportdao ; <nl> + import com . dianping . cat . consumer . advanced . dal . businessreportentity ; <nl> + import com . dianping . cat . consumer . metric . model . entity . abtest ; <nl> + import com . dianping . cat . consumer . metric . model . entity . group ; <nl> + import com . dianping . cat . consumer . metric . model . entity . metricitem ; <nl> + import com . dianping . cat . consumer . metric . model . entity . metricreport ; <nl> + import com . dianping . cat . consumer . metric . model . entity . point ; <nl> + import com . dianping . cat . consumer . metric . model . transform . defaultnativeparser ; <nl> + <nl> + public class retinaimgbusinessreporttest extends componenttestcase { <nl> + <nl> + private businessreportdao m_businessreportdao ; <nl> + <nl> + @ before <nl> + public void prepare ( ) { <nl> + try { <nl> + m_businessreportdao = lookup ( businessreportdao . class ) ; <nl> + } catch ( exception e ) { <nl> + e . printstacktrace ( ) ; <nl> + } <nl> + } <nl> + <nl> + @ test <nl> + public void test ( ) { <nl> + try { <nl> + list < businessreport > reports = m_businessreportdao . findallbyproductlineid ( 19437 , " tuangou " , <nl> + businessreportentity . readset_full ) ; <nl> + <nl> + metric pair = caculate ( reports , " / detail " ) ; <nl> + <nl> + system . out . println ( string . format ( " detail : a = % d , b = % d , sum_a = % f , sum_b = % f " , pair . m_counta , <nl> + pair . m_countb , pair . m_suma , pair . m_sumb ) ) ; <nl> + <nl> + reports = m_businessreportdao . findallbyproductlineid ( 19437 , " pay " , businessreportentity . readset_full ) ; <nl> + <nl> + pair = caculate ( reports , " / order / submitorder " ) ; <nl> + system . out . println ( string . format ( " / order / submitorder : a = % d , b = % d , sum_a = % f , sum_b = % f " , pair . m_counta , <nl> + pair . m_countb , pair . m_suma , pair . m_sumb ) ) ; <nl> + <nl> + pair = caculate ( reports , " order " ) ; <nl> + system . out . println ( string . format ( " order : a = % d , b = % d , sum_a = % f , sum_b = % f " , pair . m_counta , <nl> + pair . m_countb , pair . m_suma , pair . m_sumb ) ) ; <nl> + <nl> + pair = caculate ( reports , " payment . pending " ) ; <nl> + system . out . println ( string . format ( " payment . pending : a = % d , b = % d , sum_a = % f , sum_b = % f " , pair . m_counta , <nl> + pair . m_countb , pair . m_suma , pair . m_sumb ) ) ; <nl> + } catch ( dalexception e ) { <nl> + <nl> + e . printstacktrace ( ) ; <nl> + } <nl> + <nl> + } <nl> + <nl> + private metric caculate ( list < businessreport > reports , string target ) { <nl> + metric pair = new metric ( ) ; <nl> + <nl> + for ( businessreport report : reports ) { <nl> + metricreport metricreport = defaultnativeparser . parse ( report . getcontent ( ) ) ; <nl> + <nl> + / / system . out . println ( metricreport ) ; <nl> + map < string , metricitem > items = metricreport . getmetricitems ( ) ; <nl> + <nl> + for ( metricitem item : items . values ( ) ) { <nl> + if ( item . getid ( ) . equals ( target ) ) { <nl> + map < string , abtest > abs = item . getabtests ( ) ; <nl> + <nl> + for ( abtest abtest : abs . values ( ) ) { <nl> + map < string , group > groups = abtest . getgroups ( ) ; <nl> + <nl> + for ( group group : groups . values ( ) ) { <nl> + if ( group . getname ( ) . equalsignorecase ( " a " ) ) { <nl> + map < integer , point > points = group . getpoints ( ) ; <nl> + <nl> + for ( point point : points . values ( ) ) { <nl> + pair . m_counta + = point . getcount ( ) ; <nl> + <nl> + if ( point . getavg ( ) % num . 9 = = num . 0 | | point . getavg ( ) % num = = num . 0 ) { <nl> + / / system . out . println ( point . getsum ( ) ) ; <nl> + pair . m_suma + = point . getsum ( ) ; <nl> + } <nl> + } <nl> + } else if ( group . getname ( ) . equalsignorecase ( " b " ) ) { <nl> + map < integer , point > points = group . getpoints ( ) ; <nl> + <nl> + for ( point point : points . values ( ) ) { <nl> + pair . m_countb + = point . getcount ( ) ; <nl> + <nl> + if ( point . getavg ( ) % num . 9 = = num . 0 | | point . getavg ( ) % num = = num . 0 ) { <nl> + / / system . out . println ( point . getsum ( ) ) ; <nl> + pair . m_sumb + = point . getsum ( ) ; <nl> + } <nl> + <nl> + } <nl> + } <nl> + } <nl> + } <nl> + } <nl> + } <nl> + } <nl> + <nl> + return pair ; <nl> + } <nl> + <nl> + class metric { <nl> + public int m_counta = num ; <nl> + <nl> + public int m_countb = num ; <nl> + <nl> + public double m_suma = num . 0 ; <nl> + <nl> + public double m_sumb = num . 0 ; <nl> + } <nl> + }
public class defaultstorage < t extends data > implements storage < t > { <nl> @ override <nl> public synchronized void add ( t data ) { <nl> long timespan = compare ( data . gettimestamp ( ) , currentdata . gettimestamp ( ) ) ; <nl> + <nl> if ( timespan = = num ) { <nl> currentdata . merge ( data ) ; <nl> } else if ( timespan > num ) { <nl> mmm / dev / null <nl> ppp b / dog - home / src / main / java / com / dianping / dog / alarm / strategy / alarmstrategy . java <nl>
<nl> + package com . dianping . dog . alarm . strategy ; <nl> + <nl> + import com . dianping . dog . alarm . rule . message . message ; <nl> + <nl> + public class emailalarmstrategy implements alarmstrategy { <nl> + <nl> + @ override <nl> + public boolean dostrategy ( message message ) { <nl> + <nl> + return false ; <nl> + } <nl> + <nl> + } <nl> mmm / dev / null <nl> ppp b / dog - home / src / main / java / com / dianping / dog / alarm / strategy / smsalarmstrategy . java <nl>
<nl> + package com . dianping . dog . alarm . strategy ; <nl> + <nl> + import com . dianping . dog . alarm . rule . message . message ; <nl> + <nl> + public class smsalarmstrategy implements alarmstrategy { <nl> + <nl> + @ override <nl> + public boolean dostrategy ( message message ) { <nl> + <nl> + return false ; <nl> + } <nl> + <nl> + }
public class showhandler extends abstractcommandhandler { <nl> showstatus ( c ) ; <nl> } else if ( " variables " . equalsignorecase ( first ) ) { <nl> showvariables ( c ) ; <nl> - } else { <nl> + } else if ( " collation " . equalsignorecase ( first ) ) { <nl> + showcollation ( c ) ; <nl> + } <nl> + else { <nl> error ( c , errorcode . er_unknown_com_error , " unsupported show command " ) ; <nl> } <nl> } <nl>  <nl> + / * * <nl> + * @ param c <nl> + * / <nl> + private void showcollation ( serverconnection c ) { <nl> + map < string , string > map = new hashmap < string , string > ( ) ; <nl> + <nl> + commandcontext ctx = new commandcontext ( c ) ; <nl> + string [ ] names = { " collation " , " charset " , " id " , " default " , " compiled " , " sortlen " } ; <nl> + <nl> + ctx . writeheader ( names . length ) ; <nl> + <nl> + for ( string name : names ) { <nl> + ctx . writefield ( name , fields . field_type_var_string ) ; <nl> + } <nl> + <nl> + ctx . writeeof ( ) ; <nl> + <nl> + <nl> + <nl> + ctx . writeeof ( ) ; <nl> + ctx . complete ( ) ; <nl> + } <nl> + <nl> private void showstatus ( serverconnection c ) { <nl> map < string , string > map = new hashmap < string , string > ( ) ; <nl>  <nl> mmm a / bee - engine / src / test / java / com / dianping / bee / jdbc / jdbctest . java <nl> ppp b / bee - engine / src / test / java / com / dianping / bee / jdbc / jdbctest . java <nl>
public class defaultgraphbuilder implements graphbuilder { <nl> return this ; <nl> } <nl> } <nl> + <nl> + @ override <nl> + public void setgraphtype ( int graphtype ) { <nl> + <nl> + <nl> + } <nl> } <nl> mmm a / cat - home / src / main / java / com / dianping / cat / report / graph / graphbuilder . java <nl> ppp b / cat - home / src / main / java / com / dianping / cat / report / graph / graphbuilder . java <nl>
public class defaultmessagemanager extends containerholder implements messageman <nl>  <nl> thread thread = thread . currentthread ( ) ; <nl>  <nl> - m_tree . setthreadid ( long . tohexstring ( thread . getid ( ) ) ) ; <nl> - m_tree . setthreadid ( thread . getname ( ) ) ; <nl> + <nl> + string groupname = thread . getthreadgroup ( ) . getname ( ) ; <nl> + <nl> + m_tree . setthreadid ( groupname = = null ? long . tohexstring ( thread . getid ( ) ) : groupname ) ; <nl> + m_tree . setthreadname ( thread . getname ( ) ) ; <nl>  <nl> m_tree . setdomain ( domain ) ; <nl> m_tree . sethostname ( hostname ) ; <nl> mmm a / cat - home / src / main / java / com / dianping / cat / report / reportcontext . java <nl> ppp b / cat - home / src / main / java / com / dianping / cat / report / reportcontext . java <nl>
public final class schemametadataloaderengine { <nl> if ( dialectschemametadataloader . ispresent ( ) ) { <nl> try { <nl> return dialectschemametadataloader . get ( ) . load ( material . getdatasource ( ) , material . getactualtablenames ( ) , material . getdefaultschemaname ( ) ) ; <nl> - } catch ( final sqlexception ex ) { <nl> + <nl> + } catch ( final exception ex ) { <nl> + / / checkstyle : on <nl> log . error ( " dialect load schema meta data error . " , ex ) ; <nl> } <nl> }
public final class datasourcepropertiesvalidator { <nl> datasource = datasourcepoolcreator . create ( datasourceprops ) ; <nl> checkfailfast ( datasource , databasetype ) ; <nl> / / checkstyle : off <nl> + <nl> } catch ( final exception ex ) { <nl> / / checkstyle : on <nl> throw new invaliddatasourcepropertiesexception ( datasourcename , ex . getmessage ( ) ) ; <nl>
public final class jdbcbackendtransactionmanager implements transactionmanager < v <nl> if ( exceptions . isempty ( ) ) { <nl> return null ; <nl> } <nl> - sqlexception ex = new sqlexception ( " " ) ; <nl> - exceptions . foreach ( ex : : setnextexception ) ; <nl> + sqlexception ex = null ; <nl> + int count = num ; <nl> + for ( sqlexception each : exceptions ) { <nl> + if ( 0 = = count ) { <nl> + ex = each ; <nl> + } else { <nl> + <nl> + ex . setnextexception ( each ) ; <nl> + } <nl> + count + + ; <nl> + } <nl> throw ex ; <nl> } <nl> } <nl> mmm a / shardingsphere - proxy / shardingsphere - proxy - backend / src / main / java / org / apache / shardingsphere / proxy / backend / communication / jdbc / transaction / localtransactionmanager . java <nl> ppp b / shardingsphere - proxy / shardingsphere - proxy - backend / src / main / java / org / apache / shardingsphere / proxy / backend / communication / jdbc / transaction / localtransactionmanager . java <nl>
public final class localtransactionmanager implements transactionmanager < void > { <nl> return null ; <nl> } <nl>  <nl> - private void throwsqlexceptionifnecessary ( final collection < sqlexception > exceptions ) throws sqlexception { <nl> + private void throwsqlexceptionifnecessary ( final collection < sqlexception > exceptions ) throws sqlexception { <nl> if ( exceptions . isempty ( ) ) { <nl> - return ; <nl> + return null ; <nl> + } <nl> + sqlexception ex = null ; <nl> + int count = num ; <nl> + for ( sqlexception each : exceptions ) { <nl> + if ( 0 = = count ) { <nl> + ex = each ; <nl> + } else { <nl> + <nl> + ex . setnextexception ( each ) ; <nl> + } <nl> + count + + ; <nl> } <nl> - sqlexception ex = new sqlexception ( " " ) ; <nl> - exceptions . foreach ( ex : : setnextexception ) ; <nl> throw ex ; <nl> } <nl> }
public final class standaloneworkeridgenerator implements workeridgenerator { <nl>  <nl> @ override <nl> public long generate ( final properties props ) { <nl> - return parseworkerid ( props ) ; <nl> + if ( null = = props ) { <nl> + return default_worker_id ; <nl> + } <nl> + object workerid = props . get ( worker_id_key ) ; <nl> + <nl> + return null = = workerid ? default_worker_id : long . parselong ( workerid . tostring ( ) ) ; <nl> } <nl> }
public class assistqueryandplaininsertcolumnstokengeneratortest { <nl> tokengenerator . setencryptrule ( mockencryptrule ( ) ) ; <nl> collection < insertcolumnstoken > actual = tokengenerator . generatesqltokens ( mockinsertstatementcontext ( ) ) ; <nl> assertthat ( actual . size ( ) , is ( 1 ) ) ; <nl> - <nl> - insertstatementcontext insertstatementcontext = mock ( insertstatementcontext . class , returns_deep_stubs ) ; <nl> - when ( insertstatementcontext . getsqlstatement ( ) . gettable ( ) . gettablename ( ) . getidentifier ( ) . getvalue ( ) ) . thenreturn ( " foo_tbl " ) ; <nl> - actual = tokengenerator . generatesqltokens ( insertstatementcontext ) ; <nl> - assertthat ( actual . size ( ) , is ( 0 ) ) ; <nl> - <nl> - columnsegment columnsegment = mock ( columnsegment . class , returns_deep_stubs ) ; <nl> - when ( columnsegment . getidentifier ( ) . getvalue ( ) ) . thenreturn ( " bar_col " ) ; <nl> - when ( insertstatementcontext . getsqlstatement ( ) . getcolumns ( ) ) . thenreturn ( collections . singleton ( columnsegment ) ) ; <nl> - actual = tokengenerator . generatesqltokens ( insertstatementcontext ) ; <nl> - assertthat ( actual . size ( ) , is ( 0 ) ) ; <nl> + <nl> } <nl>  <nl> private encryptrule mockencryptrule ( ) {
public final class memoryworkeridgenerator implements workeridgenerator { <nl>  <nl> @ override <nl> public long generate ( ) { <nl> + <nl> return num ; <nl> } <nl> } <nl> mmm a / shardingsphere - mode / shardingsphere - mode - type / shardingsphere - standalone - mode / shardingsphere - standalone - mode - core / src / main / java / org / apache / shardingsphere / mode / manager / standalone / workerid / generator / standaloneworkeridgenerator . java <nl> ppp b / shardingsphere - mode / shardingsphere - mode - type / shardingsphere - standalone - mode / shardingsphere - standalone - mode - core / src / main / java / org / apache / shardingsphere / mode / manager / standalone / workerid / generator / standaloneworkeridgenerator . java <nl>
public final class shardingsphereoptimizer { <nl>  <nl> private relnode optimize ( final sqltorelconverter converter , final relroot relroot ) { <nl> reloptplanner planner = converter . getcluster ( ) . getplanner ( ) ; <nl> - relroot optimizedrelroot = createrelroot ( planner . changetraits ( relroot . rel , converter . getcluster ( ) . traitset ( ) . replace ( enumerableconvention . instance ) ) , relroot . validatedrowtype ) ; <nl> - return programs . standard ( ) . run ( planner , optimizedrelroot . rel , getdesireroottraitset ( optimizedrelroot ) , collections . emptylist ( ) , collections . emptylist ( ) ) ; <nl> + relnode optimizedrelnode = planner . changetraits ( relroot . rel , getdesiredtraitset ( converter . getcluster ( ) . traitset ( ) , enumerableconvention . instance ) ) ; <nl> + relroot optimizedrelroot = createoptimizedrelroot ( optimizedrelnode , relroot . validatedrowtype ) ; <nl> + return programs . standard ( ) . run ( planner , optimizedrelroot . rel , optimizedrelroot . rel . gettraitset ( ) , collections . emptylist ( ) , collections . emptylist ( ) ) ; <nl> } <nl>  <nl> - private relroot createrelroot ( final relnode relnode , final reldatatype resulttype ) { <nl> + <nl> + private reltraitset getdesiredtraitset ( final reltraitset reltraitset , final convention convention ) { <nl> + return reltraitset . replace ( convention ) . simplify ( ) ; <nl> + } <nl> + <nl> + private relroot createoptimizedrelroot ( final relnode relnode , final reldatatype resulttype ) { <nl> reldatatype rowtype = relnode . getrowtype ( ) ; <nl> list < pair < integer , string > > fields = pair . zip ( immutableintlist . identity ( rowtype . getfieldcount ( ) ) , rowtype . getfieldnames ( ) ) ; <nl> relcollation collation = relnode instanceof sort ? ( ( sort ) relnode ) . collation : relcollations . empty ; <nl> return new relroot ( relnode , resulttype , sqlkind . select , fields , collation , new arraylist < > ( ) ) ; <nl> } <nl> - <nl> - private reltraitset getdesireroottraitset ( final relroot relroot ) { <nl> - return relroot . rel . gettraitset ( ) . replace ( enumerableconvention . instance ) . replace ( relroot . collation ) . simplify ( ) ; <nl> - } <nl> }
public final class rulealteredjobapiimpl extends abstractpipelinejobapiimpl impl <nl> workflowconfiguration workflowconfig = jobconfig . getworkflowconfig ( ) ; <nl> scalingtaskfinishedevent taskfinishedevent = new scalingtaskfinishedevent ( workflowconfig . getschemaname ( ) , workflowconfig . getactiveversion ( ) , workflowconfig . getnewversion ( ) ) ; <nl> shardingsphereeventbus . getinstance ( ) . post ( taskfinishedevent ) ; <nl> + <nl> + rulealteredjobschedulercenter . updatejobstatus ( jobid , jobstatus . finished ) ; <nl> for ( int each : repositoryapi . getshardingitems ( jobid ) ) { <nl> repositoryapi . updateshardingjobstatus ( jobid , each , jobstatus . finished ) ; <nl> } <nl>
<nl>  <nl> package org . apache . shardingsphere . infra . rule . builder . global ; <nl>  <nl> - import com . google . common . collect . maps ; <nl> import org . apache . shardingsphere . infra . config . ruleconfiguration ; <nl> import org . apache . shardingsphere . infra . metadata . shardingspheremetadata ; <nl> - import org . apache . shardingsphere . infra . rule . shardingsphererule ; <nl> import org . junit . test ; <nl> - import org . junit . runner . runwith ; <nl> - import org . mockito . mock ; <nl> - import org . mockito . junit . mockitojunitrunner ; <nl>  <nl> - import java . util . collection ; <nl> import java . util . collections ; <nl> - import java . util . map ; <nl>  <nl> import static org . junit . assert . asserttrue ; <nl> + import static org . mockito . mockito . mock ; <nl>  <nl> - @ runwith ( mockitojunitrunner . class ) <nl> public final class globalrulesbuildertest { <nl>  <nl> - @ mock <nl> - private ruleconfiguration ruleconfiguration ; <nl> - <nl> - @ mock <nl> - private shardingspheremetadata shardingspheremetadata ; <nl> - <nl> @ test <nl> - public void assertbuildrules ( ) { <nl> - map < string , shardingspheremetadata > metadatamap = maps . newhashmap ( ) ; <nl> - metadatamap . put ( " logic_db " , shardingspheremetadata ) ; <nl> - collection < shardingsphererule > shardingsphererules = globalrulesbuilder . buildrules ( collections . singletonlist ( ruleconfiguration ) , metadatamap ) ; <nl> - asserttrue ( shardingsphererules . isempty ( ) ) ; <nl> + public void assertbuildruleswithoutglobalrules ( ) { <nl> + asserttrue ( globalrulesbuilder . buildrules ( collections . singletonlist ( mock ( ruleconfiguration . class ) ) , collections . singletonmap ( " logic_db " , mock ( shardingspheremetadata . class ) ) ) . isempty ( ) ) ; <nl> } <nl> + <nl> + <nl> }
public final class ruledefinitionbackendhandler < t extends ruledefinitionstatemen <nl> new properties ( ) ) ; <nl> if ( ! rulealteredjobworker . isonrulealteredactionenabled ( currentruleconfig ) ) { <nl> if ( rule_altered_action_list . contains ( sqlstatement . getclass ( ) . getcanonicalname ( ) ) ) { <nl> - throw new runtimeexception ( " scaling is not enabled " ) ; <nl> + <nl> + log . warn ( " rule altered and scaling is not enabled . " ) ; <nl> } <nl> } else if ( preprocessor . ispresent ( ) ) { <nl> preparescaling ( shardingspheremetadata , sqlstatement , ( ruledefinitionalterupdater ) ruledefinitionupdater , currentruleconfig , preprocessor . get ( ) ) ;
public final class postgresqlcontainer extends dockerstoragecontainer { <nl>  <nl> @ override <nl> @ sneakythrows ( { classnotfoundexception . class , sqlexception . class , interruptedexception . class } ) <nl> + <nl> protected void execute ( ) { <nl> class . forname ( datasourceenvironment . getdriverclassname ( getdatabasetype ( ) ) ) ; <nl> string url = datasourceenvironment . geturl ( getdatabasetype ( ) , gethost ( ) , getmappedport ( getport ( ) ) ) ; <nl> mmm a / shardingsphere - test / shardingsphere - integration - test / shardingsphere - integration - test - suite / src / test / resources / logback - test . xml <nl> ppp b / shardingsphere - test / shardingsphere - integration - test / shardingsphere - integration - test - suite / src / test / resources / logback - test . xml <nl>
set version_opts = <nl> if % int_version % = = num ( <nl> set version_opts = - xx : + useconcmarksweepgc - xx : + usecmsinitiatingoccupancyonly - xx : cmsinitiatingoccupancyfraction = 70 <nl> ) else if % int_version % = = num ( <nl> - set version_opts = - xx : + segmentedcodecache - xx : + aggressiveheap - xx : + unlockexperimentalvmoptions - xx : + usejvmcicompiler <nl> + set version_opts = - xx : + segmentedcodecache - xx : + aggressiveheap <nl> + @ rem <nl> ) else if % int_version % = = num ( <nl> set version_opts = - xx : + segmentedcodecache - xx : + aggressiveheap <nl> ) else ( <nl> mmm a / shardingsphere - distribution / shardingsphere - proxy - distribution / src / main / resources / bin / start . sh <nl> ppp b / shardingsphere - distribution / shardingsphere - proxy - distribution / src / main / resources / bin / start . sh <nl>
import lombok . setter ; <nl> import me . ahoo . cosid . cosid ; <nl> import me . ahoo . cosid . provider . idgeneratorprovider ; <nl> import me . ahoo . cosid . provider . lazyidgenerator ; <nl> + import org . apache . shardingsphere . infra . config . algorithm . shardingsphereinstancerequiredalgorithm ; <nl> + import org . apache . shardingsphere . infra . instance . instancecontext ; <nl> import org . apache . shardingsphere . sharding . algorithm . sharding . cosid . cosidalgorithm ; <nl> import org . apache . shardingsphere . sharding . spi . keygeneratealgorithm ; <nl>  <nl> + import java . util . optional ; <nl> import java . util . properties ; <nl>  <nl> / * * <nl> * cosid key generate algorithm . <nl> * / <nl> - public final class cosidkeygeneratealgorithm implements keygeneratealgorithm { <nl> - <nl> + public final class cosidkeygeneratealgorithm implements keygeneratealgorithm , shardingsphereinstancerequiredalgorithm { <nl> + <nl> public static final string type = cosid . cosid . touppercase ( ) ; <nl> - <nl> + <nl> public static final string as_string_key = " as - string " ; <nl> - <nl> + <nl> @ getter <nl> @ setter <nl> private properties props = new properties ( ) ; <nl> - <nl> + <nl> private volatile lazyidgenerator cosidprovider ; <nl> - <nl> + <nl> private volatile boolean asstring ; <nl> - <nl> + <nl> + <nl> + private volatile optional < instancecontext > instancecontext ; <nl> + <nl> @ override <nl> public void init ( ) { <nl> cosidprovider = new lazyidgenerator ( getprops ( ) . getordefault ( cosidalgorithm . id_name_key , idgeneratorprovider . share ) . tostring ( ) ) ; <nl>
public final class cosidintervalshardingalgorithmtest { <nl> return rangeargsprovider ( ldt - > ldt . toinstant ( zone_offset_shanghai ) . toepochmilli ( ) ) ; <nl> } <nl>  <nl> + <nl> + @ ignore <nl> @ runwith ( parameterized . class ) <nl> public static class localdatetimeprecisevaluedoshardingtest { <nl>  <nl>
public final class showinstanceexecutor extends abstractshowexecutor { <nl> } <nl>  <nl> private collection < list < object > > buildinstancerows ( ) { <nl> - linkedlist < object > row = new linkedlist < > ( ) ; <nl> - row . add ( buildrow ( clusterinstance . getinstance ( ) . getid ( ) , enable ) ) ; <nl> - return collections . singletonlist ( row ) ; <nl> + list < list < object > > rows = new linkedlist < > ( ) ; <nl> + <nl> + string instanceid = string . join ( delimiter , iputils . getip ( ) , " " ) ; <nl> + rows . add ( buildrow ( instanceid , enable ) ) ; <nl> + return rows ; <nl> } <nl>  <nl> private collection < list < object > > buildinstancerows ( final metadatapersistservice persistservice , final string status ) {
import lombok . noargsconstructor ; <nl> import org . apache . calcite . adapter . enumerable . enumerablerules ; <nl> import org . apache . calcite . plan . conventiontraitdef ; <nl> import org . apache . calcite . plan . reloptplanner ; <nl> + import org . apache . calcite . plan . volcano . volcanoplanner ; <nl> import org . apache . calcite . rel . rules . corerules ; <nl>  <nl> / * * <nl> - * planner initializer . <nl> + * query optimize planner factory . <nl> * / <nl> @ noargsconstructor ( access = accesslevel . private ) <nl> - public final class plannerinitializer { <nl> + public final class queryoptimizeplannerfactory { <nl>  <nl> / * * <nl> - * init . <nl> - * @ param planner planner <nl> + * create new instance of query optimize planner . <nl> + * <nl> + * @ return new instance of query optimize planner <nl> * / <nl> - public static void init ( final reloptplanner planner ) { <nl> + public static reloptplanner newinstance ( ) { <nl> + reloptplanner result = createplanner ( ) ; <nl> + setuprules ( result ) ; <nl> + return result ; <nl> + } <nl> + <nl> + private static reloptplanner createplanner ( ) { <nl> + <nl> + return new volcanoplanner ( ) ; <nl> + } <nl> + <nl> + private static void setuprules ( final reloptplanner planner ) { <nl> planner . addrule ( corerules . project_to_calc ) ; <nl> planner . addrule ( corerules . filter_to_calc ) ; <nl> planner . addrule ( enumerablerules . enumerable_limit_rule ) ;
import static org . junit . assert . assertthat ; <nl> import static org . junit . assert . asserttrue ; <nl> import static org . mockito . mockito . mock ; <nl>  <nl> + <nl> + @ ignore <nl> public final class filerepositorydeletevisitortest { <nl>  <nl> @ test <nl> mmm a / shardingsphere - mode / shardingsphere - mode - type / shardingsphere - standalone - mode / shardingsphere - standalone - mode - repository / shardingsphere - standalone - mode - repository - provider / shardingsphere - standalone - mode - repository - file / src / test / java / org / apache / shardingsphere / mode / repository / standalone / file / filerepositorytest . java <nl> ppp b / shardingsphere - mode / shardingsphere - mode - type / shardingsphere - standalone - mode / shardingsphere - standalone - mode - repository / shardingsphere - standalone - mode - repository - provider / shardingsphere - standalone - mode - repository - file / src / test / java / org / apache / shardingsphere / mode / repository / standalone / file / filerepositorytest . java <nl>
import static org . hamcrest . corematchers . is ; <nl> import static org . junit . assert . assertfalse ; <nl> import static org . junit . assert . assertthat ; <nl>  <nl> + <nl> + @ ignore <nl> public final class filerepositorytest { <nl>  <nl> private filerepository filerepository = new filerepository ( ) ;
<nl> < test - case sql = " select i . user_id from t_order o join t_order_item i on o . user_id = i . user_id and o . order_id = i . order_id where o . user_id in ( ? , ? ) and o . order_id between ? and ? group by i . user_id order by i . item_id desc limit ? , ? " db - types = " mysql " scenario - types = " db , tbl , dbtbl_with_readwrite_splitting , readwrite_splitting " > <nl> < assertion parameters = " 10 : int , num : int , num : int , num : int , num : int , num : int " expected - data - file = " select_pagination_with_diff_group_by_and_order_by . xml " / > <nl> < / test - case > <nl> - <nl> - < test - case sql = " select i . * from t_order o inner join t_order_item i on o . order_id = i . order_id where o . order_id = ? " scenario - types = " db , tbl , dbtbl_with_readwrite_splitting , readwrite_splitting " > <nl> + < ! - - <nl> + < test - case sql = " select i . * from t_order o inner join t_order_item i on o . order_id = i . order_id where o . order_id = ? " db - types = " mysql , h2 " scenario - types = " db , tbl , dbtbl_with_readwrite_splitting , readwrite_splitting " > <nl> < assertion parameters = " 1000 : int " expected - data - file = " select_inner_join . xml " / > <nl> < / test - case >
public final class shardingsphererulesbuilder { <nl> } <nl>  <nl> @ suppresswarnings ( " rawtypes " ) <nl> - private static map < ruleconfiguration , schemarulebuilder > appenddefaultkernelschemaruleconfigurationbuilder ( final map < ruleconfiguration , schemarulebuilder > builders ) { <nl> + private static void appenddefaultkernelschemaruleconfigurationbuilder ( final map < ruleconfiguration , schemarulebuilder > builders ) { <nl> map < schemarulebuilder , defaultkernelruleconfigurationbuilder > defaultbuilders = <nl> orderedspiregistry . getregisteredservices ( getmissedkernelschemarulebuilders ( builders . values ( ) ) , defaultkernelruleconfigurationbuilder . class ) ; <nl> - map < ruleconfiguration , schemarulebuilder > result = new linkedhashmap < > ( builders . size ( ) + defaultbuilders . size ( ) , num ) ; <nl> - result . putall ( builders ) ; <nl> + <nl> for ( entry < schemarulebuilder , defaultkernelruleconfigurationbuilder > entry : defaultbuilders . entryset ( ) ) { <nl> - result . put ( entry . getvalue ( ) . build ( ) , entry . getkey ( ) ) ; <nl> + builders . put ( entry . getvalue ( ) . build ( ) , entry . getkey ( ) ) ; <nl> } <nl> - return result ; <nl> } <nl>  <nl> @ suppresswarnings ( { " unchecked " , " rawtypes " } )
public final class commandexecutortask implements runnable { <nl> / / checkstyle : on <nl> processexception ( ex ) ; <nl> } finally { <nl> + <nl> + sqlstatementschemaholder . remove ( ) ; <nl> collection < sqlexception > exceptions = closeexecutionresources ( ) ; <nl> if ( isneedflush ) { <nl> context . flush ( ) ; <nl>
public final class postgresqlerrpacketfactory { <nl> return createerrorresponsepacketforunknownexception ( cause ) ; <nl> } <nl>  <nl> + private static postgresqlerrorresponsepacket createerrorresponsepacket ( final sqlexception cause ) { <nl> + <nl> + string sqlstate = strings . isnullorempty ( cause . getsqlstate ( ) ) ? postgresqlerrorcode . system_error . geterrorcode ( ) : cause . getsqlstate ( ) ; <nl> + string message = strings . isnullorempty ( cause . getmessage ( ) ) ? cause . tostring ( ) : cause . getmessage ( ) ; <nl> + return postgresqlerrorresponsepacket . newbuilder ( postgresqlmessageseveritylevel . error , sqlstate , message ) . build ( ) ; <nl> + } <nl> + <nl> private static postgresqlerrorresponsepacket createerrorresponsepacket ( final servererrormessage servererrormessage ) { <nl> return postgresqlerrorresponsepacket . newbuilder ( postgresqlmessageseveritylevel . valueof ( servererrormessage . getseverity ( ) ) , servererrormessage . getsqlstate ( ) , servererrormessage . getmessage ( ) ) <nl> . detail ( servererrormessage . getdetail ( ) ) . hint ( servererrormessage . gethint ( ) ) . position ( servererrormessage . getposition ( ) )
public final class postgresqlcomsyncexecutor implements querycommandexecutor { <nl>  <nl> @ override <nl> public collection < databasepacket < ? > > execute ( ) { <nl> - return collections . singletonlist ( new postgresqlreadyforquerypacket ( backendconnection . gettransactionstatus ( ) . isintransaction ( ) ) ) ; <nl> + <nl> + boolean isintransaction = backendconnection . gettransactionstatus ( ) . isintransaction ( ) ; <nl> + return collections . singletonlist ( new postgresqlreadyforquerypacket ( true ) ) ; <nl> } <nl>  <nl> @ override
public final class textprotocolbackendhandlerfactory { <nl> } <nl>  <nl> private static void sqlcheck ( final backendconnection backendconnection , final sqlstatement sqlstatement ) { <nl> - metadatacontexts contexts = proxycontext . getinstance ( ) . getmetadatacontexts ( ) ; <nl> - sqlcheckengine . check ( sqlstatement , collections . emptylist ( ) , contexts . getmetadata ( backendconnection . getschemaname ( ) ) , backendconnection . getgrantee ( ) ) ; <nl> + if ( ! strings . isnullorempty ( backendconnection . getschemaname ( ) ) ) { <nl> + <nl> + metadatacontexts contexts = proxycontext . getinstance ( ) . getmetadatacontexts ( ) ; <nl> + sqlcheckengine . check ( sqlstatement , collections . emptylist ( ) , contexts . getmetadata ( backendconnection . getschemaname ( ) ) , backendconnection . getgrantee ( ) ) ; <nl> + } <nl> } <nl>  <nl> private static databasetype getbackenddatabasetype ( final databasetype defaultdatabasetype , final backendconnection backendconnection ) {
public final class scenarioparallelrunnerexecutor implements parallelrunnerexecu <nl>  <nl> @ override <nl> public void execute ( final parameterizedarray parameterizedarray , final runnable childstatement ) { <nl> - ringbuffer . publishevent ( ( event , sequence ) - > { <nl> - event . reset ( ) ; <nl> - event . setcasekey ( new casekey ( parameterizedarray . getadapter ( ) , parameterizedarray . getscenario ( ) , parameterizedarray . getdatabasetype ( ) . getname ( ) ) ) ; <nl> - event . setchildstatement ( childstatement ) ; <nl> - } ) ; <nl> + <nl> + childstatement . run ( ) ; <nl> + / / ringbuffer . publishevent ( ( event , sequence ) - > { <nl> + / / event . reset ( ) ; <nl> + / / event . setcasekey ( new casekey ( parameterizedarray . getadapter ( ) , parameterizedarray . getscenario ( ) , parameterizedarray . getdatabasetype ( ) . getname ( ) ) ) ; <nl> + / / event . setchildstatement ( childstatement ) ; <nl> + / / } ) ; <nl> } <nl>  <nl> @ override
<nl> < input sql = " select t_account . amount , t_account_bak . amount from t_account left join t_account_bak on t_account . id = t_account_bak . id where t_account . amount = ? or t_account_bak . amount = ? " parameters = " 1 , num " / > <nl> < output sql = " select t_account . cipher_amount as amount , t_account_bak . cipher_amount as amount from t_account left join t_account_bak on t_account . id = t_account_bak . id where t_account . cipher_amount = ? or t_account_bak . cipher_amount = ? " parameters = " encrypt_1 , encrypt_2 " / > <nl> < / rewrite - assertion > <nl> + <nl> + < ! - - <nl> + < ! - - < rewrite - assertion id = " select_with_subquery " > - - > <nl> + < ! - - < input sql = " select amount from ( select amount from t_account where amount = ? ) as a " parameters = " 1 " / > - - > <nl> + < ! - - < output sql = " select amount from ( select cipher_amount as amount from t_account where cipher_amount = ? ) as a " parameters = " encrypt_1 " / > - - > <nl> + < ! - - < / rewrite - assertion > - - > <nl> < / rewrite - assertions >
public final class singletableruleloader { <nl> map < string , singletablerule > result = new hashmap < > ( ) ; <nl> for ( entry < string , datasource > entry : datasourcemap . entryset ( ) ) { <nl> map < string , singletablerule > singletablerules = load ( databasetype , entry . getkey ( ) , entry . getvalue ( ) , excludedtables ) ; <nl> - singletablerules . keyset ( ) . foreach ( each - > preconditions . checkstate ( ! result . containskey ( each ) , " single table conflict , there are multiple tables ` % s ` existed . " , each ) ) ; <nl> + <nl> result . putall ( singletablerules ) ; <nl> } <nl> return result ;
import java . util . optional ; <nl> * / <nl> public final class circuitbreakproxystate implements proxystate { <nl>  <nl> + public circuitbreakproxystate ( ) { <nl> + governanceeventbus . getinstance ( ) . register ( this ) ; <nl> + } <nl> + <nl> @ override <nl> public void execute ( final channelhandlercontext context , final object message , final databaseprotocolfrontendengine databaseprotocolfrontendengine , final backendconnection backendconnection ) { <nl> context . writeandflush ( databaseprotocolfrontendengine . getcommandexecuteengine ( ) . geterrorpacket ( new circuitbreakexception ( ) ) ) ; <nl> optional < databasepacket < ? > > databasepacket = databaseprotocolfrontendengine . getcommandexecuteengine ( ) . getotherpacket ( ) ; <nl> databasepacket . ifpresent ( context : : writeandflush ) ; <nl> } <nl> + <nl> + / * * <nl> + * renew circuit breaker state . <nl> + * <nl> + * @ param event circuit state changed event <nl> + * / <nl> + @ subscribe <nl> + public synchronized void renew ( final circuitstatechangedevent event ) { <nl> + if ( event . iscircuitbreak ( ) ) { <nl> + proxystatemachine . switchstate ( proxystatetype . circuit_break ) ; <nl> + } else { <nl> + <nl> + proxystatemachine . switchstate ( proxystatetype . ok ) ; <nl> + } <nl> + } <nl> }
public final class schemaenvironmentmanager { <nl> schemaenvironment databaseinitialization = unmarshal ( environmentpath . getdatabaseenvironmentresourcefile ( ruletype ) ) ; <nl> for ( databasetype each : integratetestenvironment . getinstance ( ) . getdatabasetypes ( ) ) { <nl> datasource datasource = datasourceutil . createdatasource ( each , null ) ; <nl> + if ( " postgresql " . equals ( each . getname ( ) ) ) { <nl> + try ( <nl> + connection connection = datasource . getconnection ( ) ; <nl> + stringreader stringreader = new stringreader ( joiner . on ( " ; \n " ) . skipnulls ( ) . join ( generateterminateconnectionsqls ( databaseinitialization . getdatabases ( ) ) ) ) ) { <nl> + runscript . execute ( connection , stringreader ) ; <nl> + } catch ( final sqlexception ex ) { <nl> + <nl> + } <nl> + } <nl> try ( <nl> connection connection = datasource . getconnection ( ) ; <nl> stringreader stringreader = new stringreader ( joiner . on ( " ; \n " ) . skipnulls ( ) . join ( generatedropdatabasesqls ( each , databaseinitialization . getdatabases ( ) ) ) ) ) { <nl>
public final class standardschemacontexts implements schemacontexts { <nl> private final boolean iscircuitbreak ; <nl>  <nl> public standardschemacontexts ( ) { <nl> + <nl> this ( new hashmap < > ( ) , new authentication ( ) , new configurationproperties ( new properties ( ) ) , new mysqldatabasetype ( ) , false ) ; <nl> } <nl>  <nl> mmm / dev / null <nl> ppp b / shardingsphere - kernel / shardingsphere - kernel - context / src / test / java / org / apache / shardingsphere / kernel / context / standardschemacontextstest . java <nl>
public final class datasourceconfiguration { <nl> if ( props . containskey ( originalname ) ) { <nl> props . put ( alias , props . get ( originalname ) ) ; <nl> } <nl> + <nl> + if ( props . containskey ( alias ) ) { <nl> + props . put ( originalname , props . get ( alias ) ) ; <nl> + } <nl> } <nl>  <nl> @ override
public final class selectstatementcontext extends commonsqlstatementcontext < sele <nl> if ( null ! = tablefactorsegment . gettable ( ) & & tablefactorsegment . gettable ( ) instanceof simpletablesegment ) { <nl> result . add ( ( simpletablesegment ) tablefactorsegment . gettable ( ) ) ; <nl> } <nl> + <nl> + if ( null ! = tablefactorsegment . gettable ( ) & & tablefactorsegment . gettable ( ) instanceof subquerytablesegment ) { <nl> + selectstatement subselect = ( ( subquerytablesegment ) tablefactorsegment . gettable ( ) ) . getsubquery ( ) . getselect ( ) ; <nl> + for ( tablereferencesegment each : subselect . gettablereferences ( ) ) { <nl> + result . addall ( gettablesfromtablereference ( each ) ) ; <nl> + } <nl> + } <nl> if ( null ! = tablefactorsegment . gettablereferences ( ) & & ! tablefactorsegment . gettablereferences ( ) . isempty ( ) ) { <nl> for ( tablereferencesegment each : tablefactorsegment . gettablereferences ( ) ) { <nl> result . addall ( gettablesfromtablereference ( each ) ) ;
import static org . junit . assert . asserttrue ; <nl> @ springboottest ( classes = springbootjnditest . class ) <nl> @ springbootapplication <nl> @ activeprofiles ( " jndi " ) <nl> + @ ignore <nl> + <nl> public class springbootjnditest { <nl>  <nl> private static final string test_datasource_url = " jdbc : h2 : mem : % s ; db_close_delay = - 1 ; database_to_upper = false ; mode = mysql " ;
public final class whereclauseassert { <nl>  <nl> private static void assertinrightvalue ( final sqlcaseassertcontext assertcontext , final predicateinrightvalue actual , final expectedpredicateinrightvalue expected ) { <nl> assertnotnull ( assertcontext . gettext ( " expected predicate in right value can not be null " ) , expected ) ; <nl> + assertparametermarkerexpressionsegment ( assertcontext , actual , expected ) ; <nl> + assertliteralexpressionsegment ( assertcontext , actual , expected ) ; <nl> + assertcommonexpressionsegment ( assertcontext , actual , expected ) ; <nl> + assertsubqueryexpressionsegment ( assertcontext , actual , expected ) ; <nl> + <nl> + } <nl> + <nl> + private static void assertparametermarkerexpressionsegment ( final sqlcaseassertcontext assertcontext , final predicateinrightvalue actual , final expectedpredicateinrightvalue expected ) { <nl> int count = num ; <nl> for ( expressionsegment each : actual . getsqlexpressions ( ) ) { <nl> if ( each instanceof parametermarkerexpressionsegment ) { <nl>
public final class mysqlhandshakeresponse41packet implements mysqlpacket { <nl> } <nl>  <nl> private string readauthpluginname ( final mysqlpacketpayload payload ) { <nl> - return num ! = ( capabilityflags & mysqlcapabilityflag . client_plugin_auth . getvalue ( ) ) ? payload . readstringnul ( ) : null ; <nl> + <nl> + return null ; <nl> } <nl>  <nl> / * * <nl> mmm a / shardingsphere - database - protocol / shardingsphere - database - protocol - mysql / src / test / java / org / apache / shardingsphere / database / protocol / mysql / packet / handshake / mysqlhandshakeresponse41packettest . java <nl> ppp b / shardingsphere - database - protocol / shardingsphere - database - protocol - mysql / src / test / java / org / apache / shardingsphere / database / protocol / mysql / packet / handshake / mysqlhandshakeresponse41packettest . java <nl>
import java . sql . sqlexception ; <nl> public class examplemain { <nl>  <nl> / * * <nl> - * main entrance . <nl> + * the example can ' t work well . <nl> + * related issue # 2884 : https : / / github . com / apache / incubator - shardingsphere / issues / 2884 <nl> * <nl> * @ param args startup arguments . <nl> * @ throws sqlexception sql exception <nl> * / <nl> @ deprecated <nl> public static void main ( final string [ ] args ) throws sqlexception { <nl> + <nl> try ( configurableapplicationcontext applicationcontext = springapplication . run ( examplemain . class , args ) ) { <nl> exampleexecutetemplate . run ( applicationcontext . getbean ( " encrypt " , exampleservice . class ) ) ; <nl> }
public class datanodemigratecontroller { <nl> * start synchronize data . <nl> * / <nl> public void start ( ) { <nl> - logposition position = new realtimedatasyncjob ( syncconfiguration , null ) . prerun ( ) ; <nl> - synchistorydata ( ) ; <nl> - syncrealtimedata ( position ) ; <nl> + new thread ( this ) . start ( ) ; <nl> } <nl>  <nl> / * * <nl> * stop synchronize data . <nl> * / <nl> public void stop ( ) { <nl> - throw new unsupportedoperationexception ( ) ; <nl> + syncjobexecutor . stop ( ) ; <nl> + <nl> } <nl>  <nl> / * * <nl> * get synchronize progress . <nl> + * <nl> + * @ return migrate progress <nl> * / <nl> public migrateprogress getprogress ( ) { <nl> - throw new unsupportedoperationexception ( ) ; <nl> + list < migrateprogress > result = syncjobexecutor . getprogresses ( ) ; <nl> + / / if history data sync job , only return first migrate progress . <nl> + / / if realtime data sync job , there only one migrate progress . <nl> + return result . get ( 0 ) ; <nl> + } <nl> + <nl> + @ override <nl> + public void run ( ) { <nl> + logposition position = new realtimedatasyncjob ( syncconfiguration , null ) . prerun ( ) ; <nl> + synchistorydata ( ) ; <nl> + syncrealtimedata ( position ) ; <nl> } <nl>  <nl> private void synchistorydata ( ) { <nl>
<nl> < sql - case id = " select_distinct_with_sum " value = " select sum ( distinct order_id ) s from t_order where order_id & lt ; num " / > <nl> < sql - case id = " select_distinct_with_count " value = " select count ( distinct order_id ) c from t_order where order_id & lt ; num " / > <nl> < sql - case id = " select_distinct_with_avg " value = " select avg ( distinct order_id ) from t_order where order_id & lt ; num " db - types = " mysql " / > <nl> - < sql - case id = " select_distinct_with_count_sum " value = " select count ( distinct order_id ) , sum ( distinct order_id ) from t_order where order_id & lt ; num " / > <nl> + < ! - - <nl> + < sql - case id = " select_distinct_with_count_sum " value = " select count ( distinct order_id ) , sum ( distinct order_id ) from t_order where order_id & lt ; num " db - types = " mysql " / > <nl> < sql - case id = " select_distinct_with_single_count_group_by " value = " select order_id , count ( distinct order_id ) c from t_order where order_id & lt ; num group by order_id order by order_id " / > <nl> < sql - case id = " select_distinct_with_count_group_by " value = " select count ( distinct order_id ) c , order_id from t_order group by order_id order by order_id " / > <nl> < sql - case id = " select_distinct_function " value = " select distinct ( item_id ) from t_order_item order by item_id " / >
public final class mysqlcomstmtprepareexecutor implements commandexecutor { <nl> return result ; <nl> } <nl>  <nl> - private int getnumcolumns ( final sqlstatement sqlstatement ) { <nl> - if ( sqlstatement instanceof selectstatement ) { <nl> - return ( ( selectstatement ) sqlstatement ) . getitems ( ) . size ( ) ; <nl> - } <nl> - if ( sqlstatement instanceof insertstatement ) { <nl> - return ( ( insertstatement ) sqlstatement ) . getcolumnnames ( ) . size ( ) ; <nl> - } <nl> + <nl> + private int getnumcolumns ( ) { <nl> return num ; <nl> } <nl> } <nl> mmm a / sharding - proxy / sharding - proxy - transport / sharding - proxy - transport - mysql / src / main / java / org / apache / shardingsphere / shardingproxy / transport / mysql / packet / command / query / binary / prepare / mysqlcomstmtprepareokpacket . java <nl> ppp b / sharding - proxy / sharding - proxy - transport / sharding - proxy - transport - mysql / src / main / java / org / apache / shardingsphere / shardingproxy / transport / mysql / packet / command / query / binary / prepare / mysqlcomstmtprepareokpacket . java <nl>
public final class encryptsqlrewritertest { <nl> } <nl>  <nl> private sqlunit getsqlunit ( final string sql , final list < object > parameters ) { <nl> - sqlstatement sqlstatement = encryptsqlparseengine . parse ( sql , false ) ; <nl> + <nl> + sqlstatement sqlstatement = encryptsqlparseentry . parse ( sql , false ) ; <nl> sqlrewriteengine sqlrewriteengine = new sqlrewriteengine ( encryptrule , sqlstatement , parameters ) ; <nl> optimizeresult optimizeresult = optimizeenginefactory . newinstance ( encryptrule , sqlstatement , parameters ) . optimize ( ) ; <nl> sqlrewriteengine . init (
public abstract class logicschema { <nl> * / <nl> public abstract shardingmetadata getmetadata ( ) ; <nl>  <nl> + / * * <nl> + * get sharding rule . <nl> + * <nl> + * @ return sharding rule <nl> + * / <nl> + <nl> + public abstract shardingrule getshardingrule ( ) ; <nl> + <nl> protected final map < string , string > getdatasourceurls ( final map < string , yamldatasourceparameter > datasourceparameters ) { <nl> map < string , string > result = new linkedhashmap < > ( datasourceparameters . size ( ) , num ) ; <nl> for ( entry < string , yamldatasourceparameter > entry : datasourceparameters . entryset ( ) ) {
public final class seataatshardingtransactionmanager implements shardingtransact <nl>  <nl> @ override <nl> public void init ( final databasetype databasetype , final collection < resourcedatasource > resourcedatasources ) { <nl> + <nl> + tmclient . init ( " default " , " default " ) ; <nl> + rmclient . init ( " default " , " default " ) ; <nl> for ( resourcedatasource each : resourcedatasources ) { <nl> datasourcemap . put ( each . getoriginalname ( ) , new datasourceproxy ( each . getdatasource ( ) ) ) ; <nl> }
import org . apache . shardingsphere . core . parse . sql . segment . sqlsegment ; <nl> @ equalsandhashcode <nl> public final class dropcolumndefinitionsegment implements sqlsegment { <nl>  <nl> + <nl> + private final int startindex = num ; <nl> + <nl> + private final int stopindex = num ; <nl> + <nl> private final string columnname ; <nl> }
import org . apache . shardingsphere . core . parse . util . sqlutil ; <nl> @ setter <nl> public final class columndefinitionsegment implements sqlsegment { <nl>  <nl> + <nl> + private final int startindex = num ; <nl> + <nl> + private final int stopindex = num ; <nl> + <nl> private string columnname ; <nl>  <nl> private string datatype ;
import java . util . linkedlist ; <nl> * <nl> * @ author duhongjun <nl> * / <nl> + @ requiredargsconstructor <nl> @ getter <nl> + <nl> public final class orpredicatesegment implements sqlsegment { <nl>  <nl> + private final int starindex = num ; <nl> + <nl> + private final int stopindex = num ; <nl> + <nl> private collection < andpredicate > andpredicates = new linkedlist < > ( ) ; <nl> }
import java . util . linkedlist ; <nl> * <nl> * @ author duhongjun <nl> * / <nl> + @ requiredargsconstructor <nl> @ getter <nl> + <nl> public final class subquerypredicatesegment implements sqlsegment { <nl>  <nl> + private final int starindex = num ; <nl> + <nl> + private final int stopindex = num ; <nl> + <nl> private collection < orpredicatesegment > orpredicates = new linkedlist < > ( ) ; <nl> }
public final class mysqlcomstmtresetexecutor implements commandexecutor { <nl>  <nl> @ override <nl> public collection < databasepacket > execute ( ) { <nl> + <nl> return collections . < databasepacket > singletonlist ( new mysqlokpacket ( 1 ) ) ; <nl> } <nl> } <nl> mmm / dev / null <nl> ppp b / sharding - proxy / sharding - proxy - frontend / sharding - proxy - frontend - mysql / src / test / java / org / apache / shardingsphere / shardingproxy / frontend / mysql / command / query / binary / reset / mysqlcomstmtresetexecutortest . java <nl>
public final class encryptorpredicatefiller implements sqlsegmentfiller < orpredic <nl> for ( predicatesegment predicate : each . getpredicates ( ) ) { <nl> if ( stopindexes . add ( predicate . getstopindex ( ) ) ) { <nl> optional < string > tablename = findtablename ( predicate , sqlstatement ) ; <nl> - if ( tablename . ispresent ( ) ) { <nl> + <nl> + if ( tablename . ispresent ( ) & & encryptrule . getencryptorengine ( ) . getshardingencryptor ( tablename . get ( ) , predicate . getcolumn ( ) . getname ( ) ) . ispresent ( ) ) { <nl> fill ( predicate , tablename . get ( ) , sqlstatement ) ; <nl> } <nl> } <nl>
createtable <nl> : create ( global temporary ) ? table tablename relationaltable <nl> ; <nl>  <nl> + createindex <nl> + : create ( unique | bitmap ) ? index indexname on ( tableindexclause_ | bitmapjoinindexclause_ ) <nl> + ; <nl> + <nl> altertable <nl> : alter table tablename ( altertableproperties | columnclauses | constraintclauses | alterexternaltable ) ? <nl> ; <nl>  <nl> + <nl> + alterindex <nl> + : alter index indexname ( rename to indexname ) ? <nl> + ; <nl> + <nl> droptable <nl> : drop table tablename <nl> ; <nl> + <nl> + dropindex <nl> + : drop index indexname <nl> + ; <nl>  <nl> truncatetable <nl> : truncate table tablename <nl>
public final class unicastbackendhandler implements textprotocolbackendhandler { <nl>  <nl> @ override <nl> public backendresponse execute ( ) { <nl> + <nl> logicschema logicschema = backendconnection . getlogicschema ( ) ; <nl> if ( null = = logicschema ) { <nl> logicschema = logicschemas . getinstance ( ) . getlogicschemas ( ) . values ( ) . iterator ( ) . next ( ) ;
public final class textprotocolbackendhandlerfactory { <nl> } <nl>  <nl> private static textprotocolbackendhandler createdalbackendhandler ( final sqlstatement sqlstatement , final string sql , final backendconnection backendconnection ) { <nl> - if ( null = = backendconnection . getlogicschema ( ) ) { <nl> - for ( string each : gui_sql ) { <nl> - if ( sql . touppercase ( ) . startswith ( each ) ) { <nl> - return new guicompatibilitybackendhandler ( ) ; <nl> - } <nl> + <nl> + for ( string each : gui_sql ) { <nl> + if ( sql . touppercase ( ) . startswith ( each ) ) { <nl> + return new guicompatibilitybackendhandler ( ) ; <nl> } <nl> } <nl> if ( sqlstatement instanceof setstatement ) {
public final class mysqlcomstmtcloseexecutor implements commandexecutor { <nl>  <nl> @ override <nl> public collection < databasepacket > execute ( ) { <nl> - packet . removecachedstatement ( ) ; <nl> + <nl> return collections . emptylist ( ) ; <nl> } <nl> } <nl> mmm a / sharding - proxy / sharding - proxy - transport / sharding - proxy - transport - mysql / src / main / java / org / apache / shardingsphere / shardingproxy / transport / mysql / packet / command / query / binary / close / mysqlcomstmtclosepacket . java <nl> ppp b / sharding - proxy / sharding - proxy - transport / sharding - proxy - transport - mysql / src / main / java / org / apache / shardingsphere / shardingproxy / transport / mysql / packet / command / query / binary / close / mysqlcomstmtclosepacket . java <nl>
public final class mysqlcomstmtclosepacket extends mysqlcommandpacket { <nl> * remove cached statement . <nl> * / <nl> public void removecachedstatement ( ) { <nl> - mysqlbinarystatementregistry . getinstance ( ) . remove ( statementid ) ; <nl> + <nl> } <nl> }
public final class sqlparserfactory { <nl> throw new sqlparsingunsupportedexception ( tokentype ) ; <nl> } <nl>  <nl> + / * * <nl> + * create encrypt sql parser . <nl> + * <nl> + * @ param dbtype db type <nl> + * @ param encryptrule encrypt rule <nl> + * @ param shardingtablemetadata sharding table meta data <nl> + * @ param sql sql <nl> + * @ return sql parser <nl> + * / <nl> + public static sqlparser newinstance ( final databasetype dbtype , final encryptrule encryptrule , final shardingtablemetadata shardingtablemetadata , final string sql ) { <nl> + if ( databasetype . mysql = = dbtype | | databasetype . h2 = = dbtype ) { <nl> + <nl> + return setparserfactory . newinstance ( ) ; <nl> + } <nl> + throw new sqlparsingunsupportedexception ( string . format ( " can not support % s " , dbtype ) ) ; <nl> + } <nl> + <nl> private static sqlparser getdqlparser ( final databasetype dbtype , final shardingrule shardingrule , final lexerengine lexerengine , final shardingtablemetadata shardingtablemetadata ) { <nl> return selectparserfactory . newinstance ( dbtype , shardingrule , lexerengine , shardingtablemetadata ) ; <nl> }
objecttypecolproperties <nl> substitutablecolumnclause <nl> : element ? is of type ? lp_ only ? datatypename_ rp_ | not ? substitutable at all levels <nl> ; <nl> + <nl> + createindex <nl> + : create ( unique | bitmap ) ? index indexname on ( tableindexclause_ | bitmapjoinindexclause_ ) <nl> + ; <nl> + <nl> + tableindexclause_ <nl> + : tablename alias ? lp_ indexexpr_ ( comma_ indexexpr_ ) * rp_ <nl> + ; <nl> + <nl> + indexexpr_ <nl> + : ( columnname | expr ) ( asc | desc ) ? <nl> + ; <nl> + <nl> + bitmapjoinindexclause_ <nl> + : tablename lp_ columnsortclause_ ( comma_ columnsortclause_ ) * rp_ from tablename alias ? ( comma_ tablename alias ? ) * where expr <nl> + ; <nl> + <nl> + columnsortclause_ <nl> + : tablename alias ? columnname ( asc | desc ) ? <nl> + ; <nl> + <nl> + dropindex <nl> + : drop index indexname <nl> + ; <nl> + <nl> + <nl> + alterindex <nl> + : alter index indexname ( rename to indexname ) ? <nl> + ; <nl> mmm a / sharding - parser / sharding - parser - oracle / src / main / antlr4 / org / apache / shardingsphere / core / parsing / antlr / autogen / oraclestatement . g4 <nl> ppp b / sharding - parser / sharding - parser - oracle / src / main / antlr4 / org / apache / shardingsphere / core / parsing / antlr / autogen / oraclestatement . g4 <nl>
public final class postgresqlcommandcompletepacket implements postgresqlpacket { <nl>  <nl> @ override <nl> public void write ( final postgresqlpacketpayload payload ) { <nl> - / / payload . writestringnul ( sqlcommand + " " + rowcount ) ; <nl> + <nl> payload . writestringnul ( " " ) ; <nl> }
<nl> + / * <nl> + * licensed to the apache software foundation ( asf ) under one or more <nl> + * contributor license agreements . see the notice file distributed with <nl> + * this work for additional information regarding copyright ownership . <nl> + * the asf licenses this file to you under the apache license , version num . 0 <nl> + * ( the " license " ) ; you may not use this file except in compliance with <nl> + * the license . you may obtain a copy of the license at <nl> + * <nl> + * http : / / www . apache . org / licenses / license - 2 . 0 <nl> + * <nl> + * unless required by applicable law or agreed to in writing , software <nl> + * distributed under the license is distributed on an " as is " basis , <nl> + * without warranties or conditions of any kind , either express or implied . <nl> + * see the license for the specific language governing permissions and <nl> + * limitations under the license . <nl> + * / <nl> + <nl> + package org . apache . shardingsphere . shardingproxy . transport . mysql . packet . command . query . binary . close ; <nl> + <nl> + import com . google . common . base . optional ; <nl> + import lombok . getter ; <nl> + import lombok . extern . slf4j . slf4j ; <nl> + import org . apache . shardingsphere . shardingproxy . transport . mysql . packet . mysqlpacketpayload ; <nl> + import org . apache . shardingsphere . shardingproxy . transport . mysql . packet . command . commandpacket ; <nl> + import org . apache . shardingsphere . shardingproxy . transport . mysql . packet . command . commandresponsepackets ; <nl> + <nl> + / * * <nl> + * com_stmt_close command packet . <nl> + * <nl> + * @ see < a href = " https : / / dev . mysql . com / doc / internals / en / com - stmt - close . html " > com_query < / a > <nl> + * <nl> + * @ author zhangyonglun <nl> + * / <nl> + @ slf4j <nl> + public final class comstmtclosepacket implements commandpacket { <nl> + <nl> + @ getter <nl> + private final int sequenceid ; <nl> + <nl> + private final int statementid ; <nl> + <nl> + public comstmtclosepacket ( final int sequenceid , final mysqlpacketpayload payload ) { <nl> + this . sequenceid = sequenceid ; <nl> + statementid = payload . readint4 ( ) ; <nl> + } <nl> + <nl> + @ override <nl> + public void write ( final mysqlpacketpayload payload ) { <nl> + } <nl> + <nl> + @ override <nl> + public optional < commandresponsepackets > execute ( ) { <nl> + log . debug ( " com_stmt_close received for sharding - proxy : { } " , statementid ) ; <nl> + <nl> + return optional . absent ( ) ; <nl> + } <nl> + }
<nl> + / * <nl> + * licensed to the apache software foundation ( asf ) under one or more <nl> + * contributor license agreements . see the notice file distributed with <nl> + * this work for additional information regarding copyright ownership . <nl> + * the asf licenses this file to you under the apache license , version num . 0 <nl> + * ( the " license " ) ; you may not use this file except in compliance with <nl> + * the license . you may obtain a copy of the license at <nl> + * <nl> + * http : / / www . apache . org / licenses / license - 2 . 0 <nl> + * <nl> + * unless required by applicable law or agreed to in writing , software <nl> + * distributed under the license is distributed on an " as is " basis , <nl> + * without warranties or conditions of any kind , either express or implied . <nl> + * see the license for the specific language governing permissions and <nl> + * limitations under the license . <nl> + * / <nl> + <nl> + package org . apache . shardingsphere . shardingproxy . frontend . common . netty ; <nl> + <nl> + import io . netty . channel . channelinitializer ; <nl> + import io . netty . channel . channelpipeline ; <nl> + import io . netty . channel . socket . socketchannel ; <nl> + import lombok . requiredargsconstructor ; <nl> + import org . apache . shardingsphere . core . constant . databasetype ; <nl> + import org . apache . shardingsphere . shardingproxy . frontend . common . frontendhandlerfactory ; <nl> + import org . apache . shardingsphere . shardingproxy . transport . common . codec . packetcodecfactory ; <nl> + <nl> + / * * <nl> + * channel initializer . <nl> + * <nl> + * @ author xiaoyu <nl> + * / <nl> + @ requiredargsconstructor <nl> + public final class serverhandlerinitializer extends channelinitializer < socketchannel > { <nl> + <nl> + @ override <nl> + protected void initchannel ( final socketchannel socketchannel ) { <nl> + channelpipeline pipeline = socketchannel . pipeline ( ) ; <nl> + <nl> + pipeline . addlast ( packetcodecfactory . newinstance ( databasetype . mysql ) ) ; <nl> + pipeline . addlast ( frontendhandlerfactory . createfrontendhandlerinstance ( databasetype . mysql ) ) ; <nl> + } <nl> + }
public final class orderbyfiller implements sqlstatementfiller < orderbysegment > { <nl> return createorderitem ( ( indexorderbyitemsegment ) orderbyitemsegment ) ; <nl> } <nl> if ( orderbyitemsegment instanceof columnnameorderbyitemsegment ) { <nl> - return createorderitem ( selectstatement , ( columnnameorderbyitemsegment ) orderbyitemsegment ) ; <nl> + orderitem result = createorderitem ( selectstatement , ( columnnameorderbyitemsegment ) orderbyitemsegment ) ; <nl> + if ( result . getowner ( ) . ispresent ( ) & & selectstatement . gettables ( ) . gettablenames ( ) . contains ( result . getowner ( ) . get ( ) ) ) { <nl> + <nl> + selectstatement . addsqltoken ( new tabletoken ( ( ( columnnameorderbyitemsegment ) orderbyitemsegment ) . getbeginposition ( ) , num , result . getowner ( ) . get ( ) ) ) ; <nl> + } <nl> + return result ; <nl> } <nl> if ( orderbyitemsegment instanceof expressionorderbyitemsegment ) { <nl> return createorderitem ( selectstatement , ( expressionorderbyitemsegment ) orderbyitemsegment ) ; <nl>
public final class orderbyitemextractor implements collectionsqlsegmentextractor <nl> public collection < orderbyitemsegment > extract ( final parserrulecontext ancestornode ) { <nl> collection < orderbyitemsegment > result = new linkedlist < > ( ) ; <nl> for ( parserrulecontext each : extractorutils . getalldescendantnodes ( ancestornode , rulename . order_by_item ) ) { <nl> - / / fixme when will count be zero ? <nl> - int count = each . getchildcount ( ) ; <nl> - if ( 0 = = count ) { <nl> - continue ; <nl> - } <nl> + int childcount = each . getchildcount ( ) ; <nl> optional < parserrulecontext > numbernode = extractorutils . findfirstchildnode ( each , rulename . number ) ; <nl> int <nl> - boolean isidentifier = rulename . column_name . getname ( ) . equalsignorecase ( each . getchild ( 0 ) . getclass ( ) . getsimplename ( ) ) ; <nl> - orderdirection orderdirection = count > num & & orderdirection . desc . name ( ) . equalsignorecase ( each . getchild ( count - num ) . gettext ( ) ) ? orderdirection . desc : orderdirection . asc ; <nl> + <nl> parserrulecontext firstchild = ( parserrulecontext ) each . getchild ( 0 ) ; <nl> + boolean isidentifier = rulename . column_name . getname ( ) . equalsignorecase ( firstchild . getclass ( ) . getsimplename ( ) ) ; <nl> + orderdirection orderdirection = num = = childcount & & orderdirection . desc . name ( ) . equalsignorecase ( each . getchild ( 1 ) . gettext ( ) ) ? orderdirection . desc : orderdirection . asc ; <nl> result . add ( new orderbyitemsegment ( index , firstchild . getstart ( ) . getstartindex ( ) , firstchild . getstop ( ) . getstopindex ( ) , <nl> isidentifier , new orderbytoken ( ancestornode . getstart ( ) . getstartindex ( ) ) , orderdirection , orderdirection . asc ) ) ; <nl> }
public final class executorgroup { <nl> * @ param commandexecutor a command executor to be run <nl> * / <nl> public void execute ( final commandexecutor commandexecutor ) { <nl> + <nl> if ( transactiontype . xa = = global_registry . gettransactiontype ( ) ) { <nl> channelthreadexecutorgroup . getinstance ( ) . get ( channelid ) . execute ( commandexecutor ) ; <nl> return ;
public abstract class selectlistclauseparser implements sqlclauseparser { <nl> return pattern . matches ( pattern , innerexpression . touppercase ( ) ) ; <nl> } <nl>  <nl> + <nl> + private string getdistinctcolumnname ( ) { <nl> + return " " ; <nl> + } <nl> + <nl> private string parserestselectitem ( final selectstatement selectstatement ) { <nl> stringbuilder result = new stringbuilder ( ) ; <nl> while ( lexerengine . equalany ( symbol . getoperators ( ) ) ) {
<nl> + / * <nl> + * copyright num - 2018 shardingsphere . io . <nl> + * < p > <nl> + * licensed under the apache license , version num . 0 ( the " license " ) ; <nl> + * you may not use this file except in compliance with the license . <nl> + * you may obtain a copy of the license at <nl> + * <nl> + * http : / / www . apache . org / licenses / license - 2 . 0 <nl> + * <nl> + * unless required by applicable law or agreed to in writing , software <nl> + * distributed under the license is distributed on an " as is " basis , <nl> + * without warranties or conditions of any kind , either express or implied . <nl> + * see the license for the specific language governing permissions and <nl> + * limitations under the license . <nl> + * < / p > <nl> + * / <nl> + <nl> + package io . shardingsphere . transaction . aspect ; <nl> + <nl> + import java . lang . reflect . method ; <nl> + <nl> + import org . aspectj . lang . joinpoint ; <nl> + import org . aspectj . lang . annotation . aspect ; <nl> + import org . aspectj . lang . annotation . before ; <nl> + import org . aspectj . lang . annotation . pointcut ; <nl> + import org . aspectj . lang . reflect . methodsignature ; <nl> + import org . springframework . core . annotation . order ; <nl> + import org . springframework . stereotype . component ; <nl> + <nl> + import io . shardingsphere . core . constant . transaction . transactiontype ; <nl> + import io . shardingsphere . core . transaction . transactiontypeholder ; <nl> + import io . shardingsphere . transaction . annotation . shardingtransactional ; <nl> + import io . shardingsphere . transaction . annotation . shardingtransactional . shardingenvironment ; <nl> + <nl> + / * * <nl> + * sharding transaction aspect . <nl> + * <nl> + * @ author yangyi <nl> + * / <nl> + @ aspect <nl> + @ component <nl> + @ order ( 2147483646 ) <nl> + public final class shardingtransactionalaspect { <nl> + <nl> + / * * <nl> + * shardingtransationnal aop pointcut . <nl> + * / <nl> + @ pointcut ( " @ annotation ( io . shardingsphere . transaction . annotation . shardingtransactional ) | | @ within ( io . shardingsphere . transaction . annotation . shardingtransactional ) " ) <nl> + public void shardingtransactionalpointcut ( ) { <nl> + <nl> + } <nl> + <nl> + @ before ( value = " shardingtransactionalpointcut ( ) " ) <nl> + public void settransactiontypebeforetransaction ( final joinpoint joinpoint ) { <nl> + shardingtransactional shardingtransactional = getannotation ( joinpoint ) ; <nl> + <nl> + if ( shardingenvironment . jdbc = = shardingenvironment . valueof ( shardingtransactional . environment ( ) ) ) { <nl> + transactiontype type = transactiontype . valueof ( shardingtransactional . type ( ) ) ; <nl> + transactiontypeholder . set ( type ) ; <nl> + } <nl> + <nl> + } <nl> + <nl> + private shardingtransactional getannotation ( final joinpoint joinpoint ) { <nl> + methodsignature methodsignature = ( methodsignature ) joinpoint . getsignature ( ) ; <nl> + method method = methodsignature . getmethod ( ) ; <nl> + shardingtransactional result = method . getannotation ( shardingtransactional . class ) ; <nl> + if ( null = = result ) { <nl> + result = method . getdeclaringclass ( ) . getannotation ( shardingtransactional . class ) ; <nl> + } <nl> + return result ; <nl> + } <nl> + <nl> + }
public final class dbcp2transactionmanagerrecoverytest extends transactionmanage <nl> datasource datasource = datasourceutils . build ( pooltype . dbcp2 , databasetype . h2 , dsname ) ; <nl> return getatomikostransactionmanager ( ) . wrapdatasource ( xadatasourcefactory . build ( databasetype . h2 ) , dsname , datasourceparameterfactory . build ( datasource ) ) ; <nl> } <nl> + <nl> + @ test <nl> + @ sneakythrows <nl> + public void assertfailedinxaresourceunreleased ( ) { <nl> + <nl> + map < string , datasource > xadatasourcemap = createxadatasourcemap ( ) ; <nl> + xadatasourcemap . get ( " ds1 " ) . getconnection ( ) ; <nl> + } <nl> }
public final class shardingschema { <nl> metadata = getshardingmetadata ( backendexecutorcontext . getinstance ( ) . getexecuteengine ( ) ) ; <nl> } <nl>  <nl> + public shardingschema ( final string name , final map < string , datasourceparameter > datasources , final shardingrule shardingrule , final masterslaverule masterslaverule ) { <nl> + this . name = name ; <nl> + <nl> + this . datasources = datasources ; <nl> + this . shardingrule = shardingrule ; <nl> + this . masterslaverule = masterslaverule ; <nl> + backenddatasource = new jdbcbackenddatasource ( datasources ) ; <nl> + metadata = getshardingmetadata ( backendexecutorcontext . getinstance ( ) . getexecuteengine ( ) ) ; <nl> + } <nl> + <nl> private shardingrule getshardingrule ( final shardingruleconfiguration shardingrule , final boolean isusingregistry ) { <nl> return isusingregistry ? new orchestrationshardingrule ( shardingrule , datasources . keyset ( ) ) : new shardingrule ( shardingrule , datasources . keyset ( ) ) ; <nl> }
public final class globalregistry { <nl> return shardingproperties . getvalue ( shardingpropertiesconstant . executor_size ) ; <nl> } <nl>  <nl> + <nl> + public boolean isusenio ( ) { <nl> + return false ; <nl> + } <nl> +
public final class globalregistry { <nl> return shardingproperties . getvalue ( shardingpropertiesconstant . max_connections_size_per_query ) ; <nl> } <nl>  <nl> - public transactiontype <nl> + public transactiontype gettransactiontype ( ) { <nl> + <nl> + return shardingproperties . < boolean > getvalue ( shardingpropertiesconstant . proxy_transaction_enabled ) ? transactiontype . xa : transactiontype . local ; <nl> + } <nl> + <nl> + public boolean isopentracingenable ( ) { <nl> + return shardingproperties . < boolean > getvalue ( shardingpropertiesconstant . proxy_opentracing_enabled ) ; <nl> + } <nl>  <nl> + public boolean isshowsql ( ) { <nl> + return shardingproperties . getvalue ( shardingpropertiesconstant . sql_show ) ; <nl> + }
official website : http : / / shardingsphere . io / <nl>  <nl> # # overview <nl>  <nl> - sharding - sphere is an open source distributed database middleware solution suite , which consists of sharding - jdbc , sharding - proxy and sharding - sidecar ( planning ) . these three sub - projects are suitable for various scenarios and provide consistent functions including data sharding , distributed transaction and database orchestration . <nl> - <nl> - as a relational database middleware , rather than implementing a new database , sharding - sphere is aimed at making the most of original capacities of database ( like compute and storage ) and making it simpler and more efficient on distribute environment . <nl> - it can cooperate with nosql and newsql , which keep staying in the cutting edge of technology and recommendable . meanwhile , sharding - sphere focuses on technologies remaining stable and changeless so as to grasp the intrinsic quality . <nl> - relational database is still the cornerstone of core business in enterprises and possesses huge market share . it is difficult to estimate trendy in future and now we focus on how to enhance the capacity of sharding - sphere with relational database . <nl> + sharding - sphere is an open - source ecosystem consisted of a set of distributed database middleware solution , including num independent products , sharding - jdbc , sharding - proxy & sharding - sidecar ( <nl> + they all provide functions of data sharding , distributed transaction and database orchestration , applicable in a variety of situations such as java isomorphism , heterogeneous language and cloud native . <nl> + aiming at reasonably making full use of the computation and storage capacity of database in distributed system , sharding - sphere defines itself as a middleware , rather than a totally new type of database . <nl> + as the cornerstone of many enterprises , relational database still takes a huge market share . <nl> + therefore , at current stage , we prefer to focus on its increment instead of a total overturn . <nl>  <nl> ! [ sharding - sphere scope ] ( http : / / ovfotjrsi . bkt . clouddn . com / sharding - sphere - scope_en . png ) <nl>  <nl>
public abstract class integratetestcaseassertion { <nl> collection < sqlvalue > result = new linkedlist < > ( ) ; <nl> int count = num ; <nl> for ( string each : splitter . on ( " , " ) . trimresults ( ) . splittolist ( parameters ) ) { <nl> + <nl> + if ( each . startswith ( " ' " ) ) { <nl> + string value = each . substring ( each . indexof ( " ' " ) + num , each . lastindexof ( " ' " ) ) ; <nl> + result . add ( new sqlvalue ( value , " json " , + + count ) ) ; <nl> + continue ; <nl> + } <nl> list < string > parameterpair = splitter . on ( " : " ) . trimresults ( ) . splittolist ( each ) ; <nl> result . add ( new sqlvalue ( parameterpair . get ( 0 ) , parameterpair . get ( 1 ) , + + count ) ) ; <nl> }
chapter = true <nl> [ ! [ github forks ] ( https : / / img . shields . io / github / forks / sharding - sphere / sharding - sphere . svg ? style = social & label = fork ) ] ( https : / / github . com / sharding - sphere / sharding - sphere / fork ) & nbsp ; <nl> [ ! [ github watchers ] ( https : / / img . shields . io / github / watchers / sharding - sphere / sharding - sphere . svg ? style = social & label = watch ) ] ( https : / / github . com / sharding - sphere / sharding - sphere / watchers ) <nl>  <nl> - sharding - sphere is an open source distributed database middleware solution suite , which consists of sharding - jdbc , sharding - proxy and sharding - sidecar ( planning ) . these three sub - projects are suitable for various scenarios and provide consistent functions including data sharding , distributed transaction and database orchestration . <nl> - <nl> - as a relational database middleware , rather than implementing a new database , sharding - sphere is aimed at making the most of original capacities of database ( like compute and storage ) and making it simpler and more efficient on distribute environment . <nl> - it can cooperate with nosql and newsql , which keep staying in the cutting edge of technology and recommendable . meanwhile , sharding - sphere focuses on technologies remaining stable and changeless so as to grasp the intrinsic quality . <nl> - relational database is still the cornerstone of core business in enterprises and possesses huge market share . it is difficult to estimate trendy in future and now we focus on how to enhance the capacity of sharding - sphere with relational database . <nl> + sharding - sphere is an open - source ecosystem consisted of a set of distributed database middleware solution , including num independent products , sharding - jdbc , sharding - proxy & sharding - sidecar ( <nl> + aiming at reasonably making full use of the computation and storage capacity of database in distributed system , sharding - sphere defines itself as a middleware , rather than a totally new type of database . as the cornerstone of many enterprises , relational database still takes a huge market share . therefore , at current stage , we prefer to focus on its increment instead of a total overturn . <nl>  <nl> [ ! [ license ] ( https : / / img . shields . io / badge / license - apache % 202 - 4eb1ba . svg ) ] ( https : / / www . apache . org / licenses / license - 2 . 0 . html ) <nl> [ ! [ gitter ] ( https : / / badges . gitter . im / shardingsphere / shardingsphere . svg ) ] ( https : / / gitter . im / shardingsphere / lobby ) <nl>
<nl> sharding - sphere <nl> < / div > <nl> < div class = " title " > opensource & nbsp ; geek & emsp ; community < / div > <nl> - < div class = " msg " > sharding - sphere is an open source distributed database middleware solution suite , which consists of sharding - jdbc , sharding - proxy and sharding - sidecar ( planning ) . these three sub - projects are suitable for various scenarios and provide consistent functions including data sharding , distributed transaction and database orchestration . < / div > <nl> - < div class = " msg " > as a relational database middleware , rather than implementing a new database , sharding - sphere is aimed at making the most of original capacities of database ( like compute and storage ) and making it simpler and more efficient on distribute environment . < / div > <nl> + < div class = " msg " > sharding - sphere is an open - source ecosystem consisted of a set of distributed database middleware solution , including num independent products , sharding - jdbc , sharding - proxy & sharding - sidecar ( <nl> + < div class = " msg " > aiming at reasonably making full use of the computation and storage capacity of database in distributed system , sharding - sphere defines itself as a middleware , rather than a totally new type of database . as the cornerstone of many enterprises , relational database still takes a huge market share . therefore , at current stage , we prefer to focus on its increment instead of a total overturn . < / div > <nl> < div class = " button " > < a class = " btn " href = " http : / / shardingsphere . io / document / current / en / " target = " _blank " > learn more < / a > < / div > <nl> < div class = " other " > <nl> < div class = " o - list " > <nl>
<nl> < artifactid > sharding - core < / artifactid > <nl> < version > $ { project . version } < / version > <nl> < / dependency > <nl> + < ! - - <nl> + < dependency > <nl> + < groupid > io . shardingsphere < / groupid > <nl> + < artifactid > sharding - jdbc - core < / artifactid > <nl> + < version > $ { project . version } < / version > <nl> + < / dependency > <nl> < / dependencies > <nl> < / project >
public final class jdbcrevertengine implements revertengine { <nl> @ override <nl> public revertresult revert ( final string datasource , final string sql , final list < list < object > > params ) throws sqlexception { <nl> datasource datasource = shardingcontext . getdatasourcemap ( ) . get ( datasource ) ; <nl> + <nl> databasetype databasetype = shardingcontext . getdatabasetype ( ) ; <nl> string logictable = getlogictable ( databasetype , sql ) ; <nl> tablemetadata tablemetadata = shardingcontext . getmetadata ( ) . gettable ( ) . gettablemetadatamap ( ) . get ( logictable ) ; <nl> mmm a / sharding - proxy / src / main / java / io / shardingsphere / proxy / revert / proxyrevertengine . java <nl> ppp b / sharding - proxy / src / main / java / io / shardingsphere / proxy / revert / proxyrevertengine . java <nl>
public final class proxyrevertengine implements revertengine { <nl> @ override <nl> public revertresult revert ( final string datasource , final string sql , final list < list < object > > params ) throws sqlexception { <nl> datasource actualdatasource = ruleregistry . getinstance ( ) . getbackenddatasource ( ) . getdatasourcemap ( ) . get ( datasource ) ; <nl> + <nl> databasetype databasetype = databasetype . mysql ; <nl> string logictable = getlogictable ( databasetype , sql ) ; <nl> tablemetadata metadata = ruleregistry . getinstance ( ) . getmetadata ( ) . gettable ( ) . gettablemetadatamap ( ) . get ( logictable ) ;
<nl> + / * <nl> + * copyright num - 2018 shardingsphere . io . <nl> + * < p > <nl> + * licensed under the apache license , version num . 0 ( the " license " ) ; <nl> + * you may not use this file except in compliance with the license . <nl> + * you may obtain a copy of the license at <nl> + * <nl> + * http : / / www . apache . org / licenses / license - 2 . 0 <nl> + * <nl> + * unless required by applicable law or agreed to in writing , software <nl> + * distributed under the license is distributed on an " as is " basis , <nl> + * without warranties or conditions of any kind , either express or implied . <nl> + * see the license for the specific language governing permissions and <nl> + * limitations under the license . <nl> + * < / p > <nl> + * / <nl> + <nl> + package io . shardingsphere . core . transaction ; <nl> + <nl> + import io . shardingsphere . core . event . transaction . shardingtransactionevent ; <nl> + <nl> + import java . sql . sqlexception ; <nl> + <nl> + / * * <nl> + * sharding transaction listener . <nl> + * <nl> + * @ author zhangliang <nl> + * <nl> + * @ param < t > transaction event type <nl> + * / <nl> + <nl> + public interface shardingtransactionlistener < t extends shardingtransactionevent > { <nl> + <nl> + / * * <nl> + * register sharding transaction listener into event bus . <nl> + * / <nl> + void register ( ) ; <nl> + <nl> + / * * <nl> + * listen event . <nl> + * <nl> + * @ param transactionevent transaction event <nl> + * @ throws sqlexception sql exception <nl> + * / <nl> + void listen ( t transactionevent ) throws sqlexception ; <nl> + }
<nl> + / * <nl> + * copyright num - 2018 shardingsphere . io . <nl> + * < p > <nl> + * licensed under the apache license , version num . 0 ( the " license " ) ; <nl> + * you may not use this file except in compliance with the license . <nl> + * you may obtain a copy of the license at <nl> + * <nl> + * http : / / www . apache . org / licenses / license - 2 . 0 <nl> + * <nl> + * unless required by applicable law or agreed to in writing , software <nl> + * distributed under the license is distributed on an " as is " basis , <nl> + * without warranties or conditions of any kind , either express or implied . <nl> + * see the license for the specific language governing permissions and <nl> + * limitations under the license . <nl> + * < / p > <nl> + * / <nl> + <nl> + package io . shardingsphere . transaction . listener . base ; <nl> + <nl> + import com . fasterxml . jackson . core . jsonprocessingexception ; <nl> + import com . google . common . eventbus . allowconcurrentevents ; <nl> + import com . google . common . eventbus . subscribe ; <nl> + import io . shardingsphere . core . constant . transaction . transactiontype ; <nl> + import io . shardingsphere . transaction . event . base . sagasqlexecutionevent ; <nl> + import io . shardingsphere . transaction . event . base . sagatransactionevent ; <nl> + import io . shardingsphere . transaction . listener . shardingtransactionlisteneradapter ; <nl> + import io . shardingsphere . transaction . manager . shardingtransactionmanagerregistry ; <nl> + import io . shardingsphere . transaction . manager . base . basetransactionmanager ; <nl> + import io . shardingsphere . transaction . manager . base . sagatransactionmanager ; <nl> + import io . shardingsphere . transaction . manager . base . servicecomb . sagadefinitionbuilder ; <nl> + import lombok . extern . slf4j . slf4j ; <nl> + <nl> + import java . sql . sqlexception ; <nl> + import java . util . map ; <nl> + import java . util . concurrent . concurrenthashmap ; <nl> + <nl> + / * * <nl> + * saga transaction listener . <nl> + * <nl> + * @ author yangyi <nl> + * / <nl> + @ slf4j <nl> + public final class sagatransactionlistener extends shardingtransactionlisteneradapter < sagatransactionevent > { <nl> + <nl> + private final basetransactionmanager < sagatransactionevent > transactionmanager = ( sagatransactionmanager ) shardingtransactionmanagerregistry . getinstance ( ) . getshardingtransactionmanager ( transactiontype . base ) ; <nl> + <nl> + private final map < string , sagadefinitionbuilder > sagadefinitionbuildermap = new concurrenthashmap < > ( ) ; <nl> + <nl> + @ subscribe <nl> + @ allowconcurrentevents <nl> + @ override <nl> + public void listen ( final sagatransactionevent transactionevent ) throws sqlexception { <nl> + switch ( transactionevent . getoperationtype ( ) ) { <nl> + case commit : <nl> + try { <nl> + transactionevent . setsagajson ( sagadefinitionbuildermap . remove ( transactionmanager . gettransactionid ( ) ) . build ( ) ) ; <nl> + dotransaction ( transactionmanager , transactionevent ) ; <nl> + } catch ( jsonprocessingexception e ) { <nl> + / / shouldn ' t really happen , but is declared as possibility so : <nl> + log . error ( " saga transaction " , transactionmanager . gettransactionid ( ) , " commit failed , caused by json build exception : " , e ) ; <nl> + return ; <nl> + } <nl> + break ; <nl> + case rollback : <nl> + sagadefinitionbuildermap . remove ( transactionmanager . gettransactionid ( ) ) ; <nl> + dotransaction ( transactionmanager , transactionevent ) ; <nl> + break ; <nl> + case begin : <nl> + dotransaction ( transactionmanager , transactionevent ) ; <nl> + sagadefinitionbuildermap . put ( transactionmanager . gettransactionid ( ) , new sagadefinitionbuilder ( ) ) ; <nl> + break ; <nl> + default : <nl> + } <nl> + } <nl> + <nl> + / * * <nl> + * listen saga sql execution event . <nl> + * <nl> + * @ param sqlexecutionevent saga sql execution event <nl> + * / <nl> + @ subscribe <nl> + @ allowconcurrentevents <nl> + public void listensqlexecutionevent ( final sagasqlexecutionevent sqlexecutionevent ) { <nl> + switch ( sqlexecutionevent . geteventtype ( ) ) { <nl> + case before_execute : <nl> + sagadefinitionbuildermap . get ( sqlexecutionevent . gettransactionid ( ) ) . switchparents ( ) ; <nl> + break ; <nl> + case execute_success : <nl> + <nl> + sagadefinitionbuildermap . get ( sqlexecutionevent . gettransactionid ( ) ) . addchildrequest ( <nl> + sqlexecutionevent . getid ( ) , <nl> + sqlexecutionevent . getdatasource ( ) , <nl> + sqlexecutionevent . getsqlunit ( ) . getsql ( ) , <nl> + sqlexecutionevent . getparameters ( ) , <nl> + " " , null ) ; <nl> + break ; <nl> + case execute_failure : <nl> + default : <nl> + } <nl> + } <nl> + }
public class shardingdatasource extends abstractdatasourceadapter implements aut <nl> configmapcontext . getinstance ( ) . getshardingconfig ( ) . putall ( configmap ) ; <nl> } <nl> this . shardingproperties = new shardingproperties ( null = = props ? new properties ( ) : props ) ; <nl> - this . shardingcontext = getshardingcontext ( datasourcemap , shardingrule ) ; <nl> + <nl> + this . shardingcontext = getshardingcontext ( getrawdatasourcemap ( datasourcemap ) , getshardingruleconfiguration ( datasourcemap , shardingrule ) ) ; <nl> } <nl>  <nl> private shardingcontext getshardingcontext ( final map < string , datasource > datasourcemap , final shardingrule shardingrule ) { <nl>
public final class comquerypacket implements querycommandpacket { <nl> @ override <nl> public optional < commandresponsepackets > execute ( ) throws sqlexception { <nl> log . debug ( " com_query received for sharding - proxy : { } " , sql ) ; <nl> - if ( transactiontype . xa ! = ruleregistry . getinstance ( ) . gettransactiontype ( ) ) { <nl> - optional < transactionoperationtype > operationtype = transactionoperationtype . getoperationtype ( sql ) ; <nl> - if ( operationtype . ispresent ( ) & & isintransaction ( operationtype . get ( ) ) ) { <nl> - eventbusinstance . getinstance ( ) . post ( new xatransactionevent ( operationtype . get ( ) ) ) ; <nl> - return optional . of ( new commandresponsepackets ( new okpacket ( 1 ) ) ) ; <nl> - } <nl> + optional < transactionoperationtype > operationtype = transactionoperationtype . getoperationtype ( sql ) ; <nl> + if ( ! operationtype . ispresent ( ) ) { <nl> + return optional . of ( backendhandler . execute ( ) ) ; <nl> } <nl> - return optional . of ( backendhandler . execute ( ) ) ; <nl> + if ( transactiontype . xa = = ruleregistry . getinstance ( ) . gettransactiontype ( ) & & isintransaction ( operationtype . get ( ) ) ) { <nl> + eventbusinstance . getinstance ( ) . post ( new xatransactionevent ( operationtype . get ( ) ) ) ; <nl> + } <nl> + <nl> + return optional . of ( new commandresponsepackets ( new okpacket ( 1 ) ) ) ; <nl> } <nl>  <nl> private boolean isintransaction ( final transactionoperationtype operationtype ) throws sqlexception {
public final class comquerypacket implements querycommandpacket { <nl> } <nl>  <nl> private boolean isintransaction ( final transactionoperationtype operationtype ) throws sqlexception { <nl> + <nl> return transactionoperationtype . rollback ! = operationtype <nl> | | status . status_no_transaction ! = shardingtransactionmanagerregistry . getinstance ( ) . getshardingtransactionmanager ( transactiontype . xa ) . getstatus ( ) ; <nl> }
public final class ruleregistry { <nl> shardingproperties shardingproperties = new shardingproperties ( null = = properties ? new properties ( ) : properties ) ; <nl> showsql = shardingproperties . getvalue ( shardingpropertiesconstant . sql_show ) ; <nl> connectionmode = connectionmode . valueof ( shardingproperties . < string > getvalue ( shardingpropertiesconstant . connection_mode ) ) ; <nl> - transactiontype = transactiontype . valueof ( shardingproperties . < string > getvalue ( shardingpropertiesconstant . proxy_transaction_mode ) ) ; <nl> + <nl> + transactiontype = shardingproperties . < boolean > getvalue ( shardingpropertiesconstant . proxy_transaction_enabled ) ? transactiontype . xa : transactiontype . local ; <nl> transactiontypeholder . set ( transactiontype ) ; <nl> acceptorsize = shardingproperties . getvalue ( shardingpropertiesconstant . acceptor_size ) ; <nl> executorsize = shardingproperties . getvalue ( shardingpropertiesconstant . executor_size ) ; <nl> mmm a / sharding - proxy / src / main / resources / conf / config . yaml <nl> ppp b / sharding - proxy / src / main / resources / conf / config . yaml <nl>
public final class ruleregistry { <nl> shardingproperties shardingproperties = new shardingproperties ( null = = properties ? new properties ( ) : properties ) ; <nl> showsql = shardingproperties . getvalue ( shardingpropertiesconstant . sql_show ) ; <nl> connectionmode = connectionmode . valueof ( shardingproperties . < string > getvalue ( shardingpropertiesconstant . connection_mode ) ) ; <nl> - transactiontype = transactiontype . valueof ( shardingproperties . < string > getvalue ( shardingpropertiesconstant . proxy_transaction_mode ) ) ; <nl> + <nl> + transactiontype = transactiontype . none ; <nl> + / / transactiontype = transactiontype . valueof ( shardingproperties . < string > getvalue ( shardingpropertiesconstant . proxy_transaction_mode ) ) ; <nl> transactionmanager = proxytransactionloader . load ( transactiontype ) ; <nl> acceptorsize = shardingproperties . getvalue ( shardingpropertiesconstant . acceptor_size ) ; <nl> executorsize = shardingproperties . getvalue ( shardingpropertiesconstant . executor_size ) ;
<nl> + # contributor covenant code of conduct <nl> + <nl> + # # development idea <nl> + <nl> + - write extremely clean , simplify and graceful code . fully agree with & lt ; refactoring : improving the design of existing code & gt ; and & lt ; clean code : a handbook of agile software craftsma & gt ; . <nl> + <nl> + # # code push conventions <nl> + <nl> + - make sure all test cases passed . <nl> + - make sure test coverage not lower than dev branch . <nl> + - use checkstyle to check code style , provide special reason if rule violated . find checkstyle template from ` sharding - sphere / src / resources / sharding_checks . xml ` , please use checkstyle num . 8 to run the rule . <nl> + - make sure ` mvn clean install ` can be success . <nl> + - delete unused code in time . <nl> + <nl> + # # code conventions <nl> + <nl> + - use linux line seperator . <nl> + - indent ( including blank lines ) is consistent with the previous line . <nl> + - no unnecessary blank line . <nl> + - all logs and java docs are in english . <nl> + - commit allow javadoc , <nl> + - give a meaningful variable name . the name of return value is result ; the name of unit value is each in for each sentence , instead of entry for map iterator . <nl> + - name of properties file is camel - case , first letter is lowercase . <nl> + - constant on left and variable on right in conditional expression . <nl> + - the nested loop should extract to a new private method . <nl> + - replace nested conditional with guard clauses . <nl> + - access permissions for classes and methods should minimal as possible . <nl> + - parameters and return value are not allowed to be null . <nl> + - if use comment to explain the code , try to split several small methods , and use method name to explain it . <nl> + - use lombok instead of the constructor , getter , setter methods and log variable . <nl> + - keep style consistent with existed code . <nl> + - no duplicate code and configuration . <nl> + <nl> + # # unit test conventions <nl> + <nl> + - test code and production code equality , should follow the same code conventions . <nl> + - test cases should fully covered if no special reason . <nl> + - separate environment preparation codes and test codes . <nl> + - only junit assert , hamcrest corematchers , mockito related can use static import . <nl> + - for single parameter assert , should use ` asserttrue ` , ` assertfalse ` , ` assertnull ` and ` assertnotnull ` . <nl> + - for multiple parameters assert , should use ` assertthat ` . <nl> + - assert accurately , do not use ` not ` , ` containsstring ` and so on . <nl> + - use actualxxx and expectedxxx to name related variable .
public final class mysqlfrontendhandler extends frontendhandler { <nl> new executorgroup ( context . channel ( ) . id ( ) ) . getexecutorservice ( ) . execute ( new commandexecutor ( context , message ) ) ; <nl> } <nl>  <nl> + @ override <nl> + public void channelwritabilitychanged ( final channelhandlercontext context ) { <nl> + context . firechannelwritabilitychanged ( ) ; <nl> + if ( context . channel ( ) . iswritable ( ) ) { <nl> + <nl> + synchronized ( this ) { <nl> + system . out . println ( " notify " ) ; <nl> + this . notifyall ( ) ; <nl> + } <nl> + } <nl> + } <nl> + <nl> @ requiredargsconstructor <nl> - static class commandexecutor implements runnable { <nl> + class commandexecutor implements runnable { <nl>  <nl> private final channelhandlercontext context ; <nl>  <nl>
public class shardingdatasourcemetadata { <nl> for ( entry < string , string > entry : datasourceurls . entryset ( ) ) { <nl> datasourcemetadatamap . put ( entry . getkey ( ) , datasourcemetadatafactory . newinstance ( databasetype , entry . getvalue ( ) ) ) ; <nl> } <nl> - return handlemasterslavedatasourcenames ( shardingrule , datasourcemetadatamap ) ; <nl> + return handlemasterslavedatasources ( shardingrule , datasourcemetadatamap ) ; <nl> } <nl>  <nl> - private map < string , datasourcemetadata > handlemasterslavedatasourcenames ( final shardingrule shardingrule , final map < string , datasourcemetadata > datasourcemetadatamap ) { <nl> + private map < string , datasourcemetadata > handlemasterslavedatasources ( final shardingrule shardingrule , final map < string , datasourcemetadata > datasourcemetadatamap ) { <nl> map < string , datasourcemetadata > result = new linkedhashmap < > ( ) ; <nl> if ( shardingrule . getmasterslaverules ( ) . isempty ( ) ) { <nl> return datasourcemetadatamap ; <nl> } <nl> for ( entry < string , datasourcemetadata > entry : datasourcemetadatamap . entryset ( ) ) { <nl> - optional < string > masterslaverulenameoptional = shardingrule . tryfindmasterslaverulename ( entry . getkey ( ) ) ; <nl> - if ( masterslaverulenameoptional . ispresent ( ) ) { <nl> - result . put ( masterslaverulenameoptional . get ( ) , entry . getvalue ( ) ) ; <nl> + optional < masterslaverule > masterslaverule = shardingrule . findmasterslaverule ( entry . getkey ( ) ) ; <nl> + <nl> + if ( masterslaverule . ispresent ( ) ) { <nl> + result . put ( masterslaverule . get ( ) . getname ( ) , entry . getvalue ( ) ) ; <nl> } <nl> } <nl> return result ; <nl> mmm a / sharding - core / src / main / java / io / shardingsphere / core / rule / shardingrule . java <nl> ppp b / sharding - core / src / main / java / io / shardingsphere / core / rule / shardingrule . java <nl>
public abstract class frontendhandler extends channelinboundhandleradapter { <nl> context . firechannelinactive ( ) ; <nl> channelthreadexecutorgroup . getinstance ( ) . unregister ( context . channel ( ) . id ( ) ) ; <nl> } <nl> + <nl> + @ override <nl> + public void channelwritabilitychanged ( final channelhandlercontext context ) { <nl> + context . firechannelwritabilitychanged ( ) ; <nl> + if ( context . channel ( ) . iswritable ( ) ) { <nl> + <nl> + } <nl> + } <nl> }
public abstract class jdbcbackendhandler implements backendhandler { <nl> if ( each instanceof okpacket ) { <nl> okpacket okpacket = ( okpacket ) each ; <nl> affectedrows + = okpacket . getaffectedrows ( ) ; <nl> + <nl> lastinsertid = okpacket . getlastinsertid ( ) ; <nl> } <nl> }
public abstract class jdbcexecuteworker implements callable < commandresponsepacke <nl> if ( proxymode . memory_strictly = = ruleregistry . getinstance ( ) . getproxymode ( ) ) { <nl> statement . setfetchsize ( fetch_one_row_a_time ) ; <nl> } <nl> - if ( executesql ( ) ) { <nl> - resultset resultset = statement . getresultset ( ) ; <nl> - if ( proxymode . memory_strictly = = ruleregistry . getinstance ( ) . getproxymode ( ) ) { <nl> - jdbcresourcemanager . addresultset ( resultset ) ; <nl> - } else { <nl> - resultlist resultlist = new resultlist ( ) ; <nl> - while ( resultset . next ( ) ) { <nl> - for ( int columnindex = num ; columnindex < = resultset . getmetadata ( ) . getcolumncount ( ) ; columnindex + + ) { <nl> - resultlist . add ( resultset . getobject ( columnindex ) ) ; <nl> - } <nl> + if ( ! executesql ( ) ) { <nl> + return new commandresponsepackets ( new okpacket ( 1 , statement . getupdatecount ( ) , isreturngeneratedkeys ? getgeneratedkey ( ) : num ) ) ; <nl> + } <nl> + resultset resultset = statement . getresultset ( ) ; <nl> + jdbcresourcemanager . addresultset ( resultset ) ; <nl> + if ( proxymode . connection_strictly = = ruleregistry . getinstance ( ) . getproxymode ( ) ) { <nl> + resultlist resultlist = new resultlist ( ) ; <nl> + while ( resultset . next ( ) ) { <nl> + for ( int columnindex = num ; columnindex < = resultset . getmetadata ( ) . getcolumncount ( ) ; columnindex + + ) { <nl> + resultlist . add ( resultset . getobject ( columnindex ) ) ; <nl> } <nl> - resultlist . setiterator ( resultlist . getresultlist ( ) . iterator ( ) ) ; <nl> - getjdbcbackendhandler ( ) . getresultlists ( ) . add ( resultlist ) ; <nl> } <nl> - return getheaderpackets ( resultset . getmetadata ( ) ) ; <nl> - } else { <nl> - return new commandresponsepackets ( new okpacket ( 1 , statement . getupdatecount ( ) , isreturngeneratedkeys ? getgeneratedkey ( ) : num ) ) ; <nl> + <nl> + resultlist . setiterator ( resultlist . getresultlist ( ) . iterator ( ) ) ; <nl> + jdbcbackendhandler . getresultlists ( ) . add ( resultlist ) ; <nl> } <nl> + return getheaderpackets ( resultset . getmetadata ( ) ) ; <nl> } <nl>  <nl> protected abstract boolean executesql ( ) throws sqlexception ;
public abstract class jdbcbackendhandler implements backendhandler { <nl> return result ; <nl> } <nl>  <nl> - private boolean isxaddl ( final sqlrouteresult routeresult ) throws systemexception { <nl> - return transactiontype . xa . equals ( ruleregistry . gettransactiontype ( ) ) <nl> - & & sqltype . ddl . equals ( routeresult . getsqlstatement ( ) . gettype ( ) ) & & status . status_no_transaction ! = atomikosusertransaction . getinstance ( ) . getstatus ( ) ; <nl> + <nl> + private boolean isunsupportedxa ( final sqltype sqltype ) throws systemexception { <nl> + return transactiontype . xa = = ruleregistry . gettransactiontype ( ) & & sqltype . ddl = = sqltype & & status . status_no_transaction ! = atomikosusertransaction . getinstance ( ) . getstatus ( ) ; <nl> } <nl>  <nl> private sqlrouteresult domasterslaveroute ( ) { <nl> mmm a / sharding - proxy / src / main / java / io / shardingsphere / proxy / transport / mysql / constant / servererrorcode . java <nl> ppp b / sharding - proxy / src / main / java / io / shardingsphere / proxy / transport / mysql / constant / servererrorcode . java <nl>
import java . util . logging . logger ; <nl> * / <nl> public abstract class abstractdatasourceadapter extends abstractunsupportedoperationdatasource { <nl>  <nl> + static { <nl> + <nl> + } <nl> + <nl> @ getter <nl> private final databasetype databasetype ;
public final class executebatchintegratetest { <nl> } <nl> assertthat ( " size of actual result set is different with size of expected dat set rows . " , count , is ( expecteddatsetrows . size ( ) ) ) ; <nl> } <nl> + <nl> + @ test <nl> + public void assertclearbatch ( ) throws sqlexception , parseexception { <nl> + <nl> + if ( ! databasetypeenvironment . isenabled ( ) | | " masterslave " . equals ( shardingruletype ) ) { <nl> + return ; <nl> + } <nl> + try ( connection connection = datasource . getconnection ( ) ) { <nl> + try ( preparedstatement preparedstatement = connection . preparestatement ( sql ) ) { <nl> + for ( integratetestcaseassertion each : integratetestcase . getintegratetestcaseassertions ( ) ) { <nl> + addbatch ( preparedstatement , each ) ; <nl> + } <nl> + preparedstatement . clearbatch ( ) ; <nl> + assertthat ( preparedstatement . executebatch ( ) . length , is ( 0 ) ) ; <nl> + } <nl> + } <nl> + } <nl> }
public final class ddlintegratetest extends baseintegratetest { <nl> } <nl>  <nl> private void assertmetadata ( final connection connection ) throws ioexception , jaxbexception , sqlexception { <nl> + <nl> + if ( null = = assertion . getexpecteddatafile ( ) ) { <nl> + return ; <nl> + } <nl> expectedmetadataroot expected ; <nl> try ( filereader reader = new filereader ( getexpecteddatafile ( ) ) ) { <nl> expected = ( expectedmetadataroot ) jaxbcontext . newinstance ( expectedmetadataroot . class ) . createunmarshaller ( ) . unmarshal ( reader ) ; <nl> mmm a / sharding - jdbc / src / test / resources / asserts / cases / ddl / ddl - integrate - test - cases . xml <nl> ppp b / sharding - jdbc / src / test / resources / asserts / cases / ddl / ddl - integrate - test - cases . xml <nl>
<nl> < assertion sharding - rule - type = " dbtbl_with_masterslave " parameters = " 1 : int , num : int , insert : string " expected - update = " 1 " expected - data - file = " dbtbl_with_masterslave / insert_for_order . xml " / > <nl> < assertion sharding - rule - type = " masterslave " parameters = " 1 : int , num : int , insert : string " expected - update = " 1 " expected - data - file = " masterslave / insert_for_order . xml " / > <nl> < / dml - test - case > <nl> + <nl> + < ! - - <nl> + < ! - - < dml - test - case sql - case - id = " insert_with_all_placeholders_for_table_identifier " > - - > <nl> + < ! - - < assertion sharding - rule - type = " db " parameters = " 1 : int , num : int , insert : string " expected - update = " 1 " expected - data - file = " db / insert_for_order . xml " / > - - > <nl> + < ! - - < assertion sharding - rule - type = " tbl " parameters = " 1 : int , num : int , insert : string " expected - update = " 1 " expected - data - file = " tbl / insert_for_order . xml " / > - - > <nl> + < ! - - < assertion sharding - rule - type = " dbtbl_with_masterslave " parameters = " 1 : int , num : int , insert : string " expected - update = " 1 " expected - data - file = " dbtbl_with_masterslave / insert_for_order . xml " / > - - > <nl> + < ! - - < assertion sharding - rule - type = " masterslave " parameters = " 1 : int , num : int , insert : string " expected - update = " 1 " expected - data - file = " masterslave / insert_for_order . xml " / > - - > <nl> + < ! - - < / dml - test - case > - - > <nl>  <nl> < dml - test - case sql - case - id = " insert_set_with_all_placeholders " > <nl> < assertion sharding - rule - type = " db " parameters = " 1 : int , num : int , insert : string " expected - update = " 1 " expected - data - file = " db / insert_for_order . xml " / > <nl> mmm a / sharding - sql - test / src / main / resources / sql / dml / insert . xml <nl> ppp b / sharding - sql - test / src / main / resources / sql / dml / insert . xml <nl>
public final class schemaenvironmentmanager { <nl> } <nl> return result ; <nl> } <nl> + <nl> + / * * <nl> + * drop table . <nl> + * <nl> + * @ param shardingruletype sharding rule type <nl> + * @ throws jaxbexception jaxb exception <nl> + * @ throws ioexception io exception <nl> + * / <nl> + public static void droptable ( final string shardingruletype ) throws jaxbexception , ioexception { <nl> + for ( databasetype each : integratetestenvironment . getinstance ( ) . getdatabasetypes ( ) ) { <nl> + schemaenvironment databaseenvironmentschema = unmarshal ( environmentpath . getdatabaseenvironmentresourcefile ( shardingruletype ) ) ; <nl> + droptable ( databaseenvironmentschema , each ) ; <nl> + } <nl> + } <nl> + <nl> + private static void droptable ( final schemaenvironment databaseenvironmentschema , final databasetype databasetype ) { <nl> + for ( string each : databaseenvironmentschema . getdatabases ( ) ) { <nl> + try ( basicdatasource datasource = ( basicdatasource ) datasourceutil . createdatasource ( databasetype , each ) ; <nl> + connection connection = datasource . getconnection ( ) ; <nl> + stringreader stringreader = new stringreader ( stringutils . join ( gettabledropsqls ( databaseenvironmentschema . gettabledropsqls ( ) , databasetype ) , " ; \n " ) ) ) { <nl> + runscript . execute ( connection , stringreader ) ; <nl> + } catch ( final sqlexception ex ) { <nl> + <nl> + } <nl> + } <nl> + } <nl> + <nl> + private static list < string > gettabledropsqls ( final list < string > tabledropsqls , final databasetype databasetype ) { <nl> + if ( databasetype . h2 = = databasetype ) { <nl> + return tabledropsqls ; <nl> + } <nl> + return new linkedlist < > ( ) ; <nl> + } <nl> }
public final class starttest { <nl>  <nl> @ parameters ( name = " { 0 } - > rule : { 3 } - > { 4 } " ) <nl> public static collection < object [ ] > getparameters ( ) { <nl> + <nl> collection < object [ ] > result = new linkedlist < > ( ) ; <nl> for ( object [ ] each : sqlcasesloader . getsupportedsqltestparameters ( arrays . < enum > aslist ( databasetype . values ( ) ) , databasetype . class ) ) { <nl> string sqlcaseid = each [ 0 ] . tostring ( ) ; <nl> mmm a / sharding - jdbc / src / test / java / io / shardingsphere / dbtest / asserts / datasetassertloader . java <nl> ppp b / sharding - jdbc / src / test / java / io / shardingsphere / dbtest / asserts / datasetassertloader . java <nl>
public final class starttest { <nl> return result ; <nl> } <nl>  <nl> - @ beforeclass <nl> + / / @ beforeclass <nl> + <nl> public static void setup ( ) throws jaxbexception , ioexception { <nl> if ( isinitialized ) { <nl> isinitialized = false ; <nl>
import java . util . list ; <nl>  <nl> / * * <nl> * created by aaa <nl> + * <nl> * / <nl> public class retryprovider extends baseprovider { <nl> private static final logger logger = loggerfactory . getlogger ( retryprovider . class ) ;
public final class starttest { <nl> } <nl>  <nl> @ test <nl> + @ ignore <nl> + <nl> public void test ( ) throws jaxbexception , saxexception , parseexception , ioexception , xpathexpressionexception , sqlexception , parserconfigurationexception { <nl> assertengine . runassert ( assertdefinition , shardingruletype , databasetypeenvironment , casetype ) ; <nl> }
public final class shardingruleregistry { <nl> } <nl> shardingrule = yamlshardingconfigurationforproxy . getshardingrule ( collections . < string > emptylist ( ) ) ; <nl> try { <nl> + <nl> shardingmetadata = new jdbcshardingmetadata ( datasourcemap , shardingrule , databasetype . mysql ) ; <nl> - / / shardingmetadata = new proxyshardingmetadata ( datasourcemap ) ; <nl> shardingmetadata . init ( shardingrule ) ; <nl> } catch ( final sqlexception ex ) { <nl> throw new shardingjdbcexception ( ex ) ;
public final class databaseenvironmentmanager { <nl> connection connection = datasource . getconnection ( ) ; <nl> stringreader stringreader = new stringreader ( stringutils . join ( databaseenvironmentschema . gettablecreatesqls ( ) , " ; \n " ) ) ) { <nl> runscript . execute ( connection , stringreader ) ; <nl> + } catch ( final sqlexception ex ) { <nl> + <nl> } <nl> } <nl> }
public final class starttest { <nl> } <nl> } <nl>  <nl> + @ afterclass <nl> + <nl> + public static void teardown ( ) throws jaxbexception , ioexception { <nl> + if ( iscleaned ) { <nl> + for ( string each : sharding_rule_types ) { <nl> + databaseenvironmentmanager . dropdatabase ( each ) ; <nl> + } <nl> + iscleaned = false ; <nl> + } <nl> + } <nl> + <nl> @ test <nl> public void test ( ) throws jaxbexception { <nl> assertengine . runassert ( path , id ) ;
public final class databaseenvironmentmanager { <nl> stringreader stringreader = new stringreader ( joiner . on ( " ; \n " ) . skipnulls ( ) . join ( generatedropdatabasesqls ( each , databaseinitialization . getdatabases ( ) ) ) ) ) { <nl> runscript . execute ( connection , stringreader ) ; <nl> } catch ( final sqlexception ex ) { <nl> - <nl> + <nl> } <nl> } <nl> } <nl>
public class contentionstrategytest extends usualclienttest { <nl> client . usestrategy ( strategytype . contention ) ; <nl> return client ; <nl> } <nl> + <nl> + <nl> } <nl> mmm a / src / test / java / com / saaavsaaa / client / zookeeper / usualclienttest . java <nl> ppp b / src / test / java / com / saaavsaaa / client / zookeeper / usualclienttest . java <nl>
<nl> package com . saaavsaaa . client . utility . constant ; <nl>  <nl> / * * <nl> - * created by aaa on num - 4 - 25 . <nl> + * created by aaa <nl> + * <nl> * / <nl> public final class properties { <nl> public static final boolean watch_on = true ;
public class usualclient extends baseclient { <nl> if ( rootnode . equals ( path ) ) { <nl> return ; <nl> } <nl> - zookeeper . create ( path , value . getbytes ( constants . utf_8 ) , authorities , createmode ) ; <nl> + try { <nl> + zookeeper . create ( path , value . getbytes ( constants . utf_8 ) , authorities , createmode ) ; <nl> + } catch ( keeperexception . nonodeexception e ) { <nl> + / / i don ' t know whether it will happen or not , if root watcher don ' t update rootexist timely <nl> + if ( e . getmessage ( ) . contains ( path ) ) { <nl> + rootexist = false ; <nl> + this . createcurrentonly ( key , value , createmode ) ; <nl> + } <nl> + } <nl> } <nl>  <nl> / * <nl> - * closed beta <nl> + * <nl> * / <nl> public void createallneedpath ( final string key , final string value , final createmode createmode ) throws keeperexception , interruptedexception { <nl> if ( key . indexof ( constants . path_
public final class statementexecutebackendhandler implements backendhandler { <nl>  <nl> @ override <nl> public commandresponsepackets execute ( ) { <nl> + <nl> sqlrouteresult routeresult = routingengine . route ( getcomstmtexecuteparameters ( ) ) ; <nl> if ( routeresult . getexecutionunits ( ) . isempty ( ) ) { <nl> return new commandresponsepackets ( new okpacket ( 1 , num , num , statusflag . server_status_autocommit . getvalue ( ) , num , " " ) ) ;
public final class comquerypacket extends commandpacket { <nl>  <nl> @ override <nl> public list < databaseprotocolpacket > execute ( ) { <nl> + <nl> return new sqlexecutebackendhandler ( sql , databasetype . mysql , true ) . execute ( ) ; <nl> } <nl> }
<nl> < / condition > <nl> < / conditions > <nl> < / parser - result > <nl> + <nl> + < ! - - <nl> + < parser - result sql - case - id = " assertupdatewithgeoinpostgresql " parameters = " ' 2017 - 06 - 07 ' num num ' { & quot ; rule2 & quot ; : & quot ; null2 & quot ; } ' num num num num " > <nl> + < tables > <nl> + < table name = " t_place " / > <nl> + < / tables > <nl> + < tokens > <nl> + < table - token begin - position = " 7 " original - literals = " t_place " / > <nl> + < / tokens > <nl> + < conditions > <nl> + < condition column - name = " user_new_id " table - name = " t_place " operator = " equal " > <nl> + < value index = " 6 " literal = " 7 " type = " int " / > <nl> + < / condition > <nl> + < condition column - name = " guid " table - name = " t_place " operator = " equal " > <nl> + < value index = " 7 " literal = " 200 " type = " int " / > <nl> + < / condition > <nl> + < / conditions > <nl> + < / parser - result > <nl> + - - > <nl> < / parser - result - sets > <nl> mmm a / sharding - core / src / test / resources / yaml / parser - rule . yaml <nl> ppp b / sharding - core / src / test / resources / yaml / parser - rule . yaml <nl>
public final class comquerypacket extends commandpacket { <nl> } <nl> return result ; <nl> } <nl> + <nl> + private boolean needgeneratedkey ( ) { <nl> + <nl> + return sql . touppercase ( ) . startswith ( " insert " ) ; <nl> + } <nl> + <nl> + private long getgeneratedkey ( final statement statement ) throws sqlexception { <nl> + long result = - 1 ; <nl> + resultset resultset = statement . getgeneratedkeys ( ) ; <nl> + if ( resultset . next ( ) ) { <nl> + result = resultset . getlong ( 1 ) ; <nl> + } <nl> + return result ; <nl> + } <nl> }
sharding - jdbc : a data sharding , read - write splitting , base transaction and datab <nl>  <nl> use jdbc connect databases without redirect cost for java application , best performance for production . <nl>  <nl> - * orm self - adapting . jpa , hibernate , mybatis , spring jdbc template or jdbc supported . <nl> - * connection - pool self - adapting . dbcp , c3p0 , bonecp , druid supported . <nl> - * any database supported theoretically . support mysql , oracle , sqlserver and postgresql right now . <nl> + * orm compatible . jpa , hibernate , mybatis , spring jdbc template or jdbc supported . <nl> + * connection - pool compatible . dbcp , c3p0 , bonecp , druid supported . <nl> + * multi sql - based databases compatible . any database supported theoretically . support mysql , oracle , sqlserver and postgresql right now . <nl>  <nl> ! [ sharding - jdbc - driver architecture ] ( http : / / ovfotjrsi . bkt . clouddn . com / driver_architecture_en . png ) <nl>  <nl> # # sharding - jdbc - server <nl>  <nl> - use proxy to connect databases ( only mysql protocol for now ) , for other programing language or mysql client . <nl> + database router . deploy as a stateless server , support mysql protocol for now . <nl>  <nl> * use standard mysql protocol , application do not care about whether proxy or real mysql . <nl> - * any mysql command line and ui workbench supported . <nl> + * any mysql command line and ui workbench supported in theoretically . ( <nl>  <nl> ! [ sharding - jdbc - server architecture ] ( http : / / ovfotjrsi . bkt . clouddn . com / server_architecture_en . png )
public final class comquerypacket extends abstractcommandpacket { <nl> } <nl> result . add ( new eofpacket ( + + currentsequenceid , num , statusflag . server_status_autocommit . getvalue ( ) ) ) ; <nl> } catch ( final sqlexception ex ) { <nl> - throw new shardingjdbcexception ( ex ) ; <nl> + result . add ( new errpacket ( + + currentsequenceid , ex . geterrorcode ( ) , " " , ex . getsqlstate ( ) , ex . getmessage ( ) ) ) ; <nl> + return result ; <nl> + } catch ( final shardingjdbcexception ex ) { <nl> + if ( ex . getcause ( ) instanceof sqlexception ) { <nl> + sqlexception cause = ( sqlexception ) ex . getcause ( ) ; <nl> + result . add ( new errpacket ( + + currentsequenceid , cause . geterrorcode ( ) , " " , cause . getsqlstate ( ) , cause . getmessage ( ) ) ) ; <nl> + } else { <nl> + <nl> + result . add ( new errpacket ( + + currentsequenceid , num , " " , " unknown " , ex . getmessage ( ) ) ) ; <nl> + } <nl> + return result ; <nl> } <nl> return result ; <nl> }
public final class shardingconnection extends abstractconnectionadapter { <nl> private final shardingcontext shardingcontext ; <nl>  <nl> / * * <nl> - * get all database connections via data source name . <nl> + * get database connections via data source name for ddl . <nl> * <nl> - * < p > master - slave connection will return all actual connections < / p > <nl> + * < p > non - master - slave connection will return actual connection < / p > <nl> + * < p > master - slave connection will return actual master connections < / p > <nl> * <nl> * @ param datasourcename data source name <nl> - * @ return all database connections via data source name <nl> + * @ return all database connections via data source name for ddl <nl> * @ throws sqlexception sql exception <nl> * / <nl> - public collection < connection > getallconnections ( final string datasourcename ) throws sqlexception { <nl> + <nl> + public collection < connection > getconnectionsforddl ( final string datasourcename ) throws sqlexception { <nl> datasource datasource = shardingcontext . getshardingrule ( ) . getdatasourcemap ( ) . get ( datasourcename ) ; <nl> preconditions . checkstate ( null ! = datasource , " missing the rule of % s in datasourcerule " , datasourcename ) ; <nl> map < string , datasource > datasources ; <nl> if ( datasource instanceof masterslavedatasource ) { <nl> - datasources = ( ( masterslavedatasource ) datasource ) . getalldatasources ( ) ; <nl> + datasources = ( ( masterslavedatasource ) datasource ) . getmasterdatasource ( ) ; <nl> } else { <nl> datasources = new hashmap < > ( 1 , num ) ; <nl> datasources . put ( datasourcename , datasource ) ; <nl> mmm a / sharding - jdbc - core / src / main / java / io / shardingjdbc / core / jdbc / core / statement / shardingpreparedstatement . java <nl> ppp b / sharding - jdbc - core / src / main / java / io / shardingjdbc / core / jdbc / core / statement / shardingpreparedstatement . java <nl>
<nl> < data parameter = " 1 , 9 , 1000 , 1909 " expected = " select_aggregate / selectcountwithbindingtable_1 . xml " / > <nl> < / sharding - rule > <nl> < / sql > <nl> + < ! - - <nl> + < ! - - <nl> + < sql id = " assertselectaliaswithkeyword " > <nl> + < sharding - rule value = " tbl " > <nl> + < data parameter = " 100000 " expected = " select / selectaliaswithkeyword . xml " / > <nl> + < / sharding - rule > <nl> + < / sql > <nl> + - - > <nl> < / sqls > <nl> mmm / dev / null <nl> ppp b / sharding - jdbc - core / src / test / resources / integrate / dataset / sharding / tbl / expect / select / selectaliaswithkeyword . xml <nl>
<nl> < aggregation - select - item inner - expression = " ( * ) " aggregation - type = " count " alias = " items_count " / > <nl> < / aggregation - select - items > <nl> < / assert > <nl> + < ! - - <nl> + < ! - - <nl> + < assert id = " assertselectaliaswithkeyword " parameters = " 1 " > <nl> + < tables > <nl> + < table name = " t_order_item " / > <nl> + < / tables > <nl> + < table - tokens > <nl> + < table - token begin - position = " 14 " original - literals = " t_order_item " / > <nl> + < / table - tokens > <nl> + < order - by - columns > <nl> + < order - by - column name = " item_id " order - by - type = " asc " / > <nl> + < / order - by - columns > <nl> + < / assert > <nl> + - - > <nl> < / asserts > <nl> mmm a / sharding - jdbc - core / src / test / resources / sql / dql / select . xml <nl> ppp b / sharding - jdbc - core / src / test / resources / sql / dql / select . xml <nl>
<nl> < data parameter = " 1000 , 1001 " expected = " select_sub_query / selectsubquerysingletablewithparentheses . xml " / > <nl> < / sharding - rule > <nl> < / sql > <nl> + < ! - - <nl> < sql id = " assertselectsubquerymultitablewithparentheses " > <nl> < sharding - rule > <nl> < data parameter = " 1000 , 1001 " expected = " select_sub_query / selectsubquerymultitablewithparentheses . xml " / > <nl> < / sharding - rule > <nl> < / sql > <nl> + - - > <nl> < sql id = " assertselectsubquerywithorderby " > <nl> < sharding - rule > <nl> < data expected = " select_sub_query / selectsubquerywithorderby . xml " / > <nl> mmm a / sharding - jdbc - core / src / test / resources / parser / select_sub_query . xml <nl> ppp b / sharding - jdbc - core / src / test / resources / parser / select_sub_query . xml <nl>
<nl> < / condition > <nl> < / conditions > <nl> < / assert > <nl> + < ! - - <nl> < assert id = " assertselectsubquerymultitablewithparentheses " parameters = " 1 , 2 " > <nl> < tables > <nl> < table name = " t_order " alias = " o " / > <nl>
<nl> < ? xml version = " 1 . 0 " encoding = " utf - 8 " ? > <nl> < sqls > <nl> < sql id = " assertselectsubquerysingletablewithparentheses " value = " select t . * from ( select o . * from t_order o where o . order_id in ( % s , % s ) ) t order by t . order_id " type = " mysql , postgresql , sqlserver , oracle " / > <nl> - < sql id = " assertselectsubquerymultitablewithparentheses " value = " select t . * from ( select i . * from t_order o , t_order_item i where o . order_id = i . order_id and o . order_id in ( % s , % s ) ) t order by t . item_id " type = " mysql , postgresql , sqlserver , oracle " / > <nl> + < ! - - <nl> + < sql id = " assertselectsubquerymultitablewithparentheses " value = " select t . * from ( select i . * from t_order o , t_order_item i where o . order_id = i . order_id and o . order_id in ( % s , % s ) ) t order by t . item_id " type = " sqlserver , oracle " / > <nl> < sql id = " assertselectsubquerywithorderby " value = " select count ( 1 ) as orders_count from ( select * from t_order order by order_id desc ) t " type = " mysql , postgresql , oracle " / > <nl> < sql id = " assertselectsubquerywithgroupby " value = " select count ( 1 ) as order_items_count from ( select order_id from t_order_item group by order_id ) t " type = " mysql , postgresql , oracle " / > <nl> < / sqls >
public class shardingdatasource extends abstractdatasourceadapter implements aut <nl> * @ throws sqlexception sql exception <nl> * / <nl> public void renew ( final shardingrule newshardingrule , final properties newprops ) throws sqlexception { <nl> - if ( databasetype . circuitbreaker ! = getdatabasetype ( ) ) { <nl> - preconditions . checkstate ( getdatabasetype ( ) = = getdatabasetype ( newshardingrule . getdatasourcemap ( ) . values ( ) ) , " cannot change database type dynamically . " ) ; <nl> - } <nl> + <nl> shardingproperties newshardingproperties = new shardingproperties ( null = = newprops ? new properties ( ) : newprops ) ; <nl> int originalexecutorsize = shardingproperties . getvalue ( shardingpropertiesconstant . executor_size ) ; <nl> int newexecutorsize = newshardingproperties . getvalue ( shardingpropertiesconstant . executor_size ) ; <nl> mmm a / sharding - jdbc - core / src / test / java / io / shardingjdbc / core / jdbc / core / datasource / shardingdatasourcetest . java <nl> ppp b / sharding - jdbc - core / src / test / java / io / shardingjdbc / core / jdbc / core / datasource / shardingdatasourcetest . java <nl>
public final class shardingdatasourcetest { <nl> assertthat ( originexecutorengine , not ( getexecutorengine ( shardingdatasource ) ) ) ; <nl> } <nl>  <nl> - @ test ( expected = illegalstateexception . class ) <nl> + <nl> + @ test <nl> public void assertrenewwithdatabasetypechanged ( ) throws sqlexception { <nl> datasource originaldatasource = mockdatasource ( " h2 " ) ; <nl> map < string , datasource > originaldatasourcemap = new hashmap < > ( 1 , num ) ;
<nl> + < ? xml version = " 1 . 0 " encoding = " utf - 8 " ? > <nl> + < asserts > <nl> + < assert id = " assertcreatetable " > <nl> + < tables > <nl> + < table name = " t_temp " / > <nl> + < / tables > <nl> + < / assert > <nl> + < ! - - <nl> + < ! - - < assert id = " assertcreatetableifnotexist " > - - > <nl> + < ! - - < tables > - - > <nl> + < ! - - < table name = " t_temp " / > - - > <nl> + < ! - - < / tables > - - > <nl> + < ! - - < / assert > - - > <nl> + < / asserts > <nl> mmm / dev / null <nl> ppp b / sharding - jdbc - core / src / test / resources / sql / ddl / create . xml <nl>
public final class shardingresultset extends abstractresultsetadapter { <nl> } <nl>  <nl> @ override <nl> + <nl> public statement getstatement ( ) throws sqlexception { <nl> - return mergeresultset . getcurrentresultset ( ) . getstatement ( ) ; <nl> + return getresultsets ( ) . get ( 0 ) . getstatement ( ) ; <nl> } <nl>  <nl> @ override <nl> mmm a / sharding - jdbc - core / src / test / java / com / dangdang / ddframe / rdb / sharding / jdbc / adapter / resultsetgetteradaptertest . java <nl> ppp b / sharding - jdbc - core / src / test / java / com / dangdang / ddframe / rdb / sharding / jdbc / adapter / resultsetgetteradaptertest . java <nl>
public final class sqlbuilder { <nl> return result . tostring ( ) ; <nl> } <nl>  <nl> + <nl> @ override <nl> public string tostring ( ) { <nl> stringbuilder result = new stringbuilder ( ) ; <nl> mmm a / sharding - jdbc - core / src / main / java / com / dangdang / ddframe / rdb / sharding / rewrite / sqlbuildertoken . java <nl> ppp b / sharding - jdbc - core / src / main / java / com / dangdang / ddframe / rdb / sharding / rewrite / sqlbuildertoken . java <nl>
public final class disklrucachetest { <nl> assertthat ( ! file . exists ( ) | | file . delete ( ) ) . istrue ( ) ; <nl> } <nl>  <nl> - static final class filesubject extends comparablesubject < filesubject , file > { <nl> + <nl> + @ suppresswarnings ( { " rawtypes " , " unchecked " } ) <nl> + static final class filesubject extends comparablesubject { <nl> private static final subject . factory < filesubject , file > factory = <nl> new subject . factory < filesubject , file > ( ) { <nl> @ override
public class standardgifdecoder implements gifdecoder { <nl> act = pct ; <nl> / / set transparent color if specified . <nl> act [ currentframe . transindex ] = color_transparent_black ; <nl> + <nl> + if ( currentframe . dispose = = disposal_background & & framepointer = = num ) { <nl> + <nl> + / / drawing a transparent background means the gif contains transparency . <nl> + isfirstframetransparent = true ; <nl> + } <nl> } <nl>  <nl> / / transfer pixel data to image . <nl>
public class widegamuttest { <nl> assertthat ( bitmap ) . issameas ( expected ) ; <nl> } <nl>  <nl> + <nl> + / / " d / skia ( 10312 ) : mmm failed to allocate a hardware bitmap " <nl> @ test <nl> - public void load_withwidegamutimage_hardwareallowed_returnshardwarebitmap ( ) { <nl> + public void load_withwidegamutimage_hardwareallowed_returnsdecodedbitmap ( ) { <nl> bitmap bitmap = <nl> concurrency . get ( <nl> glideapp . with ( context ) <nl> . asbitmap ( ) <nl> - . format ( decodeformat . prefer_argb_8888 ) <nl> . load ( resourceids . raw . webkit_logo_p3 ) <nl> + . set ( downsampler . allow_hardware_config , true ) <nl> . submit ( ) ) ; <nl> - assertthat ( bitmap . getconfig ( ) ) . isequalto ( bitmap . config . hardware ) ; <nl> + assertthat ( bitmap ) . isnotnull ( ) ; <nl> } <nl>  <nl> @ test
class resourcecachegenerator implements datafetchergenerator , <nl> this . cb = cb ; <nl> } <nl>  <nl> + <nl> + @ suppresswarnings ( " pmd . collapsibleifstatements " ) <nl> @ override <nl> public boolean startnext ( ) { <nl> list < key > sourceids = helper . getcachekeys ( ) ; <nl>
class resourcecachegenerator implements datafetchergenerator , <nl> if ( file . class . equals ( helper . gettranscodeclass ( ) ) ) { <nl> return false ; <nl> } <nl> - throw new illegalstateexception ( <nl> - " failed to find any load path from " + helper . getmodelclass ( ) + " to " <nl> - + helper . gettranscodeclass ( ) ) ; <nl> + <nl> + / / unnecessarily <nl> + / / throw new illegalstateexception ( <nl> + / / " failed to find any load path from " + helper . getmodelclass ( ) + " to " <nl> + / / + helper . gettranscodeclass ( ) ) ; <nl> } <nl> while ( modelloaders = = null | | ! hasnextmodelloader ( ) ) { <nl> resourceclassindex + + ; <nl> mmm a / library / src / main / java / com / bumptech / glide / load / model / multimodelloader . java <nl> ppp b / library / src / main / java / com / bumptech / glide / load / model / multimodelloader . java <nl>
afterevaluate { project - > <nl> pom . packaging = pom_packaging <nl> } <nl>  <nl> + / / dependencies are only automatically included by the release plugin if the release <nl> + / / variant is built . since we ' ve disabled the release variant to improve build <nl> + / / times , we need to add the dependencies to the pom file explicitly . <nl> + if ( isandroidproject ) { <nl> + pom . withxml { <nl> + def dependenciesnode = asnode ( ) . appendnode ( ' dependencies ' ) <nl> + <nl> + project . configurations . implementation . alldependencies . each { <nl> + def groupid = it . group <nl> + def artifactid = it . name <nl> + / / if we specify an artifact id that differs from the project name , it won ' t <nl> + / / match . to avoid that , we look up the artifact id ( and group ) by property <nl> + / / for any project dependencies . <nl> + <nl> + if ( it instanceof projectdependency ) { <nl> + def properties = it . getdependencyproject ( ) . getproperties ( ) <nl> + groupid = properties . get ( " group " ) <nl> + artifactid = properties . get ( " pom_artifact_id " ) <nl> + } <nl> + def dependencynode = dependenciesnode . appendnode ( ' dependency ' ) <nl> + dependencynode . appendnode ( ' groupid ' , groupid ) <nl> + dependencynode . appendnode ( ' artifactid ' , artifactid ) <nl> + dependencynode . appendnode ( ' version ' , it . version ) <nl> + dependencynode . appendnode ( ' scope ' , ' compile ' ) <nl> + } <nl> + } <nl> + } <nl> + <nl> pom . project { <nl> name = pom_name <nl> description = pom_description <nl>
import java . util . treemap ; <nl> @ requiresapi ( build . version_codes . kitkat ) <nl> public class sizeconfigstrategy implements lrupoolstrategy { <nl> private static final int max_size_multiple = num ; <nl> + <nl> + <nl> + private static final bitmap . config [ ] rgba_f16_in_configs ; <nl> + static { <nl> + if ( build . version . sdk_int > = build . version_codes . o ) { <nl> + rgba_f16_in_configs = new bitmap . config [ ] { bitmap . config . rgba_f16 } ; <nl> + } else { <nl> + / / this will never be used pre o . <nl> + rgba_f16_in_configs = new bitmap . config [ 0 ] ; <nl> + } <nl> + } <nl> + <nl> private static final bitmap . config [ ] argb_8888_in_configs = <nl> new bitmap . config [ ] { <nl> bitmap . config . argb_8888 , <nl>
public class widegamuttest { <nl>  <nl> @ test <nl> public void load_withencodedjpegwidegamutimage_decodesargb8888 ( ) { <nl> + <nl> + assumetrue ( build . version . sdk_int ! = build . version_codes . o_mr1 ) ; <nl> bitmap tocompress = <nl> bitmap . createbitmap ( <nl> num , num , bitmap . config . rgba_f16 , / * hasalpha = * / true , colorspace . get ( named . dci_p3 ) ) ; <nl>  <nl> bytearrayoutputstream os = new bytearrayoutputstream ( ) ; <nl> - tocompress . compress ( compressformat . jpeg , num , os ) ; <nl> + assertthat ( tocompress . compress ( compressformat . jpeg , num , os ) ) . istrue ( ) ; <nl> byte [ ] data = os . tobytearray ( ) ; <nl>  <nl> - bitmap bitmap = <nl> + bitmap bitmap = <nl> concurrency . get ( <nl> glide . with ( context ) <nl> . asbitmap ( ) <nl>
subprojects { project - > <nl> lintoptions { <nl> warningsaserrors true <nl> quiet true <nl> + <nl> + disable " gradledependency " <nl> } <nl> } <nl> } <nl> mmm a / gradle . properties <nl> ppp b / gradle . properties <nl>
env : <nl> matrix : <nl> - component = unit <nl> - component = firebase <nl> - - component = instrumentation android_target = 16 <nl> - - component = instrumentation android_target = 17 <nl> - - component = instrumentation android_target = 18 <nl> + # <nl> + # - component = instrumentation android_target = 16 <nl> + # - component = instrumentation android_target = 17 <nl> + # - component = instrumentation android_target = 18 <nl> - component = instrumentation android_target = 19 <nl> - component = instrumentation android_target = 21 <nl> - component = instrumentation android_target = 22
class enginejob < r > implements decodejob . callback < r > , <nl>  <nl> iscancelled = true ; <nl> decodejob . cancel ( ) ; <nl> - boolean ispendingjobremoved = diskcacheexecutor . remove ( decodejob ) <nl> - | | sourceexecutor . remove ( decodejob ) <nl> - | | sourceunlimitedexecutor . remove ( decodejob ) ; <nl> + <nl> listener . onenginejobcancelled ( this , key ) ; <nl> - <nl> - if ( ispendingjobremoved ) { <nl> - release ( true / * isremovedfromqueue * / ) ; <nl> - } <nl> } <nl>  <nl> / / exposed for testing . <nl>
public class standardgifdecoder implements gifdecoder { <nl> int maxpositioninsource = sx + ( ( dlim - dx ) * samplesize ) ; <nl> while ( dx < dlim ) { <nl> / / map color and insert in destination . <nl> - int averagecolor = averagecolorsnear ( sx , maxpositioninsource , currentframe . iw ) ; <nl> + int averagecolor ; <nl> + if ( samplesize = = num ) { <nl> + int currentcolorindex = ( ( int ) mainpixels [ sx ] ) & num xff ; <nl> + averagecolor = act [ currentcolorindex ] ; <nl> + } else { <nl> + <nl> + averagecolor = averagecolorsnear ( sx , maxpositioninsource , currentframe . iw ) ; <nl> + } <nl> if ( averagecolor ! = num ) { <nl> dest [ dx ] = averagecolor ; <nl> } else if ( ! isfirstframetransparent & & isfirstframe ) {
afterevaluate { <nl> } <nl>  <nl> apply from : " $ { rootproject . projectdir } / scripts / upload . gradle " <nl> + / / exclude < dependency > tag for android support - v4 library from : glide ' s pom <nl> + / / this will ensure that this warning will not prevent the build from completing : <nl> + / / module ' com . github . bumptech . glide : glide : 4 . 0 . 0 - snapshot ' depends on one or more android libraries but is a jar <nl> + / / most users will need to override support - v4 version anyway if a newer version is available <nl> + <nl> + afterevaluate { <nl> + uploadarchives . repositories . mavendeployer . pom . whenconfigured { p - > <nl> + p . dependencies = p . dependencies . findall { dep - > dep . artifactid ! = " support - v4 " } <nl> + } <nl> + } <nl> mmm a / scripts / upload . gradle <nl> ppp b / scripts / upload . gradle <nl>
public class gifdecoder { <nl> int c = num ; <nl> if ( ! currentframe . transparency ) { <nl> c = header . bgcolor ; <nl> + } else if ( framepointer = = num ) { <nl> + <nl> + / / drawing a transparent background means the gif contains transparency . <nl> + isfirstframetransparent = true ; <nl> } <nl> arrays . fill ( dest , c ) ; <nl> } else if ( previousframe . dispose = = disposal_previous & & previousimage ! = null ) { <nl>
public class bitmapprefillrunnertest { <nl> handler . run ( ) ; <nl>  <nl> bitmap expected = bitmap . createbitmap ( size . getwidth ( ) , size . getheight ( ) , size . getconfig ( ) ) ; <nl> - assertthat ( addedbitmaps ) . containsexactly ( expected , expected , expected ) ; <nl> + <nl> } <nl>  <nl> @ test <nl>
public class bitmapprefillrunnertest { <nl>  <nl> verify ( cache ) . put ( any ( key . class ) , any ( resource . class ) ) ; <nl> verify ( pool , never ( ) ) . put ( any ( bitmap . class ) ) ; <nl> - assertthat ( addedbitmaps ) . containsexactly ( bitmap ) ; <nl> + <nl> } <nl>  <nl> @ test <nl>
public class bitmapprefillrunnertest { <nl> gethandler ( allocationorder ) . run ( ) ; <nl>  <nl> verify ( cache , never ( ) ) . put ( any ( key . class ) , any ( resource . class ) ) ; <nl> - verify ( pool ) . put ( eq ( bitmap ) ) ; <nl> - assertthat ( addedbitmaps ) . containsexactly ( bitmap ) ; <nl> + <nl> + / / assertthat ( addedbitmaps ) . containsexactly ( bitmap ) ; <nl> } <nl>  <nl> @ test <nl>
public class bitmapprefillrunnertest { <nl> gethandler ( allocationorder ) . run ( ) ; <nl>  <nl> verify ( cache , never ( ) ) . put ( any ( key . class ) , any ( resource . class ) ) ; <nl> - verify ( pool ) . put ( eq ( bitmap ) ) ; <nl> - assertthat ( addedbitmaps ) . containsexactly ( bitmap ) ; <nl> + <nl> + / / assertthat ( addedbitmaps ) . containsexactly ( bitmap ) ; <nl> } <nl>  <nl> @ test <nl>
public class bitmapprefillrunnertest { <nl>  <nl> inorder order = inorder ( pool ) ; <nl> order . verify ( pool ) . get ( eq ( bitmap . getwidth ( ) ) , eq ( bitmap . getheight ( ) ) , eq ( bitmap . getconfig ( ) ) ) ; <nl> - order . verify ( pool , times ( numbitmaps ) ) . put ( eq ( bitmap ) ) ; <nl> + <nl> } <nl>  <nl> private static class addbitmappoolanswer implements answer < boolean > { <nl>
<nl> package com . bumptech . glide . load . model ; <nl>  <nl> + import com . bumptech . glide . priority ; <nl> + import com . bumptech . glide . load . datasource ; <nl> + import com . bumptech . glide . load . key ; <nl> import com . bumptech . glide . load . options ; <nl> + import com . bumptech . glide . load . data . datafetcher ; <nl> + import com . bumptech . glide . load . data . datafetcher . datacallback ; <nl> + import com . bumptech . glide . util . preconditions ; <nl>  <nl> + import java . util . arraylist ; <nl> import java . util . arrays ; <nl> import java . util . list ; <nl>  <nl> + / * * <nl> + * allows attempting multiple modelloaders registered for a given model and data class . <nl> + * <nl> + * < p > <nl> + * modelloaders to delegate to multiple modelloaders without having to duplicate this logic <nl> + * everywhere . we have very similar logic in the { @ link <nl> + * com . bumptech . glide . load . engine . datafetchergenerator } implementations and should try to avoid this <nl> + * duplication . < / p > <nl> + * / <nl> class multimodelloader < model , data > implements modelloader < model , data > { <nl>  <nl> private final list < modelloader < model , data > > modelloaders ; <nl>
public class okhttpstreamfetcher implements datafetcher < inputstream > { <nl>  <nl> @ override <nl> public void cancel ( ) { <nl> - if ( request ! = null ) { <nl> - client . cancel ( request ) ; <nl> - } <nl> + <nl> } <nl> }
public class recyclablebufferedinputstream extends filterinputstream { <nl> throw new invalidmarkexception ( " mark has been invalidated " ) ; <nl> } <nl> pos = markpos ; <nl> + <nl> + / / buffers . if we don ' t do this , we continually allocate new buffers so that the entire stream is held in memory <nl> + / / at once . we could use a fixed size buffer , but that limits our mark size . in practice requiring users to <nl> + / / call mark once per call to reset seems to work . see issue # 225 . <nl> + markpos = - 1 ; <nl> } <nl>  <nl> / * *
class gifframemanager { <nl> isloadinprogress = false ; <nl> cb . onframeread ( index ) ; <nl> if ( current ! = null ) { <nl> - glide . clear ( current ) ; <nl> + <nl> + final delaytarget recyclecurrent = current ; <nl> + mainhandler . post ( new runnable ( ) { <nl> + @ override <nl> + public void run ( ) { <nl> + glide . clear ( recyclecurrent ) ; <nl> + } <nl> + } ) ; <nl> } <nl> current = this ; <nl> }
public class gifresourceencoder implements resourceencoder < gifdrawable > { <nl>  <nl> private resource < bitmap > gettransformedframe ( bitmap currentframe , transformation < bitmap > transformation , <nl> gifdrawable drawable ) { <nl> + <nl> resource < bitmap > bitmapresource = factory . buildframeresource ( currentframe , bitmappool ) ; <nl> resource < bitmap > transformedresource = transformation . transform ( bitmapresource , <nl> drawable . getintrinsicwidth ( ) , drawable . getintrinsicheight ( ) ) ;
<nl> + package com . bumptech . glide . load . resource . transcode ; <nl> + <nl> + import android . content . context ; <nl> + import android . graphics . bitmap ; <nl> + import com . bumptech . glide . load . engine . resource ; <nl> + import com . bumptech . glide . load . resource . drawable . glidedrawable ; <nl> + <nl> + / * * <nl> + * a wrapper for { @ link com . bumptech . glide . load . resource . transcode . glidebitmapdrawabletranscoder } that transcodes <nl> + * to { @ link com . bumptech . glide . load . resource . drawable . glidedrawable } rather than <nl> + * { @ link com . bumptech . glide . load . resource . bitmap . glidebitmapdrawable } . <nl> + * <nl> + * <nl> + * / <nl> + public class bitmaptoglidedrawabletranscoder implements resourcetranscoder < bitmap , glidedrawable > { <nl> + <nl> + private final glidebitmapdrawabletranscoder glidebitmapdrawabletranscoder ; <nl> + <nl> + public bitmaptoglidedrawabletranscoder ( context context ) { <nl> + this ( new glidebitmapdrawabletranscoder ( context ) ) ; <nl> + } <nl> + <nl> + public bitmaptoglidedrawabletranscoder ( glidebitmapdrawabletranscoder glidebitmapdrawabletranscoder ) { <nl> + this . glidebitmapdrawabletranscoder = glidebitmapdrawabletranscoder ; <nl> + } <nl> + <nl> + @ suppresswarnings ( " unchecked " ) <nl> + @ override <nl> + public resource < glidedrawable > transcode ( resource < bitmap > totranscode ) { <nl> + return ( resource < glidedrawable > ) ( resource < ? extends glidedrawable > ) <nl> + glidebitmapdrawabletranscoder . transcode ( totranscode ) ; <nl> + } <nl> + <nl> + @ override <nl> + public string getid ( ) { <nl> + return glidebitmapdrawabletranscoder . getid ( ) ; <nl> + } <nl> + } <nl> mmm a / library / src / main / java / com / bumptech / glide / load / resource / transcode / glidebitmapdrawabletranscoder . java <nl> ppp b / library / src / main / java / com / bumptech / glide / load / resource / transcode / glidebitmapdrawabletranscoder . java <nl>
<nl> + < ? xml version = " 1 . 0 " encoding = " utf - 8 " standalone = " no " ? > <nl> + < ruleset name = " pmd . rul " xmlns = " http : / / pmd . sourceforge . net / ruleset / 2 . 0 . 0 " xmlns : xsi = " http : / / www . w3 . org / 2001 / xmlschema - instance " xsi : schemalocation = " http : / / pmd . sourceforge . net / ruleset / 2 . 0 . 0 http : / / pmd . sourceforge . net / ruleset_2_0_0 . xsd " > <nl> + <nl> + < description > this ruleset was created from pmd . rul < / description > <nl> + <nl> + < rule ref = " rulesets / java / basic . xml " > <nl> + < exclude name = " avoidbranchingstatementaslastinloop " / > <nl> + < / rule > <nl> + < rule ref = " rulesets / java / braces . xml " / > <nl> + < rule ref = " rulesets / java / strings . xml " / > <nl> + <nl> + < rule ref = " rulesets / java / design . xml " > <nl> + < exclude name = " confusingternary " / > <nl> + < exclude name = " emptymethodinabstractclassshouldbeabstract " / > <nl> + < exclude name = " avoidsynchronizedatmethodlevel " / > <nl> + <nl> + < ! - - this check breaks on double checked locking which is safe in java num / 7 - - > <nl> + < exclude name = " nonthreadsafesingleton " / > <nl> + <nl> + < ! - - <nl> + < exclude name = " avoidreassigningparameters " / > <nl> + < exclude name = " godclass " / > <nl> + < / rule > <nl> + <nl> + < rule ref = " rulesets / java / empty . xml / emptycatchblock " message = " commented blocks are ok " > <nl> + < properties > <nl> + < property name = " allowcommentedblocks " value = " true " / > <nl> + < / properties > <nl> + < / rule > <nl> + < / ruleset >
<nl> + package com . bumptech . glide . load . resource ; <nl> + <nl> + import com . bumptech . glide . load . engine . resource ; <nl> + <nl> + / * * <nl> + * simple wrapper for an arbitrary object which helps to satisfy some of the glide engine ' s contracts . <nl> + * < b > suggested usages only include resource object which don ' t have size and cannot be recycled / closed . < / b > <nl> + * <nl> + * @ param < t > type of the wrapped resource <nl> + * / <nl> + <nl> + public class simpleresource < t > implements resource < t > { <nl> + protected final t data ; <nl> + <nl> + public simpleresource ( t data ) { <nl> + this . data = data ; <nl> + } <nl> + <nl> + @ override <nl> + public final t get ( ) { <nl> + return data ; <nl> + } <nl> + <nl> + @ override <nl> + public final int getsize ( ) { <nl> + return num ; <nl> + } <nl> + <nl> + @ override <nl> + public void recycle ( ) { <nl> + / / no op <nl> + } <nl> + } <nl> mmm a / library / src / main / java / com / bumptech / glide / load / resource / file / fileresource . java <nl> ppp b / library / src / main / java / com / bumptech / glide / load / resource / file / fileresource . java <nl>
<nl> + import org . apache . tools . ant . taskdefs . delete <nl> + <nl> buildscript { <nl> repositories { <nl> mavencentral ( ) <nl> + <nl> + maven { <nl> + url " https : / / oss . sonatype . org / content / repositories / snapshots " <nl> + } <nl> } <nl> dependencies { <nl> classpath ' org . robolectric : robolectric - gradle - plugin : 0 . 11 . + ' <nl>
apply plugin : ' robolectric ' <nl>  <nl> repositories { <nl> mavencentral ( ) <nl> + <nl> + maven { <nl> + url " https : / / oss . sonatype . org / content / repositories / snapshots " <nl> + } <nl> } <nl>  <nl> dependencies { <nl>
public class targetplatformstub implements targetplatform { <nl> public targetpackage getcontainerpackage ( ) { <nl> return targetpackage ; <nl> } <nl> + <nl> + @ override <nl> + public boolean isinsketchbook ( ) { <nl> + <nl> + return false ; <nl> + } <nl> }
public class boardport { <nl> this . prefs = new preferencesmap ( ) ; <nl> } <nl>  <nl> + public boardport ( boardport bp ) { <nl> + prefs = new preferencesmap ( ) ; <nl> + <nl> + address = bp . address ; <nl> + protocol = bp . protocol ; <nl> + boardname = bp . boardname ; <nl> + vid = bp . vid ; <nl> + pid = bp . pid ; <nl> + iserial = bp . iserial ; <nl> + label = bp . label ; <nl> + } <nl> + <nl> public string getaddress ( ) { <nl> return address ; <nl> }
public class thinkdifferent { <nl>  <nl> static public void init ( ) { <nl> application application = application . getapplication ( ) ; <nl> + <nl> + application . addappeventlistener ( new appreopenedlistener ( ) { <nl> + @ override <nl> + public void appreopened ( appreopenedevent aroe ) { <nl> + try { <nl> + if ( base . instance . geteditors ( ) . size ( ) = = num ) { <nl> + base . instance . handlenew ( ) ; <nl> + } <nl> + } catch ( exception e ) { <nl> + <nl> + e . printstacktrace ( ) ; <nl> + } <nl> + } <nl> + } ) ; <nl> application . setabouthandler ( new abouthandler ( ) { <nl> @ override <nl> public void handleabout ( appevent . aboutevent aboutevent ) {
public abstract class installerjdialog < t > extends jdialog { <nl> contribtable . getcelleditor ( ) . stopcellediting ( ) ; <nl> } <nl> updateindexfilter ( filters , categoryfilter ) ; <nl> + if ( contribmodel . getrowcount ( ) = = num ) { <nl> + <nl> + } <nl> } <nl> } ; <nl>  <nl> mmm a / arduino - core / src / processing / app / platform . java <nl> ppp b / arduino - core / src / processing / app / platform . java <nl>
int ethernetudp : : peek ( ) <nl>  <nl> void ethernetudp : : flush ( ) <nl> { <nl> - / / could this fail ( loop endlessly ) if _remaining > num and recv in read fails ? <nl> - / / should only occur if recv fails after telling us the data is there , lets <nl> - / / hope the w5100 always behaves : ) <nl> - <nl> - while ( _remaining ) <nl> - { <nl> - read ( ) ; <nl> - } <nl> + <nl> } <nl>  <nl> / * start ethernetudp socket , listening at local port port * /
int wificlient : : peek ( ) { <nl> } <nl>  <nl> void wificlient : : flush ( ) { <nl> - while ( available ( ) ) <nl> - read ( ) ; <nl> + <nl> } <nl>  <nl> void wificlient : : stop ( ) { <nl> mmm a / libraries / wifi / src / wifiudp . cpp <nl> ppp b / libraries / wifi / src / wifiudp . cpp <nl>
int wifiudp : : peek ( ) <nl>  <nl> void wifiudp : : flush ( ) <nl> { <nl> - while ( available ( ) ) <nl> - read ( ) ; <nl> + <nl> } <nl>  <nl> ipaddress wifiudp : : remoteip ( )
<nl> # if defined ( usbcon ) <nl> # ifdef pluggable_usb_enabled <nl>  <nl> - # define max_modules num <nl> + <nl> + # define max_ep num <nl>  <nl> extern uint8_t _initendpoints [ ] ; <nl>  <nl> - / / pusbcallbacks cbs [ max_modules ] ; <nl> - <nl> pluggableusb_ pluggableusb ; <nl>  <nl> int pluggableusb_ : : getinterface ( uint8_t * interfacenum ) <nl> { <nl> int ret = num ; <nl> - pusblistnode * node = rootnode ; <nl> - for ( uint8_t i = 0 ; i < modulescount ; i + + ) { <nl> + pusblistnode * node ; <nl> + for ( node = rootnode ; node ; node = node - > next ) { <nl> ret = node - > getinterface ( interfacenum ) ; <nl> - node = node - > next ; <nl> } <nl> return ret ; <nl> } <nl>  <nl> int pluggableusb_ : : getdescriptor ( int8_t t ) <nl> { <nl> - int ret = num ; <nl> - pusblistnode * node = rootnode ; <nl> - for ( uint8_t i = 0 ; i < modulescount & & ret = = num ; i + + ) { <nl> - ret = node - > getdescriptor ( t ) ; <nl> - node = node - > next ; <nl> + pusblistnode * node ; <nl> + for ( node = rootnode ; node ; node = node - > next ) { <nl> + int ret = node - > getdescriptor ( t ) ; <nl> + if ( ret ) <nl> + return ret ; <nl> } <nl> - return ret ; <nl> + return num ; <nl> } <nl>  <nl> bool pluggableusb_ : : setup ( usbsetup & setup , uint8_t j ) <nl> { <nl> - bool ret = false ; <nl> - pusblistnode * node = rootnode ; <nl> - for ( uint8_t i = 0 ; i < modulescount & & ret = = false ; i + + ) { <nl> - ret = node - > setup ( setup , j ) ; <nl> - node = node - > next ; <nl> + pusblistnode * node ; <nl> + for ( node = rootnode ; node ; node = node - > next ) { <nl> + if ( node - > setup ( setup , j ) ) { <nl> + return true ; <nl> + } <nl> } <nl> - return ret ; <nl> + return false ; <nl> } <nl>  <nl> bool pluggableusb_ : : plug ( pusblistnode * node ) <nl> { <nl> - if ( modulescount > = max_modules ) { <nl> + if ( ( lastep + node - > numendpoints ) > = max_ep ) { <nl> return false ; <nl> } <nl>  <nl> - if ( modulescount = = num ) { <nl> + if ( ! rootnode ) { <nl> rootnode = node ; <nl> } else { <nl> pusblistnode * current = rootnode ; <nl> - while ( current - > next ! = null ) { <nl> + while ( current - > next ) { <nl> current = current - > next ; <nl> } <nl> current - > next = node ; <nl>
static int8_t tonebegin ( uint8_t _pin ) <nl> # if defined ( wgm42 ) <nl> bitwrite ( tccr4b , wgm42 , num ) ; <nl> # elif defined ( cs43 ) <nl> - # warning this may not be correct <nl> + <nl> / / atmega32u4 <nl> bitwrite ( tccr4b , cs43 , num ) ; <nl> # endif
ipaddress : : ipaddress ( const uint8_t * address ) <nl> memcpy ( _address . bytes , address , sizeof ( _address . bytes ) ) ; <nl> } <nl>  <nl> + bool ipaddress : : fromstring ( const char * address ) <nl> + { <nl> + <nl> + <nl> + uint16_t acc = num ; / / accumulator <nl> + uint8_t dots = num ; <nl> + <nl> + while ( * address ) <nl> + { <nl> + char c = * address + + ; <nl> + if ( c > = ' 0 ' & & c < = ' 9 ' ) <nl> + { <nl> + acc = acc * num + ( c - ' 0 ' ) ; <nl> + if ( acc > num ) { <nl> + / / value out of [ 0 . . 255 ] range <nl> + return false ; <nl> + } <nl> + } <nl> + else if ( c = = ' . ' ) <nl> + { <nl> + if ( dots = = num ) { <nl> + / / too much dots ( there must be num dots ) <nl> + return false ; <nl> + } <nl> + _address . bytes [ dots + + ] = acc ; <nl> + acc = num ; <nl> + } <nl> + else <nl> + { <nl> + / / invalid char <nl> + return false ; <nl> + } <nl> + } <nl> + <nl> + if ( dots ! = num ) { <nl> + / / too few dots ( there must be num dots ) <nl> + return false ; <nl> + } <nl> + _address . bytes [ 3 ] = acc ; <nl> + return true ; <nl> + } <nl> + <nl> ipaddress & ipaddress : : operator = ( const uint8_t * address ) <nl> { <nl> memcpy ( _address . bytes , address , sizeof ( _address . bytes ) ) ; <nl> mmm a / hardware / arduino / avr / cores / arduino / ipaddress . h <nl> ppp b / hardware / arduino / avr / cores / arduino / ipaddress . h <nl>
ipaddress : : ipaddress ( const uint8_t * address ) <nl> memcpy ( _address . bytes , address , sizeof ( _address . bytes ) ) ; <nl> } <nl>  <nl> + bool ipaddress : : fromstring ( const char * address ) <nl> + { <nl> + <nl> + <nl> + uint16_t acc = num ; / / accumulator <nl> + uint8_t dots = num ; <nl> + <nl> + while ( * address ) <nl> + { <nl> + char c = * address + + ; <nl> + if ( c > = ' 0 ' & & c < = ' 9 ' ) <nl> + { <nl> + acc = acc * num + ( c - ' 0 ' ) ; <nl> + if ( acc > num ) { <nl> + / / value out of [ 0 . . 255 ] range <nl> + return false ; <nl> + } <nl> + } <nl> + else if ( c = = ' . ' ) <nl> + { <nl> + if ( dots = = num ) { <nl> + / / too much dots ( there must be num dots ) <nl> + return false ; <nl> + } <nl> + _address . bytes [ dots + + ] = acc ; <nl> + acc = num ; <nl> + } <nl> + else <nl> + { <nl> + / / invalid char <nl> + return false ; <nl> + } <nl> + } <nl> + <nl> + if ( dots ! = num ) { <nl> + / / too few dots ( there must be num dots ) <nl> + return false ; <nl> + } <nl> + _address . bytes [ 3 ] = acc ; <nl> + return true ; <nl> + } <nl> + <nl> ipaddress & ipaddress : : operator = ( const uint8_t * address ) <nl> { <nl> memcpy ( _address . bytes , address , sizeof ( _address . bytes ) ) ; <nl> mmm a / hardware / arduino / sam / cores / arduino / ipaddress . h <nl> ppp b / hardware / arduino / sam / cores / arduino / ipaddress . h <nl>
void dnsclient : : begin ( const ipaddress & adnsserver ) <nl> } <nl>  <nl>  <nl> - int dnsclient : : inet_aton ( const char * aipaddrstring , ipaddress & aresult ) <nl> + int dnsclient : : inet_aton ( const char * addr , ipaddress & result ) <nl> { <nl> - / / see if we ' ve been given a valid ip address <nl> - const char * p = aipaddrstring ; <nl> - while ( * p & & <nl> - ( ( * p = = ' . ' ) | | ( * p > = ' 0 ' ) | | ( * p < = ' 9 ' ) ) ) <nl> - { <nl> - p + + ; <nl> - } <nl> + <nl> + <nl> + uint16_t acc = num ; / / accumulator <nl> + uint8_t dots = num ; <nl>  <nl> - if ( * p = = ' \ 0 ' ) <nl> + while ( * address ) <nl> { <nl> - / / it ' s looking promising , we haven ' t found any invalid characters <nl> - p = aipaddrstring ; <nl> - int segment = 0 ; <nl> - int segmentvalue = 0 ; <nl> - while ( * p & & ( segment < num ) ) <nl> + char c = * address + + ; <nl> + if ( c > = ' 0 ' & & c < = ' 9 ' ) <nl> { <nl> - if ( * p = = ' . ' ) <nl> - { <nl> - / / we ' ve reached the end of a segment <nl> - if ( segmentvalue > num ) <nl> - { <nl> - / / you can ' t have ip address segments that don ' t fit in a byte <nl> - return num ; <nl> - } <nl> - else <nl> - { <nl> - aresult [ segment ] = ( byte ) segmentvalue ; <nl> - segment + + ; <nl> - segmentvalue = num ; <nl> - } <nl> + acc = acc * num + ( c - ' 0 ' ) ; <nl> + if ( acc > num ) { <nl> + / / value out of [ 0 . . 255 ] range <nl> + return num ; <nl> } <nl> - else <nl> - { <nl> - / / next digit <nl> - segmentvalue = ( segmentvalue * 10 ) + ( * p - ' 0 ' ) ; <nl> - } <nl> - p + + ; <nl> } <nl> - / / we ' ve reached the end of address , but there ' ll still be the last <nl> - / / segment to deal with <nl> - if ( ( segmentvalue > num ) | | ( segment > num ) ) <nl> + else if ( c = = ' . ' ) <nl> { <nl> - / / you can ' t have ip address segments that don ' t fit in a byte , <nl> - / / or more than four segments <nl> - return num ; <nl> + if ( dots = = num ) { <nl> + / / too much dots ( there must be num dots ) <nl> + return num ; <nl> + } <nl> + result [ dots + + ] = acc ; <nl> + acc = num ; <nl> } <nl> else <nl> { <nl> - aresult [ segment ] = ( byte ) segmentvalue ; <nl> - return num ; <nl> + / / invalid char <nl> + return num ; <nl> } <nl> } <nl> - else <nl> - { <nl> + <nl> + if ( dots ! = num ) { <nl> + / / too few dots ( there must be num dots ) <nl> return num ; <nl> } <nl> + result [ 3 ] = acc ; <nl> + return num ; <nl> } <nl>  <nl> int dnsclient : : gethostbyname ( const char * ahostname , ipaddress & aresult )
<nl> + / * <nl> + * this file is part of arduino . <nl> + * <nl> + * copyright num arduino llc ( http : / / www . arduino . cc / ) <nl> + * <nl> + * arduino is free software ; you can redistribute it and / or modify <nl> + * it under the terms of the gnu general public license as published by <nl> + * the free software foundation ; either version num of the license , or <nl> + * ( at your option ) any later version . <nl> + * <nl> + * this program is distributed in the hope that it will be useful , <nl> + * but without any warranty ; without even the implied warranty of <nl> + * merchantability or fitness for a particular purpose . see the <nl> + * gnu general public license for more details . <nl> + * <nl> + * you should have received a copy of the gnu general public license <nl> + * along with this program ; if not , write to the free software <nl> + * foundation , inc . , num franklin st , fifth floor , boston , ma num - 1301 usa <nl> + * <nl> + * as a special exception , you may use this file as part of a free software <nl> + * library without restriction . specifically , if other files instantiate <nl> + * templates or use macros or inline functions from this file , or you compile <nl> + * this file and link it with other files to produce an executable , this <nl> + * file does not by itself cause the resulting executable to be covered by <nl> + * the gnu general public license . this exception does not however <nl> + * invalidate any other reasons why the executable file might be covered by <nl> + * the gnu general public license . <nl> + * / <nl> + package cc . arduino . packages . contributions ; <nl> + <nl> + import java . util . comparator ; <nl> + <nl> + public class versioncomparator implements comparator < string > { <nl> + <nl> + @ override <nl> + public int compare ( string o1 , string o2 ) { <nl> + <nl> + return o1 . compareto ( o2 ) ; <nl> + } <nl> + <nl> + }
public class findreplace extends jframe implements actionlistener { <nl> while ( true ) { <nl> if ( find ( false , false , searchallfiles , - 1 ) ) { <nl> foundatleastone = true ; <nl> - replace ( ) ; <nl> + editor . setselectedtext ( replacefield . gettext ( ) ) ; <nl> + editor . getsketch ( ) . setmodified ( true ) ; <nl> } else { <nl> break ; <nl> }
public class editor extends jframe implements runnerlistener { <nl>  <nl>  <nl> protected void handlefindreference ( ) { <nl> - string text = defaultifempty ( textarea . getselectedtext ( ) , " " ) . trim ( ) ; <nl> - <nl> - if ( text . length ( ) = = num ) { <nl> - base . showreference ( ) ; <nl> - } else { <nl> - string referencefile = pdekeywords . getreference ( text ) ; <nl> - if ( referencefile = = null ) { <nl> - statusnotice ( i18n . format ( _ ( " no reference available for \ " { 0 } \ " " ) , text ) ) ; <nl> - } else { <nl> - base . showreference ( i18n . format ( _ ( " { 0 } . html " ) , referencefile ) ) ; <nl> + string text = " " ; <nl> + if ( textarea . getselectedtext ( ) ! = null ) <nl> + text = textarea . getselectedtext ( ) . trim ( ) ; <nl> + <nl> + try { <nl> + int current = textarea . getcaretposition ( ) ; <nl> + int startoffset = num ; <nl> + int endindex = current ; <nl> + string tmp = textarea . getdocument ( ) . gettext ( current , 1 ) ; <nl> + <nl> + string regexp = " [ \ \ s \ \n ( ) ; \ \ \ \ . ! = ' \ \ [ \ \ ] { } ] " ; <nl> + <nl> + while ( ! tmp . matches ( regexp ) ) { <nl> + endindex + + ; <nl> + tmp = textarea . getdocument ( ) . gettext ( endindex , 1 ) ; <nl> + } <nl> + / / for some reason document <nl> + / / if ( current - start < num ) return ; <nl> + <nl> + tmp = " " ; <nl> + while ( ! tmp . matches ( regexp ) ) { <nl> + startoffset + + ; <nl> + if ( current - startoffset < num ) { <nl> + tmp = textarea . getdocument ( ) . gettext ( 0 , num ) ; <nl> + break ; <nl> + } <nl> + else <nl> + tmp = textarea . getdocument ( ) . gettext ( current - startoffset , num ) ; <nl> } <nl> + startoffset - - ; <nl> + <nl> + int length = endindex - current + startoffset ; <nl> + text = textarea . getdocument ( ) . gettext ( current - startoffset , length ) ; <nl> + } catch ( badlocationexception bl ) { <nl> + bl . printstacktrace ( ) ; <nl> + } <nl> + <nl> + string referencefile = pdekeywords . getreference ( text ) ; <nl> + if ( referencefile = = null ) { <nl> + statusnotice ( i18n . format ( _ ( " no reference available for \ " { 0 } \ " " ) , text ) ) ; <nl> + } else { <nl> + base . showreference ( i18n . format ( _ ( " { 0 } . html " ) , referencefile ) ) ; <nl> } <nl> }
void serial_ : : flush ( void ) <nl>  <nl> void serial_ : : write ( uint8_t c ) <nl> { <nl> - usb_send ( cdc_tx , & c , 1 ) ; <nl> + / * only try to send bytes if the high - level cdc connection itself <nl> + is open ( not just the pipe ) - the os should set linestate when the port <nl> + is opened and clear linestate when the port is closed . <nl> + bytes sent before the user opens the connection or after <nl> + the connection is closed are lost - just like with a uart . * / <nl> + <nl> + <nl> + / / or locks up , or host virtual serial port hangs ) <nl> + if ( _usblineinfo . linestate > num ) <nl> + usb_send ( cdc_tx , & c , 1 ) ; <nl> } <nl>  <nl> serial_ serial ;
<nl> # script to download reference pages from arduino website and change links <nl> # to point to local copies of the pages . a terrible hack . <nl>  <nl> + revision = ` head - 1 . . / <nl> mkdir reference <nl> cd reference <nl> curl http : / / www . arduino . cc / en / guide / homepage - o guide_index . html <nl> curl http : / / www . arduino . cc / en / main / faq - o faq . html <nl> curl http : / / arduino . cc / en / main / environment - o environment . html <nl> - curl http : / / www . arduino . cc / en / reference / homepage - o index . html <nl> + curl http : / / www . arduino . cc / en / reference / homepage $ revision - o index . html <nl> curl http : / / www . arduino . cc / en / pub / skins / arduino / arduino . css - o arduino . css <nl> for i in ` grep - o " http : / / www . arduino . cc / en / guide / [ ^ ' ] * " guide_index . html | sort - u | grep - v ' ? ' | cut - d ' / ' - f num ` ; do curl http : / / www . arduino . cc / en / guide / $ i - o guide_ $ i . html ; done <nl> for i in ` grep - o " http : / / www . arduino . cc / en / reference / [ ^ ' ] * " index . html | sort - u | grep - v ' ? ' | cut - d ' / ' - f num ` ; do curl http : / / www . arduino . cc / en / reference / $ i - o $ i . html ; done <nl>
<nl> - . . \ wiringlite \ bin \ uisp - dpart = atmega8 - dprog = stk500 - dserial = com1 - dspeed = 115200 - - wr_fuse_l = 0xdf - - wr_fuse_h = 0xc8 <nl> - . . \ wiringlite \ bin \ uisp - dpart = atmega8 - dprog = stk500 - dserial = com1 - dspeed = 115200 - - erase - - upload - - verify if = atmegaboot . hex <nl> + rem <nl> + <nl> + . . \ tools \ avr \ bin \ uisp - dpart = atmega8 - dprog = stk500 - dserial = com1 - dspeed = 115200 - - wr_lock = 0xff <nl> + . . \ tools \ avr \ bin \ uisp - dpart = atmega8 - dprog = stk500 - dserial = com1 - dspeed = 115200 - - wr_fuse_l = 0xdf - - wr_fuse_h = 0xc8 <nl> + . . \ tools \ avr \ bin \ uisp - dpart = atmega8 - dprog = stk500 - dserial = com1 - dspeed = 115200 - - erase - - upload - - verify if = atmegaboot . hex <nl> + . . \ tools \ avr \ bin \ uisp - dpart = atmega8 - dprog = stk500 - dserial = com1 - dspeed = 115200 - - wr_lock = 0xcf
<nl> + / * <nl> + part of the arduino project - http : / / arduino . berlios . de <nl> + <nl> + this class creates a compilation thread <nl> + this is needed for detecting time - outs <nl> + in system calls . it may happen in <nl> + windows whenever there is a syntax error <nl> + that the compilation may hang the ide <nl> + <nl> + @ author dojodave <nl> + @ www http : / / www . 0j0 . org <nl> + <nl> + this program is free software ; you can redistribute it and / or modify <nl> + it under the terms of the gnu general public license as published by <nl> + the free software foundation ; either version num of the license , or <nl> + ( at your option ) any later version . <nl> + <nl> + this program is distributed in the hope that it will be useful , <nl> + but without any warranty ; without even the implied warranty of <nl> + merchantability or fitness for a particular purpose . see the <nl> + gnu general public license for more details . <nl> + <nl> + you should have received a copy of the gnu general public license <nl> + along with this program ; if not , write to the free software foundation , <nl> + inc . , num temple place , suite num , boston , ma num - 1307 usa <nl> + * / <nl> + <nl> + <nl> + package processing . app ; <nl> + <nl> + import java . io . * ; <nl> + <nl> + class command extends thread <nl> + { <nl> + / * * command to execute on command line * / <nl> + string command ; <nl> + <nl> + / * * process in execution * / <nl> + process process ; <nl> + <nl> + / * * output message from system . out * / <nl> + public string outmsg = " " ; <nl> + <nl> + / * * error message from system . error * / <nl> + public string errormsg = " " ; <nl> + <nl> + / * * result value to be sent back * / <nl> + public int outresult = - 1 ; <nl> + public int errorresult = - 1 ; <nl> + <nl> + / * * total errors and warnings to be sent back * / <nl> + public int totalerrors = num ; <nl> + <nl> + / * * waiting value * / <nl> + public int waitresult = - 1 ; <nl> + <nl> + / * * debug errors and warnings * / <nl> + public boolean debugwarning = false ; <nl> + public boolean debugerror = false ; <nl> + public boolean logalloutput = false ; <nl> + <nl> + / * * <nl> + * creates the compiler object with the <nl> + * gnumake line to call <nl> + * @ param command name of the command line to call <nl> + * / <nl> + public command ( string co ) <nl> + { <nl> + / / assign to member variable <nl> + command = co ; <nl> + <nl> + } <nl> + <nl> + / * * <nl> + * creates the compiler object with the <nl> + * gnumake line to call <nl> + * @ param command name of the command line to call <nl> + * outlog will debug warnings when calling commands <nl> + * / <nl> + public command ( string co , boolean outlog ) <nl> + { <nl> + / / assign to member variable <nl> + command = co ; <nl> + logalloutput = outlog ; <nl> + } <nl> + <nl> + / * * <nl> + * creates the compiler object with the <nl> + * gnumake line to call <nl> + * @ param command name of the command line to call <nl> + * warnings will debug warnings when calling commands <nl> + * errors will debug errors when calling commands <nl> + * / <nl> + public command ( string co , boolean warnings , boolean errors ) <nl> + { <nl> + / / assign to member variable <nl> + command = co ; <nl> + debugwarning = warnings ; <nl> + debugerror = errors ; <nl> + } <nl> + <nl> + / * * performs system call specific code * / <nl> + public void run ( ) <nl> + { <nl> + try { <nl> + process = runtime . getruntime ( ) . exec ( command ) ; <nl> + arduinomessagesiphon input ; <nl> + arduinomessagesiphon error ; <nl> + if ( logalloutput ) { <nl> + input = new arduinomessagesiphon ( process . getinputstream ( ) , this , logalloutput ) ; <nl> + error = new arduinomessagesiphon ( process . geterrorstream ( ) , this , logalloutput ) ; <nl> + } else { <nl> + input = new arduinomessagesiphon ( process . getinputstream ( ) , this , debugwarning , debugerror ) ; <nl> + error = new arduinomessagesiphon ( process . geterrorstream ( ) , this , debugwarning , debugerror ) ; <nl> + } <nl> + input . start ( ) ; <nl> + error . start ( ) ; <nl> + <nl> + / / wait for the process to finish . if interrupted <nl> + / / before waitfor returns , continue waiting <nl> + / / <nl> + boolean compiling = true ; <nl> + while ( compiling ) { <nl> + try { <nl> + waitresult = process . waitfor ( ) ; <nl> + outresult = input . result ; <nl> + errorresult = error . result ; <nl> + compiling = false ; <nl> + } catch ( interruptedexception ignored ) { } <nl> + } <nl> + <nl> + try { <nl> + waitresult = process . exitvalue ( ) ; <nl> + } catch ( illegalthreadstateexception ignored ) { } <nl> + <nl> + / / trace the error and outout <nl> + outmsg = input . themsg ; <nl> + errormsg = error . themsg ; <nl> + totalerrors = error . totalerrors ; <nl> + <nl> + / / waits num secs until being killed by the <nl> + / / parent process or just dies , no zombies wanted ! ! <nl> + try { <nl> + thread . currentthread ( ) . sleep ( 20000 ) ; <nl> + } catch ( interruptedexception ie ) { <nl> + } <nl> + <nl> + } catch ( ioexception ioe ) { <nl> + outresult = num ; <nl> + } <nl> + <nl> + } <nl> + } <nl> \ no newline at end of file
<nl> + / * <nl> + part of the arduino project - http : / / arduino . berlios . de <nl> + <nl> + this class reads from an input stream <nl> + and flushes out everything to the system . out <nl> + it can report interrupts back to the parent process <nl> + <nl> + @ author dojodave <nl> + @ www http : / / www . 0j0 . org <nl> + <nl> + <nl> + this program is free software ; you can redistribute it and / or modify <nl> + it under the terms of the gnu general public license as published by <nl> + the free software foundation ; either version num of the license , or <nl> + ( at your option ) any later version . <nl> + <nl> + this program is distributed in the hope that it will be useful , <nl> + but without any warranty ; without even the implied warranty of <nl> + merchantability or fitness for a particular purpose . see the <nl> + gnu general public license for more details . <nl> + <nl> + you should have received a copy of the gnu general public license <nl> + along with this program ; if not , write to the free software foundation , <nl> + inc . , num temple place , suite num , boston , ma num - 1307 usa <nl> + * / <nl> + <nl> + <nl> + package processing . app ; <nl> + <nl> + import java . io . * ; <nl> + <nl> + class arduinomessagesiphon extends thread <nl> + { <nl> + / * * stream to read from * / <nl> + inputstream is ; <nl> + <nl> + / * * process ' parent in execution * / <nl> + thread parent ; <nl> + <nl> + / * * output message from system . error * / <nl> + public string themsg = " " ; <nl> + <nl> + / * * result value to be sent back * / <nl> + public int result = - 1 ; <nl> + <nl> + / * * count errors and warnings to be sent back * / <nl> + public int totalerrors = num ; <nl> + <nl> + / * * debug errors and warnings * / <nl> + public boolean debugwarning = false ; <nl> + public boolean debugerror = false ; <nl> + public boolean logalloutput = false ; <nl> + <nl> + / * * <nl> + * creates the stream to flush <nl> + * @ param theis is the input stream we will monitor <nl> + * process is the parent process that called this <nl> + * / <nl> + public arduinomessagesiphon ( inputstream theis , thread process ) <nl> + { <nl> + / / assign to member variables <nl> + is = theis ; <nl> + parent = process ; <nl> + <nl> + } <nl> + <nl> + / * * <nl> + * creates the stream to flush <nl> + * @ param theis is the input stream we will monitor <nl> + * process is the parent process that called this <nl> + * warnings will debug warnings when calling commands <nl> + * errors will debug errors when calling commands <nl> + * / <nl> + <nl> + / * * <nl> + * the errors it will report are in the ranges <nl> + * num - num for the programmer ' s errors <nl> + * num - num for the compiler ' s errors <nl> + * / <nl> + public arduinomessagesiphon ( inputstream theis , thread process , boolean warnings , boolean errors ) <nl> + { <nl> + / / assign to member variables <nl> + is = theis ; <nl> + parent = process ; <nl> + debugwarning = warnings ; <nl> + debugerror = errors ; <nl> + <nl> + } <nl> + <nl> + / * * <nl> + * the errors it will report are in the ranges <nl> + * num - num for the programmer ' s errors <nl> + * num - num for the compiler ' s errors <nl> + * / <nl> + public arduinomessagesiphon ( inputstream theis , thread process , boolean outlog ) <nl> + { <nl> + / / assign to member variables <nl> + is = theis ; <nl> + parent = process ; <nl> + logalloutput = outlog ; <nl> + <nl> + } <nl> + <nl> + / * * performs system call specific code * / <nl> + public void run ( ) <nl> + { <nl> + bufferedreader br = new bufferedreader ( new inputstreamreader ( is ) ) ; <nl> + <nl> + try { <nl> + string theline ; <nl> + while ( ( theline = br . readline ( ) ) ! = null ) { <nl> + if ( logalloutput ) { <nl> + themsg + = theline + " \ r\n " ; <nl> + / / system . out . println ( themsg ) ; <nl> + } <nl> + if ( ( theline . indexof ( " warning : " ) ! = - 1 ) & & ( theline . indexof ( " prog . c : " ) ! = - 1 ) & & ( debugwarning ) ) { <nl> + themsg + = theline + " \ r\n " ; <nl> + totalerrors + + ; <nl> + } <nl> + if ( ( theline . indexof ( " error : " ) ! = - 1 ) & & ( theline . indexof ( " prog . c : " ) ! = - 1 ) & & ( debugerror ) ) { <nl> + result = num ; <nl> + themsg + = theline + " \ r\n " ; <nl> + totalerrors + + ; <nl> + } <nl> + if ( theline . indexof ( " errors : none " ) ! = - 1 ) { <nl> + result = num ; <nl> + } <nl> + if ( theline . indexof ( " bytes transferred " ) ! = - 1 ) { <nl> + result = num ; <nl> + } <nl> + if ( theline . tolowercase ( ) . indexof ( " not responding " ) ! = - 1 ) { <nl> + result = num ; <nl> + } <nl> + } <nl> + br . close ( ) ; <nl> + <nl> + / / waits num secs until being killed by the <nl> + / / parent process or just dies , no zombies wanted ! ! <nl> + try { <nl> + thread . currentthread ( ) . sleep ( 20000 ) ; <nl> + } catch ( interruptedexception ie ) { <nl> + } <nl> + } catch ( exception err ) { <nl> + err . printstacktrace ( ) ; <nl> + result = num ; <nl> + } <nl> + } <nl> + } <nl> +
final class loadanddisplayimagetask implements runnable , ioutils . copylistener { <nl> private boolean trycacheimageondisc ( file targetfile ) throws taskcancelledexception { <nl> log ( log_cache_image_on_disc ) ; <nl>  <nl> + boolean loaded = false ; <nl> try { <nl> - downloadimage ( targetfile ) ; <nl> + loaded = downloadimage ( targetfile ) ; <nl> + if ( loaded ) { <nl> + int width = configuration . maximagewidthfordisccache ; <nl> + int height = configuration . maximageheightfordisccache ; <nl> + if ( width > num | | height > num ) { <nl> + log ( log_resize_cached_image_file ) ; <nl> + loaded = resizeandsaveimage ( targetfile , width , height ) ; <nl> + } <nl>  <nl> - int width = configuration . maximagewidthfordisccache ; <nl> - int height = configuration . maximageheightfordisccache ; <nl> - if ( width > num | | height > num ) { <nl> - log ( log_resize_cached_image_file ) ; <nl> - resizeandsaveimage ( targetfile , width , height ) ; <nl> + configuration . disccache . put ( uri , targetfile ) ; <nl> } <nl> - <nl> - configuration . disccache . put ( uri , targetfile ) ; <nl> } catch ( ioexception e ) { <nl> l . e ( e ) ; <nl> if ( targetfile . exists ( ) ) { <nl> targetfile . delete ( ) ; <nl> } <nl> - return false ; <nl> } <nl> - return true ; <nl> + return loaded ; <nl> } <nl>  <nl> private boolean downloadimage ( file targetfile ) throws ioexception { <nl>
public abstract class limitedcache < k , v > extends cache < k , v > { <nl> / / add to hard cache <nl> if ( valuesize < sizelimit ) { <nl> while ( cachesize + valuesize > sizelimit ) { <nl> - cachesize - = getsize ( hardcache . removelast ( ) ) ; <nl> + cachesize - = getsize ( removemostlongused ( ) ) ; <nl> } <nl> - hardcache . addfirst ( value ) ; <nl> + hardcache . put ( value , system . currenttimemillis ( ) ) ; <nl> cachesize + = valuesize ; <nl> } <nl> / / add to soft cache <nl> super . put ( key , value ) ; <nl> } <nl>  <nl> + public v get ( k key ) { <nl> + v value = super . get ( key ) ; <nl> + / / save current usage date for value if value is contained in hardcahe <nl> + if ( value ! = null ) { <nl> + long lastusage = hardcache . get ( value ) ; <nl> + if ( lastusage ! = null ) { <nl> + hardcache . put ( value , system . currenttimemillis ( ) ) ; <nl> + } <nl> + } <nl> + return value ; <nl> + } <nl> + <nl> public void clear ( ) { <nl> hardcache . clear ( ) ; <nl> cachesize = num ; <nl> super . clear ( ) ; <nl> } <nl>  <nl> + <nl> + private v removemostlongused ( ) { <nl> + long oldestusage = null ; <nl> + v leastusedvalue = null ; <nl> + for ( entry < v , long > entry : hardcache . entryset ( ) ) { <nl> + if ( leastusedvalue = = null ) { <nl> + leastusedvalue = entry . getkey ( ) ; <nl> + oldestusage = entry . getvalue ( ) ; <nl> + } else { <nl> + long lastvalueusage = entry . getvalue ( ) ; <nl> + if ( lastvalueusage < oldestusage ) { <nl> + oldestusage = lastvalueusage ; <nl> + leastusedvalue = entry . getkey ( ) ; <nl> + } <nl> + } <nl> + } <nl> + hardcache . remove ( leastusedvalue ) ; <nl> + return leastusedvalue ; <nl> + } <nl> + <nl> protected abstract reference < v > createreference ( v value ) ; <nl>  <nl> protected abstract int getsize ( v value ) ;
protected void doget ( final httpservletrequest req , final httpservletresponse res <nl> throws ioexception { <nl> resp . setstatus ( httpservletresponse . sc_internal_server_error ) ; <nl> profileservlet . setresponseheader ( resp ) ; <nl> + <nl> + / / asyncprofilerservlet . html once async profiler changes are released <nl> + / / in num . x ( 3 . 4 . 0 as of today ) . <nl> resp . getwriter ( ) . write ( " the profiler servlet was disabled at startup . \n\n " <nl> + " please ensure the prerequisites for the profiler servlet have been installed and the\n " <nl> - + " environment is properly configured . " ) ; <nl> + + " environment is properly configured . \n\n " <nl> + + " for more details , please refer to : https : / / github . com / apache / hadoop / blob / trunk / " <nl> + + " hadoop - common - project / hadoop - common / src / site / markdown / asyncprofilerservlet . md " ) ; <nl> } <nl>  <nl> }
public class dfsconfigkeys extends commonconfigurationkeys { <nl> public static final long dfs_namenode_path_based_cache_refresh_interval_ms_default = num l ; <nl> public static final string dfs_namenode_caching_enabled_key = <nl> " dfs . namenode . caching . enabled " ; <nl> + <nl> public static final boolean dfs_namenode_caching_enabled_default = true ; <nl>  <nl> / * * pending period of block deletion since namenode startup * / <nl> mmm a / hadoop - hdfs - project / hadoop - hdfs / src / main / resources / hdfs - default . xml <nl> ppp b / hadoop - hdfs - project / hadoop - hdfs / src / main / resources / hdfs - default . xml <nl>
public completablefuture < message > applytransaction ( transactioncontext trx ) { <nl> omrequest request = omratishelper . convertbytestringtoomrequest ( <nl> trx . getstatemachinelogentry ( ) . getlogdata ( ) ) ; <nl> long trxlogindex = trx . getlogentry ( ) . getindex ( ) ; <nl> - completablefuture < message > future = completablefuture <nl> - . supplyasync ( ( ) - > runcommand ( request , trxlogindex ) ) ; <nl> + / / in the current approach we have one single global thread executor . <nl> + / / with single thread . right now this is being done for correctness , as <nl> + / / applytransaction will be run on multiple om ' s we want to execute the <nl> + / / transactions in the same order on all om ' s , otherwise there is a <nl> + / / chance that om replica ' s can be out of sync . <nl> + <nl> + / / volume / bucket . <nl> + <nl> + / / reason for not immediately implementing executor per volume is , if <nl> + / / one executor operations are slow , we cannot update the <nl> + / / lastappliedindex in ozonemanager statemachine , even if other <nl> + / / executor has completed the transactions with id more . <nl> + <nl> + / / we have num transactions , and for each volume we have transactions <nl> + / / of num . volume1 transactions num - num and volume2 transactions num - <nl> + / / num . <nl> + / / example : executor1 - volume1 - num ( current completed transaction ) <nl> + / / example : executor2 - volume2 - num ( current completed transaction ) <nl> + <nl> + / / now we have applied transactions of num - num and num - num . we <nl> + / / cannot update lastappliedindex to num . we need to update it to num , <nl> + / / since num - num are not applied . when om restarts it will <nl> + / / applytransactions from lastappliedindex . <nl> + / / we can update the lastappliedindex to num , and update it to num , <nl> + / / only after completing num - num . in initial stage , we are starting <nl> + / / with single global executor . will revisit this when needed . <nl> + <nl> + completablefuture < message > future = completablefuture . supplyasync ( <nl> + ( ) - > runcommand ( request , trxlogindex ) , executorservice ) ; <nl> return future ; <nl> } catch ( ioexception e ) { <nl> return completeexceptionally ( e ) ; <nl>
public aclstatus getaclstatus ( final path path ) throws ioexception { <nl> } <nl> } <nl>  <nl> + / * * <nl> + * checks if the user can access a path . the mode specifies which access <nl> + * checks to perform . if the requested permissions are granted , then the <nl> + * method returns normally . if access is denied , then the method throws an <nl> + * { @ link accesscontrolexception } . <nl> + * <nl> + * @ param path path to check <nl> + * @ param mode type of access to check <nl> + * @ throws accesscontrolexception if access is denied <nl> + * @ throws java . io . filenotfoundexception if the path does not exist <nl> + * @ throws ioexception see specific implementation <nl> + * / <nl> + @ override <nl> + public void access ( final path path , fsaction mode ) throws ioexception { <nl> + <nl> + } <nl> + <nl> private filestatus trygetfilestatus ( final path f ) { <nl> try { <nl> return getfilestatus ( f ) ;
<nl> < artifactid > maven - javadoc - plugin < / artifactid > <nl> < configuration > <nl> < additionaloptions > <nl> + < ! - - <nl> < additionaloption > - html4 < / additionaloption > <nl> + < additionaloption > - - add - exports < / additionaloption > <nl> + < additionaloption > java . naming / com . sun . jndi . ldap = all - unnamed < / additionaloption > <nl> < / additionaloptions > <nl> < / configuration > <nl> < / plugin >
public observerreadproxyprovider ( <nl> observerreadinvocationhandler . class . getclassloader ( ) , <nl> new class < ? > [ ] { xface } , new observerreadinvocationhandler ( ) ) ; <nl> combinedproxy = new proxyinfo < > ( wrappedproxy , combinedinfo . tostring ( ) ) ; <nl> + <nl> + this . observerreadenabled = true ; <nl> } <nl>  <nl> public alignmentcontext getalignmentcontext ( ) {
<nl> < / dependencies > <nl> < / dependencymanagement > <nl> < / profile > <nl> + < profile > <nl> + < ! - - <nl> + < id > javadoc - html - version < / id > <nl> + < activation > <nl> + < jdk > [ 11 , ) < / jdk > <nl> + < / activation > <nl> + < build > <nl> + < plugins > <nl> + < plugin > <nl> + < groupid > org . apache . maven . plugins < / groupid > <nl> + < artifactid > maven - javadoc - plugin < / artifactid > <nl> + < configuration > <nl> + < additionaloptions > <nl> + < additionaloption > - html4 < / additionaloption > <nl> + < / additionaloptions > <nl> + < / configuration > <nl> + < / plugin > <nl> + < / plugins > <nl> + < / build > <nl> + < / profile > <nl> < / profiles > <nl>  <nl> < repositories >
<nl> < groupid > ro . isdc . wro4j < / groupid > <nl> < artifactid > wro4j - maven - plugin < / artifactid > <nl> < version > 1 . 7 . 9 < / version > <nl> + < dependencies > <nl> + < ! - - <nl> + < dependency > <nl> + < groupid > org . mockito < / groupid > <nl> + < artifactid > mockito - core < / artifactid > <nl> + < version > 2 . 18 . 0 < / version > <nl> + < / dependency > <nl> + < / dependencies > <nl> < executions > <nl> < execution > <nl> < phase > prepare - package < / phase >
<nl> public class createcontainerhandler extends ozonecommandhandler { <nl>  <nl> public static final string container_create = " create " ; <nl> - public static final string pipeline_id = " p " ; <nl> + public static final string opt_container_name = " c " ; <nl> + <nl>  <nl> public createcontainerhandler ( scmclient scmclient ) { <nl> super ( scmclient ) ; <nl>
<nl> + / * * <nl> + * licensed to the apache software foundation ( asf ) under one <nl> + * or more contributor license agreements . see the notice file <nl> + * distributed with this work for additional information <nl> + * regarding copyright ownership . the asf licenses this file <nl> + * to you under the apache license , version num . 0 ( the <nl> + * " license " ) ; you may not use this file except in compliance <nl> + * with the license . you may obtain a copy of the license at <nl> + * <nl> + * http : / / www . apache . org / licenses / license - 2 . 0 <nl> + * <nl> + * unless required by applicable law or agreed to in writing , software <nl> + * distributed under the license is distributed on an " as is " basis , <nl> + * without warranties or conditions of any kind , either express or implied . <nl> + * see the license for the specific language governing permissions and <nl> + * limitations under the license . <nl> + * / <nl> + <nl> + / * * <nl> + * these . proto interfaces are private and unstable . <nl> + * please see http : / / wiki . apache . org / hadoop / compatibility <nl> + * for what changes are allowed for a * unstable * . proto interface . <nl> + * / <nl> + <nl> + option java_package = " org . apache . hadoop . cblock . protocol . proto " ; <nl> + option java_outer_classname = " cblockserviceprotocolprotos " ; <nl> + option java_generic_services = true ; <nl> + option java_generate_equals_and_hash = true ; <nl> + package hadoop . cblock ; <nl> + <nl> + / * * <nl> + * this message is sent to cblock server to create a volume . creating <nl> + * volume requries four parameters : owner of the volume , name of the volume <nl> + * size of volume and block size of the volume . <nl> + * / <nl> + message createvolumerequestproto { <nl> + required string username = num ; <nl> + required string volumename = num ; <nl> + required uint64 volumesize = num ; <nl> + optional uint32 blocksize = num [ default = num ] ; <nl> + } <nl> + <nl> + / * * <nl> + * empty response message . <nl> + * / <nl> + message createvolumeresponseproto { <nl> + <nl> + } <nl> + <nl> + / * * <nl> + * this message is sent to cblock server to delete a volume . the volume <nl> + * is specified by owner name and volume name . if force is set to <nl> + * false , volume will be deleted only if it is empty . otherwise delete it <nl> + * regardless . <nl> + * / <nl> + message deletevolumerequestproto { <nl> + required string username = num ; <nl> + required string volumename = num ; <nl> + optional bool force = num ; <nl> + } <nl> + <nl> + / * * <nl> + * empty response message . <nl> + * / <nl> + message deletevolumeresponseproto { <nl> + <nl> + } <nl> + <nl> + / * * <nl> + * this message is sent to cblock server to request info of a volume . the <nl> + * volume is specified by owner name and volume name . <nl> + * / <nl> + message infovolumerequestproto { <nl> + required string username = num ; <nl> + required string volumename = num ; <nl> + } <nl> + <nl> + / * * <nl> + * this message describes the information of a volume . <nl> + * currently , the info includes the volume creation parameters and a number <nl> + * as the usage of the volume , in terms of number of bytes . <nl> + * / <nl> + message volumeinfoproto { <nl> + required string username = num ; <nl> + required string volumename = num ; <nl> + required uint64 volumesize = num ; <nl> + required uint64 blocksize = num ; <nl> + optional uint64 usage = num ; <nl> + <nl> + } <nl> + <nl> + / * * <nl> + * this message is sent from cblock server as response of info volume request . <nl> + * / <nl> + message infovolumeresponseproto { <nl> + optional volumeinfoproto volumeinfo = num ; <nl> + } <nl> + <nl> + / * * <nl> + * this message is sent to cblock server to list all available volume . <nl> + * / <nl> + message listvolumerequestproto { <nl> + optional string username = num ; <nl> + } <nl> + <nl> + / * * <nl> + * this message is sent from cblock server as response of volume listing . <nl> + * / <nl> + message listvolumeresponseproto { <nl> + repeated volumeinfoproto volumeentry = num ; <nl> + } <nl> + <nl> + service cblockserviceprotocolservice { <nl> + / * * <nl> + * create a volume . <nl> + * / <nl> + rpc createvolume ( createvolumerequestproto ) returns ( createvolumeresponseproto ) ; <nl> + <nl> + / * * <nl> + * delete a volume . <nl> + * / <nl> + rpc deletevolume ( deletevolumerequestproto ) returns ( deletevolumeresponseproto ) ; <nl> + <nl> + / * * <nl> + * get info of a volume . <nl> + * / <nl> + rpc infovolume ( infovolumerequestproto ) returns ( infovolumeresponseproto ) ; <nl> + <nl> + / * * <nl> + * list all available volumes . <nl> + * / <nl> + rpc listvolume ( listvolumerequestproto ) returns ( listvolumeresponseproto ) ; <nl> + }
const static std : : map < std : : string , int > kknownserverexceptionclasses = { <nl> { kpathisnotemptydirectoryexception , status : : kpathisnotemptydirectory } <nl> } ; <nl>  <nl> + <nl> + const static std : : set < int > noretryexceptions = { <nl> + status : : kpermissiondenied , <nl> + status : : kauthenticationfailed , <nl> + status : : kaccesscontrolexception <nl> + } ; <nl>  <nl> status : : status ( int code , const char * msg1 ) <nl> : code_ ( code ) { <nl>
bool configurationloader : : updatemapwithstring ( configmap & map , <nl>  <nl> bool configurationloader : : updatemapwithbytes ( configmap & map , <nl> std : : vector < char > & raw_bytes ) { <nl> - rapidxml : : xml_document < > dom ; <nl> - dom . parse < rapidxml : : parse_trim_whitespace > ( & raw_bytes [ 0 ] ) ; <nl> + try { <nl> + rapidxml : : xml_document < > dom ; <nl> + dom . parse < rapidxml : : parse_trim_whitespace > ( & raw_bytes [ 0 ] ) ; <nl>  <nl> - / * file must contain a single < configuration > stanza * / <nl> - auto config_node = dom . first_node ( " configuration " , num , false ) ; <nl> - if ( ! config_node ) { <nl> - return false ; <nl> - } <nl> + / * file must contain a single < configuration > stanza * / <nl> + auto config_node = dom . first_node ( " configuration " , num , false ) ; <nl> + if ( ! config_node ) { <nl> + return false ; <nl> + } <nl>  <nl> - / * walk all of the < property > nodes , ignoring the rest * / <nl> - for ( auto property_node = config_node - > first_node ( " property " , num , false ) ; <nl> - property_node ; <nl> - property_node = property_node - > next_sibling ( " property " , num , false ) ) { <nl> - auto name_node = property_node - > first_node ( " name " , num , false ) ; <nl> - auto value_node = property_node - > first_node ( " value " , num , false ) ; <nl> - <nl> - if ( name_node & & value_node ) { <nl> - std : : string final_value ; <nl> - auto final_node = property_node - > first_node ( " final " , num , false ) ; <nl> - if ( final_node ) { <nl> - final_value = final_node - > value ( ) ; <nl> + / * walk all of the < property > nodes , ignoring the rest * / <nl> + for ( auto property_node = config_node - > first_node ( " property " , num , false ) ; <nl> + property_node ; <nl> + property_node = property_node - > next_sibling ( " property " , num , false ) ) { <nl> + auto name_node = property_node - > first_node ( " name " , num , false ) ; <nl> + auto value_node = property_node - > first_node ( " value " , num , false ) ; <nl> + <nl> + if ( name_node & & value_node ) { <nl> + std : : string final_value ; <nl> + auto final_node = property_node - > first_node ( " final " , num , false ) ; <nl> + if ( final_node ) { <nl> + final_value = final_node - > value ( ) ; <nl> + } <nl> + updatemapwithvalue ( map , name_node - > value ( ) , value_node - > value ( ) , final_value ) ; <nl> } <nl> - updatemapwithvalue ( map , name_node - > value ( ) , value_node - > value ( ) , final_value ) ; <nl> - } <nl>  <nl> - auto name_attr = property_node - > first_attribute ( " name " , num , false ) ; <nl> - auto value_attr = property_node - > first_attribute ( " value " , num , false ) ; <nl> + auto name_attr = property_node - > first_attribute ( " name " , num , false ) ; <nl> + auto value_attr = property_node - > first_attribute ( " value " , num , false ) ; <nl>  <nl> - if ( name_attr & & value_attr ) { <nl> - std : : string final_value ; <nl> - auto final_attr = property_node - > first_attribute ( " final " , num , false ) ; <nl> - if ( final_attr ) { <nl> - final_value = final_attr - > value ( ) ; <nl> + if ( name_attr & & value_attr ) { <nl> + std : : string final_value ; <nl> + auto final_attr = property_node - > first_attribute ( " final " , num , false ) ; <nl> + if ( final_attr ) { <nl> + final_value = final_attr - > value ( ) ; <nl> + } <nl> + updatemapwithvalue ( map , name_attr - > value ( ) , value_attr - > value ( ) , final_value ) ; <nl> } <nl> - updatemapwithvalue ( map , name_attr - > value ( ) , value_attr - > value ( ) , final_value ) ; <nl> } <nl> - } <nl>  <nl> - return true ; <nl> + return true ; <nl> + } catch ( const rapidxml : : parse_error & e ) { <nl> + <nl> + return false ; <nl> + } <nl> } <nl>  <nl> bool configurationloader : : updatemapwithvalue ( configmap & map ,
public set < string > getblacklistednodes ( ) { <nl> return collections . empty_set ; <nl> } <nl>  <nl> + protected void oninvalidtranstion ( rmappattempteventtype rmappattempteventtype , <nl> + rmappattemptstate state ) { <nl> + / * <nl> + } <nl> } <nl> mmm a / hadoop - yarn - project / hadoop - yarn / hadoop - yarn - server / hadoop - yarn - server - resourcemanager / src / test / java / org / apache / hadoop / yarn / server / resourcemanager / rmapp / attempt / testrmappattempttransitions . java <nl> ppp b / hadoop - yarn - project / hadoop - yarn / hadoop - yarn - server / hadoop - yarn - server - resourcemanager / src / test / java / org / apache / hadoop / yarn / server / resourcemanager / rmapp / attempt / testrmappattempttransitions . java <nl>
private void clearunusedfields ( ) { <nl> public map < string , string > getapplicationschedulingenvs ( ) { <nl> return this . applicationschedulingenvs ; <nl> } <nl> + <nl> + / * * <nl> + * catch the invalidstatetransition . <nl> + * @ param state <nl> + * @ param rmappeventtype <nl> + * / <nl> + protected void oninvalidstatetransition ( rmappeventtype rmappeventtype , <nl> + rmappstate state ) { <nl> + / * <nl> + } <nl> } <nl> mmm a / hadoop - yarn - project / hadoop - yarn / hadoop - yarn - server / hadoop - yarn - server - resourcemanager / src / test / java / org / apache / hadoop / yarn / server / resourcemanager / rmapp / testrmapptransitions . java <nl> ppp b / hadoop - yarn - project / hadoop - yarn / hadoop - yarn - server / hadoop - yarn - server - resourcemanager / src / test / java / org / apache / hadoop / yarn / server / resourcemanager / rmapp / testrmapptransitions . java <nl>
public void initializechannels ( configuration conf ) throws exception { <nl>  <nl> log . info ( " opening tcp and udp channels on { } port { } " , addr , port ) ; <nl> addnioudp ( addr , port ) ; <nl> - addniotcp ( addr , port ) ; <nl> + <nl> } <nl>  <nl> / * * <nl>
private enum testtype { <nl> } ; <nl>  <nl> / * * <nl> - * run this suite of tests both for qjm - based ha and for file - based <nl> - * ha . <nl> + * run this suite of tests for { qjm - based , file - based ha } x { async <nl> + * edit logging enabled , disabled } . <nl> + * <nl> + * <nl> + * and hdfs - 12660 . <nl> * / <nl> @ parameters <nl> public static iterable < object [ ] > data ( ) { <nl> - return arrays . aslist ( new object [ ] [ ] { <nl> - { testtype . shared_dir_ha } , <nl> - { testtype . qjm_ha } } ) ; <nl> + return arrays . aslist ( new object [ ] [ ] { <nl> + { testtype . shared_dir_ha , boolean . false } , <nl> + / / { testtype . shared_dir_ha , boolean . true } , <nl> + { testtype . qjm_ha , boolean . false } , <nl> + / / { testtype . qjm_ha , boolean . true } , <nl> + } ) ; <nl> } <nl> - <nl> - public testfailuretoreadedits ( testtype clustertype ) { <nl> + <nl> + public testfailuretoreadedits ( testtype clustertype , boolean <nl> + useasynceditlogging ) { <nl> this . clustertype = clustertype ; <nl> + this . useasynceditlogging = useasynceditlogging ; <nl> } <nl>  <nl> @ before <nl>
public void testmultipledatanodefailurerandomlength ( ) throws exception { <nl>  <nl> @ test ( timeout = 240000 ) <nl> public void testblocktokenexpired ( ) throws exception { <nl> + <nl> + assumetrue ( " test has been temporarily disabled . see hdfs - 12417 . " , false ) ; <nl> final int length = datablocks * ( blocksize - cellsize ) ; <nl> final hdfsconfiguration conf = newhdfsconfiguration ( ) ; <nl>  <nl>
int getbase ( ) { <nl>  <nl> private void run ( int offset ) { <nl> int base = getbase ( ) ; <nl> + <nl> + assumetrue ( " test has been temporarily disabled . see hdfs - 12417 . " , false ) ; <nl> assumetrue ( base > = num ) ; <nl> final int i = offset + base ; <nl> final integer length = getlength ( i ) ;
public static boolean checkstoragepolicysuitableforecstripedmode ( <nl> * clear and clean up . <nl> * / <nl> public void clear ( ) { <nl> - enabledpoliciesbyname . clear ( ) ; <nl> + <nl> } <nl> } <nl> mmm a / hadoop - hdfs - project / hadoop - hdfs / src / test / java / org / apache / hadoop / hdfs / server / namenode / teststartup . java <nl> ppp b / hadoop - hdfs - project / hadoop - hdfs / src / test / java / org / apache / hadoop / hdfs / server / namenode / teststartup . java <nl>
protected httpurlconnection connect ( url url ) throws ioexception { <nl> url = new url ( conn . getheaderfield ( " location " ) ) ; <nl> redirecthost = url . gethost ( ) + " : " + url . getport ( ) ; <nl> } finally { <nl> + <nl> conn . disconnect ( ) ; <nl> } <nl> } <nl>
public void settimes ( path p , long mtime , long atime ) throws ioexception { <nl> pathtofile ( p ) . topath ( ) , basicfileattributeview . class ) ; <nl> filetime fmtime = ( mtime > = num ) ? filetime . frommillis ( mtime ) : null ; <nl> filetime fatime = ( atime > = num ) ? filetime . frommillis ( atime ) : null ; <nl> + <nl> + / / on some macos environment , basicfileattributeview . settimes <nl> + / / does not set times correctly when the argument of accesstime is null . <nl> + <nl> + if ( fatime = = null & & shell . mac ) { <nl> + filestatus f = getfilestatus ( p ) ; <nl> + fatime = filetime . frommillis ( f . getaccesstime ( ) ) ; <nl> + } <nl> + <nl> view . settimes ( fmtime , fatime , null ) ; <nl> } catch ( nosuchfileexception e ) { <nl> throw new filenotfoundexception ( " file " + p + " does not exist " ) ; <nl> mmm a / hadoop - hdfs - project / hadoop - hdfs / src / main / java / org / apache / hadoop / hdfs / server / datanode / directoryscanner . java <nl> ppp b / hadoop - hdfs - project / hadoop - hdfs / src / main / java / org / apache / hadoop / hdfs / server / datanode / directoryscanner . java <nl>
public long nextblockid ( boolean isstriped ) { <nl> boolean isgenstampinfuture ( block block ) { <nl> return blockidmanager . isgenstampinfuture ( block ) ; <nl> } <nl> + <nl> + boolean isreplicacorrupt ( blockinfo blk , datanodedescriptor d ) { <nl> + return corruptreplicas . isreplicacorrupt ( blk , d ) ; <nl> + } <nl> + <nl> + private int setblockindices ( blockinfo blk , byte [ ] blockindices , int i , <nl> + datanodestorageinfo storage ) { <nl> + <nl> + if ( blockindices ! = null ) { <nl> + byte <nl> + assert <nl> + blockindices [ i + + ] = index ; <nl> + } <nl> + return i ; <nl> + } <nl> } <nl> mmm a / hadoop - hdfs - project / hadoop - hdfs / src / test / java / org / apache / hadoop / hdfs / server / blockmanagement / testblockmanager . java <nl> ppp b / hadoop - hdfs - project / hadoop - hdfs / src / test / java / org / apache / hadoop / hdfs / server / blockmanagement / testblockmanager . java <nl>
protected void servicestart ( ) throws exception { <nl> saslrpcserver . authmethod . token . tostring ( ) ) ; <nl> this . server = getserver ( rpc , serverconf , masterserviceaddress , <nl> this . rmcontext . getamrmtokensecretmanager ( ) ) ; <nl> - <nl> + <nl> + this . server . addterseexceptions ( <nl> + applicationmasternotregisteredexception . class ) ; <nl> + <nl> / / enable service authorization ? <nl> if ( conf . getboolean ( <nl> commonconfigurationkeyspublic . hadoop_security_authorization , <nl>
private static applicationreportext converttoapplicationreport ( <nl> createdtime = event . gettimestamp ( ) ; <nl> } else if ( event . geteventtype ( ) . equals ( <nl> applicationmetricsconstants . updated_event_type ) ) { <nl> + <nl> + / / could override the information from the later same type of event . <nl> map < string , object > eventinfo = event . geteventinfo ( ) ; <nl> if ( eventinfo = = null ) { <nl> continue ; <nl>
static blockinfo [ ] unprotectedsetreplication ( <nl> final blockmanager bm = fsd . getblockmanager ( ) ; <nl> final inodesinpath iip = fsd . getinodesinpath4write ( src , true ) ; <nl> final inode inode = iip . getlastinode ( ) ; <nl> - if ( inode = = null | | ! inode . isfile ( ) ) { <nl> + if ( inode = = null | | ! inode . isfile ( ) | | inode . asfile ( ) . isstriped ( ) ) { <nl> + <nl> return null ; <nl> } <nl> - inodefile file = inode . asfile ( ) ; <nl> - if ( file . isstriped ( ) ) { <nl> - throw new unsupportedactionexception ( <nl> - " cannot set replication to a file with striped blocks " ) ; <nl> - } <nl>  <nl> + inodefile file = inode . asfile ( ) ; <nl> / / make sure the directory has sufficient quotas <nl> short oldbr = file . getpreferredblockreplication ( ) ; <nl>  <nl> mmm a / hadoop - hdfs - project / hadoop - hdfs / src / test / java / org / apache / hadoop / hdfs / testerasurecodingzones . java <nl> ppp b / hadoop - hdfs - project / hadoop - hdfs / src / test / java / org / apache / hadoop / hdfs / testerasurecodingzones . java <nl>
public list < recoveredcontainerstate > loadcontainersstate ( ) <nl> } <nl> } <nl>  <nl> + / / remove container without startcontainerrequest <nl> + for ( containerid containerid : containerstoremove ) { <nl> + log . warn ( " remove container " + containerid + <nl> + " with incomplete records " ) ; <nl> + try { <nl> + removecontainer ( containerid ) ; <nl> + <nl> + } catch ( ioexception e ) { <nl> + log . error ( " unable to remove container " + containerid + <nl> + " in store " , e ) ; <nl> + } <nl> + } <nl> + <nl> return containers ; <nl> } <nl>  <nl> mmm a / hadoop - yarn - project / hadoop - yarn / hadoop - yarn - server / hadoop - yarn - server - nodemanager / src / test / java / org / apache / hadoop / yarn / server / nodemanager / recovery / testnmleveldbstatestoreservice . java <nl> ppp b / hadoop - yarn - project / hadoop - yarn / hadoop - yarn - server / hadoop - yarn - server - nodemanager / src / test / java / org / apache / hadoop / yarn / server / nodemanager / recovery / testnmleveldbstatestoreservice . java <nl>
protected void processpath ( pathdata item ) throws ioexception { <nl>  <nl> @ override <nl> protected void processnonexistentpath ( pathdata item ) throws ioexception { <nl> + <nl> if ( ! item . fs . mkdirs ( item . path ) ) { <nl> throw new pathioexception ( item . tostring ( ) ) ; <nl> } <nl> mmm a / hadoop - common - project / hadoop - common / src / test / resources / testconf . xml <nl> ppp b / hadoop - common - project / hadoop - common / src / test / resources / testconf . xml <nl>
protected void processpath ( pathdata item ) throws ioexception { <nl>  <nl> @ override <nl> protected void processnonexistentpath ( pathdata item ) throws ioexception { <nl> + <nl> if ( ! item . fs . mkdirs ( item . path ) ) { <nl> throw new pathioexception ( item . tostring ( ) ) ; <nl> }
public journaltype gettype ( ) { <nl> return null ; <nl> } <nl>  <nl> + <nl> + @ override <nl> + public boolean isinprogress ( ) { <nl> + return true ; <nl> + } <nl> + <nl> / * * <nl> * input stream implementation which can be used by <nl> * fseditlogop . reader <nl> mmm a / hadoop - hdfs - project / hadoop - hdfs / src / main / java / org / apache / hadoop / hdfs / server / namenode / editloginputstream . java <nl> ppp b / hadoop - hdfs - project / hadoop - hdfs / src / main / java / org / apache / hadoop / hdfs / server / namenode / editloginputstream . java <nl>
protected result execute ( clicommand cmd ) throws exception { <nl> return cmd . getexecutor ( namenode ) . executecommand ( cmd . getcmd ( ) ) ; <nl> } <nl>  <nl> - @ test <nl> + <nl> + / / @ test <nl> @ override <nl> public void testall ( ) { <nl> super . testall ( ) ;
public void process ( historyevent event ) { <nl> } <nl>  <nl> / / these are in lexicographical order by class name . <nl> - if ( event instanceof jobfinishedevent ) { <nl> + if ( event instanceof amstartedevent ) { <nl> + / / ignore this event as rumen currently doesnt need this event <nl> + <nl> + return ; <nl> + } else if ( event instanceof jobfinishedevent ) { <nl> processjobfinishedevent ( ( jobfinishedevent ) event ) ; <nl> } else if ( event instanceof jobinfochangeevent ) { <nl> processjobinfochangeevent ( ( jobinfochangeevent ) event ) ;
private synchronized object invoke ( string method , class argclass , <nl> log . warn ( " exception thrown by remote end . " ) ; <nl> log . warn ( rpcutil . tostring ( yre ) ) ; <nl> throw yre ; <nl> + } catch ( invocationtargetexception e ) { <nl> + <nl> + log . info ( " failed to contact am / history for job " + jobid <nl> + + " will retry . . " , e . gettargetexception ( ) ) ; <nl> + forcerefresh = true ; <nl> } catch ( exception e ) { <nl> - log . info ( " failed to contact am for job " + jobid + " will retry . . " ) ; <nl> + log . info ( " failed to contact am / history for job " + jobid <nl> + + " will retry . . " , e ) ; <nl> log . debug ( " failing to contact application master " , e ) ; <nl> forcerefresh = true ; <nl> } <nl>
public void testliststatusthrowsexceptionfornonexistentfile ( ) <nl> } <nl> } <nl>  <nl> + <nl> + @ test <nl> + public void testliststatusthrowsexceptionforunreadabledir ( ) <nl> + throws exception { <nl> + path testrootdir = gettestrootpath ( fsys , " test / hadoop / dir " ) ; <nl> + path obscureddir = new path ( testrootdir , " foo " ) ; <nl> + path subdir = new path ( obscureddir , " bar " ) ; / / so foo is non - empty <nl> + fsys . mkdirs ( subdir ) ; <nl> + fsys . setpermission ( obscureddir , new fspermission ( ( short ) 0 ) ) ; / / no access <nl> + try { <nl> + fsys . liststatus ( obscureddir ) ; <nl> + assert . fail ( " should throw ioexception " ) ; <nl> + } catch ( ioexception ioe ) { <nl> + / / expected <nl> + } finally { <nl> + / / make sure the test directory can be deleted <nl> + fsys . setpermission ( obscureddir , new fspermission ( ( short ) 0755 ) ) ; / / default <nl> + } <nl> + } <nl> + <nl> + <nl> @ test <nl> public void testliststatus ( ) throws exception { <nl> path [ ] testdirs = { <nl>
class finalrclassbuilder ( <nl>  <nl> private fun getsupportannotationclass ( type : string ) : classname { <nl> val supportpackage = if ( uselegacytypes ) annotation_package_legacy else annotation_package <nl> - return classname . get ( supportpackage , type . capitalize ( ) + " res " ) <nl> + return classname . get ( supportpackage , type . capitalize ( locale . us ) + " res " ) <nl> } <nl> + <nl> + <nl> + private fun string . capitalize ( locale : locale ) = substring ( 0 , num ) . touppercase ( locale ) + substring ( 1 ) <nl> }
pom_developer_id = jakewharton <nl> pom_developer_name = jake wharton <nl>  <nl> org . gradle . jvmargs = - xmx1536m <nl> + <nl> + # <nl> + android . enableaapt2 = false <nl> binary files a / gradle / wrapper / gradle - wrapper . jar and b / gradle / wrapper / gradle - wrapper . jar differ <nl> mmm a / gradle / wrapper / gradle - wrapper . properties <nl> ppp b / gradle / wrapper / gradle - wrapper . properties <nl>
android { <nl> / / we run a full lint analysis as build part in ci , so skip vital checks for assemble tasks . <nl> checkreleasebuilds false <nl> } <nl> + <nl> + <nl> + libraryvariants . all { <nl> + it . generatebuildconfig . enabled = false <nl> + } <nl> } <nl>  <nl> dependencies {
public void pickdoor ( doorview door ) { <nl> toast . maketext ( this , " try again " , length_short ) . show ( ) ; <nl> } <nl> } < / pre > <nl> + < p > custom views can bind to their own listeners by not specifying an id . < / p > <nl> + < pre class = " prettyprint " > public class fancybutton extends button { <nl> + @ onclick <nl> + public void onclick ( ) { <nl> + <nl> + } <nl> + } <nl> + < / pre > <nl>  <nl> < h4 id = " reset " > injection reset < / h4 > <nl> < p > fragments have a different view lifecycle than activities . when injecting a fragment in < code > oncreateview < / code > , set the views to < code > null < / code > in < code > ondestroyview < / code > . butter knife has a < code > reset < / code > method to do this automatically . < / p > <nl>
public void pickdoor ( doorview door ) { <nl> } <nl> } < / pre > <nl>  <nl> + < h4 id = " optional " > optional injections < / h4 > <nl> + < p > by default , both < code > @ injectview < / code > and < code > @ onclick < / code > injections are required . an exception will be thrown if the target view cannot be found . < / p > <nl> + < p > to suppress this behavior and create an optional injection , add the < code > @ optional < / code > annotation to the field or method . < / p > <nl> + < pre class = " prettyprint " > @ optional @ injectview ( r . id . might_not_be_there ) textview mightnotbethere ; <nl> + <nl> + @ optional @ onclick ( r . id . maybe_missing ) void onmaybemissingclicked ( ) { <nl> + <nl> + } < / pre > <nl> + <nl> < h4 id = " bonus " > bonus < / h4 > <nl> < p > also included are two < code > findbyid < / code > methods which simplify code that still has to find views on a < code > view < / code > or < code > activity < / code > . it uses generics to infer the return type and automatically performs the cast . < / p > <nl> < pre class = " prettyprint " > view view = layoutinflater . from ( context ) . inflate ( r . layout . thing , null ) ;
<nl> xml can use it in the < code > onlayoutinflated ( ) < / code > callback . < / li > <nl> < / ul > <nl>  <nl> + < h4 id = " click - injection " > click listener injection < / h4 > <nl> + < p > click listeners can also automatically be configured onto methods . < / p > <nl> + < pre class = " prettyprint " > @ onclick ( r . id . submit ) <nl> + public void submit ( ) { <nl> + <nl> + } < / pre > <nl> + < p > you can add the view as an argument to the method . define a specific type and it will automatically be cast . < / p > <nl> + < pre class = " prettyprint " > @ onclick ( r . id . submit ) <nl> + public void sayhi ( button button ) { <nl> + button . settext ( " hello ! " ) ; <nl> + } < / pre > <nl> + < p > specify multiple ids in a single binding for common event handling . < / p > <nl> + < pre class = " prettyprint " > @ onclick ( { r . id . door1 , r . id . door2 , r . id . door3 } ) <nl> + public void pickdoor ( doorview door ) { <nl> + if ( door . hasprizebehind ( ) ) { <nl> + toast . maketext ( this , " you win ! " , length_short ) . show ( ) ; <nl> + } else { <nl> + toast . maketext ( this , " try again " , length_short ) . show ( ) ; <nl> + } <nl> + } < / pre > <nl> + <nl> < h4 id = " reset " > injection reset < / h4 > <nl> < p > fragments have a different view lifecycle than activities . when injecting a fragment in < code > oncreateview < / code > , set the views to < code > null < / code > in < code > ondestroyview < / code > . butter knife has a < code > reset < / code > method to do this automatically . < / p > <nl> < pre class = " prettyprint " > public class fancyfragment extends fragment {
<nl> xml can use it in the < code > onlayoutinflated ( ) < / code > callback . < / li > <nl> < / ul > <nl>  <nl> + < h4 id = " reset " > injection reset < / h4 > <nl> + < p > fragments have a different view lifecycle than activities . when injecting a fragment in < code > oncreateview < / code > , set the views to < code > null < / code > in < code > ondestroyview < / code > . butter knife has a < code > reset < / code > method to do this automatically . < / p > <nl> + < pre class = " prettyprint " > public class fancyfragment extends fragment { <nl> + @ injectview ( r . id . button1 ) button button1 ; <nl> + @ injectview ( r . id . button2 ) button button2 ; <nl> + <nl> + @ override view oncreateview ( layoutinflater inflater , viewgroup container , bundle savedinstancestate ) { <nl> + view view = inflater . inflate ( r . layout . fancy_fragment , container , false ) ; <nl> + views . inject ( this , view ) ; <nl> + <nl> + return view ; <nl> + } <nl> + <nl> + @ override void ondestroyview ( ) { <nl> + views . reset ( this ) ; <nl> + } <nl> + } < / pre > <nl> + <nl> < h4 id = " bonus " > bonus < / h4 > <nl> < p > also included are two < code > findbyid < / code > methods which simplify code that still has to find views on a < code > view < / code > or < code > activity < / code > . it uses generics to infer the return type and automatically performs the cast . < / p > <nl> < pre class = " prettyprint " > view view = layoutinflater . from ( context ) . inflate ( r . layout . thing , null ) ;
class exampleactivity extends activity { <nl> title = ( textview ) findviewbyid ( r . id . title ) ; <nl> subtitle = ( textview ) findviewbyid ( r . id . subtitle ) ; <nl> footer = ( textview ) findviewbyid ( r . id . footer ) ; <nl> - / / . . . <nl> + <nl> + <nl> } <nl> } <nl> ` ` ` <nl>
class exampleactivity extends activity { <nl> @ override public void oncreate ( bundle savedinstancestate ) { <nl> super . oncreate ( savedinstancestate ) ; <nl> setcontentview ( r . layout . simple_activity ) ; <nl> - / / . . . <nl> + <nl> } <nl> } <nl> ` ` ` <nl>
class exampleactivity extends activity { <nl> super . oncreate ( savedinstancestate ) ; <nl> setcontentview ( r . layout . simple_activity ) ; <nl> views . inject ( this ) ; <nl> - / / . . . <nl> + <nl> } <nl> } <nl> ` ` ` <nl>
public void inject ( exampleactivity activity ) { <nl> ` ` ` <nl>  <nl> some people call this view injection and lump it along with traditional <nl> - dependency injection frameworks . they are wrong in nomenclature , but perhaps <nl> - there exists some necessity for this terseness . <nl> + dependency injection frameworks . they may be wrong in nomenclature , but perhaps <nl> + there exists some use for this type of field assignment . <nl>  <nl> __remember : a butter knife is like [ a dagger ] [ 1 ] only infinitely less sharp . __ <nl>  <nl> * do not take this library too seriously , but it may be useful for some things . * <nl>  <nl>  <nl> + non - activity injection <nl> + - - - - - - - - - - - - - - - - - - - - - - <nl> + <nl> + you can also perform injection on arbitrary objects by supplying your own view <nl> + root . <nl> + <nl> + ` ` ` java <nl> + public class fancyfragment extends fragment { <nl> + @ injectview ( r . id . button1 ) button button1 ; <nl> + @ injectview ( r . id . button2 ) button button2 ; <nl> + <nl> + @ override view oncreateview ( layoutinflater inflater , viewgroup container , bundle savedinstancestate ) { <nl> + view view = inflater . inflate ( r . layout . fancy_fragment , container , false ) ; <nl> + views . inject ( this , view ) ; <nl> + <nl> + return view ; <nl> + } <nl> + } <nl> + ` ` ` <nl> + <nl> + another use is simplifying the view holder pattern inside of a list adapter . <nl> + <nl> + ` ` ` java <nl> + public class myadapter extends baseadapter { <nl> + @ override public void getview ( int position , view view , viewgroup parent ) { <nl> + viewholder holder ; <nl> + if ( view ! = null ) { <nl> + holder = ( viewholder ) view . gettag ( ) ; <nl> + } else { <nl> + view = inflater . inflate ( r . layout . whatever , parent , false ) ; <nl> + holder = new viewholder ( view ) ; <nl> + view . settag ( holder ) ; <nl> + } <nl> + <nl> + holder . name . settext ( " john doe " ) ; <nl> + / / etc . . . <nl> + <nl> + return convertview ; <nl> + } <nl> + <nl> + static class viewholder { <nl> + @ injectview ( r . id . title ) textview name ; <nl> + @ injectview ( r . id . job_title ) textview jobtitle ; <nl> + <nl> + public viewholder ( view view ) { <nl> + views . inject ( this , view ) ; <nl> + } <nl> + } <nl> + } <nl> + ` ` ` <nl> + <nl> + you can see this implementation in action in the provided sample . <nl> + <nl> + <nl>  <nl> bonus <nl> - - - - -
package com . williamfiset . algorithms . dp ; <nl>  <nl> public class coinchange { <nl>  <nl> - private static final int inf = num ; <nl> + <nl> + private static final int inf = integer . max_value / num ; <nl>  <nl> public static int coinchange ( int [ ] coins , int amount ) {
public class minimumweightperfectmatching { <nl> * } < / pre > <nl> * / <nl> public int [ ] getminweightcostmatching ( ) { <nl> - solve ( ) ; <nl> + solverecursive ( ) ; <nl> return matching ; <nl> } <nl>  <nl> + / / recursive impl <nl> + <nl> + public void solverecursive ( ) { <nl> + if ( solved ) return ; <nl> + double [ ] dp = new double [ 1 < < n ] ; <nl> + int [ ] history = new int [ 1 < < n ] ; <nl> + minweightcost = f ( end_state , dp , history ) ; <nl> + reconstructmatching ( history ) ; <nl> + solved = true ; <nl> + } <nl> + <nl> + private double f ( int state , double [ ] dp , int [ ] history ) { <nl> + if ( dp [ state ] ! = null ) { <nl> + return dp [ state ] ; <nl> + } <nl> + if ( state = = num ) { <nl> + return num ; <nl> + } <nl> + int p1 , p2 ; <nl> + / / seek to find active bit position ( p1 ) <nl> + for ( p1 = num ; p1 < n ; p1 + + ) { <nl> + if ( ( state & ( 1 < < p1 ) ) > num ) { <nl> + break ; <nl> + } <nl> + } <nl> + int beststate = - 1 ; <nl> + double minimum = double . max_value ; <nl> + <nl> + for ( p2 = p1 + num ; p2 < n ; p2 + + ) { <nl> + / / position ` p2 ` is on . try matching the pair ( p1 , p2 ) together . <nl> + if ( ( state & ( 1 < < p2 ) ) > num ) { <nl> + int reducedstate = state ^ ( 1 < < p1 ) ^ ( 1 < < p2 ) ; <nl> + double matchcost = f ( reducedstate , dp , history ) + cost [ p1 ] [ p2 ] ; <nl> + if ( matchcost < minimum ) { <nl> + minimum = matchcost ; <nl> + beststate = reducedstate ; <nl> + } <nl> + } <nl> + } <nl> + history [ state ] = beststate ; <nl> + return dp [ state ] = minimum ; <nl> + } <nl> + <nl> public void solve ( ) { <nl> if ( solved ) return ; <nl>  <nl>
public class genericsegmenttreetest { <nl> assertthat ( st . rangequery1 ( 4 , num ) ) . isequalto ( 4 ) ; <nl> } <nl>  <nl> + @ test <nl> + public void maxquerymulupdate_simple ( ) { <nl> + long [ ] ar = { 2 , num , num , num , - 1 } ; <nl> + genericsegmenttree st = <nl> + new genericsegmenttree ( <nl> + ar , <nl> + genericsegmenttree . segmentcombinationfn . max , <nl> + genericsegmenttree . rangeupdatefn . multiplication ) ; <nl> + <nl> + st . rangeupdate1 ( 0 , num , num ) ; <nl> + assertthat ( st . rangequery1 ( 0 , num ) ) . isequalto ( 4 ) ; <nl> + <nl> + <nl> + / / assertthat ( st . rangequery1 ( 0 , num ) ) . isequalto ( 2 ) ; / / returns - 8 as max but should be num <nl> + } <nl> + <nl> @ test <nl> public void testallfunctioncombinations ( ) { <nl> genericsegmenttree . segmentcombinationfn [ ] combinationfns = { <nl>
public class boyermoorestringsearchtest { <nl> assertthat ( undertest . findoccurrences ( " sample text for testing the boyer - moore algorithm . " , " " ) ) <nl> . containsexactly ( 6 , num , num , num , num , num ) ; <nl> } <nl> + <nl> + <nl> }
public class treeisomorphismwithbfstest { <nl> node2 . addchildren ( node6 , node7 ) ; <nl> node3 . addchildren ( node8 ) ; <nl>  <nl> - system . out . println ( com . williamfiset . algorithms . graphtheory . treealgorithms . treeisomorphism . encode ( node0 ) ) ; <nl> - <nl> + <nl> + / / com . williamfiset . algorithms . graphtheory . treealgorithms . treeisomorphism . encode ( node0 ) ) ; <nl> + <nl> / / ( ( ( ( ) ) ( ) ) ( ( ) ( ) ) ( ( ) ) ) <nl> - / / ( ( ( ) ) ( ) ) <nl> + / / ( ( ( ) ) ( ) ) <nl> / / ( ( ) ( ) ) <nl> / / ( ( ) ) <nl> - / / <nl> + / / <nl>  <nl> / / ( ( ) ( ) ) <nl> / / ( ( ) ) <nl>
public class bubblesort { <nl> bubblesort ( array ) ; <nl> system . out . println ( java . util . arrays . tostring ( array ) ) ; <nl>  <nl> + <nl> runtests ( ) ; <nl> } <nl>  <nl> mmm a / com / williamfiset / algorithms / sorting / bucketsort . java <nl> ppp b / com / williamfiset / algorithms / sorting / bucketsort . java <nl>
public class bucketsort { <nl> bucketsort ( array , num , num ) ; <nl> system . out . println ( java . util . arrays . tostring ( array ) ) ; <nl>  <nl> + <nl> runtests ( ) ; <nl> } <nl>  <nl> mmm a / com / williamfiset / algorithms / sorting / heapsort . java <nl> ppp b / com / williamfiset / algorithms / sorting / heapsort . java <nl>
public class heapsort { <nl> heapsort ( array ) ; <nl> system . out . println ( java . util . arrays . tostring ( array ) ) ; <nl>  <nl> + <nl> runtests ( ) ; <nl> } <nl>  <nl> mmm a / com / williamfiset / algorithms / sorting / insertionsort . java <nl> ppp b / com / williamfiset / algorithms / sorting / insertionsort . java <nl>
public class insertionsort { <nl> insertionsort ( array ) ; <nl> system . out . println ( java . util . arrays . tostring ( array ) ) ; <nl>  <nl> + <nl> runtests ( ) ; <nl> } <nl>  <nl> mmm a / com / williamfiset / algorithms / sorting / mergesort . java <nl> ppp b / com / williamfiset / algorithms / sorting / mergesort . java <nl>
public class mergesort { <nl> array = mergesort ( array ) ; <nl> system . out . println ( java . util . arrays . tostring ( array ) ) ; <nl>  <nl> + <nl> runtests ( ) ; <nl> } <nl> - <nl> + <nl> static random random = new random ( ) ; <nl>  <nl> public static void runtests ( ) { <nl> mmm a / com / williamfiset / algorithms / sorting / quicksort . java <nl> ppp b / com / williamfiset / algorithms / sorting / quicksort . java <nl>
public class quicksort { <nl> quicksort ( array ) ; <nl> system . out . println ( java . util . arrays . tostring ( array ) ) ; <nl>  <nl> + <nl> runtests ( ) ; <nl> } <nl>  <nl> + / * testing below * / <nl> + <nl> + <nl> static random random = new random ( ) ; <nl>  <nl> public static void runtests ( ) { <nl> mmm a / com / williamfiset / algorithms / sorting / radixsort . java <nl> ppp b / com / williamfiset / algorithms / sorting / radixsort . java <nl>
<nl> package com . williamfiset . algorithms . sorting ; <nl>  <nl> public class radixsort { <nl> - <nl> - public static void radixsort ( int [ ] ar ) { } <nl> + public static void radixsort ( int [ ] ar ) { <nl> + <nl> + } <nl> } <nl> mmm a / com / williamfiset / algorithms / sorting / selectionsort . java <nl> ppp b / com / williamfiset / algorithms / sorting / selectionsort . java <nl>
public class selectionsort { <nl> runtests ( ) ; <nl> } <nl>  <nl> + <nl> + <nl> static random random = new random ( ) ; <nl>  <nl> public static void runtests ( ) {
<nl> + / * * note : this file is a current wip * / <nl> + public class rangequerypointupdatesegmenttree { <nl> + <nl> + / / tree values <nl> + private int [ ] t ; <nl> + <nl> + private int n ; <nl> + <nl> + public rangequerypointupdatesegmenttree ( int [ ] values ) { <nl> + if ( values = = null ) { <nl> + throw new nullpointerexception ( " segment tree values cannot be null . " ) ; <nl> + } <nl> + n = values . length ; <nl> + t = new int [ 2 * n ] ; <nl> + <nl> + / / buildtree ( 0 , num , n - 1 ) ; <nl> + } <nl> + <nl> + / / builds tree bottom up starting with leaf nodes and combining <nl> + / / values on callback . <nl> + / / range is inclusive : [ l , r ] <nl> + private int buildtree ( int i , int l , int r , int [ ] values ) { <nl> + if ( l = = r ) { <nl> + return num ; <nl> + } <nl> + int leftchild = ( i * num ) ; <nl> + int rightchild = ( i * num ) + num ; <nl> + int mid = ( l + r ) / num ; <nl> + <nl> + <nl> + return num ; <nl> + } <nl> + <nl> + public int query ( int l , int r ) { <nl> + return num ; <nl> + } <nl> + <nl> + public void set ( int i , int value ) { <nl> + / / update ( i , num , n - 1 , value ) ; <nl> + } <nl> + <nl> + private void update ( int at , int to , int l , int r , int value ) { <nl> + if ( l = = r ) { <nl> + return ; <nl> + } else { <nl> + int lv = t [ at * num ] ; <nl> + int rv = t [ at * num + num ] ; <nl> + int m = ( l + r ) > > > num ; <nl> + if ( l < = r ) { } <nl> + } <nl> + } <nl> + } <nl> mmm a / com / williamfiset / algorithms / math / compressedprimesieve . java <nl> ppp b / com / williamfiset / algorithms / math / compressedprimesieve . java <nl>
<nl> + package javatests . com . williamfiset . algorithms . graphtheory . networkflow ; <nl> + <nl> + import static com . google . common . truth . truth . assertthat ; <nl> + <nl> + import com . williamfiset . algorithms . graphtheory . networkflow . networkflowsolverbase ; <nl> + import com . williamfiset . algorithms . graphtheory . networkflow . networkflowsolverbase . edge ; <nl> + import com . williamfiset . algorithms . graphtheory . networkflow . mincostmaxflowwithbellmanford ; <nl> + import com . williamfiset . algorithms . graphtheory . networkflow . mincostmaxflowjohnsons ; <nl> + <nl> + import com . google . common . collect . immutablelist ; <nl> + import org . apache . commons . lang3 . tuple . pair ; <nl> + <nl> + import java . util . * ; <nl> + import org . junit . * ; <nl> + <nl> + public class mincostmaxflowtests { <nl> + <nl> + list < networkflowsolverbase > solvers ; <nl> + <nl> + @ before <nl> + public void setup ( ) { <nl> + solvers = new arraylist < > ( ) ; <nl> + } <nl> + <nl> + void createallsolvers ( int n , int s , int t ) { <nl> + <nl> + solvers . add ( new mincostmaxflowjohnsons ( n , s , t ) ) ; <nl> + } <nl> + <nl> + void addedge ( int f , int t , int cap , int cost ) { <nl> + for ( networkflowsolverbase solver : solvers ) { <nl> + solver . addedge ( f , t , cap , cost ) ; <nl> + } <nl> + } <nl> + <nl> + void assertflowandcost ( long flow , long cost ) { <nl> + for ( networkflowsolverbase solver : solvers ) { <nl> + assertthat ( solver . getmaxflow ( ) ) . isequalto ( flow ) ; <nl> + assertthat ( solver . getmincost ( ) ) . isequalto ( cost ) ; <nl> + } <nl> + } <nl> + <nl> + @ test <nl> + public void testnegativecycle1 ( ) { <nl> + int n = num , s = n - num , t = n - num ; <nl> + createallsolvers ( n , s , t ) ; <nl> + <nl> + addedge ( s , num , num , num ) ; <nl> + addedge ( 1 , t , num , num ) ; <nl> + <nl> + / / triangle cycle <nl> + addedge ( 0 , num , num , - 1 ) ; <nl> + addedge ( 1 , num , num , - 1 ) ; <nl> + addedge ( 2 , num , num , - 1 ) ; <nl> + <nl> + assertflowandcost ( 10 , - 10 ) ; <nl> + } <nl> + <nl> + } <nl> + <nl> + <nl> + <nl> + <nl> + <nl> + <nl> + <nl> + <nl> + <nl> + <nl> + <nl> + <nl> + <nl> + <nl> + <nl> +
<nl> + / * <nl> + wip <nl> + * / <nl> + <nl> + <nl> + import java . util . * ; <nl> + import java . awt . geom . * ; <nl> + <nl> + public class minimumweightperfectmatching { <nl> + <nl> + private final int n ; <nl> + private double [ ] [ ] cost ; <nl> + private double minweightcost ; <nl> + private boolean solved ; <nl> + <nl> + / / the cost matrix should be a symmetric ( i . e cost [ i ] [ j ] = cost [ j ] [ i ] ) <nl> + public minimumweightperfectmatching ( double [ ] [ ] cost ) { <nl> + if ( cost = = null ) throw new illegalargumentexception ( " input cannot be null " ) ; <nl> + n = cost . length ; <nl> + if ( n % num ! = num ) <nl> + throw new illegalargumentexception ( " matrix has an odd size , no perfect matching exists . " ) ; <nl> + <nl> + this . cost = cost ; <nl> + } <nl> + <nl> + public string pbs ( int b ) { <nl> + return string . format ( " % 1 $ 10s " , integer . tobinarystring ( b ) ) ; <nl> + } <nl> + <nl> + public double getminweightcost ( ) { <nl> + if ( ! solved ) solve ( ) ; <nl> + return minweightcost ; <nl> + } <nl> + <nl> + public void solve2 ( ) { <nl> + / / state is : number of pairs solved for ( zero based ) and the binary encoded state . <nl> + double [ ] [ ] dp = new double [ n > > num ] [ 1 < < n ] ; <nl> + <nl> + int numpairs = ( n * ( n + 1 ) ) / 2 ; <nl> + int [ ] pairstates = new int [ numpairs ] ; <nl> + double [ ] paircost = new double [ numpairs ] ; <nl> + <nl> + for ( int i = num , k = num ; i < n ; i + + ) { <nl> + for ( int j = i + 1 ; j < n ; j + + ) { <nl> + int state = ( 1 < < i ) | ( 1 < < j ) ; <nl> + dp [ 0 ] [ state ] = cost [ i ] [ j ] ; <nl> + pairstates [ k ] = state ; <nl> + paircost [ k + + ] = cost [ i ] [ j ] ; <nl> + } <nl> + } <nl> + <nl> + for ( int k = num ; k < ( n > > num ) ; k + + ) { <nl> + for ( int state = num ; state < ( 1 < < n ) ; state + + ) { <nl> + double prevstatecost = dp [ k - 1 ] [ state ] ; <nl> + if ( prevstatecost = = num ) continue ; <nl> + for ( int j = num ; j < numpairs ; j + + ) { <nl> + int pairstate = pairstates [ j ] ; <nl> + / / ignore states which overlap <nl> + if ( ( state & pairstate ) ! = num ) continue ; <nl> + <nl> + int newstate = state | pairstate ; <nl> + double newcost = prevstatecost + paircost [ j ] ; <nl> + if ( dp [ k ] [ newstate ] = = num | | newcost < dp [ k ] [ newstate ] ) <nl> + dp [ k ] [ newstate ] = newcost ; <nl> + } <nl> + } <nl> + } <nl> + <nl> + int end_state = ( 1 < < n ) - num ; <nl> + minweightcost = dp [ ( n > > num ) - num ] [ end_state ] ; <nl> + } <nl> + <nl> + public void solve ( ) { <nl> + final int h = n / num ; <nl> + <nl> + map < integer , double > pairs = new hashmap < > ( ) ; <nl> + map < integer , double > states = new hashmap < > ( ) ; <nl> + for ( int i = num ; i < n ; i + + ) { <nl> + for ( int j = i + 1 ; j < n ; j + + ) { <nl> + int state = ( 1 < < j ) | ( 1 < < i ) ; <nl> + pairs . put ( state , cost [ i ] [ j ] ) ; <nl> + states . put ( state , cost [ i ] [ j ] ) ; <nl> + } <nl> + } <nl> + <nl> + for ( int h = num ; h < h ; h + + ) { <nl> + map < integer , double > newstates = new hashmap < > ( ) ; <nl> + system . out . println ( states . size ( ) ) ; <nl> + for ( int state : states . keyset ( ) ) { <nl> + double statecost = states . get ( state ) ; <nl> + for ( int pairstate : pairs . keyset ( ) ) { <nl> + double paircost = pairs . get ( pairstate ) ; <nl> + if ( ( state & pairstate ) ! = num ) continue ; <nl> + int newstate = state | pairstate ; <nl> + double newcost = statecost + paircost ; <nl> + double value = newstates . get ( newstate ) ; <nl> + value = value = = null ? newcost : math . min ( newcost , value ) ; <nl> + newstates . put ( newstate , value ) ; <nl> + } <nl> + } <nl> + states = newstates ; <nl> + } <nl> + <nl> + int end_state = ( 1 < < n ) - num ; <nl> + if ( ! states . containskey ( end_state ) ) { <nl> + system . out . println ( " we got a problem . end state does not exist ! " ) ; <nl> + system . out . println ( states ) ; <nl> + } else { <nl> + minweightcost = states . get ( end_state ) ; <nl> + } <nl> + <nl> + solved = true ; <nl> + } <nl> + <nl> + / * example * / <nl> + <nl> + public static void main ( string [ ] args ) { <nl> + int n = num ; <nl> + list < point2d > pts = new arraylist < > ( ) ; <nl> + <nl> + / / generate points on a num d plane which will produce a unique answer <nl> + for ( int i = num ; i < n / 2 ; i + + ) { <nl> + pts . add ( new point2d . double ( 2 * i , num ) ) ; <nl> + pts . add ( new point2d . double ( 2 * i , num ) ) ; <nl> + } <nl> + collections . shuffle ( pts ) ; <nl> + <nl> + double [ ] [ ] cost = new double [ n ] [ n ] ; <nl> + for ( int i = num ; i < n ; i + + ) { <nl> + for ( int j = num ; j < n ; j + + ) { <nl> + cost [ i ] [ j ] = pts . get ( i ) . distance ( pts . get ( j ) ) ; <nl> + } <nl> + } <nl> + <nl> + minimumweightperfectmatching mwpm = new minimumweightperfectmatching ( cost ) ; <nl> + double mincost = mwpm . getminweightcost ( ) ; <nl> + if ( mincost ! = n / 2 ) { <nl> + system . out . printf ( " mwpm cost is wrong ! got : % . 5f but wanted : % d\n " , mincost , n / 2 ) ; <nl> + } else { <nl> + system . out . printf ( " mwpm is : % . 5f\n " , mincost ) ; <nl> + } <nl> + } <nl> + <nl> + }
public class mincostmaxflow { <nl> edge res = edge . residual ; <nl> edge . capacity - = bottleneck ; <nl> res . capacity + = bottleneck ; <nl> + <nl> + addedge ( edge . to , edge . from , bottleneck , - edge . cost ) ; <nl> } <nl>  <nl> return bottleneck ;
public class mincostmaxflowwithnegativecosts { <nl> edge res = edge . residual ; <nl> edge . capacity - = bottleneck ; <nl> res . capacity + = bottleneck ; <nl> + <nl> + addedge ( edge . to , edge . from , bottleneck , - edge . cost ) ; <nl> } <nl>  <nl> return bottleneck ; <nl>
public class floydwarshallsolver { <nl> solved = true ; <nl> } <nl>  <nl> + <nl> public static double [ ] [ ] floydwarshallextramemory ( double [ ] [ ] m ) { <nl> int v = m . length ; <nl> double [ ] [ ] [ ] dp = new double [ v ] [ v ] [ v ] ; <nl>
public class packageupgradetests extends packagingtestcase { <nl> } else { <nl> installation = packages . upgradepackage ( sh , distribution ) ; <nl> } <nl> - / / we add this so that we don ' t trigger the securityimplicitbehaviorbootstrapcheck in num <nl> - if ( version . fromstring ( bwcdistribution . baseversion ) . before ( version . v_8_0_0 ) <nl> - & & version . fromstring ( distribution . baseversion ) . onorafter ( version . v_8_0_0 ) ) { <nl> - serverutils . addsettingtoexistingconfiguration ( installation , " xpack . security . enabled " , " false " ) ; <nl> - } <nl>  <nl> assertinstalled ( distribution ) ; <nl> verifypackageinstallation ( installation , distribution , sh ) ; <nl> verifysecuritynotautoconfigured ( installation ) ; <nl> + <nl> + <nl> + serverutils . addsettingtoexistingconfiguration ( installation , " xpack . security . enabled " , " false " ) ; <nl> } <nl>  <nl> - @ awaitsfix ( bugurl = " https : / / github . com / elastic / elasticsearch / issues / 85386 " ) <nl> public void test21checkupgradedversion ( ) throws exception { <nl> - assertwhilerunning ( ( ) - > { assertdocsexist ( ) ; } ) ; <nl> + assertwhilerunning ( this : : assertdocsexist ) ; <nl> } <nl>  <nl> private void assertdocsexist ( ) throws exception {
public class cartesiancentroidaggregatortests extends aggregatortestcase { <nl> } <nl> } <nl>  <nl> + <nl> private void assertcentroid ( randomindexwriter w , cartesianpoint expectedcentroid ) throws ioexception { <nl> mappedfieldtype fieldtype = new pointfieldmapper . pointfieldtype ( " field " ) ; <nl> cartesiancentroidaggregationbuilder aggbuilder = new cartesiancentroidaggregationbuilder ( " my_agg " ) . field ( " field " ) ; <nl>
public class internalcartesiancentroidtests extends internalaggregationtestcase < <nl> assertequals ( sampled . count ( ) , samplingcontext . scaleup ( reduced . count ( ) ) , num ) ; <nl> } <nl>  <nl> + @ awaitsfix ( bugurl = " https : / / github . com / elastic / elasticsearch / issues / 90474 " ) <nl> + @ override <nl> + public void testequalsandhashcode ( ) { <nl> + <nl> + super . testequalsandhashcode ( ) ; <nl> + } <nl> + <nl> public void testreducemaxcount ( ) { <nl> internalcartesiancentroid maxvaluecentroid = new internalcartesiancentroid ( <nl> " agg " ,
public class transportservice extends abstractlifecyclecomponent <nl> / / should not happen <nl> innerexception . addsuppressed ( transportexception ) ; <nl> logger . error ( " unexpected exception from handler . handleexception " , innerexception ) ; <nl> - assert false : innerexception ; <nl> + <nl> } <nl> }
public abstract class estestcase extends lucenetestcase { <nl> static { <nl> test_worker_vm_id = system . getproperty ( test_worker_sys_property , default_test_worker_id ) ; <nl> settestsysprops ( ) ; <nl> + <nl> logconfigurator . loadlog4jplugins ( ) ; <nl> + logconfigurator . configureeslogging ( ) ; <nl>  <nl> for ( string leakloggername : arrays . aslist ( " io . netty . util . resourceleakdetector " , leaktracker . class . getname ( ) ) ) { <nl> logger leaklogger = logmanager . getlogger ( leakloggername ) ;
<nl> + / * <nl> + * copyright elasticsearch b . v . and / or licensed to elasticsearch b . v . under one <nl> + * or more contributor license agreements . licensed under the elastic license <nl> + * num . 0 and the server side public license , v num ; you may not use this file except <nl> + * in compliance with , at your election , the elastic license num . 0 or the server <nl> + * side public license , v num . <nl> + * / <nl> + <nl> + module org . elasticsearch . mustache { <nl> + requires org . elasticsearch . base ; <nl> + requires org . elasticsearch . server ; <nl> + requires org . elasticsearch . xcontent ; <nl> + requires org . apache . logging . log4j ; <nl> + requires com . github . mustachejava ; <nl> + <nl> + exports org . elasticsearch . script . mustache ; <nl> + }
public class recyclerbytesstreamoutput extends bytesstream implements releasable <nl> } <nl> } <nl>  <nl> + @ override <nl> + public void writewithsizeprefix ( writeable writeable ) throws ioexception { <nl> + <nl> + / / that make assumptions about the page size <nl> + try ( recyclerbytesstreamoutput tmp = new recyclerbytesstreamoutput ( recycler ) ) { <nl> + tmp . setversion ( getversion ( ) ) ; <nl> + writeable . writeto ( tmp ) ; <nl> + int size = tmp . size ( ) ; <nl> + writevint ( size ) ; <nl> + int tmppage = num ; <nl> + while ( size > num ) { <nl> + final recycler . v < bytesref > p = tmp . pages . get ( tmppage ) ; <nl> + final bytesref b = p . v ( ) ; <nl> + final int writesize = math . min ( size , b . length ) ; <nl> + writebytes ( b . bytes , b . offset , writesize ) ; <nl> + tmp . pages . set ( tmppage , null ) . close ( ) ; <nl> + size - = writesize ; <nl> + tmppage + + ; <nl> + } <nl> + } <nl> + } <nl> + <nl> @ override <nl> public void reset ( ) { <nl> releasables . close ( pages ) ; <nl> mmm a / server / src / main / java / org / elasticsearch / common / io / stream / streamoutput . java <nl> ppp b / server / src / main / java / org / elasticsearch / common / io / stream / streamoutput . java <nl>
public class searchablesnapshotenableallocationdecider extends allocationdecider <nl> " xpack . searchable . snapshot . allocate_on_rolling_restart " , <nl> false , <nl> setting . property . dynamic , <nl> - setting . property . nodescope <nl> + setting . property . nodescope , <nl> + setting . property . deprecated <nl> ) ; <nl>  <nl> + static { <nl> + <nl> + assert version . current . major = = version . v_7_17_0 . major + num ; <nl> + } <nl> + <nl> private volatile enableallocationdecider . allocation enableallocation ; <nl> private volatile boolean allocateonrollingrestart ;
public class dosection implements executablesection { <nl> final string testpath = executioncontext . getclientyamltestcandidate ( ) ! = null <nl> ? executioncontext . getclientyamltestcandidate ( ) . gettestpath ( ) <nl> : null ; <nl> - checkelasticproductheader ( response . getheaders ( " x - elastic - product " ) ) ; <nl> + if ( executioncontext . esversion ( ) . after ( version . v_8_1_0 ) <nl> + | | ( executioncontext . esversion ( ) . major = = version . v_7_17_0 . major & & executioncontext . esversion ( ) . after ( version . v_7_17_1 ) ) ) { <nl> + / / # 84038 and # 84089 mean that this assertion fails when running against a small number of released versions , but at time of <nl> + / / writing it ' s unclear exactly which released versions will contain the fix . <nl> + <nl> + checkelasticproductheader ( response . getheaders ( " x - elastic - product " ) ) ; <nl> + } <nl> checkwarningheaders ( response . getwarningheaders ( ) , testpath ) ; <nl> } catch ( clientyamltestresponseexception e ) { <nl> clientyamltestresponse resttestresponse = e . getresttestresponse ( ) ; <nl> mmm a / test / framework / src / test / java / org / elasticsearch / test / rest / yaml / section / dosectiontests . java <nl> ppp b / test / framework / src / test / java / org / elasticsearch / test / rest / yaml / section / dosectiontests . java <nl>
public class netty4tcpchannel implements tcpchannel { <nl> try { <nl> channel . config ( ) . setoption ( channeloption . so_linger , num ) ; <nl> } catch ( exception e ) { <nl> + if ( ioutils . mac_os_x ) { <nl> + / / just ignore on osx for now , there is no reliably way of determining if the socket is still in a state that <nl> + / / accepts the setting because it could have already been reset from the other end which quietly does nothing on <nl> + / / linux but throws osx . <nl> + <nl> + return ; <nl> + } <nl> if ( channel . isopen ( ) ) { <nl> throw e ; <nl> }
public class packageupgradetests extends packagingtestcase { <nl> bwcdistribution = new distribution ( paths . get ( system . getproperty ( " tests . bwc - distribution " ) ) ) ; <nl> } <nl>  <nl> + @ beforeclass <nl> + public static void filterversions ( ) { <nl> + <nl> + assumetrue ( " only wire compatible versions " , version . fromstring ( bwcdistribution . baseversion ) . iscompatible ( version . current ) ) ; <nl> + } <nl> + <nl> public void test10installbwcversion ( ) throws exception { <nl> installation = installpackage ( sh , bwcdistribution ) ; <nl> assertinstalled ( bwcdistribution ) ;
public class snapshotsservice extends abstractlifecyclecomponent implements clus <nl> assert currentlyfinalizing . contains ( deleteentry . repository ( ) ) ; <nl> final list < snapshotid > snapshotids = deleteentry . getsnapshots ( ) ; <nl> assert deleteentry . state ( ) = = snapshotdeletionsinprogress . state . started : " incorrect state for entry [ " + deleteentry + " ] " ; <nl> + if ( snapshotids . isempty ( ) ) { <nl> + / / this deletion overlapped one or more deletions that were successfully processed and there is no remaining snapshot to <nl> + / / delete now , we can avoid reaching to the repository and can complete the deletion . <nl> + <nl> + removesnapshotdeletionfromclusterstate ( deleteentry , null , repositorydata ) ; <nl> + return ; <nl> + } <nl> repositoriesservice . repository ( deleteentry . repository ( ) ) <nl> . deletesnapshots ( <nl> snapshotids ,
public class snapshotlifecycletask implements schedulerengine . listener { <nl> ) ; <nl> / / add each failed shard ' s exception as suppressed , the exception contains <nl> / / information about which shard failed <nl> - snapinfo . shardfailures ( ) . foreach ( failure - > e . addsuppressed ( failure . getcause ( ) ) ) ; <nl> + <nl> + snapinfo . shardfailures ( ) . foreach ( e : : addsuppressed ) ; <nl> / / call the failure handler to register this as a failure and persist it <nl> onfailure ( e ) ; <nl> }
public class featurefactory { <nl> private final coordinatesequencefilter sequencefilter ; <nl> / / pixel precision of the tile in the mercator projection . <nl> private final double pixelprecision ; <nl> + / / size of the buffer in pixels for the clip envelope . we choose a values that makes sure <nl> + / / we have values outside the tile for polygon crossing the tile so the outline of the <nl> + / / tile is not part of the final result . <nl> + <nl> + private static final int buffer_size_pixels = num ; <nl>  <nl> public featurefactory ( int z , int x , int y , int extent ) { <nl> this . pixelprecision = num * sphericalmercatorutils . mercator_bounds / ( ( 1l < < z ) * extent ) ; <nl> final rectangle r = sphericalmercatorutils . rectosphericalmercator ( geotileutils . toboundingbox ( x , y , z ) ) ; <nl> final envelope tileenvelope = new envelope ( r . getminx ( ) , r . getmaxx ( ) , r . getminy ( ) , r . getmaxy ( ) ) ; <nl> final envelope clipenvelope = new envelope ( tileenvelope ) ; <nl> - clipenvelope . expandby ( this . pixelprecision , this . pixelprecision ) ; <nl> + / / expand enough the clip envelope to prevent visual artefacts <nl> + clipenvelope . expandby ( buffer_size_pixels * this . pixelprecision , buffer_size_pixels * this . pixelprecision ) ; <nl> final geometryfactory geomfactory = new geometryfactory ( ) ; <nl> this . builder = new jtsgeometrybuilder ( geomfactory ) ; <nl> this . cliptile = geomfactory . togeometry ( clipenvelope ) ;
public class doublevaluescomparatorsource extends indexfielddata . xfieldcomparato <nl> } ; <nl> } <nl> } ; <nl> + <nl> + comparator . disableskipping ( ) ; <nl> + return comparator ; <nl> } <nl>  <nl> @ override <nl> mmm a / server / src / main / java / org / elasticsearch / index / fielddata / fieldcomparator / floatvaluescomparatorsource . java <nl> ppp b / server / src / main / java / org / elasticsearch / index / fielddata / fieldcomparator / floatvaluescomparatorsource . java <nl>
public class floatvaluescomparatorsource extends indexfielddata . xfieldcomparator <nl> } ; <nl> } <nl> } ; <nl> + <nl> + comparator . disableskipping ( ) ; <nl> + return comparator ; <nl> } <nl>  <nl> @ override <nl> mmm a / server / src / main / java / org / elasticsearch / index / fielddata / fieldcomparator / longvaluescomparatorsource . java <nl> ppp b / server / src / main / java / org / elasticsearch / index / fielddata / fieldcomparator / longvaluescomparatorsource . java <nl>
public class longvaluescomparatorsource extends indexfielddata . xfieldcomparators <nl> } ; <nl> } <nl> } ; <nl> + <nl> + comparator . disableskipping ( ) ; <nl> + return comparator ; <nl> } <nl>  <nl> @ override
public class prunechangelogstasktests extends gradleunittestcase { <nl>  <nl> @ before <nl> public void setup ( ) { <nl> + <nl> + assumefalse ( os . current ( ) = = windows ) ; <nl> gitwrapper = mock ( gitwrapper . class ) ; <nl> deletehelper = mock ( deletehelper . class ) ; <nl> }
<nl> [ [ snapshots - restore - snapshot ] ] <nl> = = restore a snapshot <nl>  <nl> + <nl> + [ [ change - index - settings - during - restore ] ] <nl> this guide shows you how to restore a snapshot . snapshots are a convenient way <nl> to store a copy of your data outside of a cluster . you can restore a snapshot <nl> to recover indices and data streams after deletion or a hardware failure . you
import java . io . ioexception ; <nl>  <nl> / * * <nl> * thrown when snapshot creation fails completely <nl> + * <nl> + * @ deprecated this exception isn ' t thrown anymore . it ' s only here for bwc . <nl> * / <nl> + @ deprecated <nl> public class snapshotcreationexception extends snapshotexception { <nl>  <nl> public snapshotcreationexception ( streaminput in ) throws ioexception {
public class textclassificationprocessor implements nlptask . processor { <nl> return new warninginferenceresults ( " text classification result has no data " ) ; <nl> } <nl>  <nl> - if ( pytorchresult . getinferenceresult ( ) [ 0 ] . length ! = classlabels . length ) { <nl> + <nl> + if ( pytorchresult . getinferenceresult ( ) [ 0 ] [ 0 ] . length ! = classlabels . length ) { <nl> return new warninginferenceresults ( <nl> " expected exactly [ { } ] values in text classification result ; got [ { } ] " , <nl> classlabels . length , <nl> - pytorchresult . getinferenceresult ( ) [ 0 ] . length <nl> + pytorchresult . getinferenceresult ( ) [ 0 ] [ 0 ] . length <nl> ) ; <nl> }
buildscript { <nl> mavencentral ( ) <nl> maven { url ' https : / / jitpack . io ' } <nl> } <nl> + <nl> + / / we rely on a patched version of the redline library used to build rpm packages <nl> + / / to support sha256header in our elasticsearch rpms <nl> + <nl> + configurations . all { <nl> + resolutionstrategy { <nl> + dependencysubstitution { <nl> + substitute module ( ' org . redline - rpm : redline ' ) using module ( ' com . github . breskeby : redline : caa0ede ' ) <nl> + } <nl> + } <nl> + } <nl> + <nl> dependencies { <nl> classpath " com . github . breskeby : gradle - ospackage - plugin : 98455c1 " <nl> } <nl> + <nl> } <nl>  <nl> apply plugin : " nebula . ospackage - base "
if ( system . getproperty ( ' idea . active ' ) = = ' true ' ) { <nl> } <nl> runconfigurations { <nl> defaults ( junit ) { <nl> - vmparameters = ' - ea - djava . locale . providers = spi , compat ' <nl> + vmparameters = [ <nl> + ' - ea ' , <nl> + ' - djava . locale . providers = spi , compat ' , <nl> + " - - illegal - access = deny " , <nl> + <nl> + ' - - add - opens = java . base / java . security . cert = all - unnamed ' , <nl> + ' - - add - opens = java . base / java . nio . channels = all - unnamed ' , <nl> + ' - - add - opens = java . base / java . net = all - unnamed ' , <nl> + ' - - add - opens = java . base / javax . net . ssl = all - unnamed ' , <nl> + ' - - add - opens = java . base / java . nio . file = all - unnamed ' , <nl> + ' - - add - opens = java . base / java . time = all - unnamed ' <nl> + ] . join ( ' ' ) <nl> } <nl> } <nl> copyright {
public class bwcsetupextension { <nl> } ) ; <nl> } <nl>  <nl> + <nl> + private string minimumcompilerversionpath ( project project , provider < file > checkoutdir ) { <nl> + return ( checkoutdir . get ( ) . getname ( ) . endswith ( " 7 . x " ) ) ? <nl> + " build - tools - internal / " + minimum_compiler_version_path : <nl> + " buildsrc / " + minimum_compiler_version_path ; <nl> + } <nl> + <nl> private static class indentingoutputstream extends outputstream { <nl>  <nl> public final byte [ ] indent ; <nl>
public class elasticsearchtestbaseplugin implements plugin < project > { <nl> test . jvmargs ( <nl> " - xmx " + system . getproperty ( " tests . heap . size " , " 512m " ) , <nl> " - xms " + system . getproperty ( " tests . heap . size " , " 512m " ) , <nl> - " - - illegal - access = warn " , <nl> + " - - illegal - access = deny " , <nl> + <nl> + " - - add - opens = java . base / java . security . cert = all - unnamed " , <nl> + " - - add - opens = java . base / java . nio . channels = all - unnamed " , <nl> + " - - add - opens = java . base / java . net = all - unnamed " , <nl> + " - - add - opens = java . base / javax . net . ssl = all - unnamed " , <nl> + " - - add - opens = java . base / java . nio . file = all - unnamed " , <nl> + " - - add - opens = java . base / java . time = all - unnamed " , <nl> " - xx : + heapdumponoutofmemoryerror " <nl> ) ; <nl>  <nl> mmm a / plugins / repository - hdfs / build . gradle <nl> ppp b / plugins / repository - hdfs / build . gradle <nl>
subprojects { <nl> if ( bwcversion . onorafter ( version . fromstring ( " 7 . 9 . 0 " ) ) & & ( bwcversion . equals ( versionproperties . elasticsearchversion ) = = false ) ) { <nl> string basename = " v $ { bwcversion } " <nl> unreleasedversioninfo unreleasedversion = buildparams . bwcversions . unreleasedinfo ( bwcversion ) <nl> - configuration driverconfiguration = configurations . create ( " jdbcdriver $ { basename } " ) <nl> + configuration driverconfiguration = configurations . create ( " jdbcdriver $ { basename } " ) { <nl> + <nl> + transitive = false <nl> + } <nl> object driverdependency = null <nl>  <nl> if ( unreleasedversion ) {
<nl> * / <nl>  <nl> / * * <nl> - * builds analytic information over all hits in a search request . <nl> + * < h2 > aggregations < / h2 > <nl> + * < p > builds analytic information over all hits in a search request . aggregations <nl> + * are essentially a tool for sumarizing data , and that summary is often used <nl> + * to generate a visualization . < / p > <nl> + * <nl> + * < h2 > types of aggregations < / h2 > <nl> + * there are three main types of aggregations , each in their own sub package : <nl> + * < ul > <nl> + * < li > bucket aggregations - which group documents ( e . g . a histogram ) < / li > <nl> + * < li > metric aggregations - which compute a summary value from several <nl> + * documents ( e . g . a sum ) < / li > <nl> + * < li > pipeline aggregations - which run as a seperate step and compute <nl> + * values across buckets < / li > <nl> + * < / ul > <nl> + * additionally there is a support sub package , which contains the type checking <nl> + * and resolution logic , primarily . <nl> + * <nl> + * < h2 > how aggregations work < / h2 > <nl> + * < p > <nl> + * <nl> + * < p > aggregations operate in general as map reduce jobs . the coordinating node for <nl> + * the query dispatches the aggregation to each data node . the data nodes all <nl> + * instantiate an { @ link org . elasticsearch . search . aggregations . aggregationbuilder } <nl> + * of the appropriate type , which in turn builds the <nl> + * { @ link org . elasticsearch . search . aggregations . aggregator } for that node . this <nl> + * collects the data from that shard , via <nl> + * { @ link org . elasticsearch . search . aggregations . aggregator # getleafcollector ( org . apache . lucene . index . leafreadercontext ) } <nl> + * more or less . these values are shipped back to the coordinating node , which <nl> + * performs the reduction on them ( partial reductions in place on the data nodes <nl> + * are also possible ) . < / p > <nl> + * <nl> + * < h3 > three modes of operation < / h3 > <nl> + * < p > when it comes to actually collecting values , there are three ways aggregations <nl> + * operate , in general . which one we choose depends on limitations in the query <nl> + * and how the data was ingested ( e . g . if it is searchable ) . < / p > <nl> + * <nl> + * < p > the easiest to understand is the < strong > compatible < / strong > ( i . e . usable in <nl> + * all situations ) mode , which can be thought of as iterating each query hit and <nl> + * collecting a value from it . this is the least performant way to evaluate <nl> + * aggregations , requiring looking at every hit . < / p > <nl> + * <nl> + * < p > the fastest way to run an aggregation is by < strong > looking at the <nl> + * directly . < / strong > for example , lucene just stores the minimum and maximum values <nl> + * of fields per segment , so a min aggregation matching all documents in a segment <nl> + * can just look up its result . generally speaking , this mode can be engaged when <nl> + * there are no queries or sub - aggregations , and is gated by <nl> + * { @ link org . elasticsearch . search . aggregations . support . valuessourceconfig # getpointreaderornull ( ) } . < / p > <nl> + * <nl> + * < p > finally , we can < strong > rewrite < / strong > an aggregation into faster aggregations , <nl> + * or ideally into just a query . generally , the goal here is to get to <nl> + * < strong > filter by filters < / strong > ( which is an optimization on the filters aggregation <nl> + * which runs it as a set of filter queries ) . often this process will look like rewriting <nl> + * a datehistogram into a daterange , and then rewriting the daterange into filters . <nl> + * if you see { @ link org . elasticsearch . search . aggregations . adaptingaggregator } , that ' s <nl> + * a good clue that the rewrite mode is being used . in general , when we rewrite aggregations , <nl> + * we are able to detect if the rewritten agg can run in a " fast " mode , and decline the <nl> + * rewrite if it can ' t . < / p > <nl> + * <nl> + * < p > in general , aggs will try to use one of the fast modes , and if that ' s not possible , <nl> + * fall back to running in compatible mode . < / p > <nl> * / <nl> package org . elasticsearch . search . aggregations ;
teardown : <nl> - length : { terms : num } <nl>  <nl> mmm <nl> + " test null search string allowed " : <nl> + - skip : <nl> + version : " - num . 99 . 99 " <nl> + reason : <nl> + <nl> + - do : <nl> + terms_enum : <nl> + index : test_k <nl> + body : { " field " : " foo " } <nl> + - length : { terms : num } <nl> + mmm <nl> " test search after keyword field " : <nl> - do : <nl> terms_enum :
public class snapshotsservice extends abstractlifecyclecomponent implements clus <nl> entry . partial ( ) ? shardgenerations . totalshards ( ) : entry . shards ( ) . size ( ) , <nl> shardfailures , <nl> entry . includeglobalstate ( ) , <nl> - entry . usermetadata ( ) , <nl> + <nl> + entry . usermetadata ( ) = = null ? null : new hashmap < > ( entry . usermetadata ( ) ) , <nl> entry . starttime ( ) , <nl> indexsnapshotdetails ) ; <nl> repo . finalizesnapshot ( <nl> mmm a / x - pack / plugin / repository - encrypted / src / main / java / org / elasticsearch / repositories / encrypted / encryptedrepository . java <nl> ppp b / x - pack / plugin / repository - encrypted / src / main / java / org / elasticsearch / repositories / encrypted / encryptedrepository . java <nl>
public class transportmountsearchablesnapshotaction extends transportmasternodea <nl> . put ( index_recovery_type_setting . getkey ( ) , searchablesnapshotsconstants . snapshot_recovery_state_factory_key ) ; <nl>  <nl> if ( storage = = mountsearchablesnapshotrequest . storage . shared_cache ) { <nl> + if ( minnodeversion . before ( version . v_7_12_0 ) ) { <nl> + throw new illegalargumentexception ( " shared cache searchable snapshots require minimum node version " + version . v_7_12_0 ) ; <nl> + } <nl> settings . put ( searchablesnapshotsconstants . snapshot_partial_setting . getkey ( ) , true ) <nl> - . put ( diskthresholddecider . setting_ignore_disk_watermarks . getkey ( ) , true ) <nl> - . put ( shardlimitvalidator . index_setting_shard_limit_group . getkey ( ) , shardlimitvalidator . frozen_group ) ; <nl> + . put ( diskthresholddecider . setting_ignore_disk_watermarks . getkey ( ) , true ) ; <nl> + <nl> + / / we cannot apply this setting during rolling upgrade . <nl> + <nl> + if ( minnodeversion . onorafter ( version . v_8_0_0 ) ) { <nl> + settings . put ( shardlimitvalidator . index_setting_shard_limit_group . getkey ( ) , shardlimitvalidator . frozen_group ) ; <nl> + } <nl> } <nl>  <nl> return settings . build ( ) ; <nl>
final class systemjvmoptions { <nl> * due to internationalization enhancements in jdk num elasticsearch need to set the provider to compat otherwise time / date <nl> * parsing will break in an incompatible way for some date patterns and locales . <nl> * / <nl> - " - djava . locale . providers = spi , compat " <nl> + " - djava . locale . providers = spi , compat " , <nl> + / * <nl> + * temporarily suppress illegal reflective access in searchable snapshots shared cache preallocation ; this is temporary while we <nl> + * explore alternatives . see org . elasticsearch . xpack . searchablesnapshots . preallocate . preallocate . <nl> + * <nl> + * <nl> + * / <nl> + " - - add - opens = java . base / java . io = all - unnamed " <nl> ) . stream ( ) . filter ( e - > e . isempty ( ) = = false ) . collect ( collectors . tolist ( ) ) ; <nl> }
public class multibucketcollector extends bucketcollector { <nl> } <nl> switch ( leafcollectors . size ( ) ) { <nl> case num : <nl> + <nl> + / * <nl> + * see minaggregator which only throws if it has a parent . <nl> + * that is because it doesn ' t want there to ever drop <nl> + * to this case and throw , thus skipping calculating the parent . <nl> + * / <nl> throw new collectionterminatedexception ( ) ; <nl> case num : <nl> return leafcollectors . get ( 0 ) ; <nl> mmm a / server / src / main / java / org / elasticsearch / search / aggregations / bucket / terms / globalordinalsstringtermsaggregator . java <nl> ppp b / server / src / main / java / org / elasticsearch / search / aggregations / bucket / terms / globalordinalsstringtermsaggregator . java <nl>
public class policyutiltests extends estestcase { <nl> } <nl>  <nl> static final list < string > plugin_test_permissions = list . of ( <nl> + <nl> + " java . io . filepermission / foo / bar read " , <nl> + <nl> " java . lang . reflect . reflectpermission suppressaccesschecks " , <nl> " java . lang . runtimepermission createclassloader " , <nl> " java . lang . runtimepermission getclassloader " , <nl>
public class policyutil { <nl> private static final permissionmatcher allowed_module_permissions ; <nl> static { <nl> list < permission > namedpermissions = list . of ( <nl> + <nl> + createfilepermission ( " < < all files > > " , " read " ) , <nl> + <nl> new reflectpermission ( " suppressaccesschecks " ) , <nl> new runtimepermission ( " createclassloader " ) , <nl> new runtimepermission ( " getclassloader " ) ,
import org . apache . lucene . util . constants ; <nl> import org . elasticsearch . common . nullable ; <nl>  <nl> / * * <nl> - * system specific wrappers of the fallocate system call via jna for linux and osx . <nl> + * system specific wrappers of the fallocate system call via jna for linux . <nl> + * <nl> * / <nl> abstract class jnafalloc { <nl>  <nl>
class yamlrestcompattestpluginfunctest extends abstractrestresourcesfunctest { <nl> } <nl>  <nl> when : <nl> - result = gradlerunner ( transformtask ) . build ( ) <nl> + <nl> + result = gradlerunner ( transformtask , " - i " ) . build ( ) <nl>  <nl> then : <nl> result . task ( transformtask ) . outcome = = taskoutcome . up_to_date
public class verifiererrormessagestests extends estestcase { <nl>  <nl> public void testaggsinwhere ( ) { <nl> assertequals ( " 1 : 33 : cannot use where filtering on aggregate function [ max ( int ) ] , use having instead " , <nl> - error ( " select max ( int ) from test where max ( int ) > num group by bool " ) ) ; <nl> + error ( " select max ( int ) from test where max ( int ) > num group by bool " ) ) ; <nl> + } <nl> + <nl> + public void testhavinginaggs ( ) { <nl> + assertequals ( " 1 : 29 : [ int ] field must appear in the group by clause or in an aggregate function " , <nl> + error ( " select int from test having max ( int ) = num " ) ) ; <nl> + <nl> + assertequals ( " 1 : 35 : [ int ] field must appear in the group by clause or in an aggregate function " , <nl> + error ( " select int from test having int = count ( 1 ) " ) ) ; <nl> + } <nl> + <nl> + public void testhavingaswhere ( ) { <nl> + <nl> + accept ( " select int from test having int = num " ) ; <nl> + accept ( " select int from test having sin ( int ) + num > num . 5 " ) ; <nl> + / / having ' s expression being and ' ed to where ' s <nl> + accept ( " select int from test where int > num having power ( int , num ) < num " ) ; <nl> } <nl>  <nl> public void testhistograminfilter ( ) {
setup : <nl> - match : { hits . hits . 2 . fields . ul . 0 : " 9223372036854775808 " } <nl> - match : { hits . hits . 3 . fields . ul . 0 : " 18446744073709551614 " } <nl> - match : { hits . hits . 4 . fields . ul . 0 : " 18446744073709551615 " } <nl> + <nl> + mmm <nl> + " composite aggregations " : <nl> + - skip : <nl> + version : " - num . 99 . 99 " <nl> + reason : " <nl> + <nl> + - do : <nl> + search : <nl> + index : test1 <nl> + body : <nl> + size : num <nl> + aggs : <nl> + test : <nl> + composite : <nl> + size : num <nl> + sources : [ { <nl> + " ul " : { <nl> + " terms " : { <nl> + " field " : " ul " <nl> + } <nl> + } <nl> + } ] <nl> + <nl> + - set : { aggregations . test . after_key : after_key } <nl> + - length : { aggregations . test . buckets : num } <nl> + - match : { aggregations . test . buckets . 0 . key . ul : num } <nl> + - match : { aggregations . test . buckets . 0 . doc_count : num } <nl> + - match : { aggregations . test . buckets . 1 . key . ul : num } <nl> + - match : { aggregations . test . buckets . 1 . doc_count : num } <nl> + - match : { aggregations . test . buckets . 2 . key . ul : num } <nl> + - match : { aggregations . test . buckets . 2 . doc_count : num } <nl> + <nl> + - do : <nl> + search : <nl> + index : test1 <nl> + body : <nl> + size : num <nl> + aggs : <nl> + test : <nl> + composite : <nl> + size : num <nl> + after : $ after_key <nl> + sources : [ { <nl> + " ul " : { <nl> + " terms " : { <nl> + " field " : " ul " <nl> + } <nl> + } <nl> + } ] <nl> + <nl> + - set : { aggregations . test . after_key : after_key } <nl> + - length : { aggregations . test . buckets : num } <nl> + - match : { aggregations . test . buckets . 0 . key . ul : num } <nl> + - match : { aggregations . test . buckets . 0 . doc_count : num } <nl> + - match : { aggregations . test . buckets . 1 . key . ul : num } <nl> + - match : { aggregations . test . buckets . 1 . doc_count : num } <nl> + <nl> + - do : <nl> + search : <nl> + index : test1 <nl> + body : <nl> + size : num <nl> + aggs : <nl> + test : <nl> + composite : <nl> + size : num <nl> + after : $ after_key <nl> + sources : [ { <nl> + " ul " : { <nl> + " terms " : { <nl> + " field " : " ul " <nl> + } <nl> + } <nl> + } ] <nl> + <nl> + - length : { aggregations . test . buckets : num }
public class internalengine extends engine { <nl>  <nl> @ override <nl> public void writeindexingbuffer ( ) throws engineexception { <nl> + <nl> refresh ( " write indexing buffer " , searcherscope . internal , false ) ; <nl> }
public class parsedmediatype { <nl>  <nl> / * * <nl> * parses a header value into it ' s parts . <nl> - * follows https : / / tools . ietf . org / html / rfc7231 # section - 3 . 1 . 1 . 1 but allows only single media type and do not support quality factors <nl> + * follows https : / / tools . ietf . org / html / rfc7231 # section - 3 . 1 . 1 . 1 <nl> + * but allows only single media type . media ranges will be ignored ( treated as not provided ) <nl> * note : parsing can return null , but it will throw exceptions once https : / / github . com / elastic / elasticsearch / issues / 63080 is done <nl> - * do not rely on nulls <nl> + * <nl> * <nl> * @ return a { @ link parsedmediatype } if the header could be parsed . <nl> * @ throws illegalargumentexception if the header is malformed <nl> * / <nl> public static parsedmediatype parsemediatype ( string headervalue ) { <nl> - if ( default_accept_string . equals ( headervalue ) | | " * / * " . equals ( headervalue ) ) { <nl> - return null ; <nl> - } <nl> if ( headervalue ! = null ) { <nl> + if ( ismediarange ( headervalue ) | | " * / * " . equals ( headervalue ) ) { <nl> + return null ; <nl> + } <nl> final string [ ] elements = headervalue . tolowercase ( locale . root ) . split ( " [ \ \ s \ \ t ] * ; " ) ; <nl>  <nl> final string [ ] splitmediatype = elements [ 0 ] . split ( " / " ) ; <nl>
public class snapshotsservice extends abstractlifecyclecomponent implements clus <nl> final string repositoryname = request . repository ( ) ; <nl> final string snapshotname = indexnameexpressionresolver . resolvedatemathexpression ( request . snapshot ( ) ) ; <nl> validate ( repositoryname , snapshotname ) ; <nl> + <nl> final snapshotid snapshotid = new snapshotid ( snapshotname , uuids . randombase64uuid ( ) ) ; / / new uuid for the snapshot <nl> repository repository = repositoriesservice . repository ( request . repository ( ) ) ; <nl> if ( repository . isreadonly ( ) ) { <nl>
public class snapshotsservice extends abstractlifecyclecomponent implements clus <nl> } <nl> final string snapshotname = indexnameexpressionresolver . resolvedatemathexpression ( request . target ( ) ) ; <nl> validate ( repositoryname , snapshotname ) ; <nl> + <nl> final snapshotid snapshotid = new snapshotid ( snapshotname , uuids . randombase64uuid ( ) ) ; <nl> final snapshot snapshot = new snapshot ( repositoryname , snapshotid ) ; <nl> initializingclones . add ( snapshot ) ;
public class mlmappingsupgradeit extends abstractupgradetestcase { <nl> } ) ; <nl> } <nl>  <nl> + @ suppresswarnings ( " unchecked " ) <nl> + private void assertupgradedannotationsmappings ( ) throws exception { <nl> + <nl> + assertbusy ( ( ) - > { <nl> + request getmappings = new request ( " get " , " . ml - annotations - write / _mappings " ) ; <nl> + response response = client ( ) . performrequest ( getmappings ) ; <nl> + <nl> + map < string , object > responselevel = entityasmap ( response ) ; <nl> + assertnotnull ( responselevel ) ; <nl> + map < string , object > indexlevel = null ; <nl> + / / the name of the concrete <nl> + / / changed by the upgrade process ( depending on what other tests are being run and the order they ' re run <nl> + / / in ) , so navigating to the next level of the tree must account for both cases <nl> + for ( map . entry < string , object > entry : responselevel . entryset ( ) ) { <nl> + if ( entry . getkey ( ) . startswith ( " . ml - annotations - " ) ) { <nl> + indexlevel = ( map < string , object > ) entry . getvalue ( ) ; <nl> + break ; <nl> + } <nl> + } <nl> + assertnotnull ( indexlevel ) ; <nl> + <nl> + assertequals ( version . current . tostring ( ) , extractvalue ( " mappings . _meta . version " , indexlevel ) ) ; <nl> + <nl> + <nl> + / / mappings , for example a field we want to be " keyword " incorrectly mapped as " text " <nl> + assertequals ( " incorrect type for event in " + responselevel , " keyword " , <nl> + extractvalue ( " mappings . properties . event . type " , indexlevel ) ) ; <nl> + } ) ; <nl> + } <nl> + <nl> @ suppresswarnings ( " unchecked " ) <nl> private void assertupgradedconfigmappings ( ) throws exception {
public class elasticsearchnode implements testclusterconfiguration { <nl> } <nl>  <nl> private boolean canuseshareddistribution ( ) { <nl> - return extrajarfiles . size ( ) = = num & & modules . size ( ) = = num & & plugins . size ( ) = = num ; <nl> + / / using original location can be too long due to max_path restrictions on windows ci <nl> + <nl> + return os . current ( ) ! = os . windows & & extrajarfiles . size ( ) = = num & & modules . size ( ) = = num & & plugins . size ( ) = = num ; <nl> } <nl>  <nl> private void logtoprocessstdout ( string message ) { <nl>
public class regressionit extends mlnativedataframeanalyticsintegtestcase { <nl> assertthat ( resultsobject . get ( " is_training " ) , is ( destdoc . containskey ( dependent_variable_field ) ) ) ; <nl> @ suppresswarnings ( " unchecked " ) <nl> list < map < string , object > > importancearray = ( list < map < string , object > > ) resultsobject . get ( " feature_importance " ) ; <nl> - assertthat ( importancearray , hassize ( greaterthan ( 0 ) ) ) ; <nl> - assertthat ( <nl> - importancearray . stream ( ) . filter ( m - > numerical_feature_field . equals ( m . get ( " feature_name " ) ) <nl> - | | discrete_numerical_feature_field . equals ( m . get ( " feature_name " ) ) ) . findany ( ) , <nl> - ispresent ( ) ) ; <nl> + <nl> + if ( importancearray . isempty ( ) ) { <nl> + if ( boolean . true . equals ( resultsobject . get ( " is_training " ) ) ) { <nl> + trainingdocswithemptyfeatureimportance + + ; <nl> + } else { <nl> + testdocswithemptyfeatureimportance + + ; <nl> + } <nl> + } <nl> + <nl> + <nl> + / / assertthat ( importancearray , hassize ( greaterthan ( 0 ) ) ) ; <nl> + / / assertthat ( <nl> + / / importancearray . stream ( ) . filter ( m - > numerical_feature_field . equals ( m . get ( " feature_name " ) ) <nl> + / / | | discrete_numerical_feature_field . equals ( m . get ( " feature_name " ) ) ) . findany ( ) , <nl> + / / ispresent ( ) ) ; <nl> } <nl>  <nl> + / / if feature importance was empty for some of the docs this assertion helps us <nl> + / / understand whether the offending docs were training or test docs . <nl> + assertthat ( " there were [ " + trainingdocswithemptyfeatureimportance + " ] training docs and [ " <nl> + + testdocswithemptyfeatureimportance + " ] test docs with empty feature importance " , <nl> + trainingdocswithemptyfeatureimportance + testdocswithemptyfeatureimportance , equalto ( 0 ) ) ; <nl> + <nl> assertprogresscomplete ( jobid ) ; <nl> assertthat ( searchstoredprogress ( jobid ) . gethits ( ) . gettotalhits ( ) . value , equalto ( 1l ) ) ; <nl> assertmodelstatepersisted ( statedocid ( ) ) ;
<nl> + / * <nl> + * copyright elasticsearch b . v . and / or licensed to elasticsearch b . v . under one <nl> + * or more contributor license agreements . licensed under the elastic license ; <nl> + * you may not use this file except in compliance with the elastic license . <nl> + * / <nl> + <nl> + <nl> + / * <nl> + * only want to do because we don ' t yet have a fieldmapper implementation . <nl> + * once we have that we can move to mock scripts in unit tests and painless <nl> + * in integration tests . * / <nl> + <nl> + grant { <nl> + / / needed to generate runtime classes <nl> + permission java . lang . runtimepermission " createclassloader " ; <nl> + <nl> + / / needed to find the classloader to load whitelisted classes from <nl> + permission java . lang . runtimepermission " getclassloader " ; <nl> + } ; <nl> +
import static org . hamcrest . matchers . equalto ; <nl> import static org . hamcrest . matchers . hassize ; <nl>  <nl> / * * runs rest tests against external cluster * / <nl> + <nl> + @ timeoutsuite ( millis = num * timeunits . minute ) <nl> public class xpackrestit extends esclientyamlsuitetestcase { <nl> private static final string basic_auth_value = <nl> basicauthheadervalue ( " x_pack_rest_user " , securitysettingssourcefield . test_password_secure_string ) ;
class precommittasks { <nl> classpath = project . files { sourceset . runtimeclasspath . plus ( sourceset . compileclasspath ) } <nl>  <nl> targetcompatibility = buildparams . runtimejavaversion . majorversion <nl> - if ( buildparams . runtimejavaversion > javaversion . version_13 ) { <nl> - / / forbidden apis does not yet support java num ( it will in version num . 0 ) , so we must use java num target <nl> - targetcompatibility = javaversion . version_13 . majorversion <nl> + if ( buildparams . runtimejavaversion > javaversion . version_14 ) { <nl> + <nl> + targetcompatibility = javaversion . version_14 . majorversion <nl> } <nl> bundledsignatures = [ <nl> " jdk - unsafe " , " jdk - deprecated " , " jdk - non - portable " , " jdk - system - out "
public enum corevaluessourcetype implements valuessourcetype { <nl> number missing = docvalueformat . parsedouble ( rawmissing . tostring ( ) , false , nowsupplier ) ; <nl> return missingvalues . replacemissing ( ( valuessource . numeric ) valuessource , missing ) ; <nl> } <nl> + <nl> + @ override <nl> + public docvalueformat getformatter ( string format , zoneid tz ) { <nl> + / * <nl> + before we can solve this , we need to resolve https : / / github . com / elastic / elasticsearch / issues / 47469 which deals <nl> + with the fact that the same formatter is used for input and output values . we want to support a use case in sql <nl> + ( and elsewhere ) that allows for passing a long value milliseconds since epoch into date aggregations . in that case , <nl> + the timezone is sensible as part of the bucket key format . <nl> + * / <nl> + if ( format = = null ) { <nl> + return docvalueformat . raw ; <nl> + } else { <nl> + return new docvalueformat . decimal ( format ) ; <nl> + } <nl> + <nl> + } <nl> } , <nl> bytes ( ) { <nl> @ override <nl> mmm a / server / src / test / java / org / elasticsearch / search / aggregations / metrics / weightedavgaggregatortests . java <nl> ppp b / server / src / test / java / org / elasticsearch / search / aggregations / metrics / weightedavgaggregatortests . java <nl>
public abstract class esclientyamlsuitetestcase extends esresttestcase { <nl> configureclient ( builder , restclientsettings ( ) ) ; <nl> return builder ; <nl> } <nl> + <nl> + protected final boolean preservedatastreamsuponcompletion ( ) { <nl> + <nl> + / / the client runners need to be adjust to remove data streams after each test too , <nl> + / / otherwise rest yaml tests using data streams succeed in elasticsearch , but may fail when clients run <nl> + / / the yaml test suite . in the mean time we should delete data streams manually after each test . <nl> + return true ; <nl> + } <nl> }
public class snapshotit extends esresthighlevelclienttestcase { <nl> createsnapshotresponse response = createtestsnapshot ( request ) ; <nl> assertequals ( waitforcompletion ? reststatus . ok : reststatus . accepted , response . status ( ) ) ; <nl> if ( waitforcompletion = = false ) { <nl> - / / if we don ' t wait for the snapshot to complete we have to cancel it to not leak the snapshot task <nl> - acknowledgedresponse deleteresponse = execute ( <nl> - new deletesnapshotrequest ( repository , snapshot ) , <nl> - highlevelclient ( ) . snapshot ( ) : : delete , highlevelclient ( ) . snapshot ( ) : : deleteasync <nl> - ) ; <nl> - asserttrue ( deleteresponse . isacknowledged ( ) ) ; <nl> + / / busy assert on the delete because a known race condition could cause the delete request to not see <nl> + / / the snapshot if delete and snapshot finalization happen at the same time <nl> + / / see https : / / github . com / elastic / elasticsearch / issues / 53509 # issuecomment - 603899620 for details <nl> + <nl> + assertbusy ( ( ) - > { <nl> + / / if we don ' t wait for the snapshot to complete we have to cancel it to not leak the snapshot task <nl> + acknowledgedresponse deleteresponse ; <nl> + try { <nl> + deleteresponse = execute ( <nl> + new deletesnapshotrequest ( repository , snapshot ) , <nl> + highlevelclient ( ) . snapshot ( ) : : delete , highlevelclient ( ) . snapshot ( ) : : deleteasync <nl> + ) ; <nl> + } catch ( exception e ) { <nl> + throw new assertionerror ( e ) ; <nl> + } <nl> + asserttrue ( deleteresponse . isacknowledged ( ) ) ; <nl> + } ) ; <nl> } <nl> }
public abstract class internalterms < a extends internalterms < a , b > , b extends int <nl> } <nl> } <nl>  <nl> - final int size = reducecontext . isfinalreduce ( ) = = false ? buckets . size ( ) : math . min ( requiredsize , buckets . size ( ) ) ; <nl> - final bucketpriorityqueue < b > ordered = new bucketpriorityqueue < > ( size , order . comparator ( ) ) ; <nl> - for ( list < b > sametermbuckets : buckets . values ( ) ) { <nl> - final b b = reducebucket ( sametermbuckets , reducecontext ) ; <nl> - if ( sumdoccounterror = = - 1 ) { <nl> - b . doccounterror = - 1 ; <nl> - } else { <nl> - b . doccounterror + = sumdoccounterror ; <nl> + final b [ ] list ; <nl> + if ( reducecontext . isfinalreduce ( ) ) { <nl> + final int size = math . min ( requiredsize , buckets . size ( ) ) ; <nl> + final bucketpriorityqueue < b > ordered = new bucketpriorityqueue < > ( size , order . comparator ( ) ) ; <nl> + for ( list < b > sametermbuckets : buckets . values ( ) ) { <nl> + final b b = reducebucket ( sametermbuckets , reducecontext ) ; <nl> + if ( sumdoccounterror = = - 1 ) { <nl> + b . doccounterror = - 1 ; <nl> + } else { <nl> + b . doccounterror + = sumdoccounterror ; <nl> + } <nl> + if ( b . doccount > = mindoccount ) { <nl> + b removed = ordered . insertwithoverflow ( b ) ; <nl> + if ( removed ! = null ) { <nl> + otherdoccount + = removed . getdoccount ( ) ; <nl> + reducecontext . consumebucketsandmaybebreak ( - countinnerbucket ( removed ) ) ; <nl> + } else { <nl> + reducecontext . consumebucketsandmaybebreak ( 1 ) ; <nl> + } <nl> + } else { <nl> + reducecontext . consumebucketsandmaybebreak ( - countinnerbucket ( b ) ) ; <nl> + } <nl> } <nl> - if ( b . doccount > = mindoccount | | reducecontext . isfinalreduce ( ) = = false ) { <nl> - b removed = ordered . insertwithoverflow ( b ) ; <nl> - if ( removed ! = null ) { <nl> - otherdoccount + = removed . getdoccount ( ) ; <nl> - reducecontext . consumebucketsandmaybebreak ( - countinnerbucket ( removed ) ) ; <nl> + list = createbucketsarray ( ordered . size ( ) ) ; <nl> + for ( int i = ordered . size ( ) - num ; i > = num ; i - - ) { <nl> + list [ i ] = ordered . pop ( ) ; <nl> + } <nl> + } else { <nl> + / / keep all buckets on partial reduce <nl> + <nl> + list = createbucketsarray ( buckets . size ( ) ) ; <nl> + int pos = num ; <nl> + for ( list < b > sametermbuckets : buckets . values ( ) ) { <nl> + final b b = reducebucket ( sametermbuckets , reducecontext ) ; <nl> + reducecontext . consumebucketsandmaybebreak ( 1 ) ; <nl> + if ( sumdoccounterror = = - 1 ) { <nl> + b . doccounterror = - 1 ; <nl> } else { <nl> - reducecontext . consumebucketsandmaybebreak ( 1 ) ; <nl> + b . doccounterror + = sumdoccounterror ; <nl> } <nl> - } else { <nl> - reducecontext . consumebucketsandmaybebreak ( - countinnerbucket ( b ) ) ; <nl> + list [ pos + + ] = b ; <nl> } <nl> } <nl> - b [ ] list = createbucketsarray ( ordered . size ( ) ) ; <nl> - for ( int i = ordered . size ( ) - num ; i > = num ; i - - ) { <nl> - list [ i ] = ordered . pop ( ) ; <nl> - } <nl> long doccounterror ; <nl> if ( sumdoccounterror = = - 1 ) { <nl> doccounterror = - 1 ;
task internalclustertest ( type : test ) { <nl>  <nl> check . dependson internalclustertest <nl>  <nl> - / / add all sub - projects of the qa sub - project <nl> - gradle . projectsevaluated { <nl> - project . subprojects <nl> - . find { it . path = = project . path + " : qa " } <nl> - . subprojects <nl> - . findall { it . path . startswith ( project . path + " : qa " ) } <nl> - . each { check . dependson it . check } <nl> + / * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * <nl> + * enable qa / rest integration tests for snapshot builds only * <nl> + * <nl> + * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * / <nl> + if ( buildparams . issnapshotbuild ( ) ) { <nl> + / / add all sub - projects of the qa sub - project <nl> + gradle . projectsevaluated { <nl> + project . subprojects <nl> + . find { it . path = = project . path + " : qa " } <nl> + . subprojects <nl> + . findall { it . path . startswith ( project . path + " : qa " ) } <nl> + . each { check . dependson it . check } <nl> + } <nl> } <nl>  <nl> / * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *
bwcversions . forpreviousunreleased { bwcversions . unreleasedversioninfo unreleased <nl> spooloutput = true <nl> workingdir = checkoutdir <nl> dofirst { <nl> + <nl> + if ( gradleversion . version ( file ( " $ { checkoutdir } / buildsrc / src / main / resources / minimumgradleversion " ) . text ) ! = gradleversion . current ( ) ) { <nl> + environment = environment . findall { key , val - > key ! = ' openshift_ip ' } <nl> + } <nl> + <nl> / / execution time so that the checkouts are available <nl> list < string > lines = file ( " $ { checkoutdir } / . ci / java - versions . properties " ) . readlines ( ) <nl> environment (
public abstract class blobstorerepository extends abstractlifecyclecomponent imp <nl> return false ; <nl> } <nl> return allsnapshotids . contains ( founduuid ) = = false ; <nl> + } else if ( blob . startswith ( index_file_prefix ) ) { <nl> + <nl> + return repositorydata . getgenid ( ) > long . parselong ( blob . substring ( index_file_prefix . length ( ) ) ) ; <nl> } <nl> return false ; <nl> } <nl> mmm a / server / src / test / java / org / elasticsearch / repositories / blobstore / blobstorerepositorycleanupit . java <nl> ppp b / server / src / test / java / org / elasticsearch / repositories / blobstore / blobstorerepositorycleanupit . java <nl>
public class nodesubclasstests < t extends b , b extends node < b > > extends estestcas <nl> * test { @ link node # replacechildren } implementation on { @ link # subclass } . <nl> * / <nl> public void testreplacechildren ( ) throws exception { <nl> + <nl> + assume . assumefalse ( subclass . equals ( pivot . class ) ) ; <nl> + <nl> constructor < t > ctor = longestctor ( subclass ) ; <nl> object [ ] nodectorargs = ctorargs ( ctor ) ; <nl> t node = ctor . newinstance ( nodectorargs ) ;
class buildplugin implements plugin < project > { <nl> } else { <nl> noninputproperties . systemproperty ( ' runtime . java ' , " $ { - > ( ext . get ( ' runtimejavaversion ' ) as javaversion ) . getmajorversion ( ) } " ) <nl> } <nl> + <nl> + test . systemproperty ( ' java . locale . providers ' , ' spi , compat ' ) <nl> } <nl>  <nl> test . jvmargumentproviders . add ( noninputproperties ) <nl>
public class slmsnapshotblockingintegtests extends esintegtestcase { <nl> snapshotsstatusresponse s = <nl> client ( ) . admin ( ) . cluster ( ) . preparesnapshotstatus ( repo ) . setsnapshots ( completedsnapshotname ) . get ( ) ; <nl> assertnull ( " expected no snapshot but one was returned " , s . getsnapshots ( ) . get ( 0 ) ) ; <nl> + } catch ( repositoryexception e ) { <nl> + / / concurrent status calls and write operations may lead to failures in determining the current repository generation <nl> + <nl> + throw new assertionerror ( e ) ; <nl> } catch ( snapshotmissingexception e ) { <nl> / / great , we wanted it to be deleted ! <nl> }
class precommittasks { <nl> dofirst { <nl> / / we need to defer this configuration since we don ' t know the runtime java version until execution time <nl> targetcompatibility = project . runtimejavaversion . getmajorversion ( ) <nl> - if ( project . runtimejavaversion > javaversion . version_11 ) { <nl> + / * <nl> + <nl> + if ( project . runtimejavaversion > javaversion . version_13 ) { <nl> project . logger . info ( <nl> - " forbidden apis does not support java version past num . will use the signatures from num for " , <nl> + " forbidden apis does not support java version past num . will use the signatures from num for " , <nl> project . runtimejavaversion <nl> ) <nl> - targetcompatibility = javaversion . version_11 . getmajorversion ( ) <nl> + targetcompatibility = javaversion . version_13 . getmajorversion ( ) <nl> } <nl> + * / <nl> } <nl> bundledsignatures = [ <nl> " jdk - unsafe " , " jdk - deprecated " , " jdk - non - portable " , " jdk - system - out " <nl> mmm a / buildsrc / src / testkit / thirdpartyaudit / build . gradle <nl> ppp b / buildsrc / src / testkit / thirdpartyaudit / build . gradle <nl>
public class restindicesaction extends abstractcataction { <nl>  <nl> @ override <nl> public void onfailure ( final exception e ) { <nl> + / / temporary logging to help debug https : / / github . com / elastic / elasticsearch / issues / 45652 <nl> + <nl> + if ( e instanceof indexnotfoundexception ) { <nl> + logger . debug ( " _cat / indices returning index_not_found_exception " , e ) ; <nl> + } <nl> listener . onfailure ( e ) ; <nl> } <nl> } ) ; <nl>
public class restindicesaction extends abstractcataction { <nl>  <nl> @ override <nl> public void onfailure ( final exception e ) { <nl> + / / temporary logging to help debug https : / / github . com / elastic / elasticsearch / issues / 45652 <nl> + <nl> + if ( e instanceof indexnotfoundexception ) { <nl> + logger . debug ( " _cat / indices returning index_not_found_exception " , e ) ; <nl> + } <nl> listener . onfailure ( e ) ; <nl> } <nl> } , size ) ; <nl> mmm a / x - pack / plugin / ml / qa / native - multi - node - tests / build . gradle <nl> ppp b / x - pack / plugin / ml / qa / native - multi - node - tests / build . gradle <nl>
testclusters . integtest { <nl> setting ' xpack . security . audit . enabled ' , ' false ' <nl> setting ' xpack . license . self_generated . type ' , ' trial ' <nl> setting ' xpack . ml . min_disk_space_off_heap ' , ' 200mb ' <nl> + <nl> + setting ' logger . org . elasticsearch . rest . action . cat ' , ' debug ' <nl>  <nl> keystore ' bootstrap . password ' , ' x - pack - test - password ' <nl> keystore ' xpack . security . transport . ssl . secure_key_passphrase ' , ' testnode '
public class elasticsearchnode implements testclusterconfiguration { <nl> / / don ' t wait for state , just start up quickly . this will also allow new and old nodes in the bwc case to become the master <nl> defaultconfig . put ( " discovery . initial_state_timeout " , " 0s " ) ; <nl>  <nl> + <nl> + defaultconfig . put ( " logger . org . elasticsearch . action . support . master " , " debug " ) ; <nl> + defaultconfig . put ( " logger . org . elasticsearch . cluster . coordination " , " debug " ) ; <nl> + <nl> hashset < string > overriden = new hashset < > ( defaultconfig . keyset ( ) ) ; <nl> overriden . retainall ( settings . keyset ( ) ) ; <nl> overriden . removeall ( overridable_settings ) ; <nl> mmm a / server / src / main / java / org / elasticsearch / action / admin / cluster / reroute / transportclusterrerouteaction . java <nl> ppp b / server / src / main / java / org / elasticsearch / action / admin / cluster / reroute / transportclusterrerouteaction . java <nl>
testclusters . integtest { <nl> setting ' xpack . ml . enabled ' , ' false ' <nl> setting ' xpack . license . self_generated . type ' , ' trial ' <nl> setting ' indices . lifecycle . poll_interval ' , ' 1000ms ' <nl> + <nl> + / / the limit simultaneously and the rate limiter then moves to wait minutes to make up for this . <nl> + setting ' thread_pool . snapshot . max ' , ' 1 ' <nl> }
integtestrunner { <nl> systemproperty ' es . set . netty . runtime . available . processors ' , ' false ' <nl> } <nl>  <nl> + taskprovider < test > pooledtest = tasks . register ( " pooledtest " , test ) { <nl> + include ' * * / * tests . class ' <nl> + systemproperty ' es . set . netty . runtime . available . processors ' , ' false ' <nl> + systemproperty ' io . netty . allocator . type ' , ' pooled ' <nl> + } <nl> + <nl> + restintegtesttask pooledintegtest = tasks . create ( " pooledintegtest " , restintegtesttask ) { <nl> + runner { <nl> + systemproperty ' es . set . netty . runtime . available . processors ' , ' false ' <nl> + } <nl> + } <nl> + testclusters . pooledintegtest { <nl> + systemproperty ' io . netty . allocator . type ' , ' pooled ' <nl> + } <nl> + check . dependson ( pooledtest , pooledintegtest ) <nl> + <nl> thirdpartyaudit { <nl> ignoremissingclasses ( <nl> / / classes are missing
public class internalengine extends engine { <nl> } <nl> } <nl>  <nl> + / * * <nl> + * whether we should treat any document failure as tragic error . <nl> + * if we hit any failure while processing an indexing on a replica , we should treat that error as tragic and fail the engine . <nl> + * however , we prefer to fail a request individually ( instead of a shard ) if we hit a document failure on the primary . <nl> + * / <nl> + private boolean treatdocumentfailureastragicerror ( index index ) { <nl> + <nl> + return index . origin ( ) = = operation . origin . replica ; <nl> + } <nl> + <nl> / * * <nl> * returns true if the indexing operation may have already be processed by this engine . <nl> * note that it is ok to rarely return true even if this is not the case . however a ` false ` <nl> mmm a / server / src / test / java / org / elasticsearch / index / engine / internalenginetests . java <nl> ppp b / server / src / test / java / org / elasticsearch / index / engine / internalenginetests . java <nl>
setup : <nl> - match : { datafeeds . 0 . datafeed_id : " datafeed - 1 " } <nl> - match : { datafeeds . 0 . state : " stopped " } <nl> - match : { datafeeds . 0 . timing_stats . job_id : " get - datafeed - stats - 1 " } <nl> - - match : { datafeeds . 0 . timing_stats . search_count : num } <nl> + # <nl> + - gte : { datafeeds . 0 . timing_stats . search_count : num } <nl> - gte : { datafeeds . 0 . timing_stats . total_search_time_ms : num . 0 } <nl>  <nl> mmm
public class dedicatedclustersnapshotrestoreit extends abstractsnapshotintegtest <nl> } <nl>  <nl> logger . info ( " - - > making sure that snapshot no longer exists " ) ; <nl> - assertthrows ( client ( ) . admin ( ) . cluster ( ) . preparegetsnapshots ( " test - repo " ) . setsnapshots ( " test - snap " ) . execute ( ) , <nl> - snapshotmissingexception . class ) ; <nl> + expectthrows ( snapshotmissingexception . class , <nl> + ( ) - > client ( ) . admin ( ) . cluster ( ) . preparegetsnapshots ( " test - repo " ) . setsnapshots ( " test - snap " ) <nl> + . execute ( ) . actionget ( ) . getsnapshots ( " test - repo " ) ) ; <nl> + <nl> + <nl> + logger . info ( " - - > go through a loop of creating and deleting a snapshot to trigger repository cleanup " ) ; <nl> + client ( ) . admin ( ) . cluster ( ) . preparecreatesnapshot ( " test - repo " , " test - snap - tmp " ) <nl> + . setwaitforcompletion ( true ) <nl> + . setindices ( " test - idx " ) <nl> + . get ( ) ; <nl> + client ( ) . admin ( ) . cluster ( ) . preparedeletesnapshot ( " test - repo " , " test - snap - tmp " ) . get ( ) ; <nl> + <nl> / / subtract four files that will remain in the repository : <nl> - / / ( 1 ) index - 1 <nl> - / / ( 2 ) index - 0 ( because we keep the previous version ) and <nl> + / / ( 1 ) index - ( n + 1 ) <nl> + / / ( 2 ) index - n ( because we keep the previous version ) and <nl> / / ( 3 ) index - latest <nl> / / ( 4 ) incompatible - snapshots <nl> assertfilecount ( repo , num ) ;
see { stack - ov } / security - privileges . html [ security privileges ] and <nl>  <nl> = = = = examples <nl>  <nl> + the following example skips for the first five { dataframe - transforms } and <nl> + gets usage information for a maximum of ten results : <nl> + <nl> + [ source , js ] <nl> + - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - <nl> + get _data_frame / transforms / _stats ? from = 5 & size = 10 <nl> + - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - <nl> + / / console <nl> + <nl> + <nl> the following example gets usage information for the ` ecommerce_transform ` <nl> { dataframe - transform } : <nl>  <nl> mmm a / docs / reference / data - frames / apis / get - transform . asciidoc <nl> ppp b / docs / reference / data - frames / apis / get - transform . asciidoc <nl>
import org . elasticsearch . xpack . core . ml . action . mlinfoaction ; <nl> import org . elasticsearch . xpack . core . ml . datafeed . datafeedconfig ; <nl> import org . elasticsearch . xpack . core . ml . job . config . analysislimits ; <nl> import org . elasticsearch . xpack . core . ml . job . config . job ; <nl> + import org . elasticsearch . xpack . ml . process . nativecontroller ; <nl> + import org . elasticsearch . xpack . ml . process . nativecontrollerholder ; <nl>  <nl> + import java . io . ioexception ; <nl> + import java . util . collections ; <nl> import java . util . hashmap ; <nl> import java . util . map ; <nl> + import java . util . concurrent . timeoutexception ; <nl> import java . util . function . supplier ; <nl>  <nl> public class transportmlinfoaction extends handledtransportaction < mlinfoaction . request , mlinfoaction . response > { <nl>  <nl> private final clusterservice clusterservice ; <nl> + private final map < string , object > nativecodeinfo ; <nl>  <nl> @ inject <nl> - public transportmlinfoaction ( transportservice transportservice , actionfilters actionfilters , clusterservice clusterservice ) { <nl> + public transportmlinfoaction ( transportservice transportservice , actionfilters actionfilters , <nl> + clusterservice clusterservice , environment env ) { <nl> super ( mlinfoaction . name , transportservice , actionfilters , ( supplier < mlinfoaction . request > ) mlinfoaction . request : : new ) ; <nl> this . clusterservice = clusterservice ; <nl> + <nl> + try { <nl> + nativecontroller nativecontroller = nativecontrollerholder . getnativecontroller ( clusterservice . getnodename ( ) , env ) ; <nl> + <nl> + if ( nativecontroller ! = null ) { <nl> + nativecodeinfo = nativecontroller . getnativecodeinfo ( ) ; <nl> + } else { <nl> + nativecodeinfo = collections . emptymap ( ) ; <nl> + } <nl> + } catch ( ioexception e ) { <nl> + / / this should not be possible since this action is only registered when ml is enabled , <nl> + / / and the machinelearning plugin would have failed to create components <nl> + throw new illegalstateexception ( " native controller failed to load " , e ) ; <nl> + } catch ( timeoutexception e ) { <nl> + throw new runtimeexception ( " could not get native code info from native controller " , e ) ; <nl> + } <nl> } <nl>  <nl> @ override <nl>
class vagranttestplugin implements plugin < project > { <nl> ' oel - 6 ' , <nl> ' oel - 7 ' , <nl> ' opensuse - 42 ' , <nl> - ' rhel - 8 ' , <nl> + / * <nl> ' sles - 12 ' , <nl> ' ubuntu - 1604 ' , <nl> ' ubuntu - 1804 '
class buildplugin implements plugin < project > { <nl> standardoutput = stdout <nl> } <nl> return integer . parseint ( stdout . tostring ( ' utf - 8 ' ) . trim ( ) ) <nl> + } else { <nl> + / / guess that it is half the number of processors ( which is wrong on systems that do not have simultaneous multi - threading ) <nl> + <nl> + return runtime . getruntime ( ) . availableprocessors ( ) / num <nl> } <nl> - return runtime . getruntime ( ) . availableprocessors ( ) / num <nl> } <nl>  <nl> private static configureprecommit ( project project ) {
public final class attachmentprocessor extends abstractprocessor { <nl> } <nl>  <nl> if ( properties . contains ( property . language ) & & strings . haslength ( parsedcontent ) ) { <nl> + <nl> languageidentifier identifier = new languageidentifier ( parsedcontent ) ; <nl> string language = identifier . getlanguage ( ) ; <nl> additionalfields . put ( property . language . tolowercase ( ) , language ) ; <nl> mmm a / plugins / mapper - size / build . gradle <nl> ppp b / plugins / mapper - size / build . gradle <nl>
public class internalautodatehistogramtests extends internalmultibucketaggregati <nl> assertthat ( result , equalto ( 2 ) ) ; <nl> } <nl>  <nl> + @ override <nl> + @ awaitsfix ( bugurl = " https : / / github . com / elastic / elasticsearch / issues / 39497 " ) <nl> + <nl> + public void testreducerandom ( ) { <nl> + super . testreducerandom ( ) ; <nl> + } <nl> + <nl> @ override <nl> protected void assertreduced ( internalautodatehistogram reduced , list < internalautodatehistogram > inputs ) {
public class shardfollowtask extends immutablefollowparameters implements xpackp <nl> } <nl>  <nl> public static shardfollowtask readfrom ( streaminput in ) throws ioexception { <nl> - return new shardfollowtask ( in . readstring ( ) , shardid . readshardid ( in ) , shardid . readshardid ( in ) , in ) ; <nl> - } <nl> - <nl> - private shardfollowtask ( string remotecluster , shardid followshardid , shardid leadershardid , streaminput in ) throws ioexception { <nl> - super ( in ) ; <nl> - this . remotecluster = remotecluster ; <nl> - this . followshardid = followshardid ; <nl> - this . leadershardid = leadershardid ; <nl> - this . headers = collections . unmodifiablemap ( in . readmap ( streaminput : : readstring , streaminput : : readstring ) ) ; <nl> + string remotecluster = in . readstring ( ) ; <nl> + shardid followshardid = shardid . readshardid ( in ) ; <nl> + shardid leadershardid = shardid . readshardid ( in ) ; <nl> + <nl> + int maxreadrequestoperationcount = in . readvint ( ) ; <nl> + bytesizevalue maxreadrequestsize = new bytesizevalue ( in ) ; <nl> + int maxoutstandingreadrequests = in . readvint ( ) ; <nl> + int maxwriterequestoperationcount = in . readvint ( ) ; <nl> + bytesizevalue maxwriterequestsize = new bytesizevalue ( in ) ; <nl> + int maxoutstandingwriterequests = in . readvint ( ) ; <nl> + int maxwritebuffercount = in . readvint ( ) ; <nl> + bytesizevalue maxwritebuffersize = new bytesizevalue ( in ) ; <nl> + timevalue maxretrydelay = in . readtimevalue ( ) ; <nl> + timevalue readpolltimeout = in . readtimevalue ( ) ; <nl> + map < string , string > headers = collections . unmodifiablemap ( in . readmap ( streaminput : : readstring , streaminput : : readstring ) ) ; <nl> + return new shardfollowtask ( remotecluster , followshardid , leadershardid , maxreadrequestoperationcount , <nl> + maxwriterequestoperationcount , maxoutstandingreadrequests , maxoutstandingwriterequests , maxreadrequestsize , <nl> + maxwriterequestsize , maxwritebuffercount , maxwritebuffersize , maxretrydelay , readpolltimeout , headers ) ; <nl> } <nl>  <nl> public string getremotecluster ( ) { <nl>
public class shardfollowtask extends immutablefollowparameters implements xpackp <nl> out . writestring ( remotecluster ) ; <nl> followshardid . writeto ( out ) ; <nl> leadershardid . writeto ( out ) ; <nl> - super . writeto ( out ) ; <nl> + <nl> + out . writevlong ( getmaxreadrequestoperationcount ( ) ) ; <nl> + getmaxreadrequestsize ( ) . writeto ( out ) ; <nl> + out . writevint ( getmaxoutstandingreadrequests ( ) ) ; <nl> + out . writevlong ( getmaxwriterequestoperationcount ( ) ) ; <nl> + getmaxwriterequestsize ( ) . writeto ( out ) ; <nl> + out . writevint ( getmaxoutstandingwriterequests ( ) ) ; <nl> + out . writevint ( getmaxwritebuffercount ( ) ) ; <nl> + getmaxwritebuffersize ( ) . writeto ( out ) ; <nl> + out . writetimevalue ( getmaxretrydelay ( ) ) ; <nl> + out . writetimevalue ( getreadpolltimeout ( ) ) ; <nl> out . writemap ( headers , streamoutput : : writestring , streamoutput : : writestring ) ; <nl> }
<nl> + / * <nl> + * copyright elasticsearch b . v . and / or licensed to elasticsearch b . v . under one <nl> + * or more contributor license agreements . licensed under the elastic license ; <nl> + * you may not use this file except in compliance with the elastic license . <nl> + * / <nl> + <nl> + package org . elasticsearch . xpack . ccr ; <nl> + <nl> + import org . elasticsearch . common . settings . settings ; <nl> + import org . elasticsearch . plugins . plugin ; <nl> + import org . elasticsearch . test . esintegtestcase ; <nl> + import org . elasticsearch . xpack . core . xpackclientplugin ; <nl> + import org . elasticsearch . xpack . core . xpacksettings ; <nl> + <nl> + import java . util . collection ; <nl> + import java . util . collections ; <nl> + <nl> + public class ccrdisabledit extends esintegtestcase { <nl> + <nl> + public void testclustercanstartwithccrinstalledbutnotenabled ( ) throws exception { <nl> + <nl> + ensuregreen ( ) ; <nl> + } <nl> + <nl> + @ override <nl> + protected settings nodesettings ( int nodeordinal ) { <nl> + return settings . builder ( ) . put ( super . nodesettings ( nodeordinal ) ) . put ( xpacksettings . ccr_enabled_setting . getkey ( ) , true ) <nl> + . put ( xpacksettings . security_enabled . getkey ( ) , false ) . build ( ) ; <nl> + } <nl> + <nl> + @ override <nl> + protected settings transportclientsettings ( ) { <nl> + return settings . builder ( ) . put ( super . transportclientsettings ( ) ) . put ( xpacksettings . security_enabled . getkey ( ) , false ) . build ( ) ; <nl> + } <nl> + <nl> + @ override <nl> + protected collection < class < ? extends plugin > > nodeplugins ( ) { <nl> + return collections . singletonlist ( localstateccr . class ) ; <nl> + } <nl> + <nl> + @ override <nl> + protected collection < class < ? extends plugin > > transportclientplugins ( ) { <nl> + return collections . singletonlist ( xpackclientplugin . class ) ; <nl> + } <nl> + }
public class unusedstateremover implements mldataremover { <nl> } <nl>  <nl> private set < string > getjobids ( ) { <nl> - return mlmetadata . getmlmetadata ( clusterservice . state ( ) ) . getjobs ( ) . keyset ( ) ; <nl> + set < string > jobids = new hashset < > ( ) ; <nl> + <nl> + <nl> + jobids . addall ( mlmetadata . getmlmetadata ( clusterservice . state ( ) ) . getjobs ( ) . keyset ( ) ) ; <nl> + <nl> + batchedjobsiterator jobsiterator = new batchedjobsiterator ( client , anomalydetectorsindex . configindexname ( ) ) ; <nl> + while ( jobsiterator . hasnext ( ) ) { <nl> + deque < job . builder > jobs = jobsiterator . next ( ) ; <nl> + jobs . stream ( ) . map ( job . builder : : getid ) . foreach ( jobids : : add ) ; <nl> + } <nl> + return jobids ; <nl> } <nl>  <nl> private void executedeleteunusedstatedocs ( bulkrequestbuilder deleteunusedstaterequestbuilder , actionlistener < boolean > listener ) {
public final class transportsettings { <nl> / / the scheduled internal ping interval setting , defaults to disabled ( - 1 ) <nl> public static final setting < timevalue > ping_schedule = <nl> timesetting ( " transport . ping_schedule " , timevalue . timevalueseconds ( - 1 ) , setting . property . nodescope ) ; <nl> + <nl> public static final setting < timevalue > tcp_connect_timeout = <nl> timesetting ( " transport . tcp . connect_timeout " , networkservice . tcp_connect_timeout , setting . property . nodescope ) ; <nl> public static final setting < timevalue > connect_timeout =
public class searchit extends esresthighlevelclienttestcase { <nl> countrequest countrequest = new countrequest ( ) ; <nl> countresponse countresponse = execute ( countrequest , highlevelclient ( ) : : count , highlevelclient ( ) : : countasync ) ; <nl> assertcountheader ( countresponse ) ; <nl> + / / add logging to get more info about why https : / / github . com / elastic / elasticsearch / issues / 35644 is failing <nl> + <nl> + if ( countresponse . getcount ( ) ! = num ) { <nl> + searchrequest searchrequest = new searchrequest ( ) ; <nl> + searchrequest . source ( new searchsourcebuilder ( ) . size ( 20 ) ) ; <nl> + searchresponse searchresponse = execute ( searchrequest , highlevelclient ( ) : : search , highlevelclient ( ) : : searchasync ) ; <nl> + logger . info ( " unexpected hit count , was expecting num hits but got : " + searchresponse . tostring ( ) ) ; <nl> + } <nl> assertequals ( 12 , countresponse . getcount ( ) ) ; <nl> }
public class sourceonlysnapshotit extends esintegtestcase { <nl> } <nl> } <nl>  <nl> + public void testtostopsuitefailing ( ) { <nl> + / / this is required because otherwise every test in the suite is muted <nl> + <nl> + } <nl> + <nl> + @ awaitsfix ( bugurl = " https : / / github . com / elastic / elasticsearch / issues / 36330 " ) <nl> public void testsnapshotandrestore ( ) throws exception { <nl> final string sourceidx = " test - idx " ; <nl> boolean requirerouting = randomboolean ( ) ;
public class gatewaymetastate implements clusterstateapplier , coordinationstate . <nl> } <nl>  <nl> try { <nl> + / / hack : this is to ensure that non - master - eligible zen2 nodes always store a current term <nl> + / / that ' s higher than the last accepted term . <nl> + <nl> + if ( event . state ( ) . term ( ) > getcurrentterm ( ) ) { <nl> + innersetcurrentterm ( event . state ( ) . term ( ) ) ; <nl> + } <nl> + <nl> updateclusterstate ( event . state ( ) , event . previousstate ( ) ) ; <nl> incrementalwrite = true ; <nl> } catch ( writestateexception e ) { <nl>
<nl> apply plugin : ' elasticsearch . build ' <nl> apply plugin : ' elasticsearch . test . fixtures ' <nl> + <nl> + <nl> + jarhell . enabled = false
public class multisearchrequest extends actionrequest implements compositeindice <nl> searchrequest . routing ( nodestringvalue ( value , null ) ) ; <nl> } else if ( " allow_partial_search_results " . equals ( entry . getkey ( ) ) ) { <nl> searchrequest . allowpartialsearchresults ( nodebooleanvalue ( value , null ) ) ; <nl> + } else { <nl> + <nl> } <nl> + <nl> } <nl> defaultoptions = indicesoptions . frommap ( source , defaultoptions ) ; <nl> } <nl> mmm a / server / src / main / java / org / elasticsearch / rest / action / search / restmultisearchaction . java <nl> ppp b / server / src / main / java / org / elasticsearch / rest / action / search / restmultisearchaction . java <nl>
<nl> - do : <nl> snapshot . create_repository : <nl> repository : my_repo <nl> + # <nl> + verify : false <nl> body : <nl> type : url <nl> settings :
public class discoverydisruptionit extends abstractdisruptiontestcase { <nl> * test cluster join with issues in cluster state publishing * <nl> * / <nl> public void testclusterjoindespiteofpublishingissues ( ) throws exception { <nl> - string masternode = internalcluster ( ) . startmasteronlynode ( settings . empty ) ; <nl> - string nonmasternode = internalcluster ( ) . startdataonlynode ( settings . empty ) ; <nl> + <nl> + string masternode = internalcluster ( ) . startmasteronlynode ( <nl> + settings . builder ( ) . put ( testzendiscovery . use_zen2 . getkey ( ) , false ) . build ( ) ) ; <nl> + string nonmasternode = internalcluster ( ) . startdataonlynode ( <nl> + settings . builder ( ) . put ( testzendiscovery . use_zen2 . getkey ( ) , false ) . build ( ) ) ; <nl>  <nl> discoverynodes discoverynodes = internalcluster ( ) . getinstance ( clusterservice . class , nonmasternode ) . state ( ) . nodes ( ) ; <nl>  <nl>
public class sslconfigurationreloadertests extends estestcase { <nl> try ( inputstream is = files . newinputstream ( keystorepath ) ) { <nl> keystore . load ( is , keystorepass . tochararray ( ) ) ; <nl> } <nl> - final sslcontext sslcontext = new sslcontextbuilder ( ) . loadkeymaterial ( keystore , keystorepass . tochararray ( ) ) <nl> + <nl> + final sslcontext sslcontext = new sslcontextbuilder ( ) . useprotocol ( " tlsv1 . 2 " ) . loadkeymaterial ( keystore , keystorepass . tochararray ( ) ) <nl> . build ( ) ; <nl> mockwebserver server = new mockwebserver ( sslcontext , false ) ; <nl> server . enqueue ( new mockresponse ( ) . setresponsecode ( 200 ) . setbody ( " body " ) ) ; <nl>
public class sslconfigurationreloadertests extends estestcase { <nl> keystore . load ( null , password . tochararray ( ) ) ; <nl> keystore . setkeyentry ( " testnode_ec " , pemutils . readprivatekey ( keypath , password : : tochararray ) , password . tochararray ( ) , <nl> certparsingutils . readcertificates ( collections . singletonlist ( certpath ) ) ) ; <nl> - final sslcontext sslcontext = new sslcontextbuilder ( ) . loadkeymaterial ( keystore , password . tochararray ( ) ) <nl> + <nl> + final sslcontext sslcontext = new sslcontextbuilder ( ) . useprotocol ( " tlsv1 . 2 " ) . loadkeymaterial ( keystore , password . tochararray ( ) ) <nl> . build ( ) ; <nl> mockwebserver server = new mockwebserver ( sslcontext , false ) ; <nl> server . enqueue ( new mockresponse ( ) . setresponsecode ( 200 ) . setbody ( " body " ) ) ;
dependencies { <nl> / / security deps <nl> shadow ' com . unboundid : unboundid - ldapsdk : 3 . 2 . 0 ' <nl> shadow project ( path : ' : modules : transport - netty4 ' , configuration : ' runtime ' ) <nl> + shadow ( project ( path : ' : plugins : transport - nio ' , configuration : ' runtime ' ) ) { <nl> + <nl> + exclude group : " org . elasticsearch " , module : " elasticsearch - core " <nl> + } <nl>  <nl> testcompile ' org . elasticsearch : securemock : 1 . 2 ' <nl> testcompile " org . elasticsearch : mocksocket : $ { versions . mocksocket } "
public final class internaltestcluster extends testcluster { <nl> final circuitbreakerservice breakerservice = getinstancefromnode ( circuitbreakerservice . class , nodeandclient . node ) ; <nl> circuitbreaker fdbreaker = breakerservice . getbreaker ( circuitbreaker . fielddata ) ; <nl> assertthat ( " fielddata breaker not reset to num on node : " + name , fdbreaker . getused ( ) , equalto ( 0l ) ) ; <nl> - circuitbreaker acctbreaker = breakerservice . getbreaker ( circuitbreaker . accounting ) ; <nl> - assertthat ( " accounting breaker not reset to num on node : " + name , acctbreaker . getused ( ) , equalto ( 0l ) ) ; <nl> + <nl> + / / circuitbreaker acctbreaker = breakerservice . getbreaker ( circuitbreaker . accounting ) ; <nl> + / / assertthat ( " accounting breaker not reset to num on node : " + name , acctbreaker . getused ( ) , equalto ( 0l ) ) ; <nl> / / anything that uses transport or http can increase the <nl> / / request breaker ( because they use bigarrays ) , because of <nl> / / that the breaker can sometimes be incremented from ping
if ( iseclipse ) { <nl> compilejava . options . compilerargs < < " - xlint : - cast , - deprecation , - rawtypes , - try , - unchecked " <nl> compiletestjava . options . compilerargs < < " - xlint : - cast , - deprecation , - rawtypes , - try , - unchecked " <nl>  <nl> + <nl> + additionaltest ( ' testscriptdocvaluesmissingv6behaviour ' ) { <nl> + include ' * * / scriptdocvaluesmissingv6behaviourtests . class ' <nl> + systemproperty ' es . scripting . exception_for_missing_value ' , ' false ' <nl> + } <nl> + test { <nl> + / / these are tested explicitly in separate test tasks <nl> + exclude ' * * / * scriptdocvaluesmissingv6behaviourtests . class ' <nl> + } <nl> + <nl> forbiddenpatterns { <nl> exclude ' * * / * . json ' <nl> exclude ' * * / * . jmx ' <nl>
public final class engineconfig { <nl> this . codecservice = codecservice ; <nl> this . eventlistener = eventlistener ; <nl> codecname = indexsettings . getvalue ( index_codec_setting ) ; <nl> - / / we give indexwriter a " huge " ( 256 mb ) buffer , so it won ' t flush on its own unless the es indexing buffer is also huge and / or <nl> - / / there are not too many shards allocated to this node . instead , indexingmemorycontroller periodically checks <nl> - / / and refreshes the most heap - consuming shards when total indexing heap usage across all shards is too high : <nl> - indexingbuffersize = new bytesizevalue ( 256 , bytesizeunit . mb ) ; <nl> + / / we need to make the indexing buffer for this shard at least as large <nl> + / / as the amount of memory that is available for all engines on the <nl> + / / local node so that decisions to flush segments to disk are made by <nl> + / / indexingmemorycontroller rather than lucene . <nl> + / / add an escape hatch in case this change proves problematic - it used <nl> + / / to be a fixed amound of ram : num mb . <nl> + <nl> + final string escapehatchproperty = " es . index . memory . max_index_buffer_size " ; <nl> + string maxbuffersize = system . getproperty ( escapehatchproperty ) ; <nl> + if ( maxbuffersize ! = null ) { <nl> + indexingbuffersize = memorysizevalue . parsebytessizevalueorheapratio ( maxbuffersize , escapehatchproperty ) ; <nl> + } else { <nl> + indexingbuffersize = indexingmemorycontroller . index_buffer_size_setting . get ( indexsettings . getnodesettings ( ) ) ; <nl> + } <nl> this . querycache = querycache ; <nl> this . querycachingpolicy = querycachingpolicy ; <nl> this . translogconfig = translogconfig ;
<nl> [ [ sql - data - types ] ] <nl> = = = data type and mapping <nl>  <nl> + <nl> list of data types in sql and how they actually map to elasticsearch . <nl> - also mention the corner cases - multi - fields , names with dots , etc . . . <nl> \ no newline at end of file <nl> + also mention the corner cases - multi - fields , names with dots , etc . . . <nl> mmm a / docs / en / sql / language / syntax . asciidoc <nl> ppp b / docs / en / sql / language / syntax . asciidoc <nl>
public class datetimeformattertimestampconverter implements timestampconverter { <nl> if ( hastimezone ) { <nl> return instant . from ( parsed ) ; <nl> } <nl> + return toinstantunsafelyignoringambiguity ( parsed ) ; <nl> + } <nl> + <nl> + @ suppressforbidden ( reason = " <nl> + private instant toinstantunsafelyignoringambiguity ( temporalaccessor parsed ) { <nl> return localdatetime . from ( parsed ) . atzone ( defaultzoneid ) . toinstant ( ) ; <nl> } <nl> }
public class detector implements toxcontentobject , writeable { <nl> public static final parsefield partition_field_name_field = new parsefield ( " partition_field_name " ) ; <nl> public static final parsefield use_null_field = new parsefield ( " use_null " ) ; <nl> public static final parsefield exclude_frequent_field = new parsefield ( " exclude_frequent " ) ; <nl> - public static final parsefield rules_field = new parsefield ( " rules " ) ; <nl> + <nl> + public static final parsefield rules_field = new parsefield ( " rules " , " detector_rules " ) ; <nl> public static final parsefield detector_index = new parsefield ( " detector_index " ) ; <nl>  <nl> / / these parsers follow the pattern that metadata is parsed leniently ( to allow for enhancements ) , whilst config is parsed strictly
public abstract class estestcase extends lucenetestcase { <nl>  <nl> @ beforeclass <nl> public static void setusenio ( ) throws exception { <nl> - usenio = randomboolean ( ) ; <nl> + / / usenio = randomboolean ( ) ; <nl> + <nl> + usenio = false ; <nl> } <nl>  <nl> public static string gettesttransporttype ( ) {
public class testtranslog { <nl> assertthat ( " no translog file corrupted " , corruptedfiles , not ( empty ( ) ) ) ; <nl> return corruptedfiles ; <nl> } <nl> + <nl> + / * * <nl> + * lists all existing commits in a given <nl> + * / <nl> + private static long mintransloggenusedinrecovery ( path indexpath ) throws ioexception { <nl> + try ( niofsdirectory directory = new niofsdirectory ( indexpath ) ) { <nl> + final list < indexcommit > commits = directoryreader . listcommits ( directory ) ; <nl> + <nl> + final indexcommit recoveringcommit = commits . get ( commits . size ( ) - num ) ; <nl> + return long . parselong ( recoveringcommit . getuserdata ( ) . get ( translog . translog_generation_key ) ) ; <nl> + } <nl> + } <nl> }
case $ key in <nl> " - dtests . badapples = true " <nl> ) <nl> ; ; <nl> + smoketestsql ) # <nl> + gradle_cli_args = ( <nl> + " - - info " <nl> + " - psql " <nl> + " check " <nl> + " : x - pack - elasticsearch : plugin : precommit " <nl> + " : x - pack - elasticsearch : qa : sql : check " <nl> + " : x - pack - elasticsearch : qa : sql : multinode : check " <nl> + " : x - pack - elasticsearch : qa : sql : no - security : check " <nl> + " : x - pack - elasticsearch : qa : sql : security : check " <nl> + " : x - pack - elasticsearch : qa : sql : security : no - ssl : check " <nl> + " : x - pack - elasticsearch : qa : sql : security : ssl : check " <nl> + ) <nl> + ; ; <nl> releasetest ) <nl> gradle_cli_args = ( <nl> " - - info " <nl>
score and time constraints : <nl> { <nl> " timestamp " : num , <nl> " bucket_span " : num , <nl> - " overall_score " : num . 0 , <nl> + " overall_score " : num . 0 , <nl> + " jobs " : [ <nl> + { <nl> + " job_id " : " job - 1 " , <nl> + " max_anomaly_score " : num . 0 <nl> + } , <nl> + { <nl> + " job_id " : " job - 2 " , <nl> + " max_anomaly_score " : num . 0 <nl> + } , <nl> + { <nl> + " job_id " : " job - 3 " , <nl> + " max_anomaly_score " : num . 0 <nl> + } <nl> + ] , <nl> + " is_interim " : false , <nl> + " result_type " : " overall_bucket " <nl> + } <nl> + ] <nl> + } <nl> + - - - - <nl> + <nl> + the next example is similar but this time ` top_n ` is set to ` 2 ` : <nl> + <nl> + [ source , js ] <nl> + - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - <nl> + get _xpack / ml / anomaly_detectors / job - * / results / overall_buckets <nl> + { <nl> + " top_n " : num , <nl> + " overall_score " : num . 0 , <nl> + " start " : " 1403532000000 " <nl> + } <nl> + - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - <nl> + / / console <nl> + <nl> + <nl> + note how the ` overall_score ` is now the average of the top num job scores : <nl> + [ source , js ] <nl> + - - - - <nl> + { <nl> + " count " : num , <nl> + " overall_buckets " : [ <nl> + { <nl> + " timestamp " : num , <nl> + " bucket_span " : num , <nl> + " overall_score " : num . 0 , <nl> " jobs " : [ <nl> { <nl> " job_id " : " job - 1 " , <nl> mmm a / docs / en / rest - api / ml / get - record . asciidoc <nl> ppp b / docs / en / rest - api / ml / get - record . asciidoc <nl>
public class transportbulkshardoperationsaction <nl> final bulkshardoperationsrequest request , final indexshard shard , final engine . operation . origin origin ) throws ioexception { <nl> translog . location location = null ; <nl> for ( final translog . operation operation : request . getoperations ( ) ) { <nl> - final engine . result result = shard . applytranslogoperation ( operation , origin , m - > { } ) ; <nl> + final engine . result result = shard . applytranslogoperation ( operation , origin , m - > { <nl> + <nl> + throw new mapperexception ( " dynamic mapping updates are not allowed in follow shards [ " + operation + " ] " ) ; <nl> + } ) ; <nl> assert result . getseqno ( ) = = operation . seqno ( ) ; <nl> assert result . hasfailure ( ) = = false ; <nl> location = locationtosync ( location , result . gettransloglocation ( ) ) ;
get two : logs - 2017 . 04 / _search < 1 > <nl> } <nl> } <nl> - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - <nl> + / / console <nl> + <nl> / / tbd : is there a missing description of the < 1 > callout above ? <nl>  <nl> include : : { xkb - repo - dir } / security / cross - cluster - kibana . asciidoc [ ]
class combineddeletionpolicy extends indexdeletionpolicy { <nl> } <nl>  <nl> private void setlastcommittedtransloggeneration ( list < ? extends indexcommit > commits ) throws ioexception { <nl> - / / when opening an existing lucene index , we currently always open the last commit . <nl> - / / we therefore use the translog gen as the one that will be required for recovery <nl> - final indexcommit indexcommit = commits . get ( commits . size ( ) - num ) ; <nl> - assert indexcommit . isdeleted ( ) = = false : " last commit is deleted " ; <nl> - long mingen = long . parselong ( indexcommit . getuserdata ( ) . get ( translog . translog_generation_key ) ) ; <nl> - translogdeletionpolicy . setmintransloggenerationforrecovery ( mingen ) ; <nl> + / / we need to keep translog since the smallest translog generation of un - deleted commits . <nl> + / / however , there are commits that are not deleted just because they are being snapshotted ( rather than being kept by the policy ) . <nl> + <nl> + long minrequiredgen = long . max_value ; <nl> + for ( indexcommit indexcommit : commits ) { <nl> + if ( indexcommit . isdeleted ( ) = = false ) { <nl> + long transloggen = long . parselong ( indexcommit . getuserdata ( ) . get ( translog . translog_generation_key ) ) ; <nl> + minrequiredgen = math . min ( transloggen , minrequiredgen ) ; <nl> + } <nl> + } <nl> + assert minrequiredgen ! = long . max_value : " all commits are deleted " ; <nl> + translogdeletionpolicy . setmintransloggenerationforrecovery ( minrequiredgen ) ; <nl> } <nl>  <nl> public snapshotdeletionpolicy getindexdeletionpolicy ( ) { <nl> mmm a / core / src / test / java / org / elasticsearch / index / engine / combineddeletionpolicytests . java <nl> ppp b / core / src / test / java / org / elasticsearch / index / engine / combineddeletionpolicytests . java <nl>
public class remotefailure { <nl> responsemessage = builder . tostring ( ) ; <nl> } <nl> } catch ( ioexception replayexception ) { <nl> - / / nocommit check for failed reset and return different error <nl> + <nl> responsemessage = " attempted to include response but failed because [ " + replayexception . getmessage ( ) + " ] . " ; <nl> } <nl> string parserlocation = " " ;
public final class proto extends abstractproto { <nl> meta_column ( metacolumnrequest : : new ) , <nl> query_init ( queryinitrequest : : new ) , <nl> query_page ( querypagerequest : : new ) , <nl> - / / query_close ( queryclosenrequest : : new ) , nocommit implement me <nl> + <nl> ; <nl>  <nl> private final requestreader reader ; <nl> mmm a / sql / server / src / main / java / org / elasticsearch / xpack / sql / session / rowset . java <nl> ppp b / sql / server / src / main / java / org / elasticsearch / xpack / sql / session / rowset . java <nl>
public abstract class sqlspectestcase extends specbaseintegrationtestcase { <nl> try ( connection h2 = h2 . get ( ) ; <nl> connection es = esjdbc ( ) ) { <nl>  <nl> + <nl> + ( ( jdbcconnection ) es ) . settimezone ( timezone . gettimezone ( " utc " ) ) ; <nl> + <nl> resultset expected , elasticresults ; <nl> expected = executejdbcquery ( h2 , query ) ; <nl> elasticresults = executejdbcquery ( es , query ) ;
public class showcolumns extends command { <nl>  <nl> @ override <nl> public list < attribute > output ( ) { <nl> - return aslist ( new rootfieldattribute ( location ( ) , " column " , datatypes . keyword ) , <nl> - new rootfieldattribute ( location ( ) , " type " , datatypes . keyword ) ) ; <nl> + return aslist ( new rootfieldattribute ( location ( ) , " column " , datatypes . keyword ) , <nl> + new rootfieldattribute ( location ( ) , " type " , datatypes . keyword ) ) ; <nl> + } <nl> + <nl> + @ override <nl> + public void execute ( sqlsession session , actionlistener < rowset > listener ) { <nl> + session . getindices ( new string [ ] { index } , indicesoptions . strictexpandopenandforbidclosed ( ) , actionlistener . wrap ( <nl> + esindices - > { <nl> + list < list < ? > > rows = new arraylist < > ( ) ; <nl> + if ( esindices . isempty ( ) = = false ) { <nl> + <nl> + fillinrows ( esindices . get ( 0 ) . mapping ( ) , null , rows ) ; <nl> + } <nl> + listener . onresponse ( rows . of ( output ( ) , rows ) ) ; <nl> + } , <nl> + listener : : onfailure <nl> + ) ) ; <nl> } <nl>  <nl> @ override <nl> protected rowset execute ( sqlsession session ) { <nl> - list < list < ? > > rows = new arraylist < > ( ) ; <nl> - esindex fetched ; <nl> - try { <nl> - fetched = session . getindexsync ( index ) ; <nl> - } catch ( sqlillegalargumentexception e ) { <nl> - throw new illegalargumentexception ( e ) ; <nl> - } <nl> - if ( fetched ! = null ) { <nl> - fillinrows ( fetched . mapping ( ) , null , rows ) ; <nl> - } <nl> - return rows . of ( output ( ) , rows ) ; <nl> + throw new unsupportedoperationexception ( " no synchronous exec " ) ; <nl> } <nl>  <nl> private void fillinrows ( map < string , datatype > mapping , string prefix , list < list < ? > > rows ) { <nl>
public abstract class datetimefunction extends unaryscalarfunction implements ti <nl>  <nl> @ override <nl> protected scripttemplate asscriptfrom ( fieldattribute field ) { <nl> - / / nocommit i think we should investigate registering sql as a script engine so we don ' t need to generate painless <nl> + <nl> return new scripttemplate ( createtemplate ( ) , <nl> paramsbuilder ( ) <nl> . variable ( field . name ( ) ) <nl>
public abstract class datetimefunction extends unaryscalarfunction implements ti <nl> if ( datetimezone . utc . equals ( timezone ) ) { <nl> return formattemplate ( " doc [ { } ] . value . get " + extractfunction ( ) + " ( ) " ) ; <nl> } else { <nl> - / / nocommit ewwww <nl> + <nl> / * this uses the java num time api because painless doesn ' t whitelist creation of new <nl> * joda classes . * / <nl>  <nl> mmm a / sql / server / src / main / java / org / elasticsearch / xpack / sql / plugin / abstractsqlserver . java <nl> ppp b / sql / server / src / main / java / org / elasticsearch / xpack / sql / plugin / abstractsqlserver . java <nl>
public class clientexception extends runtimeexception { <nl> super ( message ) ; <nl> } <nl>  <nl> - public clientexception ( string message , object . . . args ) { / / nocommit these are not popular in core any more . . . . <nl> + public clientexception ( string message , object . . . args ) { <nl> super ( format ( locale . root , message , args ) ) ; <nl> }
public abstract class abstractproto { <nl> throw new ioexception ( " response version [ " + version + " ] does not match client version [ " <nl> + current_version + " ] . server is busted . " ) ; <nl> } <nl> - / / nocommit why do i need the response type at all ? just a byte for err / exception / normal , then get response type from request . <nl> + <nl> response response = readresponsetype ( in ) . reader ( ) . read ( request , in ) ; <nl> if ( response . requesttype ( ) ! = request . requesttype ( ) ) { <nl> throw new ioexception ( " expected request type to be [ " + request . requesttype ( ) <nl> mmm a / sql / shared - proto / src / main / java / org / elasticsearch / xpack / sql / protocol / shared / timeoutinfo . java <nl> ppp b / sql / shared - proto / src / main / java / org / elasticsearch / xpack / sql / protocol / shared / timeoutinfo . java <nl>
public class fullclusterrestartit extends esresttestcase { <nl> } <nl> } <nl>  <nl> + public void testsqlfailsonindexwithtwotypes ( ) throws ioexception { <nl> + <nl> + assumetrue ( " it is only possible to build an <nl> + oldclusterversion . onorafter ( version . v_6_0_0_alpha1 ) ) ; <nl> + if ( runningagainstoldcluster ) { <nl> + client ( ) . performrequest ( " post " , " / testsqlfailsonindexwithtwotypes / type1 " , emptymap ( ) , new stringentity ( " { } " ) ) ; <nl> + client ( ) . performrequest ( " post " , " / testsqlfailsonindexwithtwotypes / type2 " , emptymap ( ) , new stringentity ( " { } " ) ) ; <nl> + return ; <nl> + } <nl> + responseexception e = expectthrows ( responseexception . class , ( ) - > client ( ) . performrequest ( " post " , " / _sql " , emptymap ( ) , <nl> + new stringentity ( " { \ " query \ " : \ " select * from testsqlfailsonindexwithtwotypes \ " } " ) ) ) ; <nl> + assertequals ( 400 , e . getresponse ( ) . getstatusline ( ) . getstatuscode ( ) ) ; <nl> + assertthat ( e . getmessage ( ) , containsstring ( " invalid <nl> + } <nl> + <nl> private string loadwatch ( string watch ) throws ioexception { <nl> return streamsutils . copytostringfromclasspath ( " / org / elasticsearch / xpack / restart / " + watch ) ; <nl> } <nl> mmm a / sql / jdbc / src / test / java / org / elasticsearch / xpack / sql / jdbc / errorsit . java <nl> ppp b / sql / jdbc / src / test / java / org / elasticsearch / xpack / sql / jdbc / errorsit . java <nl>
public class versiontests extends estestcase { <nl> assertthat ( version . fromstring ( " 2 . 3 . 0 " ) . minimumcompatibilityversion ( ) , equalto ( major ) ) ; <nl> / / from num . 0 on we are supporting the latest minor of the previous major . . . this might fail once we add a new version ie . num . x is <nl> / / released since we need to bump the supported minor in version # minimumcompatibilityversion ( ) <nl> - version lastversion = versionutils . getpreviousversion ( version . v_6_0_0_alpha1 ) ; <nl> + version lastversion = version . v_5_6_0 ; <nl> assertequals ( lastversion . major , version . v_6_0_0_beta1 . minimumcompatibilityversion ( ) . major ) ; <nl> assertequals ( " did you miss to bump the minor in version # minimumcompatibilityversion ( ) " , <nl> lastversion . minor , version . v_6_0_0_beta1 . minimumcompatibilityversion ( ) . minor ) ; <nl>
public class securitytribeit extends nativerealmintegtestcase { <nl> tribe1defaults . put ( " tribe . t1 . " + entry . getkey ( ) , entry . getvalue ( ) ) ; <nl> tribe2defaults . put ( " tribe . t2 . " + entry . getkey ( ) , entry . getvalue ( ) ) ; <nl> } <nl> + <nl> + mocksecuresettings securesettingstemplate = <nl> + ( mocksecuresettings ) settings . builder ( ) . put ( cluster2settingssource . nodesettings ( 0 ) ) . getsecuresettings ( ) ; <nl> + mocksecuresettings securesettings = new mocksecuresettings ( ) ; <nl> + for ( string settingname : securesettingstemplate . getsettingnames ( ) ) { <nl> + string settingvalue = securesettingstemplate . getstring ( settingname ) . tostring ( ) ; <nl> + securesettings . setstring ( settingname , settingvalue ) ; <nl> + securesettings . setstring ( " tribe . t1 . " + settingname , settingvalue ) ; <nl> + securesettings . setstring ( " tribe . t2 . " + settingname , settingvalue ) ; <nl> + } <nl>  <nl> settings merged = settings . builder ( ) <nl> . put ( internalcluster ( ) . getdefaultsettings ( ) ) <nl>
include : : { xkb - repo - dir } / reporting / watch - example . asciidoc [ ] <nl>  <nl> include : : { xkb - repo - dir } / reporting / report - intervals . asciidoc [ ] <nl>  <nl> - for more information , see <nl> - { kibana - ref } / automating - report - generation . html [ automating report generation ] . <nl> + <nl> + / / { kibana - ref } / automating - report - generation . html [ automating report generation ] . <nl>  <nl> [ [ email - action - attributes ] ] <nl> = = = = email action attributes
index sorting supports the following settings : <nl> [ warning ] <nl> index sorting can be defined only once at <nl> a sort on an existing index . <nl> + <nl> + <nl> + <nl> + [ [ index - modules - index - sorting - conjunctions ] ] <nl> + = = = use <nl> + <nl> + index sorting can be useful in order to organize lucene doc ids ( not to be <nl> + conflated with ` _id ` ) in a way that makes conjunctions ( a and b and . . . ) more <nl> + efficient . in order to be efficient , conjunctions rely on the fact that if any <nl> + clause does not match , then the entire conjunction does not match . by using <nl> + <nl> + help skip efficiently over large ranges of doc ids that do not match the <nl> + conjunction . <nl> + <nl> + this trick only works with low - cardinality fields . a rule of thumb is that <nl> + you should sort first on fields that both have a low cardinality and are <nl> + frequently used for filtering . the sort order ( ` asc ` or ` desc ` ) does not <nl> + matter as we only care about putting values that would match the same clauses <nl> + close to each other . <nl> + <nl> + for instance if you were indexing cars for sale , it might be interesting to <nl> + sort by fuel type , body type , make , year of registration and finally mileage . <nl> +
public class xpackrestit extends xpackresttestcase { <nl> } <nl>  <nl> / * * <nl> - * disable monitoring <nl> + * cleanup after tests . <nl> + * <nl> + * feature - specific cleanup methods should be called from here rather than using <nl> + * separate @ after annotated methods to ensure there is a well - defined cleanup order . <nl> * / <nl> @ after <nl> - public void disablemonitoring ( ) throws exception { <nl> + public void cleanup ( ) throws exception { <nl> + disablemonitoring ( ) ; <nl> + / / this also generically waits for pending tasks to complete , so must go last ( otherwise <nl> + / / it could be waiting for pending tasks while monitoring is still running ) . <nl> + <nl> + clearmlstate ( ) ; <nl> + } <nl> + <nl> + / * * <nl> + * disable monitoring <nl> + * / <nl> + private void disablemonitoring ( ) throws exception { <nl> if ( ismonitoringtest ( ) ) { <nl> final map < string , object > settings = new hashmap < > ( ) ; <nl> settings . put ( " xpack . monitoring . collection . interval " , ( string ) null ) ; <nl>
public class relocationit extends esintegtestcase { <nl>  <nl> / / refresh is a replication action so this forces a global checkpoint sync which is needed as these are asserted on in tear down <nl> client ( ) . admin ( ) . indices ( ) . preparerefresh ( " test " ) . get ( ) ; <nl> + / * <nl> + * we have to execute a second refresh as in the face of relocations , the relocation target is not aware of the in - sync set and so <nl> + * the first refresh would bring back the local checkpoint for any shards added to the in - sync set that the relocation target was <nl> + * not tracking . <nl> + * / <nl> + <nl> + client ( ) . admin ( ) . indices ( ) . preparerefresh ( " test " ) . get ( ) ; <nl>  <nl> }
public class indexshard extends abstractindexshardcomponent implements indicescl <nl>  <nl> private boolean assertmaxunsafeautoidincommit ( ) throws ioexception { <nl> final map < string , string > userdata = segmentinfos . readlatestcommit ( store . directory ( ) ) . getuserdata ( ) ; <nl> - if ( recoverystate ( ) . getrecoverysource ( ) . gettype ( ) = = recoverysource . type . peer ) { <nl> + if ( indexsettings . getindexversioncreated ( ) . onorafter ( version . v_5_5_0_unreleased ) & & <nl> + <nl> + recoverystate ( ) . getrecoverysource ( ) . gettype ( ) ! = recoverysource . type . local_shards ) { <nl> / / as of num . 5 . 0 , the engine stores the maxunsafeautoidtimestamp in the commit point . <nl> / / this should have baked into the commit by the primary we recover from , regardless of the <nl> - assert userdata . containskey ( internalengine . max_unsafe_auto_id_timestamp_commit_id ) : <nl> - " recovery from remote but " + internalengine . max_unsafe_auto_id_timestamp_commit_id + " is not found in commit " ; <nl> - } else if ( recoverystate ( ) . getrecoverysource ( ) . gettype ( ) = = recoverysource . type . existing_store & & <nl> - indexsettings . getindexversioncreated ( ) . onorafter ( version . v_5_5_0_unreleased ) ) { <nl> assert userdata . containskey ( internalengine . max_unsafe_auto_id_timestamp_commit_id ) : <nl> " opening <nl> + " is not found in commit " ;
teardown : <nl> - match : { hits . total : num } <nl> - match : { hits . hits . 0 . _source . filter_field : num } <nl> - match : { hits . hits . 0 . _index : " my_remote_cluster : test_index " } <nl> + <nl> + mmm <nl> + " search across clusters via a secured alias " : <nl> + <nl> + - do : <nl> + headers : { authorization : " basic am9lonmza3jpda = = " } <nl> + search : <nl> + index : my_remote_cluster : secure_alias # <nl> + <nl> + - match : { _shards . total : num } <nl> + - match : { hits . total : num } <nl> + - is_true : hits . hits . 0 . _source . secure <nl> + - match : { hits . hits . 0 . _index : " my_remote_cluster : secured_via_alias " } <nl> + <nl> mmm a / qa / multi - cluster - search - security / src / test / resources / rest - api - spec / test / remote_cluster / 10_basic . yaml <nl> ppp b / qa / multi - cluster - search - security / src / test / resources / rest - api - spec / test / remote_cluster / 10_basic . yaml <nl>
public final class searchphasecontroller extends abstractcomponent { <nl> scoredoc sharddoc = sorteddocs [ scoredocindex ] ; <nl> searchphaseresult searchresultprovider = resultslookup . apply ( sharddoc . shardindex ) ; <nl> if ( searchresultprovider = = null ) { <nl> + / / this can happen if we are hitting a shard failure during the fetch phase <nl> + / / in this case we referenced the shard result via teh scoredoc but never got a <nl> + / / result from fetch . <nl> + <nl> continue ; <nl> } <nl> fetchsearchresult fetchresult = searchresultprovider . fetchresult ( ) ; <nl>
public final class searchphasecontroller extends abstractcomponent { <nl> scoredoc sharddoc = sorteddocs [ i ] ; <nl> searchphaseresult fetchresultprovider = resultslookup . apply ( sharddoc . shardindex ) ; <nl> if ( fetchresultprovider = = null ) { <nl> + / / this can happen if we are hitting a shard failure during the fetch phase <nl> + / / in this case we referenced the shard result via teh scoredoc but never got a <nl> + / / result from fetch . <nl> + <nl> continue ; <nl> } <nl> fetchsearchresult fetchresult = fetchresultprovider . fetchresult ( ) ;
public class mapperqueryparser extends analyzingqueryparser { <nl> @ override <nl> protected query getwildcardquery ( string field , string termstr ) throws parseexception { <nl> if ( termstr . equals ( " * " ) & & field ! = null ) { <nl> - if ( " * " . equals ( field ) ) { <nl> + / * * <nl> + * we rewrite _all : * to a match all query . <nl> + * <nl> + * / <nl> + if ( " * " . equals ( field ) | | allfieldmapper . name . equals ( field ) ) { <nl> return newmatchalldocsquery ( ) ; <nl> } <nl> string actualfield = field ; <nl> mmm a / core / src / test / java / org / elasticsearch / index / query / querystringquerybuildertests . java <nl> ppp b / core / src / test / java / org / elasticsearch / index / query / querystringquerybuildertests . java <nl>
integtest { <nl> / / know whether to expect an authorization exception or a validation exception <nl> integtestrunner { <nl> systemproperty ' tests . rest . blacklist ' , [ <nl> + <nl> + ' ml / jobs_crud / test close job ' , <nl> + ' ml / jobs_crud / test force close job ' , <nl> + ' ml / start_stop_datafeed / test force stop datafeed ' , <nl> + / / non - temporary <nl> ' ml / datafeeds_crud / test delete datafeed with missing id ' , <nl> ' ml / datafeeds_crud / test put datafeed referring to missing job_id ' , <nl> ' ml / datafeeds_crud / test put datafeed with invalid query ' , <nl> mmm a / qa / smoke - test - ml - with - security / src / test / java / org / elasticsearch / xpack / ml / integration / mlrestteststatecleaner . java <nl> ppp b / qa / smoke - test - ml - with - security / src / test / java / org / elasticsearch / xpack / ml / integration / mlrestteststatecleaner . java <nl>
public class job extends abstractdiffable < job > implements writeable , toxcontent <nl>  <nl> private final string jobid ; <nl> private final string description ; <nl> - / / norelease : use jodatime instead <nl> + <nl> private final date createtime ; <nl> private final date finishedtime ; <nl> private final date lastdatatime ; <nl> mmm a / plugin / src / main / java / org / elasticsearch / xpack / ml / job / process / autodetect / state / datacounts . java <nl> ppp b / plugin / src / main / java / org / elasticsearch / xpack / ml / job / process / autodetect / state / datacounts . java <nl>
public class datacounts extends toxcontenttobytes implements writeable { <nl> private long emptybucketcount ; <nl> private long sparsebucketcount ; <nl> private long bucketcount ; <nl> - / / norelease : use jodatime instead <nl> + <nl> private date earliestrecordtimestamp ; <nl> private date latestrecordtimestamp ; <nl> private date lastdatatimestamp ; <nl> mmm a / plugin / src / main / java / org / elasticsearch / xpack / ml / job / process / autodetect / state / modelsizestats . java <nl> ppp b / plugin / src / main / java / org / elasticsearch / xpack / ml / job / process / autodetect / state / modelsizestats . java <nl>
extends action < revertmodelsnapshotaction . request , revertmodelsnapshotaction . resp <nl>  <nl> logger . info ( " deleting results after ' " + deleteafter + " ' " ) ; <nl>  <nl> - / / norelease : jobdatadeleter is basically delete - by - query . <nl> - / / we should replace this whole abstraction with dbq eventually <nl> + <nl> jobdatadeleter datadeleter = new jobdatadeleter ( client , jobid ) ; <nl> datadeleter . deleteresultsfromtime ( deleteafter . gettime ( ) + num , new actionlistener < boolean > ( ) { <nl> @ override
setup : <nl> job_id : " farequote " <nl> - match : { acknowledged : true } <nl>  <nl> - - do : <nl> - indices . refresh : { } <nl> + # <nl> + # we ' d have a way to wait for delete_job to finish its work , but for now just assert some <nl> + # other things before refreshing the indexes to give time for delete_job to do its work <nl>  <nl> - do : <nl> indices . exists : <nl> index : " . ml - anomalies - shared " <nl> - is_true : ' ' <nl>  <nl> + - do : <nl> + indices . refresh : { } <nl> + <nl> - do : <nl> count : <nl> index : . ml - anomalies - shared <nl>
setup : <nl> job_id : " farequote2 " <nl> - match : { acknowledged : true } <nl>  <nl> - - do : <nl> - indices . refresh : { } <nl> + # <nl> + # we ' d have a way to wait for delete_job to finish its work , but for now just assert some <nl> + # other things before refreshing the indexes to give time for delete_job to do its work <nl>  <nl> - do : <nl> indices . exists : <nl>
setup : <nl> job_id : " farequote " <nl> - match : { acknowledged : true } <nl>  <nl> + # <nl> + # we ' d have a way to wait for delete_job to finish its work , but for now just assert some <nl> + # other things before refreshing the indexes to give time for delete_job to do its work <nl> + <nl> - do : <nl> - indices . refresh : { } <nl> + indices . exists : <nl> + index : " . ml - anomalies - shared " <nl> + - is_true : ' ' <nl> + <nl> + - do : <nl> + indices . exists : <nl> + index : " . ml - anomalies - foo " <nl> + - is_true : ' ' <nl> + <nl> + - do : <nl> + indices . exists : <nl> + index : " foo " <nl> + - is_true : ' ' <nl> + <nl> + - do : <nl> + indices . refresh : { } <nl>  <nl> - do : <nl> count : <nl>
def provision ( config , <nl> rm - rf / tmp / gradle . zip <nl> ln - s / opt / gradle - 3 . 3 / bin / gradle / usr / bin / gradle <nl> # make nfs mounted gradle home dir writeable <nl> - chown vagrant : vagrant / home / vagrant / . gradle <nl> + # <nl> + chown vagrant / home / vagrant / . gradle <nl> }
class vagranttestplugin implements plugin < project > { <nl> static list < string > boxes = [ <nl> ' centos - 6 ' , <nl> ' centos - 7 ' , <nl> - ' debian - 8 ' , <nl> + <nl> ' fedora - 24 ' , <nl> ' oel - 6 ' , <nl> ' oel - 7 ' ,
public class auditor { <nl> } <nl>  <nl> private void indexdoc ( string type , toxcontent toxcontent ) { <nl> - client . prepareindex ( notifications_index , type ) <nl> + <nl> + client . prepareindex ( notifications_index , type , uuids . base64uuid ( ) ) <nl> . setsource ( toxcontentbuilder ( toxcontent ) ) <nl> . execute ( new actionlistener < indexresponse > ( ) { <nl> @ override
public class jobresultspersister extends abstractcomponent { <nl> this . jobid = jobid ; <nl> this . object = object ; <nl> this . type = type ; <nl> - this . id = id ; <nl> + <nl> + this . id = id ! = null ? id : uuids . base64uuid ( ) ; <nl> } <nl>  <nl> boolean persist ( string indexname ) {
abstract class abstractsearchasyncaction < firstresult extends searchphaseresult > <nl>  <nl> void performfirstphase ( final int shardindex , final sharditerator shardit , final shardrouting shard ) { <nl> if ( shard = = null ) { <nl> + <nl> / / no more active shards . . . ( we should not really get here , but just for safety ) <nl> onfirstphaseresult ( shardindex , null , null , shardit , new noshardavailableactionexception ( shardit . shardid ( ) ) ) ; <nl> } else { <nl> - final transport . connection connection = nodeidtoconnection . apply ( shard . currentnodeid ( ) ) ; <nl> - if ( connection = = null ) { <nl> - onfirstphaseresult ( shardindex , shard , null , shardit , new noshardavailableactionexception ( shardit . shardid ( ) ) ) ; <nl> - } else { <nl> + try { <nl> + final transport . connection connection = nodeidtoconnection . apply ( shard . currentnodeid ( ) ) ; <nl> aliasfilter filter = this . aliasfilter . get ( shard . index ( ) . getuuid ( ) ) ; <nl> assert filter ! = null ; <nl>  <nl> float indexboost = concreteindexboosts . getordefault ( shard . index ( ) . getuuid ( ) , default_index_boost ) ; <nl> shardsearchtransportrequest transportrequest = new shardsearchtransportrequest ( request , shardit . shardid ( ) , shardsits . size ( ) , <nl> filter , indexboost , starttime ( ) ) ; <nl> - sendexecutefirstphase ( connection , transportrequest , new actionlistener < firstresult > ( ) { <nl> - @ override <nl> - public void onresponse ( firstresult result ) { <nl> - onfirstphaseresult ( shardindex , shard . currentnodeid ( ) , result , shardit ) ; <nl> - } <nl> - <nl> - @ override <nl> - public void onfailure ( exception t ) { <nl> - onfirstphaseresult ( shardindex , shard , connection . getnode ( ) . getid ( ) , shardit , t ) ; <nl> - } <nl> - } ) ; <nl> + sendexecutefirstphase ( connection , transportrequest , new actionlistener < firstresult > ( ) { <nl> + @ override <nl> + public void onresponse ( firstresult result ) { <nl> + onfirstphaseresult ( shardindex , shard . currentnodeid ( ) , result , shardit ) ; <nl> + } <nl> + <nl> + @ override <nl> + public void onfailure ( exception t ) { <nl> + onfirstphaseresult ( shardindex , shard , connection . getnode ( ) . getid ( ) , shardit , t ) ; <nl> + } <nl> + } ) ; <nl> + } catch ( connecttransportexception | illegalargumentexception ex ) { <nl> + / / we are getting the connection early here so we might run into nodes that are not connected . in that case we move on to <nl> + / / the next shard . <nl> + onfirstphaseresult ( shardindex , shard , shard . currentnodeid ( ) , shardit , ex ) ; <nl> } <nl> } <nl> }
public class prebuiltxpacktransportclienttests extends randomizedtest { <nl>  <nl> @ test <nl> public void testplugininstalled ( ) { <nl> + <nl> + assumefalse ( constants . jre_is_minimum_java9 ) ; <nl> try ( transportclient client = new prebuiltxpacktransportclient ( settings . empty ) ) { <nl> settings settings = client . settings ( ) ; <nl> assertequals ( security . name4 , networkmodule . transport_type_setting . get ( settings ) ) ; <nl> } <nl> } <nl> + <nl> }
public abstract class abstractoldxpackindicesbackwardscompatibilitytestcase exte <nl> } <nl> } <nl>  <nl> + <nl> + @ awaitsfix ( bugurl = " we need to fix bwc first " ) <nl> public void testoldindexes ( ) throws exception { <nl> collections . shuffle ( datafiles , random ( ) ) ; <nl> for ( string datafile : datafiles ) { <nl> mmm a / elasticsearch / src / test / java / org / elasticsearch / test / settingsfiltertests . java <nl> ppp b / elasticsearch / src / test / java / org / elasticsearch / test / settingsfiltertests . java <nl>
public class esnativemigratetooltests extends nativerealmintegtestcase { <nl> return internalcluster ( ) . getinstances ( environment . class ) . iterator ( ) . next ( ) ; <nl> } <nl>  <nl> + <nl> + @ awaitsfix ( bugurl = " we need to fix bwc first " ) <nl> public void testretrieveusers ( ) throws exception { <nl> final environment nodeenvironment = nodeenvironment ( ) ; <nl> string home = environment . path_home_setting . get ( nodeenvironment . settings ( ) ) ; <nl>
public class esnativemigratetooltests extends nativerealmintegtestcase { <nl> } <nl> } <nl>  <nl> + <nl> + @ awaitsfix ( bugurl = " we need to fix bwc first " ) <nl> public void testretrieveroles ( ) throws exception { <nl> final environment nodeenvironment = nodeenvironment ( ) ; <nl> string home = environment . path_home_setting . get ( nodeenvironment . settings ( ) ) ; <nl> mmm a / elasticsearch / src / test / resources / missing - version - security - index - template . json <nl> ppp b / elasticsearch / src / test / resources / missing - version - security - index - template . json <nl>
public class searchtransportservice extends abstractcomponent { <nl> final atomicreference < transportexception > transportexception = new atomicreference < > ( ) ; <nl> for ( map . entry < string , list < string > > entry : remoteindicesbycluster . entryset ( ) ) { <nl> final string clustername = entry . getkey ( ) ; <nl> + <nl> final discoverynode node = connecttoremotecluster ( clustername ) ; <nl> final list < string > indices = entry . getvalue ( ) ; <nl> / / local true so we don ' t go to the master for each single remote search
public class searchtransportservice extends abstractcomponent { <nl> transportservice . disconnectfromnode ( remotenode ) ; / / disconnect the light connection <nl> / / now go and do a real connection with the updated version of the node <nl> transportservice . connecttonode ( discoverynode ) ; <nl> + <nl> return discoverynode ; <nl> }
public class seqnofieldmapper extends metadatafieldmapper { <nl>  <nl> @ override <nl> public fieldstats stats ( indexreader reader ) throws ioexception { <nl> - / / nocommit remove implementation when late - binding commits <nl> - / / are possible <nl> + <nl> final list < leafreadercontext > leaves = reader . leaves ( ) ; <nl> if ( leaves . isempty ( ) ) { <nl> return null ;
public class discoverymodule { <nl> public discovery getdiscovery ( ) { <nl> return discovery ; <nl> } <nl> + <nl> + <nl> + public zenping getzenping ( ) { <nl> + return zenping ; <nl> + } <nl> } <nl> mmm a / core / src / main / java / org / elasticsearch / discovery / zen / zendiscovery . java <nl> ppp b / core / src / main / java / org / elasticsearch / discovery / zen / zendiscovery . java <nl>
subprojects { <nl> } <nl> } <nl>  <nl> + allprojects { <nl> + / / injecting groovy property variables into all projects <nl> + project . ext { <nl> + / / for ide hacks . . . <nl> + iseclipse = system . getproperty ( " eclipse . launcher " ) ! = null | | gradle . startparameter . tasknames . contains ( ' eclipse ' ) | | gradle . startparameter . tasknames . contains ( ' cleaneclipse ' ) <nl> + isidea = system . getproperty ( " idea . active " ) ! = null | | gradle . startparameter . tasknames . contains ( ' idea ' ) | | gradle . startparameter . tasknames . contains ( ' cleanidea ' ) <nl> + } <nl> + } <nl> + <nl> + allprojects { <nl> + apply plugin : ' idea ' <nl> + <nl> + if ( isidea ) { <nl> + project . builddir = file ( ' build - idea ' ) <nl> + } <nl> + idea { <nl> + module { <nl> + inheritoutputdirs = false <nl> + outputdir = file ( ' build - idea / classes / main ' ) <nl> + testoutputdir = file ( ' build - idea / classes / test ' ) <nl> + <nl> + / / also ignore other possible build dirs <nl> + excludedirs + = file ( ' build ' ) <nl> + excludedirs + = file ( ' build - eclipse ' ) <nl> + <nl> + iml { <nl> + / / fix so that gradle idea plugin properly generates support for resource folders <nl> + / / see also https : / / issues . gradle . org / browse / gradle - 2975 <nl> + withxml { <nl> + it . asnode ( ) . component . content . sourcefolder . findall { it . @ url = = ' file : / / $ module_dir $ / src / main / resources ' } . each { <nl> + it . attributes ( ) . remove ( ' istestsource ' ) <nl> + it . attributes ( ) . put ( ' type ' , ' java - resource ' ) <nl> + } <nl> + it . asnode ( ) . component . content . sourcefolder . findall { it . @ url = = ' file : / / $ module_dir $ / src / test / resources ' } . each { <nl> + it . attributes ( ) . remove ( ' istestsource ' ) <nl> + it . attributes ( ) . put ( ' type ' , ' java - test - resource ' ) <nl> + } <nl> + } <nl> + } <nl> + } <nl> + } <nl> + } <nl> + <nl> + / / make sure gradle idea was run before running anything in intellij ( including import ) . <nl> + file ideamarker = new file ( projectdir , ' . local - idea - is - configured ' ) <nl> + tasks . idea . dolast { <nl> + ideamarker . settext ( ' ' , ' utf - 8 ' ) <nl> + } <nl> + if ( system . getproperty ( ' idea . active ' ) ! = null & & ideamarker . exists ( ) = = false ) { <nl> + throw new gradleexception ( ' you must run gradle idea from the root of elasticsearch before importing into intellij ' ) <nl> + } <nl> + <nl> + / / eclipse configuration <nl> + allprojects { <nl> + apply plugin : ' eclipse ' <nl> + / / name all the non - root projects after their path so that paths get grouped together when imported into eclipse . <nl> + if ( path ! = ' : ' ) { <nl> + eclipse . project . name = path <nl> + if ( os . isfamily ( os . family_windows ) ) { <nl> + eclipse . project . name = eclipse . project . name . replace ( ' : ' , ' _ ' ) <nl> + } <nl> + } <nl> + <nl> + plugins . withtype ( javabaseplugin ) { <nl> + file eclipsebuild = project . file ( ' build - eclipse ' ) <nl> + eclipse . classpath . defaultoutputdir = eclipsebuild <nl> + if ( iseclipse ) { <nl> + / / set this so generated dirs will be relative to eclipse build <nl> + project . builddir = eclipsebuild <nl> + } <nl> + eclipse . classpath . file . whenmerged { classpath - > <nl> + / / give each source folder a unique corresponding output folder <nl> + int i = num ; <nl> + classpath . entries . findall { it instanceof sourcefolder } . each { folder - > <nl> + i + + ; <nl> + / / this is * not * a path or a file . <nl> + folder . output = " build - eclipse / " + i <nl> + } <nl> + } <nl> + } <nl> + task copyeclipsesettings ( type : copy ) { <nl> + <nl> + from new file ( project . rootdir , ' buildsrc / src / main / resources / eclipse . settings ' ) <nl> + into ' . settings ' <nl> + } <nl> + / / otherwise . settings is not nuked entirely <nl> + task wipeeclipsesettings ( type : delete ) { <nl> + delete ' . settings ' <nl> + } <nl> + tasks . cleaneclipse . dependson ( wipeeclipsesettings ) <nl> + / / otherwise the eclipse merging is * super confusing * <nl> + tasks . eclipse . dependson ( cleaneclipse , copyeclipsesettings ) <nl> + } <nl> +
public class s3repositoryplugin extends plugin implements repositoryplugin { <nl> @ override <nl> public void run ( ) { <nl> try { <nl> + / / kick jackson to do some static caching of declared members info <nl> + jackson . jsonnodeof ( " { } " ) ; <nl> + / / clientconfiguration clinit has some classloader problems <nl> + <nl> class . forname ( " com . amazonaws . clientconfiguration " ) ; <nl> } catch ( classnotfoundexception e ) { <nl> throw new runtimeexception ( e ) ;
public class ec2discoveryplugin extends plugin implements discoveryplugin , close <nl> @ override <nl> public void run ( ) { <nl> try { <nl> + / / kick jackson to do some static caching of declared members info <nl> + jackson . jsonnodeof ( " { } " ) ; <nl> + / / clientconfiguration clinit has some classloader problems <nl> + <nl> class . forname ( " com . amazonaws . clientconfiguration " ) ; <nl> } catch ( classnotfoundexception e ) { <nl> throw new runtimeexception ( e ) ;
publishing { <nl> artifactid ' elasticsearch ' <nl> artifact buildzip <nl> } <nl> + <nl> nebularealpom ( mavenpublication ) { <nl> artifactid ' elasticsearch ' <nl> pom . packaging = ' pom ' <nl> + pom . withxml { xmlprovider xml - > <nl> + node root = xml . asnode ( ) <nl> + root . appendnode ( ' name ' , ' elasticsearch ' ) <nl> + root . appendnode ( ' description ' , ' a distributed restful search engine ' ) <nl> + root . appendnode ( ' url ' , pluginbuildplugin . urlfromorigin ( project . scminfo . origin ) ) <nl> + node scmnode = root . appendnode ( ' scm ' ) <nl> + scmnode . appendnode ( ' url ' , project . scminfo . origin ) <nl> + } <nl> } <nl> } <nl> } <nl> mmm a / distribution / zip / build . gradle <nl> ppp b / distribution / zip / build . gradle <nl>
publishing { <nl> artifactid ' elasticsearch ' <nl> artifact buildzip <nl> } <nl> + <nl> nebularealpom ( mavenpublication ) { <nl> artifactid ' elasticsearch ' <nl> pom . packaging = ' pom ' <nl> + pom . withxml { xmlprovider xml - > <nl> + node root = xml . asnode ( ) <nl> + root . appendnode ( ' name ' , ' elasticsearch ' ) <nl> + root . appendnode ( ' description ' , ' a distributed restful search engine ' ) <nl> + root . appendnode ( ' url ' , pluginbuildplugin . urlfromorigin ( project . scminfo . origin ) ) <nl> + node scmnode = root . appendnode ( ' scm ' ) <nl> + scmnode . appendnode ( ' url ' , project . scminfo . origin ) <nl> + } <nl> } <nl> } <nl> } <nl>  <nl> integtest . dependson buildzip <nl> -
public abstract class mappedfieldtype extends fieldtype { <nl> eagerglobalordinals , similarity = = null ? null : similarity . name ( ) , nullvalue , nullvalueasstring ) ; <nl> } <nl>  <nl> - / / norelease : we need to override freeze ( ) and add safety checks that all settings are actually set <nl> + <nl>  <nl> / * * returns the name of this type , as would be specified in mapping properties * / <nl> public abstract string typename ( ) ;
public class watcherdatetimeutils { <nl> * parse a { @ link timevalue } with support for fractional values . <nl> * / <nl> public static timevalue parsetimevaluesupportingfractional ( @ nullable string svalue , string settingname ) { <nl> + <nl> / / this code is lifted almost straight from num . x ' s timevalue . java <nl> objects . requirenonnull ( settingname ) ; <nl> if ( svalue = = null ) { <nl> mmm a / elasticsearch / x - pack / watcher / src / test / java / org / elasticsearch / xpack / watcher / support / watcherdatetimeutilstests . java <nl> ppp b / elasticsearch / x - pack / watcher / src / test / java / org / elasticsearch / xpack / watcher / support / watcherdatetimeutilstests . java <nl>
public class smoketestclientit extends essmokeclienttestcase { <nl> * create an <nl> * / <nl> public void testputdocument ( ) { <nl> + <nl> + assumefalse ( " jdk is jdk num " , constants . jre_is_minimum_java9 ) ; <nl> client client = getclient ( ) ; <nl>  <nl> / / start snippet : java - doc - index - doc - simple <nl>
public class prebuilttransportclienttests extends randomizedtest { <nl>  <nl> @ test <nl> public void testplugininstalled ( ) { <nl> + <nl> + assumefalse ( constants . jre_is_minimum_java9 ) ; <nl> try ( transportclient client = new prebuilttransportclient ( settings . empty ) ) { <nl> settings settings = client . settings ( ) ; <nl> assertequals ( netty4plugin . netty_transport_name , networkmodule . http_default_type_setting . get ( settings ) ) ; <nl>
public class reciprocalrank extends rankedlistqualitymetric < reciprocalrank > { <nl> @ override <nl> public xcontentbuilder toxcontent ( xcontentbuilder builder , params params ) throws ioexception { <nl> builder . startobject ( ) ; <nl> - / / builder . startobject ( name ) ; <nl> + / / builder . startobject ( name ) ; <nl> builder . field ( max_rank_field . getpreferredname ( ) , this . maxacceptablerank ) ; <nl> / / builder . endobject ( ) ; <nl> builder . endobject ( ) ;
public class precisionatn extends rankedlistqualitymetric < precisionatn > { <nl>  <nl> @ override <nl> public xcontentbuilder toxcontent ( xcontentbuilder builder , params params ) throws ioexception { <nl> - builder . startobject ( name ) ; <nl> + <nl> + builder . startobject ( ) ; <nl> builder . field ( size_field . getpreferredname ( ) , this . n ) ; <nl> builder . endobject ( ) ; <nl> return builder ; <nl> } <nl> + <nl> + @ override <nl> + public final boolean equals ( object obj ) { <nl> + if ( this = = obj ) { <nl> + return true ; <nl> + } <nl> + if ( obj = = null | | getclass ( ) ! = obj . getclass ( ) ) { <nl> + return false ; <nl> + } <nl> + precisionatn other = ( precisionatn ) obj ; <nl> + return objects . equals ( n , other . n ) ; <nl> + } <nl> + <nl> + @ override <nl> + public final int hashcode ( ) { <nl> + return objects . hash ( getclass ( ) , n ) ; <nl> + } <nl>  <nl> } <nl> mmm a / modules / rank - eval / src / test / java / org / elasticsearch / index / rankeval / precisionatntests . java <nl> ppp b / modules / rank - eval / src / test / java / org / elasticsearch / index / rankeval / precisionatntests . java <nl>
package org . elasticsearch . http . netty3 ; <nl>  <nl> import com . carrotsearch . randomizedtesting . annotations . name ; <nl> import com . carrotsearch . randomizedtesting . annotations . parametersfactory ; <nl> - <nl> + import com . carrotsearch . randomizedtesting . annotations . timeoutsuite ; <nl> + import org . apache . lucene . util . timeunits ; <nl> import org . elasticsearch . test . rest . yaml . clientyamltestcandidate ; <nl> import org . elasticsearch . test . rest . yaml . esclientyamlsuitetestcase ; <nl> import org . elasticsearch . test . rest . yaml . parser . clientyamltestparseexception ; <nl>  <nl> import java . io . ioexception ; <nl>  <nl> + <nl> + @ timeoutsuite ( millis = num * timeunits . minute ) <nl> public class netty3clientyamltestsuiteit extends esclientyamlsuitetestcase { <nl>  <nl> public netty3clientyamltestsuiteit ( @ name ( " yaml " ) clientyamltestcandidate testcandidate ) { <nl>
import java . util . optional ; <nl> / * * <nl> * facilitates creating template query requests . <nl> * * / <nl> + @ deprecated <nl> + <nl> public class templatequerybuilder extends abstractquerybuilder < templatequerybuilder > { <nl> + <nl> public static final string name = " template " ; <nl> + private static final deprecationlogger deprecation_logger = new deprecationlogger ( loggers . getlogger ( templatequerybuilder . class ) ) ; <nl>  <nl> / * * template to fill . * / <nl> private final script template ; <nl>
package org . elasticsearch . http . netty4 ; <nl> import com . carrotsearch . randomizedtesting . annotations . name ; <nl> import com . carrotsearch . randomizedtesting . annotations . parametersfactory ; <nl>  <nl> + import com . carrotsearch . randomizedtesting . annotations . timeoutsuite ; <nl> + import org . apache . lucene . util . timeunits ; <nl> import org . elasticsearch . test . rest . esclientyamlsuitetestcase ; <nl> import org . elasticsearch . test . rest . resttestcandidate ; <nl> import org . elasticsearch . test . rest . parser . resttestparseexception ; <nl>  <nl> import java . io . ioexception ; <nl>  <nl> + <nl> + @ timeoutsuite ( millis = num * timeunits . minute ) <nl> public class netty4restit extends esclientyamlsuitetestcase { <nl>  <nl> public netty4restit ( @ name ( " yaml " ) resttestcandidate testcandidate ) { <nl>
<nl>  <nl> the azure classic discovery plugin uses the azure classic api for unicast discovery . <nl>  <nl> + <nl> + deprecated [ 5 . 0 . 0 , use coming azure arm discovery plugin instead ] <nl> + <nl> [ [ discovery - azure - classic - install ] ] <nl> [ float ] <nl> = = = = installation
apply plugin : ' groovy ' <nl>  <nl> group = ' org . elasticsearch . gradle ' <nl>  <nl> + <nl> + / / progresslogger to be an internal api . until this is made available again , <nl> + / / we can ' t upgrade without losing our nice progress logging <nl> + / / note that this check duplicates that in buildplugin , but we need to check <nl> + / / early here before trying to compile the broken classes in buildsrc <nl> + if ( gradleversion . current ( ) ! = gradleversion . version ( ' 2 . 13 ' ) ) { <nl> + throw new gradleexception ( ' gradle num . 13 is required to build elasticsearch ' ) <nl> + } <nl> + <nl> if ( project = = rootproject ) { <nl> / / change the build dir used during build init , so that doing a clean <nl> / / won ' t wipe out the buildscript jar
public final class defbootstrap { <nl> default : throw new assertionerror ( ) ; <nl> } <nl> } <nl> + <nl> + / * * <nl> + * creates the { @ link methodhandle } for the megamorphic call site <nl> + * using { @ link classvalue } and { @ link methodhandles # exactinvoker ( methodtype ) } : <nl> + * < p > <nl> + * <nl> + * / <nl> + private methodhandle createmegamorphichandle ( final object [ ] callargs ) throws throwable { <nl> + final methodtype type = type ( ) ; <nl> + final classvalue < methodhandle > megamorphiccache = new classvalue < methodhandle > ( ) { <nl> + @ override <nl> + protected methodhandle computevalue ( class < ? > receivertype ) { <nl> + / / it ' s too stupid that we cannot throw checked exceptions . . . ( use rethrow puzzler ) : <nl> + try { <nl> + return lookup ( flavor , name , receivertype , callargs ) . astype ( type ) ; <nl> + } catch ( throwable t ) { <nl> + def . rethrow ( t ) ; <nl> + throw new assertionerror ( ) ; <nl> + } <nl> + } <nl> + } ; <nl> + methodhandle cachelookup = megamorphic_lookup . bindto ( megamorphiccache ) ; <nl> + cachelookup = methodhandles . droparguments ( cachelookup , <nl> + num , type . parameterlist ( ) . sublist ( 1 , type . parametercount ( ) ) ) ; <nl> + return methodhandles . foldarguments ( methodhandles . exactinvoker ( type ) , cachelookup ) ; <nl> + } <nl>  <nl> / * * <nl> * called when a new type is encountered ( or , when we have encountered more than { @ code max_depth } <nl>
grant { <nl> / / to load the class with the application class loader <nl> permission java . lang . runtimepermission " setcontextclassloader " ; <nl> permission java . lang . runtimepermission " getclassloader " ; <nl> + <nl> permission java . lang . runtimepermission " accessclassinpackage . com . sun . activation . registries " ; <nl>  <nl> / / bouncy castle
<nl> + / * <nl> + * licensed to elasticsearch under one or more contributor <nl> + * license agreements . see the notice file distributed with <nl> + * this work for additional information regarding copyright <nl> + * ownership . elasticsearch licenses this file to you under <nl> + * the apache license , version num . 0 ( the " license " ) ; you may <nl> + * not use this file except in compliance with the license . <nl> + * you may obtain a copy of the license at <nl> + * <nl> + * http : / / www . apache . org / licenses / license - 2 . 0 <nl> + * <nl> + * unless required by applicable law or agreed to in writing , <nl> + * software distributed under the license is distributed on an <nl> + * " as is " basis , without warranties or conditions of any <nl> + * kind , either express or implied . see the license for the <nl> + * specific language governing permissions and limitations <nl> + * under the license . <nl> + * / <nl> + <nl> + package org . apache . log4j ; <nl> + <nl> + import org . apache . log4j . helpers . threadlocalmap ; <nl> + <nl> + / * * <nl> + * <nl> + * / <nl> + public class java9hack { <nl> + <nl> + public static void fixlog4j ( ) { <nl> + mdc . mdc . tlm = new threadlocalmap ( ) ; <nl> + } <nl> + } <nl> mmm a / core / src / main / java / org / elasticsearch / common / logging / logconfigurator . java <nl> ppp b / core / src / main / java / org / elasticsearch / common / logging / logconfigurator . java <nl>
public final class echain extends aexpression { <nl> if ( last instanceof adeflink ) { <nl> final adeflink lastdef = ( adeflink ) last ; <nl> expression . analyze ( settings , definition , variables ) ; <nl> + <nl> lastdef . storevaluetype = expression . expected = expression . actual ; <nl> this . actual = read ? lastdef . storevaluetype : definition . voidtype ; <nl> } else { <nl>
public class restgraphaction extends baseresthandler { <nl> @ inject <nl> public restgraphaction ( settings settings , restcontroller controller , client client , indicesqueriesregistry indicesqueriesregistry ) { <nl> super ( settings , client ) ; <nl> + <nl> controller . registerhandler ( get , " / { index } / _graph / explore " , this ) ; <nl> controller . registerhandler ( post , " / { index } / _graph / explore " , this ) ; <nl> controller . registerhandler ( get , " / { index } / { type } / _graph / explore " , this ) ; <nl> controller . registerhandler ( post , " / { index } / { type } / _graph / explore " , this ) ; <nl> + / / new rest endpoint <nl> + controller . registerhandler ( get , " / { index } / _xpack / graph / _explore " , this ) ; <nl> + controller . registerhandler ( post , " / { index } / _xpack / graph / _explore " , this ) ; <nl> + controller . registerhandler ( get , " / { index } / { type } / _xpack / graph / _explore " , this ) ; <nl> + controller . registerhandler ( post , " / { index } / { type } / _xpack / graph / _explore " , this ) ; <nl> this . indicesqueriesregistry = indicesqueriesregistry ; <nl> } <nl>  <nl> mmm a / elasticsearch / x - pack / graph / src / test / resources / rest - api - spec / api / graph . explore . json <nl> ppp b / elasticsearch / x - pack / graph / src / test / resources / rest - api - spec / api / graph . explore . json <nl>
import java . util . collection ; <nl> import java . util . objects ; <nl>  <nl> / * * <nl> - * a query that will execute the wrapped query only for the specified indices , and " match_all " when <nl> - * it does not match those indices ( by default ) . <nl> + * a query that will execute the wrapped query only for the specified indices , <nl> + * and " match_all " when it does not match those indices ( by default ) . <nl> + * <nl> + * @ deprecated instead search on the ` _index ` field <nl> * / <nl> + @ deprecated <nl> + <nl> public class indicesquerybuilder extends abstractquerybuilder < indicesquerybuilder > { <nl>  <nl> public static final string name = " indices " ; <nl>
public abstract class querybuilders { <nl> } <nl>  <nl> / * * <nl> - * a query that will execute the wrapped query only for the specified indices , and " match_all " when <nl> - * it does not match those indices . <nl> + * a query that will execute the wrapped query only for the specified <nl> + * indices , and " match_all " when it does not match those indices . <nl> + * <nl> + * @ deprecated instead search on the ` _index ` field <nl> * / <nl> + @ deprecated <nl> public static indicesquerybuilder indicesquery ( querybuilder querybuilder , string . . . indices ) { <nl> + <nl> return new indicesquerybuilder ( querybuilder , indices ) ; <nl> } <nl>  <nl> mmm a / core / src / main / java / org / elasticsearch / search / searchmodule . java <nl> ppp b / core / src / main / java / org / elasticsearch / search / searchmodule . java <nl>
public class searchmodule extends abstractmodule { <nl> registerquery ( spanorquerybuilder : : new , spanorquerybuilder : : fromxcontent , spanorquerybuilder . query_name_field ) ; <nl> registerquery ( morelikethisquerybuilder : : new , morelikethisquerybuilder : : fromxcontent , morelikethisquerybuilder . query_name_field ) ; <nl> registerquery ( wrapperquerybuilder : : new , wrapperquerybuilder : : fromxcontent , wrapperquerybuilder . query_name_field ) ; <nl> + <nl> registerquery ( indicesquerybuilder : : new , indicesquerybuilder : : fromxcontent , indicesquerybuilder . query_name_field ) ; <nl> registerquery ( commontermsquerybuilder : : new , commontermsquerybuilder : : fromxcontent , commontermsquerybuilder . query_name_field ) ; <nl> registerquery ( spanmultitermquerybuilder : : new , spanmultitermquerybuilder : : fromxcontent , spanmultitermquerybuilder . query_name_field ) ;
public class zendiscovery extends abstractlifecyclecomponent < discovery > implemen <nl> list < zenping . pingresponse > pingresponses = new arraylist < > ( ) ; <nl> for ( zenping . pingresponse pingresponse : fullpingresponses ) { <nl> discoverynode node = pingresponse . node ( ) ; <nl> - / / nocommit we should rename this and its setting , also we ignore node . ingest , but maybe it ' s ok here <nl> + <nl> if ( masterelectionfilterclientnodes & & node . masternode ( ) = = false & & node . datanode ( ) = = false ) { <nl> / / filter out nodes that don ' t hold data and are not master eligible <nl> } else if ( masterelectionfilterdatanodes & & node . masternode ( ) = = false & & node . datanode ( ) ) {
public class queryphase implements searchphase { <nl>  <nl> @ override <nl> public void execute ( searchcontext searchcontext ) throws queryphaseexecutionexception { <nl> + if ( searchcontext . hasonlysuggest ( ) ) { <nl> + suggestphase . execute ( searchcontext ) ; <nl> + <nl> + searchcontext . queryresult ( ) . topdocs ( new topdocs ( 0 , lucene . empty_score_docs , num ) ) ; <nl> + return ; <nl> + } <nl> / / pre - process aggregations as late as possible . in the case of a dfs_q_t_f <nl> / / request , preprocess is called on the dfs phase phase , this is why we pre - process them <nl> / / here to make sure it happens during the query phase
public abstract class abstractscopedsettings extends abstractcomponent { <nl> } <nl> } <nl>  <nl> + / * * <nl> + * returns < code > true < / code > iff the setting is a private setting ie . it should be treated as valid even though it has no internal <nl> + * representation . otherwise < code > false < / code > <nl> + * / <nl> + <nl> protected boolean isprivatesetting ( string key ) { <nl> return false ; <nl> }
final class bootstrapcliparser extends command { <nl> . withrequiredarg ( ) ; <nl> } <nl>  <nl> + <nl> + @ suppressforbidden ( reason = " sets system properties passed as cli parameters " ) <nl> @ override <nl> protected void execute ( terminal terminal , optionset options ) throws exception { <nl> if ( options . has ( versionoption ) ) { <nl> mmm a / modules / lang - groovy / build . gradle <nl> ppp b / modules / lang - groovy / build . gradle <nl>
public class stringfieldmapper extends fieldmapper implements allfieldmapper . inc <nl> public static class typeparser implements mapper . typeparser { <nl> @ override <nl> public mapper . builder parse ( string fieldname , map < string , object > node , parsercontext parsercontext ) throws mapperparsingexception { <nl> - if ( parsercontext . indexversioncreated ( ) . onorafter ( version . v_5_0_0 ) ) { <nl> + <nl> + / * if ( parsercontext . indexversioncreated ( ) . onorafter ( version . v_5_0_0 ) ) { <nl> throw new illegalargumentexception ( " the [ string ] type is removed in num . 0 . you should now use either a [ text ] " <nl> + " or [ keyword ] field instead for field [ " + fieldname + " ] " ) ; <nl> - } <nl> + } * / <nl> stringfieldmapper . builder builder = new stringfieldmapper . builder ( fieldname ) ; <nl> / / hack for the fact that string can ' t just accept true / false for <nl> / / the <nl>
public class stringfieldmapper extends fieldmapper implements allfieldmapper . inc <nl> int positionincrementgap , int ignoreabove , <nl> settings indexsettings , multifields multifields , copyto copyto ) { <nl> super ( simplename , fieldtype , defaultfieldtype , indexsettings , multifields , copyto ) ; <nl> - if ( version . indexcreated ( indexsettings ) . onorafter ( version . v_5_0_0 ) ) { <nl> + <nl> + / * if ( version . indexcreated ( indexsettings ) . onorafter ( version . v_5_0_0 ) ) { <nl> throw new illegalargumentexception ( " the [ string ] type is removed in num . 0 . you should now use either a [ text ] " <nl> + " or [ keyword ] field instead for field [ " + fieldtype . name ( ) + " ] " ) ; <nl> - } <nl> + } * / <nl> if ( fieldtype . tokenized ( ) & & fieldtype . indexoptions ( ) ! = none & & fieldtype ( ) . hasdocvalues ( ) ) { <nl> throw new mapperparsingexception ( " field [ " + fieldtype . name ( ) + " ] cannot be analyzed and have doc values " ) ; <nl> }
public class tribeservicetests extends estestcase { <nl> assertequals ( " conf / path " , clientsettings . get ( " path . conf " ) ) ; <nl> assertequals ( " plugins / path " , clientsettings . get ( " path . plugins " ) ) ; <nl> assertequals ( " logs / path " , clientsettings . get ( " path . logs " ) ) ; <nl> + <nl> + <nl> + settings tribesettings = settings . builder ( ) <nl> + . put ( " path . home " , " alternate / path " ) . build ( ) ; <nl> + clientsettings = tribeservice . buildclientsettings ( " tribe1 " , globalsettings , tribesettings ) ; <nl> + assertequals ( " some / path " , clientsettings . get ( " path . home " ) ) ; <nl> } <nl>  <nl> public void testpassthroughsettings ( ) {
public final class clustersettings extends abstractscopedsettings { <nl>  <nl>  <nl> public static set < setting < ? > > built_in_cluster_settings = collections . unmodifiableset ( new hashset < > ( arrays . aslist ( awarenessallocationdecider . cluster_routing_allocation_awareness_attribute_setting , <nl> + transportclientnodesservice . client_transport_nodes_sampler_interval , <nl> + transportclientnodesservice . client_transport_ping_timeout , <nl> + transportclientnodesservice . client_transport_ignore_cluster_name , <nl> awarenessallocationdecider . cluster_routing_allocation_awareness_force_group_setting , <nl> balancedshardsallocator . index_balance_factor_setting , <nl> balancedshardsallocator . shard_balance_factor_setting ,
final class autoexpandreplicas { <nl> / / the value we recognize in the " max " position to mean all the nodes <nl> private static final string all_nodes_value = " all " ; <nl> public static final setting < autoexpandreplicas > setting = new setting < > ( indexmetadata . setting_auto_expand_replicas , " false " , ( value ) - > { <nl> - final int min ; <nl> - final int max ; <nl> + <nl> + int min ; <nl> + int max ; <nl> if ( booleans . parseboolean ( value , true ) = = false ) { <nl> return new autoexpandreplicas ( 0 , num , false ) ; <nl> }
public class restintegtesttask extends randomizedtestingtask { <nl> project . gradle . projectsevaluated { <nl> nodeinfo node = clusterformationtasks . setup ( project , this , clusterconfig ) <nl> systemproperty ( ' tests . rest . cluster ' , " localhost : $ { - > new url ( ' http : / / ' + node . httpuri ( ) ) . getport ( ) } " ) <nl> + <nl> + / / both as separate sysprops <nl> systemproperty ( ' tests . cluster ' , " $ { - > node . transporturi ( ) } " ) <nl> } <nl> }
public final class hdfsrepository extends blobstorerepository { <nl> private final repositorysettings repositorysettings ; <nl> private final bytesizevalue chunksize ; <nl> private final boolean compress ; <nl> - <nl> + <nl> private hdfsblobstore blobstore ; <nl>  <nl> + / / buffer size passed to hdfs read / write methods <nl> + <nl> + private static final bytesizevalue default_buffer_size = new bytesizevalue ( 100 , bytesizeunit . kb ) ; <nl> + <nl> @ inject <nl> public hdfsrepository ( repositoryname name , repositorysettings repositorysettings , indexshardrepository indexshardrepository ) throws ioexception { <nl> super ( name . getname ( ) , repositorysettings , indexshardrepository ) ; <nl>
public class hdfsplugin extends plugin { <nl>  <nl> / / initialize some problematic classes with elevated privileges <nl> static { <nl> - securitymanager sm = system . getsecuritymanager ( ) ; <nl> - if ( sm ! = null ) { <nl> - sm . checkpermission ( new specialpermission ( ) ) ; <nl> - } <nl> - accesscontroller . doprivileged ( new privilegedaction < void > ( ) { <nl> - @ override <nl> - public void run ( ) { <nl> - try { <nl> - class . forname ( " org . apache . hadoop . security . usergroupinformation " ) ; <nl> - class . forname ( " org . apache . hadoop . util . stringutils " ) ; <nl> - class . forname ( " org . apache . hadoop . util . shutdownhookmanager " ) ; <nl> - } catch ( classnotfoundexception e ) { <nl> - throw new runtimeexception ( e ) ; <nl> - } <nl> - return null ; <nl> - } <nl> - } ) ; <nl> + securitymanager sm = system . getsecuritymanager ( ) ; <nl> + if ( sm ! = null ) { <nl> + sm . checkpermission ( new specialpermission ( ) ) ; <nl> + } <nl> + accesscontroller . doprivileged ( new privilegedaction < void > ( ) { <nl> + @ override <nl> + public void run ( ) { <nl> + return evilhadoopinit ( ) ; <nl> + } <nl> + } ) ; <nl> + } <nl> + <nl> + @ suppressforbidden ( reason = " needs a security hack for hadoop on windows , until hadoop - xxxx is fixed " ) <nl> + private static void evilhadoopinit ( ) { <nl> + string oldvalue = null ; <nl> + try { <nl> + / / hack : on windows , shell ' s cinit has a similar problem that on unix , <nl> + / / but here we can workaround it for now by setting hadoop home <nl> + <nl> + path hadoophome = files . createtempdirectory ( " hadoop " ) . toabsolutepath ( ) ; <nl> + oldvalue = system . setproperty ( " hadoop . home . dir " , hadoophome . tostring ( ) ) ; <nl> + class . forname ( " org . apache . hadoop . security . usergroupinformation " ) ; <nl> + class . forname ( " org . apache . hadoop . util . stringutils " ) ; <nl> + class . forname ( " org . apache . hadoop . util . shutdownhookmanager " ) ; <nl> + } catch ( classnotfoundexception | ioexception e ) { <nl> + throw new runtimeexception ( e ) ; <nl> + } finally { <nl> + if ( oldvalue = = null ) { <nl> + system . clearproperty ( " hadoop . home . dir " ) ; <nl> + } else { <nl> + system . setproperty ( " hadoop . home . dir " , oldvalue ) ; <nl> + } <nl> + } <nl> + return null ; <nl> } <nl>  <nl> @ override
public class templatequeryparsertests extends estestcase { <nl> } ) ; <nl> index <nl> indexsettings idxsettings = indexsettingsmodule . newindexsettings ( index , settings ) ; <nl> + scriptmodule scriptmodule = new scriptmodule ( settings ) ; <nl> + <nl> + scriptmodule . addscriptengine ( mustachescriptengineservice . class ) ; <nl> injector = new modulesbuilder ( ) . add ( <nl> new environmentmodule ( new environment ( settings ) ) , <nl> new settingsmodule ( settings , new settingsfilter ( settings ) ) , <nl>
public class terminaltests extends clitooltestcase { <nl> assertprinted ( terminal , terminal . verbosity . verbose , " text " ) ; <nl> } <nl>  <nl> + public void testerror ( ) throws exception { <nl> + try { <nl> + / / actually throw so we have a stacktrace <nl> + throw new nosuchfileexception ( " / path / to / some / file " ) ; <nl> + } catch ( nosuchfileexception e ) { <nl> + captureoutputterminal terminal = new captureoutputterminal ( terminal . verbosity . normal ) ; <nl> + terminal . printerror ( e ) ; <nl> + list < string > output = terminal . getterminaloutput ( ) ; <nl> + assertfalse ( output . isempty ( ) ) ; <nl> + asserttrue ( output . get ( 0 ) , output . get ( 0 ) . contains ( " nosuchfileexception " ) ) ; / / exception class <nl> + asserttrue ( output . get ( 0 ) , output . get ( 0 ) . contains ( " / path / to / some / file " ) ) ; / / message <nl> + assertequals ( 1 , output . size ( ) ) ; <nl> + <nl> + <nl> + } <nl> + } <nl> + <nl> private void assertprinted ( captureoutputterminal logterminal , terminal . verbosity verbosity , string text ) { <nl> logterminal . print ( verbosity , text ) ; <nl> assertthat ( logterminal . getterminaloutput ( ) , hassize ( 1 ) ) ; <nl> - assertthat ( logterminal . getterminaloutput ( ) , hasitem ( is ( " text " ) ) ) ; <nl> + assertthat ( logterminal . getterminaloutput ( ) , hasitem ( text ) ) ; <nl> logterminal . terminaloutput . clear ( ) ; <nl> }
apply plugin : ' elasticsearch . rest - test ' <nl>  <nl> dependencies { <nl> testcompile project ( path : ' : x - plugins : watcher ' , configuration : ' runtime ' ) <nl> - testcompile project ( path : ' : plugins : lang - groovy ' , configuration : ' runtime ' ) <nl> + testcompile project ( path : ' : modules : lang - groovy ' , configuration : ' runtime ' ) <nl> } <nl>  <nl> integtest { <nl> cluster { <nl> plugin ' license ' , project ( ' : x - plugins : license : plugin ' ) <nl> plugin ' watcher ' , project ( ' : x - plugins : watcher ' ) <nl> - plugin ' groovy ' , project ( ' : plugins : lang - groovy ' ) <nl> + <nl> + plugin ' groovy ' , project ( ' : modules : lang - groovy ' ) <nl> systemproperty ' es . script . inline ' , ' on ' <nl> } <nl> }
ext . versions = [ <nl> okhttp : ' 2 . 3 . 0 ' <nl> ] <nl>  <nl> + <nl> + ext . compactprofile = ' full ' <nl> + <nl> dependencies { <nl> / / license deps <nl> compile project ( ' : x - plugins : elasticsearch : license : plugin - api ' ) <nl>
bundleplugin { <nl> } <nl> } <nl> } <nl> + <nl> + <nl> + configurations { <nl> + testartifacts . extendsfrom testruntime <nl> + } <nl> + task testjar ( type : jar ) { <nl> + classifier " test " <nl> + from sourcesets . test . output <nl> + } <nl> + artifacts { <nl> + testartifacts testjar <nl> + }
forbiddenapismain { <nl> signaturesurls = [ precommittasks . getresource ( ' / forbidden / all - signatures . txt ' ) , <nl> precommittasks . getresource ( ' / forbidden / test - signatures . txt ' ) ] <nl> } <nl> + <nl> + <nl> + dependencylicenses . enabled = false <nl> +
public class dependencylicensestask extends defaulttask { <nl>  <nl> @ taskaction <nl> public void checkdependencies ( ) { <nl> + <nl> + if ( licensesdir . exists ( ) = = false ) { <nl> + return <nl> + } <nl> if ( licensesdir . exists ( ) = = false & & dependencies . isempty ( ) = = false ) { <nl> throw new gradleexception ( " licences dir $ { licensesdir } does not exist , but there are dependencies " ) <nl> }
ext . versions = [ <nl> okhttp : ' 2 . 3 . 0 ' <nl> ] <nl>  <nl> + <nl> + ext . compactprofile = ' full ' <nl> + <nl> dependencies { <nl> provided project ( path : ' : x - plugins : license : plugin ' , configuration : ' runtime ' ) <nl> provided project ( path : ' : x - plugins : shield ' , configuration : ' runtime ' )
<nl> + # integration tests for smoke testing plugins <nl> + # <nl> + " plugins are actually installed " : <nl> + - do : <nl> + cluster . state : { } <nl> + <nl> + # get master node id <nl> + - set : { master_node : master } <nl> + <nl> + - do : <nl> + nodes . info : { } <nl> + <nl> + - length : { nodes . $ master . plugins : $ { expected . plugin . count } } <nl> + #
subprojects { <nl> } <nl> } <nl>  <nl> - configurations { <nl> - all { <nl> - resolutionstrategy { <nl> - dependencysubstitution { <nl> - substitute module ( " org . elasticsearch : rest - api - spec : $ { version } " ) with project ( " $ { projectsprefix } : rest - api - spec " ) <nl> - substitute module ( " org . elasticsearch : elasticsearch : $ { version } " ) with project ( " $ { projectsprefix } : core " ) <nl> - substitute module ( " org . elasticsearch : test - framework : $ { version } " ) with project ( " $ { projectsprefix } : test - framework " ) <nl> - substitute module ( " org . elasticsearch . distribution . zip : elasticsearch : $ { version } " ) with project ( " $ { projectsprefix } : distribution : zip " ) <nl> - substitute module ( " org . elasticsearch . distribution . tar : elasticsearch : $ { version } " ) with project ( " $ { projectsprefix } : distribution : tar " ) <nl> + ext . projectsubstitutions = [ <nl> + " org . elasticsearch : rest - api - spec : $ { version } " : " $ { projectsprefix } : rest - api - spec " , <nl> + " org . elasticsearch : elasticsearch : $ { version } " : " $ { projectsprefix } : core " , <nl> + " org . elasticsearch : test - framework : $ { version } " : " $ { projectsprefix } : test - framework " , <nl> + " org . elasticsearch . distribution . zip : elasticsearch : $ { version } " : " $ { projectsprefix } : distribution : zip " , <nl> + " org . elasticsearch . distribution . tar : elasticsearch : $ { version } " : " $ { projectsprefix } : distribution : tar " <nl> + ] <nl> + configurations . all { <nl> + resolutionstrategy . dependencysubstitution { dependencysubstitutions subs - > <nl> + projectsubstitutions . each { k , v - > <nl> + subs . substitute ( subs . module ( k ) ) . with ( subs . project ( v ) ) <nl> + } <nl> + } <nl> + } <nl> + } <nl> + <nl> + / / ensure similar tasks in dependent projects run first . the projectsevaluated here is <nl> + / / important because , while dependencies . all will pickup future dependencies , <nl> + / / it is not necessarily true that the task exists in both projects at the time <nl> + / / the dependency is added . <nl> + gradle . projectsevaluated { <nl> + allprojects { <nl> + if ( project . path = = ' : test - framework ' ) { <nl> + / / : test - framework : test cannot run before and after : core : test <nl> + return <nl> + } <nl> + configurations . all { <nl> + dependencies . all { dependency dep - > <nl> + project upstreamproject = null <nl> + if ( dep instanceof projectdependency ) { <nl> + upstreamproject = dep . dependencyproject <nl> + } else { <nl> + / / gradle doesn ' t apply substitutions until resolve time , so they won ' t <nl> + / / show up as a projectdependency above <nl> + string substitution = projectsubstitutions . get ( " $ { dep . group } : $ { dep . name } : $ { dep . version } " ) <nl> + if ( substitution ! = null ) { <nl> + upstreamproject = findproject ( substitution ) <nl> + } <nl> + } <nl> + if ( upstreamproject ! = null ) { <nl> + if ( project . path = = upstreamproject . path ) { <nl> + <nl> + return <nl> + } <nl> + for ( string taskname : [ ' test ' , ' integtest ' ] ) { <nl> + task task = project . tasks . findbyname ( taskname ) <nl> + task upstreamtask = upstreamproject . tasks . findbyname ( taskname ) <nl> + if ( task ! = null & & upstreamtask ! = null ) { <nl> + task . mustrunafter ( upstreamtask ) <nl> + } <nl> + } <nl> } <nl> } <nl> } <nl>
public final class dateprocessor implements processor { <nl> } <nl> } <nl>  <nl> - public static class builder implements processor . builder { <nl> - <nl> - private string timezone ; <nl> - private string locale ; <nl> - private string matchfield ; <nl> - private list < string > matchformats ; <nl> - private string targetfield ; <nl> - <nl> - public builder ( ) { <nl> - matchformats = new arraylist < string > ( ) ; <nl> - } <nl> - <nl> - public void settimezone ( string timezone ) { <nl> - this . timezone = timezone ; <nl> - } <nl> - <nl> - public void setlocale ( string locale ) { <nl> - this . locale = locale ; <nl> - } <nl> - <nl> - public void setmatchfield ( string matchfield ) { <nl> - this . matchfield = matchfield ; <nl> - } <nl> - <nl> - public void addmatchformat ( string matchformat ) { <nl> - matchformats . add ( matchformat ) ; <nl> - } <nl> - <nl> - public void settargetfield ( string targetfield ) { <nl> - this . targetfield = targetfield ; <nl> - } <nl> + public static class factory implements processor . factory { <nl>  <nl> @ suppresswarnings ( " unchecked " ) <nl> - public void frommap ( map < string , object > config ) { <nl> - this . timezone = ( string ) config . get ( " timezone " ) ; <nl> - this . locale = ( string ) config . get ( " locale " ) ; <nl> - this . matchfield = ( string ) config . get ( " match_field " ) ; <nl> - this . matchformats = ( list < string > ) config . get ( " match_formats " ) ; <nl> - this . targetfield = ( string ) config . get ( " target_field " ) ; <nl> - } <nl> - <nl> - @ override <nl> - public processor build ( ) { <nl> + public processor create ( map < string , object > config ) { <nl> + <nl> + string timezone = ( string ) config . get ( " timezone " ) ; <nl> + string locale = ( string ) config . get ( " locale " ) ; <nl> + string matchfield = ( string ) config . get ( " match_field " ) ; <nl> + list < string > matchformats = ( list < string > ) config . get ( " match_formats " ) ; <nl> + string targetfield = ( string ) config . get ( " target_field " ) ; <nl> return new dateprocessor ( timezone , locale , matchfield , matchformats , targetfield ) ; <nl> } <nl> - <nl> - public static class factory implements processor . builder . factory { <nl> - <nl> - @ override <nl> - public processor . builder create ( ) { <nl> - return new builder ( ) ; <nl> - } <nl> - } <nl> - <nl> } <nl>  <nl> } <nl> mmm a / plugins / ingest / src / main / java / org / elasticsearch / plugin / ingest / ingestmodule . java <nl> ppp b / plugins / ingest / src / main / java / org / elasticsearch / plugin / ingest / ingestmodule . java <nl>
<nl> * under the license . <nl> * / <nl>  <nl> + / * <nl> + * evil tests that need to do unrealistic things : test os security <nl> + * integration , change default filesystem impl , mess with arbitrary <nl> + * threads , etc . <nl> + * / <nl> + <nl> apply plugin : ' elasticsearch . standalone - test ' <nl>  <nl> + dependencies { <nl> + testcompile ' com . google . jimfs : jimfs : 1 . 0 ' <nl> + } <nl> + <nl> + <nl> + <nl> test { <nl> systemproperty ' tests . security . manager ' , ' false ' <nl> } <nl> mmm a / test - framework / build . gradle <nl> ppp b / test - framework / build . gradle <nl>
class clusterformationtasks { <nl> file pidfile = pidfile ( basedir ) <nl> string clustername = " $ { task . path . replace ( ' : ' , ' _ ' ) . substring ( 1 ) } " <nl> file home = homedir ( basedir , config . distribution ) <nl> + map esconfig = [ <nl> + ' cluster . name ' : clustername , <nl> + ' http . port ' : config . httpport , <nl> + ' transport . tcp . port ' : config . transportport , <nl> + ' pidfile ' : pidfile , <nl> + <nl> + ' discovery . zen . ping . unicast . hosts ' : " localhost : $ { config . transportport } " , <nl> + ' path . repo ' : " $ { home } / repo " , <nl> + ' path . shared_data ' : " $ { home } / . . / " , <nl> + / / define a node attribute so we can test that it exists <nl> + ' node . testattr ' : ' test ' , <nl> + ' repositories . url . allowed_urls ' : ' http : / / snapshot . test * ' <nl> + ] <nl> + map esenv = [ <nl> + ' java_home ' : system . getproperty ( ' java . home ' ) , <nl> + ' es_gc_opts ' : config . jvmargs <nl> + ] <nl> + <nl> list setupdeps = [ ] / / need to copy the deps , since start will later be added , which would create a circular task dep ! <nl> setupdeps . addall ( task . dependson ) <nl> task setup = project . tasks . create ( name : " $ { task . name } # clean " , type : delete , dependson : setupdeps ) { <nl>
public final class data { <nl>  <nl> @ suppresswarnings ( " unchecked " ) <nl> public < t > t getproperty ( string path ) { <nl> + <nl> return ( t ) xcontentmapvalues . extractvalue ( path , document ) ; <nl> }
public final class data { <nl> this . document = document ; <nl> } <nl>  <nl> + <nl> @ suppresswarnings ( " unchecked " ) <nl> public < t > t getproperty ( string path ) { <nl> return ( t ) xcontentmapvalues . extractvalue ( path , document ) ; <nl> } <nl>  <nl> - public void addfield ( string field , object value ) { <nl> + / * * <nl> + * add ` value ` to path in document . if path does not exist , <nl> + * nested hashmaps will be put in as parent key values until <nl> + * leaf key name in path is reached . <nl> + * <nl> + * @ param path the path within the document in dot - notation <nl> + * @ param value the value to put in for the path key <nl> + * / <nl> + public void addfield ( string path , object value ) { <nl> modified = true ; <nl> - document . put ( field , value ) ; <nl> + <nl> + string [ ] pathelements = strings . splitstringtoarray ( path , ' . ' ) ; <nl> + <nl> + string writekey = pathelements [ pathelements . length - num ] ; <nl> + map < string , object > inner = document ; <nl> + <nl> + for ( int i = num ; i < pathelements . length - num ; i + + ) { <nl> + inner . putifabsent ( pathelements [ i ] , new hashmap < string , object > ( ) ) ; <nl> + inner = ( hashmap < string , object > ) inner . get ( pathelements [ i ] ) ; <nl> + } <nl> + <nl> + inner . put ( writekey , value ) ; <nl> } <nl>  <nl> public string getindex ( ) { <nl> mmm / dev / null <nl> ppp b / plugins / ingest / src / test / java / org / elasticsearch / ingest / datatests . java <nl>
public class mapbuilder < k , v > { <nl> } <nl>  <nl> / * * <nl> - * build an immutable copy of the map under construction . <nl> - * <nl> - * @ deprecated always copies the map under construction . prefer building a <nl> - * hashmap by hand and wrapping it in an unmodifiablemap <nl> + * build an immutable copy of the map under construction . always copies the map under construction . prefer building <nl> + * a hashmap by hand and wrapping it in an unmodifiablemap <nl> * / <nl> - @ deprecated <nl> public map < k , v > immutablemap ( ) { <nl> - / / note that this whole method is going to have to go next but we ' re changing it like this here just to keep the commit smaller . <nl> + <nl> return unmodifiablemap ( new hashmap < > ( map ) ) ; <nl> } <nl> }
public class pythonsecuritytests extends estestcase { <nl> fail ( " did not get expected exception " ) ; <nl> } catch ( pyexception expected ) { <nl> throwable cause = expected . getcause ( ) ; <nl> - assertnotnull ( " null cause for exception : " + expected , cause ) ; <nl> + <nl> + / / assertnotnull ( " null cause for exception : " + expected , cause ) ; <nl> + assertnotnull ( " null cause for exception " , cause ) ; <nl> asserttrue ( " unexpected exception : " + cause , cause instanceof securityexception ) ; <nl> } <nl> }
public class gcecomputeserviceimpl extends abstractlifecyclecomponent < gcecompute <nl> logger . debug ( " get instances for project [ { } ] , zones [ { } ] " , project , zones ) ; <nl> final list < instance > instances = zones . stream ( ) . map ( ( zoneid ) - > { <nl> try { <nl> - compute . instances . list list = client ( ) . instances ( ) . list ( project , zoneid ) ; <nl> - instancelist instancelist = list . execute ( ) ; <nl> + / / hack around code messiness in gce code <nl> + <nl> + instancelist instancelist = accesscontroller . doprivileged ( new privilegedexceptionaction < instancelist > ( ) { <nl> + @ override <nl> + public instancelist run ( ) throws exception { <nl> + compute . instances . list list = client ( ) . instances ( ) . list ( project , zoneid ) ; <nl> + return list . execute ( ) ; <nl> + } <nl> + } ) ; <nl> if ( instancelist . isempty ( ) ) { <nl> return collections . empty_list ; <nl> } <nl> return instancelist . getitems ( ) ; <nl> - } catch ( ioexception e ) { <nl> + } catch ( privilegedactionexception e ) { <nl> logger . warn ( " problem fetching instance list for zone { } " , zoneid ) ; <nl> logger . debug ( " full exception : " , e ) ; <nl> return collections . empty_list ; <nl> mmm a / plugins / cloud - gce / src / main / java / org / elasticsearch / discovery / gce / gceunicasthostsprovider . java <nl> ppp b / plugins / cloud - gce / src / main / java / org / elasticsearch / discovery / gce / gceunicasthostsprovider . java <nl>
governing permissions and limitations under the license . - - > <nl> < tests . rest . suite > cloud_gce < / tests . rest . suite > <nl> < tests . rest . load_packaged > false < / tests . rest . load_packaged > <nl> < xlint . options > - xlint : - rawtypes , - unchecked < / xlint . options > <nl> + < ! - - <nl> + https : / / github . com / elastic / elasticsearch / issues / 13623 - - > <nl> + < skip . unit . tests > true < / skip . unit . tests > <nl> < / properties > <nl>  <nl> < dependencies >
public class indexaudittrail extends abstractcomponent implements audittrail , cl <nl> datetime = datetime . now ( datetimezone . utc ) ; <nl> } <nl> string <nl> - if ( client . admin ( ) . indices ( ) . prepareexists ( index ) . get ( ) . isexists ( ) ) { <nl> + indicesexistsrequest existsrequest = new indicesexistsrequest ( index ) ; <nl> + <nl> + if ( ! indextoremotecluster ) { <nl> + authenticationservice . attachuserheaderifmissing ( existsrequest , audituser . user ( ) ) ; <nl> + } <nl> + <nl> + if ( client . admin ( ) . indices ( ) . exists ( existsrequest ) . get ( ) . isexists ( ) ) { <nl> logger . debug ( " <nl> - putmappingresponse putmappingresponse = client . admin ( ) . indices ( ) <nl> - . prepareputmapping ( index ) <nl> - . settype ( doc_type ) <nl> - . setsource ( request . mappings ( ) . get ( doc_type ) ) <nl> - . get ( ) ; <nl> + putmappingrequest putmappingrequest = new putmappingrequest ( index ) . type ( doc_type ) . source ( request . mappings ( ) . get ( doc_type ) ) ; <nl> + if ( ! indextoremotecluster ) { <nl> + authenticationservice . attachuserheaderifmissing ( putmappingrequest , audituser . user ( ) ) ; <nl> + } <nl> + <nl> + putmappingresponse putmappingresponse = client . admin ( ) . indices ( ) . putmapping ( putmappingrequest ) . get ( ) ; <nl> if ( ! putmappingresponse . isacknowledged ( ) ) { <nl> throw new illegalstateexception ( " failed to put mappings for audit logging <nl> } <nl> mmm a / shield / src / main / java / org / elasticsearch / shield / audit / index / indexaudituserholder . java <nl> ppp b / shield / src / main / java / org / elasticsearch / shield / audit / index / indexaudituserholder . java <nl>
public class esexceptiontests extends estestcase { <nl> } else { <nl> assertequals ( e . getcause ( ) . getclass ( ) , notserializableexceptionwrapper . class ) ; <nl> } <nl> - assertarrayequals ( e . getstacktrace ( ) , ex . getstacktrace ( ) ) ; <nl> + <nl> + / / but was : < sun . reflect . nativemethodaccessorimpl . invoke0 ( java . base @ 9 . 0 / native method ) > <nl> + if ( ! constants . jre_is_minimum_java9 ) { <nl> + assertarrayequals ( e . getstacktrace ( ) , ex . getstacktrace ( ) ) ; <nl> + } <nl> asserttrue ( e . getstacktrace ( ) . length > num ) ; <nl> elasticsearchassertions . assertversionserializable ( versionutils . randomversion ( getrandom ( ) ) , t ) ; <nl> elasticsearchassertions . assertversionserializable ( versionutils . randomversion ( getrandom ( ) ) , ex ) ; <nl> mmm a / core / src / test / java / org / elasticsearch / exceptionserializationtests . java <nl> ppp b / core / src / test / java / org / elasticsearch / exceptionserializationtests . java <nl>
public class exceptionserializationtests extends estestcase { <nl> } <nl> throwable deserialized = serialize ( t ) ; <nl> asserttrue ( deserialized instanceof notserializableexceptionwrapper ) ; <nl> - assertarrayequals ( t . getstacktrace ( ) , deserialized . getstacktrace ( ) ) ; <nl> - assertequals ( t . getsuppressed ( ) . length , deserialized . getsuppressed ( ) . length ) ; <nl> - if ( t . getsuppressed ( ) . length > num ) { <nl> - asserttrue ( deserialized . getsuppressed ( ) [ 0 ] instanceof notserializableexceptionwrapper ) ; <nl> - assertarrayequals ( t . getsuppressed ( ) [ 0 ] . getstacktrace ( ) , deserialized . getsuppressed ( ) [ 0 ] . getstacktrace ( ) ) ; <nl> - asserttrue ( deserialized . getsuppressed ( ) [ 1 ] instanceof nullpointerexception ) ; <nl> + <nl> + if ( ! constants . jre_is_minimum_java9 ) { <nl> + assertarrayequals ( t . getstacktrace ( ) , deserialized . getstacktrace ( ) ) ; <nl> + assertequals ( t . getsuppressed ( ) . length , deserialized . getsuppressed ( ) . length ) ; <nl> + if ( t . getsuppressed ( ) . length > num ) { <nl> + asserttrue ( deserialized . getsuppressed ( ) [ 0 ] instanceof notserializableexceptionwrapper ) ; <nl> + assertarrayequals ( t . getsuppressed ( ) [ 0 ] . getstacktrace ( ) , deserialized . getsuppressed ( ) [ 0 ] . getstacktrace ( ) ) ; <nl> + asserttrue ( deserialized . getsuppressed ( ) [ 1 ] instanceof nullpointerexception ) ; <nl> + } <nl> } <nl> } <nl> }
public class shieldintegration { <nl> } <nl> } <nl>  <nl> + <nl> + public void putuserincontext ( hascontext context ) { <nl> + if ( userholder ! = null ) { <nl> + context . putincontext ( " _shield_user " , ( ( watcheruserholder ) userholder ) . user ) ; <nl> + } <nl> + } <nl> + <nl> static boolean installed ( ) { <nl> try { <nl> shieldintegration . class . getclassloader ( ) . loadclass ( " org . elasticsearch . shield . shieldplugin " ) ; <nl> mmm a / watcher / src / main / java / org / elasticsearch / watcher / support / init / proxy / scriptserviceproxy . java <nl> ppp b / watcher / src / main / java / org / elasticsearch / watcher / support / init / proxy / scriptserviceproxy . java <nl>
public class routingtable implements iterable < indexroutingtable > , diffable < routi <nl> * iterator contains a single shardrouting pointing at the relocating target <nl> * / <nl> public groupshardsiterator allassignedshardsgrouped ( string [ ] indices , boolean includeempty , boolean includerelocationtargets ) { <nl> + return allsatisfyingpredicateshardsgrouped ( indices , includeempty , includerelocationtargets , assigned_predicate ) ; <nl> + } <nl> + <nl> + private static predicate < shardrouting > active_predicate = new predicate < shardrouting > ( ) { <nl> + @ override <nl> + public boolean apply ( shardrouting shardrouting ) { <nl> + return shardrouting . active ( ) ; <nl> + } <nl> + } ; <nl> + <nl> + private static predicate < shardrouting > assigned_predicate = new predicate < shardrouting > ( ) { <nl> + @ override <nl> + public boolean apply ( shardrouting shardrouting ) { <nl> + return shardrouting . assignedtonode ( ) ; <nl> + } <nl> + } ; <nl> + <nl> + <nl> + private groupshardsiterator allsatisfyingpredicateshardsgrouped ( string [ ] indices , boolean includeempty , boolean includerelocationtargets , predicate < shardrouting > predicate ) { <nl> / / use list here since we need to maintain identity across shards <nl> arraylist < sharditerator > set = new arraylist < > ( ) ; <nl> for ( string <nl>
public class indexshard extends abstractindexshardcomponent { <nl> if ( indexsettings . getasboolean ( indexcachemodule . query_cache_everything , false ) ) { <nl> cachingpolicy = querycachingpolicy . always_cache ; <nl> } else { <nl> - cachingpolicy = new usagetrackingquerycachingpolicy ( ) ; <nl> + assert version . current . luceneversion = = org . apache . lucene . util . version . lucene_5_2_1 ; <nl> + <nl> + / / cachingpolicy = new usagetrackingquerycachingpolicy ( ) ; <nl> + <nl> + final querycachingpolicy wrapped = new usagetrackingquerycachingpolicy ( ) ; <nl> + cachingpolicy = new querycachingpolicy ( ) { <nl> + <nl> + @ override <nl> + public boolean shouldcache ( query query , leafreadercontext context ) throws ioexception { <nl> + if ( query instanceof matchalldocsquery <nl> + / / matchnodocsquery currently rewrites to a booleanquery , <nl> + / / but who knows , it might get its own weight one day <nl> + | | query instanceof matchnodocsquery ) { <nl> + return false ; <nl> + } <nl> + if ( query instanceof booleanquery ) { <nl> + booleanquery bq = ( booleanquery ) query ; <nl> + if ( bq . clauses ( ) . isempty ( ) ) { <nl> + return false ; <nl> + } <nl> + } <nl> + if ( query instanceof disjunctionmaxquery ) { <nl> + disjunctionmaxquery dmq = ( disjunctionmaxquery ) query ; <nl> + if ( dmq . getdisjuncts ( ) . isempty ( ) ) { <nl> + return false ; <nl> + } <nl> + } <nl> + return wrapped . shouldcache ( query , context ) ; <nl> + } <nl> + <nl> + @ override <nl> + public void onuse ( query query ) { <nl> + wrapped . onuse ( query ) ; <nl> + } <nl> + } ; <nl> } <nl> this . engineconfig = newengineconfig ( translogconfig , cachingpolicy ) ; <nl> this . indexshardoperationcounter = new indexshardoperationcounter ( logger , shardid ) ;
<nl> + : : <nl> + : : build zip package , but ensuring its from the current source <nl> + : : turn off tests and other validation to speed it up <nl> + : : <nl> + call mvn - am - pl dev - tools , distribution / zip package - dskiptests - drun - pdev <nl> mmm a / run . sh <nl> ppp b / run . sh <nl>
<nl> < / parent > <nl>  <nl> < properties > <nl> + < ! - - we aren ' t really a plugin . . . - - > <nl> + < ! - - <nl> + < enforcer . skip > true < / enforcer . skip > <nl> < / properties > <nl>  <nl> < dependencies > <nl> mmm a / qa / smoke - test - plugins / pom . xml <nl> ppp b / qa / smoke - test - plugins / pom . xml <nl>
<nl> + / * <nl> + * licensed to elasticsearch under one or more contributor <nl> + * license agreements . see the notice file distributed with <nl> + * this work for additional information regarding copyright <nl> + * ownership . elasticsearch licenses this file to you under <nl> + * the apache license , version num . 0 ( the " license " ) ; you may <nl> + * not use this file except in compliance with the license . <nl> + * you may obtain a copy of the license at <nl> + * <nl> + * http : / / www . apache . org / licenses / license - 2 . 0 <nl> + * <nl> + * unless required by applicable law or agreed to in writing , <nl> + * software distributed under the license is distributed on an <nl> + * " as is " basis , without warranties or conditions of any <nl> + * kind , either express or implied . see the license for the <nl> + * specific language governing permissions and limitations <nl> + * under the license . <nl> + * / <nl> + <nl> + package org . elasticsearch . example ; <nl> + <nl> + import org . apache . http . impl . client . closeablehttpclient ; <nl> + import org . apache . http . impl . client . httpclients ; <nl> + import org . apache . http . impl . conn . poolinghttpclientconnectionmanager ; <nl> + import org . elasticsearch . test . esintegtestcase ; <nl> + import org . elasticsearch . test . externaltestcluster ; <nl> + import org . elasticsearch . test . testcluster ; <nl> + import org . elasticsearch . test . rest . client . restresponse ; <nl> + import org . elasticsearch . test . rest . client . http . httprequestbuilder ; <nl> + <nl> + import java . net . inetsocketaddress ; <nl> + import java . util . concurrent . timeunit ; <nl> + <nl> + / * * <nl> + * verifies content is actually served for the site plugin <nl> + * / <nl> + public class sitecontentsit extends esintegtestcase { <nl> + <nl> + <nl> + public void test ( ) throws exception { <nl> + testcluster cluster = cluster ( ) ; <nl> + assumetrue ( " this test will not work from an ide unless you pass test . cluster pointing to a running instance " , cluster instanceof externaltestcluster ) ; <nl> + externaltestcluster externalcluster = ( externaltestcluster ) cluster ; <nl> + try ( closeablehttpclient httpclient = httpclients . createminimal ( new poolinghttpclientconnectionmanager ( 15 , timeunit . seconds ) ) ) { <nl> + for ( inetsocketaddress address : externalcluster . httpaddresses ( ) ) { <nl> + restresponse restresponse = new restresponse ( <nl> + new httprequestbuilder ( httpclient ) <nl> + . host ( address . gethostname ( ) ) . port ( address . getport ( ) ) <nl> + . path ( " / _plugin / site - example / " ) <nl> + . method ( " get " ) . execute ( ) ) ; <nl> + assertequals ( 200 , restresponse . getstatuscode ( ) ) ; <nl> + string body = restresponse . getbodyasstring ( ) ; <nl> + asserttrue ( " unexpected body contents : " + body , body . contains ( " < body > page body < / body > " ) ) ; <nl> + } <nl> + } <nl> + } <nl> + }
public class internalauthorizationservice extends abstractcomponent implements a <nl> immutablelist . builder < string > indicesandaliases = immutablelist . builder ( ) ; <nl> predicate < string > predicate = predicates . or ( predicates . build ( ) ) ; <nl> metadata metadata = clusterservice . state ( ) . metadata ( ) ; <nl> - for ( string <nl> - if ( predicate . apply ( index ) ) { <nl> - indicesandaliases . add ( index ) ; <nl> - } <nl> - } <nl> - for ( iterator < string > iter = metadata . getaliases ( ) . keysit ( ) ; iter . hasnext ( ) ; ) { <nl> - string alias = iter . next ( ) ; <nl> - if ( predicate . apply ( alias ) ) { <nl> - indicesandaliases . add ( alias ) ; <nl> + <nl> + for ( map . entry < string , aliasorindex > entry : metadata . getaliasandindexlookup ( ) . entryset ( ) ) { <nl> + string aliasorindex = entry . getkey ( ) ; <nl> + if ( predicate . apply ( aliasorindex ) ) { <nl> + indicesandaliases . add ( aliasorindex ) ; <nl> } <nl> } <nl> return indicesandaliases . build ( ) ; <nl> mmm a / shield / src / main / java / org / elasticsearch / shield / authz / indicesresolver / defaultindicesresolver . java <nl> ppp b / shield / src / main / java / org / elasticsearch / shield / authz / indicesresolver / defaultindicesresolver . java <nl>
<nl> < / sequential > <nl> < / target > <nl>  <nl> + < ! - - run elasticsearch in the foreground ( for debugging etc ) - - > <nl> + < ! - - <nl> + < target name = " start - foreground " depends = " stop - external - cluster " > <nl> + < delete dir = " $ { integ . scratch } " / > <nl> + < unzip src = " $ { project . build . directory } / releases / $ { project . artifactid } - $ { project . version } . zip " dest = " $ { integ . scratch } " / > <nl> + < local name = " home " / > <nl> + < property name = " home " location = " $ { integ . scratch } / elasticsearch - $ { elasticsearch . version } " / > <nl> + < run - script dir = " $ { home } " script = " bin / elasticsearch " spawn = " false " <nl> + args = " $ { integ . args } - des . path . repo = $ { home } / repo " > <nl> + < nested > <nl> + < env key = " java_opts " value = " - agentlib : jdwp = transport = dt_socket , server = y , suspend = n , address = 8000 " / > <nl> + < / nested > <nl> + < / run - script > <nl> + < / target > <nl> + <nl> < ! - - unzip core release artifact and start es - - > <nl> < target name = " start - external - cluster " depends = " setup - workspace " unless = " $ { shouldskip } " > <nl> < startup - elasticsearch / >
<nl> < properties > <nl> < xplugins . basedir > $ { project . parent . basedir } < / xplugins . basedir > <nl> < tests . rest . blacklist > indices . get / 10_basic / * allow_no_indices * , cat . count / 10_basic / test cat count output , cat . aliases / 10_basic / empty cluster , indices . segments / 10_basic / no segments test , indices . clear_cache / 10_basic / clear_cache test , indices . status / 10_basic / indices status test , cat . indices / 10_basic / test cat indices output , cat . recovery / 10_basic / test cat recovery output , cat . shards / 10_basic / test cat shards output , termvector / 20_issue7121 / * , index / 10_with_id / index with id , indices . get_alias / 20_emtpy / * , cat . segments / 10_basic / test cat segments output , indices . put_settings / 10_basic / test indices settings allow_no_indices , indices . put_settings / 10_basic / test indices settings ignore_unavailable , indices . refresh / 10_basic / indices refresh test no - match wildcard , indices . stats / 10_index / index - star * , indices . recovery / 10_basic / indices recovery test * , template / 30_render_search_template / * < / tests . rest . blacklist > <nl> + < ! - - <nl> + < elasticsearch . integ . antfile > $ { basedir } / dev - tools / integration - tests . xml < / elasticsearch . integ . antfile > <nl> < / properties > <nl>  <nl> < dependencies > <nl> mmm a / watcher / pom . xml <nl> ppp b / watcher / pom . xml <nl>
<nl> < artifactid > aws - java - sdk - s3 < / artifactid > <nl> < version > $ { amazonaws . version } < / version > <nl> < / dependency > <nl> + < ! - - we need to force here the compile scope as it was defined as test scope in plugins / pom . xml - - > <nl> + < ! - - <nl> + < dependency > <nl> + < groupid > org . apache . httpcomponents < / groupid > <nl> + < artifactid > httpclient < / artifactid > <nl> + < scope > compile < / scope > <nl> + < / dependency > <nl> < / dependencies > <nl>  <nl> < build > <nl> mmm a / plugins / cloud - azure / pom . xml <nl> ppp b / plugins / cloud - azure / pom . xml <nl>
governing permissions and limitations under the license . - - > <nl> < artifactid > azure - management < / artifactid > <nl> < version > 0 . 7 . 0 < / version > <nl> < / dependency > <nl> + < ! - - we need to force here the compile scope as it was defined as test scope in plugins / pom . xml - - > <nl> + < ! - - <nl> + < dependency > <nl> + < groupid > org . apache . httpcomponents < / groupid > <nl> + < artifactid > httpclient < / artifactid > <nl> + < scope > compile < / scope > <nl> + < / dependency > <nl> < / dependencies > <nl>  <nl> < build > <nl> mmm a / plugins / cloud - gce / pom . xml <nl> ppp b / plugins / cloud - gce / pom . xml <nl>
governing permissions and limitations under the license . - - > <nl> < / exclusion > <nl> < / exclusions > <nl> < / dependency > <nl> + < ! - - we need to force here the compile scope as it was defined as test scope in plugins / pom . xml - - > <nl> + < ! - - <nl> + < dependency > <nl> + < groupid > org . apache . httpcomponents < / groupid > <nl> + < artifactid > httpclient < / artifactid > <nl> + < scope > compile < / scope > <nl> + < / dependency > <nl> < / dependencies > <nl>  <nl> < build > <nl> mmm a / plugins / delete - by - query / pom . xml <nl> ppp b / plugins / delete - by - query / pom . xml <nl>
<nl> < artifactid > jna < / artifactid > <nl> < scope > provided < / scope > <nl> < / dependency > <nl> + <nl> + < ! - - required by the rest test framework - - > <nl> + < ! - - <nl> + < dependency > <nl> + < groupid > org . apache . httpcomponents < / groupid > <nl> + < artifactid > httpclient < / artifactid > <nl> + < scope > test < / scope > <nl> + < / dependency > <nl> < / dependencies > <nl>  <nl> < ! - - typical layout for plugins - - >
<nl> < / repositories > <nl>  <nl> < properties > <nl> + < ! - - <nl> + < skip . integ . tests > true < / skip . integ . tests > <nl> < elasticsearch . license . header > dev - tools / elasticsearch_license_header . txt < / elasticsearch . license . header > <nl> < elasticsearch . license . headerdefinition > dev - tools / license_header_definition . xml < / elasticsearch . license . headerdefinition > <nl> < license . plugin . version > 2 . 0 . 0 - snapshot < / license . plugin . version >
public class variousdoctest extends attachmentunittestcase { <nl> * / <nl> @ test <nl> public void testasciidocdocument ( ) throws exception { <nl> - testtika ( " asciidoc . asciidoc " , false ) ; <nl> + assertparseable ( " asciidoc . asciidoc " ) ; <nl> testmapper ( " asciidoc . asciidoc " , false ) ; <nl> } <nl>  <nl> - protected void testtika ( string filename , boolean errorexpected ) { <nl> + void assertexception ( string filename ) { <nl> + tika tika = tika ( ) ; <nl> + assumetrue ( " tika has been disabled . ignoring test . . . " , tika ! = null ) ; <nl> + <nl> + try ( inputstream is = variousdoctest . class . getresourceasstream ( " / org / elasticsearch / index / mapper / attachment / test / sample - files / " + filename ) ) { <nl> + tika . parsetostring ( is ) ; <nl> + fail ( " expected exception " ) ; <nl> + } catch ( exception e ) { <nl> + <nl> + } <nl> + } <nl> + <nl> + protected void assertparseable ( string filename ) throws exception { <nl> tika tika = tika ( ) ; <nl> assumetrue ( " tika has been disabled . ignoring test . . . " , tika ! = null ) ; <nl>  <nl>
public final class settings implements toxcontent { <nl> private transient classloader classloader ; <nl>  <nl> settings ( map < string , string > settings , classloader classloader ) { <nl> - this . settings = immutablemap . copyof ( new treemap < > ( settings ) ) ; <nl> + / / we use a sorted map for consistent serialization when using getasmap ( ) <nl> + <nl> + this . settings = immutablesortedmap . copyof ( settings ) ; <nl> map < string , string > forcedunderscoresettings = null ; <nl> for ( map . entry < string , string > entry : settings . entryset ( ) ) { <nl> string tounderscorecase = strings . tounderscorecase ( entry . getkey ( ) ) ; <nl> mmm a / core / src / main / java / org / elasticsearch / index / mapper / core / abstractfieldmapper . java <nl> ppp b / core / src / main / java / org / elasticsearch / index / mapper / core / abstractfieldmapper . java <nl>
<nl> + / * <nl> + * copyright elasticsearch b . v . and / or licensed to elasticsearch b . v . under one <nl> + * or more contributor license agreements . licensed under the elastic license ; <nl> + * you may not use this file except in compliance with the elastic license . <nl> + * / <nl> + package org . elasticsearch . license . plugin . core ; <nl> + <nl> + import org . elasticsearch . elasticsearchexception ; <nl> + import org . elasticsearch . common . collect . tuple ; <nl> + <nl> + public class licenseutils { <nl> + <nl> + public final static string expired_feature_header = " es . license . expired . feature " ; <nl> + <nl> + / * * <nl> + * exception to be thrown when a feature action requires a valid license , but license <nl> + * has expired <nl> + * <nl> + * < code > feature < / code > accessible through { @ link # expired_feature_header } in the <nl> + * exception ' s rest header <nl> + * / <nl> + public static elasticsearchexception newexpirationexception ( string feature ) { <nl> + <nl> + return new elasticsearchexception . withrestheadersexception ( " license expired for feature [ " + feature + " ] " , <nl> + tuple . tuple ( expired_feature_header , new string [ ] { feature } ) ) ; <nl> + } <nl> + }
final class security { <nl> for ( map . entry < pattern , string > e : special_jars . entryset ( ) ) { <nl> if ( e . getkey ( ) . matcher ( url . getpath ( ) ) . matches ( ) ) { <nl> string prop = e . getvalue ( ) ; <nl> + <nl> + / / if ( system . getproperty ( prop ) ! = null ) { <nl> + / / throw new illegalstateexception ( " property : " + prop + " is unexpectedly set : " + system . getproperty ( prop ) ) ; <nl> + / / } <nl> system . setproperty ( prop , url . tostring ( ) ) ; <nl> } <nl> }
grant { <nl> / / needed by jdkesloggertests <nl> permission java . util . logging . loggingpermission " control " ; <nl>  <nl> - / / needed by mockito <nl> + / / needed by mockito to create mocks <nl> + <nl> permission java . lang . runtimepermission " reflectionfactoryaccess " ; <nl>  <nl> / / needed to install sslfactories , advanced ssl configuration , etc .
import static org . elasticsearch . test . hamcrest . elasticsearchassertions . assertsear <nl>  <nl> public class existsmissingtests extends elasticsearchintegrationtest { <nl>  <nl> + <nl> + public void testemptyindex ( ) throws exception { <nl> + createindex ( " test " ) ; <nl> + ensureyellow ( " test " ) ; <nl> + searchresponse resp = client ( ) . preparesearch ( " test " ) . setquery ( querybuilders . existsquery ( " foo " ) ) . execute ( ) . actionget ( ) ; <nl> + assertsearchresponse ( resp ) ; <nl> + resp = client ( ) . preparesearch ( " test " ) . setquery ( querybuilders . missingquery ( " foo " ) ) . execute ( ) . actionget ( ) ; <nl> + assertsearchresponse ( resp ) ; <nl> + } <nl> + <nl> public void testexistsmissing ( ) throws exception { <nl> xcontentbuilder mapping = xcontentbuilder . builder ( jsonxcontent . jsonxcontent ) <nl> . startobject ( )
migrateplugin " analysis - phonetic " <nl> migrateplugin " analysis - icu " <nl>  <nl> # mapper <nl> - migrateplugin " mapper - attachments " <nl> + # <nl> + # migrateplugin " mapper - attachments " <nl>  <nl> # cloud <nl> migrateplugin " cloud - gce "
package org . elasticsearch . common ; <nl> * / <nl> public class booleans { <nl>  <nl> - / / nocommit remove this lenient one and cutover to parsebooleanexact <nl> / * * <nl> * returns < code > false < / code > if text is in < tt > false < / tt > , < tt > 0 < / tt > , < tt > off < / tt > , < tt > no < / tt > ; else , true <nl> * / <nl> public static boolean parseboolean ( char [ ] text , int offset , int length , boolean defaultvalue ) { <nl> + <nl> if ( text = = null | | length = = num ) { <nl> return defaultvalue ; <nl> } <nl>
public class timevalue implements serializable , streamable { <nl> } <nl> try { <nl> long millis ; <nl> + <nl> if ( svalue . endswith ( " s " ) ) { <nl> millis = long . parselong ( svalue . substring ( 0 , svalue . length ( ) - num ) ) ; <nl> } else if ( svalue . endswith ( " ms " ) ) {
class jnanatives { <nl> logger . warn ( " unable to lock jvm memory : error = " + errno + " , reason = " + errmsg + " . this can result in part of the jvm being swapped out " ) ; <nl> if ( errno = = jnaclibrary . enomem ) { <nl> if ( rlimitsuccess ) { <nl> - logger . warn ( " increase rlimit_memlock ( ulimit ) . soft limit : " + softlimit + " , hard limit : " + hardlimit ) ; <nl> + logger . warn ( " increase rlimit_memlock ( ulimit ) . soft limit : " + rlimittostring ( softlimit ) + " , hard limit : " + rlimittostring ( hardlimit ) ) ; <nl> } else { <nl> logger . warn ( " increase rlimit_memlock ( ulimit ) . " ) ; <nl> } <nl> } <nl> } <nl>  <nl> + static string rlimittostring ( long value ) { <nl> + assert constants . linux | | constants . mac_os_x ; <nl> + if ( value = = jnaclibrary . rlim_infinity ) { <nl> + return " unlimited " ; <nl> + } else { <nl> + <nl> + return long . tostring ( value ) ; <nl> + } <nl> + } <nl> + <nl> / * * returns true if user is root , false if not , or if we don ' t know * / <nl> static boolean definitelyrunningasroot ( ) { <nl> if ( constants . windows ) {
<nl> < groupid > org . apache . maven . plugins < / groupid > <nl> < artifactid > maven - assembly - plugin < / artifactid > <nl> < / plugin > <nl> + < plugin > <nl> + < groupid > com . mycila < / groupid > <nl> + < artifactid > license - maven - plugin < / artifactid > <nl> + < configuration > <nl> + < excludes > <nl> + < ! - - <nl> + < exclude > * * / indexablebinarystringtools . java < / exclude > <nl> + < exclude > * * / icucollationkeyfilter . java < / exclude > <nl> + < exclude > * * / testindexablebinarystringtools . java < / exclude > <nl> + < / excludes > <nl> + < / configuration > <nl> + < / plugin > <nl> < / plugins > <nl> < / build >
grant { <nl> permission java . lang . runtimepermission " accessclassinpackage . sun . nio . ch " ; <nl> / / needed by groovy engine <nl> permission java . lang . runtimepermission " accessclassinpackage . sun . reflect " ; <nl> + <nl> + permission java . lang . runtimepermission " accessclassinpackage . sun . security . ssl " ; <nl>  <nl> / / needed by randomizedrunner <nl> permission java . lang . runtimepermission " accessdeclaredmembers " ; <nl> mmm a / src / test / java / org / elasticsearch / bootstrap / bootstrapfortesting . java <nl> ppp b / src / test / java / org / elasticsearch / bootstrap / bootstrapfortesting . java <nl>
public class metadatawritedatanodestests extends elasticsearchintegrationtest { <nl> assertmetastate ( nodename , indexname , true ) ; <nl> } <nl>  <nl> + <nl> private void assertmetastate ( final string nodename , final string indexname , final boolean shouldbe ) throws exception { <nl> awaitbusy ( new predicate < object > ( ) { <nl> @ override <nl> public boolean apply ( object o ) { <nl> logger . info ( " checking if meta state exists . . . " ) ; <nl> - return shouldbe = = metastateexists ( nodename , indexname ) ; <nl> + try { <nl> + return shouldbe = = metastateexists ( nodename , indexname ) ; <nl> + } catch ( throwable t ) { <nl> + logger . info ( " failed to load meta state " , t ) ; <nl> + <nl> + return false ; <nl> + } <nl> } <nl> } ) ; <nl> boolean inmetasate = metastateexists ( nodename , indexname ) ; <nl>
class security { <nl> path newconfig = processtemplate ( environment . configfile ( ) . resolve ( " security . policy " ) , environment ) ; <nl> system . setproperty ( " java . security . policy " , newconfig . tostring ( ) ) ; <nl> system . setsecuritymanager ( new securitymanager ( ) ) ; <nl> - try { <nl> - files . delete ( newconfig ) ; <nl> - } catch ( exception e ) { <nl> - loggers . getlogger ( security . class ) . warn ( " unable to remove temporary file : " + newconfig , e ) ; <nl> - } <nl> + ioutils . deletefilesignoringexceptions ( newconfig ) ; <nl> } <nl>  <nl> / / package - private for testing
public class movavgtests extends elasticsearchintegrationtest { <nl> numvaluebuckets = randomintbetween ( 6 , num ) ; <nl> numfilledvaluebuckets = numvaluebuckets ; <nl> windowsize = randomintbetween ( 3 , 10 ) ; <nl> - gappolicy = randomboolean ( ) ? buckethelpers . gappolicy . ignore : buckethelpers . gappolicy . insert_zeros ; <nl> + gappolicy = buckethelpers . gappolicy . insert_zeros ; <nl>  <nl> doccounts = new long [ numvaluebuckets ] ; <nl> valuecounts = new long [ numvaluebuckets ] ;
import static org . elasticsearch . test . hamcrest . elasticsearchassertions . * ; <nl> import static org . hamcrest . matchers . * ; <nl>  <nl> @ elasticsearchintegrationtest . clusterscope ( scope = elasticsearchintegrationtest . scope . suite ) <nl> + @ lucenetestcase . suppressfilesystems ( " extrasfs " ) <nl> public class corruptedfiletest extends elasticsearchintegrationtest { <nl>  <nl> @ override
<nl> < name > lucene snapshots < / name > <nl> < url > https : / / download . elastic . co / lucenesnapshots / 1674278 < / url > <nl> < / repository > <nl> + < ! - - <nl> + < repository > <nl> + < id > oss - sonatype < / id > <nl> + < name > temporarily situation < / name > <nl> + < url > http : / / oss . sonatype . org / content / repositories / releases < / url > <nl> + < / repository > <nl> < / repositories > <nl>  <nl> < dependencies > <nl>
public class mockdirectoryhelper { <nl> private final boolean crash ; <nl> private volatile runtimeexception closeexception ; <nl> private final object lock = new object ( ) ; <nl> + private final set < string > superunsyncedfiles ; <nl> + private final random superrandomstate ; <nl>  <nl> public elasticsearchmockdirectorywrapper ( random random , directory delegate , eslogger logger , boolean crash ) { <nl> super ( random , delegate ) ; <nl> this . crash = crash ; <nl> this . logger = logger ; <nl> + <nl> + <nl> + try { <nl> + field field = mockdirectorywrapper . class . getdeclaredfield ( " unsyncedfiles " ) ; <nl> + field . setaccessible ( true ) ; <nl> + superunsyncedfiles = ( set < string > ) field . get ( this ) ; <nl> + <nl> + field = mockdirectorywrapper . class . getdeclaredfield ( " randomstate " ) ; <nl> + field . setaccessible ( true ) ; <nl> + superrandomstate = ( random ) field . get ( this ) ; <nl> + } catch ( reflectiveoperationexception roe ) { <nl> + throw new runtimeexception ( roe ) ; <nl> + } <nl> } <nl>  <nl> @ override <nl>
import static org . hamcrest . matchers . equalto ; <nl> @ lucenetestcase . suppresscodecs ( value = { " lucene40 " , " lucene3x " } ) <nl> public abstract class abstractchildtests extends elasticsearchsinglenodelucenetestcase { <nl>  <nl> + <nl> + private static final querycache default_query_cache = indexsearcher . getdefaultquerycache ( ) ; <nl> + <nl> + @ before <nl> + public void disablequerycache ( ) { <nl> + indexsearcher . setdefaultquerycache ( null ) ; <nl> + } <nl> + <nl> + @ after <nl> + public void restorequerycache ( ) { <nl> + indexsearcher . setdefaultquerycache ( default_query_cache ) ; <nl> + } <nl> + <nl> / * * <nl> * the name of the field within the child type that stores a score to use in test queries . <nl> * < p / >
public abstract class elasticsearchlucenetestcase extends lucenetestcase { <nl> public static int scaledrandomintbetween ( int min , int max ) { <nl> return randomizedtest . scaledrandomintbetween ( min , max ) ; <nl> } <nl> + <nl> + @ afterclass <nl> + public static void cleardefaultquerycache ( ) { <nl> + <nl> + indexsearcher . setdefaultquerycache ( null ) ; <nl> + } <nl> }
public class jsonxcontentparser extends abstractxcontentparser { <nl>  <nl> @ override <nl> public bytesref utf8bytes ( ) throws ioexception { <nl> + / / tentative workaround for https : / / github . com / elastic / elasticsearch / issues / 8629 <nl> + <nl> + if ( parser . gettextlength ( ) = = num ) { <nl> + return new bytesref ( ) ; <nl> + } <nl> return new bytesref ( charbuffer . wrap ( parser . gettextcharacters ( ) , parser . gettextoffset ( ) , parser . gettextlength ( ) ) ) ; <nl> } <nl>  <nl> mmm / dev / null <nl> ppp b / src / test / java / org / elasticsearch / common / xcontent / cbor / cborxcontentparsertests . java <nl>
public class version { <nl> public static final int v_1_4_4_id = num ; <nl> public static final version v_1_4_4 = new version ( v_1_4_4_id , false , org . apache . lucene . util . version . lucene_4_10_3 ) ; <nl> public static final int v_1_4_5_id = num ; <nl> - public static final version v_1_4_5 = new version ( v_1_4_5_id , true , org . apache . lucene . util . version . lucene_4_10_3 ) ; <nl> + public static final version v_1_4_5 = new version ( v_1_4_5_id , true , org . apache . lucene . util . version . lucene_4_10_3 ) ; <nl> public static final int v_1_5_0_id = num ; <nl> public static final version v_1_5_0 = new version ( v_1_5_0_id , true , org . apache . lucene . util . version . lucene_4_10_3 ) ; <nl> + public static final int v_1_6_0_id = num ; <nl> + public static final version v_1_6_0 = new version ( v_1_6_0_id , true , org . apache . lucene . util . version . lucene_4_10_3 ) ; <nl> public static final int v_2_0_0_id = num ; <nl> public static final version v_2_0_0 = new version ( v_2_0_0_id , true , org . apache . lucene . util . version . lucene_5_1_0 ) ; <nl>  <nl>
public class recoveryfromgatewaytests extends elasticsearchintegrationtest { <nl> if ( numnodes = = num ) { <nl> logger . info ( " - - > one node is closed - start indexing data into the second one " ) ; <nl> client . prepareindex ( " test " , " type1 " , " 3 " ) . setsource ( jsonbuilder ( ) . startobject ( ) . field ( " field " , " value3 " ) . endobject ( ) ) . execute ( ) . actionget ( ) ; <nl> + <nl> + client . admin ( ) . cluster ( ) . preparehealth ( " test " ) . setwaitforyellowstatus ( ) . get ( ) ; <nl> client . admin ( ) . indices ( ) . preparerefresh ( ) . execute ( ) . actionget ( ) ; <nl>  <nl> for ( int i = num ; i < num ; i + + ) {
public class basicalertstests extends abstractalertsintegrationtests { <nl> . get ( ) ; <nl> assertthat ( indexresponse . indexresponse ( ) . iscreated ( ) , is ( true ) ) ; <nl>  <nl> + <nl> + / / we need to wait here because of a test timing issue . when we tear down a test we delete the alert and delete all <nl> + / / indices , but there may still be inflight fired alerts , which may trigger the alert history to be created again , before <nl> + / / we finished the tear down phase . <nl> + assertalertwithnoactionneeded ( " my - first - alert " , num ) ; <nl> + <nl> deletealertrequest deletealertrequest = new deletealertrequest ( " my - first - alert " ) ; <nl> deletealertresponse deletealertresponse = alertsclient . deletealert ( deletealertrequest ) . actionget ( ) ; <nl> assertnotnull ( deletealertresponse . deleteresponse ( ) ) ;
public class alertsservice extends abstractcomponent { <nl> manuallystopped = ! settings . getasboolean ( " alerts . start_immediately " , true ) ; <nl> } <nl>  <nl> + <nl> + / / and the first invocation sets the state to stopping then the second invocation will just return , because the <nl> + / / first invocation will do the work to stop alerts plugin . if the second invocation was caused by a test teardown <nl> + / / then the thread lead detection will fail , because it assumes that everything should have been stopped & closed . <nl> + / / this isn ' t the case in the situation , although this will happen , but to late for the thread leak detection to <nl> + / / not see it as a failure . <nl> + <nl> / * * <nl> * manually starts alerting if not already started <nl> * / <nl> mmm a / src / test / java / org / elasticsearch / alerts / test / abstractalertssinglenodetests . java <nl> ppp b / src / test / java / org / elasticsearch / alerts / test / abstractalertssinglenodetests . java <nl>
<nl> + / * <nl> + * copyright elasticsearch b . v . and / or licensed to elasticsearch b . v . under one <nl> + * or more contributor license agreements . licensed under the elastic license ; <nl> + * you may not use this file except in compliance with the elastic license . <nl> + * / <nl> + package org . elasticsearch . http . netty ; <nl> + <nl> + import org . elasticsearch . common . netty . channel . channelhandlercontext ; <nl> + import org . elasticsearch . common . netty . channel . exceptionevent ; <nl> + import org . elasticsearch . common . network . networkservice ; <nl> + import org . elasticsearch . common . settings . settings ; <nl> + import org . elasticsearch . common . util . bigarrays ; <nl> + <nl> + / * * <nl> + * makes the exceptioncaught method of { @ link org . elasticsearch . http . netty . nettyhttpservertransport } visible <nl> + * to overriding classes . <nl> + * <nl> + * <nl> + * / <nl> + public class visiblenettyhttpservertransport extends nettyhttpservertransport { <nl> + <nl> + public visiblenettyhttpservertransport ( settings settings , networkservice networkservice , bigarrays bigarrays ) { <nl> + super ( settings , networkservice , bigarrays ) ; <nl> + } <nl> + <nl> + @ override <nl> + protected void exceptioncaught ( channelhandlercontext ctx , exceptionevent e ) throws exception { <nl> + super . exceptioncaught ( ctx , e ) ; <nl> + } <nl> + <nl> + } <nl> mmm a / src / main / java / org / elasticsearch / shield / transport / netty / shieldnettyhttpservertransport . java <nl> ppp b / src / main / java / org / elasticsearch / shield / transport / netty / shieldnettyhttpservertransport . java <nl>
public class aggregatorparsers { <nl> subfactories = parseaggregators ( parser , context , level + 1 ) ; <nl> break ; <nl> default : <nl> - if ( aggfactory ! = null ) { <nl> - throw new searchparseexception ( context , " found two aggregation type definitions in [ " + aggregationname + " ] : [ " <nl> + if ( aggfactory ! = null ) { <nl> + throw new searchparseexception ( context , " found two aggregation type definitions in [ " + aggregationname + " ] : [ " <nl> + aggfactory . type + " ] and [ " + fieldname + " ] " ) ; <nl> } <nl> + if ( reducerfactory ! = null ) { <nl> + <nl> + throw new searchparseexception ( context , " found two aggregation type definitions in [ " + aggregationname + " ] : [ " <nl> + + reducerfactory + " ] and [ " + fieldname + " ] " ) ; <nl> + } <nl> + <nl> aggregator . parser aggregatorparser = parser ( fieldname ) ; <nl> if ( aggregatorparser = = null ) { <nl> - reducer . parser reducerparser = reducer ( fieldname ) ; <nl> - if ( reducerparser = = null ) { <nl> - throw new searchparseexception ( context , " could not find aggregator type [ " + fieldname + " ] in [ " <nl> + reducer . parser reducerparser = reducer ( fieldname ) ; <nl> + if ( reducerparser = = null ) { <nl> + throw new searchparseexception ( context , " could not find aggregator type [ " + fieldname + " ] in [ " <nl> + aggregationname + " ] " ) ; <nl> + } else { <nl> + reducerfactory = reducerparser . parse ( aggregationname , parser , context ) ; <nl> + } <nl> } else { <nl> - reducerfactory = reducerparser . parse ( aggregationname , parser , context ) ; <nl> + aggfactory = aggregatorparser . parse ( aggregationname , parser , context ) ; <nl> } <nl> - } else { <nl> - aggfactory = aggregatorparser . parse ( aggregationname , parser , context ) ; <nl> - } <nl> } <nl> } <nl>  <nl> if ( aggfactory = = null & & reducerfactory = = null ) { <nl> throw new searchparseexception ( context , " missing definition for aggregation [ " + aggregationname + " ] " ) ; <nl> } else if ( aggfactory ! = null ) { <nl> + assert reducerfactory = = null ; <nl> if ( metadata ! = null ) { <nl> aggfactory . setmetadata ( metadata ) ; <nl> } <nl>
public class aggregatorparsers { <nl> } <nl>  <nl> factories . addaggregator ( aggfactory ) ; <nl> - } else if ( reducerfactory ! = null ) { <nl> + } else { <nl> + assert reducerfactory ! = null ; <nl> if ( subfactories ! = null ) { <nl> throw new searchparseexception ( context , " aggregation [ " + aggregationname + " ] cannot define sub - aggregations " ) ; <nl> } <nl> + <nl> factories . addreducer ( reducerfactory ) ; <nl> - } else { <nl> - throw new searchparseexception ( context , " found two sub aggregation definitions under [ " + aggregationname + " ] " ) ; <nl> } <nl> }
public class attachmentmapper extends abstractfieldmapper < object > { <nl> / / set the maximum length of strings returned by the parsetostring method , - 1 sets no limit <nl> parsedcontent = tika ( ) . parsetostring ( new bytesstreaminput ( content , false ) , metadata , indexedchars ) ; <nl> } catch ( throwable e ) { <nl> + / / it could happen that tika adds a system property ` sun . font . fontmanager ` which should not happen <nl> + <nl> + system . clearproperty ( " sun . font . fontmanager " ) ; <nl> + <nl> / / # 18 : we could ignore errors when tika does not parse data <nl> if ( ! ignoreerrors ) { <nl> throw new mapperparsingexception ( " failed to extract [ " + indexedchars + " ] characters of text for [ " + name + " ] " , e ) ;
public class defaultindicesresolver implements indicesresolver < transportrequest > <nl> } <nl> } <nl>  <nl> + / * <nl> + * <nl> + * get https : / / github . com / elasticsearch / elasticsearch - shield / pull / 669 in <nl> + * / <nl> if ( indicesrequest instanceof indicesaliasesrequest ) { <nl> / / special treatment for indicesaliasesrequest since we need to extract indices from indices ( ) as well as aliases ( ) <nl> / / also , we need to replace wildcards in both with authorized indices and / or aliases ( indicesaliasesrequest doesn ' t implement replaceable ) <nl> mmm a / src / test / java / org / elasticsearch / shield / versioncompatibilitytests . java <nl> ppp b / src / test / java / org / elasticsearch / shield / versioncompatibilitytests . java <nl>
import java . util . hashset ; <nl> import java . util . set ; <nl> import java . util . concurrent . atomic . atomicinteger ; <nl>  <nl> + <nl> public class clusterdiscoveryconfiguration extends settingssource { <nl>  <nl> - static { <nl> - / / see https : / / github . com / elasticsearch / elasticsearch / pull / 8634 <nl> - assert version . current . onorbefore ( version . v_1_4_2 ) : " remove this class or bump the version , the required fixes will come with es core num . 5 " ; <nl> - } <nl> - <nl> static settings default_node_settings = immutablesettings . settingsbuilder ( ) <nl> . put ( " gateway . type " , " local " ) <nl> . put ( " discovery . type " , " zen " ) . build ( ) ;
public class securedmessagechannelhandler extends messagechannelhandler { <nl> return action ; <nl> } <nl>  <nl> - / * * <nl> - * should be removed after upgrade <nl> - * / <nl> + <nl> public static class visiblenettytransportchannel extends nettytransportchannel { <nl>  <nl> private final string profile ; <nl>
public class securedmessagechannelhandler extends messagechannelhandler { <nl> } <nl> } <nl>  <nl> - / * * <nl> - * this is just here to make this class visible <nl> - * / <nl> + <nl> class requesthandler extends abstractrunnable { <nl> private final transportrequesthandler handler ; <nl> private final transportrequest request ; <nl> mmm / dev / null <nl> ppp b / src / test / java / org / elasticsearch / shield / versioncompatibilitychecks . java <nl>
import java . util . map ; <nl> * <nl> * see < a href = " https : / / github . com / elasticsearch / elasticsearch / pull / 9134 " > https : / / github . com / elasticsearch / elasticsearch / pull / 9134 < / a > <nl> * / <nl> + <nl> public class transportprofileutil { <nl>  <nl> private transportprofileutil ( ) { }
public class version implements serializable { <nl> public static final int v_1_4_3_id = / * 00 * / 1040399 ; <nl> public static final version v_1_4_3 = new version ( v_1_4_3_id , false , org . apache . lucene . util . version . lucene_4_10_2 ) ; <nl> public static final int v_1_5_0_id = / * 00 * / 1050099 ; <nl> - public static final version v_1_5_0 = new version ( v_1_5_0_id , false , org . apache . lucene . util . version . lucene_4_10_2 ) ; <nl> + public static final version v_1_5_0 = new version ( v_1_5_0_id , false , org . apache . lucene . util . version . frombits ( 4 , num , num ) ) ; <nl> public static final int v_2_0_0_id = / * 00 * / 2000099 ; <nl> public static final version v_2_0_0 = new version ( v_2_0_0_id , true , org . apache . lucene . util . version . lucene_5_0_0 ) ;
import java . util . map ; <nl> import static org . elasticsearch . test . hamcrest . elasticsearchassertions . assertacked ; <nl>  <nl> public class oldindexbackwardscompatibilitytests extends staticindexbackwardcompatibilitytest { <nl> + <nl>  <nl> list < string > indexes = arrays . aslist ( <nl> - / / not yet : until https : / / github . com / elasticsearch / elasticsearch / pull / 9142 <nl> - / / " index - 0 . 20 . 6 . zip " , <nl> " index - 0 . 90 . 0 . zip " , <nl> " index - 0 . 90 . 1 . zip " , <nl> " index - 0 . 90 . 2 . zip " ,
public class alertactionmanager extends abstractcomponent { <nl> } <nl>  <nl> public void addalertaction ( alert alert , datetime scheduledfiretime , datetime firetime ) throws ioexception { <nl> + addalertaction ( alert , scheduledfiretime , firetime , true ) ; <nl> + } <nl> + <nl> + public void addalertaction ( alert alert , datetime scheduledfiretime , datetime firetime , boolean retry ) throws ioexception { <nl> ensurestarted ( ) ; <nl> logger . debug ( " adding alert action for alert [ { } ] " , alert . alertname ( ) ) ; <nl> - <nl> - alertactionentry entry = new alertactionentry ( alert , scheduledfiretime , firetime , alertactionstate . search_needed ) ; <nl> string alerthistoryindex = getalerthistoryindexnamefortime ( scheduledfiretime ) ; <nl> - indexresponse response = client . prepareindex ( alerthistoryindex , alert_history_type , entry . getid ( ) ) <nl> - . setsource ( xcontentfactory . jsonbuilder ( ) . value ( entry ) ) <nl> - . setoptype ( indexrequest . optype . create ) <nl> - . get ( ) ; <nl> + alertactionentry entry = new alertactionentry ( alert , scheduledfiretime , firetime , alertactionstate . search_needed ) ; <nl> + try { <nl> + indexresponse response = client . prepareindex ( alerthistoryindex , alert_history_type , entry . getid ( ) ) <nl> + . setsource ( xcontentfactory . jsonbuilder ( ) . value ( entry ) ) <nl> + . setoptype ( indexrequest . optype . create ) <nl> + . get ( ) ; <nl> + entry . setversion ( response . getversion ( ) ) ; <nl> + } catch ( indexmissingexception ime ) { <nl> + / <nl> + if ( retry ) { <nl> + logger . error ( " unable to dynamically implicitly create alert history <nl> + client . admin ( ) . indices ( ) . preparecreate ( alerthistoryindex ) . get ( ) ; <nl> + addalertaction ( alert , scheduledfiretime , firetime , false ) ; <nl> + } else { <nl> + throw new elasticsearchexception ( " unable to create alert history <nl> + } <nl> + } <nl>  <nl> - entry . setversion ( response . getversion ( ) ) ; <nl> long currentsize = actionstobeprocessed . size ( ) + num ; <nl> actionstobeprocessed . add ( entry ) ; <nl> long currentlargestqueuesize = largestqueuesize . get ( ) ;
public class internalauthorizationservice extends abstractcomponent implements a <nl> private final audittrail audittrail ; <nl> private final indicesresolver [ ] indicesresolvers ; <nl>  <nl> - static { <nl> - / / see https : / / github . com / elasticsearch / elasticsearch / pull / 8415 <nl> - assert version . current . onorbefore ( version . v_1_4_0 ) : " replace the provider < clusterservice > with clusterservice " ; <nl> - } <nl> - <nl> @ inject <nl> + <nl> public internalauthorizationservice ( settings settings , rolesstore rolesstore , provider < clusterservice > clusterserviceprovider , audittrail audittrail ) { <nl> super ( settings ) ; <nl> this . rolesstore = rolesstore ;
public class unicastzenping extends abstractlifecyclecomponent < zenping > implemen <nl> sendpingshandler . close ( ) ; <nl> } <nl> } ) ; <nl> + } catch ( esrejectedexecutionexception ex ) { <nl> + sendpingshandler . close ( ) ; <nl> + / / we are shutting down <nl> } catch ( exception e ) { <nl> sendpingshandler . close ( ) ; <nl> throw new elasticsearchexception ( " ping execution failed " , e ) ;
<nl>  <nl> < groupid > org . elasticsearch < / groupid > <nl> < artifactid > elasticsearch - license < / artifactid > <nl> - < version > 1 . 0 - snapshot < / version > <nl> + < version > 1 . 0 . 0 - snapshot < / version > <nl> + <nl> + < parent > <nl> + < groupid > org . sonatype . oss < / groupid > <nl> + < artifactid > oss - parent < / artifactid > <nl> + < version > 7 < / version > <nl> + < / parent > <nl>  <nl> < properties > <nl> < elasticsearch . version > 1 . 4 . 0 - snapshot < / elasticsearch . version > <nl> < lucene . version > 4 . 10 . 1 < / lucene . version > <nl> + < ! - - <nl> < keys . path > $ { basedir } / src / test / resources < / keys . path > <nl> - < project . build . sourceencoding > utf - 8 < / project . build . sourceencoding > <nl> < / properties > <nl>  <nl> < dependencies > <nl>
public abstract class elasticsearchintegrationtest extends elasticsearchtestcase <nl> logger . info ( " [ { } # { } ] : cleaned up after test " , gettestclass ( ) . getsimplename ( ) , gettestname ( ) ) ; <nl> success = true ; <nl> } finally { <nl> + <nl> if ( ! success | | currenttestfailedmarker . testfailed ( ) ) { <nl> - <nl> - logger . info ( " [ { } # { } ] : now dump all thread stacks on failure " , gettestclass ( ) . getsimplename ( ) , gettestname ( ) ) ; <nl> - elasticsearchtestcase . printstackdump ( logger ) ; <nl> - logger . info ( " [ { } # { } ] : done dump all thread stacks on failure " , gettestclass ( ) . getsimplename ( ) , gettestname ( ) ) ; <nl> - <nl> / / if we failed that means that something broke horribly so we should <nl> / / clear all clusters and if the current cluster is the global we shut that one <nl> / / down as well to prevent subsequent tests from failing due to the same problem . <nl> mmm / dev / null <nl> ppp b / src / test / java / org / elasticsearch / test / printallthreadstacksonfailure . java <nl>
public class acktests extends elasticsearchintegrationtest { <nl>  <nl> @ test <nl> public void testdeletewarmeracknowledgement ( ) { <nl> - createindex ( " test " ) ; <nl> + <nl> + assertacked ( client ( ) . admin ( ) . indices ( ) . preparecreate ( " test " ) . setsettings ( <nl> + immutablesettings . settingsbuilder ( ) <nl> + / / never run checkindex in the end : <nl> + . put ( mockfsdirectoryservice . check_index_on_close , false ) . build ( ) ) ) ; <nl> ensuregreen ( ) ; <nl>  <nl> assertacked ( client ( ) . admin ( ) . indices ( ) . prepareputwarmer ( " custom_warmer " ) <nl>
public class acktests extends elasticsearchintegrationtest { <nl>  <nl> @ test <nl> public void testdeletewarmernoacknowledgement ( ) throws interruptedexception { <nl> - createindex ( " test " ) ; <nl> + <nl> + assertacked ( client ( ) . admin ( ) . indices ( ) . preparecreate ( " test " ) . setsettings ( <nl> + immutablesettings . settingsbuilder ( ) <nl> + / / never run checkindex in the end : <nl> + . put ( mockfsdirectoryservice . check_index_on_close , false ) . build ( ) ) ) ; <nl> ensuregreen ( ) ; <nl>  <nl> assertacked ( client ( ) . admin ( ) . indices ( ) . prepareputwarmer ( " custom_warmer " ) <nl>
public class acktests extends elasticsearchintegrationtest { <nl>  <nl> @ test <nl> public void testindicesaliasesnoacknowledgement ( ) { <nl> - createindex ( " test " ) ; <nl> + <nl> + assertacked ( client ( ) . admin ( ) . indices ( ) . preparecreate ( " test " ) . setsettings ( <nl> + immutablesettings . settingsbuilder ( ) <nl> + / / never run checkindex in the end : <nl> + . put ( mockfsdirectoryservice . check_index_on_close , false ) . build ( ) ) ) ; <nl>  <nl> indicesaliasesresponse indicesaliasesresponse = client ( ) . admin ( ) . indices ( ) . preparealiases ( ) . addalias ( " test " , " alias " ) . settimeout ( " 0s " ) . get ( ) ; <nl> assertthat ( indicesaliasesresponse . isacknowledged ( ) , equalto ( false ) ) ;
public class acktests extends elasticsearchintegrationtest { <nl>  <nl> @ test <nl> public void testupdatesettingsnoacknowledgement ( ) { <nl> - createindex ( " test " ) ; <nl> + <nl> + assertacked ( client ( ) . admin ( ) . indices ( ) . preparecreate ( " test " ) . setsettings ( <nl> + immutablesettings . settingsbuilder ( ) <nl> + / / never run checkindex in the end : <nl> + . put ( mockfsdirectoryservice . check_index_on_close , false ) . build ( ) ) ) ; <nl>  <nl> updatesettingsresponse updatesettingsresponse = client ( ) . admin ( ) . indices ( ) . prepareupdatesettings ( " test " ) . settimeout ( " 0s " ) <nl> . setsettings ( immutablesettings . builder ( ) . put ( " refresh_interval " , num ) ) . get ( ) ;
public final class elasticsearchthreadfilter implements threadfilter { <nl> | | threadname . contains ( " keep - alive - timer " ) ) { <nl> return true ; <nl> } <nl> - return nodeprefix . matcher ( t . getname ( ) ) . find ( ) ; <nl> + return nodeprefix . matcher ( t . getname ( ) ) . find ( ) | | true ; <nl> } <nl> } <nl> \ no newline at end of file
public abstract class elasticsearchintegrationtest extends elasticsearchtestcase <nl> builder . put ( indicesquerycache . index_cache_query_enabled , random . nextboolean ( ) ) ; <nl> } <nl>  <nl> - if ( random . nextboolean ( ) ) { <nl> + / / disabled for now as it seems to make tests unstable <nl> + <nl> + / * if ( random . nextboolean ( ) ) { <nl> builder . put ( indexfielddataservice . fielddata_cache_key , randomfrom ( <nl> indexfielddataservice . fielddata_cache_value_node , <nl> indexfielddataservice . fielddata_cache_value_resident , <nl> indexfielddataservice . fielddata_cache_value_soft ) ) ; <nl> - } <nl> + } * / <nl>  <nl> return builder ; <nl> }
public class clitoolconfig { <nl> } <nl>  <nl> public options options ( ) { <nl> - return options ; <nl> + <nl> + / / see https : / / issues . apache . org / jira / browse / cli - 183 <nl> + options copy = new options ( ) ; <nl> + for ( object ooption : options . getoptions ( ) ) { <nl> + option option = ( option ) ooption ; <nl> + copy . addoption ( option ) ; <nl> + } <nl> + optionssource . verbosity . populate ( copy ) ; <nl> + return copy ; <nl> } <nl>  <nl> public void printusage ( terminal terminal ) { <nl> mmm a / src / test / java / org / elasticsearch / common / cli / clitooltests . java <nl> ppp b / src / test / java / org / elasticsearch / common / cli / clitooltests . java <nl>
public class corruptedfiletest extends elasticsearchintegrationtest { <nl> final file [ ] files = file . listfiles ( new filefilter ( ) { <nl> @ override <nl> public boolean accept ( file pathname ) { <nl> - return pathname . isfile ( ) & & ! " write . lock " . equals ( pathname . getname ( ) ) ; <nl> + return pathname . isfile ( ) & & ! " write . lock " . equals ( pathname . getname ( ) ) <nl> + & & ! pathname . getname ( ) . endswith ( " . del " ) ; / / temporary fix - del files might be generational and we corrupt an old generation <nl> + <nl> } <nl> } ) ; <nl> if ( files . length > num ) {
public class store extends abstractindexshardcomponent implements closeableindex <nl> / / no segments file - - can ' t read metadata <nl> logger . trace ( " can ' t read segment infos " , ex ) ; <nl> return immutablemap . of ( ) ; <nl> + } catch ( eofexception eof ) { <nl> + <nl> + throw new corruptindexexception ( " read past eof while reading segment infos " , eof ) ; <nl> } <nl> version maxversion = version . lucene_3_0 ; / / we don ' t know which version was used to write so we take the max version . <nl> set < string > added = new hashset < > ( ) ;
package org . elasticsearch . discovery . gce ; <nl>  <nl> import org . elasticsearch . common . settings . immutablesettings ; <nl> import org . elasticsearch . common . settings . settings ; <nl> + import org . junit . ignore ; <nl>  <nl> + / * * <nl> + * we need to ignore this test from elasticsearch version num . 2 . 1 as <nl> + * expected nodes running is num and this test will create num clusters with one node each . <nl> + * @ see org . elasticsearch . test . elasticsearchintegrationtest # ensureclustersizeconsistency ( ) <nl> + * <nl> + * / <nl> + @ ignore <nl> public class gcedifferenttagsonetagtest extends abstractgcecomputeservicetest { <nl>  <nl> @ override <nl> mmm a / src / test / java / org / elasticsearch / discovery / gce / gcedifferenttagstwotagstest . java <nl> ppp b / src / test / java / org / elasticsearch / discovery / gce / gcedifferenttagstwotagstest . java <nl>
package org . elasticsearch . discovery . gce ; <nl>  <nl> import org . elasticsearch . common . settings . immutablesettings ; <nl> import org . elasticsearch . common . settings . settings ; <nl> + import org . junit . ignore ; <nl>  <nl> + / * * <nl> + * we need to ignore this test from elasticsearch version num . 2 . 1 as <nl> + * expected nodes running is num and this test will create num clusters with one node each . <nl> + * @ see org . elasticsearch . test . elasticsearchintegrationtest # ensureclustersizeconsistency ( ) <nl> + * <nl> + * / <nl> + @ ignore <nl> public class gcedifferenttagstwotagstest extends abstractgcecomputeservicetest { <nl>  <nl> @ override
public class indicesfielddatacache extends abstractcomponent implements removall <nl>  <nl> @ override <nl> public void clear ( ) { <nl> + <nl> for ( key key : cache . asmap ( ) . keyset ( ) ) { <nl> if ( key . indexcache . index . equals ( index ) ) { <nl> cache . invalidate ( key ) ; <nl> } <nl> } <nl> + / / there is an explicit call to cache . cleanup ( ) here because cache <nl> + / / invalidation in guava does not immediately remove values from the <nl> + / / cache . in the case of a cache with a rare write or read rate , <nl> + / / it ' s possible for values to persist longer than desired . in the <nl> + / / case of the circuit breaker , when clearing the entire cache all <nl> + / / entries should immediately be evicted so that their sizes are <nl> + / / removed from the breaker estimates . <nl> + / / <nl> + / / note this is intended by the guava developers , see : <nl> + / / https : / / code . google . com / p / guava - libraries / wiki / cachesexplained # eviction <nl> + / / ( the " when does cleanup happen " section ) <nl> + cache . cleanup ( ) ; <nl> } <nl>  <nl> @ override
public class multimatchquerytests extends elasticsearchintegrationtest { <nl> asserthitcount ( searchresponse , num l ) ; <nl> } <nl>  <nl> + @ test <nl> + public void testsinglefield ( ) { <nl> + searchresponse searchresponse = client ( ) . preparesearch ( " test " ) <nl> + . setquery ( randomizetype ( multimatchquery ( " 15 " , " skill " ) ) ) . get ( ) ; <nl> + assertnofailures ( searchresponse ) ; <nl> + assertfirsthit ( searchresponse , hasid ( " theone " ) ) ; <nl> + <nl> + } <nl> + <nl> @ test <nl> public void testcutofffreq ( ) throws executionexception , interruptedexception { <nl> final long numdocs = client ( ) . preparecount ( " test " )
public class concurrentmergeschedulerprovider extends mergeschedulerprovider { <nl> public concurrentmergeschedulerprovider ( shardid shardid , @ indexsettings settings indexsettings , threadpool threadpool , indexsettingsservice indexsettingsservice ) { <nl> super ( shardid , indexsettings , threadpool ) ; <nl> this . indexsettingsservice = indexsettingsservice ; <nl> - this . maxthreadcount = componentsettings . getasint ( " max_thread_count " , concurrentmergescheduler . default_max_thread_count ) ; <nl> - this . maxmergecount = componentsettings . getasint ( " max_merge_count " , concurrentmergescheduler . default_max_merge_count ) ; <nl> + <nl> + this . maxthreadcount = componentsettings . getasint ( " max_thread_count " , math . max ( 1 , math . min ( 3 , runtime . getruntime ( ) . availableprocessors ( ) / num ) ) ) ; <nl> + this . maxmergecount = componentsettings . getasint ( " max_merge_count " , maxthreadcount + num ) ; <nl> logger . debug ( " using [ concurrent ] merge scheduler with max_thread_count [ { } ] , max_merge_count [ { } ] " , maxthreadcount , maxmergecount ) ; <nl>  <nl> indexsettingsservice . addlistener ( applysettings ) ;
public class indicesoptionstests extends elasticsearchintegrationtest { <nl>  <nl> options = indicesoptions . strict ( ) ; <nl> assertacked ( preparecreate ( " test2 " ) ) ; <nl> - ensureyellow ( ) ; <nl> + <nl> + ensuregreen ( ) ; <nl> + waitforrelocation ( ) ; <nl> verify ( snapshot ( " snap3 " , " test1 " , " test2 " ) . setindicesoptions ( options ) , false ) ; <nl> verify ( restore ( " snap3 " , " test1 " , " test2 " ) . setindicesoptions ( options ) , false ) ; <nl> } <nl>
public class indicesoptionstests extends elasticsearchintegrationtest { <nl> verify ( restore ( " snap2 " , " foo * " , " bar * " ) . setindicesoptions ( options ) , false ) ; <nl>  <nl> assertacked ( preparecreate ( " barbaz " ) ) ; <nl> - ensureyellow ( ) ; <nl> + <nl> + ensuregreen ( ) ; <nl> + waitforrelocation ( ) ; <nl> options = indicesoptions . fromoptions ( false , false , true , false ) ; <nl> verify ( snapshot ( " snap3 " , " foo * " , " bar * " ) . setindicesoptions ( options ) , false ) ; <nl> verify ( restore ( " snap3 " , " foo * " , " bar * " ) . setindicesoptions ( options ) , false ) ;
import java . util . * ; <nl> * / <nl> public abstract class internalsignificantterms extends internalaggregation implements significantterms , toxcontent , streamable { <nl>  <nl> + protected int requiredsize ; <nl> + protected long mindoccount ; <nl> + protected collection < bucket > buckets ; <nl> + protected map < string , bucket > bucketmap ; <nl> + protected long subsetsize ; <nl> + protected long supersetsize ; <nl> + protected internalsignificantterms ( ) { } / / for serialization <nl> + <nl> + <nl> + @ suppresswarnings ( " pmd . constructorcallsoverridablemethod " ) <nl> public static abstract class bucket extends significantterms . bucket { <nl>  <nl> long bucketord ; <nl>
public abstract class blobstorerepository extends abstractlifecyclecomponent < rep <nl> public snapshot readsnapshot ( snapshotid snapshotid ) { <nl> try { <nl> string blobname = snapshotblobname ( snapshotid ) ; <nl> - byte [ ] data = snapshotsblobcontainer . readblobfully ( blobname ) ; <nl> - return readsnapshot ( data ) ; <nl> + int retrycount = num ; <nl> + while ( true ) { <nl> + byte [ ] data = snapshotsblobcontainer . readblobfully ( blobname ) ; <nl> + / / because we are overriding snapshot during finalization , it ' s possible that <nl> + / / we can get an empty or incomplete snapshot for a brief moment <nl> + / / retrying after some what can resolve the issue <nl> + <nl> + try { <nl> + return readsnapshot ( data ) ; <nl> + } catch ( elasticsearchparseexception ex ) { <nl> + if ( retrycount + + < num ) { <nl> + try { <nl> + thread . sleep ( 50 ) ; <nl> + } catch ( interruptedexception ex1 ) { <nl> + thread . currentthread ( ) . interrupt ( ) ; <nl> + } <nl> + } else { <nl> + throw ex ; <nl> + } <nl> + } <nl> + } <nl> } catch ( filenotfoundexception ex ) { <nl> throw new snapshotmissingexception ( snapshotid , ex ) ; <nl> } catch ( ioexception ex ) { <nl>
public class bloomfilter { <nl> out . writeint ( 0 ) ; / / hashtype <nl> } <nl>  <nl> + <nl> + public static bloomfilter readfrom ( streaminput in ) throws ioexception { <nl> + int version = in . readvint ( ) ; / / we do nothing with this now . . . , defaults to num <nl> + <nl> + int numlongs = in . readvint ( ) ; <nl> + long [ ] data = new long [ numlongs ] ; <nl> + for ( int i = num ; i < numlongs ; i + + ) { <nl> + data [ i ] = in . readlong ( ) ; <nl> + } <nl> + <nl> + int numberofhashfunctions = in . readvint ( ) ; <nl> + <nl> + int hashtype = in . readvint ( ) ; / / again , nothing to do now . . . <nl> + <nl> + return new bloomfilter ( new bitarray ( data ) , numberofhashfunctions ) ; <nl> + } <nl> + <nl> + public static void writeto ( bloomfilter filter , streamoutput out ) throws ioexception { <nl> + out . writevint ( 0 ) ; / / version <nl> + <nl> + bitarray bits = filter . bits ; <nl> + out . writevint ( bits . data . length ) ; <nl> + for ( long l : bits . data ) { <nl> + out . writelong ( l ) ; <nl> + } <nl> + <nl> + out . writevint ( filter . numhashfunctions ) ; <nl> + <nl> + out . writevint ( 0 ) ; / / hashtype <nl> + } <nl> + <nl> / * * <nl> * the bit set of the bloomfilter ( not necessarily power of num ! ) <nl> * / <nl>
<nl> - match : { get . fields . foo : bar } <nl> - is_false : get . fields . bar <nl>  <nl> - <nl> - # # # # add _routing etc <nl> + # <nl> + # <nl> + # - add _routing <nl> mmm a / rest - api - spec / test / update / 85_fields_meta . yaml <nl> ppp b / rest - api - spec / test / update / 85_fields_meta . yaml <nl>
import java . io . ioexception ; <nl> * / <nl> public class docidsets { <nl>  <nl> + static { <nl> + <nl> + assert version . lucene_44 . onorafter ( lucene . version ) ; <nl> + } <nl> + <nl> public static long sizeinbytes ( docidset docidset ) { <nl> if ( docidset instanceof fixedbitset ) { <nl> return ( ( fixedbitset ) docidset ) . getbits ( ) . length * num + num ;
public class updatemappingtests extends abstractsharedclustertest { <nl> @ suppresswarnings ( " unchecked " ) <nl> @ test <nl> public void updatedefaultmappingsettings ( ) throws exception { <nl> - client ( ) . admin ( ) . indices ( ) . preparecreate ( " test " ) . addmapping ( mapperservice . default_mapping , <nl> + <nl> + <nl> + createindex ( " test " ) ; <nl> + client ( ) . admin ( ) . indices ( ) . prepareputmapping ( " test " ) . settype ( mapperservice . default_mapping ) . setsource ( <nl> jsonxcontent . contentbuilder ( ) . startobject ( ) . startobject ( mapperservice . default_mapping ) <nl> . field ( " date_detection " , false ) <nl> . endobject ( ) . endobject ( )
public class updatesettingstests extends abstractsharedclustertest { <nl> assertthat ( indexmetadata . settings ( ) . get ( " index . refresh_interval " ) , equalto ( " 1s " ) ) ; <nl> assertthat ( indexmetadata . settings ( ) . get ( " index . cache . filter . type " ) , equalto ( " none " ) ) ; <nl> } <nl> + <nl> + @ test <nl> + public void testrobinenginegcdeletessetting ( ) throws interruptedexception { <nl> + createindex ( " test " ) ; <nl> + client ( ) . prepareindex ( " test " , " type " , " 1 " ) . setsource ( " f " , num ) . get ( ) ; / / set version to num <nl> + client ( ) . preparedelete ( " test " , " type " , " 1 " ) . get ( ) ; / / sets version to num <nl> + client ( ) . prepareindex ( " test " , " type " , " 1 " ) . setsource ( " f " , num ) . setversion ( 2 ) . get ( ) ; / / delete is still in cache this should work & set version to num <nl> + client ( ) . admin ( ) . indices ( ) . prepareupdatesettings ( " test " ) <nl> + . setsettings ( immutablesettings . settingsbuilder ( ) <nl> + . put ( " index . gc_deletes " , num ) <nl> + ) . get ( ) ; <nl> + <nl> + client ( ) . preparedelete ( " test " , " type " , " 1 " ) . get ( ) ; / / sets version to num <nl> + thread . sleep ( 300 ) ; <nl> + assertthrows ( client ( ) . prepareindex ( " test " , " type " , " 1 " ) . setsource ( " f " , num ) . setversion ( 4 ) , versionconflictengineexception . class ) ; / / delete is should not be in cache <nl> + <nl> + } <nl> } <nl> \ no newline at end of file
public class simplenestedtests extends abstractsharedclustertest { <nl> assertthat ( termsstatsfacet . getentries ( ) . get ( 0 ) . getcount ( ) , equalto ( 3l ) ) ; <nl> assertthat ( termsstatsfacet . getentries ( ) . get ( 0 ) . gettotal ( ) , equalto ( 8d ) ) ; <nl>  <nl> + <nl> + refresh ( ) ; <nl> + <nl> / / test scope ones ( post based ) <nl> searchresponse = client ( ) . preparesearch ( " test " ) <nl> . setquery ( <nl>
public class stringscriptdatacomparator extends fieldcomparator < bytesref > { <nl>  <nl> private final searchscript script ; <nl>  <nl> - private bytesref [ ] values ; <nl> + private bytesref [ ] values ; <nl>  <nl> private bytesref bottom ; <nl>  <nl> - private bytesref spare = new bytesref ( ) ; <nl> + private final bytesref spare = new bytesref ( ) ; <nl>  <nl> private int sparedoc = - 1 ; <nl>  <nl>
<nl> " paths " : [ " / _suggest " , " / { index } / _suggest " ] , <nl> " parts " : { <nl> " index " : { <nl> + " type " : " list " , <nl> + " description " : " a comma - separated list of <nl> } <nl> } , <nl> " params " : { <nl> " ignore_indices " : { <nl> - } , <nl> - " index " : { <nl> + " type " : " enum " , <nl> + " options " : [ " none " , " missing " ] , <nl> + " default " : " none " , <nl> + " description " : " when performed on multiple indices , allows to ignore ` missing ` ones " <nl> } , <nl> " operation_threading " : { <nl> + " description " : " <nl> } , <nl> " preference " : { <nl> + " type " : " string " , <nl> + " description " : " specify the shards the operation should be performed on ( default : random shard ) " <nl> } , <nl> " routing " : { <nl> + " type " : " string " , <nl> + " description " : " specific routing value " <nl> } , <nl> " source " : { <nl> + " type " : " string " , <nl> + " description " : " the url - encoded request definition ( instead of using request body ) " <nl> } <nl> } <nl> } , <nl> " body " : { <nl> + " description " : " the request definition " <nl> } <nl> } <nl> }
<nl> { <nl> " indices . validate . query " : { <nl> - " documentation " : " " , <nl> + " documentation " : " http : / / www . elasticsearch . org / guide / reference / api / validate / " , <nl> " methods " : [ " get " , " post " ] , <nl> " url " : { <nl> " path " : " / _validate / query " , <nl> " paths " : [ " / _validate / query " , " / { index } / _validate / query " , " / { index } / { type } / _validate / query " ] , <nl> " parts " : { <nl> " index " : { <nl> + " type " : " list " , <nl> + " description " : " a comma - separated list of <nl> } , <nl> " type " : { <nl> + " type " : " list " , <nl> + " description " : " a comma - separated list of document types to restrict the operation ; leave empty to perform the operation on all types " <nl> } <nl> } , <nl> " params " : { <nl> " explain " : { <nl> + " type " : " boolean " , <nl> + " description " : " return detailed information about the error " <nl> } , <nl> " ignore_indices " : { <nl> - } , <nl> - " index " : { <nl> + " type " : " enum " , <nl> + " options " : [ " none " , " missing " ] , <nl> + " default " : " none " , <nl> + " description " : " when performed on multiple indices , allows to ignore ` missing ` ones " <nl> } , <nl> " operation_threading " : { <nl> + " description " : " <nl> } , <nl> " source " : { <nl> - } , <nl> - " type " : { <nl> + " type " : " string " , <nl> + " description " : " the url - encoded query definition ( instead of using the request body ) " <nl> } <nl> } <nl> } , <nl> " body " : { <nl> + " description " : " the query definition " <nl> } <nl> } <nl> }
<nl> " paths " : [ " / _segments " , " / { index } / _segments " ] , <nl> " parts " : { <nl> " index " : { <nl> + " type " : " list " , <nl> + " required " : true , <nl> + " description " : " a comma - separated list of <nl> } <nl> } , <nl> " params " : { <nl> " ignore_indices " : { <nl> - } , <nl> - " index " : { <nl> + " type " : " enum " , <nl> + " options " : [ " none " , " missing " ] , <nl> + " default " : " none " , <nl> + " description " : " when performed on multiple indices , allows to ignore ` missing ` ones " <nl> } , <nl> " operation_threading " : { <nl> + " description " : " <nl> } <nl> } <nl> } ,
<nl> { <nl> " indices . refresh " : { <nl> - " documentation " : " " , <nl> + " documentation " : " http : / / www . elasticsearch . org / guide / reference / api / admin - indices - refresh / " , <nl> " methods " : [ " post " , " get " ] , <nl> " url " : { <nl> " path " : " / _refresh " , <nl> " paths " : [ " / _refresh " , " / { index } / _refresh " ] , <nl> " parts " : { <nl> " index " : { <nl> + " type " : " list " , <nl> + " required " : true , <nl> + " description " : " a comma - separated list of <nl> } <nl> } , <nl> " params " : { <nl> " ignore_indices " : { <nl> - } , <nl> - " index " : { <nl> + " type " : " enum " , <nl> + " options " : [ " none " , " missing " ] , <nl> + " default " : " none " , <nl> + " description " : " when performed on multiple indices , allows to ignore ` missing ` ones " <nl> } , <nl> " operation_threading " : { <nl> + " description " : " <nl> } <nl> } <nl> } ,
<nl> { <nl> " indices . optimize " : { <nl> - " documentation " : " " , <nl> + " documentation " : " http : / / www . elasticsearch . org / guide / reference / api / admin - indices - optimize / " , <nl> " methods " : [ " post " , " get " ] , <nl> " url " : { <nl> " path " : " / _optimize " , <nl> " paths " : [ " / _optimize " , " / { index } / _optimize " ] , <nl> " parts " : { <nl> " index " : { <nl> + " type " : " list " , <nl> + " required " : true , <nl> + " description " : " a comma - separated list of <nl> } <nl> } , <nl> " params " : { <nl> " flush " : { <nl> + " type " : " boolean " , <nl> + " description " : " specify whether the <nl> } , <nl> " ignore_indices " : { <nl> - } , <nl> - " index " : { <nl> + " type " : " enum " , <nl> + " options " : [ " none " , " missing " ] , <nl> + " default " : " none " , <nl> + " description " : " when performed on multiple indices , allows to ignore ` missing ` ones " <nl> } , <nl> " max_num_segments " : { <nl> + " type " : " number " , <nl> + " description " : " the number of segments the <nl> } , <nl> " only_expunge_deletes " : { <nl> + " type " : " boolean " , <nl> + " description " : " specify whether the operation should only expunge deleted documents " <nl> } , <nl> " operation_threading " : { <nl> + " description " : " <nl> } , <nl> " refresh " : { <nl> + " type " : " boolean " , <nl> + " description " : " specify whether the <nl> } , <nl> " wait_for_merge " : { <nl> + " type " : " boolean " , <nl> + " description " : " specify whether the request should block until the merge process is finished ( default : true ) " <nl> } <nl> } <nl> } ,
<nl> { <nl> " indices . cache . clear " : { <nl> - " documentation " : " " , <nl> + " documentation " : " http : / / www . elasticsearch . org / guide / reference / api / admin - indices - clearcache / " , <nl> " methods " : [ " post " , " get " ] , <nl> " url " : { <nl> " path " : " / _cache / clear " , <nl> " paths " : [ " / _cache / clear " , " / { index } / _cache / clear " ] , <nl> " parts " : { <nl> " index " : { <nl> + " type " : " list " , <nl> + " description " : " a comma - separated list of <nl> } <nl> } , <nl> " params " : { <nl> " field_data " : { <nl> + " type " : " boolean " , <nl> + " description " : " clear field data " <nl> } , <nl> " fielddata " : { <nl> + " type " : " boolean " , <nl> + " description " : " clear field data " <nl> } , <nl> " fields " : { <nl> + " type " : " list " , <nl> + " description " : " a comma - separated list of fields to clear when using the ` field_data ` parameter ( default : all ) " <nl> } , <nl> " filter " : { <nl> + " type " : " boolean " , <nl> + " description " : " clear filter caches " <nl> } , <nl> " filter_cache " : { <nl> + " type " : " boolean " , <nl> + " description " : " clear filter caches " <nl> } , <nl> " filter_keys " : { <nl> + " type " : " boolean " , <nl> + " description " : " a comma - separated list of keys to clear when using the ` filter_cache ` parameter ( default : all ) " <nl> } , <nl> " id " : { <nl> + " type " : " boolean " , <nl> + " description " : " clear id caches for parent / child " <nl> } , <nl> " id_cache " : { <nl> + " type " : " boolean " , <nl> + " description " : " clear id caches for parent / child " <nl> } , <nl> " ignore_indices " : { <nl> + " type " : " enum " , <nl> + " options " : [ " none " , " missing " ] , <nl> + " default " : " none " , <nl> + " description " : " when performed on multiple indices , allows to ignore ` missing ` ones " <nl> } , <nl> " index " : { <nl> + " type " : " list " , <nl> + " description " : " a comma - separated list of <nl> } , <nl> " recycler " : { <nl> + " type " : " boolean " , <nl> + " description " : " <nl> } <nl> } <nl> } ,
<nl> " paths " : [ " / _count " , " / { index } / _count " , " / { index } / { type } / _count " ] , <nl> " parts " : { <nl> " index " : { <nl> + " type " : " list " , <nl> + " description " : " a comma - separated list of indices to restrict the results " <nl> } , <nl> " type " : { <nl> + " type " : " list " , <nl> + " description " : " a comma - separated list of types to restrict the results " <nl> } <nl> } , <nl> " params " : { <nl> " ignore_indices " : { <nl> + " type " : " enum " , <nl> + " options " : [ " none " , " missing " ] , <nl> + " default " : " none " , <nl> + " description " : " when performed on multiple indices , allows to ignore ` missing ` ones " <nl> } , <nl> " index " : { <nl> + " type " : " list " , <nl> + " description " : " a comma - separated list of indices to restrict the results " <nl> } , <nl> " min_score " : { <nl> + " type " : " number " , <nl> + " description " : " include only documents with a specific ` _score ` value in the result " <nl> } , <nl> " operation_threading " : { <nl> + " description " : " <nl> } , <nl> " preference " : { <nl> + " type " : " string " , <nl> + " description " : " specify the shards the operation should be performed on ( default : random shard ) " <nl> } , <nl> " routing " : { <nl> + " type " : " string " , <nl> + " description " : " specific routing value " <nl> } , <nl> " source " : { <nl> + " type " : " string " , <nl> + " description " : " the url - encoded query definition ( instead of using the request body ) " <nl> } , <nl> " type " : { <nl> + " type " : " list " , <nl> + " description " : " a comma - separated list of document types to restrict the results " <nl> } <nl> } <nl> } , <nl> " body " : { <nl> + " description " : " a query to restrict the results ( optional ) " <nl> } <nl> } <nl> }
<nl> } , <nl> " params " : { <nl> " dry_run " : { <nl> + " type " : " boolean " , <nl> + " description " : " simulate the operation only and return the resulting state after rebalancing " <nl> } , <nl> " filter_metadata " : { <nl> + " type " : " boolean " , <nl> + " description " : " <nl> } <nl> } <nl> } , <nl> " body " : { <nl> + " description " : " the definition of ` commands ` to perform ( ` move ` , ` cancel ` , ` allocate ` ) " <nl> } <nl> } <nl> }
<nl> + { <nl> + " cluster . node . hot_threads " : { <nl> + " documentation " : " http : / / www . elasticsearch . org / guide / reference / api / admin - cluster - nodes - hot - threads / " , <nl> + " methods " : [ " get " ] , <nl> + " url " : { <nl> + " path " : " / _cluster / nodes / hot_threads " , <nl> + " paths " : [ " / _cluster / nodes / hotthreads " , " / _cluster / nodes / hot_threads " , " / _cluster / nodes / { nodeid } / hotthreads " , " / _cluster / nodes / { nodeid } / hot_threads " , " / _nodes / hotthreads " , " / _nodes / hot_threads " , " / _nodes / { nodeid } / hotthreads " , " / _nodes / { nodeid } / hot_threads " ] , <nl> + " parts " : { <nl> + " nodeid " : { <nl> + " type " : " list " , <nl> + " description " : " a comma - separated list of nodes to limit the returned information " <nl> + } <nl> + } , <nl> + " params " : { <nl> + " interval " : { <nl> + " type " : " time " , <nl> + " description " : " the interval for the second sampling of threads " <nl> + } , <nl> + " snapshots " : { <nl> + " type " : " string " , <nl> + " description " : " <nl> + } , <nl> + " threads " : { <nl> + " type " : " number " , <nl> + " description " : " specify the number of threads to provide information for ( default : num ) " <nl> + } , <nl> + " type " : { <nl> + " type " : " enum " , <nl> + " options " : [ " cpu " , " wait " , " block " ] , <nl> + " description " : " the type to sample ( default : cpu ) " <nl> + } <nl> + } <nl> + } , <nl> + " body " : null <nl> + } <nl> + } <nl> mmm a / rest - api - spec / api / cluster . node . hotthreads . json <nl> ppp / dev / null <nl>
public class simpleidcache extends abstractindexcomponent implements idcache , se <nl> docsenum docsenum = null ; <nl> for ( bytesref term = termsenum . next ( ) ; term ! = null ; term = termsenum . next ( ) ) { <nl> hashedbytesarray [ ] typeandid = uid . splituidintotypeandid ( term ) ; <nl> - typebuilder typebuilder = readerbuilder . get ( typeandid [ 0 ] . toutf8 ( ) ) ; <nl> + <nl> + if ( ! parenttypes . contains ( typeandid [ 0 ] ) ) { <nl> + continue ; <nl> + } <nl> + <nl> + string type = typeandid [ 0 ] . toutf8 ( ) ; <nl> + typebuilder typebuilder = readerbuilder . get ( type ) ; <nl> if ( typebuilder = = null ) { <nl> typebuilder = new typebuilder ( reader ) ; <nl> - readerbuilder . put ( typeandid [ 0 ] . toutf8 ( ) , typebuilder ) ; <nl> + readerbuilder . put ( type , typebuilder ) ; <nl> } <nl>  <nl> hashedbytesarray idasbytes = checkifcanreuse ( builders , typeandid [ 1 ] ) ; <nl> mmm a / src / test / java / org / elasticsearch / benchmark / search / child / childsearchbenchmark . java <nl> ppp b / src / test / java / org / elasticsearch / benchmark / search / child / childsearchbenchmark . java <nl>
public class threadpool extends abstractcomponent { <nl>  <nl> map < string , settings > groupsettings = settings . getgroups ( threadpool_group ) ; <nl>  <nl> + <nl> defaultexecutortypesettings = immutablemap . < string , settings > builder ( ) <nl> . put ( names . generic , settingsbuilder ( ) . put ( " type " , " cached " ) . put ( " keep_alive " , " 30s " ) . build ( ) ) <nl> . put ( names . index , settingsbuilder ( ) . put ( " type " , " cached " ) . build ( ) ) <nl>
public class httpserver extends abstractlifecyclecomponent < httpserver > { <nl> channel . sendresponse ( new stringrestresponse ( forbidden ) ) ; <nl> return ; <nl> } <nl> + <nl>  <nl> string path = request . rawpath ( ) . substring ( " / _plugin / " . length ( ) ) ; <nl> int i1 = path . indexof ( ' / ' ) ; <nl> string pluginname ; <nl> string sitepath ; <nl> if ( i1 = = - 1 ) { <nl> - / / if user tries to reach " / _plugin / " endpoint , we display a page that lists all the plugins # 2664 <nl> - if ( ! strings . hastext ( path ) ) { <nl> - try { <nl> - xcontentbuilder json = jsonbuilder ( ) ; <nl> - if ( request . hasparam ( " pretty " ) ) { <nl> - json . prettyprint ( ) ; <nl> - } <nl> - json . startobject ( ) . startarray ( " sites " ) ; <nl> - <nl> - for ( string plugin : pluginshelper . siteplugins ( environment ) ) { <nl> - json . startobject ( ) <nl> - . field ( " name " , plugin ) <nl> - . field ( " url " , " / _plugin / " + plugin + " / " ) <nl> - . endobject ( ) ; <nl> - } <nl> - json . endarray ( ) . endobject ( ) ; <nl> - channel . sendresponse ( new bytesrestresponse ( json . bytes ( ) . tobytes ( ) , <nl> - guessmimetype ( guessmimetype ( " index . json " ) ) ) ) ; <nl> - } catch ( ioexception e ) { <nl> - channel . sendresponse ( new stringrestresponse ( internal_server_error ) ) ; <nl> - } <nl> - <nl> - return ; <nl> - } <nl> - <nl> + pluginname = path ; <nl> + sitepath = null ; <nl> / / if a trailing / is missing , we redirect to the right page # 2654 <nl> - channel . sendresponse ( new httpredirectrestresponse ( request . rawpath ( ) + " / " ) ) ; <nl> + channel . sendresponse ( new httpredirectrestresponse ( request . rawpath ( ) + " / " ) ) ; <nl> return ; <nl> } else { <nl> pluginname = path . substring ( 0 , i1 ) ; <nl>
public class indexfielddataservice extends abstractindexcomponent { <nl> } <nl> } <nl>  <nl> + public fielddatastats stats ( ) { <nl> + <nl> + return new fielddatastats ( ) ; <nl> + } <nl> + <nl> public < ifd extends indexfielddata > ifd getforfield ( fieldmapper mapper ) { <nl> return getforfield ( mapper . names ( ) , mapper . fielddatatype2 ( ) ) ; <nl> }
public final class xcontentbuilder implements bytesstream { <nl> return this ; <nl> } <nl>  <nl> + public xcontentbuilder field ( xcontentbuilderstring name , text value ) throws ioexception { <nl> + field ( name ) ; <nl> + if ( value . hasbytes ( ) & & value . bytes ( ) . hasarray ( ) ) { <nl> + generator . writeutf8string ( value . bytes ( ) . array ( ) , value . bytes ( ) . arrayoffset ( ) , value . bytes ( ) . length ( ) ) ; <nl> + return this ; <nl> + } <nl> + if ( value . hasstring ( ) ) { <nl> + generator . writestring ( value . string ( ) ) ; <nl> + return this ; <nl> + } <nl> + <nl> + bytesarray bytesarray = value . bytes ( ) . tobytesarray ( ) ; <nl> + generator . writeutf8string ( bytesarray . array ( ) , bytesarray . arrayoffset ( ) , bytesarray . length ( ) ) ; <nl> + return this ; <nl> + } <nl>  <nl> public xcontentbuilder field ( string name , byte [ ] value , int offset , int length ) throws ioexception { <nl> field ( name ) ; <nl>
public class stringandbytestext implements text { <nl>  <nl> @ override <nl> public string string ( ) { <nl> + <nl> if ( text = = null ) { <nl> if ( ! bytes . hasarray ( ) ) { <nl> bytes = bytes . tobytesarray ( ) ; <nl> } <nl> - text = new string ( bytes . array ( ) , bytes . arrayoffset ( ) , bytes . length ( ) ) ; <nl> + text = new string ( bytes . array ( ) , bytes . arrayoffset ( ) , bytes . length ( ) , charsets . utf_8 ) ; <nl> } <nl> return text ; <nl> }
import java . io . inputstream ; <nl> / * * <nl> * extends the tika class , so as to provide a way for setting the maximumstringlength on a per parse document basis . <nl> * / <nl> + <nl> public class tikaextended extends tika { <nl>  <nl> public string parsetostring ( inputstream stream , metadata metadata , int maxstringlength )
public class robinengine extends abstractindexshardcomponent implements engine { <nl>  <nl> private volatile indexwriter indexwriter ; <nl>  <nl> + <nl> + / / we won ' t need acquirableresource any more as well , and close will not need to replace it with a closeable one <nl> private volatile acquirableresource < readersearcherholder > nrtresource ; <nl>  <nl> private volatile boolean closed = false ; <nl>
public class haschildfilterparser implements filterparser { <nl> currentfieldname = parser . currentname ( ) ; <nl> } else if ( token = = xcontentparser . token . start_object ) { <nl> if ( " query " . equals ( currentfieldname ) ) { <nl> + <nl> / / since we switch types , make sure we change the context <nl> string [ ] origtypes = queryparsecontext . settypeswithprevious ( childtype = = null ? null : new string [ ] { childtype } ) ; <nl> try { <nl> mmm a / src / main / java / org / elasticsearch / index / query / haschildqueryparser . java <nl> ppp b / src / main / java / org / elasticsearch / index / query / haschildqueryparser . java <nl>
public class haschildqueryparser implements queryparser { <nl> currentfieldname = parser . currentname ( ) ; <nl> } else if ( token = = xcontentparser . token . start_object ) { <nl> if ( " query " . equals ( currentfieldname ) ) { <nl> + <nl> / / since we switch types , make sure we change the context <nl> string [ ] origtypes = queryparsecontext . settypeswithprevious ( childtype = = null ? null : new string [ ] { childtype } ) ; <nl> try { <nl> mmm a / src / main / java / org / elasticsearch / index / query / topchildrenqueryparser . java <nl> ppp b / src / main / java / org / elasticsearch / index / query / topchildrenqueryparser . java <nl>
public class topchildrenqueryparser implements queryparser { <nl> currentfieldname = parser . currentname ( ) ; <nl> } else if ( token = = xcontentparser . token . start_object ) { <nl> if ( " query " . equals ( currentfieldname ) ) { <nl> - query = parsecontext . parseinnerquery ( ) ; <nl> + <nl> + string [ ] origtypes = queryparsecontext . settypeswithprevious ( childtype = = null ? null : new string [ ] { childtype } ) ; <nl> + try { <nl> + query = parsecontext . parseinnerquery ( ) ; <nl> + } finally { <nl> + queryparsecontext . settypes ( origtypes ) ; <nl> + } <nl> } else { <nl> throw new queryparsingexception ( parsecontext . index ( ) , " [ top_children ] query does not support [ " + currentfieldname + " ] " ) ; <nl> }
public class couchdbriver extends abstractrivercomponent implements river { <nl> } <nl> } <nl> } <nl> + } else { <nl> + <nl> } <nl>  <nl> bulk . add ( indexrequest ( index ) . type ( type ) . id ( id ) . source ( doc ) . routing ( extractrouting ( ctx ) ) ) ; <nl>
public class uidfilter extends filter { <nl> arrays . sort ( uids ) ; <nl> } <nl>  <nl> + <nl> + / / - we can use sorted int array docidset to reserve memory compared to openbitset in some cases <nl> @ override public docidset getdocidset ( indexreader reader ) throws ioexception { <nl> bloomfilter filter = bloomcache . filter ( reader , uidfieldmapper . name , true ) ; <nl> openbitset set = null ;
public class nodecache extends abstractcomponent { <nl> public queryparsercache queryparser ( ) { <nl> return queryparsercache ; <nl> } <nl> + <nl> + / / listen on cluster change events to invalidate the query parser cache <nl> + @ override public void clusterchanged ( clusterchangedevent event ) { <nl> + <nl> + if ( event . metadatachanged ( ) ) { <nl> + queryparsercache . clear ( ) ; <nl> + } <nl> + } <nl> }
public class transportdeleteaction extends transportshardreplicationoperationact <nl> if ( request . routing ( ) = = null ) { <nl> indexdeleteaction . execute ( new indexdeleterequest ( request ) , new actionlistener < indexdeleteresponse > ( ) { <nl> @ override public void onresponse ( indexdeleteresponse indexdeleteresponse ) { <nl> + <nl> listener . onresponse ( new deleteresponse ( request . index ( ) , request . type ( ) , request . id ( ) ) ) ; <nl> }
public class localgatewaynodeallocation extends nodeallocation { <nl> routingnodes routingnodes = allocation . routingnodes ( ) ; <nl>  <nl> for ( indexroutingtable indexroutingtable : routingnodes . routingtable ( ) ) { <nl> - / / only do the allocation if there is a local " index not recovered " block <nl> - if ( ! routingnodes . blocks ( ) . hasindexblock ( indexroutingtable . index ( ) , localgateway . index_not_recovered_block ) ) { <nl> - continue ; <nl> - } <nl> - <nl> + <nl> if ( indexroutingtable . allprimaryshardsunassigned ( ) ) { <nl> / / all primary are unassigned for the index , see if we can allocate it on existing nodes , if not , don ' t assign <nl> set < string > nodesids = sets . newhashset ( ) ; <nl>
public class twitterindexer extends abstractindexercomponent implements indexer <nl> logger . info ( " starting twitter stream " ) ; <nl> try { <nl> client . admin ( ) . indices ( ) . preparecreate ( indexname ) . execute ( ) . actionget ( ) ; <nl> - currentrequest = client . preparebulk ( ) ; <nl> - stream . sample ( ) ; <nl> } catch ( exception e ) { <nl> if ( exceptionshelper . unwrapcause ( e ) instanceof indexalreadyexistsexception ) { <nl> / / that ' s fine <nl> + } else if ( exceptionshelper . unwrapcause ( e ) instanceof clusterblockexception ) { <nl> + / / ok , not recovered yet . . . , lets start indexing and hope we recover by the first bulk <nl> + <nl> } else { <nl> logger . warn ( " failed to create <nl> + return ; <nl> } <nl> } <nl> + currentrequest = client . preparebulk ( ) ; <nl> + stream . sample ( ) ; <nl> } <nl>  <nl> @ override public void close ( ) {
public class alphamemorymonitor extends abstractlifecyclecomponent < memorymonitor <nl> logger . info ( sb . tostring ( ) ) ; <nl> } <nl> indicesmemorycleaner . cacheclear ( ) ; <nl> + <nl> indicesmemorycleaner . fullmemoryclean ( ) ; <nl> threadlocals . clearreferencesthreadlocals ( ) ; <nl> fullcounter = num ;
class serverconnection extends connectionbase implements httpconnection { <nl> } else { <nl> / / requeue <nl> / / paused = true = > queueing = true <nl> + <nl> + / / it will be added at the wrong place and create a bug <nl> pending . add ( lasthttpcontent . empty_last_content ) ; <nl> } <nl> }
let ' s discuss the different concepts and features in core . <nl>  <nl> = = in the beginning there was vert . x <nl>  <nl> - note : much of this is java specific - need someway of swapping in language specific parts <nl> + / / / / <nl> + <nl>  <nl> - you can ' t do much in vert . x - land unless you can commune with a ` link : . . / . . / apidocs / io / vertx / core / vertx . html [ vertx ] ` object ! <nl> + you can ' t do much in vert . x - land unless you can communicate with a ` link : . . / . . / apidocs / io / vertx / core / vertx . html [ vertx ] ` object ! <nl>  <nl> it ' s the control centre of vert . x and is how you do pretty much everything , including creating clients and servers , <nl> getting a reference to the event bus , setting timers , as well as many other things . <nl>
<nl> * <nl> * = = in the beginning there was vert . x <nl> * <nl> - * note : much of this is java specific - need someway of swapping in language specific parts <nl> + * / / / / <nl> + * <nl> + * / / / / <nl> * <nl> - * you can ' t do much in vert . x - land unless you can commune with a { @ link io . vertx . core . vertx } object ! <nl> + * you can ' t do much in vert . x - land unless you can communicate with a { @ link io . vertx . core . vertx } object ! <nl> * <nl> * it ' s the control centre of vert . x and is how you do pretty much everything , including creating clients and servers , <nl> * getting a reference to the event bus , setting timers , as well as many other things . <nl>
public class nettest extends vertxtestbase { <nl> await ( ) ; <nl> } <nl>  <nl> + <nl> + <nl> @ test <nl> public void testhostverificationhttpsmatching ( ) { <nl> server . close ( ) ; <nl>
import static junit . framework . assert . asserttrue ; <nl> * these tests check the jul log delegate . it analyses the output , so any change in the configuration may break the <nl> * tests . <nl> * <nl> + * <nl> + * <nl> * @ author < a href = " http : / / escoffier . me " > clement escoffier < / a > <nl> * / <nl> public class jullogdelegatetest { <nl>
public class dnsresponsedecoder extends messagetomessagedecoder < datagrampacket > <nl> response . addquestion ( decodequestion ( buf ) ) ; <nl> } <nl> if ( header . getresponsecode ( ) ! = num ) { <nl> - system . err . println ( " encountered error decoding dns response for domain \ " " <nl> - + response . getquestions ( ) . get ( 0 ) . name ( ) + " \ " : " <nl> - + dnsresponsecode . valueof ( header . getresponsecode ( ) ) ) ; <nl> + <nl> + return response ; <nl> } <nl> for ( int i = num ; i < header . getreadanswers ( ) ; i + + ) { <nl> response . addanswer ( decoderesource ( buf , allocator ) ) ;
basic_java_binary_attributes = merge_attrs ( <nl> " _java_runtime_toolchain_type " : attr . label ( default = semantics . java_runtime_toolchain_type ) , <nl> } , <nl> ) <nl> + <nl> + def _bazel_java_binary_impl ( ctx ) : <nl> + toolchain = semantics . find_java_toolchain ( ctx ) <nl> + java_runtime_toolchain = semantics . find_java_runtime_toolchain ( ctx ) <nl> + cc_toolchain = cc_helper . find_cpp_toolchain ( ctx ) <nl> + deps = helper . collect_all_targets_as_deps ( ctx ) <nl> + <nl> + main_class = none <nl> + coverage_main_class = none <nl> + coverage_config = none <nl> + launcher_info = none <nl> + executable = none <nl> + feature_config = helper . get_feature_config ( ctx ) <nl> + strip_as_default = helper . should_strip_as_default ( ctx , feature_config ) <nl> + <nl> + providers , default_info , jvm_flags = basic_java_binary ( <nl> + ctx , <nl> + deps , <nl> + ctx . files . resources , <nl> + main_class , <nl> + coverage_main_class , <nl> + coverage_config , <nl> + launcher_info , <nl> + executable , <nl> + feature_config , <nl> + strip_as_default , <nl> + ) <nl> + <nl> + return providers . values ( ) <nl> + <nl> + def _compute_test_support ( use_testrunner ) : <nl> + return label ( " @ / / tools / jdk : testrunner " ) if use_testrunner else none <nl> + <nl> + def make_java_binary ( executable , resolve_launcher_flag ) : <nl> + return rule ( <nl> + _bazel_java_binary_impl , <nl> + attrs = merge_attrs ( <nl> + basic_java_binary_attributes , <nl> + { <nl> + " _java_launcher " : attr . label ( <nl> + default = configuration_field ( <nl> + fragment = " java " , <nl> + name = " launcher " , <nl> + ) if resolve_launcher_flag else none , <nl> + ) , <nl> + " _test_support " : attr . label ( default = _compute_test_support ) , <nl> + } , <nl> + ( { } if executable else { <nl> + " args " : attr . string_list ( ) , <nl> + " output_licenses " : attr . license ( ) if hasattr ( attr , " license " ) else attr . string_list ( ) , <nl> + } ) , <nl> + ) , <nl> + fragments = [ " cpp " , " java " ] , <nl> + provides = [ javainfo ] , <nl> + toolchains = [ semantics . java_toolchain , semantics . java_runtime_toolchain ] + cc_helper . use_cpp_toolchain ( ) , <nl> + # <nl> + outputs = { <nl> + " classjar " : " % { name } . jar " , <nl> + " sourcejar " : " % { name } - src . jar " , <nl> + " deploysrcjar " : " % { name } _deploy - src . jar " , <nl> + } , <nl> + executable = executable , <nl> + exec_groups = { <nl> + " cpp_link " : exec_group ( copy_from_rule = true ) , <nl> + } , <nl> + ) <nl> + <nl> + java_binary = make_java_binary ( executable = true , resolve_launcher_flag = true )
public class packageoptions extends optionsbase { <nl>  <nl> @ option ( <nl> name = " incompatible_config_setting_private_default_visibility " , <nl> - defaultvalue = " false " , <nl> + <nl> + defaultvalue = " true " , <nl> documentationcategory = optiondocumentationcategory . starlark_semantics , <nl> effecttags = { optioneffecttag . loading_and_analysis } , <nl> metadatatags = { optionmetadatatag . incompatible_change } ,
<nl> # limitations under the license . <nl> " " " implementation of py_runtime rule . " " " <nl>  <nl> + load ( " : common / paths . bzl " , " paths " ) <nl> + <nl> + _pyruntimeinfo = _builtins . toplevel . pyruntimeinfo <nl> + <nl> def _py_runtime_impl ( ctx ) : <nl> - _ = ctx # @ unused <nl> - fail ( " not implemented " ) <nl> + interpreter_path = ctx . attr . interpreter_path <nl> + interpreter = ctx . file . interpreter <nl> + if ( interpreter_path and interpreter ) or ( not interpreter_path and not interpreter ) : <nl> + fail ( " exactly one of the ' interpreter ' or ' interpreter_path ' attributes must be specified " ) <nl> + <nl> + hermetic = bool ( interpreter ) <nl> + runtime_files = ctx . attr . files [ defaultinfo ] . files <nl> + if not hermetic : <nl> + if runtime_files : <nl> + fail ( " if ' interpreter_path ' is given then ' files ' must be empty " ) <nl> + if not paths . is_absolute ( interpreter_path ) : <nl> + fail ( " interpreter_path must be an absolute path " ) <nl> + <nl> + if ctx . attr . coverage_tool : <nl> + coverage_di = ctx . attr . coverage_tool [ defaultinfo ] <nl> + <nl> + # <nl> + # instead of always flattening to a list <nl> + coverage_di_files = coverage_di . files . to_list ( ) <nl> + if len ( coverage_di_files ) = = num : <nl> + coverage_tool = coverage_di_files [ 0 ] <nl> + elif coverage_di . files_to_run and coverage_di . files_to_run . executable : <nl> + coverage_tool = coverage_di . files_to_run . executable <nl> + else : <nl> + fail ( " coverage_tool must be an executable target or must produce exactly one file . " ) <nl> + <nl> + coverage_files = depset ( transitive = [ <nl> + coverage_di . files , <nl> + coverage_di . default_runfiles . files , <nl> + ] ) <nl> + else : <nl> + coverage_tool = none <nl> + coverage_files = none <nl> + <nl> + python_version = ctx . attr . python_version <nl> + if python_version = = " _internal_sentinel " : <nl> + if ctx . fragments . py . use_toolchains : <nl> + fail ( <nl> + " when using python toolchains , this attribute must be set explicitly to either ' py2 ' " + <nl> + " or ' py3 ' . see https : / / github . com / bazelbuild / bazel / issues / 7899 for more " + <nl> + " information . you can temporarily avoid this error by reverting to the legacy " + <nl> + " python runtime mechanism ( ` - - incompatible_use_python_toolchains = false ` ) . " , <nl> + ) <nl> + else : <nl> + python_version = ctx . fragments . default_python_version <nl> + <nl> + return [ <nl> + _pyruntimeinfo ( <nl> + files = runtime_files , <nl> + coverage_tool = coverage_tool , <nl> + coverage_files = coverage_files , <nl> + python_version = python_version , <nl> + stub_shebang = ctx . attr . stub_shebang , <nl> + ) , <nl> + defaultinfo ( <nl> + files = runtime_files , <nl> + runfiles = ctx . runfiles ( ) , <nl> + ) , <nl> + ] <nl>  <nl> # bind to the name " py_runtime " to preserve the kind / rule_class it shows up <nl> # as elsewhere .
<nl> # limitations under the license . <nl> " " " implementation of py_runtime rule . " " " <nl>  <nl> + def _py_runtime_impl ( ctx ) : <nl> + _ = ctx # @ unused <nl> + fail ( " not implemented " ) <nl> + <nl> # bind to the name " py_runtime " to preserve the kind / rule_class it shows up <nl> # as elsewhere . <nl> - py_runtime = _builtins . native . py_runtime <nl> + py_runtime = rule ( <nl> + implementation = _py_runtime_impl , <nl> + doc = " " " <nl> + represents a python runtime used to execute python code . <nl> + <nl> + a ` py_runtime ` target can represent either a * platform runtime * or an * in - build <nl> + runtime * . a platform runtime accesses a system - installed interpreter at a known <nl> + path , whereas an in - build runtime points to an executable target that acts as <nl> + the interpreter . in both cases , an " interpreter " means any executable binary or <nl> + wrapper script that is capable of running a python script passed on the command <nl> + line , following the same conventions as the standard cpython interpreter . <nl> + <nl> + a platform runtime is by its nature non - hermetic . it imposes a requirement on <nl> + the target platform to have an interpreter located at a specific path . an <nl> + in - build runtime may or may not be hermetic , depending on whether it points to <nl> + a checked - in interpreter or a wrapper script that accesses the system <nl> + interpreter . <nl> + <nl> + # example <nl> + <nl> + ` ` ` <nl> + py_runtime ( <nl> + name = " python - 2 . 7 . 12 " , <nl> + files = glob ( [ " python - 2 . 7 . 12 / * * " ] ) , <nl> + interpreter = " python - 2 . 7 . 12 / bin / python " , <nl> + ) <nl> + <nl> + py_runtime ( <nl> + name = " python - 3 . 6 . 0 " , <nl> + interpreter_path = " / opt / pyenv / versions / 3 . 6 . 0 / bin / python " , <nl> + ) <nl> + ` ` ` <nl> + " " " , <nl> + fragments = [ " py " ] , <nl> + attrs = { <nl> + " files " : attr . label_list ( <nl> + allow_files = true , <nl> + doc = " " " <nl> + for an in - build runtime , this is the set of files comprising this runtime . <nl> + these files will be added to the runfiles of python binaries that use this <nl> + runtime . for a platform runtime this attribute must not be set . <nl> + " " " , <nl> + ) , <nl> + " interpreter " : attr . label ( <nl> + allow_single_file = true , <nl> + doc = " " " <nl> + for an in - build runtime , this is the target to invoke as the interpreter . for a <nl> + platform runtime this attribute must not be set . <nl> + " " " , <nl> + ) , <nl> + " interpreter_path " : attr . string ( doc = " " " <nl> + for a platform runtime , this is the absolute path of a python interpreter on <nl> + the target platform . for an in - build runtime this attribute must not be set . <nl> + " " " ) , <nl> + " coverage_tool " : attr . label ( <nl> + allow_files = false , <nl> + doc = " " " <nl> + this is a target to use for collecting code coverage information from ` py_binary ` <nl> + and ` py_test ` targets . <nl> + <nl> + if set , the target must either produce a single file or be an executable target . <nl> + the path to the single file , or the executable if the target is executable , <nl> + determines the entry point for the python coverage tool . the target and its <nl> + runfiles will be added to the runfiles when coverage is enabled . <nl> + <nl> + the entry point for the tool must be loadable by a python interpreter ( e . g . a <nl> + ` . py ` or ` . pyc ` file ) . it must accept the command line arguments <nl> + of coverage . py ( https : / / coverage . readthedocs . io ) , at least including <nl> + the ` run ` and ` lcov ` subcommands . <nl> + " " " , <nl> + ) , <nl> + " python_version " : attr . string ( <nl> + values = [ " py2 " , " py3 " , " _internal_sentinel " ] , <nl> + doc = " " " <nl> + whether this runtime is for python major version num or num . valid values are ` " py2 " ` <nl> + and ` " py3 " ` . <nl> + <nl> + the default value is controlled by the ` - - incompatible_py3_is_default ` flag . <nl> + however , in the future this attribute will be mandatory and have no default <nl> + value . <nl> + " " " , <nl> + ) , <nl> + " stub_shebang " : attr . string ( <nl> + # <nl> + # constant <nl> + default = " # ! / usr / bin / env python3 " , <nl> + doc = " " " <nl> + " shebang " expression prepended to the bootstrapping python stub script <nl> + used when executing ` py_binary ` targets . <nl> + <nl> + see https : / / github . com / bazelbuild / bazel / issues / 8685 for <nl> + motivation . <nl> + <nl> + does not apply to windows . <nl> + " " " , <nl> + ) , <nl> + } , <nl> + )
public class treeartifactvalue implements hasdigest , skyvalue { <nl>  <nl> private final boolean entirelyremote ; <nl>  <nl> + / * * a fileartifactvalue used to stand in for a treeartifactvalue . * / <nl> + private static final class treeartifactcompositefileartifactvalue extends fileartifactvalue { <nl> + private final byte [ ] digest ; <nl> + private final boolean isremote ; <nl> + <nl> + treeartifactcompositefileartifactvalue ( byte [ ] digest , boolean isremote ) { <nl> + this . digest = digest ; <nl> + this . isremote = isremote ; <nl> + } <nl> + <nl> + @ override <nl> + public boolean equals ( object o ) { <nl> + if ( this = = o ) { <nl> + return true ; <nl> + } <nl> + if ( ! ( o instanceof treeartifactcompositefileartifactvalue ) ) { <nl> + return false ; <nl> + } <nl> + treeartifactcompositefileartifactvalue that = ( treeartifactcompositefileartifactvalue ) o ; <nl> + return arrays . equals ( digest , that . digest ) ; <nl> + } <nl> + <nl> + @ override <nl> + public int hashcode ( ) { <nl> + return arrays . hashcode ( digest ) ; <nl> + } <nl> + <nl> + @ override <nl> + public filestatetype gettype ( ) { <nl> + <nl> + return filestatetype . regular_file ; <nl> + } <nl> + <nl> + @ override <nl> + public byte [ ] getdigest ( ) { <nl> + return digest ; <nl> + } <nl> + <nl> + @ override <nl> + @ nullable <nl> + public filecontentsproxy getcontentsproxy ( ) { <nl> + return null ; <nl> + } <nl> + <nl> + @ override <nl> + public long getsize ( ) { <nl> + return num ; <nl> + } <nl> + <nl> + @ override <nl> + public boolean wasmodifiedsincedigest ( path path ) { <nl> + return false ; <nl> + } <nl> + <nl> + @ override <nl> + public long getmodifiedtime ( ) { <nl> + throw new unsupportedoperationexception ( ) ; <nl> + } <nl> + <nl> + @ override <nl> + public string tostring ( ) { <nl> + return moreobjects . tostringhelper ( this ) <nl> + . add ( " digest " , baseencoding . base16 ( ) . lowercase ( ) . encode ( digest ) ) <nl> + . tostring ( ) ; <nl> + } <nl> + <nl> + @ override <nl> + protected boolean couldbemodifiedbymetadata ( fileartifactvalue o ) { <nl> + return false ; <nl> + } <nl> + <nl> + @ override <nl> + public boolean isremote ( ) { <nl> + return isremote ; <nl> + } <nl> + } <nl> + <nl> private treeartifactvalue ( <nl> byte [ ] digest , <nl> immutablesortedmap < treefileartifact , fileartifactvalue > childdata , <nl>
public class remoteactionfilesystem extends delegatefilesystem { <nl> pathfragment path = execroot . getrelative ( execpath ) ; <nl> artifact output = entry . getvalue ( ) ; <nl> if ( output . istreeartifact ( ) ) { <nl> - specialartifact parent = ( specialartifact ) output ; <nl> - treeartifactvalue . builder tree = treeartifactvalue . newbuilder ( parent ) ; <nl> if ( remoteoutputtree . exists ( path ) ) { <nl> + specialartifact parent = ( specialartifact ) output ; <nl> + treeartifactvalue . builder tree = treeartifactvalue . newbuilder ( parent ) ; <nl> + <nl> + <nl> treeartifactvalue . visittree ( <nl> remoteoutputtree . getpath ( path ) , <nl> ( parentrelativepath , type ) - > { <nl>
public class packageoptions extends optionsbase { <nl>  <nl> @ option ( <nl> name = " incompatible_config_setting_private_default_visibility " , <nl> - defaultvalue = " false " , <nl> + <nl> + defaultvalue = " true " , <nl> documentationcategory = optiondocumentationcategory . starlark_semantics , <nl> effecttags = { optioneffecttag . loading_and_analysis } , <nl> metadatatags = { optionmetadatatag . incompatible_change } ,
public final class pycommon { <nl> if ( rulecontext . getconfiguration ( ) . getactionlisteners ( ) . isempty ( ) ) { <nl> return ; <nl> } <nl> + registerpyextraactionpseudoaction ( rulecontext , dependencytransitivepythonsources ) ; <nl> + } <nl> + <nl> + / / public so that starlark bindings can access it . should only be called by pystarlarkbuiltins . <nl> + <nl> + public static void registerpyextraactionpseudoaction ( <nl> + rulecontext rulecontext , nestedset < artifact > dependencytransitivepythonsources ) { <nl> rulecontext . registeraction ( <nl> makepyextraactionpseudoaction ( <nl> rulecontext . getactionowner ( ) ,
public class packageoptions extends optionsbase { <nl>  <nl> @ option ( <nl> name = " incompatible_enforce_config_setting_visibility " , <nl> - defaultvalue = " false " , <nl> + <nl> + defaultvalue = " true " , <nl> documentationcategory = optiondocumentationcategory . starlark_semantics , <nl> effecttags = { optioneffecttag . loading_and_analysis } , <nl> metadatatags = { optionmetadatatag . incompatible_change } ,
public class packageoptions extends optionsbase { <nl>  <nl> @ option ( <nl> name = " incompatible_enforce_config_setting_visibility " , <nl> - defaultvalue = " false " , <nl> + <nl> + defaultvalue = " true " , <nl> documentationcategory = optiondocumentationcategory . starlark_semantics , <nl> effecttags = { optioneffecttag . loading_and_analysis } , <nl> metadatatags = { optionmetadatatag . incompatible_change } ,
public final class bazelbuildeventservicemoduletest extends buildintegrationtest <nl> events . assertnowarningsorerrors ( ) ; <nl> } <nl>  <nl> + <nl> + @ ignore ( " b / 246912214 " ) <nl> @ test <nl> public void testbeforesecondcommand_fullyasync_slowhalfclosewarning ( ) throws exception { <nl> buildeventservice . setdelaybeforehalfclosingstream ( duration . ofseconds ( 10 ) ) ; <nl>
public final class bazelbuildeventservicemoduletest extends buildintegrationtest <nl> events . assertnowarningsorerrors ( ) ; <nl> } <nl>  <nl> + <nl> + @ ignore ( " b / 246912214 " ) <nl> @ test <nl> public void testbeforesecondcommand_fullyasync_bestimeout_slowhalfclosewarning ( ) <nl> throws exception {
eof <nl> expect_log " in pkg / library . cpp : ' ' " <nl> } <nl>  <nl> + function test_compiler_flag_gcc ( ) { <nl> + # the default macos toolchain always uses xcode ' s clang . <nl> + [ " $ platform " ! = " darwin " ] | | return num <nl> + type - p gcc | | return num <nl> + <nl> + cat > build . bazel < < ' eof ' <nl> + config_setting ( <nl> + name = " gcc_compiler " , <nl> + flag_values = { " @ bazel_tools / / tools / cpp : compiler " : " gcc " } , <nl> + ) <nl> + <nl> + cc_binary ( <nl> + name = " main " , <nl> + srcs = select ( { " : gcc_compiler " : [ " main . cc " ] } ) , <nl> + ) <nl> + eof <nl> + cat > main . cc < < ' eof ' <nl> + int main ( ) { } <nl> + eof <nl> + <nl> + bazel build / / : main - - repo_env = cc = gcc | | fail " expected compiler flag to have value ' gcc ' " <nl> + } <nl> + <nl> + function test_compiler_flag_clang ( ) { <nl> + # <nl> + # " compiler " . <nl> + [ " $ platform " ! = " darwin " ] | | return num <nl> + type - p clang | | return num <nl> + <nl> + cat > build . bazel < < ' eof ' <nl> + config_setting ( <nl> + name = " clang_compiler " , <nl> + flag_values = { " @ bazel_tools / / tools / cpp : compiler " : " clang " } , <nl> + ) <nl> + <nl> + cc_binary ( <nl> + name = " main " , <nl> + srcs = select ( { " : clang_compiler " : [ " main . cc " ] } ) , <nl> + ) <nl> + eof <nl> + cat > main . cc < < ' eof ' <nl> + int main ( ) { } <nl> + eof <nl> + <nl> + bazel build / / : main - - repo_env = cc = clang | | fail " expected compiler flag to have value ' clang ' " <nl> + } <nl> + <nl> run_suite " cc_integration_test " <nl> mmm a / tools / cpp / unix_cc_configure . bzl <nl> ppp b / tools / cpp / unix_cc_configure . bzl <nl>
platforms : <nl> build_flags : <nl> - " - - copt = - w " <nl> - " - - host_copt = - w " <nl> - - " - c " <nl> - - " opt " <nl> + # <nl> + # - " - c " <nl> + # - " opt " <nl> build_targets : <nl> - " / / src : bazel . exe " <nl> - " / / src : bazel_nojdk . exe " <nl>
platforms : <nl> build_flags : <nl> - " - - copt = - w " <nl> - " - - host_copt = - w " <nl> - - " - c " <nl> - - " opt " <nl> + # <nl> + # - " - c " <nl> + # - " opt " <nl> - " - - cpu = x64_arm64_windows " <nl> build_targets : <nl> - " / / src : bazel . exe "
that provide a reproducible version of this rule ( which a tag not necessarily <nl> is ) . <nl> " " " , <nl> ) <nl> + <nl> + # <nl> + new_git_repository = git_repository
public class coreoptions extends fragmentoptions implements cloneable { <nl> " if true , the target platform is used in the output directory name instead of the cpu . " ) <nl> public boolean platforminoutputdir ; <nl>  <nl> + <nl> @ option ( <nl> name = " incompatible_use_platforms_repo_for_constraints " , <nl> defaultvalue = " false " ,
public class localdiffawarenessintegrationtest extends skyframeintegrationtestba <nl>  <nl> @ test <nl> public void changedfile_detectschange ( ) throws exception { <nl> + <nl> + assume ( ) . that ( os . getcurrent ( ) ) . isnotequalto ( os . darwin ) ; <nl> write ( " foo / build " , " genrule ( name = ' foo ' , outs = [ ' out ' ] , cmd = ' echo hello > $ @ ' ) " ) ; <nl> buildtarget ( " / / foo " ) ; <nl> assertcontents ( " hello " , " / / foo " ) ; <nl>
public class localdiffawarenessintegrationtest extends skyframeintegrationtestba <nl>  <nl> @ test <nl> public void changedfile_statfails_throwserror ( ) throws exception { <nl> + <nl> + assume ( ) . that ( os . getcurrent ( ) ) . isnotequalto ( os . darwin ) ; <nl> write ( " foo / build " , " genrule ( name = ' foo ' , outs = [ ' out ' ] , cmd = ' echo hello > $ @ ' ) " ) ; <nl> buildtarget ( " / / foo " ) ; <nl> assertcontents ( " hello " , " / / foo " ) ;
public class dexarchiveaspect extends nativeaspectclass implements configuredasp <nl> javaruleoutputjarsprovider outputjarsprovider = <nl> base . getprovider ( javaruleoutputjarsprovider . class ) ; <nl> if ( outputjarsprovider ! = null ) { <nl> + <nl> return outputjarsprovider . getjavaoutputs ( ) . stream ( ) <nl> . map ( javaoutput : : getclassjar ) <nl> . collect ( toimmutablelist ( ) ) ; <nl> } else { <nl> javainfo javainfo = javainfo . getjavainfo ( base ) ; <nl> if ( javainfo ! = null ) { <nl> - return javainfo . getdirectruntimejars ( ) ; <nl> + return javainfo . getjavaoutputs ( ) . stream ( ) <nl> + . map ( javaoutput : : getclassjar ) <nl> + . collect ( toimmutablelist ( ) ) ; <nl> } <nl> } <nl> }
public class cppruleclasses { <nl> return env . gettoolslabel ( cpphelper . toolchain_type_label ) ; <nl> } <nl>  <nl> + public static toolchaintyperequirement cctoolchaintyperequirement ( label cctoolchaintype ) { <nl> + <nl> + return toolchaintyperequirement . builder ( cctoolchaintype ) . mandatory ( true ) . build ( ) ; <nl> + } <nl> + <nl> + public static toolchaintyperequirement cctoolchaintyperequirement ( ruledefinitionenvironment env ) { <nl> + return cctoolchaintyperequirement ( cppruleclasses . cctoolchaintypeattribute ( env ) ) ; <nl> + } <nl> + <nl> / / artifacts of these types are discarded from the ' hdrs ' attribute in cc rules <nl> static final filetypeset disallowed_hdrs_files = <nl> filetypeset . of (
final class javainfobuildhelper { <nl> . addprovider ( javacompilationargsprovider . class , javacompilationargsprovider ) <nl> . addprovider ( <nl> javasourcejarsprovider . class , <nl> - createjavasourcejarsprovider ( outputsourcejars , concat ( runtimedeps , exports , deps ) ) ) <nl> + createoutputsourcejar <nl> + ? createjavasourcejarsprovider ( outputsourcejars , concat ( runtimedeps , exports , deps ) ) <nl> + : javasourcejarsprovider . create ( <nl> + <nl> + nestedsetbuilder . wrap ( order . stable_order , sourcejars ) , sourcejars ) ) <nl> . addprovider ( javaruleoutputjarsprovider . class , outputjarsbuilder . build ( ) ) <nl> . javaplugininfo ( mergeexportedjavaplugininfo ( exportedplugins , exports ) ) <nl> . addprovider ( javaccinfoprovider . class , javaccinfoprovider . merge ( transitivenativelibraries ) )
public class desugar { <nl> descriptorutils . descriptortobinaryname ( <nl> missingtypediagnostic . getmissingtype ( ) . getdescriptor ( ) ) ) ; <nl> } <nl> + <nl> + if ( warning instanceof stringdiagnostic <nl> + & & warning <nl> + . getdiagnosticmessage ( ) <nl> + . contains ( <nl> + " retargeting non final method encoded method java . nio . channels . filechannel " ) ) { <nl> + / / ignore . <nl> + return ; <nl> + } <nl> diagnosticshandler . super . warning ( warning ) ; <nl> } <nl> }
base_jdk9_jvm_opts = [ <nl> # and : https : / / github . com / bazelbuild / bazel / issues / 5599 <nl> " - - add - opens = java . base / java . nio = all - unnamed " , <nl> " - - add - opens = java . base / java . lang = all - unnamed " , <nl> + <nl> + # <nl> + # disable symlinks resolution cache since symlinks in exec root change <nl> + " - dsun . io . usecanoncaches = false " , <nl> ] <nl>  <nl> jdk9_jvm_opts = base_jdk9_jvm_opts <nl>
public abstract class resolvedtoolchaincontext implements toolchaincontext { <nl> } <nl> } <nl>  <nl> - / / verify that all mandatory toolchain type requirements are present . <nl> immutablemap < toolchaintypeinfo , toolchaininfo > toolchains = toolchainsbuilder . buildorthrow ( ) ; <nl> + <nl> + / / verify that all mandatory toolchain type requirements are present . <nl> + <nl> + / * <nl> for ( toolchaintyperequirement toolchaintyperequirement : <nl> unloadedtoolchaincontext . toolchaintypes ( ) ) { <nl> if ( toolchaintyperequirement . mandatory ( ) ) { <nl>
public class resolvedtoolchaincontexttest extends toolchaintestcase { <nl> . isequalto ( " baz " ) ; <nl> } <nl>  <nl> + <nl> @ test <nl> + @ ignore ( " b / 232128775 " ) <nl> public void load_mandatory_missing ( ) throws exception { <nl> toolchaincontextkey toolchaincontextkey = <nl> toolchaincontextkey . key ( ) <nl> mmm a / src / test / shell / integration / toolchain_test . sh <nl> ppp b / src / test / shell / integration / toolchain_test . sh <nl>
eof <nl> expect_log ' using toolchain in aspect : rule message : " bar from demo " , toolchain extra_str : " foo from test_toolchain " ' <nl> } <nl>  <nl> + function test_toolchain_use_in_aspect_with_output_file { <nl> + local - r pkg = " $ { funcname [ 0 ] } " <nl> + write_test_toolchain " $ { pkg } " <nl> + write_test_aspect " $ { pkg } " <nl> + write_register_toolchain " $ { pkg } " <nl> + <nl> + mkdir - p " $ { pkg } / demo " <nl> + cat > " $ { pkg } / demo / demo . bzl " < < eof <nl> + def _impl ( ctx ) : <nl> + output = ctx . outputs . out <nl> + ctx . actions . write ( output = output , content = ctx . attr . message ) <nl> + <nl> + demo = rule ( <nl> + implementation = _impl , <nl> + attrs = { <nl> + ' message ' : attr . string ( ) , <nl> + ' out ' : attr . output ( ) , <nl> + } <nl> + ) <nl> + eof <nl> + cat > " $ { pkg } / demo / build " < < eof <nl> + load ( ' : demo . bzl ' , ' demo ' ) <nl> + demo ( <nl> + name = ' use ' , <nl> + message = ' bar from demo ' , <nl> + out = ' use . log ' , <nl> + ) <nl> + eof <nl> + <nl> + # also test aspects executing on an output file . <nl> + bazel build \ <nl> + - - aspects / / $ { pkg } / toolchain : aspect_use_toolchain . bzl % use_toolchain \ <nl> + " / / $ { pkg } / demo : use . log " & > $ test_log | | fail " build failed " <nl> + # <nl> + # expect_log ' using toolchain in aspect : rule message : " bar from demo " , toolchain extra_str : " foo from test_toolchain " ' <nl> + } <nl> + <nl> function test_toolchain_use_in_aspect_non_required_toolchain { <nl> local - r pkg = " $ { funcname [ 0 ] } " <nl> write_test_toolchain " $ { pkg } "
public class analysisoptions extends optionsbase { <nl>  <nl> @ option ( <nl> name = " experimental_keep_config_nodes_on_analysis_discard " , <nl> - defaultvalue = " true " , <nl> + <nl> + defaultvalue = " false " , <nl> documentationcategory = optiondocumentationcategory . undocumented , <nl> effecttags = { optioneffecttag . loses_incremental_state } , <nl> help =
public interface gowrapcchelperapi < <nl> public runfilesapi starlarkgetgorunfiles ( starlarkrulecontextt starlarkrulecontext ) <nl> throws evalexception , interruptedexception ; <nl>  <nl> + @ starlarkmethod ( <nl> + name = " get_arch_int_size " , <nl> + doc = " " , <nl> + documented = false , <nl> + parameters = { <nl> + @ param ( name = " go " , positional = false , named = true ) , <nl> + } ) <nl> + <nl> + public int getarchintsize ( goconfigurationt goconfig ) ; <nl> + <nl> @ starlarkmethod ( <nl> name = " collect_transitive_go_context_gopkg " , <nl> doc = " " ,
bool findzip64centraldirectory ( const u1 * bytes , size_t in_length , <nl> if ( maybereadzip64centraldirectory ( bytes , in_length , <nl> bytes + zip64_end_of_central_dir_offset , <nl> end_of_central_dir , cd ) ) { <nl> - if ( disk_with_zip64_central_directory ! = num | | zip64_total_disks ! = num ) { <nl> + <nl> + if ( disk_with_zip64_central_directory ! = num | | zip64_total_disks > num ) { <nl> fprintf ( stderr , " multi - disk jar files are not supported\n " ) ; <nl> return false ; <nl> }
public class cpphelper { <nl> } <nl> } <nl>  <nl> + <nl> / * * returns the suffix ( _ { hash } ) for artifacts generated by cc_library on windows . * / <nl> public static string getdllhashsuffix ( <nl> rulecontext rulecontext , featureconfiguration featureconfiguration ) { <nl> mmm a / src / main / starlark / builtins_bzl / common / cc / cc_helper . bzl <nl> ppp b / src / main / starlark / builtins_bzl / common / cc / cc_helper . bzl <nl>
sh_test ( <nl> ] , <nl> tags = [ " no_windows " ] , <nl> ) <nl> - for java_version in java_versions_coverage <nl> + # <nl> + for java_version in java_versions_coverage + ( " 17 " , ) <nl> ] <nl>  <nl> sh_test (
eof <nl> / / a : consumer > & $ test_log | | fail " failed to build without remote cache " <nl> } <nl>  <nl> + function test_download_top_level_remote_execution_after_local_fetches_inputs ( ) { <nl> + if [ [ " $ platform " = = " darwin " ] ] ; then <nl> + # <nl> + # setting sdkroot and developer_dir appropriately , as is required of <nl> + # action executors in order to select the appropriate xcode toolchain . <nl> + return num <nl> + fi <nl> + mkdir a <nl> + cat > a / build < < ' eof ' <nl> + genrule ( name = " dep " , srcs = [ " not_used " ] , outs = [ " dep . c " ] , cmd = " touch $ @ " ) <nl> + cc_library ( name = " foo " , srcs = [ " dep . c " ] ) <nl> + eof <nl> + echo hello > a / not_used <nl> + bazel build \ <nl> + - - experimental_ui_debug_all_events \ <nl> + - - remote_executor = grpc : / / localhost : " $ { worker_port } " \ <nl> + - - remote_download_toplevel \ <nl> + - - genrule_strategy = local \ <nl> + / / a : dep > & " $ { test_log } " | | fail " expected success " <nl> + expect_log " start . * : \ [ . * \ ] executing genrule / / a : dep " <nl> + <nl> + echo there > a / not_used <nl> + # local compilation requires now remote dep . c to successfully download . <nl> + bazel build \ <nl> + - - experimental_ui_debug_all_events \ <nl> + - - remote_executor = grpc : / / localhost : " $ { worker_port } " \ <nl> + - - remote_download_toplevel \ <nl> + - - genrule_strategy = remote \ <nl> + - - strategy = cppcompile = local \ <nl> + / / a : foo > & " $ { test_log } " | | fail " expected success " <nl> + <nl> + expect_log " start . * : \ [ . * \ ] executing genrule / / a : dep " <nl> + } <nl> + <nl> function test_uploader_respect_no_cache ( ) { <nl> mkdir - p a <nl> cat > a / build < < eof
public class starlarkjavaliteprotolibrarytest extends buildviewtestcase { <nl> * java_library / java_binary and similar rules . <nl> * / <nl> @ test <nl> + @ ignore ( " <nl> public void jplcorrectlydefinesdirectjars_strictdepsdisabled ( ) throws exception { <nl> scratch . file ( <nl> " x / build " ,
def android_lint_action ( ctx , source_files , source_jars , compilation_info ) : <nl> progress_message = semantics . lint_progress_message , <nl> executable = executable , <nl> inputs = depset ( <nl> + # <nl> source_files + source_jars , <nl> transitive = transitive_inputs , <nl> ) , <nl> mmm a / src / main / starlark / builtins_bzl / common / java / java_common . bzl <nl> ppp b / src / main / starlark / builtins_bzl / common / java / java_common . bzl <nl>
def _compile_action ( <nl>  <nl> return java_info , compilation_info <nl>  <nl> + compile_action_implicit_attrs = { <nl> + " _java_toolchain " : attr . label ( <nl> + default = semantics . java_toolchain_label , <nl> + providers = [ java_common . javatoolchaininfo ] , <nl> + ) , <nl> + } <nl> + <nl> + # <nl> compile_action = create_dep ( <nl> - _compile_action , <nl> + compile_action , <nl> attrs = { <nl> " srcs " : attr . label_list ( <nl> allow_files = [ " . java " , " . srcjar " , " . properties " ] + semantics . extra_srcs_types , <nl> mmm a / src / main / starlark / builtins_bzl / common / java / java_common . bzl <nl> ppp b / src / main / starlark / builtins_bzl / common / java / java_common . bzl <nl>
def construct_defaultinfo ( ctx , files , neverlink , has_sources_or_resources , * extr <nl> ) <nl> return default_info <nl>  <nl> + basic_java_library_implicit_attrs = merge_attrs ( <nl> + compile_action_implicit_attrs , <nl> + { <nl> + " _java_plugins " : attr . label ( <nl> + default = semantics . java_plugins_flag_alias_label , <nl> + providers = [ javaplugininfo ] , <nl> + ) , <nl> + } , <nl> + ) <nl> + <nl> + # <nl> java_common_dep = create_composite_dep ( <nl> basic_java_library , <nl> compile_action , <nl> mmm a / src / main / starlark / builtins_bzl / common / java / proguard_validation . bzl <nl> ppp b / src / main / starlark / builtins_bzl / common / java / proguard_validation . bzl <nl>
def _validate_proguard_specs_impl ( ctx , proguard_specs = [ ] , transitive_attrs = [ <nl> ) , <nl> ) <nl>  <nl> + validate_proguard_specs_implicit_attrs = { <nl> + " _proguard_allowlister " : attr . label ( <nl> + allow_files = true , <nl> + default = semantics . proguard_allowlister_label , <nl> + cfg = " exec " , <nl> + executable = true , <nl> + ) , <nl> + } <nl> + <nl> + # <nl> validate_proguard_specs = create_dep ( <nl> - _validate_proguard_specs_impl , <nl> + validate_proguard_specs , <nl> { <nl> " proguard_specs " : attr . label_list ( allow_files = true ) , <nl> " _proguard_allowlister " : attr . label (
public interface actioninputprefetcher { <nl> * initiates best - effort prefetching of all given inputs . this should not block . <nl> * <nl> * < p > for any path not under this prefetcher ' s control , the call should be a no - op . <nl> + * <nl> + * < p > <nl> + * this method to return a future . <nl> * / <nl> void prefetchfiles ( iterable < ? extends actioninput > inputs , metadataprovider metadataprovider ) <nl> throws ioexception , interruptedexception ;
public class dynamicspawnstrategy implements spawnstrategy { <nl> private void tryschedulelocaljob ( ) { <nl> synchronized ( waitinglocaljobs ) { <nl> while ( ! waitinglocaljobs . isempty ( ) & & threadlimiter . tryacquire ( ) ) { <nl> - localbranch job = waitinglocaljobs . polllast ( ) ; <nl> + localbranch job ; <nl> + <nl> + if ( options . slowremotetime > num <nl> + & & waitinglocaljobs <nl> + . peekfirst ( ) <nl> + . getage ( ) <nl> + . compareto ( duration . ofseconds ( options . slowremotetime ) ) <nl> + > num ) { <nl> + job = waitinglocaljobs . pollfirst ( ) ; <nl> + } else { <nl> + job = waitinglocaljobs . polllast ( ) ; <nl> + } <nl> job . execute ( executorservice ) ; <nl> } <nl> } <nl> mmm a / src / main / java / com / google / devtools / build / lib / dynamic / localbranch . java <nl> ppp b / src / main / java / com / google / devtools / build / lib / dynamic / localbranch . java <nl>
bazel_dep ( name = " rules_cc " , version = " 0 . 0 . 1 " ) <nl> bazel_dep ( name = " rules_python " , version = " 0 . 4 . 0 " ) <nl> bazel_dep ( name = " rules_java " , version = " 5 . 0 . 0 " ) <nl> bazel_dep ( name = " rules_proto " , version = " 4 . 0 . 0 " ) <nl> + <nl> + # <nl> + single_version_override ( <nl> + module_name = " protobuf " , <nl> + patches = [ " / / third_party / protobuf : 3 . 19 . 2 . bzlmod . patch " ] , <nl> + patch_strip = num , <nl> + )
public final class nestedset < e > { <nl> private int walk ( <nl> compacthashset < object > sets , compacthashset < e > members , object [ ] children , int pos ) { <nl> for ( object child : children ) { <nl> + if ( pos < num ) { <nl> + <nl> + throw new illegalstateexception ( <nl> + " negative position " <nl> + + pos <nl> + + " with memo length " <nl> + + memo . length <nl> + + " and child length " <nl> + + children . length ) ; <nl> + } <nl> if ( ( pos > > num ) > = memo . length ) { <nl> memo = arrays . copyof ( memo , memo . length * num ) ; <nl> }
eof <nl> rmdir " $ { socket_dir } " <nl> } <nl>  <nl> - function test_remote_grpc_via_unix_socket_direct ( ) { <nl> + # <nl> + function disabled_test_remote_grpc_via_unix_socket_direct ( ) { <nl> case " $ platform " in <nl> darwin | freebsd | linux | openbsd ) <nl> ; ;
eof <nl> | | fail " failed to build / / a : foo with remote cache " <nl> } <nl>  <nl> - function test_remote_grpc_via_unix_socket_proxy ( ) { <nl> + # <nl> + function disabled_test_remote_grpc_via_unix_socket_proxy ( ) { <nl> case " $ platform " in <nl> darwin | freebsd | linux | openbsd ) <nl> ; ;
cc_binary_attrs = { <nl> " _stl " : attr . label ( default = " @ / / third_party / stl " ) , <nl> " _cc_toolchain " : attr . label ( default = " @ / / tools / cpp : current_cc_toolchain " ) , <nl> " _cc_toolchain_type " : attr . label ( default = " @ / / tools / cpp : toolchain_type " ) , <nl> + # <nl> + " _default_copts " : attr . string_list ( ) , <nl> } <nl> cc_binary_attrs . update ( semantics . get_licenses_attr ( ) ) <nl> cc_binary_attrs . update ( semantics . get_distribs_attr ( ) )
if [ [ - n " $ verbose_coverage " ] ] ; then <nl> set - x <nl> fi <nl>  <nl> + if [ [ - z " $ lcov_merger " ] ] ; then <nl> + # this can happen if a rule returns an instrumentedfilesinfo ( which all do <nl> + # following num b216b2 ) but does not define an _lcov_merger attribute . <nl> + # unfortunately , we cannot simply stop this script being called in this case <nl> + # due to conflicts with how things work within google . <nl> + # the file creation is required because testactionbuilder has already declared <nl> + # it . <nl> + # <nl> + touch $ coverage_output_file <nl> + exit num <nl> + fi <nl> + <nl> function resolve_links ( ) { <nl> local name = " $ 1 "
public class platformoptions extends fragmentoptions { <nl> optioneffecttag . changes_inputs , <nl> optioneffecttag . loading_and_analysis <nl> } , <nl> - metadatatags = { optionmetadatatag . explicit_in_output_path } , <nl> + <nl> help = <nl> " the labels of the platform rules describing the target platforms for the current " <nl> + " command . " )
public abstract class skyframeexecutor implements walkablegraphfactory , configur <nl> lastremotedefaultexecproperties ! = null <nl> & & ! remotedefaultexecproperties . equals ( lastremotedefaultexecproperties ) ; <nl> lastremotedefaultexecproperties = remotedefaultexecproperties ; <nl> + <nl> + boolean remotecacheenabled = remoteoptions ! = null & & remoteoptions . isremotecacheenabled ( ) ; <nl> + / / if we have remote metadata from last build , and the remote cache is not <nl> + / / enabled in this build , invalidate actions since they can ' t download those <nl> + / / remote files . <nl> + / / <nl> + <nl> + if ( lastremoteoutputsmode ! = remoteoutputsmode . all ) { <nl> + needsdeletion | = <nl> + lastremotecacheenabled ! = null & & lastremotecacheenabled & & ! remotecacheenabled ; <nl> + } <nl> + lastremotecacheenabled = remotecacheenabled ; <nl> + <nl> remoteoutputsmode remoteoutputsmode = <nl> remoteoptions ! = null ? remoteoptions . remoteoutputsmode : remoteoutputsmode . all ; <nl> needsdeletion | = lastremoteoutputsmode ! = null & & lastremoteoutputsmode ! = remoteoutputsmode ; <nl> this . lastremoteoutputsmode = remoteoutputsmode ; <nl> + <nl> if ( needsdeletion ) { <nl> memoizingevaluator . delete ( k - > skyfunctions . action_execution . equals ( k . functionname ( ) ) ) ; <nl> } <nl> mmm a / src / test / shell / bazel / remote / remote_execution_test . sh <nl> ppp b / src / test / shell / bazel / remote / remote_execution_test . sh <nl>
eof <nl> } <nl>  <nl> # regression test for b / 205753626 . <nl> + # this test case isn ' t testing aquery for correctness , just using aquery as a <nl> + # vehicle for testing lower - level logic . <nl> + # <nl> function test_starlark_action_with_reqs_has_deterministic_action_key ( ) { <nl> local - r pkg = " $ { funcname [ 0 ] } " <nl> mkdir - p " $ pkg " | | fail " mkdir - p $ pkg "
<nl> + # replace the original workspace file with this file to build bazel with bzlmod . <nl> + # we still need the bind rules to make protobuf work . <nl> + workspace ( name = " io_bazel " ) <nl> + <nl> + # required by @ com_google_protobuf / / java / util : util in protobuf num . 19 . 0 <nl> + # <nl> + # fetch jar dependencies via rules_jvm_external with module extension . <nl> + bind ( <nl> + name = " error_prone_annotations " , <nl> + actual = " / / third_party : error_prone_annotations " , <nl> + ) <nl> + <nl> + bind ( <nl> + name = " j2objc_annotations " , <nl> + actual = " / / third_party / java / j2objc - annotations : j2objc - annotations " , <nl> + ) <nl> + <nl> + bind ( <nl> + name = " gson " , <nl> + actual = " / / third_party : gson " , <nl> + ) <nl> + <nl> + bind ( <nl> + name = " jsr305 " , <nl> + actual = " / / third_party : jsr305 " , <nl> + ) <nl> + <nl> + bind ( <nl> + name = " guava " , <nl> + actual = " / / third_party : guava " , <nl> + ) <nl> mmm a / src / package - bazel . sh <nl> ppp b / src / package - bazel . sh <nl>
def _get_escaped_xcode_cxx_inc_directories ( repository_ctx , cc , xcode_toolchains ) <nl>  <nl> return include_dirs <nl>  <nl> - def _compile_cc_file ( repository_ctx , src_name , out_name ) : <nl> + # <nl> + def _compile_cc_file_single_arch ( repository_ctx , src_name , out_name ) : <nl> env = repository_ctx . os . environ <nl> xcrun_result = repository_ctx . execute ( [ <nl> " env " , <nl>
public final class bazelmockccsupport extends mockccsupport { <nl> public predicate < string > labelnamefilter ( ) { <nl> return bazelmockccsupport : : isnotcclabel ; <nl> } <nl> + <nl> + / * * creates bare - minimum filesystem state to support cpp rules . * / <nl> + private static void createdummycpppackages ( mocktoolsconfig config ) throws ioexception { <nl> + if ( config . isrealfilesystem ( ) ) { <nl> + <nl> + config . append ( <nl> + testconstants . tools_repository_scratch + " tools / cpp / build " , <nl> + " exports_files ( [ ' toolchain ' , ' grep - includes ' , ' malloc ' ] ) " ) ; <nl> + config . create ( testconstants . tools_repository_scratch + " tools / cpp / toolchain " , " " ) ; <nl> + config . create ( testconstants . tools_repository_scratch + " tools / cpp / grep - includes " , " " ) ; <nl> + config . create ( testconstants . tools_repository_scratch + " tools / cpp / malloc " , " " ) ; <nl> + } <nl> + } <nl> }
public class commandfailureutils { <nl> } <nl> output . append ( <nl> describecommand ( form , / * prettyprintargs = * / false , commandlineelements , env , cwd ) ) ; <nl> + <nl> if ( verbose & & executionplatform ! = null ) { <nl> output . append ( " \n " ) ; <nl> output . append ( " execution platform : " ) . append ( executionplatform . label ( ) ) ; <nl> mmm a / src / main / java / com / google / devtools / build / lib / util / describableexecutionunit . java <nl> ppp b / src / main / java / com / google / devtools / build / lib / util / describableexecutionunit . java <nl>
public class dataresourcexmltest { <nl> . xmlcontentsisequalto ( resourcesxmlfrom ( source , xml ) ) ; <nl> } <nl>  <nl> + @ test <nl> + public void writeoverlayablexmlresource ( ) throws exception { <nl> + <nl> + assumetrue ( resourcetype . getenum ( " overlayable " ) ! = null ) ; <nl> + <nl> + string xml = <nl> + " < overlayable name = ' foo ' > " <nl> + + " < policy type = ' public ' > " <nl> + + " < item name = ' my_color ' type = ' color ' / > " <nl> + + " < / policy > " <nl> + + " < / overlayable > " ; <nl> + path source = writeresourcexml ( xml ) ; <nl> + assertabout ( resourcepaths ) <nl> + . that ( parsedandwritten ( source , fqn ( " overlayable / foo " ) ) ) <nl> + . xmlcontentsisequalto ( resourcesxmlfrom ( source , xml ) ) ; <nl> + } <nl> + <nl> @ test <nl> public void serializemultiplesimplexmlresources ( ) throws exception { <nl> path serialized = fs . getpath ( " out / out . bin " ) ; <nl> mmm a / src / tools / android / java / com / google / devtools / build / android / dataresourcexml . java <nl> ppp b / src / tools / android / java / com / google / devtools / build / android / dataresourcexml . java <nl>
public class spawnstrategyregistrytest { <nl> . containsexactly ( strategy2 ) ; <nl> } <nl>  <nl> + / * * <nl> + * this demostrate a legacy behavior that the latter description filter doesn ' t override <nl> + * preceeding one of same regexp . filter = val_1 filter = val_2 is equivalent to filter = val_2 , val_1 <nl> + * <nl> + * / <nl> + @ test <nl> + public void testduplicateddescriptionfilter ( ) throws exception { <nl> + noopstrategy strategy1 = new noopstrategy ( " 1 " ) ; <nl> + noopstrategy strategy2 = new noopstrategy ( " 2 " ) ; <nl> + spawnstrategyregistry strategyregistry = <nl> + spawnstrategyregistry . builder ( ) <nl> + . registerstrategy ( strategy1 , " foo " ) <nl> + . registerstrategy ( strategy2 , " bar " ) <nl> + . adddescriptionfilter ( ello_matcher , immutablelist . of ( " foo " ) ) <nl> + . adddescriptionfilter ( ello_matcher , immutablelist . of ( " bar " ) ) <nl> + . build ( ) ; <nl> + <nl> + assertthat ( <nl> + strategyregistry . getstrategies ( <nl> + createspawnwithmnemonicanddescription ( " " , " hello " ) , <nl> + spawnstrategyregistrytest : : noopeventhandler ) ) <nl> + . containsexactly ( strategy2 , strategy1 ) ; <nl> + } <nl> + <nl> @ test <nl> public void testmultipledefaultstrategies ( ) throws exception { <nl> noopstrategy strategy1 = new noopstrategy ( " 1 " ) ; <nl>
public class spawnstrategyregistrytest { <nl> assertthat ( exception ) . hasmessagethat ( ) . containsmatch ( " bar . * valid . * foo " ) ; <nl> } <nl>  <nl> + / * * <nl> + * <nl> + * outcome here . <nl> + * / <nl> @ test <nl> public void testdescriptionstrategynotpresent ( ) { <nl> noopstrategy strategy1 = new noopstrategy ( " 1 " ) ; <nl>
public abstract class invalidatingnodevisitor < grapht extends queryablegraph > { <nl> googleautoprofilerutils . logged ( " invalidation graph traversal " , min_time_for_logging ) ) { <nl> executor . awaitquiescence ( / * interruptworkers = * / true ) ; <nl> } <nl> + concurrenthashmap . keysetview < skykey , boolean > deletedkeys = <nl> + state . visitedkeysacrossinterruptions . keyset ( ) ; <nl> + <nl> try ( autoprofiler ignored = <nl> - googleautoprofilerutils . logged ( " reverse dep removal " , min_time_for_logging ) ) { <nl> + googleautoprofilerutils . logged ( <nl> + " reverse dep removal of " <nl> + + deletedkeys . size ( ) <nl> + + " deleted rdeps from " <nl> + + state . donekeyswithrdepstoremove . size ( ) <nl> + + " deps " , <nl> + min_time_for_logging ) ) { <nl> state . donekeyswithrdepstoremove . foreachentry ( <nl> / * parallelismthreshold = * / num , <nl> e - > { <nl> nodeentry entry = graph . get ( null , reason . rdep_removal , e . getkey ( ) ) ; <nl> - if ( entry = = null ) { <nl> - return ; <nl> + if ( entry ! = null ) { <nl> + entry . removereversedepsfromdoneentryduetodeletion ( deletedkeys ) ; <nl> } <nl> - entry . removereversedepsfromdoneentryduetodeletion ( <nl> - state . visitedkeysacrossinterruptions . keyset ( ) ) ; <nl> } ) ; <nl> state . clear ( ) ; <nl> }
<nl> package com . google . devtools . build . lib . bazel . bzlmod ; <nl>  <nl> import com . google . auto . value . autovalue ; <nl> + import com . google . common . collect . immutablemap ; <nl>  <nl> / * * a module name , version pair that identifies a module in the external dependency graph . * / <nl> @ autovalue <nl> public abstract class modulekey { <nl>  <nl> + / * * <nl> + * a mapping from module name to repository name . <nl> + * <nl> + * < p > for some well known modules , their repository names are referenced in default label values <nl> + * of some native rules ' attributes and command line flags , which don ' t go through repo mappings . <nl> + * therefore , we have to keep its canonical repository name the same as its well known repository <nl> + * name . eg . " @ com_google_protobuf / / : protoc " is used for - - proto_compiler flag . <nl> + * <nl> + * < p > <nl> + * situation . <nl> + * / <nl> + private static final immutablemap < string , string > well_known_modules = <nl> + immutablemap . of ( " com_google_protobuf " , " com_google_protobuf " ) ; <nl> + <nl> public static final modulekey root = create ( " " , version . empty ) ; <nl>  <nl> public static modulekey create ( string name , version version ) { <nl>
public abstract class androidbinary implements ruleconfiguredtargetfactory { <nl> . addstarlarkoptions ( androidfeatureflagsetprovider . getfeatureflags ( rulecontext ) ) ; <nl> } <nl>  <nl> + / / first propagate validations from most rule attributes as usual ; then handle " deps " separately <nl> + / / to propagate validations from each config split but avoid known - redundant android lint <nl> + / / validations ( b / 168038145 , b / 180746622 ) . <nl> + <nl> + ruleconfiguredtargetbuilder . collecttransitivevalidationoutputgroups ( <nl> + rulecontext , <nl> + attr - > ! " deps " . equals ( attr ) , <nl> + validations - > builder . addoutputgroup ( outputgroupinfo . validation_transitive , validations ) ) ; <nl> + boolean filtersplitvalidations = false ; / / propagate validations from first split unfiltered <nl> + for ( list < ? extends transitiveinfocollection > deps : <nl> + rulecontext . getsplitprerequisites ( " deps " ) . values ( ) ) { <nl> + for ( outputgroupinfo provider : <nl> + analysisutils . getproviders ( deps , outputgroupinfo . starlark_constructor ) ) { <nl> + nestedset < artifact > validations = provider . getoutputgroup ( outputgroupinfo . validation ) ; <nl> + if ( filtersplitvalidations ) { <nl> + / / filter out android lint validations by name : we know these validations are expensive <nl> + / / and duplicative between splits , so arbitrarily only propagate them from the first split <nl> + / / ( b / 180746622 ) . while it ' s cheesy to rely on naming patterns , more semantic filtering <nl> + / / requires a lot of work ( e . g . , using an aspect that observes actions by mnemonic ) . <nl> + nestedsetbuilder < artifact > filtered = nestedsetbuilder . stableorder ( ) ; <nl> + validations . tolist ( ) . stream ( ) <nl> + . filter ( artifact : : hasknowngeneratingaction ) <nl> + . filter ( a - > ! a . getfilename ( ) . endswith ( " android_lint_output . xml " ) ) <nl> + . foreach ( filtered : : add ) ; <nl> + validations = filtered . build ( ) ; <nl> + } <nl> + if ( ! validations . isempty ( ) ) { <nl> + builder . addoutputgroup ( outputgroupinfo . validation_transitive , validations ) ; <nl> + } <nl> + } <nl> + / / filter out android lint validations from any subsequent split , <nl> + / / because they ' re redundant with those in the first split . <nl> + filtersplitvalidations = true ; <nl> + } <nl> + <nl> return builder <nl> . setfilestobuild ( filestobuild ) <nl> . addprovider (
public class dataresourcexmltest { <nl> null ) ) ; <nl> } <nl>  <nl> + @ test <nl> + public void writemacroxmlresource ( ) throws exception { <nl> + <nl> + assumetrue ( resourcetype . getenum ( " macro " ) ! = null ) ; <nl> + <nl> + string xml = " < macro name = ' foo ' > @ string / bar < / macro > " ; <nl> + path source = writeresourcexml ( xml ) ; <nl> + assertabout ( resourcepaths ) <nl> + . that ( parsedandwritten ( source , fqn ( " macro / foo " ) ) ) <nl> + . xmlcontentsisequalto ( resourcesxmlfrom ( source , xml ) ) ; <nl> + } <nl> + <nl> @ test <nl> public void serializemultiplesimplexmlresources ( ) throws exception { <nl> path serialized = fs . getpath ( " out / out . bin " ) ; <nl> mmm a / src / tools / android / java / com / google / devtools / build / android / dataresourcexml . java <nl> ppp b / src / tools / android / java / com / google / devtools / build / android / dataresourcexml . java <nl>
public class dataresourcexml implements dataresource { <nl> case xml : <nl> return xmlresourcevalues . parsesimple ( eventreader , resourcetype , start , namespacescollector ) ; <nl> default : <nl> + <nl> + / / until the layoutlib preuilt is updated or the dependency on it is removed . <nl> + if ( " macro " . equals ( resourcetype . getname ( ) ) ) { <nl> + return xmlresourcevalues . parsemacro ( eventreader , start , namespacescollector ) ; <nl> + } <nl> throw new xmlstreamexception ( <nl> string . format ( " unhandled resourcetype % s " , resourcetype ) , start . getlocation ( ) ) ; <nl> } <nl> mmm a / src / tools / android / java / com / google / devtools / build / android / xmlresourcevalues . java <nl> ppp b / src / tools / android / java / com / google / devtools / build / android / xmlresourcevalues . java <nl>
public class applecommandlineoptions extends fragmentoptions { <nl> + " option may be provided multiple times . " ) <nl> public list < map . entry < appleplatform . platformtype , applebitcodemode > > applebitcodemode ; <nl>  <nl> + <nl> + @ option ( <nl> + name = " apple_platforms " , <nl> + converter = commaseparatedoptionlistconverter . class , <nl> + defaultvalue = " null " , <nl> + documentationcategory = optiondocumentationcategory . undocumented , <nl> + effecttags = { optioneffecttag . loses_incremental_state , optioneffecttag . loading_and_analysis } , <nl> + help = " comma - separated list of platforms to use when building apple binaries . " ) <nl> + public list < string > appleplatforms ; <nl> + <nl> / * * returns whether the minimum os version is explicitly set for the current platform . * / <nl> public dottedversion getminimumosversion ( ) { <nl> dottedversion . option option ;
import com . google . devtools . build . lib . rules . apple . appleconfiguration . configuratio <nl> import com . google . devtools . build . lib . rules . apple . appleplatform ; <nl> import com . google . devtools . build . lib . rules . cpp . cppoptions ; <nl> import com . google . devtools . build . lib . skyframe . serialization . autocodec . serializationconstant ; <nl> - import net . starlark . java . eval . starlarkvalue ; <nl>  <nl> / * * <nl> * transition that produces a configuration that causes c + + toolchain selection to use the crosstool <nl> * given in apple_crosstool_top . <nl> * / <nl> - public final class applecrosstooltransition implements patchtransition , starlarkvalue { <nl> + <nl> + public final class applecrosstooltransition implements patchtransition { <nl>  <nl> / * * a singleton instance of applecrosstooltransition . * / <nl> @ serializationconstant <nl> public static final patchtransition apple_crosstool_transition = new applecrosstooltransition ( ) ; <nl>  <nl> - public applecrosstooltransition ( ) { } <nl> + private applecrosstooltransition ( ) { } <nl>  <nl> @ override <nl> public immutableset < class < ? extends fragmentoptions > > requiresoptionfragments ( ) { <nl> mmm a / src / main / java / com / google / devtools / build / lib / rules / objc / applestarlarkcommon . java <nl> ppp b / src / main / java / com / google / devtools / build / lib / rules / objc / applestarlarkcommon . java <nl>
final class lexer { <nl> / / identifier , or comment token , and records the raw text of the token . <nl> private void setvalue ( object value ) { <nl> this . value = value ; <nl> + <nl> + / / instead ? <nl> this . raw = bufferslice ( start , end ) ; <nl> } <nl>  <nl>
public class workrequesthandler implements autocloseable { <nl> * returns . if { @ code in } reaches eof , it also returns . <nl> * / <nl> public void processrequests ( ) throws ioexception { <nl> - while ( true ) { <nl> - workrequest request = messageprocessor . readworkrequest ( ) ; <nl> - if ( request = = null ) { <nl> - break ; <nl> - } <nl> - if ( request . getcancel ( ) ) { <nl> - respondtocancelrequest ( request ) ; <nl> - } else { <nl> - startresponsethread ( request ) ; <nl> + try { <nl> + while ( true ) { <nl> + workrequest request = messageprocessor . readworkrequest ( ) ; <nl> + if ( request = = null ) { <nl> + break ; <nl> + } <nl> + if ( request . getcancel ( ) ) { <nl> + respondtocancelrequest ( request ) ; <nl> + } else { <nl> + startresponsethread ( request ) ; <nl> + } <nl> } <nl> + } catch ( interruptedexception e ) { <nl> + thread . currentthread ( ) . interrupt ( ) ; <nl> + stderr . println ( " interruptedexception processing requests . " ) ; <nl> } <nl> } <nl>  <nl> / * * starts a thread for the given request . * / <nl> - void startresponsethread ( workrequest request ) { <nl> + void startresponsethread ( workrequest request ) throws interruptedexception { <nl> thread currentthread = thread . currentthread ( ) ; <nl> string threadname = <nl> request . getrequestid ( ) > num <nl> ? " multiplex - request - " + request . getrequestid ( ) <nl> : " singleplex - request " ; <nl> + <nl> + if ( request . getrequestid ( ) = = num ) { <nl> + while ( activerequests . containskey ( request . getrequestid ( ) ) ) { <nl> + / / b / 194051480 : previous singleplex requests can still be in activerequests for a bit after <nl> + / / the response has been sent . we need to wait for them to vanish . <nl> + thread . sleep ( 1 ) ; <nl> + } <nl> + } <nl> thread t = <nl> new thread ( <nl> ( ) - > { <nl> mmm a / src / test / java / com / google / devtools / build / lib / worker / exampleworker . java <nl> ppp b / src / test / java / com / google / devtools / build / lib / worker / exampleworker . java <nl>
public class testrunneraction extends abstractaction <nl> if ( executionsettings . gettotalruns ( ) > num & & ! env . containskey ( " test_random_seed " ) ) { <nl> env . put ( " test_random_seed " , integer . tostring ( getrunnumber ( ) + num ) ) ; <nl> } <nl> + <nl> + / / explicitly set test_run_number to indicate the run number and actually set test_random_seed <nl> + / / with a random seed . however , much code has come to depend on it being set to the run number <nl> + / / and this is an externally documented behavior . modifying test_random_seed should be done <nl> + / / carefully . <nl> + if ( executionsettings . gettotalruns ( ) > num & & ! env . containskey ( " test_run_number " ) ) { <nl> + env . put ( " test_run_number " , integer . tostring ( getrunnumber ( ) + num ) ) ; <nl> + } <nl>  <nl> string testfilter = getexecutionsettings ( ) . gettestfilter ( ) ; <nl> if ( testfilter ! = null ) {
public class blazejavacmain { <nl> | | name . startswith ( " com . sun . tools . " ) <nl> | | name . startswith ( " com . google . devtools . build . buildjar . javac . statistics . " ) <nl> | | name . startswith ( " dagger . model . " ) <nl> - | | name . startswith ( " dagger . spi . " ) <nl> + <nl> + | | ( name . startswith ( " dagger . spi . " ) & & ! name . startswith ( " dagger . spi . model . " ) ) <nl> | | builtinprocessors . contains ( name ) ) { <nl> return class . forname ( name ) ; <nl> }
public final class invocationpolicyenforcer { <nl> return ; <nl> } <nl>  <nl> + <nl> + invocationpolicy . getflagpolicieslist ( ) . stream ( ) <nl> + . filter ( p - > p . hassetvalue ( ) & & p . getsetvalue ( ) . getbehavior ( ) = = behavior . undefined ) <nl> + . findfirst ( ) <nl> + . ifpresent ( <nl> + policy - > <nl> + logger . atwarning ( ) . atmostevery ( 5 , minutes ) . log ( <nl> + " invocation policy has missing / undefined behavior : % s " , policy ) ) ; <nl> + <nl> / / the effective policy returned is expanded , filtered for applicable commands , and cleaned of <nl> / / redundancies and conflicts . <nl> list < flagpolicywithcontext > effectivepolicies =
public final class parameterfilewriteaction extends abstractfilewriteaction { <nl> * <nl> * < p > 2019 - 01 - 10 , @ leba : using this method for aquery since it ' s not performance - critical and the <nl> * includeparamfile option is flag - guarded with warning regarding output size to user . <nl> + * <nl> + * < p > <nl> + * artifacts . <nl> * / <nl> public iterable < string > getarguments ( ) <nl> throws commandlineexpansionexception , interruptedexception { <nl> - preconditions . checkstate ( <nl> - ! hasinputartifacttoexpand , <nl> - " this action contains a commandline with treeartifacts : % s , which must be expanded using " <nl> - + " artifactexpander first before we can evaluate the commandline . " , <nl> - getinputs ( ) ) ; <nl> return commandline . arguments ( ) ; <nl> } <nl>  <nl> mmm a / src / test / shell / integration / aquery_test . sh <nl> ppp b / src / test / shell / integration / aquery_test . sh <nl>
eof <nl> diff " $ { package } / run_1_timestamp " " $ { package } / run_2_timestamp " \ <nl> | | fail " starlark action should not rerun after bazel shutdown " <nl>  <nl> - # test that the starlark action would rerun if the inputs of the <nl> - # shadowed action changed <nl> - rm " $ { package } / x . h " <nl> - echo " inline int x ( ) { return num ; } " > " $ { package } / x . h " <nl> - <nl> - bazel build " $ { package } : a " \ <nl> - - - aspects = " / / $ { package } : lib . bzl % actions_test_aspect " \ <nl> - - - output_groups = out | | \ <nl> - fail " bazel build should ' ve succeeded " <nl> - <nl> - cp " bazel - bin / $ { package } / run_timestamp " " $ { package } / run_3_timestamp " <nl> - <nl> - diff " $ { package } / run_1_timestamp " " $ { package } / run_3_timestamp " \ <nl> - & & fail " starlark action should rerun after shadowed action inputs change " \ <nl> - | | : <nl> + # <nl> + # # test that the starlark action would rerun if the inputs of the <nl> + # # shadowed action changed <nl> + # rm " $ { package } / x . h " <nl> + # echo " inline int x ( ) { return num ; } " > " $ { package } / x . h " <nl> + <nl> + # bazel build " $ { package } : a " \ <nl> + # - - aspects = " / / $ { package } : lib . bzl % actions_test_aspect " \ <nl> + # - - output_groups = out | | \ <nl> + # fail " bazel build should ' ve succeeded " <nl> + <nl> + # cp " bazel - bin / $ { package } / run_timestamp " " $ { package } / run_3_timestamp " <nl> + <nl> + # diff " $ { package } / run_1_timestamp " " $ { package } / run_3_timestamp " \ <nl> + # & & fail " starlark action should rerun after shadowed action inputs change " \ <nl> + # | | : <nl> } <nl>  <nl> run_suite " tests starlark api pertaining to action inspection via aspect "
function gen_redirects { <nl> fi <nl> } <nl>  <nl> + # <nl> + # temporarily redirect / versions / master to main . remove when we decide to stop <nl> + # serving under the old name . <nl> + <nl> + # generates a redirect for a documentation page under <nl> + # / versions / $ latest_release_version . <nl> + function gen_master_redirect { <nl> + f = " $ 1 " <nl> + local output_dir = $ out_dir / versions / master / $ ( dirname $ f ) <nl> + if [ [ ! - d " $ output_dir " ] ] ; then <nl> + mkdir - p " $ output_dir " <nl> + fi <nl> + <nl> + local src_basename = $ ( basename $ f ) <nl> + local md_basename = " $ { src_basename % . * } . md " <nl> + local html_file = " $ { f % . * } . html " <nl> + local redirect_file = " $ output_dir / $ md_basename " <nl> + cat > " $ redirect_file " < < eof <nl> + mmm <nl> + layout : redirect <nl> + redirect : / versions / main / $ html_file <nl> + mmm <nl> + eof <nl> + } <nl> + <nl> + function gen_master_redirects { <nl> + if [ [ " $ version " = = " main " ] ] ; then <nl> + master_dir = " $ out_dir / versions / master " <nl> + mkdir - p " $ master_dir " <nl> + for f in $ ( cd " $ out_dir / versions / main " ; find . - name ' * . html ' - o - name ' * . md ' - type f ) ; do <nl> + gen_master_redirect $ f <nl> + done <nl> + fi <nl> + } <nl> + <nl> # creates a tar archive containing the final jekyll tree . <nl> function package_output { <nl> cd " $ out_dir " <nl>
public class ruleclass { <nl> / / an instance of the built - in ' test_suite ' rule with an undefined or empty ' tests ' attribute <nl> / / attribute gets an ' $ implicit_tests ' attribute , whose value is a shared per - package list of <nl> / / all test labels , populated later . <nl> - if ( this . name . equals ( " test_suite " ) ) { <nl> + <nl> + if ( this . name . equals ( " test_suite " ) & & ! this . isstarlark ( ) ) { <nl> attribute implicittests = this . getattributebyname ( " $ implicit_tests " ) ; <nl> nonconfigurableattributemapper attributemapper = nonconfigurableattributemapper . of ( rule ) ; <nl> if ( implicittests ! = null & & attributemapper . get ( " tests " , buildtype . label_list ) . isempty ( ) ) {
message setvalue { <nl> / / whether to allow this policy to be overridden by user - specified values . <nl> / / when set , if the user specified a value for this flag , use the value <nl> / / from the user , otherwise use the value specified in this policy . <nl> + / / this value is redundant to behavior - - please keep it in sync with it . <nl> optional bool overridable = num ; <nl>  <nl> / / if true , and if the flag named in the policy is a repeatable flag , then <nl> / / the values listed in flag_value do not replace all the user - set or default <nl> / / values of the flag , but instead append to them . if the flag is not <nl> / / repeatable , then this has no effect . <nl> + / / this value is redundant to behavior - - please keep it in sync with it . <nl> optional bool append = num ; <nl> + <nl> + enum behavior { <nl> + undefined = num ; <nl> + / / change the flag value but allow it to be overridden by explicit settings <nl> + / / from command line / config expansion / rc files . <nl> + / / matching old flag values : append = false , overridable = true . <nl> + allow_overrides = num ; <nl> + / / append a new value for a repeatable flag , leave old values and allow <nl> + / / further overrides . <nl> + / / matching old flag values : append = true , overridable = false . <nl> + append = num ; <nl> + / / set a final value of the flag . any overrides provided by the user for <nl> + / / this flag will be ignored . <nl> + / / matching old flag values : append = false , overridable = false . <nl> + final_value_ignore_overrides = num ; <nl> + } <nl> + <nl> + / / defines how invocation policy should interact with user settings for the <nl> + / / same flag . <nl> + / / for the time being , it coexists with overridable and append with duplicate <nl> + / / semantics . please fill both of the values as we migrate to use behavior <nl> + / / only . <nl> + <nl> + optional behavior behavior = num ; <nl> } <nl>  <nl> message usedefault {
message setvalue { <nl> / / whether to allow this policy to be overridden by user - specified values . <nl> / / when set , if the user specified a value for this flag , use the value <nl> / / from the user , otherwise use the value specified in this policy . <nl> + / / this value is redundant to behavior - - please keep it in sync with it . <nl> optional bool overridable = num ; <nl>  <nl> / / if true , and if the flag named in the policy is a repeatable flag , then <nl> / / the values listed in flag_value do not replace all the user - set or default <nl> / / values of the flag , but instead append to them . if the flag is not <nl> / / repeatable , then this has no effect . <nl> + / / this value is redundant to behavior - - please keep it in sync with it . <nl> optional bool append = num ; <nl> + <nl> + enum behavior { <nl> + undefined = num ; <nl> + / / change the flag value but allow it to be overridden by explicit settings <nl> + / / from command line / config expansion / rc files . <nl> + / / matching old flag values : append = false , overridable = true . <nl> + allow_overrides = num ; <nl> + / / append a new value for a repeatable flag , leave old values and allow <nl> + / / further overrides . <nl> + / / matching old flag values : append = true , overridable = false . <nl> + append = num ; <nl> + / / set a final value of the flag . any overrides provided by the user for <nl> + / / this flag will be ignored . <nl> + / / matching old flag values : append = false , overridable = false . <nl> + final_value_ignore_overrides = num ; <nl> + } <nl> + <nl> + / / defines how invocation policy should interact with user settings for the <nl> + / / same flag . <nl> + / / for the time being , it coexists with overridable and append with duplicate <nl> + / / semantics . please fill both of the values as we migrate to use behavior <nl> + / / only . <nl> + <nl> + optional behavior behavior = num ; <nl> } <nl>  <nl> message usedefault {
public class multiarchbinarysupport { <nl> . map ( ccinfo : : getcclinkingcontext ) <nl> . collect ( toimmutablelist ( ) ) ; <nl>  <nl> + <nl> + appleplatform cpuplatform = appleplatform . fortargetcpu ( configcpu ) ; <nl> platformtobinariesmap . put ( <nl> - platform . cpustringwithtargetenvironmentfortargetcpu ( configcpu ) , <nl> + cpuplatform . cpustringwithtargetenvironmentfortargetcpu ( configcpu ) , <nl> intermediateartifacts . strippedsinglearchitecturebinary ( ) ) ; <nl>  <nl> objcprovider objcprovider = dependencyspecificconfiguration . objclinkprovider ( ) ;
platforms : <nl> build_flags : <nl> - " - c " <nl> - " opt " <nl> + macos_arm64 : <nl> + xcode_version : " 12 . 4 " <nl> + build_targets : <nl> + - " / / src : bazel " <nl> + - " / / src : bazel_nojdk " <nl> + build_flags : <nl> + - " - c " <nl> + - " opt " <nl> + # <nl> + # silicon machines for macos_arm64 platform <nl> + - " - - cpu = darwin_arm64 " <nl> windows : <nl> build_flags : <nl> - " - - copt = - w "
sh_test ( <nl> " / / src / test / shell / bazel / testdata : jdk_http_archives_filegroup " , <nl> " / / tools / test / coverageoutputgenerator / java / com / google / devtools / coverageoutputgenerator : coverage_output_generator_repo " , <nl> ] , <nl> - tags = [ " no_windows " ] , <nl> + # <nl> + tags = [ <nl> + " manual " , <nl> + " no_windows " , <nl> + ] , <nl> ) <nl> for java_version in java_versions <nl> ] <nl> mmm a / src / test / shell / bazel / bazel_java_tools_dist_test . sh <nl> ppp b / src / test / shell / bazel / bazel_java_tools_dist_test . sh <nl>
function test_java_tools_has_javac ( ) { <nl> expect_path_in_java_tools " javac - 9 + 181 - r4173 - 1 . srcjar " <nl> } <nl>  <nl> - function test_java_tools_has_jacocoagent ( ) { <nl> + # <nl> + function disable_test_java_tools_has_jacocoagent ( ) { <nl> expect_path_in_java_tools " third_party / java / jacoco / org . jacoco . agent - 0 . 8 . 3 - sources . jar " <nl> expect_path_in_java_tools " third_party / java / jacoco / org . jacoco . core - 0 . 8 . 3 - sources . jar " <nl> expect_path_in_java_tools " third_party / java / jacoco / org . jacoco . report - 0 . 8 . 3 - sources . jar " <nl> mmm a / src / test / shell / bazel / bazel_java_tools_test . sh <nl> ppp b / src / test / shell / bazel / bazel_java_tools_test . sh <nl>
function test_java_tools_has_build ( ) { <nl> expect_path_in_java_tools " build " <nl> } <nl>  <nl> - function test_java_tools_has_jacocoagent ( ) { <nl> + # <nl> + function disable_test_java_tools_has_jacocoagent ( ) { <nl> expect_path_in_java_tools " java_tools / third_party / java / jacoco / jacocoagent - 0 . 8 . 3 . jar " <nl> expect_path_in_java_tools " java_tools / third_party / java / jacoco / org . jacoco . agent - 0 . 8 . 3 . jar " <nl> expect_path_in_java_tools " java_tools / third_party / java / jacoco / org . jacoco . core - 0 . 8 . 3 . jar "
public interface starlarkindexable extends starlarkvalue { <nl> * convention . <nl> * / <nl> boolean containskey ( starlarksemantics semantics , object key ) throws evalexception ; <nl> + <nl> + / * * <nl> + * a variant of { @ link starlarkindexable } that also provides a starlarkthread instance on method <nl> + * calls . <nl> + * / <nl> + <nl> + interface threaded { <nl> + / * * { @ see starlarkindexable . getindex } * / <nl> + object getindex ( starlarkthread starlarkthread , starlarksemantics semantics , object key ) <nl> + throws evalexception ; <nl> + <nl> + / * * { @ see starlarkindexable . containskey } * / <nl> + boolean containskey ( starlarkthread starlarkthread , starlarksemantics semantics , object key ) <nl> + throws evalexception ; <nl> + } <nl> }
end_of_record " <nl> assert_equals " $ expected_result " " $ ( cat bazel - testlogs / java / factorial / fact - test / coverage . dat ) " <nl> } <nl>  <nl> + # runs coverage with ` cc_test ` and re then checks the coverage file is returned . <nl> + # older versions of gcov are not supported with bazel coverage and so will be skipped . <nl> + # see the above ` test_java_rbe_coverage_produces_report ` for more information . <nl> + function test_cc_rbe_coverage_produces_report ( ) { <nl> + if [ [ " $ platform " = = " darwin " ] ] ; then <nl> + # <nl> + # setting sdkroot and developer_dir appropriately , as is required of <nl> + # action executors in order to select the appropriate xcode toolchain . <nl> + return num <nl> + fi <nl> + <nl> + # check to see if intermediate files are supported , otherwise skip . <nl> + gcov - - help | grep " \ - i , " | | return num <nl> + <nl> + local test_dir = " a / cc / coverage_test " <nl> + mkdir - p $ test_dir <nl> + <nl> + cat > " $ test_dir " / build < < ' eof ' <nl> + package ( default_visibility = [ " / / visibility : public " ] ) <nl> + <nl> + cc_library ( <nl> + name = " hello - lib " , <nl> + srcs = [ " hello - lib . cc " ] , <nl> + hdrs = [ " hello - lib . h " ] , <nl> + ) <nl> + <nl> + cc_binary ( <nl> + name = " hello - world " , <nl> + srcs = [ " hello - world . cc " ] , <nl> + deps = [ " : hello - lib " ] , <nl> + ) <nl> + <nl> + cc_test ( <nl> + name = " hello - test " , <nl> + srcs = [ " hello - world . cc " ] , <nl> + deps = [ " : hello - lib " ] , <nl> + ) <nl> + <nl> + eof <nl> + <nl> + cat > " $ test_dir " / hello - lib . cc < < ' eof ' <nl> + # include " hello - lib . h " <nl> + <nl> + # include < iostream > <nl> + <nl> + using std : : cout ; <nl> + using std : : endl ; <nl> + using std : : string ; <nl> + <nl> + namespace hello { <nl> + <nl> + hellolib : : hellolib ( const string & greeting ) : greeting_ ( new string ( greeting ) ) { <nl> + } <nl> + <nl> + void hellolib : : greet ( const string & thing ) { <nl> + cout < < * greeting_ < < " " < < thing < < endl ; <nl> + } <nl> + <nl> + } / / namespace hello <nl> + <nl> + eof <nl> + <nl> + cat > " $ test_dir " / hello - lib . h < < ' eof ' <nl> + # ifndef hello_lib_h_ <nl> + # define hello_lib_h_ <nl> + <nl> + # include < string > <nl> + # include < memory > <nl> + <nl> + namespace hello { <nl> + <nl> + class hellolib { <nl> + public : <nl> + explicit hellolib ( const std : : string & greeting ) ; <nl> + <nl> + void greet ( const std : : string & thing ) ; <nl> + <nl> + private : <nl> + std : : unique_ptr < const std : : string > greeting_ ; <nl> + } ; <nl> + <nl> + } / / namespace hello <nl> + <nl> + # endif / / hello_lib_h_ <nl> + <nl> + eof <nl> + <nl> + cat > " $ test_dir " / hello - world . cc < < ' eof ' <nl> + # include " hello - lib . h " <nl> + <nl> + # include < string > <nl> + <nl> + using hello : : hellolib ; <nl> + using std : : string ; <nl> + <nl> + int main ( int argc , char * * argv ) { <nl> + hellolib lib ( " hello " ) ; <nl> + string thing = " world " ; <nl> + if ( argc > num ) { <nl> + thing = argv [ 1 ] ; <nl> + } <nl> + lib . greet ( thing ) ; <nl> + return num ; <nl> + } <nl> + <nl> + eof <nl> + <nl> + bazel coverage \ <nl> + - - test_output = all \ <nl> + - - experimental_fetch_all_coverage_outputs \ <nl> + - - experimental_split_coverage_postprocessing \ <nl> + - - spawn_strategy = remote \ <nl> + - - remote_executor = grpc : / / localhost : $ { worker_port } \ <nl> + / / " $ test_dir " : hello - test > & $ test_log \ <nl> + | | fail " failed to run coverage for cc_test " <nl> + <nl> + # different gcov versions generate different outputs . <nl> + # simply check if this is empty or not . <nl> + if [ [ ! - s bazel - testlogs / a / cc / coverage_test / hello - test / coverage . dat ] ] ; then <nl> + echo " coverage is empty . failing now . " <nl> + return num <nl> + fi <nl> + } <nl> + <nl> run_suite " remote execution and remote cache tests "
pkg_tar ( <nl> " : generated_resources " , <nl> " : srcs " , <nl> ] , <nl> + # <nl> remap_paths = { <nl> " workspace . filtered " : " workspace " , <nl> # rewrite paths coming from local repositories back into third_party . <nl> - " . . / googleapis " : " third_party / googleapis " , <nl> - " . . / remoteapis " : " third_party / remoteapis " , <nl> + " external / googleapis " : " third_party / googleapis " , <nl> + " external / remoteapis " : " third_party / remoteapis " , <nl> } , <nl> strip_prefix = " . " , <nl> # public but bazel - only visibility . <nl>
function test_root_cause_before_target_summary ( ) { <nl>  <nl> function test_action_conf ( ) { <nl> # verify that the expected configurations for actions are reported . <nl> - # the example contains a configuration transition ( from building for <nl> - # target to building for host ) . as the action fails , we expect the <nl> - # configuration of the action to be reported as well . <nl> - ( bazel build - - build_event_text_file = $ test_log \ <nl> + # expect the following configurations : <nl> + # num . the top - level target configuration <nl> + # num . host configuration ( since example contains transition to host ) . <nl> + # num . trimmed top - level target configuration ( since non - test rule ) . <nl> + # as the action fails , we expect the configuration of the action to be <nl> + # reported as well . <nl> + # <nl> + # once it is ( very soon ) default true . <nl> + ( bazel build - - trim_test_configuration - - build_event_text_file = $ test_log \ <nl> - k failingtool / . . . & & fail " build failure expected " ) | | true <nl> count = ` grep ' ^ configuration ' " $ { test_log } " | wc - l ` <nl> - [ " $ { count } " - eq num ] | | fail " expected num configurations , found $ count . " <nl> + [ " $ { count } " - eq num ] | | fail " expected num configurations , found $ count . " <nl> } <nl>  <nl> function test_loading_failure ( ) { <nl> mmm a / src / test / shell / integration / configured_query_test . sh <nl> ppp b / src / test / shell / integration / configured_query_test . sh <nl>
public final class testtrimmingtransitionfactory implements transitionfactory < ru <nl> / / nothing to do , already trimmed this fragment <nl> return originaloptions . underlying ( ) ; <nl> } <nl> + coreoptions originalcoreoptions = originaloptions . get ( coreoptions . class ) ; <nl> testoptions originaltestoptions = originaloptions . get ( testoptions . class ) ; <nl> - if ( ! originaltestoptions . trimtestconfiguration ) { <nl> + if ( ! originaltestoptions . trimtestconfiguration <nl> + | | ! originalcoreoptions . usedistincthostconfiguration ) { <nl> / / nothing to do , trimming is disabled <nl> + / / due to repercussions of b / 117932061 , do not trim when ` - - nodistinct_host_configuration ` <nl> + <nl> return originaloptions . underlying ( ) ; <nl> } <nl> return cache . applytransition (
public final class crash { <nl> } <nl>  <nl> / * * creates a crash caused by the given { @ link throwable } with a specified { @ link exitcode } . * / <nl> + <nl> public static crash from ( throwable throwable , exitcode exitcode ) { <nl> return new crash ( <nl> throwable , detailedexitcode . of ( exitcode , crashfailuredetails . forthrowable ( throwable ) ) ) ; <nl> } <nl>  <nl> + / * * <nl> + * creates a crash caused by the given { @ link throwable } with a specified { @ link <nl> + * detailedexitcode } . <nl> + * / <nl> + public static crash from ( throwable throwable , detailedexitcode detailedexitcode ) { <nl> + return new crash ( throwable , detailedexitcode ) ; <nl> + } <nl> + <nl> private final throwable throwable ; <nl> private final detailedexitcode detailedexitcode ;
public class bzlloadvalue implements skyvalue { <nl> } <nl> } <nl>  <nl> + <nl> @ override <nl> public string tostring ( ) { <nl> return label . tostring ( ) ;
abstract class abstractparallelevaluator { <nl> childerrorkey , <nl> childerrorinfomaybe ) ; <nl> evaluatorcontext . getvisitor ( ) . preventnewevaluations ( ) ; <nl> + <nl> + if ( childerrorinfo . getexception ( ) instanceof ioexception ) { <nl> + logger . atinfo ( ) . withcause ( childerrorinfo . getexception ( ) ) . log ( <nl> + " child % s with ioexception forced abort of % s " , childerrorkey , skykey ) ; <nl> + } <nl> throw schedulerexception . oferror ( childerrorinfo , childerrorkey , immutableset . of ( skykey ) ) ; <nl> } <nl>  <nl> mmm a / src / main / java / com / google / devtools / build / skyframe / skyfunctionenvironment . java <nl> ppp b / src / main / java / com / google / devtools / build / skyframe / skyfunctionenvironment . java <nl>
class skyfunctionenvironment extends abstractskyfunctionenvironment { <nl> if ( errorinfo = = null ) { <nl> errorinfo = evaluatorcontext . geterrorinfomanager ( ) . geterrorinfotouse ( <nl> skykey , value ! = null , childerrorinfos ) ; <nl> + <nl> + if ( errorinfo ! = null & & errorinfo . getexception ( ) instanceof ioexception ) { <nl> + logger . atinfo ( ) . withcause ( errorinfo . getexception ( ) ) . log ( <nl> + " synthetic errorinfo for % s " , skykey ) ; <nl> + } <nl> } <nl>  <nl> / / we have the following implications :
public abstract class abstractskyfunctionenvironment implements skyfunction . envi <nl> & & ( exceptionclass4 = = null | | ! exceptionclass4 . isinstance ( e ) ) <nl> & & ( exceptionclass5 = = null | | ! exceptionclass5 . isinstance ( e ) ) ) ) { <nl> valuesmissing = true ; <nl> + <nl> + if ( e instanceof ioexception & & ! ( e instanceof filenotfoundexception ) ) { <nl> + logger . atinfo ( ) . withstacktrace ( stacksize . small ) . withcause ( e ) . log ( <nl> + " ioexception suppressed by lack of skyframe declaration ( % s % s % s % s % s ) " , <nl> + exceptionclass1 , <nl> + exceptionclass2 , <nl> + exceptionclass3 , <nl> + exceptionclass4 , <nl> + exceptionclass5 ) ; <nl> + } <nl> return ; <nl> } <nl> }
function test_java_tools_has_jacocoagent ( ) { <nl> expect_path_in_java_tools " third_party / asm / asm - 8 . 0 - sources . jar " <nl> } <nl>  <nl> + # <nl> function test_java_tools_has_proguard ( ) { <nl> expect_path_in_java_tools " third_party / java / proguard " <nl> - expect_path_in_java_tools " third_party / java / proguard / proguard5 . 3 . 3 " <nl> - expect_path_in_java_tools " third_party / java / proguard / proguard5 . 3 . 3 / bin " <nl> - expect_path_in_java_tools " third_party / java / proguard / proguard5 . 3 . 3 / buildscripts " <nl> - expect_path_in_java_tools " third_party / java / proguard / proguard5 . 3 . 3 / src " <nl> - expect_path_in_java_tools " third_party / java / proguard / proguard5 . 3 . 3 / src / proguard " <nl> + expect_path_in_java_tools " third_party / java / proguard / proguard . * " <nl> + expect_path_in_java_tools " third_party / java / proguard / proguard . * / bin " <nl> + expect_path_in_java_tools " third_party / java / proguard / proguard . * / buildscripts " <nl> + expect_path_in_java_tools " third_party / java / proguard / proguard . * / src " <nl> + expect_path_in_java_tools " third_party / java / proguard / proguard . * / src / proguard " <nl> } <nl>  <nl> run_suite " java tools archive tests " <nl> mmm a / src / test / shell / bazel / bazel_java_tools_test . sh <nl> ppp b / src / test / shell / bazel / bazel_java_tools_test . sh <nl>
function test_java_tools_has_jacocoagent ( ) { <nl> expect_path_in_java_tools " java_tools / third_party / java / jacoco / license " <nl> } <nl>  <nl> + # <nl> function test_java_tools_has_proguard ( ) { <nl> expect_path_in_java_tools " java_tools / third_party / java / proguard / proguard . jar " <nl> - expect_path_in_java_tools " java_tools / third_party / java / proguard / gpl . html " <nl> + expect_path_in_java_tools " java_tools / third_party / java / proguard / gpl . * " <nl> } <nl>  <nl> function test_java_tools_toolchain_builds ( ) {
public class legacyincludescanner implements includescanner { <nl> checkforinterrupt ( " processing " , source ) ; <nl>  <nl> collection < inclusion > inclusions ; <nl> - settablefuture < collection < inclusion > > future = settablefuture . create ( ) ; <nl> - future < collection < inclusion > > previous = fileparsecache . putifabsent ( source , future ) ; <nl> - if ( previous = = null ) { <nl> - previous = future ; <nl> + try { <nl> + inclusions = <nl> + fileparsecache <nl> + . computeifabsent ( <nl> + source , <nl> + file - > { <nl> + try { <nl> + return futures . immediatefuture ( <nl> + parser . extractinclusions ( <nl> + file , <nl> + actionexecutionmetadata , <nl> + actionexecutioncontext , <nl> + grepincludes , <nl> + spawnincludescannersupplier . get ( ) , <nl> + isrealoutputfile ( source . getexecpath ( ) ) ) ) ; <nl> + } catch ( ioexception e ) { <nl> + throw new ioruntimeexception ( e ) ; <nl> + } catch ( execexception e ) { <nl> + throw new execruntimeexception ( e ) ; <nl> + } catch ( interruptedexception e ) { <nl> + throw new interruptedruntimeexception ( e ) ; <nl> + } <nl> + } ) <nl> + . get ( ) ; <nl> + } catch ( executionexception ee ) { <nl> try { <nl> - future . set ( <nl> - parser . extractinclusions ( <nl> - source , <nl> - actionexecutionmetadata , <nl> - actionexecutioncontext , <nl> - grepincludes , <nl> - spawnincludescannersupplier . get ( ) , <nl> - isrealoutputfile ( source . getexecpath ( ) ) ) ) ; <nl> - } catch ( throwable t ) { <nl> - future . setexception ( t ) ; <nl> - fileparsecache . remove ( source ) ; <nl> - throw t ; <nl> + throwables . throwifinstanceof ( ee . getcause ( ) , runtimeexception . class ) ; <nl> + throw new illegalstateexception ( ee . getcause ( ) ) ; <nl> + } catch ( ioruntimeexception e ) { <nl> + throw e . getcauseioexception ( ) ; <nl> + } catch ( execruntimeexception e ) { <nl> + throw e . getrealcause ( ) ; <nl> + } catch ( interruptedruntimeexception e ) { <nl> + throw e . getrealcause ( ) ; <nl> } <nl> - } <nl> - try { <nl> - inclusions = previous . get ( ) ; <nl> - } catch ( executionexception e ) { <nl> - throwables . propagateifpossible ( e . getcause ( ) , ioexception . class , interruptedexception . class ) ; <nl> - throwables . throwifinstanceof ( e . getcause ( ) , execexception . class ) ; <nl> - throw new illegalstateexception ( e . getcause ( ) ) ; <nl> + } catch ( runtimeexception e ) { <nl> + <nl> + logger . atsevere ( ) . withcause ( e ) . log ( " uncaught exception in call to extractinclusions " ) ; <nl> + throw e ; <nl> } <nl> preconditions . checknotnull ( inclusions , source ) ;
eof <nl> assert_equals " $ ( cat foo / expected_ap_output ) " " $ ( cat bazel - bin / foo / allpaths ) " <nl> } <nl>  <nl> + function test_graphless_query_matches_graphless_genquery_output ( ) { <nl> + mkdir - p foo <nl> + cat > foo / build < < eof <nl> + sh_library ( name = " b " , deps = [ " : c " ] ) <nl> + sh_library ( name = " c " , deps = [ " : a " ] ) <nl> + sh_library ( name = " a " ) <nl> + genquery ( <nl> + name = " q " , <nl> + expression = " deps ( / / foo : b ) " , <nl> + scope = [ " / / foo : b " ] , <nl> + ) <nl> + eof <nl> + <nl> + cat > foo / expected_lexicographical_result < < eof <nl> + / / foo : a <nl> + / / foo : b <nl> + / / foo : c <nl> + eof <nl> + <nl> + # genquery uses a graphless blaze environment by default . <nl> + bazel build - - experimental_genquery_use_graphless_query \ <nl> + / / foo : q | | fail " expected success " <nl> + <nl> + # <nl> + # query currently requires the - - incompatible_prefer_unordered_output flag to <nl> + # switch to graphless . <nl> + # in addition , - - incompatible_use_lexicographical_unordered_output is used to <nl> + # switch sort the graphless output in lexicographical order . <nl> + bazel query - - incompatible_prefer_unordered_output \ <nl> + - - incompatible_use_lexicographical_unordered_output \ <nl> + " deps ( / / foo : b ) " | grep foo > & foo / query_output | | fail " expected success " <nl> + <nl> + # the outputs of graphless query and graphless genquery should be the same . <nl> + assert_equals " $ ( cat bazel - bin / foo / q ) " " $ ( cat foo / query_output ) " <nl> + <nl> + # the outputs of both graphless query and graphless genquery should be in <nl> + # lexicographical order ( comparing one should be sufficient ) . <nl> + assert_equals \ <nl> + " $ ( cat foo / expected_lexicographical_result ) " " $ ( cat bazel - bin / foo / q ) " <nl> + } <nl> + <nl> # regression test for https : / / github . com / bazelbuild / bazel / issues / 8582 . <nl> function test_rbuildfiles_can_handle_non_loading_phase_edges ( ) { <nl> mkdir - p foo
public abstract class starlarkint implements starlarkvalue , comparable < starlarki <nl>  <nl> / * * returns x * y . * / <nl> public static starlarkint multiply ( starlarkint x , starlarkint y ) { <nl> + / / fast path for common case : int32 * int32 . <nl> if ( x instanceof int32 & & y instanceof int32 ) { <nl> long xl = ( ( int32 ) x ) . v ; <nl> long yl = ( ( int32 ) y ) . v ; <nl> return starlarkint . of ( xl * yl ) ; <nl> } <nl>  <nl> + try { <nl> + long xl = x . tolongfast ( ) ; <nl> + long yl = y . tolongfast ( ) ; <nl> + <nl> + / / signed int128 multiplication , using hacker ' s delight num - 2 <nl> + / / ( high - order half of num - bit product ) extended to num bits . <nl> + <nl> + long xlo = xl & num xffffffffl ; <nl> + long xhi = xl > > num ; <nl> + long ylo = yl & num xffffffffl ; <nl> + long yhi = yl > > num ; <nl> + long zlo = xlo * ylo ; <nl> + long t = xhi * ylo + ( zlo > > > num ) ; <nl> + long z1 = t & num xffffffffl ; <nl> + long z2 = t > > num ; <nl> + z1 + = xlo * yhi ; <nl> + <nl> + / / high and low arms of result <nl> + long z128hi = xhi * yhi + z2 + ( z1 > > num ) ; <nl> + long z128lo = xl * yl ; <nl> + <nl> + / / check int128 result is within int64 range . <nl> + if ( z128hi = = ( z128lo & long . min_value ) > > num ) { <nl> + return starlarkint . of ( z128lo ) ; <nl> + } <nl> + <nl> + / * overflow * / <nl> + <nl> + } catch ( overflow unused ) { <nl> + / * fall through * / <nl> + } <nl> + <nl> + / / avoid unnecessary conversion to biginteger if the other operand is - 1 , num , num . <nl> + / / ( also makes self - test below faster . ) <nl> + if ( x = = zero | | y = = one ) { <nl> + return x ; <nl> + } else if ( y = = zero | | x = = one ) { <nl> + return y ; <nl> + } else if ( x = = minus_one ) { <nl> + return starlarkint . uminus ( y ) ; <nl> + } else if ( y = = minus_one ) { <nl> + return starlarkint . uminus ( x ) ; <nl> + } <nl> + <nl> biginteger xbig = x . tobiginteger ( ) ; <nl> biginteger ybig = y . tobiginteger ( ) ; <nl> biginteger zbig = xbig . multiply ( ybig ) ; <nl> - return starlarkint . of ( zbig ) ; <nl> + starlarkint z = starlarkint . of ( zbig ) ; <nl> + / / cheap self - test <nl> + if ( ! ( z instanceof big ) ) { <nl> + throw new assertionerror ( <nl> + string . format ( <nl> + " bug in multiplication : % s * % s = % s , must be long multiplication " , x , y , z ) ) ; <nl> + } <nl> + return z ; <nl> } <nl>  <nl> / * * returns x / / y ( floor of integer division ) . * / <nl> mmm a / src / test / java / net / starlark / java / eval / scripttest . java <nl> ppp b / src / test / java / net / starlark / java / eval / scripttest . java <nl>
public final class runfilessupport { <nl> } <nl>  <nl> private static actionenvironment computeactionenvironment ( rulecontext rulecontext ) { <nl> - if ( ! rulecontext . getrule ( ) . isattrdefined ( " env " , type . string_dict ) <nl> - & & ! rulecontext . getrule ( ) . isattrdefined ( " env_inherit " , type . string_list ) ) { <nl> + / / currently , " env " and " env_inherit " are not added to starlark - defined rules ( unlike " args " ) , <nl> + / / in order to avoid breaking existing starlark rules that use those attribute names . <nl> + <nl> + boolean isnativerule = <nl> + rulecontext . getrule ( ) . getruleclassobject ( ) . getruledefinitionenvironmentlabel ( ) = = null ; <nl> + if ( ! isnativerule <nl> + | | ( ! rulecontext . getrule ( ) . isattrdefined ( " env " , type . string_dict ) <nl> + & & ! rulecontext . getrule ( ) . isattrdefined ( " env_inherit " , type . string_list ) ) ) { <nl> return actionenvironment . empty ; <nl> } <nl> treemap < string , string > fixedenv = new treemap < > ( ) ;
eof <nl> # we ' re not validating visibility here . let everything access these targets . <nl> package ( default_visibility = [ " / / visibility : public " ] ) <nl>  <nl> + # <nl> + # right now it ' s problematic because google ci doesn ' t support @ platforms . <nl> constraint_setting ( name = " not_compatible_setting " ) <nl>  <nl> constraint_value ( <nl> mmm a / src / test / shell / integration / target_compatible_with_test_external_repo . sh <nl> ppp b / src / test / shell / integration / target_compatible_with_test_external_repo . sh <nl>
public class legacyincludescanner implements includescanner { <nl> * inclusions <nl> * @ param visited the set to receive the files that are transitively included by { @ code source } <nl> * / <nl> + <nl> + @ suppresswarnings ( " logandthrow " ) / / temporary debugging . <nl> private void process ( <nl> final artifact source , int contextpathpos , kind contextkind , set < artifact > visited ) <nl> throws ioexception , execexception , interruptedexception { <nl>
public class legacyincludescanner implements includescanner { <nl> } catch ( interruptedruntimeexception e ) { <nl> throw e . getrealcause ( ) ; <nl> } <nl> + } catch ( runtimeexception e ) { <nl> + <nl> + logger . atsevere ( ) . withcause ( e ) . log ( " uncaught exception in call to extractinclusions " ) ; <nl> + throw e ; <nl> } <nl> preconditions . checknotnull ( inclusions , source ) ;
class skyfunctionenvironment extends abstractskyfunctionenvironment { <nl> if ( prefetch_old_deps ) { <nl> request = new queryablegraph . prefetchdepsrequest ( requestor , olddeps , depkeys ) ; <nl> evaluatorcontext . getgraph ( ) . prefetchdeps ( request ) ; <nl> + } else if ( prefetch_and_retain_old_deps ) { <nl> + <nl> + immutablemap . builder < skykey , skyvalue > olddepvaluesbuilder = <nl> + immutablemap . builderwithexpectedsize ( olddeps . size ( ) ) ; <nl> + map < skykey , ? extends nodeentry > map = <nl> + evaluatorcontext . getbatchvalues ( requestor , reason . prefetch , olddeps ) ; <nl> + for ( entry < skykey , ? extends nodeentry > entry : map . entryset ( ) ) { <nl> + skyvalue valuemaybewithmetadata = entry . getvalue ( ) . getvaluemaybewithmetadata ( ) ; <nl> + if ( valuemaybewithmetadata ! = null ) { <nl> + olddepvaluesbuilder . put ( entry . getkey ( ) , valuemaybewithmetadata ) ; <nl> + } <nl> + } <nl> + this . olddepsvalues = olddepvaluesbuilder . build ( ) ; <nl> } <nl> map < skykey , ? extends nodeentry > batchmap = <nl> evaluatorcontext . getbatchvalues ( <nl>
<nl> config_setting ( <nl> name = " freebsd " , <nl> - constraint_values = [ " @ platforms / / os : freebsd " ] , <nl> + constraint_values = [ " @ platforms / / os : freebsd " ] , <nl> visibility = [ " / / visibility : public " ] , <nl> ) <nl>  <nl> config_setting ( <nl> name = " openbsd " , <nl> - constraint_values = [ " @ platforms / / os : openbsd " ] , <nl> + constraint_values = [ " @ platforms / / os : openbsd " ] , <nl> visibility = [ " / / visibility : public " ] , <nl> ) <nl>  <nl> config_setting ( <nl> name = " darwin " , <nl> - constraint_values = [ " @ platforms / / os : macos " ] , <nl> + constraint_values = [ " @ platforms / / os : macos " ] , <nl> visibility = [ " / / visibility : public " ] , <nl> ) <nl>  <nl> config_setting ( <nl> name = " linux_ppc " , <nl> - constraint_values = [ " @ platforms / / os : linux " , " @ platforms / / cpu : ppc " ] , <nl> + constraint_values = [ <nl> + " @ platforms / / os : linux " , <nl> + " @ platforms / / cpu : ppc " , <nl> + ] , <nl> visibility = [ " / / visibility : public " ] , <nl> ) <nl>  <nl> config_setting ( <nl> name = " linux_ppc64le " , <nl> - constraint_values = [ " @ platforms / / os : linux " , " @ platforms / / cpu : ppc " ] , <nl> + constraint_values = [ <nl> + " @ platforms / / os : linux " , <nl> + " @ platforms / / cpu : ppc " , <nl> + ] , <nl> visibility = [ " / / visibility : public " ] , <nl> ) <nl>  <nl> config_setting ( <nl> name = " linux_s390x " , <nl> - constraint_values = [ " @ platforms / / os : linux " , " @ platforms / / cpu : s390x " ] , <nl> + constraint_values = [ <nl> + " @ platforms / / os : linux " , <nl> + " @ platforms / / cpu : s390x " , <nl> + ] , <nl> visibility = [ " / / visibility : public " ] , <nl> ) <nl>  <nl> config_setting ( <nl> name = " linux_x86_64 " , <nl> - constraint_values = [ " @ platforms / / os : linux " , " @ platforms / / cpu : x86_64 " ] , <nl> + constraint_values = [ <nl> + " @ platforms / / os : linux " , <nl> + " @ platforms / / cpu : x86_64 " , <nl> + ] , <nl> visibility = [ " / / visibility : public " ] , <nl> ) <nl>  <nl> config_setting ( <nl> name = " linux_aarch64 " , <nl> - constraint_values = [ " @ platforms / / os : linux " , " @ platforms / / cpu : aarch64 " ] , <nl> + constraint_values = [ <nl> + " @ platforms / / os : linux " , <nl> + " @ platforms / / cpu : aarch64 " , <nl> + ] , <nl> visibility = [ " / / visibility : public " ] , <nl> ) <nl>  <nl> config_setting ( <nl> name = " darwin_x86_64 " , <nl> - constraint_values = [ " @ platforms / / os : macos " , " @ platforms / / cpu : x86_64 " ] , <nl> + constraint_values = [ <nl> + " @ platforms / / os : macos " , <nl> + " @ platforms / / cpu : x86_64 " , <nl> + ] , <nl> visibility = [ " / / visibility : public " ] , <nl> ) <nl>  <nl> config_setting ( <nl> name = " darwin_arm64 " , <nl> - constraint_values = [ " @ platforms / / os : macos " , " @ platforms / / cpu : arm64 " ] , <nl> + constraint_values = [ <nl> + " @ platforms / / os : macos " , <nl> + " @ platforms / / cpu : arm64 " , <nl> + ] , <nl> visibility = [ " / / visibility : public " ] , <nl> ) <nl>  <nl> config_setting ( <nl> name = " darwin_arm64e " , <nl> - constraint_values = [ " @ platforms / / os : macos " , " @ platforms / / cpu : arm64e " ] , <nl> + constraint_values = [ <nl> + " @ platforms / / os : macos " , <nl> + " @ platforms / / cpu : arm64e " , <nl> + ] , <nl> visibility = [ " / / visibility : public " ] , <nl> ) <nl>  <nl> config_setting ( <nl> name = " windows " , <nl> - constraint_values = [ " @ platforms / / os : windows " ] , <nl> + constraint_values = [ " @ platforms / / os : windows " ] , <nl> + visibility = [ " / / visibility : public " ] , <nl> + ) <nl> + <nl> + # <nl> + config_setting ( <nl> + name = " windows_msvc " , <nl> + values = { " cpu " : " x64_windows_msvc " } , <nl> visibility = [ " / / visibility : public " ] , <nl> )
config_setting ( <nl> ) <nl>  <nl> config_setting ( <nl> - name = " darwin_arm64 " , <nl> + name = " darwin_arm64_constraint " , <nl> constraint_values = [ <nl> " @ platforms / / os : macos " , <nl> " @ platforms / / cpu : arm64 " , <nl> ] , <nl> + ) <nl> + <nl> + config_setting ( <nl> + name = " darwin_arm64_flag " , <nl> + values = { " cpu " : " darwin_arm64 " } , <nl> + ) <nl> + <nl> + # workaround for an issue where the dummy cc toolchain isn ' t being picked up <nl> + # when cross - compile from darwin_x86_64 to darwin_arm64 cpu . <nl> + # <nl> + # select when the issue is resolved . <nl> + selects . config_setting_group ( <nl> + name = " darwin_arm64 " , <nl> + match_any = [ <nl> + " : darwin_arm64_constraint " , <nl> + " : darwin_arm64_flag " , <nl> + ] , <nl> visibility = [ " / / visibility : public " ] , <nl> )
eof <nl> } <nl>  <nl> function test_workspace_name_change ( ) { <nl> + # <nl> + [ [ " $ { product_name } " ! = bazel ] ] & & return num <nl> + <nl> # rewrite the workspace name but leave the rest of workspace alone . <nl> sed - ie ' s , workspace ( . * , workspace ( name = " foo " ) , ' workspace
class main { <nl> thread . setprinthandler ( ( th , msg ) - > system . out . println ( msg ) ) ; <nl> } <nl>  <nl> + / / prompts the user for a chunk of input , and returns it . <nl> private static string prompt ( ) { <nl> stringbuilder input = new stringbuilder ( ) ; <nl> system . out . print ( start_prompt ) ; <nl> try { <nl> string lineseparator = " " ; <nl> + loop : <nl> while ( true ) { <nl> string line = reader . readline ( ) ; <nl> if ( line = = null ) { <nl> return null ; <nl> } <nl> if ( line . isempty ( ) ) { <nl> - return input . tostring ( ) ; <nl> + break loop ; / / a blank line ends the chunk <nl> } <nl> input . append ( lineseparator ) . append ( line ) ; <nl> + <nl> + / / read lines until input produces valid statements , unless the last is if / def / for , <nl> + / / which can be multiline , in which case we must wait for a blank line . <nl> + <nl> + / / integration with the lexer so that it consumes new <nl> + / / lines only until the parse is complete . <nl> + starlarkfile file = starlarkfile . parse ( parserinput . fromstring ( input . tostring ( ) , " < stdin > " ) ) ; <nl> + if ( file . ok ( ) ) { <nl> + list < statement > stmts = file . getstatements ( ) ; <nl> + if ( ! stmts . isempty ( ) ) { <nl> + statement last = stmts . get ( stmts . size ( ) - num ) ; <nl> + switch ( last . kind ( ) ) { <nl> + case if : <nl> + case def : <nl> + case for : <nl> + break ; / / keep going until blank line <nl> + default : <nl> + break loop ; <nl> + } <nl> + } <nl> + } <nl> + <nl> lineseparator = " \n " ; <nl> system . out . print ( continuation_prompt ) ; <nl> } <nl>
public class starlarkactionfactory implements starlarkactionfactoryapi { <nl> for ( runfilessupplier supplier : <nl> sequence . cast ( inputmanifestsunchecked , runfilessupplier . class , " runfiles suppliers " ) ) { <nl> builder . addrunfilessupplier ( supplier ) ; <nl> + / / normally these artifacts will be added directly to the inputs , but we ' re gentle if the <nl> + / / user fails to do so . unfortunately , because ctx . resolve_command currently flattens <nl> + <nl> + / / those inputs include the runfiles . <nl> + builder . addtransitiveinputs ( supplier . getartifacts ( ) ) ; <nl> } <nl> } <nl>  <nl> mmm a / src / test / shell / bazel / remote / remote_execution_test . sh <nl> ppp b / src / test / shell / bazel / remote / remote_execution_test . sh <nl>
function run_test_glob_with_io_error ( ) { <nl> chmod num $ pkg / t / u <nl>  <nl> bazel query " $ option " " / / $ pkg / t : * " > & $ test_log & & fail " expected failure " <nl> - expect_log ' error globbing . * permission denied ' <nl> + # <nl> + # improved , add it here too . <nl> + expect_log ' error globbing ' <nl>  <nl> chmod num $ pkg / t / u <nl> bazel query " $ option " " / / $ pkg / t : * " > & $ test_log | | fail " expected success " <nl> - expect_not_log ' error globbing . * permission denied ' <nl> + expect_not_log ' error globbing ' <nl> expect_log " / / $ pkg / t : u " <nl> expect_log " / / $ pkg / t : u / v " <nl> }
eof <nl> bazel info server_pid > & " $ test_log " | | fail " couldn ' t use server " <nl> } <nl>  <nl> + function test_progress_bar_after_stderr ( ) { <nl> + mkdir - p foo <nl> + cat > foo / build < < ' eof ' <nl> + genrule ( name = ' fail ' , outs = [ ' fail . out ' ] , cmd = ' false ' ) <nl> + sh_test ( name = ' foo ' , data = [ ' : fail ' ] , srcs = [ ' foo . sh ' ] ) <nl> + eof <nl> + touch foo / foo . sh <nl> + chmod + x foo / foo . sh <nl> + # build event file needed so ui considers build to continue after failure . <nl> + ! bazel test - - build_event_json_file = bep . json - - curses = yes - - color = yes \ <nl> + / / foo : foo & > " $ test_log " | | fail " expected failure " <nl> + # expect to see a failure message with an " erase line " control code prepended . <nl> + expect_log $ ' \ e ' " \ [ k " $ ' \ e ' " \ [ 31m " $ ' \ e ' " \ [ 1mfailed : " $ ' \ e ' " \ [ 0m build did not complete successfully " <nl> + # we should not see a build failure message without an " erase line " to start . <nl> + # <nl> + expect_log_n " ^ " $ ' \ e ' " \ [ 31m " $ ' \ e ' " \ [ 1mfailed : " $ ' \ e ' " \ [ 0m build did not complete successfully " num <nl> + } <nl> + <nl> run_suite " integration tests for $ { product_name } ' s ui "
public final class proguardlibrary { <nl> . getrootrelativepath ( ) <nl> . replacename ( spectovalidate . getfilename ( ) + " _valid " ) , <nl> rulecontext . getbinorgenfilesdirectory ( ) ) ; <nl> - rulecontext . registeraction ( <nl> - new spawnaction . builder ( ) <nl> - . addinput ( spectovalidate ) <nl> - . addoutput ( output ) <nl> - . setexecutable ( proguardallowlister ) <nl> - . setprogressmessage ( " validating proguard configuration " ) <nl> - . setmnemonic ( " validateproguard " ) <nl> - . addcommandline ( <nl> - customcommandline . builder ( ) <nl> - . addexecpath ( " - - path " , spectovalidate ) <nl> - . addexecpath ( " - - output " , output ) <nl> - . build ( ) ) <nl> - . build ( rulecontext ) ) ; <nl> + spawnaction . builder builder = <nl> + new spawnaction . builder ( ) . addinput ( spectovalidate ) . addoutput ( output ) ; <nl> + if ( proguardallowlister . getexecutable ( ) . getextension ( ) . equals ( " jar " ) ) { <nl> + builder <nl> + . setjarexecutable ( <nl> + javacommon . gethostjavaexecutable ( rulecontext ) , <nl> + proguardallowlister . getexecutable ( ) , <nl> + javatoolchainprovider . from ( rulecontext ) . getjvmoptions ( ) ) <nl> + . addtransitiveinputs ( javaruntimeinfo . forhost ( rulecontext ) . javabaseinputsmiddleman ( ) ) ; <nl> + } else { <nl> + <nl> + builder . setexecutable ( proguardallowlister ) ; <nl> + } <nl> + builder <nl> + . setprogressmessage ( " validating proguard configuration " ) <nl> + . setmnemonic ( " validateproguard " ) <nl> + . addcommandline ( <nl> + customcommandline . builder ( ) <nl> + . addexecpath ( " - - path " , spectovalidate ) <nl> + . addexecpath ( " - - output " , output ) <nl> + . build ( ) ) ; <nl> + rulecontext . registeraction ( builder . build ( rulecontext ) ) ; <nl> return output ; <nl> } <nl> }
class namedartifactgroup implements buildevent { <nl> throw new illegalstateexception ( " unexpected type in artifact set : " + artifact ) ; <nl> } <nl> } <nl> - for ( nestedset < ? > succ : artifacts . getnonleaves ( ) ) { <nl> + boolean nodirects = res . isempty ( ) ; <nl> + <nl> + immutablelist < ? extends nestedset < ? > > nonleaves = artifacts . getnonleaves ( ) ; <nl> + for ( nestedset < ? > succ : nonleaves ) { <nl> res . addtransitive ( succ ) ; <nl> } <nl> - return res . build ( ) ; <nl> + <nl> + nestedset < ? > result = res . build ( ) ; <nl> + <nl> + / / if we have executed one call to res . addtransitive ( x ) <nl> + / / and none to res . add , then res . build ( ) simply returns x <nl> + / / ( " inlining " ) , which may violate our postcondition on elements . <nl> + / / ( this can happen if ' artifacts ' contains one non - leaf successor <nl> + / / and one or more leaf successors for which visitartifacts is a no - op . ) <nl> + / / <nl> + / / in that case we need to recursively apply the expansion . ugh . <nl> + if ( nodirects & & nonleaves . size ( ) = = num ) { <nl> + return expandset ( ctx , result ) ; <nl> + } <nl> + <nl> + return result ; <nl> } <nl>  <nl> private static final class expandedartifact { <nl> - public final artifact artifact ; <nl> + final artifact artifact ; <nl> / / these fields are used only for fileset links . <nl> - @ nullable public final pathfragment relpath ; <nl> - @ nullable public final path target ; <nl> + @ nullable final pathfragment relpath ; <nl> + @ nullable final path target ; <nl>  <nl> - public expandedartifact ( artifact artifact , pathfragment relpath , path target ) { <nl> + expandedartifact ( artifact artifact , pathfragment relpath , path target ) { <nl> this . artifact = artifact ; <nl> this . relpath = relpath ; <nl> this . target = target ; <nl> } <nl> + <nl> + <nl> + / / explicitly named artifact ( see b / 70354083 ) . both of these artifacts are in its " files to <nl> + / / build " . then bar / will be expanded to bar / baz , and we will have two identical ( but not equal ) <nl> + / / expandedartifact objects , leading to a duplicate emission of bar / baz in bep . <nl> } <nl> } <nl> mmm a / src / test / shell / integration / build_event_stream_test . sh <nl> ppp b / src / test / shell / integration / build_event_stream_test . sh <nl>
eof <nl> expect_log ' option_value : " 666 " ' <nl> } <nl>  <nl> + # <nl> + function disabled_test_empty_tree_in_named_files ( ) { <nl> + mkdir - p foo <nl> + cat > foo / rule . bzl < < ' eof ' <nl> + def _leaf_impl ( ctx ) : <nl> + ctx . actions . write ( output = ctx . outputs . out2 , content = ' hello\n ' ) <nl> + ctx . actions . write ( output = ctx . outputs . out1 , content = ' hello\n ' ) <nl> + return [ defaultinfo ( files = depset ( [ ctx . outputs . out1 , ctx . outputs . out2 ] ) ) ] <nl> + <nl> + def _top_impl ( ctx ) : <nl> + dir = ctx . actions . declare_directory ( ' dir ' ) <nl> + ctx . actions . run_shell ( outputs = [ dir ] , command = ' true ' ) <nl> + return [ defaultinfo ( files = depset ( [ dir ] , <nl> + transitive = [ dep [ defaultinfo ] . files <nl> + for dep in ctx . attr . deps ] ) ) ] <nl> + <nl> + leaf = rule ( <nl> + implementation = _leaf_impl , <nl> + attrs = { " out1 " : attr . output ( ) , " out2 " : attr . output ( ) } , <nl> + ) <nl> + <nl> + top = rule ( <nl> + implementation = _top_impl , <nl> + attrs = { " deps " : attr . label_list ( ) } <nl> + ) <nl> + eof <nl> + cat > foo / build < < ' eof ' <nl> + load ( ' / / foo : rule . bzl ' , ' leaf ' , ' top ' ) <nl> + <nl> + leaf ( name = ' leaf ' , out1 = ' 1 . out ' , out2 = ' 2 . out ' ) <nl> + top ( name = ' top ' , deps = [ ' : leaf ' ] ) <nl> + eof <nl> + <nl> + bazel build - - build_event_text_file = bep . txt / / foo : top > & " $ test_log " \ <nl> + | | fail " expected success " <nl> + expect_not_log classcastexception <nl> + cat bep . txt > " $ test_log " <nl> + expect_log " 1 . out " <nl> + expect_log " 2 . out " <nl> + } <nl> + <nl> run_suite " integration tests for the build event stream "
public class genclassoptionsparser { <nl> case " - - output_jar " : <nl> builder . setoutputjar ( readpath ( it ) ) ; <nl> break ; <nl> + case " - - temp_dir " : <nl> + <nl> + readpath ( it ) ; <nl> + break ; <nl> default : <nl> throw new illegalargumentexception ( <nl> string . format ( " unexpected argument : ' % s ' in % s " , arg , args ) ) ;
public class genclassoptionsparser { <nl> case " - - output_jar " : <nl> builder . setoutputjar ( readpath ( it ) ) ; <nl> break ; <nl> + case " - - temp_dir " : <nl> + <nl> + readpath ( it ) ; <nl> + break ; <nl> default : <nl> throw new illegalargumentexception ( <nl> string . format ( " unexpected argument : ' % s ' in % s " , arg , args ) ) ;
eof <nl> assert_not_contains " outputs : \ [ " output <nl> } <nl>  <nl> + # <nl> function test_aquery_textproto ( ) { <nl> local pkg = " $ { funcname [ 0 ] } " <nl> mkdir - p " $ pkg " | | fail " mkdir - p $ pkg " <nl>
genrule ( <nl> eof <nl> echo " hello aquery " > " $ pkg / in . txt " <nl>  <nl> - bazel aquery - - output = textproto " / / $ pkg : bar " > output num > " $ test_log " \ <nl> + bazel aquery - - noincompatible_proto_output_v2 - - output = textproto " / / $ pkg : bar " > output num > " $ test_log " \ <nl> | | fail " expected success " <nl> cat output > > " $ test_log " <nl> assert_contains " exec_path : \ " $ pkg / dummy . txt \ " " output <nl> - assert_contains " nemonic : \ " genrule \ " " output <nl> + assert_contains " mnemonic : \ " genrule \ " " output <nl> assert_contains " mnemonic : \ " . * - fastbuild \ " " output <nl> assert_contains " echo unused " output <nl>  <nl> - bazel aquery - - output = textproto - - noinclude_commandline " / / $ pkg : bar " > output \ <nl> + bazel aquery - - noincompatible_proto_output_v2 - - output = textproto - - noinclude_commandline " / / $ pkg : bar " > output \ <nl> num > " $ test_log " | | fail " expected success " <nl> assert_not_contains " echo unused " output <nl> } <nl>  <nl> + # <nl> function test_aquery_jsonproto ( ) { <nl> local pkg = " $ { funcname [ 0 ] } " <nl> mkdir - p " $ pkg " | | fail " mkdir - p $ pkg " <nl>
message aborted { <nl> / / build incomplete due to an earlier build failure ( e . g . - - keep_going was <nl> / / set to false causing the build be ended upon failure ) . <nl> incomplete = num ; <nl> + <nl> + / / the build tool ran out of memory and crashed . not yet used . ooms are <nl> + / / currently reported as internal . <nl> + <nl> + out_of_memory = num ; <nl> } <nl> abortreason reason = num ;
abstract class abstractparallelevaluator { <nl> evaluatorcontext <nl> . geterrorinfomanager ( ) <nl> . fromexception ( skykey , reifiedbuilderexception , istransitivelytransient ) ; <nl> + <nl> + if ( istransitivelytransient <nl> + & & ! shouldfailfast <nl> + & & errorinfo . getexception ( ) instanceof ioexception ) { <nl> + / / this is essentially unconditionally logged , and not often . ok to evaluate eagerly . <nl> + string keystring = skykey . tostring ( ) ; <nl> + string errorstring = errorinfo . tostring ( ) ; <nl> + logger . atinfo ( ) . log ( <nl> + " got ioexception for % s ( % s ) " , <nl> + keystring . substring ( 0 , min ( 1000 , keystring . length ( ) ) ) , <nl> + errorstring . substring ( 0 , min ( 1000 , errorstring . length ( ) ) ) ) ; <nl> + } <nl> env . seterror ( state , errorinfo ) ; <nl> set < skykey > rdepstobubbleupto = <nl> env . commit (
public final class blazeruntime implements bugreport . blazeruntimeinterface { <nl>  <nl> @ override <nl> public void cleanupforcrash ( detailedexitcode exitcode ) { <nl> + <nl> + logger . atinfo ( ) . log ( " cleaning up in crash : % s " , exitcode ) ; <nl> if ( declareexitcode ( exitcode ) ) { <nl> / / only try to publish events if we won the exit code race . otherwise someone else is already <nl> / / exiting for us . <nl>
public final class blazeruntime implements bugreport . blazeruntimeinterface { <nl>  <nl> / * * invokes { @ link blazemodule # blazeshutdownoncrash ( ) } on all registered modules . * / <nl> private void shutdownmodulesoncrash ( ) { <nl> + <nl> + logger . atinfo ( ) . log ( " shutting down modules on crash : % s " , blazemodules ) ; <nl> try { <nl> for ( blazemodule module : blazemodules ) { <nl> + logger . atinfo ( ) . log ( " shutting down % s on crash " , module ) ; <nl> module . blazeshutdownoncrash ( ) ; <nl> } <nl> } finally {
filegroup ( <nl> visibility = [ " / / src : __subpackages__ " ] , <nl> ) <nl>  <nl> + # <nl> + <nl> java_test ( <nl> name = " jobsconvertertest " , <nl> srcs = [
register_local_rc_exe_toolchains ( ) <nl>  <nl> register_toolchains ( " / / src / main / res : empty_rc_toolchain " ) <nl>  <nl> + # patch upb for grpc due to https : / / github . com / bazelbuild / bazel / issues / 12056 <nl> + # <nl> + # affected by this issue . <nl> + http_archive ( <nl> + name = " upb " , <nl> + sha256 = " <commit_id> " , <nl> + patches = [ " / / third_party / grpc : upb_gcc10_fix . patch " ] , <nl> + patch_args = [ " - p1 " ] , <nl> + strip_prefix = " upb - <commit_id> " , <nl> + urls = [ <nl> + " https : / / mirror . bazel . build / github . com / protocolbuffers / upb / archive / <commit_id> . tar . gz " , <nl> + " https : / / github . com / protocolbuffers / upb / archive / <commit_id> . tar . gz " , <nl> + ] , <nl> + ) <nl> + <nl> http_archive ( <nl> name = " com_github_grpc_grpc " , <nl> urls = [
message query { <nl> query_stdout_flush_failure = num [ ( metadata ) = { exit_code : num } ] ; <nl> analysis_query_prereq_unmet = num [ ( metadata ) = { exit_code : num } ] ; <nl> query_results_flush_failure = num [ ( metadata ) = { exit_code : num } ] ; <nl> - reserved num ; <nl> + <nl> + unclosed_quotation_expression_error = num [ ( metadata ) = { exit_code : num } ] ; <nl> variable_name_invalid = num [ ( metadata ) = { exit_code : num } ] ; <nl> variable_undefined = num [ ( metadata ) = { exit_code : num } ] ; <nl> buildfiles_and_loadfiles_cannot_use_output_location_error = num <nl>
message query { <nl> arguments_missing = num [ ( metadata ) = { exit_code : num } ] ; <nl> rbuildfiles_function_requires_skyquery = num [ ( metadata ) = { exit_code : num } ] ; <nl> full_targets_not_supported = num [ ( metadata ) = { exit_code : num } ] ; <nl> - reserved num to num ; <nl> + <nl> + unexpected_token_error = num [ ( metadata ) = { exit_code : num } ] ; <nl> + integer_literal_missing = num [ ( metadata ) = { exit_code : num } ] ; <nl> + invalid_starting_character_error = num [ ( metadata ) = { exit_code : num } ] ; <nl> + premature_end_of_input_error = num [ ( metadata ) = { exit_code : num } ] ; <nl> / / indicates the user specified invalid query syntax . <nl> syntax_error = num [ ( metadata ) = { exit_code : num } ] ; <nl> output_formatter_io_exception = num [ ( metadata ) = { exit_code : num } ] ;
public final class rulecontext extends targetcontext <nl> * specified attribute . <nl> * / <nl> public list < ? extends transitiveinfocollection > getprerequisites ( string attributename ) { <nl> + if ( ! attributes ( ) . has ( attributename ) ) { <nl> + return immutablelist . of ( ) ; <nl> + } <nl> + <nl> + list < configuredtargetanddata > prerequisiteconfiguredtargets ; <nl> + if ( getrule ( ) . getruleclass ( ) . equals ( " android_binary " ) <nl> + & & attributename . equals ( " deps " ) <nl> + & & attributes ( ) . getattributedefinition ( attributename ) . gettransitionfactory ( ) . issplit ( ) ) { <nl> + <nl> + / / callers should be identified , cleaned up , and this check removed . <nl> + map < optional < string > , list < configuredtargetanddata > > map = <nl> + getsplitprerequisiteconfiguredtargetandtargets ( attributename ) ; <nl> + prerequisiteconfiguredtargets = <nl> + map . isempty ( ) ? immutablelist . of ( ) : map . entryset ( ) . iterator ( ) . next ( ) . getvalue ( ) ; <nl> + } else { <nl> + prerequisiteconfiguredtargets = getprerequisiteconfiguredtargets ( attributename ) ; <nl> + } <nl> + <nl> return lists . transform ( <nl> - getprerequisiteconfiguredtargets ( attributename ) , <nl> - configuredtargetanddata : : getconfiguredtarget ) ; <nl> + prerequisiteconfiguredtargets , configuredtargetanddata : : getconfiguredtarget ) ; <nl> } <nl>  <nl> / * * <nl> mmm a / src / test / java / com / google / devtools / build / lib / rules / android / androidstarlarktest . java <nl> ppp b / src / test / java / com / google / devtools / build / lib / rules / android / androidstarlarktest . java <nl>
public class androidstarlarktest extends buildviewtestcase { <nl>  <nl> / / the regular ctx . attr . deps should be a single list with all the branches of the split merged <nl> / / together ( i . e . for aspects ) . <nl> + <nl> + / * <nl> @ suppresswarnings ( " unchecked " ) <nl> list < configuredtarget > attrdeps = ( list < configuredtarget > ) myinfo . getvalue ( " attr_deps " ) ; <nl> assertthat ( attrdeps ) . hassize ( 4 ) ; <nl>
public class androidstarlarktest extends buildviewtestcase { <nl> } <nl> assertthat ( attrdepsmap ) . valuesforkey ( " k8 " ) . hassize ( 2 ) ; <nl> assertthat ( attrdepsmap ) . valuesforkey ( " armeabi - v7a " ) . hassize ( 2 ) ; <nl> + * / <nl>  <nl> / / check that even though my_rule . dep is defined as a single label , ctx . attr . dep is still a list <nl> / / with multiple configuredtarget objects because of the two different cpus . <nl> + <nl> + / * <nl> @ suppresswarnings ( " unchecked " ) <nl> list < configuredtarget > attrdep = ( list < configuredtarget > ) myinfo . getvalue ( " attr_dep " ) ; <nl> assertthat ( attrdep ) . hassize ( 2 ) ; <nl>
public abstract class bugreport { <nl> if ( runtime ! = null ) { <nl> runtime . cleanupforcrash ( detailedexitcode ) ; <nl> } <nl> + <nl> + logger . atinfo ( ) . log ( " finished runtime cleanup " ) ; <nl> customexitcodepublisher . maybewriteexitstatusfile ( numericexitcode ) ; <nl> + logger . atinfo ( ) . log ( " wrote exit status file " ) ; <nl> customfailuredetailpublisher . maybewritefailuredetailfile ( <nl> detailedexitcode . getfailuredetail ( ) ) ; <nl> + logger . atinfo ( ) . log ( " wrote failure detail file " ) ; <nl> } finally { <nl> + logger . atinfo ( ) . log ( " entered inner finally block " ) ; <nl> / / avoid shutdown deadlock issues : if an application shutdown hook crashes , it will <nl> / / trigger our blaze crash handler ( this method ) . calling system # exit ( ) here , would <nl> / / therefore induce a deadlock . this call would block on the shutdown sequence completing , <nl> / / but the shutdown sequence would in turn be blocked on this thread finishing . instead , <nl> / / exit fast via halt ( ) . <nl> runtime . getruntime ( ) . halt ( numericexitcode ) ; <nl> + logger . atsevere ( ) . log ( " failed to halt ( inner block ) ! " ) ; <nl> } <nl> } <nl> } catch ( throwable t ) { <nl> + logger . atsevere ( ) . withcause ( t ) . log ( " threw while crashing " ) ; <nl> system . err . println ( <nl> " error : a crash occurred while " <nl> + getproductname ( ) <nl>
public final class resolver extends nodevisitor { <nl>  <nl> @ override <nl> public void visit ( comprehension node ) { <nl> - immutablelist < comprehension . clause > clauses = node . getclauses ( ) ; <nl> - <nl> - / / following python3 , the first for clause is resolved <nl> - / / outside the comprehension block . all the other loops <nl> - / / are resolved in the scope of their own bindings , <nl> - / / permitting forward references . <nl> - comprehension . for for0 = ( comprehension . for ) clauses . get ( 0 ) ; <nl> - visit ( for0 . getiterable ( ) ) ; <nl> - <nl> openblock ( scope . local ) ; <nl> - for ( comprehension . clause clause : clauses ) { <nl> + for ( comprehension . clause clause : node . getclauses ( ) ) { <nl> if ( clause instanceof comprehension . for ) { <nl> comprehension . for forclause = ( comprehension . for ) clause ; <nl> createbindings ( forclause . getvars ( ) ) ; <nl> } <nl> } <nl> - for ( int i = num ; i < clauses . size ( ) ; i + + ) { <nl> - comprehension . clause clause = clauses . get ( i ) ; <nl> + <nl> + for ( comprehension . clause clause : node . getclauses ( ) ) { <nl> if ( clause instanceof comprehension . for ) { <nl> comprehension . for forclause = ( comprehension . for ) clause ; <nl> - if ( i > num ) { <nl> - visit ( forclause . getiterable ( ) ) ; <nl> - } <nl> + visit ( forclause . getiterable ( ) ) ; <nl> assign ( forclause . getvars ( ) ) ; <nl> } else { <nl> comprehension . if ifclause = ( comprehension . if ) clause ; <nl> mmm a / src / test / java / com / google / devtools / build / lib / syntax / resolvertest . java <nl> ppp b / src / test / java / com / google / devtools / build / lib / syntax / resolvertest . java <nl>
public class coreoptions extends fragmentoptions implements cloneable { <nl> help = " whether to enable the use of aggregatingmiddleman in rules . " ) <nl> public boolean enableaggregatingmiddleman ; <nl>  <nl> + <nl> + @ option ( <nl> + name = " experimental_enable_shorthand_aliases " , <nl> + defaultvalue = " false " , <nl> + documentationcategory = optiondocumentationcategory . input_strictness , <nl> + effecttags = { optioneffecttag . changes_inputs } , <nl> + metadatatags = { optionmetadatatag . experimental } , <nl> + help = " when enabled , alternate names can be assigned to starlark - defined flags . " ) <nl> + public boolean enableshorthandaliases ; <nl> + <nl> / * * ways configured targets may provide the { @ link fragment } s they require . * / <nl> public enum includeconfigfragmentsenum { <nl> / * *
public class configuredtargetkey implements actionlookupkey { <nl>  <nl> @ override <nl> public final string tostring ( ) { <nl> + <nl> + moreobjects . tostringhelper helper = <nl> + moreobjects . tostringhelper ( this ) . add ( " label " , label ) . add ( " config " , configurationkey ) ; <nl> if ( gettoolchaincontextkey ( ) ! = null ) { <nl> - return string . format ( " % s % s % s " , label , configurationkey , gettoolchaincontextkey ( ) ) ; <nl> + helper . add ( " toolchaincontextkey " , gettoolchaincontextkey ( ) ) ; <nl> } <nl> - return string . format ( " % s % s " , label , configurationkey ) ; <nl> + return helper . tostring ( ) ; <nl> } <nl>  <nl> @ autocodec . visibleforserialization <nl> mmm a / src / main / java / com / google / devtools / build / skyframe / skyfunctionenvironment . java <nl> ppp b / src / main / java / com / google / devtools / build / skyframe / skyfunctionenvironment . java <nl>
class skyfunctionenvironment extends abstractskyfunctionenvironment { <nl> maybeupdatemaxchildversion ( entry . getvalue ( ) ) ; <nl> } <nl> } <nl> - return depvaluesbuilder . build ( ) ; <nl> + try { <nl> + return depvaluesbuilder . build ( ) ; <nl> + } catch ( illegalargumentexception e ) { <nl> + <nl> + / / out all the data we have for better debugging . remove this as soon as bug is fixed . <nl> + list < skykey > keys = immutablelist . copyof ( batchmap . keyset ( ) ) ; <nl> + list < pair < list < object > , list < object > > > duplicateornearduplicatekeys = new arraylist < > ( ) ; <nl> + for ( int i = num ; i < keys . size ( ) ; i + + ) { <nl> + for ( int j = num ; j < keys . size ( ) ; j + + ) { <nl> + if ( i = = j ) { <nl> + continue ; <nl> + } <nl> + / / if equals ( ) is somehow non - symmetric , we ' ll catch the other direction later in loop . <nl> + skykey ikey = keys . get ( i ) ; <nl> + skykey jkey = keys . get ( j ) ; <nl> + if ( ikey . equals ( jkey ) | | ( ikey . hashcode ( ) = = jkey . hashcode ( ) ) ) { <nl> + duplicateornearduplicatekeys . add ( <nl> + pair . of ( <nl> + immutablelist . of ( ikey , i , ikey . hashcode ( ) , system . identityhashcode ( ikey ) ) , <nl> + immutablelist . of ( jkey , j , jkey . hashcode ( ) , system . identityhashcode ( jkey ) ) ) ) ; <nl> + } <nl> + } <nl> + } <nl> + throw new illegalargumentexception ( <nl> + string . format ( <nl> + " impossible error with duplicate keys for % s ( % s % s % s ) " , <nl> + skykey , <nl> + duplicateornearduplicatekeys , <nl> + keys . size ( ) , <nl> + keys . stream ( ) <nl> + . map ( <nl> + k - > immutablelist . of ( k , k . hashcode ( ) , system . identityhashcode ( k ) ) . tostring ( ) ) <nl> + . collect ( joining ( " \n " ) ) ) , <nl> + e ) ; <nl> + } <nl> } <nl>  <nl> private void checkactive ( ) {
public class targetpatternfunction implements skyfunction { <nl> @ override <nl> public void process ( iterable < target > partialresult ) { <nl> for ( target target : partialresult ) { <nl> + <nl> + / / downside to doing this is that implicit outputs won ' t be listed when doing <nl> + / / somepackage : * for the handful of cases still on the allowlist . this is only a <nl> + / / google internal problem and the scale of it is acceptable in the short term <nl> + / / while cleaning up the allowlist . <nl> + if ( target instanceof outputfile <nl> + & & ( ( outputfile ) target ) <nl> + . getgeneratingrule ( ) <nl> + . getruleclass ( ) <nl> + . equals ( " cc_library " ) ) { <nl> + continue ; <nl> + } <nl> resolvedtargetsbuilder . add ( target ) ; <nl> } <nl> }
import java . io . ioexception ; <nl> import java . io . inputstream ; <nl> import java . util . set ; <nl>  <nl> + <nl> / * * a proxy that talks to the multiplexer * / <nl> final class workerproxy extends worker { <nl> private static final googlelogger logger = googlelogger . forenclosingclass ( ) ; <nl> - private workermultiplexer workermultiplexer ; <nl> + private final workermultiplexer workermultiplexer ; <nl> private string recordingstreammessage ; <nl>  <nl> workerproxy ( <nl>
public final class resolver extends nodevisitor { <nl> assign ( elem ) ; <nl> } <nl> } else { <nl> + <nl> errorf ( lhs , " cannot assign to ' % s ' " , lhs ) ; <nl> } <nl> } <nl> mmm a / src / test / java / com / google / devtools / build / lib / syntax / evaluationtest . java <nl> ppp b / src / test / java / com / google / devtools / build / lib / syntax / evaluationtest . java <nl>
class httpconnector { <nl> try { <nl> connection = ( httpurlconnection ) <nl> url . openconnection ( proxyhelper . createproxyifneeded ( url ) ) ; <nl> + <nl> + connection . addrequestproperty ( " accept " , " text / html , image / gif , image / jpeg , * / * " ) ; <nl> boolean isalreadycompressed = <nl> compressed_extensions . contains ( httputils . getextension ( url . getpath ( ) ) ) <nl> | | compressed_extensions . contains ( httputils . getextension ( originalurl . getpath ( ) ) ) ;
public class cppcompileaction extends abstractaction implements includescannable <nl> return executioninfo ; <nl> } <nl>  <nl> + private boolean validateinclude ( <nl> + actionexecutioncontext actionexecutioncontext , <nl> + set < artifact > allowedincludes , <nl> + set < pathfragment > loosehdrsdirs , <nl> + iterable < pathfragment > ignoredirs , <nl> + artifact include ) { <nl> + / / only declared modules are added to an action and so they are always valid . <nl> + return include . isfiletype ( cppfiletypes . cpp_module ) <nl> + | | <nl> + <nl> + include . isfiletype ( cppfiletypes . objc_module_map ) <nl> + | | <nl> + / / it ' s a declared include / <nl> + allowedincludes . contains ( include ) <nl> + | | <nl> + / / ignore headers from built - in include directories . <nl> + filesystemutils . startswithany ( include . getexecpath ( ) , ignoredirs ) <nl> + | | isdeclaredin ( cppconfiguration , actionexecutioncontext , include , loosehdrsdirs ) ; <nl> + } <nl> + <nl> / * * <nl> * enforce that the includes actually visited during the compile were properly declared in the <nl> * rules . <nl>
final class starlarkdocumentationcollector { <nl> * a map that maps starlark module name to the module documentation . <nl> * / <nl> public static map < string , starlarkbuiltindoc > collectmodules ( iterable < class < ? > > classes ) { <nl> + / / force class loading of com . google . devtools . build . lib . syntax . starlark before we do any of our <nl> + / / own processing . otherwise , we ' re in trouble since com . google . devtools . build . lib . syntax . dict <nl> + / / happens to be the first class on our classpath that we proccess via # collectmodulemethods , <nl> + / / but that entails a logical cycle in <nl> + / / com . google . devtools . build . lib . syntax . callutils # getcachevalue . <nl> + <nl> + @ suppresswarnings ( " unused " ) <nl> + object forceclassloading = starlark . universe ; <nl> + <nl> map < string , starlarkbuiltindoc > modules = new treemap < > ( ) ; <nl> / / the top level module first . <nl> / / ( this is a special case of { @ link starlarkbuiltindoc } as it has no object name ) .
public final class dict < k , v > <nl> } <nl>  <nl> / * * returns a new dict with the specified mutability containing the entries of { @ code m } . * / <nl> + @ suppresswarnings ( " unchecked " ) <nl> public static < k , v > dict < k , v > copyof ( @ nullable mutability mu , map < ? extends k , ? extends v > m ) { <nl> - return new dict < k , v > ( mu ) . putallunsafe ( m ) ; <nl> + <nl> + dict < k , v > dict = new dict < > ( mu ) ; <nl> + for ( map . entry < ? , ? > e : m . entryset ( ) ) { <nl> + dict . contents . put ( ( k ) e . getkey ( ) , ( v ) starlark . fromjava ( e . getvalue ( ) , mu ) ) ; <nl> + } <nl> + return dict ; <nl> } <nl>  <nl> / * * puts the given entry into the dict , without calling { @ link # checkmutable } . * / <nl>
public class grpcserverimpl extends commandservergrpc . commandserverimplbase impl <nl> / / and if that fails , try again with ipv4 . <nl> inetsocketaddress address = new inetsocketaddress ( " [ : : 1 ] " , port ) ; <nl> try { <nl> + <nl> + if ( netutil . isipv4stackpreferred ( ) ) { <nl> + throw new ioexception ( " ipv4 is preferred on the system . " ) ; <nl> + } <nl> server = <nl> nettyserverbuilder . foraddress ( address ) . addservice ( this ) . directexecutor ( ) . build ( ) . start ( ) ; <nl> } catch ( ioexception ipv6exception ) {
public final class actions { <nl> . addescape ( ' : ' , " _c " ) <nl> . build ( ) ; <nl>  <nl> + / * * flag used to limit the number of warnings about shared actions to one per build . * / <nl> + private static final atomicboolean issuedwarningforsharedactionswithtreeartifactinput = <nl> + new atomicboolean ( ) ; <nl> + <nl> + <nl> + public static void clearsharedactionswarningflag ( ) { <nl> + issuedwarningforsharedactionswithtreeartifactinput . set ( false ) ; <nl> + } <nl> + <nl> / * * <nl> * checks if the two actions are equivalent . this method exists to support sharing actions between <nl> * configured targets for cases where there is no canonical target that could own the action . in <nl>
import com . google . devtools . common . options . optionmetadatatag ; <nl> import com . google . devtools . common . options . optionsbase ; <nl>  <nl> / * * configuration options for starlark debugging . * / <nl> + <nl> public final class starlarkdebuggeroptions extends optionsbase { <nl> @ option ( <nl> - name = " experimental_starlark_debug " , <nl> + name = " experimental_skylark_debug " , <nl> defaultvalue = " false " , <nl> documentationcategory = optiondocumentationcategory . undocumented , <nl> effecttags = { optioneffecttag . execution } , <nl>
public class executiontool { <nl> env . geteventbus ( ) . post ( new execrootpreparedevent ( packagerootmap ) ) ; <nl> } <nl>  <nl> + private static void logdeletetreefailure ( <nl> + path directory , string description , ioexception deletetreefailure ) { <nl> + logger . atwarning ( ) . withcause ( deletetreefailure ) . log ( <nl> + " failed to delete % s ' % s ' " , description , directory ) ; <nl> + if ( directory . exists ( ) ) { <nl> + try { <nl> + collection < path > entries = directory . getdirectoryentries ( ) ; <nl> + stringbuilder directorydetails = <nl> + new stringbuilder ( " ' " ) <nl> + . append ( directory ) <nl> + . append ( " ' contains " ) <nl> + . append ( entries . size ( ) ) <nl> + . append ( " entries : " ) ; <nl> + for ( path entry : entries ) { <nl> + directorydetails . append ( " ' " ) . append ( entry . getbasename ( ) ) . append ( " ' " ) ; <nl> + } <nl> + logger . atwarning ( ) . log ( directorydetails . tostring ( ) ) ; <nl> + } catch ( ioexception e ) { <nl> + logger . atwarning ( ) . withcause ( e ) . log ( " ' % s ' exists but could not be read " , directory ) ; <nl> + } <nl> + } else { <nl> + logger . atwarning ( ) . log ( " ' % s ' does not exist " , directory ) ; <nl> + } <nl> + } <nl> + <nl> private void createactionlogdirectory ( ) throws abruptexitexception { <nl> path directory = env . getactiontempsdirectory ( ) ; <nl> if ( directory . exists ( ) ) { <nl> try { <nl> directory . deletetree ( ) ; <nl> } catch ( ioexception e ) { <nl> + <nl> + logdeletetreefailure ( directory , " action output directory " , e ) ; <nl> throw createexitexception ( <nl> " couldn ' t delete action output directory " , <nl> code . action_output_directory_deletion_failure ,
public class compilationsupport { <nl> activatedcrosstoolselectables . addall ( cccommon . getcoveragefeatures ( cppconfiguration ) ) ; <nl>  <nl> try { <nl> - return cctoolchain <nl> - . getfeatures ( ) <nl> - . getfeatureconfiguration ( activatedcrosstoolselectables . build ( ) ) ; <nl> + immutableset < string > activatedcrosstoolselectablesset ; <nl> + if ( ! cctoolchain . supportsheaderparsing ( ) ) { <nl> + <nl> + activatedcrosstoolselectablesset = <nl> + activatedcrosstoolselectables . build ( ) . stream ( ) <nl> + . filter ( feature - > ! feature . equals ( cppruleclasses . parse_headers ) ) <nl> + . collect ( toimmutableset ( ) ) ; <nl> + } else { <nl> + activatedcrosstoolselectablesset = activatedcrosstoolselectables . build ( ) ; <nl> + } <nl> + return cctoolchain . getfeatures ( ) . getfeatureconfiguration ( activatedcrosstoolselectablesset ) ; <nl> } catch ( collidingprovidesexception e ) { <nl> rulecontext . ruleerror ( e . getmessage ( ) ) ; <nl> return featureconfiguration . empty ;
package com . google . devtools . build . lib . actions ; <nl>  <nl> import com . google . common . collect . immutablelist ; <nl>  <nl> - / * * a context that allows execution of { @ link spawn } instances . * / <nl> - @ actioncontextmarker ( name = " spawn " ) <nl> - public interface spawnstrategy extends actioncontext { <nl> + / * * <nl> + * an implementation of how to { @ linkplain # exec execute } a { @ link spawn } instance . <nl> + * <nl> + * < p > strategies are used during the execution phase based on how they were { @ linkplain <nl> + * com . google . devtools . build . lib . runtime . blazemodule # registerspawnstrategies registered by a module } <nl> + * and whether they { @ linkplain # canexec match a given spawn based on their abilities } . <nl> + * / <nl> + <nl> + / / a shadow hierarchy graph that looks like that of the corresponding strategies . <nl> + public interface spawnstrategy { <nl>  <nl> / * * <nl> * executes the given spawn and returns metadata about the execution . implementations must <nl>
eof <nl> expect_log " artifactnestedsetfunction options changed . resetting evaluator . . . " <nl> } <nl>  <nl> - function test_experimental_nested_set_as_skykey_dirty_file ( ) { <nl> + function test_eval_as_one_group_dirty_file ( ) { <nl> + export dont_sanity_check_serialization = 1 <nl> + cat > foo / build < < eof <nl> + load ( " : foo . bzl " , " foo_library " , " foo_binary " ) <nl> + py_binary ( <nl> + name = " foocc " , <nl> + srcs = [ " foocc . py " ] , <nl> + ) <nl> + <nl> + foo_library ( <nl> + name = " a " , <nl> + srcs = [ " 1 . a " ] , <nl> + ) <nl> + <nl> + foo_library ( <nl> + name = " b " , <nl> + srcs = [ " 1 . b " ] , <nl> + deps = [ " : a " ] , <nl> + ) <nl> + foo_binary ( <nl> + name = " c " , <nl> + srcs = [ " c . foo " ] , <nl> + deps = [ " : b " ] , <nl> + ) <nl> + eof <nl> + touch foo / 1 . a foo / 1 . b foo / c . foo <nl> + <nl> + bazel build - - experimental_nested_set_as_skykey_threshold = 1 \ <nl> + - - experimental_nsos_eval_keys_as_one_group \ <nl> + / / foo : c & > " $ test_log " | | fail " build failed " <nl> + # deliberately breaking the file . <nl> + echo omgomgomg > > foo / foocc . py <nl> + bazel build - - experimental_nested_set_as_skykey_threshold = 1 \ <nl> + - - experimental_nsos_eval_keys_as_one_group \ <nl> + / / foo : c & > " $ test_log " & & fail " expected failure " <nl> + <nl> + true # reset the last exit code so the test won ' t be considered failed <nl> + } <nl> + <nl> + # regression test for b / 154716911 . <nl> + function test_eval_as_one_group_missing_file ( ) { <nl> + export dont_sanity_check_serialization = 1 <nl> + cat > foo / build < < eof <nl> + genrule ( <nl> + name = " foo " , <nl> + outs = [ " file . o " ] , <nl> + cmd = ( " touch $ @ " ) , <nl> + tools = [ " : bar " ] , <nl> + ) <nl> + <nl> + cc_binary ( <nl> + name = " bar " , <nl> + srcs = [ <nl> + " bar . cc " , <nl> + " missing . a " , <nl> + ] , <nl> + ) <nl> + eof <nl> + touch foo / bar . cc <nl> + <nl> + bazel build - - experimental_nested_set_as_skykey_threshold = 1 \ <nl> + - - experimental_nsos_eval_keys_as_one_group \ <nl> + / / foo : foo & > " $ test_log " & & fail " expected failure " <nl> + <nl> + exit_code = $ ? <nl> + [ [ $ exit_code - eq num ] ] | | fail " unexpected exit code : $ exit_code " <nl> + <nl> + true # reset the last exit code so the test won ' t be considered failed <nl> + } <nl> + <nl> + # regression test for b / 155850727 . <nl> + function test_eval_as_one_group_incremental_err_reporting ( ) { <nl> + export dont_sanity_check_serialization = 1 <nl> + cat > foo / build < < eof <nl> + genrule ( <nl> + name = " foo " , <nl> + outs = [ " file . o " ] , <nl> + cmd = ( " touch $ @ " ) , <nl> + tools = [ " : bar " ] , <nl> + ) <nl> + <nl> + java_library ( <nl> + name = " bar " , <nl> + srcs = [ <nl> + " bar . java " , <nl> + ] , <nl> + ) <nl> + eof <nl> + echo " randomstuffs " > foo / bar . java <nl> + <nl> + bazel build - - experimental_nested_set_as_skykey_threshold = 1 \ <nl> + - - experimental_nsos_eval_keys_as_one_group \ <nl> + / / foo : foo & > " $ test_log " & & fail " expected failure " <nl> + <nl> + # verify that the incremental run prints the expected failure message . <nl> + bazel build - - experimental_nested_set_as_skykey_threshold = 1 \ <nl> + - - experimental_nsos_eval_keys_as_one_group \ <nl> + / / foo : foo & > " $ test_log " & & fail " expected failure " <nl> + <nl> + expect_log " error " <nl> + expect_log " randomstuffs " <nl> + } <nl> + <nl> + # <nl> + # - - experimental_nsos_eval_keys_as_one_group is stable . <nl> + function test_dirty_file ( ) { <nl> export dont_sanity_check_serialization = 1 <nl> cat > foo / build < < eof <nl> load ( " : foo . bzl " , " foo_library " , " foo_binary " ) <nl>
public final class starlarkthread { <nl> debug . threadhook . onpushfirst ( this ) ; <nl> } <nl>  <nl> + profilertask taskkind ; <nl> if ( fn instanceof starlarkfunction ) { <nl> starlarkfunction sfn = ( starlarkfunction ) fn ; <nl> fr . locals = maps . newlinkedhashmapwithexpectedsize ( sfn . getparameternames ( ) . size ( ) ) ; <nl> + taskkind = profilertask . starlark_user_fn ; <nl> } else { <nl> / / built - in function <nl> fr . locals = immutablemap . of ( ) ; <nl> + taskkind = profilertask . starlark_builtin_fn ; <nl> } <nl>  <nl> fr . loc = fn . getlocation ( ) ; <nl>  <nl> + / / start wall - time profile span <nl> + <nl> + if ( profiler . instance ( ) . isactive ( ) ) { <nl> + fr . profilespan = profiler . instance ( ) . profile ( taskkind , fn . getname ( ) ) ; <nl> + } <nl> + <nl> / / poll for newly installed cpu profiler . <nl> if ( profiler = = null ) { <nl> this . profiler = cpuprofiler . get ( ) ; <nl>
public interface androidresourcesinfoapi < <nl> type = depset . class , <nl> generic1 = fileapi . class ) , <nl> @ param ( <nl> + <nl> name = " transitive_static_lib " , <nl> doc = " a depset of artifacts of static lib files in the transitive closure . " , <nl> positional = true , <nl> named = true , <nl> type = depset . class , <nl> + defaultvalue = " unbound " , <nl> generic1 = fileapi . class ) , <nl> @ param ( <nl> name = " transitive_r_txt " , <nl>
public class optionpriority implements comparable < optionpriority > { <nl> public static optionpriority getchildpriority ( optionpriority parentpriority ) <nl> throws optionsparsingexception { <nl> if ( parentpriority . alreadyexpanded ) { <nl> - throw new optionsparsingexception ( " tried to expand option too many times " ) ; <nl> + <nl> + logger . atwarning ( ) . log ( " tried to expand option too many times . " ) ; <nl> } <nl> / / prevent this option from being re - expanded . <nl> parentpriority . alreadyexpanded = true ;
fi <nl> # latter depends on the bazel binary used to run the test . <nl> # sort the targets for a deterministic diffing experience . <nl> current_deps = " $ { test_tmpdir } / current_deps " <nl> - grep - v " ^ @ bazel_tools / / \ | ^ @ remote_java_tools " \ <nl> + grep - v " ^ @ bazel_tools / / \ | ^ @ remote_java_tools \ | ^ @ debian_cc_deps " \ <nl> " $ { test_srcdir } / io_bazel / src / test / shell / bazel / embedded_tools_deps " \ <nl> | sort > " $ { current_deps } " <nl>  <nl> + # <nl> + # https : / / github . com / bazelbuild / bazel / pull / 11300 <nl> + # remove the following line after the pr is merged . <nl> + sed - i . bak s / \ : zlib $ / \ : zlib_checked_in / " $ { current_deps } " <nl> + <nl> # load the current allowed dependencies of / / src : embedded_tools_srcs <nl> allowed_deps = $ { testdata_path } / embedded_tools_srcs_deps <nl>  <nl> mmm a / src / test / shell / bazel / testdata / embedded_tools_srcs_deps <nl> ppp b / src / test / shell / bazel / testdata / embedded_tools_srcs_deps <nl>
<nl> package ( default_visibility = [ " / / visibility : public " ] ) <nl>  <nl> # libnetty - java <nl> + # <nl> + # all netty jars here . replace them with netty - all . jar once it ' s fixed . <nl> java_import ( <nl> name = " netty " , <nl> - jars = [ " netty - all . jar " ] , <nl> + jars = [ <nl> + " netty - buffer . jar " , <nl> + " netty - codec - dns . jar " , <nl> + " netty - codec - haproxy . jar " , <nl> + " netty - codec - http2 . jar " , <nl> + " netty - codec - http . jar " , <nl> + " netty - codec . jar " , <nl> + " netty - codec - memcache . jar " , <nl> + " netty - codec - mqtt . jar " , <nl> + " netty - codec - redis . jar " , <nl> + " netty - codec - smtp . jar " , <nl> + " netty - codec - socks . jar " , <nl> + " netty - codec - stomp . jar " , <nl> + " netty - common . jar " , <nl> + " netty - handler . jar " , <nl> + " netty - handler - proxy . jar " , <nl> + " netty - resolver - dns . jar " , <nl> + " netty - resolver - dns - native - macos . jar " , <nl> + " netty - resolver . jar " , <nl> + " netty - transport . jar " , <nl> + " netty - transport - native - epoll . jar " , <nl> + " netty - transport - native - kqueue . jar " , <nl> + " netty - transport - native - unix - common . jar " , <nl> + " netty - transport - sctp . jar " , <nl> + ] , <nl> ) <nl>  <nl> # libgoogle - gson - java
genrule ( <nl> " zip - qd $ @ " + unnecessary_dynamic_libraries + " ; fi " , <nl> ) <nl>  <nl> - java_import ( <nl> + distrib_java_import ( <nl> name = " netty " , <nl> jars = [ " netty / netty - all - 4 . 1 . 34 . final . jar " ] , <nl> + # <nl> + # enable_distributions = [ " debian " ] , <nl> ) <nl>  <nl> java_import ( <nl>
public class skydocmain { <nl>  <nl> envbuilder . putall ( starlark . universe ) ; <nl>  <nl> + / / add stub declarations for blaze - only things as a quick fix <nl> + <nl> + envbuilder . put ( " js_common " , num ) ; <nl> + envbuilder . put ( " proguardspecprovider " , num ) ; <nl> + envbuilder . put ( " databindingv2info " , num ) ; <nl> + <nl> / / declare a fake implementation of select that just returns the first <nl> / / value in the dict . ( this program is forbidden from depending on the real <nl> / / implementation of ' select ' in lib . packages , and so the hacks multiply . )
public class filesystemvaluecheckertest { <nl> } <nl>  <nl> @ test <nl> + <nl> + @ ignore <nl> public void testdirtyactionsbatchstatwithdigest ( ) throws exception { <nl> checkdirtyactions ( <nl> new batchstat ( ) { <nl>
public class filesystemvaluecheckertest { <nl> } <nl>  <nl> @ test <nl> + <nl> + @ ignore <nl> public void testdirtyactionsbatchstatfallback ( ) throws exception { <nl> checkdirtyactions ( <nl> new batchstat ( ) {
genrule ( <nl> cmd = ( <nl> " cat $ ( location / / site : command - line - reference - prefix . html ) > $ @ & & " + <nl> " tmp = ` mktemp - d / tmp / tmp . xxxxxxxxxx ` & & " + <nl> + # <nl> + " export jarbin = $ ( javabase ) / bin / jar & & " + <nl> " $ ( location / / src / main / java / com / google / devtools / build / lib / bazel : bazelserver ) " + <nl> " - - jvm_flag = - dio . bazel . enablejni = 0 - - batch " + <nl> " - - install_base = $ $ { tmp } - - output_base = $ $ { tmp } / output / - - output_user_root = $ $ { tmp } " + <nl>
public abstract class starlarktransition implements configurationtransition { <nl> / / clean up aliased values . <nl> buildoptions options = unalias ( tooptions . get ( splitkey ) , aliastoactual ) ; <nl> for ( map . entry < label , rule > changedsettingwithrule : changedsettingtorule . entryset ( ) ) { <nl> - label setting = changedsettingwithrule . getkey ( ) ; <nl> + / / if the build setting was referenced in the transition via an alias , this is that alias <nl> + label maybealiassetting = changedsettingwithrule . getkey ( ) ; <nl> rule rule = changedsettingwithrule . getvalue ( ) ; <nl> - object newvalue = options . getstarlarkoptions ( ) . get ( rule . getlabel ( ) ) ; <nl> + / / if the build setting was * not * referenced in the transition by an alias , this is the same <nl> + / / value as { @ code maybealiassetting } above . <nl> + label actualsetting = rule . getlabel ( ) ; <nl> + object newvalue = options . getstarlarkoptions ( ) . get ( actualsetting ) ; <nl> + <nl> + preconditions . checkstate ( <nl> + newvalue ! = null , <nl> + " error while attempting to validate new values from starlark " <nl> + + " transition ( s ) with the outputs % s . post - transition configuration should include " <nl> + + " ' % s ' but only includes starlark options : % s . if you run into this error " <nl> + + " please ping b / 154132845 or email blaze - configurability @ google . com . " , <nl> + changedsettingtorule . keyset ( ) , <nl> + actualsetting , <nl> + options . getstarlarkoptions ( ) . keyset ( ) ) ; <nl> object convertedvalue ; <nl> try { <nl> convertedvalue = <nl> - rule . getruleclassobject ( ) . getbuildsetting ( ) . gettype ( ) . convert ( newvalue , setting ) ; <nl> + rule . getruleclassobject ( ) <nl> + . getbuildsetting ( ) <nl> + . gettype ( ) <nl> + . convert ( newvalue , maybealiassetting ) ; <nl> } catch ( conversionexception e ) { <nl> throw new transitionexception ( e ) ; <nl> }
public class ruleclass { <nl> return this ; <nl> } <nl>  <nl> + / * * <nl> + * adds an attribute to the builder . <nl> + * <nl> + * < p > throws an illegalstateexception if an attribute of that name already exists . <nl> + * <nl> + * < p > <nl> + * / <nl> public builder addattribute ( attribute attribute ) { <nl> - preconditions . checkstate ( ! attributes . containskey ( attribute . getname ( ) ) , <nl> - " an attribute with the name ' % s ' already exists . " , attribute . getname ( ) ) ; <nl> - attributes . put ( attribute . getname ( ) , attribute ) ; <nl> + attribute prevval = attributes . putifabsent ( attribute . getname ( ) , attribute ) ; <nl> + if ( prevval ! = null ) { <nl> + throw new illegalstateexception ( <nl> + string . format ( <nl> + " there is already a built - in attribute ' % s ' which cannot be overridden . " , <nl> + attribute . getname ( ) ) ) ; <nl> + } <nl> return this ; <nl> } <nl>  <nl> mmm a / src / test / java / com / google / devtools / build / lib / bazel / repository / skylark / skylarkrepositorycontexttest . java <nl> ppp b / src / test / java / com / google / devtools / build / lib / bazel / repository / skylark / skylarkrepositorycontexttest . java <nl>
public class functiontransitionutil { <nl> optiondefinition def = optioninfo . getdefinition ( ) ; <nl> field field = def . getfield ( ) ; <nl> fragmentoptions options = buildoptions . get ( optioninfo . getoptionclass ( ) ) ; <nl> + <nl> if ( optionvalue = = null | | def . gettype ( ) . isinstance ( optionvalue ) ) { <nl> field . set ( options , optionvalue ) ; <nl> convertednewvalues . put ( entry . getkey ( ) , optionvalue ) ; <nl> mmm a / src / test / java / com / google / devtools / build / lib / analysis / starlarkruletransitionprovidertest . java <nl> ppp b / src / test / java / com / google / devtools / build / lib / analysis / starlarkruletransitionprovidertest . java <nl>
public abstract class abstractexceptionalparallelevaluator < e extends exception > <nl> / / clear interrupted status . we ' re not listening to interrupts here . <nl> thread . interrupted ( ) ; <nl> } <nl> - if ( completedrun ) { <nl> + <nl> + if ( completedrun <nl> + & & error . getexception ( ) ! = null <nl> + & & error . getexception ( ) instanceof ioexception ) { <nl> logger . info ( <nl> " skyfunction did not rethrow error , may be a bug that it did not expect one : " <nl> + errorkey
public class shadowedapiadapterhelper { <nl> * no in - process label , such as " __desugar__ / " , is attached to this invocation site . <nl> * / <nl> static boolean shoulduseinlinetypeconversion ( methodinvocationsite verbatiminvocationsite ) { <nl> + / / fix for b / 153441709 : type adapter generation causes one - version violation . <nl> + <nl> + if ( verbatiminvocationsite . owner ( ) . haspackageprefix ( " android / app / usage / usagestatsmanager " ) ) { <nl> + return true ; <nl> + } <nl> return verbatiminvocationsite . isconstructorinvocation ( ) <nl> & & verbatiminvocationsite . owner ( ) . isinpackageeligiblefortypeadapter ( ) <nl> & & stream . concat (
public class pythonoptions extends fragmentoptions { <nl> + " python target will be an error . " ) <nl> public boolean incompatibledisallowlegacypyprovider ; <nl>  <nl> + <nl> @ option ( <nl> name = " incompatible_use_python_toolchains " , <nl> defaultvalue = " true " , <nl> mmm a / src / test / java / com / google / devtools / build / lib / testutil / testconstants . java <nl> ppp b / src / test / java / com / google / devtools / build / lib / testutil / testconstants . java <nl>
import com . google . devtools . build . lib . util . filetype ; <nl> * <nl> * < p > this class exposes a unified view over both the legacy and modern python providers . <nl> * / <nl> + <nl> public class pyproviderutils { <nl>  <nl> / / disable construction . <nl> mmm a / src / main / java / com / google / devtools / build / lib / rules / python / pystructutils . java <nl> ppp b / src / main / java / com / google / devtools / build / lib / rules / python / pystructutils . java <nl>
public final class spawnlogmodule extends blazemodule { <nl> env . getexecroot ( ) , outstream , env . getoptions ( ) . getoptions ( remoteoptions . class ) ) ; <nl> } <nl>  <nl> + @ override <nl> + public void registeractioncontexts ( <nl> + moduleactioncontextregistry . builder registrybuilder , <nl> + commandenvironment env , <nl> + buildrequest buildrequest ) { <nl> + if ( spawnlogcontext ! = null ) { <nl> + <nl> + registrybuilder . register ( spawnlogcontext . class , spawnlogcontext , " spawn - log " ) ; <nl> + registrybuilder . restrictto ( spawnlogcontext . class , " " ) ; <nl> + } <nl> + } <nl> + <nl> @ override <nl> public void executorinit ( commandenvironment env , buildrequest request , executorbuilder builder ) { <nl> env . geteventbus ( ) . register ( this ) ; <nl>
filegroup ( <nl> visibility = [ " / / src : __subpackages__ " ] , <nl> ) <nl>  <nl> + type_srcs = [ " type . java " ] <nl> + <nl> + build_type_srcs = [ <nl> + " buildtype . java " , <nl> + " filesetentry . java " , <nl> + " license . java " , <nl> + " selectorlist . java " , <nl> + " selectorvalue . java " , <nl> + " tristate . java " , <nl> + ] <nl> + <nl> java_library ( <nl> name = " packages " , <nl> srcs = glob ( <nl> [ " * . java " ] , <nl> - exclude = [ <nl> + exclude = type_srcs + build_type_srcs + [ <nl> " builderfactoryfortesting . java " , <nl> " starlarksemanticsoptions . java " , <nl> - " type . java " , <nl> ] , <nl> ) , <nl> + # <nl> + exports = [ <nl> + " : build_type " , <nl> + ] , <nl> deps = [ <nl> + " : build_type " , <nl> " : type " , <nl> " / / src / main / java / com / google / devtools / build / lib : config - matching - provider " , <nl> " / / src / main / java / com / google / devtools / build / lib : config - transitions " , <nl>
eof <nl> : # so the exit code of the test is not inferred from that of " - r " above <nl> } <nl>  <nl> + # trivial test to verify that the various flags that specify resource limits <nl> + # accept the same syntax . <nl> + function test_resource_flags_syntax ( ) { <nl> + local threads = host_cpus * 0 . 8 <nl> + local ram = host_ram * 0 . 8 <nl> + # <nl> + # part of the build , so this flag , which we should test here , isn ' t <nl> + # available : - - experimental_include_scanning_parallelism = " $ { threads } " <nl> + bazel build - - nobuild \ <nl> + - - experimental_sandbox_async_tree_delete_idle_threads = " $ { threads } " \ <nl> + - - jobs = " $ { threads } " \ <nl> + - - loading_phase_threads = " $ { threads } " \ <nl> + - - local_cpu_resources = " $ { threads } " \ <nl> + - - local_ram_resources = " $ { ram } " \ <nl> + - - local_test_jobs = " $ { threads } " \ <nl> + | | fail " empty build failed " <nl> + } <nl> + <nl> run_suite " integration tests of $ { product_name } using the execution phase . "
java_library ( <nl> exclude = [ <nl> " builderfactoryfortesting . java " , <nl> " starlarksemanticsoptions . java " , <nl> + " type . java " , <nl> ] , <nl> ) , <nl> + # <nl> + exports = [ <nl> + " : type " , <nl> + ] , <nl> deps = [ <nl> + " : type " , <nl> " / / src / main / java / com / google / devtools / build / lib : config - matching - provider " , <nl> " / / src / main / java / com / google / devtools / build / lib : config - transitions " , <nl> " / / src / main / java / com / google / devtools / build / lib : events " , <nl>
import javax . annotation . nullable ; <nl>  <nl> / * * ninja files parser . the types of tokens : { @ link ninjatoken } . ninja lexer : { @ link ninjalexer } . * / <nl> public class ninjaparserstep { <nl> + / * * <nl> + * an interner for { @ link pathfragment } instances for the inputs and outputs of { @ link <nl> + * ninjatarget } . <nl> + * / <nl> + <nl> + / / object in ninja parsing is . once i figure out which object has the lifetime of " exactly as long <nl> + / / as the parsing is running " , i can just put this in a field of that object and plumb it here . <nl> + private static final interner < pathfragment > path_fragment_interner = <nl> + blazeinterners . newweakinterner ( ) ; <nl> + <nl> private final ninjalexer lexer ; <nl>  <nl> public ninjaparserstep ( ninjalexer lexer ) { <nl>
public class actionexecutedevent implements buildeventwithconfiguration , progres <nl> . settype ( action . getmnemonic ( ) ) ; <nl>  <nl> if ( exception ! = null & & exception . getexitcode ( ) ! = null ) { <nl> + <nl> + / / however , the value returned by exception . getexitcode ( ) . getnumericexitcode ( ) is intended as <nl> + / / an exit code that this bazel invocation might return to the user . <nl> actionbuilder . setexitcode ( exception . getexitcode ( ) . getnumericexitcode ( ) ) ; <nl> } <nl> if ( stdout ! = null ) { <nl> mmm a / src / main / java / com / google / devtools / build / lib / skyframe / skyframeactionexecutor . java <nl> ppp b / src / main / java / com / google / devtools / build / lib / skyframe / skyframeactionexecutor . java <nl>
public final class actionmetadatahandler implements metadatahandler { <nl> throw new ioexception ( errormessage , e ) ; <nl> } <nl>  <nl> + <nl> / / a minor hack : maybestoreadditionaldata will force the data to be stored via <nl> / / store . putadditionaloutputdata , if the underlying outputstore supports it . <nl> filemetadata = maybestoreadditionaldata ( treefileartifact , filemetadata , null ) ; <nl> mmm a / src / test / java / com / google / devtools / build / lib / skyframe / actionmetadatahandlertest . java <nl> ppp b / src / test / java / com / google / devtools / build / lib / skyframe / actionmetadatahandlertest . java <nl>
<nl> layout : documentation <nl> title : user ' s guide <nl> mmm <nl> + < ! - - begin - block : internal <nl> + <nl> < h1 > a user ' s guide to bazel < / h1 > <nl>  <nl>  <nl>
public final class macosxfseventsdiffawareness extends localdiffawareness { <nl> private native void create ( string [ ] paths , double latency ) ; <nl>  <nl> / * * <nl> - * run the main loop <nl> + * runs the main loop to listen for fsevents . <nl> + * <nl> + * @ param listening latch that is decremented when the fsevents queue has been set up . the caller <nl> + * must wait until this happens before polling for events to ensure no events are lost between <nl> + * when this function returns and when the queue is listening . <nl> * / <nl> - private native void run ( ) ; <nl> + private native void run ( countdownlatch listening ) ; <nl>  <nl> private void init ( ) { <nl> / / the code below is based on the assumption that init ( ) can never fail , which is currently the <nl> / / case ; if you change init ( ) , then you also need to update { @ link # getcurrentview } . <nl> + <nl> preconditions . checkstate ( ! opened ) ; <nl> opened = true ; <nl> create ( new string [ ] { watchrootpath . toabsolutepath ( ) . tostring ( ) } , latency ) ; <nl> + <nl> / / start a thread that just contains the os x run loop . <nl> - new thread ( ( ) - > macosxfseventsdiffawareness . this . run ( ) , " osx - fs - events " ) . start ( ) ; <nl> + countdownlatch listening = new countdownlatch ( 1 ) ; <nl> + new thread ( ( ) - > macosxfseventsdiffawareness . this . run ( listening ) , " osx - fs - events " ) . start ( ) ; <nl> + try { <nl> + listening . await ( ) ; <nl> + } catch ( interruptedexception e ) { <nl> + thread . currentthread ( ) . interrupt ( ) ; <nl> + } <nl> } <nl>  <nl> / * * <nl> mmm a / src / main / native / fsevents . cc <nl> ppp b / src / main / native / fsevents . cc <nl>
public class testrunneraction extends abstractaction <nl> . getcontext ( testactioncontext . class ) <nl> . newcachedtestresult ( executor . getexecroot ( ) , this , readcachestatus ( ) ) ) ; <nl> } catch ( ioexception e ) { <nl> + <nl> loggingutil . logtoremote ( level . warning , " failed creating cached protocol buffer " , e ) ; <nl> } <nl> }
public final class javainfo extends nativeinfo implements javainfoapi < artifact > <nl>  <nl> public builder maybetransitiveonlyruntimejarstojavainfo ( <nl> list < ? extends transitiveinfocollection > deps , boolean shouldadd ) { <nl> + <nl> if ( shouldadd ) { <nl> deps . stream ( ) <nl> . map ( javainfo : : getjavainfo )
target platform , action environment variables , and command - line [ build <nl> flags ] ( # command - flags ) . [ transitions ] ( # transition ) may create additional <nl> configurations , e . g . for host tools or cross - compilation . <nl>  <nl> + < ! - - <nl> + <nl> # # # # configuration trimming <nl>  <nl> the process of only including the pieces of [ configuration ] ( # configuration ) a <nl>
sh_test ( <nl> ] , <nl> tags = [ <nl> " local " , <nl> + " manual " , # <nl> " no_windows " , <nl> ] , <nl> )
public interface spawnstrategy extends actioncontext { <nl>  <nl> / * * returns whether this spawnactioncontext supports executing the given spawn . * / <nl> boolean canexec ( spawn spawn , actioncontext . actioncontextregistry actioncontextregistry ) ; <nl> + <nl> + / * * <nl> + * performs any actions conditional on this strategy not only being registered but triggered as <nl> + * used because its identifier was requested and it was not overridden . <nl> + * <nl> + * @ param actioncontextregistry a registry containing all available contexts <nl> + * / <nl> + <nl> + @ override <nl> + default void usedcontext ( actioncontext . actioncontextregistry actioncontextregistry ) { } <nl> }
public class resourcecompiler { <nl> file , <nl> false ) ; <nl> / / aapt2 only generates pseudo locales for the default locale . <nl> + <nl> generatedresourcesout . ifpresent ( <nl> out - > compile ( directoryname , filename , results , out , file , true ) ) ; <nl> } else {
public class bazelpythonsemantics implements pythonsemantics { <nl>  <nl> if ( os . getcurrent ( ) ! = os . windows ) { <nl> pathfragment shexecutable = shtoolchain . getpathorerror ( rulecontext ) ; <nl> + <nl> + string pythonexecutablename = os . getcurrent ( ) = = os . openbsd ? " python3 " : " python " ; <nl> rulecontext . registeraction ( <nl> new spawnaction . builder ( ) <nl> . addinput ( zipfile ) <nl> . addoutput ( executable ) <nl> . setshellcommand ( <nl> shexecutable , <nl> - " echo ' # ! / usr / bin / env python ' | cat - " <nl> + " echo ' # ! / usr / bin / env " <nl> + + pythonexecutablename <nl> + + " ' | cat - " <nl> + zipfile . getexecpathstring ( ) <nl> + " > " <nl> + executable . getexecpathstring ( ) )
test_suite ( <nl> " / / src / test / java / com / google / devtools / common / options : all_windows_tests " , <nl> " / / src / test / native / windows : all_windows_tests " , <nl> " / / src / test / py / bazel : all_windows_tests " , <nl> - " / / src / test / res : all_windows_tests " , <nl> + # <nl> + # " / / src / test / res : all_windows_tests " , <nl> " / / src / test / shell : all_windows_tests " , <nl> " / / src / test / shell / bazel / android : all_windows_tests " , <nl> " / / src / tools / launcher : all_windows_tests " ,
public class androidcompileddatadeserializer implements androiddatadeserializer <nl>  <nl> strings . add ( new string ( bytes , stringoffset , length , " utf8 " ) ) ; <nl> } else { <nl> + <nl> int charactercount = bytebuffer . get ( stringoffset ) & num xffff ; <nl> if ( ( charactercount & num x8000 ) ! = num ) { <nl> charactercount = <nl> mmm a / src / tools / android / java / com / google / devtools / build / android / aapt2 / protoapk . java <nl> ppp b / src / tools / android / java / com / google / devtools / build / android / aapt2 / protoapk . java <nl>
public class protoapk implements closeable { <nl>  <nl> strings . add ( new string ( bytes , stringoffset , length , " utf8 " ) ) ; <nl> } else { <nl> + <nl> int charactercount = bytebuffer . get ( stringoffset ) & num xffff ; <nl> if ( ( charactercount & num x8000 ) ! = num ) { <nl> charactercount =
import com . google . devtools . build . lib . view . test . teststatus . testresultdata ; <nl> @ autovalue <nl> public abstract class standalonetestresult implements testactioncontext . testattemptresult { <nl> @ override <nl> - public boolean haspassed ( ) { <nl> - return testresultdatabuilder ( ) . getstatus ( ) = = blazeteststatus . passed ; <nl> + public testactioncontext . testattemptresult . result result ( ) { <nl> + <nl> + return testresultdatabuilder ( ) . getstatus ( ) = = blazeteststatus . passed <nl> + ? result . passed <nl> + : result . failed_can_retry ; <nl> } <nl>  <nl> / * * returns the spawnresults created by the test , if any . * /
for name in " $ lcov_merger " ; do <nl> done <nl>  <nl> # setting up the environment for executing the c + + tests . <nl> - export gcov_prefix_strip = 3 <nl> + if [ [ - z " $ gcov_prefix_strip " ] ] ; then <nl> + # <nl> + export gcov_prefix_strip = 3 <nl> + fi <nl> export gcov_prefix = " $ { coverage_dir } " <nl> export llvm_profile_file = " $ { coverage_dir } / % h - % p - % m . profraw "
test_tar_utf8 ( ) { <nl> echo ' hello world ' > ext / data . txt <nl> touch ext / $ ' unrelated \ xf0 \ x9f \ x8d \ x83 . txt ' <nl> touch ext / $ ' cyrillic \ xd0 \ x90 \ xd0 \ x91 \ xd0 \ x92 \ xd0 \ x93 \ xd0 \ x94 . . . ' <nl> - touch ext / $ ' umlauts \ xc3 \ x84 \ xc3 \ x96 \ xc3 \ x9c \ xc3 \ xa4 \ xc3 \ xb6 \ xc3 \ xbc ' <nl> + touch ext / $ ' umlauts \ x41 \ xcc \ x88 \ x4f \ xcc \ x88 \ x55 \ xcc \ x88 \ x61 \ xcc \ x88 \ x6f \ xcc \ x88 \ x75 \ xcc \ x88 ' <nl> + # <nl> + # macos catalina when using this form ( nfc normalized ) . <nl> + # touch ext / $ ' umlauts \ xc3 \ x84 \ xc3 \ x96 \ xc3 \ x9c \ xc3 \ xa4 \ xc3 \ xb6 \ xc3 \ xbc ' <nl>  <nl> tar cf ext . tar ext <nl> rm - rf ext
public final class skyframebuildview { <nl> packageroots ) ; <nl> } <nl>  <nl> + private boolean checkforconflicts ( immutableset < skykey > newkeys ) { <nl> + if ( someconfiguredtargetevaluated ) { <nl> + / / a top - level target was added and may introduce a conflict , or a top - level target was <nl> + / / recomputed and may introduce or resolve a conflict . <nl> + return true ; <nl> + } <nl> + <nl> + if ( anyconfiguredtargetdeleted ) { <nl> + / / no target was ( re ) computed , but some were deleted , which may resolve a conflict . <nl> + <nl> + return true ; <nl> + } <nl> + <nl> + if ( ! dirtiedconfiguredtargetkeys . isempty ( ) ) { <nl> + / / no target was ( re ) computed and none was deleted , but at least one was dirtied . <nl> + / / example : ( / / : x / / foo : y ) are built , and in conflict ( / / : x creates foo / c and / / foo : y <nl> + / / creates c ) . then y is removed from foo / build and only / / : x is built , so / / foo : y is <nl> + / / dirtied but not recomputed , and no other nodes are recomputed ( and none are deleted ) . <nl> + / / still we must do the conflict checking because previously there was a conflict but now <nl> + / / there isn ' t . <nl> + return true ; <nl> + } <nl> + <nl> + if ( ! skyframeactionexecutor . badactions ( ) . isempty ( ) ) { <nl> + / / example sequence : <nl> + / / num . build ( x y z ) , and there is a conflict . we store ( x y z ) as the largest checked key <nl> + / / set , and record the fact that there were bad actions . <nl> + / / num . null - build ( x z ) , so we don ' t evaluate or dirty or delete anything , but because we know <nl> + / / there was some conflict last time but don ' t know exactly which targets conflicted , it <nl> + / / could have been ( x z ) , so we now check again . <nl> + return true ; <nl> + } <nl> + <nl> + if ( ! largesttoplevelkeysetcheckedforconflicts . containsall ( newkeys ) ) { <nl> + / / example sequence : <nl> + / / num . build ( x y z ) , and there is a conflict . we store ( x y z ) as the largest checked key <nl> + / / set , and record the fact that there were bad actions . <nl> + / / num . null - build ( x z ) , so we don ' t evaluate or dirty or delete anything , but because we know <nl> + / / there was some conflict last time but don ' t know exactly which targets conflicted , it <nl> + / / could have been ( x z ) , so we now check again , and store ( x z ) as the largest checked <nl> + / / key set . <nl> + / / num . null - build ( y z ) , so again we don ' t evaluate or dirty or delete anything , and the <nl> + / / previous build had no conflicts , so no other condition is true . but because ( y z ) is no <nl> + / / subset of ( x z ) and we only keep the most recent largest checked key set , we don ' t know <nl> + / / if ( y z ) are conflict free , so we check . <nl> + return true ; <nl> + } <nl> + <nl> + / / we believe the conditions above are correct in the sense that we always check for conflicts <nl> + / / when we have to . but they are incomplete , so we sometimes check for conflicts even if we <nl> + / / wouldn ' t have to . for example : <nl> + / / - if no target was evaluated ( nor dirtied , nor deleted ) , and build sequence is ( x y ) <nl> + / / [ no conflict ] , ( z ) , where z is in the transitive closure of ( x y ) , then we shouldn ' t check . <nl> + / / - if no target was evaluated ( nor dirtied , nor deleted ) , and build sequence is ( x y ) <nl> + / / [ no conflict ] , ( z ) , ( x ) , then the last build shouldn ' t conflict - check because ( x y ) was <nl> + / / checked earlier . but it does , since after the second build we store ( z ) as the largest <nl> + / / checked set of which ( x ) is no subset . <nl> + return false ; <nl> + } <nl> + <nl> / * * <nl> * process errors encountered during analysis , and return a { @ link pair } indicating the existence <nl> * of a loading - phase error , if any , and an exception to be thrown to halt the build , if { @ code
import java . util . list ; <nl> / / this module needs to be exported to skylark so it can be passed as a mandatory host / target <nl> / / configuration fragment in aspect definitions . <nl> public class protoconfiguration extends fragment implements protoconfigurationapi { <nl> + <nl> + private static final label default_javalite_toolchain_old = <nl> + label . parseabsoluteunchecked ( " @ com_google_protobuf_javalite / / : javalite_toolchain " ) ; <nl> + private static final label default_javalite_toolchain_new = <nl> + label . parseabsoluteunchecked ( " @ com_google_protobuf / / : javalite_toolchain " ) ; <nl> + <nl> / * * command line options . * / <nl> public static class options extends fragmentoptions { <nl> @ option ( <nl>
public class protoconfiguration extends fragment implements protoconfigurationap <nl>  <nl> @ option ( <nl> name = " proto_toolchain_for_javalite " , <nl> - defaultvalue = " @ com_google_protobuf_javalite / / : javalite_toolchain " , <nl> + <nl> + / / defaults to true . <nl> + defaultvalue = " null " , <nl> converter = coreoptionconverters . emptytonulllabelconverter . class , <nl> documentationcategory = optiondocumentationcategory . uncategorized , <nl> effecttags = { optioneffecttag . affects_outputs , optioneffecttag . loading_and_analysis } , <nl>
public class resourceprocessorbusybox { <nl> optionsparser . parse ( args ) ; <nl> options = optionsparser . getoptions ( options . class ) ; <nl> options . tool . call ( optionsparser . getresidue ( ) . toarray ( new string [ 0 ] ) ) ; <nl> - } catch ( <nl> - optionsparsingexception <nl> - | mergingexception <nl> - | ioexception <nl> - | aapt2exception <nl> - | invalidjavaidentifier e ) { <nl> + } catch ( userexception e ) { <nl> + / / userexception is for exceptions that shouldn ' t have stack traces recorded , including <nl> + / / androiddatamerger . mergeconflictexception . <nl> + logger . log ( level . severe , e . getmessage ( ) ) ; <nl> + return num ; <nl> + } catch ( optionsparsingexception | ioexception | aapt2exception | invalidjavaidentifier e ) { <nl> logsuppressed ( e ) ; <nl> throw e ; <nl> } catch ( exception e ) { <nl> + <nl> logger . log ( level . severe , " error during processing " , e ) ; <nl> throw e ; <nl> }
public final class nestedsetbuilder < e > { <nl> return this ; <nl> } <nl>  <nl> + / * * <nl> + * similar to { @ link # addtransitive } except that if the subset is based on a deserialization <nl> + * future , blocks for that future to complete . <nl> + * <nl> + * < p > the block would occur anyway upon calling { @ link # build } . however , { @ link # build } crashes <nl> + * instead of propagating { @ link interruptedexception } . this method may be preferable if the <nl> + * caller can propagate { @ link interruptedexception } . <nl> + * / <nl> + <nl> + public nestedsetbuilder < e > addtransitiveandblockiffuture ( nestedset < ? extends e > subset ) <nl> + throws interruptedexception { <nl> + object children = subset . rawchildren ( ) ; <nl> + if ( children instanceof listenablefuture ) { <nl> + morefutures . waitforfutureandget ( ( listenablefuture < ? > ) children ) ; <nl> + } <nl> + return addtransitive ( subset ) ; <nl> + } <nl> + <nl> / * * <nl> * builds the actual nested set . <nl> * <nl> mmm a / src / main / java / com / google / devtools / build / lib / rules / cpp / cppcompileaction . java <nl> ppp b / src / main / java / com / google / devtools / build / lib / rules / cpp / cppcompileaction . java <nl>
import javax . annotation . nullable ; <nl> * / <nl> public class compiledresources implements manifestcontainer { <nl>  <nl> + / * * <nl> + * file extension for persisting { @ code < resources tool : * / > } attributes . these files are bundled <nl> + * with * . flat files in the { @ link resources } zip file and ignored by aapt2 . the format is <nl> + * internal to resourceprocessorbusybox and can be changed at any time . <nl> + * / <nl> + <nl> + public static final string attributes_file_extension = " . attributes " ; <nl> + <nl> private final path resources ; <nl> @ nullable private final path manifest ; <nl> private final list < path > assetsdirs ; <nl> mmm a / src / tools / android / java / com / google / devtools / build / android / aapt2 / resourcecompiler . java <nl> ppp b / src / tools / android / java / com / google / devtools / build / android / aapt2 / resourcecompiler . java <nl>
<nl> + / / copyright num the bazel authors . all rights reserved . <nl> + / / <nl> + / / licensed under the apache license , version num . 0 ( the " license " ) ; <nl> + / / you may not use this file except in compliance with the license . <nl> + / / you may obtain a copy of the license at <nl> + / / <nl> + / / http : / / www . apache . org / licenses / license - 2 . 0 <nl> + / / <nl> + / / unless required by applicable law or agreed to in writing , software <nl> + / / distributed under the license is distributed on an " as is " basis , <nl> + / / without warranties or conditions of any kind , either express or implied . <nl> + / / see the license for the specific language governing permissions and <nl> + / / limitations under the license . <nl> + package com . google . devtools . build . android . desugar . runtime ; <nl> + <nl> + import android . app . role . rolemanager ; <nl> + import android . os . userhandle ; <nl> + import java . util . concurrent . executor ; <nl> + import java . util . function . consumer ; <nl> + <nl> + / * * <nl> + * conversion from desugared to built - in { @ link consumer } for calling hidden android apis ( see <nl> + * b / 145531945 ) . <nl> + * / <nl> + <nl> + @ suppresswarnings ( " androidjdklibschecker " ) <nl> + public final class hiddenconsumerwrapper < t > implements consumer < t > { <nl> + <nl> + private final j $ . util . function . consumer < t > wrapped ; <nl> + <nl> + private hiddenconsumerwrapper ( j $ . util . function . consumer < t > wrapped ) { <nl> + this . wrapped = wrapped ; <nl> + } <nl> + <nl> + @ override <nl> + public void accept ( t t ) { <nl> + wrapped . accept ( t ) ; <nl> + } <nl> + <nl> + public static void addroleholderasuser ( <nl> + rolemanager receiver , <nl> + string rolename , <nl> + string packagename , <nl> + int flags , <nl> + userhandle user , <nl> + executor executor , <nl> + j $ . util . function . consumer < boolean > callback ) { <nl> + receiver . addroleholderasuser ( <nl> + rolename , <nl> + packagename , <nl> + flags , <nl> + user , <nl> + executor , <nl> + callback ! = null ? new hiddenconsumerwrapper < boolean > ( callback ) : null ) ; <nl> + } <nl> + }
public class androiddatacontext implements androiddatacontextapi { <nl> androidsdkprovider . fromrulecontext ( rulecontext ) , <nl> hasexemption ( rulecontext , " allow_raw_access_to_resource_paths " , false ) , <nl> hasexemption ( rulecontext , " allow_resource_name_obfuscation_opt_out " , false ) , <nl> - ! hasexemption ( rulecontext , " allow_shrink_resources_attribute " , true ) , <nl> + <nl> + hasexemption ( rulecontext , " allow_resource_shrinking_opt_out " , false ) , <nl> ! hasexemption ( rulecontext , " allow_proguard_apply_dictionary " , true ) , <nl> ! hasexemption ( rulecontext , " allow_proguard_apply_mapping " , true ) , <nl> ! hasexemption ( rulecontext , " allow_resource_conflicts " , true ) , <nl>
public class androiddatacontext implements androiddatacontextapi { <nl> return optoutofresourcenameobfuscation ; <nl> } <nl>  <nl> - public boolean throwonshrinkresources ( ) { <nl> - return throwonshrinkresources ; <nl> + <nl> + public boolean optoutofresourceshrinking ( ) { <nl> + return optoutofresourceshrinking ; <nl> } <nl>  <nl> public boolean throwonproguardapplydictionary ( ) { <nl>
public class nativeinfo extends structimpl { <nl> string . format ( " access of field % s was unexpectedly interrupted , but should be " <nl> + " uninterruptible . this is indicative of a bad provider implementation . " , name ) ) ; <nl> } <nl> + } else if ( name . equals ( " to_json " ) | | name . equals ( " to_proto " ) ) { <nl> + / / to_json and to_proto should not be methods of struct or provider instances . <nl> + / / however , they are , for now , and it is important that they be consistently <nl> + / / returned by attribute lookup operations regardless of whether a field or method <nl> + <nl> + return new builtincallable ( this , name ) ; <nl> } else { <nl> return null ; <nl> } <nl> mmm a / src / main / java / com / google / devtools / build / lib / packages / skylarkinfo . java <nl> ppp b / src / main / java / com / google / devtools / build / lib / packages / skylarkinfo . java <nl>
public abstract class skylarkinfo extends structimpl implements concatable , skyl <nl> public object getvalue ( location loc , starlarksemantics starlarksemantics , string name ) <nl> throws evalexception { <nl> / / by default , a skylarkinfo ' s field values are not affected by the starlark semantics . <nl> - return getvalue ( name ) ; <nl> + object x = getvalue ( name ) ; <nl> + if ( x ! = null ) { <nl> + return x ; <nl> + } else if ( name . equals ( " to_json " ) | | name . equals ( " to_proto " ) ) { <nl> + / / to_json and to_proto should not be methods of struct or provider instances . <nl> + / / however , they are , for now , and it is important that they be consistently <nl> + / / returned by attribute lookup operations regardless of whether a field or method <nl> + <nl> + return new builtincallable ( this , name ) ; <nl> + } else { <nl> + return null ; <nl> + } <nl> } <nl>  <nl> / * * <nl> mmm a / src / main / java / com / google / devtools / build / lib / syntax / builtincallable . java <nl> ppp b / src / main / java / com / google / devtools / build / lib / syntax / builtincallable . java <nl>
public final class builtincallable implements starlarkcallable { <nl> private final object obj ; <nl> private final string methodname ; <nl>  <nl> - builtincallable ( object obj , string methodname ) { <nl> + / / this function is only public for the to_ { json , proto } hack . <nl> + <nl> + public builtincallable ( object obj , string methodname ) { <nl> this . obj = obj ; <nl> this . methodname = methodname ; <nl> } <nl> mmm a / src / test / java / com / google / devtools / build / lib / syntax / skylarkevaluationtest . java <nl> ppp b / src / test / java / com / google / devtools / build / lib / syntax / skylarkevaluationtest . java <nl>
def _find_gold_linker_path ( repository_ctx , cc ) : <nl> for flag in line . split ( " " ) : <nl> if flag . find ( " gold " ) = = - 1 : <nl> continue <nl> + if flag . find ( " - - enable - gold " ) > - 1 or flag . find ( " - - with - plugin - ld " ) > - 1 : <nl> + # skip build configuration options of gcc itself <nl> + # <nl> + continue <nl>  <nl> # flag is ' - fuse - ld = gold ' for gcc or " / usr / lib / ld . gold " for clang <nl> # strip space , single quote , and double quotes
public class cppcompileaction extends abstractaction <nl> if ( input . isfiletype ( cppfiletypes . cpp_module ) ) { <nl> continue ; <nl> } <nl> + <nl> + if ( input . isfiletype ( cppfiletypes . objc_module_map ) ) { <nl> + continue ; <nl> + } <nl> if ( allowedincludes . contains ( input ) ) { <nl> continue ; <nl> } <nl> mmm a / src / main / java / com / google / devtools / build / lib / rules / cpp / cppfiletypes . java <nl> ppp b / src / main / java / com / google / devtools / build / lib / rules / cpp / cppfiletypes . java <nl>
public class platformconfiguration extends buildconfiguration . fragment <nl> this . targetfiltertoadditionalexecconstraints = targetfiltertoadditionalexecconstraints ; <nl> } <nl>  <nl> + @ override <nl> + public void reportinvalidoptions ( eventhandler reporter , buildoptions buildoptions ) { <nl> + platformoptions platformoptions = buildoptions . get ( platformoptions . class ) ; <nl> + <nl> + if ( platformoptions . platforms . size ( ) > num ) { <nl> + reporter . handle ( <nl> + event . warn ( <nl> + string . format ( <nl> + " - - platforms only supports a single target platform : using the first option % s " , <nl> + this . targetplatform ) ) ) ; <nl> + } <nl> + } <nl> + <nl> @ override <nl> public label gethostplatform ( ) { <nl> return hostplatform ; <nl> mmm a / src / main / java / com / google / devtools / build / lib / skyframe / platformmappingvalue . java <nl> ppp b / src / main / java / com / google / devtools / build / lib / skyframe / platformmappingvalue . java <nl>
public final class depset implements skylarkvalue { <nl>  <nl> / * * adds a direct element , checking that its type is equal to the elements already added . * / <nl> public builder adddirect ( object x ) throws evalexception { <nl> - evalutils . checkvaliddictkey ( x ) ; <nl> + <nl> + / / evalutils . checkvaliddictkey ( x ) ; <nl> skylarktype xt = skylarktype . of ( x ) ; <nl> this . contenttype = checktype ( contenttype , xt , location ) ; <nl> builder . add ( x ) ;
public final class androidruleclasses { <nl> implicitoutputs . add ( <nl> androidruleclasses . android_library_class_jar , <nl> androidruleclasses . android_library_source_jar , <nl> - androidruleclasses . android_library_aar ) ; <nl> + androidruleclasses . android_library_aar / * <nl>  <nl> if ( androidresources . definesandroidresources ( attributes ) ) { <nl> implicitoutputs . add ( <nl> mmm a / src / main / java / com / google / devtools / build / lib / rules / android / androidskylarkdata . java <nl> ppp b / src / main / java / com / google / devtools / build / lib / rules / android / androidskylarkdata . java <nl>
class includeparser { <nl> artifact file , <nl> actionexecutionmetadata actionexecutionmetadata , <nl> actionexecutioncontext actionexecutioncontext , <nl> - artifact grepincludes , <nl> + @ nullable artifact grepincludes , <nl> @ nullable spawnincludescanner remoteincludescanner , <nl> boolean isoutputfile ) <nl> throws ioexception , execexception , interruptedexception { <nl> collection < inclusion > inclusions ; <nl>  <nl> + <nl> if ( remoteincludescanner ! = null <nl> + & & grepincludes ! = null <nl> & & remoteincludescanner . shouldparseremotely ( file , actionexecutioncontext ) ) { <nl> inclusions = <nl> remoteincludescanner . extractinclusions ( <nl>
public class bazelpythonsemantics implements pythonsemantics { <nl>  <nl> public static final pathfragment zip_runfiles_directory_name = pathfragment . create ( " runfiles " ) ; <nl>  <nl> + @ override <nl> + public string getsrcsversiondocurl ( ) { <nl> + <nl> + return " https : / / docs . bazel . build / versions / master / be / python . html # py_binary . srcs_version " ; <nl> + } <nl> + <nl> @ override <nl> public void validate ( rulecontext rulecontext , pycommon common ) { <nl> } <nl> mmm a / src / main / java / com / google / devtools / build / lib / rules / python / pycommon . java <nl> ppp b / src / main / java / com / google / devtools / build / lib / rules / python / pycommon . java <nl>
public class dataresourcexml implements dataresource { <nl> string attributename = <nl> attribute . getname ( ) . getnamespaceuri ( ) . isempty ( ) <nl> ? attribute . getname ( ) . getlocalpart ( ) <nl> + / / this is intentionally putting the " package " in the wrong place ! <nl> + <nl> : attribute . getname ( ) . getprefix ( ) + " : " + attribute . getname ( ) . getlocalpart ( ) ; <nl> fullyqualifiedname fqn = <nl> fqnfactory . create ( virtualtype . resources_attribute , attribute . getname ( ) . tostring ( ) ) ; <nl> mmm a / src / tools / android / java / com / google / devtools / build / android / placeholderidfieldinitializerbuilder . java <nl> ppp b / src / tools / android / java / com / google / devtools / build / android / placeholderidfieldinitializerbuilder . java <nl>
public final class stringliteral extends expression { <nl> } <nl>  <nl> @ override <nl> - public void prettyprint ( appendable buffer ) throws ioexception { <nl> - buffer . append ( printer . repr ( value ) ) ; <nl> + public void prettyprint ( appendable buf ) throws ioexception { <nl> + <nl> + / / however , that may come with a memory cost until we start compiling <nl> + / / ( at which point the cost is only transient ) . <nl> + / / for now , just simulate the behavior of repr ( str ) . <nl> + buf . append ( ' " ' ) ; <nl> + for ( int i = num ; i < value . length ( ) ; i + + ) { <nl> + char c = value . charat ( i ) ; <nl> + switch ( c ) { <nl> + case ' " ' : <nl> + buf . append ( " \ \ \ " " ) ; <nl> + break ; <nl> + case ' \ \ ' : <nl> + buf . append ( " \ \ \ \ " ) ; <nl> + break ; <nl> + case ' \ r ' : <nl> + buf . append ( " \ \ r " ) ; <nl> + break ; <nl> + case ' \n ' : <nl> + buf . append ( " \ \n " ) ; <nl> + break ; <nl> + case ' \ t ' : <nl> + buf . append ( " \ \ t " ) ; <nl> + break ; <nl> + default : <nl> + / / the starlark spec ( and lexer ) are far from complete here , <nl> + / / and it ' s hard to come up with a clean semantics for <nl> + / / string escapes that serves java ( utf - 16 ) and go ( utf - 8 ) . <nl> + / / clearly string literals should not contain non - printable <nl> + / / characters . for now we ' ll continue to pretend that all <nl> + / / non - printables are < num , but this obviously false . <nl> + if ( c < num ) { <nl> + buf . append ( string . format ( " \ \ x % 02x " , ( int ) c ) ) ; <nl> + } else { <nl> + buf . append ( c ) ; <nl> + } <nl> + } <nl> + } <nl> + buf . append ( ' " ' ) ; <nl> } <nl>  <nl> @ override
static void executeprogram ( const blaze_util : : path & exe , <nl> / / adverse scheduling effects on any tools invoked via executeprogram . <nl> charpp argv ( args_vector ) ; <nl> execv ( exe . asnativepath ( ) . c_str ( ) , argv . get ( ) ) ; <nl> + string err = getlasterrorstring ( ) ; <nl> + bazel_die ( blaze_exit_code : : internal_error ) <nl> + < < " execv of ' " < < exe . asprintablepath ( ) < < " ' failed : " < < err ; <nl> + <nl> + std : : abort ( ) ; / / not reachable . <nl> } <nl>  <nl> void executeserverjvm ( const blaze_util : : path & exe , <nl> mmm a / src / main / cpp / blaze_util_windows . cc <nl> ppp b / src / main / cpp / blaze_util_windows . cc <nl>
eof <nl> function test_downloads_toplevel_runfiles ( ) { <nl> # test that - - remote_download_toplevel fetches only the top level binaries <nl> # and generated runfiles . <nl> + if [ [ " $ platform " = = " darwin " ] ] ; then <nl> + # <nl> + # setting sdkroot and developer_dir appropriately , as is required of <nl> + # action executors in order to select the appropriate xcode toolchain . <nl> + return num <nl> + fi <nl> + <nl> mkdir - p a <nl>  <nl> cat > a / create_bar . tmpl < < ' eof '
eof <nl> function test_downloads_minimal_failure ( ) { <nl> # test that outputs of failing actions are downloaded when using <nl> # - - remote_download_minimal <nl> + if [ [ " $ platform " = = " darwin " ] ] ; then <nl> + # <nl> + # setting sdkroot and developer_dir appropriately , as is required of <nl> + # action executors in order to select the appropriate xcode toolchain . <nl> + return num <nl> + fi <nl> + <nl> mkdir - p a <nl> cat > a / build < < ' eof ' <nl> genrule (
static const void gotoworkspace ( <nl> } <nl> } <nl>  <nl> + / / replace this process with the blaze server . does not exit . <nl> + static void runservermode ( <nl> + const string & server_exe , <nl> + const vector < string > & server_exe_args , <nl> + const workspacelayout & workspace_layout , <nl> + const string & workspace , <nl> + const optionprocessor & option_processor , <nl> + const startupoptions & startup_options , <nl> + blazeserver * server ) { <nl> + if ( startup_options . batch ) { <nl> + bazel_die ( blaze_exit_code : : bad_argv ) <nl> + < < " exec - server command is not compatible with - - batch " ; <nl> + } <nl> + <nl> + bazel_log ( info ) < < " running in server mode . " ; <nl> + <nl> + <nl> + if ( server - > connected ( ) ) { <nl> + server - > killrunningserver ( ) ; <nl> + } <nl> + <nl> + const string server_dir = <nl> + blaze_util : : joinpath ( startup_options . output_base , " server " ) ; <nl> + <nl> + ensureserverdir ( server_dir ) ; <nl> + <nl> + blaze_util : : writefile ( blaze : : getprocessidasstring ( ) , <nl> + blaze_util : : joinpath ( server_dir , " server . pid . txt " ) ) ; <nl> + blaze_util : : writefile ( getargumentstring ( server_exe_args ) , <nl> + blaze_util : : joinpath ( server_dir , " cmdline " ) ) ; <nl> + <nl> + gotoworkspace ( workspace_layout , workspace ) ; <nl> + <nl> + setscheduling ( startup_options . batch_cpu_scheduling , <nl> + startup_options . io_nice_level ) ; <nl> + <nl> + { <nl> + withenvvars env_obj ( prepareenvironmentforjvm ( ) ) ; <nl> + executeserverjvm ( server_exe , server_exe_args ) ; <nl> + bazel_die ( blaze_exit_code : : internal_error ) <nl> + < < " execv of ' " < < server_exe < < " ' failed : " < < getlasterrorstring ( ) ; <nl> + } <nl> + } <nl> + <nl> / / replace this process with blaze in standalone / batch mode . <nl> / / the batch mode blaze process handles the command and exits . <nl> static void runbatchmode ( <nl>
file_test ( <nl> " / / conditions : default " : " not supported " , <nl> } ) , <nl> file = " : run_app " , <nl> + # <nl> + # https : / / github . com / bazelbuild / bazel / issues / 9104 # issuecomment - 521231693 <nl> + tags = [ " no_windows " ] , <nl> ) <nl>  <nl> test_suite ( name = " all_tests " )
public class platformtest extends buildviewtestcase { <nl> @ rule public expectedexception expectedexception = expectedexception . none ( ) ; <nl>  <nl> @ test <nl> + <nl> public void testplatform_autoconfig ( ) throws exception { <nl> - useconfiguration ( " - - host_cpu = piii " , " - - cpu = k8 " ) ; <nl> + useconfiguration ( <nl> + " - - host_cpu = piii " , " - - cpu = k8 " , " - - noincompatible_auto_configure_host_platform " ) ; <nl>  <nl> scratch . file ( <nl> " autoconfig / build " , <nl> mmm a / src / test / java / com / google / devtools / build / lib / skyframe / platformmappingfunctiontest . java <nl> ppp b / src / test / java / com / google / devtools / build / lib / skyframe / platformmappingfunctiontest . java <nl>
import org . objectweb . asm . tree . methodnode ; <nl> * / <nl> public class defaultmethodclassfixer extends classvisitor { <nl>  <nl> + / * * don ' t expect base classes for android things apis ( preinstalled but not in android . jar ) . * / <nl> + <nl> + private static final string unavailable_baseclasses_prefix = " com / google / android / things / pio / " ; <nl> + <nl> private final boolean usegeneratedbaseclasses ; <nl> private final classreaderfactory classpath ; <nl> private final classreaderfactory bootclasspath ; <nl>
public abstract class buildintegrationtestcase { <nl>  <nl> runtimewrapper . addoptions ( " - - experimental_extended_sanity_checks " ) ; <nl> runtimewrapper . addoptions ( testconstants . product_specific_flags ) ; <nl> + <nl> + runtimewrapper . addoptions ( " - - noincompatible_use_specific_tool_files " ) ; <nl> } <nl>  <nl> protected void resetoptions ( ) {
public class grpcremotecache extends abstractremoteactioncache { <nl> uploader . uploadblobs ( filestoupload , / * forceupload = * / true ) ; <nl> } <nl>  <nl> - if ( manifest . getstderrdigest ( ) ! = null ) { <nl> - result . setstderrdigest ( manifest . getstderrdigest ( ) ) ; <nl> + <nl> + if ( outerr . geterrorpath ( ) . exists ( ) ) { <nl> + digest stderr = uploadfilecontents ( outerr . geterrorpath ( ) ) ; <nl> + result . setstderrdigest ( stderr ) ; <nl> } <nl> - if ( manifest . getstdoutdigest ( ) ! = null ) { <nl> - result . setstdoutdigest ( manifest . getstdoutdigest ( ) ) ; <nl> + if ( outerr . getoutputpath ( ) . exists ( ) ) { <nl> + digest stdout = uploadfilecontents ( outerr . getoutputpath ( ) ) ; <nl> + result . setstdoutdigest ( stdout ) ; <nl> } <nl> } <nl> + <nl> + / * * <nl> + * put the file contents cache if it is not already in it . no - op if the file is already stored in <nl> + * cache . the given path must be a full absolute path . <nl> + * <nl> + * @ return the key for fetching the file contents blob from cache . <nl> + * / <nl> + private digest uploadfilecontents ( path file ) throws ioexception , interruptedexception { <nl> + digest digest = digestutil . compute ( file ) ; <nl> + immutableset < digest > missing = getmissingdigests ( immutablelist . of ( digest ) ) ; <nl> + if ( ! missing . isempty ( ) ) { <nl> + uploader . uploadblob ( <nl> + hashcode . fromstring ( digest . gethash ( ) ) , <nl> + chunker . builder ( ) . setinput ( digest . getsizebytes ( ) , file ) . build ( ) , <nl> + / * forceupload = * / true ) ; <nl> + } <nl> + return digest ; <nl> + } <nl>  <nl> / / execution cache api
new_local_repository ( <nl> path = " . / third_party / protobuf / 3 . 6 . 1 / " , <nl> ) <nl>  <nl> + # this is a mock version of bazelbuild / rules_python that contains only <nl> + # @ rules_python / / python : defs . bzl . it is used by protobuf . <nl> + # <nl> + new_local_repository ( <nl> + name = " rules_python " , <nl> + path = " . / third_party / rules_python " , <nl> + build_file = " / / third_party / rules_python : build " , <nl> + workspace_file = " / / third_party / rules_python : rules_python . workspace " , <nl> + ) <nl> + <nl> local_repository ( <nl> name = " googleapis " , <nl> path = " . / third_party / googleapis / " , <nl> mmm a / src / test / shell / integration / modify_execution_info_test . sh <nl> ppp b / src / test / shell / integration / modify_execution_info_test . sh <nl>
new_local_repository ( <nl> path = " $ ( dirname $ ( rlocation io_bazel / third_party / protobuf / 3 . 6 . 1 / build ) ) " , <nl> build_file = " $ ( rlocation io_bazel / third_party / protobuf / 3 . 6 . 1 / build ) " , <nl> ) <nl> + <nl> + # <nl> + # @ rules_python in the real source tree , since this third_party / package won ' t <nl> + # be available . <nl> + new_local_repository ( <nl> + name = " rules_python " , <nl> + path = " $ ( dirname $ ( rlocation io_bazel / third_party / rules_python / rules_python . workspace ) ) " , <nl> + build_file = " $ ( rlocation io_bazel / third_party / rules_python / build ) " , <nl> + workspace_file = " $ ( rlocation io_bazel / third_party / rules_python / rules_python . workspace ) " , <nl> + ) <nl> eof <nl> fi <nl> local pkg = " $ { funcname [ 0 ] } "
public abstract class fileartifactvalue implements skyvalue , hasdigest { <nl>  <nl> @ override <nl> public boolean couldbemodifiedsince ( fileartifactvalue o ) { <nl> + if ( digest ! = null & & o . getdigest ( ) ! = null ) { <nl> + <nl> + return ! arrays . equals ( digest , o . getdigest ( ) ) | | getsize ( ) ! = o . getsize ( ) ; <nl> + } <nl> + <nl> if ( ! ( o instanceof regularfileartifactvalue ) ) { <nl> return true ; <nl> } <nl>
public abstract class fileartifactvalue implements skyvalue , hasdigest { <nl> throw new unsupportedoperationexception ( ) ; <nl> } <nl>  <nl> + @ override <nl> + public boolean couldbemodifiedsince ( fileartifactvalue o ) { <nl> + if ( digest ! = null & & o . getdigest ( ) ! = null ) { <nl> + <nl> + return ! arrays . equals ( digest , o . getdigest ( ) ) | | getsize ( ) ! = o . getsize ( ) ; <nl> + } <nl> + <nl> + return true ; <nl> + } <nl> + <nl> @ override <nl> public long getsize ( ) { <nl> return size ;
<nl> + # a stub version of bazelbuild / rules_python that contains only the defs . bzl <nl> + # file , which is needed to access native python rules under <nl> + # - - incompatible_load_python_rules_from_bzl ( # 9006 ) . <nl> + # <nl> + # <nl> + <nl> + workspace ( name = " rules_python " )
public final class pycommon { <nl> if ( ! rulecontext . getfragment ( pythonconfiguration . class ) . usenewpyversionsemantics ( ) ) { <nl> return false ; <nl> } <nl> + <nl> string errortemplate = <nl> " this target is being built for python % s but ( transitively ) includes python % s - only " <nl> + " sources . you can get diagnostic information about which dependencies introduce this " <nl> + " version requirement by running the ` find_requirements ` aspect . for more info see " <nl> - + " the documentation for the ` srcs_version ` attribute . " ; <nl> + + " the documentation for the ` srcs_version ` attribute : " <nl> + + " https : / / docs . bazel . build / versions / master / be / python . html # py_binary . srcs_version " ; <nl> + <nl> string error = null ; <nl> if ( version = = pythonversion . py2 & & haspy3onlysources ) { <nl> error = string . format ( errortemplate , " 2 " , " 3 " ) ;
public class resourcelinker { <nl> . add ( " optimize " ) <nl> . when ( objects . equals ( logger . getlevel ( ) , level . fine ) ) <nl> . thenadd ( " - v " ) <nl> - . add ( " - - target - densities " , densities . stream ( ) . collect ( collectors . joining ( " , " ) ) ) <nl> + <nl> + / / the apk analyzer dashboard . <nl> + . when ( densities . size ( ) > = num ) <nl> + . thenadd ( " - - target - densities " , densities . stream ( ) . collect ( collectors . joining ( " , " ) ) ) <nl> . add ( " - o " , optimized ) <nl> . add ( binary . tostring ( ) ) <nl> . execute ( string . format ( " optimizing % s " , compiled . getmanifest ( ) ) ) ) ;
http_archive ( <nl> eof <nl> } <nl>  <nl> + # <nl> + # from / / workspace <nl> + function add_rules_pkg_to_workspace ( ) { <nl> + cat > > " $ 1 " < < eof <nl> + load ( " @ bazel_tools / / tools / build_defs / repo : http . bzl " , " http_archive " ) <nl> + <nl> + http_archive ( <nl> + name = " rules_pkg " , <nl> + sha256 = " <commit_id> " , <nl> + urls = [ <nl> + " https : / / mirror . bazel . build / github . com / bazelbuild / rules_pkg / rules_pkg - 0 . 2 . 0 . tar . gz " , <nl> + " https : / / github . com / bazelbuild / rules_pkg / releases / download / 0 . 2 . 0 / rules_pkg - 0 . 2 . 0 . tar . gz " , <nl> + ] , <nl> + ) <nl> + eof <nl> + } <nl> + <nl> function create_workspace_with_default_repos ( ) { <nl> touch " $ 1 " <nl> - add_rules_cc_to_workspace $ 1 <nl> + add_rules_cc_to_workspace " $ 1 " <nl> + add_rules_pkg_to_workspace " $ 1 " <nl> echo " $ 1 " <nl> } <nl>  <nl>
import org . apache . velocity . runtime . resource . loader . jarresourceloader ; <nl> * produces skydoc output in markdown form . <nl> * / <nl> public class markdownrenderer { <nl> - <nl> + <nl> private final string headertemplatefilename ; <nl> private final string ruletemplatefilename ; <nl> private final string providertemplatefilename ; <nl>
public class androidbootstrap implements bootstrap { <nl>  <nl> @ override <nl> public void addbindingstobuilder ( immutablemap . builder < string , object > builder ) { <nl> - builder . put ( <nl> - " android_common " , <nl> - flagguardedvalue . onlywhenexperimentalflagistrue ( <nl> - flagidentifier . experimental_google_legacy_api , androidcommon ) ) ; <nl> + <nl> + / / rationale : android_common module contains commonly used functions used outside of <nl> + / / the android starlark migration . let ' s not break them without an incompatible <nl> + / / change process . <nl> + builder . put ( " android_common " , androidcommon ) ; <nl> + <nl> builder . put ( <nl> apkinfoapi . name , <nl> flagguardedvalue . onlywhenexperimentalflagistrue (
these rules are improved versions of the native http rules and will eventually <nl> replace the native rules . <nl> " " " <nl>  <nl> - load ( " : utils . bzl " , " patch " , " update_attrs " , " workspace_and_buildfile " ) <nl> + load ( <nl> + " : utils . bzl " , <nl> + " patch " , <nl> + " read_netrc " , <nl> + " update_attrs " , <nl> + " use_netrc " , <nl> + " workspace_and_buildfile " , <nl> + ) <nl> + <nl> + def _get_auth ( ctx , urls ) : <nl> + " " " given the list of urls obtain the correct auth dict . " " " <nl> + if ctx . attr . netrc : <nl> + netrc = read_netrc ( ctx , ctx . attr . netrc ) <nl> + return use_netrc ( netrc , urls ) <nl> + <nl> + # <nl> + return { } <nl>  <nl> def _http_archive_impl ( ctx ) : <nl> " " " implementation of the http_archive rule . " " " <nl>
public final class ruleconfiguredtarget extends abstractconfiguredtarget { <nl> @ override <nl> protected object rawgetskylarkprovider ( string providerkey ) { <nl> if ( providerkey . equals ( actions_field_name ) ) { <nl> - return actions ; <nl> + / / only expose actions which are legitimate starlark values , otherwise they will later <nl> + / / cause a bazel crash . <nl> + <nl> + return actions . stream ( ) <nl> + . filter ( action - > action instanceof actionapi ) <nl> + . collect ( immutablelist . toimmutablelist ( ) ) ; <nl> } <nl> return providers . get ( providerkey ) ; <nl> }
<nl> mmm <nl> platforms : <nl> + centos7 : <nl> + shell_commands : <nl> + - sed - i . bak - e ' s / ^ # android_sdk_repository / android_sdk_repository / ' - e ' s / ^ # <nl> + android_ndk_repository / android_ndk_repository / ' workspace <nl> + - rm - f workspace . bak <nl> + build_targets : <nl> + - " / / src : bazel " <nl> + - " / / src : bazel_jdk_minimal " <nl> + test_flags : <nl> + - " - - test_timeout = 1200 " <nl> + test_targets : <nl> + - " - - " <nl> + - " / / scripts / . . . " <nl> + - " / / src / java_tools / . . . " <nl> + - " / / src / test / . . . " <nl> + - " / / src / tools / execlog / . . . " <nl> + - " / / src / tools / singlejar / . . . " <nl> + - " / / src / tools / workspacelog / . . . " <nl> + - " / / third_party / ijar / . . . " <nl> + - " / / tools / android / . . . " <nl> + - " / / tools / aquery_differ / . . . " <nl> + - " / / tools / python / . . . " <nl> + # disable slow tests <nl> + - " - / / src / test / shell / bazel : bazel_determinism_test " <nl> + # re - enable once fixed : https : / / github . com / bazelbuild / bazel / issues / 4663 <nl> + - " - / / src / test / shell / bazel / android : android_ndk_integration_test " <nl> + # re - enable once fixed : https : / / github . com / bazelbuild / bazel / issues / 8162 <nl> + - " - / / src / java_tools / buildjar / . . . " <nl> + - " - / / src / java_tools / import_deps_checker / . . . " <nl> + # <nl> + - " - / / src / test / shell / bazel : bazel_cc_code_coverage_test " <nl> + - " - / / src / test / shell / bazel : bazel_coverage_cc_test_gcc " <nl> + - " - / / src / test / shell / bazel : bazel_coverage_sh_test " <nl> ubuntu1604 : <nl> shell_commands : <nl> - sed - i . bak - e ' s / ^ # android_sdk_repository / android_sdk_repository / ' - e ' s / ^ #
public class androidconfiguration extends buildconfiguration . fragment <nl> this . alwaysfilterduplicateclassesfromandroidtest = <nl> options . alwaysfilterduplicateclassesfromandroidtest ; <nl>  <nl> + / / make the value of - - android_aapt aapt2 if - - incompatible_use_aapt2_by_default is enabled <nl> + / / and - - android_aapt = auto <nl> + / / <nl> + / / we use the - - incompatible_use_aapt2_by_default flag to signal a breaking change in bazel . <nl> + / / this is required by the bazel incompatible changes policy . <nl> + / / <nl> + <nl> + if ( options . incompatibleuseaapt2bydefault <nl> + & & options . androidaaptversion = = androidaaptversion . auto ) { <nl> + this . androidaaptversion = androidaaptversion . aapt2 ; <nl> + } else { <nl> + this . androidaaptversion = options . androidaaptversion ; <nl> + } <nl> + <nl> if ( incrementaldexingshardsafterproguard < num ) { <nl> throw new invalidconfigurationexception ( <nl> " - - experimental_incremental_dexing_after_proguard must be a positive number " ) ;
<nl> + / / copyright num the bazel authors . all rights reserved . <nl> + / / <nl> + / / licensed under the apache license , version num . 0 ( the " license " ) ; <nl> + / / you may not use this file except in compliance with the license . <nl> + / / you may obtain a copy of the license at <nl> + / / <nl> + / / http : / / www . apache . org / licenses / license - 2 . 0 <nl> + / / <nl> + / / unless required by applicable law or agreed to in writing , software <nl> + / / distributed under the license is distributed on an " as is " basis , <nl> + / / without warranties or conditions of any kind , either express or implied . <nl> + / / see the license for the specific language governing permissions and <nl> + / / limitations under the license . <nl> + <nl> + package com . google . devtools . build . skydoc . renderer ; <nl> + <nl> + / * * <nl> + * main entry point for renderer binary . <nl> + * <nl> + * < p > this renderer will take in raw stardoc_proto protos as input and produce rich markdown output . <nl> + * / <nl> + public class renderermain { <nl> + <nl> + <nl> + public static void main ( string [ ] args ) { } <nl> + }
public class optionsparser implements optionsparsingresult { <nl> } <nl>  <nl> / * * <nl> - * indicates whether or not the parser will allow a non - empty residue ; that <nl> - * is , iff this value is true then a call to one of the { @ code parse } <nl> - * methods will throw { @ link optionsparsingexception } unless <nl> - * { @ link # getresidue ( ) } is empty after parsing . <nl> + * indicates whether or not the parser will allow a non - empty residue ; that is , iff this value is <nl> + * true then a call to one of the { @ code parse } methods will throw { @ link optionsparsingexception } <nl> + * unless { @ link # getresidue ( ) } is empty after parsing . <nl> * / <nl> + <nl> public void setallowresidue ( boolean allowresidue ) { <nl> this . allowresidue = allowresidue ; <nl> } <nl>
public class optionsparser implements optionsparsingresult { <nl> / * * <nl> * enables the parser to handle params files using the provided { @ link paramsfilepreprocessor } . <nl> * / <nl> + <nl> public void enableparamsfilesupport ( paramsfilepreprocessor preprocessor ) { <nl> this . impl . setargspreprocessor ( preprocessor ) ; <nl> }
public class objclibrary implements ruleconfiguredtargetfactory { <nl>  <nl> / * * throws errors or warnings for bad attribute state . * / <nl> private static void validateattributes ( rulecontext rulecontext ) throws ruleerrorexception { <nl> + <nl> + if ( rulecontext . gettarget ( ) . getname ( ) . indexof ( ' / ' ) ! = - 1 ) { <nl> + rulecontext . attributeerror ( " name " , " this attribute has unsupported character ' / ' " ) ; <nl> + } <nl> for ( string copt : objccommon . getnoncrosstoolcopts ( rulecontext ) ) { <nl> if ( copt . contains ( " - fmodules - cache - path " ) ) { <nl> rulecontext . rulewarning ( compilationsupport . modules_cache_path_warning ) ; <nl> mmm a / src / test / java / com / google / devtools / build / lib / rules / objc / objclibrarytest . java <nl> ppp b / src / test / java / com / google / devtools / build / lib / rules / objc / objclibrarytest . java <nl>
public final class objcprovider extends info implements objcproviderapi < artifact <nl> * / <nl> void addelementsfromskylark ( key < ? > key , object skylarktoadd ) throws evalexception { <nl> nestedset < ? > toadd = objcproviderskylarkconverters . converttojava ( key , skylarktoadd ) ; <nl> - uncheckedaddtransitive ( key , toadd , this . items ) ; <nl> + <nl> + uncheckedaddall ( key , toadd . tolist ( ) , this . items ) ; <nl> if ( objcprovider . keys_for_direct . contains ( key ) ) { <nl> uncheckedaddalldirect ( key , toadd , this . directitems ) ; <nl> }
public final class watchservicediffawareness extends localdiffawareness { <nl> / / contain files that are modified between init ( ) and poll ( ) below , because those are <nl> / / already taken into account for the current build , as we ended up with <nl> / / modifiedfileset . everything_modified in the current build . <nl> - boolean watchfs = options . getoptions ( options . class ) . watchfs ; <nl> + / / disable watchfs on windows , because it is not implemented correctly on windows . <nl> + <nl> + boolean watchfs = options . getoptions ( options . class ) . watchfs & & os . getcurrent ( ) ! = os . windows ; <nl> if ( watchfs & & watchservice = = null ) { <nl> init ( ) ; <nl> } else if ( ! watchfs & & ( watchservice ! = null ) ) {
public final class proxyspawnactioncontext implements spawnactioncontext { <nl> } <nl>  <nl> if ( strategies . isempty ( ) ) { <nl> - throw new userexecexception ( <nl> - string . format ( <nl> - " no usable spawn strategy found for spawn with mnemonic % s . are your - - spawn_strategy " <nl> - + " or - - strategy flags too strict ? " , <nl> - spawn . getmnemonic ( ) ) ) ; <nl> + <nl> + if ( listbasedexecutionstrategyselection ) { <nl> + throw new userexecexception ( <nl> + string . format ( <nl> + " no usable spawn strategy found for spawn with mnemonic % s . your - - spawn_strategy " <nl> + + " or - - strategy flags are probably too strict . " <nl> + + " visit https : / / github . com / bazelbuild / bazel / issues / 7480 for migration advises " , <nl> + spawn . getmnemonic ( ) ) ) ; <nl> + } else { <nl> + throw new userexecexception ( <nl> + string . format ( <nl> + " no usable spawn strategy found for spawn with mnemonic % s . " <nl> + + " are your - - spawn_strategy or - - strategy flags too strict ? " , <nl> + spawn . getmnemonic ( ) ) ) ; <nl> + } <nl> } <nl>  <nl> return strategies ;
public final class nestedsetbuilder < e > { <nl> * / <nl> public nestedsetbuilder < e > addall ( iterable < ? extends e > elements ) { <nl> preconditions . checknotnull ( elements ) ; <nl> + if ( elements instanceof nestedset ) { <nl> + nestedset < ? extends e > elementsasnestedset = ( nestedset < ? extends e > ) elements ; <nl> + if ( order . equals ( order . stable_order ) ) { <nl> + / / if direct / transitive order doesn ' t matter , add the nested set as a transitive member to <nl> + / / avoid copying its elements . <nl> + return addtransitive ( elementsasnestedset ) ; <nl> + } else { <nl> + / / direct / transitive order matters , but we might be able to save an iteration if we hit the <nl> + / / iterables . size call below with a list instead of a nested set . <nl> + <nl> + elements = elementsasnestedset . tolist ( ) ; <nl> + } <nl> + } <nl> if ( items = = null ) { <nl> items = compacthashset . createwithexpectedsize ( iterables . size ( elements ) ) ; <nl> } <nl>
sh_test ( <nl> ] , <nl> tags = [ <nl> " no_windows " , <nl> + # <nl> + " manual " , <nl> ] , <nl> ) <nl> for java_version in java_versions <nl> mmm a / tools / jdk / build . java_tools <nl> ppp b / tools / jdk / build . java_tools <nl>
build : remote - - extra_execution_platforms = / / : rbe_highcpu_platform <nl> build : remote - - host_platform = @ bazel_rbe_toolchains / / configs / bazel_0 . 25 . 0 / bazel - ubuntu1804 : default_platform <nl> build : remote - - platforms = @ bazel_rbe_toolchains / / configs / bazel_0 . 25 . 0 / bazel - ubuntu1804 : default_platform <nl>  <nl> - build : remote - - spawn_strategy = remote <nl> - build : remote - - strategy = javac = remote <nl> - build : remote - - strategy = closure = remote <nl> - build : remote - - strategy = genrule = remote <nl> + # <nl> + build : remote - - incompatible_list_based_execution_strategy_selection <nl> + <nl> build : remote - - define = executor = remote <nl>  <nl> build : remote - - remote_instance_name = projects / bazel - untrusted / instances / default_instance <nl>
public abstract class parallelvisitor < t , v > { <nl> / / num . errors ( queryexception or interruptedexception ) occurred and visitations should fail <nl> / / fast . <nl> / / num . there is no pending visit in the queue and no pending task running . <nl> - while ( ! mustjobsbestopped ( ) & & ( ! processingqueue . isempty ( ) | | gettaskcount ( ) > num ) ) { <nl> + while ( ! mustjobsbestopped ( ) & & morewor <nl> / / to achieve maximum efficiency , queue is drained in either of the following two <nl> / / conditions : <nl> / / <nl>
public abstract class parallelvisitor < t , v > { <nl> awaitterminationandpropagateerrorsifany ( ) ; <nl> } <nl>  <nl> + private boolean morewor <nl> + / / following race condition : <nl> + / / ( 1 ) check processing queue and observe that it is empty <nl> + / / ( 2 ) a remaining task adds to the processing queue and shuts down <nl> + / / ( 3 ) we check the task count and observe it is empty <nl> + return gettaskcount ( ) > num | | ! processingqueue . isempty ( ) ; <nl> + } <nl> + <nl> private void awaitterminationandpropagateerrorsifany ( ) <nl> throws queryexception , interruptedexception { <nl> try {
genrule ( <nl> tools = [ " / / src : zip_files " ] , <nl> ) <nl>  <nl> + filegroup ( <nl> + name = " transitive_sources " , <nl> + srcs = glob ( [ ' * - src . jar ' ] ) + [ " license " ] + [ <nl> + " / / third_party : asm / asm - 7 . 0 - sources . jar " , <nl> + " / / third_party : asm / asm - analysis - 7 . 0 - sources . jar " , <nl> + " / / third_party : asm / asm - commons - 7 . 0 - sources . jar " <nl> + ] , <nl> + ) <nl> + <nl> + # <nl> genrule ( <nl> name = " jacoco_source_jars_zip " , <nl> srcs = glob ( [ ' * - src . jar ' ] ) + [ " license " ] + [ <nl> mmm a / third_party / java / proguard / build <nl> ppp b / third_party / java / proguard / build <nl>
genrule ( <nl> visibility = [ " / / src : __pkg__ " ] , <nl> ) <nl>  <nl> + # <nl> genrule ( <nl> name = " proguard_srcs_zip " , <nl> srcs = [ " : srcs " ] , <nl>
public class applecommandlineoptions extends fragmentoptions { <nl> host . tvossdkversion = tvossdkversion ; <nl> host . macossdkversion = macossdkversion ; <nl> host . applebitcodemode = applebitcodemode ; <nl> + <nl> / / the host apple platform type will always be macos , as no other apple platform type can <nl> / / currently execute build actions . if that were the case , a host_apple_platform_type flag might <nl> / / be needed . <nl>
public class applecommandlineoptions extends fragmentoptions { <nl> return host ; <nl> } <nl>  <nl> + @ override <nl> + public fragmentoptions getexec ( ) { <nl> + applecommandlineoptions exec = ( applecommandlineoptions ) super . getexec ( ) ; <nl> + <nl> + / / currently execute build actions . <nl> + exec . appleplatformtype = platformtype . macos ; <nl> + return exec ; <nl> + } <nl> + <nl> void serialize ( serializationcontext context , codedoutputstream out ) <nl> throws ioexception , serializationexception { <nl> context . serialize ( this , out ) ;
public class cppoptions extends fragmentoptions { <nl> return host ; <nl> } <nl>  <nl> + @ override <nl> + public fragmentoptions getexec ( ) { <nl> + cppoptions exec = ( cppoptions ) super . getexec ( ) ; <nl> + <nl> + / / the crosstool options are partially copied from the target configuration . <nl> + if ( hostcrosstooltop ! = null ) { <nl> + exec . crosstooltop = hostcrosstooltop ; <nl> + exec . cppcompiler = hostcppcompiler ; <nl> + } <nl> + <nl> + / / hostlibctop doesn ' t default to the target ' s libctop . <nl> + / / only an explicit command - line option will change it . <nl> + / / the default is whatever the host ' s crosstool ( which might have been specified <nl> + / / by - - host_crosstool_top , or - - crosstool_top as a fallback ) says it should be . <nl> + exec . libctoplabel = hostlibctoplabel ; <nl> + <nl> + exec . targetlibctoplabel = libctoplabel ; <nl> + <nl> + / / - g0 is the default , but allowmultiple options cannot have default values so we just pass <nl> + / / - g0 first and let the user options override it . <nl> + immutablelist . builder < string > coptlistbuilder = immutablelist . builder ( ) ; <nl> + immutablelist . builder < string > cxxoptlistbuilder = immutablelist . builder ( ) ; <nl> + / / don ' t add - g0 if the host platform is windows . <nl> + / / note that host platform is not necessarily the platform bazel is running on ( foundry ) <nl> + if ( os . getcurrent ( ) ! = os . windows ) { <nl> + coptlistbuilder . add ( " - g0 " ) ; <nl> + cxxoptlistbuilder . add ( " - g0 " ) ; <nl> + } <nl> + exec . coptlist = coptlistbuilder . addall ( hostcoptlist ) . build ( ) ; <nl> + exec . cxxoptlist = cxxoptlistbuilder . addall ( hostcxxoptlist ) . build ( ) ; <nl> + exec . conlyoptlist = immutablelist . copyof ( hostconlyoptlist ) ; <nl> + exec . linkoptlist = immutablelist . copyof ( hostlinkoptlist ) ; <nl> + <nl> + exec . stripbinaries = stripmode . always ; <nl> + <nl> + return exec ; <nl> + } <nl> + <nl> / * * <nl> * returns true if targets under this configuration should apply fdo . <nl> * /
public class buildviewtest extends buildviewtestbase { <nl> / / regression test : " output_filter broken ( but in a different way ) " <nl> @ test <nl> public void testoutputfilterseewarning ( ) throws exception { <nl> + if ( defaultflags ( ) . contains ( flag . trimmed_configurations ) ) { <nl> + <nl> + return ; <nl> + } <nl> runanalysiswithoutputfilter ( pattern . compile ( " . * " ) ) ; <nl> assertcontainsevent ( " please do not import ' / / java / a : a . java ' " ) ; <nl> } <nl>
public class buildviewtest extends buildviewtestbase { <nl> * / <nl> @ test <nl> public void testmultibuildinvalidationrevalidation ( ) throws exception { <nl> + if ( defaultflags ( ) . contains ( flag . trimmed_configurations ) ) { <nl> + <nl> + return ; <nl> + } <nl> scratch . file ( " java / a / a . java " , " bla1 " ) ; <nl> scratch . file ( " java / a / c . java " , " bla2 " ) ; <nl> scratch . file ( " java / a / build " ,
public class ruleclass { <nl>  <nl> for ( attribute attribute : parent . getattributes ( ) ) { <nl> string attrname = attribute . getname ( ) ; <nl> + <nl> + if ( attrname . equals ( ruleclass . exec_compatible_with_attr ) ) { <nl> + / / don ' t inherit : this will be re - created <nl> + continue ; <nl> + } <nl> preconditions . checkargument ( <nl> ! attributes . containskey ( attrname ) | | attributes . get ( attrname ) . equals ( attribute ) , <nl> " attribute % s is inherited multiple times in % s ruleclass " , <nl> mmm a / src / main / java / com / google / devtools / build / lib / rules / genrule / genrulebaserule . java <nl> ppp b / src / main / java / com / google / devtools / build / lib / rules / genrule / genrulebaserule . java <nl>
public final class buildoptions implements cloneable , serializable { <nl> * / <nl> public static configurationcomparer . result comparefragments ( <nl> optionsdiffforreconstruction left , optionsdiffforreconstruction right ) { <nl> + <nl> preconditions . checkargument ( <nl> arrays . equals ( left . basefingerprint , right . basefingerprint ) , <nl> " can ' t compare diffs with different bases : % s and % s " ,
function test_glob_control_chars ( ) { <nl> done <nl> } <nl>  <nl> - function test_glob_utf8 ( ) { <nl> + # <nl> + function disabled_test_glob_utf8 ( ) { <nl> local - r pkg = " $ funcname " <nl> mkdir $ pkg <nl> echo " filegroup ( name = ' t ' , srcs = glob ( [ ' * ' ] ) ) " > $ pkg / build
public interface skylarknativemoduleapi { <nl> @ param ( <nl> name = " name " , <nl> type = string . class , <nl> + <nl> legacynamed = true , <nl> doc = " the name of the target . " ) <nl> } , <nl>
public class buildviewfortesting { <nl> try { <nl> target = skyframeexecutor . getpackagemanager ( ) . gettarget ( handler , label ) ; <nl> } catch ( nosuchpackageexception | nosuchtargetexception e ) { <nl> + <nl> + / / method and many test cases rely on not erroring out here so be able to reach an error <nl> + / / later on . <nl> return notransition . instance ; <nl> } catch ( interruptedexception e ) { <nl> thread . currentthread ( ) . interrupt ( ) ;
public final class configuredtargetfunction implements skyfunction { <nl> super ( e , transience . persistent ) ; <nl> } <nl> } <nl> + <nl> + <nl> + public static label labelwithundonepackagetodiagnosebug = null ; <nl> }
public class protolangtoolchain implements ruleconfiguredtargetfactory { <nl> public configuredtarget create ( rulecontext rulecontext ) <nl> throws interruptedexception , ruleerrorexception , actionconflictexception { <nl> nestedsetbuilder < artifact > blacklistedprotos = nestedsetbuilder . stableorder ( ) ; <nl> - for ( fileprovider protos : <nl> - rulecontext . getprerequisites ( " blacklisted_protos " , target , fileprovider . class ) ) { <nl> - blacklistedprotos . addtransitive ( protos . getfilestobuild ( ) ) ; <nl> + for ( transitiveinfocollection protos : <nl> + rulecontext . getprerequisites ( " blacklisted_protos " , target ) ) { <nl> + blacklistedprotos . addtransitive ( protos . getprovider ( fileprovider . class ) . getfilestobuild ( ) ) ; <nl> + protoinfo protoinfo = protos . get ( protoinfo . provider ) ; <nl> + <nl> + if ( protoinfo ! = null ) { <nl> + blacklistedprotos . addall ( protoinfo . getdirectprotosources ( ) ) ; <nl> + } <nl> } <nl>  <nl> return new ruleconfiguredtargetbuilder ( rulecontext )
public class javaskylarkapitest extends buildviewtestcase { <nl>  <nl> useconfiguration ( <nl> " - - javabase = / / a : jvm " , " - - extra_toolchains = / / a : all " , " - - platforms = / / a : platform " ) ; <nl> + <nl> + configuredtarget genrule = gethostconfiguredtarget ( " / / a : gen " ) ; <nl> configuredtarget ct = getconfiguredtarget ( " / / a : r " ) ; <nl> @ suppresswarnings ( " unchecked " ) <nl> pathfragment javahomeexecpath = ( pathfragment ) ct . get ( " java_home_exec_path " ) ; <nl> assertthat ( javahomeexecpath . getpathstring ( ) ) <nl> - . isequalto ( getgenfilesartifactwithnoowner ( " a / foo / bar " ) . getexecpathstring ( ) ) ; <nl> + . isequalto ( getgenfilesartifact ( " foo / bar " , genrule ) . getexecpathstring ( ) ) ; <nl> @ suppresswarnings ( " unchecked " ) <nl> pathfragment javaexecutableexecpath = ( pathfragment ) ct . get ( " java_executable_exec_path " ) ; <nl> assertthat ( javaexecutableexecpath . getpathstring ( ) ) <nl> - . startswith ( getgenfilesartifactwithnoowner ( " a / foo / bar / bin / java " ) . getexecpathstring ( ) ) ; <nl> + . startswith ( getgenfilesartifact ( " foo / bar / bin / java " , genrule ) . getexecpathstring ( ) ) ; <nl> @ suppresswarnings ( " unchecked " ) <nl> pathfragment javahomerunfilespath = ( pathfragment ) ct . get ( " java_home_runfiles_path " ) ; <nl> assertthat ( javahomerunfilespath . getpathstring ( ) ) . isequalto ( " a / foo / bar " ) ; <nl> mmm a / src / test / java / com / google / devtools / build / lib / testutil / testconstants . java <nl> ppp b / src / test / java / com / google / devtools / build / lib / testutil / testconstants . java <nl>
public final class pycommon { <nl> " the python toolchain does not provide a runtime for python version % s " , <nl> version . name ( ) ) ) ; <nl> } <nl> + <nl> + / / hack around the fact that the autodetecting python toolchain , which is automatically <nl> + / / registered , does not yet support windows . in this case , we want to return null so that <nl> + / / bazelpythonsemantics falls back on - - python_path . see toolchain . bzl . <nl> + <nl> + if ( py2runtimeinfo ! = null <nl> + & & py2runtimeinfo . getinterpreterpathstring ( ) ! = null <nl> + & & py2runtimeinfo <nl> + . getinterpreterpathstring ( ) <nl> + . equals ( " / _magic_pyruntime_sentinel_do_not_use " ) ) { <nl> + return null ; <nl> + } <nl> + <nl> return result ; <nl> } <nl>  <nl> mmm a / tools / python / build . tools <nl> ppp b / tools / python / build . tools <nl>
public abstract class abstractparallelevaluator { <nl> static boolean isdoneforbuild ( @ nullable nodeentry entry ) { <nl> return entry ! = null & & entry . isdone ( ) ; <nl> } <nl> + <nl> + <nl> + public static skykey missingskykeytodiagnosebug = null ; <nl> + <nl> + static boolean matchesmissingskykey ( skykey key ) { <nl> + return ( missingskykeytodiagnosebug ! = null & & missingskykeytodiagnosebug . equals ( key ) ) ; <nl> + } <nl> } <nl> mmm a / src / main / java / com / google / devtools / build / skyframe / skyfunctionenvironment . java <nl> ppp b / src / main / java / com / google / devtools / build / skyframe / skyfunctionenvironment . java <nl>
<nl> + / / copyright num the bazel authors . all rights reserved . <nl> + / / <nl> + / / licensed under the apache license , version num . 0 ( the " license " ) ; <nl> + / / you may not use this file except in compliance with the license . <nl> + / / you may obtain a copy of the license at <nl> + / / <nl> + / / http : / / www . apache . org / licenses / license - 2 . 0 <nl> + / / <nl> + / / unless required by applicable law or agreed to in writing , software <nl> + / / distributed under the license is distributed on an " as is " basis , <nl> + / / without warranties or conditions of any kind , either express or implied . <nl> + / / see the license for the specific language governing permissions and <nl> + / / limitations under the license . <nl> + package com . google . devtools . build . android . desugar . runtime ; <nl> + <nl> + import android . telephony . availablenetworkinfo ; <nl> + import android . telephony . telephonymanager ; <nl> + import java . util . list ; <nl> + import java . util . concurrent . executor ; <nl> + import java . util . function . consumer ; <nl> + <nl> + / * * <nl> + * conversion from desugared to built - in { @ link consumer } for calling built - in android apis ( see <nl> + * b / 128638076 ) . <nl> + * / <nl> + <nl> + @ suppresswarnings ( " androidjdklibschecker " ) <nl> + public final class consumerwrapper < t > implements consumer < t > { <nl> + <nl> + private final j $ . util . function . consumer < t > wrapped ; <nl> + <nl> + private consumerwrapper ( j $ . util . function . consumer < t > wrapped ) { <nl> + this . wrapped = wrapped ; <nl> + } <nl> + <nl> + @ override <nl> + public void accept ( t t ) { <nl> + wrapped . accept ( t ) ; <nl> + } <nl> + <nl> + public static void setpreferredopportunisticdatasubscription ( <nl> + telephonymanager receiver , <nl> + int subid , <nl> + boolean needvalidation , <nl> + executor executor , <nl> + j $ . util . function . consumer < integer > callback ) { <nl> + receiver . setpreferredopportunisticdatasubscription ( <nl> + subid , <nl> + needvalidation , <nl> + executor , <nl> + callback ! = null ? new consumerwrapper < integer > ( callback ) : null ) ; <nl> + } <nl> + <nl> + public static void updateavailablenetworks ( <nl> + telephonymanager receiver , <nl> + list < availablenetworkinfo > availablenetworks , <nl> + executor executor , <nl> + j $ . util . function . consumer < integer > callback ) { <nl> + receiver . updateavailablenetworks ( <nl> + availablenetworks , <nl> + executor , <nl> + callback ! = null ? new consumerwrapper < integer > ( callback ) : null ) ; <nl> + } <nl> + }
import javax . annotation . nullable ; <nl> public class blazejavacresult { <nl> / * * the compilation result . * / <nl> public enum status { <nl> - ok , <nl> - error , <nl> - requires_fallback , <nl> + ok ( 0 ) , <nl> + error ( 1 ) , <nl> + <nl> + requires_fallback ( 1 ) ; <nl> + <nl> + private final int exitcode ; <nl> + <nl> + private status ( int exitcode ) { <nl> + this . exitcode = exitcode ; <nl> + } <nl> + <nl> + public int exitcode ( ) { <nl> + return exitcode ; <nl> + } <nl> } <nl>  <nl> private final status status ;
<nl> + / / copyright num the bazel authors . all rights reserved . <nl> + / / <nl> + / / licensed under the apache license , version num . 0 ( the " license " ) ; <nl> + / / you may not use this file except in compliance with the license . <nl> + / / you may obtain a copy of the license at <nl> + / / <nl> + / / http : / / www . apache . org / licenses / license - 2 . 0 <nl> + / / <nl> + / / unless required by applicable law or agreed to in writing , software <nl> + / / distributed under the license is distributed on an " as is " basis , <nl> + / / without warranties or conditions of any kind , either express or implied . <nl> + / / see the license for the specific language governing permissions and <nl> + / / limitations under the license . <nl> + package com . google . devtools . build . lib . analysis . config . transitions ; <nl> + <nl> + import com . google . devtools . build . lib . analysis . config . transitions . transitionfactory . transitionfactorydata ; <nl> + <nl> + / * * <nl> + * factory interface for transitions that are created dynamically , instead of being created as <nl> + * singletons . <nl> + * <nl> + * < p > this class allows for cases where the general < i > type < / i > of a transition is known , but the <nl> + * specifics of the transition itself cannot be determined until the target is configured . examples <nl> + * of this are transitions that depend on other ( non - configured ) attributes from the same target , or <nl> + * transitions that depend on state determined during configuration , such as the execution platform <nl> + * or resolved toolchains . <nl> + * <nl> + * < p > implementations must override { @ link object # equals } and { @ link object # hashcode } unless <nl> + * exclusively accessed as singletons . <nl> + * <nl> + * @ param < t > the type of data object passed to the { @ link # create } method , used to create the <nl> + * actual { @ link configurationtransition } instance <nl> + * / <nl> + public interface transitionfactory < t extends transitionfactorydata > { <nl> + <nl> + / * * interface for types of data that a { @ link transitionfactory } can use . * / <nl> + interface transitionfactorydata { } <nl> + <nl> + / * * returns a new { @ link configurationtransition } , based on the given data . * / <nl> + configurationtransition create ( t data ) ; <nl> + <nl> + <nl> + / * * returns { @ code true } if the result of this { @ link transitionfactory } is a host transition . * / <nl> + default boolean ishost ( ) { <nl> + return false ; <nl> + } <nl> + <nl> + / * * returns { @ code true } if the result of this { @ link transitionfactory } is a split transition . * / <nl> + default boolean issplit ( ) { <nl> + return false ; <nl> + } <nl> + <nl> + / * * returns { @ code true } if the result of this { @ link transitionfactory } is a final transition . * / <nl> + default boolean isfinal ( ) { <nl> + return false ; <nl> + } <nl> + } <nl> mmm / dev / null <nl> ppp b / src / main / java / com / google / devtools / build / lib / packages / ruletransitiondata . java <nl>
<nl> + / / copyright num the bazel authors . all rights reserved . <nl> + / / <nl> + / / licensed under the apache license , version num . 0 ( the " license " ) ; <nl> + / / you may not use this file except in compliance with the license . <nl> + / / you may obtain a copy of the license at <nl> + / / <nl> + / / http : / / www . apache . org / licenses / license - 2 . 0 <nl> + / / <nl> + / / unless required by applicable law or agreed to in writing , software <nl> + / / distributed under the license is distributed on an " as is " basis , <nl> + / / without warranties or conditions of any kind , either express or implied . <nl> + / / see the license for the specific language governing permissions and <nl> + / / limitations under the license . <nl> + package com . google . devtools . build . lib . packages ; <nl> + <nl> + import com . google . auto . value . autovalue ; <nl> + import com . google . devtools . build . lib . analysis . config . transitions . transitionfactory ; <nl> + <nl> + / * * <nl> + * helper class which contains data used by a { @ link transitionfactory } to create a transition for <nl> + * rules and attributes . <nl> + * / <nl> + / / this class is in lib . packages in order to access attributemap , which is not available to <nl> + / / the lib . analysis . config . transitions package . <nl> + @ autovalue <nl> + public abstract class ruletransitiondata implements transitionfactory . transitionfactorydata { <nl> + / * * returns the { @ link attributemap } which can be used to create a transition . * / <nl> + public abstract attributemap attributes ( ) ; <nl> + <nl> + <nl> + <nl> + / * * returns a new { @ link ruletransitiondata } instance . * / <nl> + public static ruletransitiondata create ( attributemap attributes ) { <nl> + return new autovalue_ruletransitiondata ( attributes ) ; <nl> + } <nl> + }
public abstract class dependencyresolver { <nl> collectpropagatingaspects ( <nl> aspects , attribute . getname ( ) , entry . getkey ( ) . getowningaspect ( ) , propagatingaspects ) ; <nl>  <nl> + <nl> configurationtransition attributetransition = <nl> attribute . hassplitconfigurationtransition ( ) <nl> ? attribute . getsplittransition ( attributemap ) <nl> - : attribute . getconfigurationtransition ( ) ; <nl> + : attribute . getconfigurationtransition ( attributemap ) ; <nl> partiallyresolveddeps . put ( <nl> entry . getkey ( ) , <nl> partiallyresolveddependency . of ( tolabel , attributetransition , propagatingaspects . build ( ) ) ) ; <nl> mmm a / src / main / java / com / google / devtools / build / lib / analysis / rulecontext . java <nl> ppp b / src / main / java / com / google / devtools / build / lib / analysis / rulecontext . java <nl>
public final class rulecontext extends targetcontext <nl> throw new illegalstateexception ( getruleclassnameforlogging ( ) + " attribute " + attributename <nl> + " is not a label type attribute " ) ; <nl> } <nl> - configurationtransition transition = attributedefinition . getconfigurationtransition ( ) ; <nl> + <nl> + configurationtransition transition = attributedefinition . getconfigurationtransition ( null ) ; <nl> if ( mode = = mode . host ) { <nl> if ( ! ( transition instanceof patchtransition ) ) { <nl> throw new illegalstateexception ( getrule ( ) . getlocation ( ) + " : " <nl> mmm a / src / main / java / com / google / devtools / build / lib / packages / attribute . java <nl> ppp b / src / main / java / com / google / devtools / build / lib / packages / attribute . java <nl>
else <nl> fi <nl>  <nl> function test_bootstrap ( ) { <nl> + execute_bootstrap " - - host_javabase = @ local_jdk / / : jdk " <nl> + } <nl> + <nl> + # <nl> + function test_bootstrap_with_cc_rules_using_platforms ( ) { <nl> + execute_bootstrap " - - host_javabase = @ local_jdk / / : jdk " \ <nl> + " - - incompatible_enable_cc_toolchain_resolution " <nl> + } <nl> + <nl> + function execute_bootstrap ( ) { <nl> cd " $ ( mktemp - d $ { test_tmpdir } / bazelbootstrap . xxxxxxxx ) " <nl> export source_date_epoch = 1501234567 <nl> unzip - q " $ { distfile } " <nl>
filegroup ( <nl> visibility = [ " / / visibility : public " ] , <nl> ) <nl>  <nl> - # these files are embedded into the remote java tools <nl> - # because they are needed by ijar . <nl> + # <nl> filegroup ( <nl> name = " embed_into_java_tools " , <nl> srcs = glob ( [ " * . cc " ] ) + glob ( [ " * . h " ] ) , <nl> visibility = [ " / / visibility : public " ] , <nl> ) <nl> + <nl> + pkg_tar ( <nl> + name = " cpp_util_with_deps_archive " , <nl> + extension = " tar . gz " , <nl> + mode = " 755 " , <nl> + visibility = [ " / / third_party / ijar : __pkg__ " ] , <nl> + deps = [ <nl> + " : cpp_util_archive " , <nl> + " / / src / main / native / windows : src_main_native_windows " , <nl> + ] , <nl> + ) <nl> + <nl> + pkg_tar ( <nl> + name = " cpp_util_archive " , <nl> + srcs = glob ( [ " * . cc " ] ) + glob ( [ " * . h " ] ) , <nl> + extension = " tar . gz " , <nl> + mode = " 755 " , <nl> + # create a pkg_tar to preserve the directory structure src / main / cpp / util . <nl> + package_dir = " src / main / cpp / util " , <nl> + visibility = [ " / / visibility : private " ] , <nl> + ) <nl> mmm a / src / main / native / windows / build <nl> ppp b / src / main / native / windows / build <nl>
filegroup ( <nl> visibility = [ " / / visibility : public " ] , <nl> ) <nl>  <nl> + # <nl> filegroup ( <nl> name = " embed_into_java_tools " , <nl> srcs = glob ( <nl>
public final class buildtype { <nl> return ( tristate ) x ; <nl> } <nl> if ( x instanceof boolean ) { <nl> - throw new conversionexception ( <nl> - this , <nl> - x , <nl> - " rule attribute ( tristate is being replaced by " <nl> - + " attr . int ( values = [ - 1 , num , num ] ) , and it no longer accepts boolean values ; " <nl> - + " instead , use num or num , or none for the default ) " ) ; <nl> + <nl> + / / " rule attribute ( tristate is being replaced by " <nl> + / / + " attr . int ( values = [ - 1 , num , num ] ) , and it no longer accepts boolean values ; " <nl> + / / + " instead , use num or num , or none for the default ) " ) ; <nl> + return ( ( boolean ) x ) ? tristate . yes : tristate . no ; <nl> } <nl> integer xasinteger = integer . convert ( x , what , context ) ; <nl> if ( xasinteger = = - 1 ) { <nl> mmm a / src / test / java / com / google / devtools / build / lib / syntax / typetest . java <nl> ppp b / src / test / java / com / google / devtools / build / lib / syntax / typetest . java <nl>
public class typetest { <nl> } <nl>  <nl> @ test <nl> - public void testtristatedoesnotacceptstringsorbools ( ) throws exception { <nl> - list < ? > listofcases = lists . newarraylist ( " bad " , " true " , " auto " , " false " , true , false ) ; <nl> + public void testtristatedoesnotacceptstrings ( ) throws exception { <nl> + list < ? > listofcases = lists . newarraylist ( " bad " , " true " , " auto " , " false " ) ; <nl> + <nl> for ( object entry : listofcases ) { <nl> try { <nl> buildtype . tristate . convert ( entry , null ) ;
function test_no_arguments ( ) { <nl> expect_log " usage : b \ \ ( laze \ \ | azel \ \ ) " <nl> } <nl>  <nl> - <nl> function test_max_idle_secs ( ) { <nl> - # remove when https : / / github . com / bazelbuild / bazel / issues / 6773 is fixed . <nl> + # <nl> bazel shutdown <nl>  <nl> - local server_pid1 = $ ( bazel - - max_idle_secs = 1 info server_pid num > $ test_log ) <nl> - sleep num <nl> - local server_pid2 = $ ( bazel info server_pid num > $ test_log ) <nl> - assert_not_equals " $ server_pid1 " " $ server_pid2 " # pid changed . <nl> + local options = ( - - max_idle_secs = 1 ) <nl> + <nl> + local output_base <nl> + output_base = " $ ( bazel " $ { options [ @ ] } " info output_base num > " $ test_log " ) " \ <nl> + | | fail " bazel info failed " <nl> + local timeout = 60 # lower than the default - - max_idle_secs . <nl> + while [ [ - f " $ { output_base } / server / server . pid . txt " ] ] ; do <nl> + timeout = " $ ( ( $ { timeout } - num ) ) " <nl> + [ [ " $ { timeout } " - gt num ] ] | | fail " - - max_idle_secs was not respected " <nl> + <nl> + # wait for the server to go away . <nl> + sleep num <nl> + done <nl> + <nl> + bazel " $ { options [ @ ] } " info > " $ test_log " num > & 1 | | fail " bazel info failed " <nl> + expect_log " starting local . * server and connecting to it " <nl> + # ensure the restart was not triggered by different startup options . <nl> expect_not_log " warning : running b \ \ ( azel \ \ | laze \ \ ) server needs to be killed " <nl> }
public final class dexarchiveaspect extends nativeaspectclass implements configu <nl> / / these are all transitive hjars of dependencies and hjar of the jar itself <nl> nestedset < artifact > compiletimeclasspath = <nl> getjavacompilationargsprovider ( base , rulecontext ) . gettransitivecompiletimejars ( ) ; <nl> + immutableset . builder < artifact > jars = immutableset . builder ( ) ; <nl> + jars . addall ( javainfo . getdirectruntimejars ( ) ) ; <nl> + <nl> + / / if the target is an android_library , it may be a starlark android_library in which case <nl> + / / get the r . jar from the androidideinfoprovider . <nl> + if ( isandroidlibrary ( rulecontext ) ) { <nl> + artifact rjar = getandroidlibraryrjar ( base ) ; <nl> + if ( rjar ! = null ) { <nl> + <nl> + jars . add ( rjar ) ; <nl> + } <nl> + } <nl> + <nl> / / for android_ * targets we need to honor their bootclasspath ( nicer in general to do so ) <nl> immutablelist < artifact > bootclasspath = getbootclasspath ( base , rulecontext ) ; <nl>  <nl> - <nl> - boolean basenameclash = checkbasenameclash ( javainfo . getdirectruntimejars ( ) ) ; <nl> - for ( artifact jar : javainfo . getdirectruntimejars ( ) ) { <nl> + immutableset < artifact > jarstoprocess = jars . build ( ) ; <nl> + boolean basenameclash = checkbasenameclash ( jarstoprocess ) ; <nl> + for ( artifact jar : jarstoprocess ) { <nl> artifact desugared = <nl> createdesugaraction ( <nl> rulecontext , basenameclash , jar , bootclasspath , compiletimeclasspath ) ; <nl>
public class memoizingevaluatortest { <nl> * evaluation depending on a node in error . <nl> * / <nl> @ test <nl> + @ ignore <nl> public void shutdownbuildoncachederror_done ( ) throws exception { <nl> / / errorkey will be invalidated due to its dependence on invalidatedkey , but later revalidated <nl> / / since invalidatedkey re - evaluates to the same value on a subsequent build .
public class bazeljavasemantics implements javasemantics { <nl> " classpath " , <nl> " ; " , <nl> iterables . transform ( classpath , artifact . root_relative_path_string ) ) <nl> - . addjoinedvalues ( " jvm_flags " , " " , jvmflags ) <nl> + <nl> + / / flags , joined by tab characters . the launcher splits up the string to get the <nl> + / / individual jvm_flags . this approach breaks with flags that contain a tab character . <nl> + . addjoinedvalues ( " jvm_flags " , " \ t " , jvmflags ) <nl> . build ( ) ; <nl>  <nl> launcherfilewriteaction . createandregister ( rulecontext , javalauncher , launchinfo ) ; <nl> mmm a / src / tools / launcher / java_launcher . cc <nl> ppp b / src / tools / launcher / java_launcher . cc <nl>
public final class objcprovider extends info implements objcproviderapi < artifact <nl> immutablelist . < key < ? > > of ( <nl> asset_catalog , <nl> bundle_file , <nl> - merge_zip , <nl> + <nl> root_merge_zip , <nl> storyboard , <nl> strings ,
eof <nl> - - spawn_strategy = remote \ <nl> - - remote_executor = localhost : $ { worker_port } \ <nl> - - test_output = errors \ <nl> + - - noexperimental_split_xml_generation \ <nl> + / / a : test > & $ test_log \ <nl> + | | fail " failed to run / / a : test with remote execution " <nl> + } <nl> + <nl> + function test_cc_test_split_xml ( ) { <nl> + if [ [ " $ platform " = = " darwin " ] ] ; then <nl> + # <nl> + # setting sdkroot and developer_dir appropriately , as is required of <nl> + # action executors in order to select the appropriate xcode toolchain . <nl> + return num <nl> + fi <nl> + <nl> + mkdir - p a <nl> + cat > a / build < < eof <nl> + package ( default_visibility = [ " / / visibility : public " ] ) <nl> + cc_test ( <nl> + name = ' test ' , <nl> + srcs = [ ' test . cc ' ] , <nl> + ) <nl> + eof <nl> + cat > a / test . cc < < eof <nl> + # include < iostream > <nl> + int main ( ) { std : : cout < < " hello test ! " < < std : : endl ; return num ; } <nl> + eof <nl> + bazel test \ <nl> + - - spawn_strategy = remote \ <nl> + - - remote_executor = localhost : $ { worker_port } \ <nl> + - - test_output = errors \ <nl> + - - experimental_split_xml_generation \ <nl> / / a : test > & $ test_log \ <nl> | | fail " failed to run / / a : test with remote execution " <nl> }
public abstract class librarytolinkwrapper implements librarytolinkwrapperapi < ar <nl> public static final class linkstamp { <nl> private final artifact artifact ; <nl> private final nestedset < artifact > declaredincludesrcs ; <nl> - <nl> - linkstamp ( artifact artifact , nestedset < artifact > declaredincludesrcs ) { <nl> + private final byte [ ] nesteddigest ; <nl> + <nl> + <nl> + / / happen , so doing an expensive digest should be ok then . <nl> + linkstamp ( <nl> + artifact artifact , <nl> + nestedset < artifact > declaredincludesrcs , <nl> + actionkeycontext actionkeycontext ) { <nl> this . artifact = preconditions . checknotnull ( artifact ) ; <nl> this . declaredincludesrcs = preconditions . checknotnull ( declaredincludesrcs ) ; <nl> + fingerprint fp = new fingerprint ( ) ; <nl> + actionkeycontext . addnestedsettofingerprint ( fp , this . declaredincludesrcs ) ; <nl> + nesteddigest = fp . digestandreset ( ) ; <nl> } <nl>  <nl> / * * returns the linkstamp artifact . * / <nl>
public class dumpplatformclasspath { <nl> je . settime ( fixed_timestamp ) ; <nl> je . setmethod ( zipentry . stored ) ; <nl> byte [ ] bytes = tobytearray ( input ) ; <nl> + / / when targeting jdk > = num , patch the major version so it will be accepted by javac num <nl> + <nl> + if ( bytes [ 7 ] > num ) { <nl> + bytes [ 7 ] = num ; <nl> + } <nl> je . setsize ( bytes . length ) ; <nl> crc32 crc = new crc32 ( ) ; <nl> crc . update ( bytes ) ;
public final class mergedconfiguredtarget extends abstractconfiguredtarget { <nl> protected object rawgetskylarkprovider ( string providerkey ) { <nl> if ( providerkey . equals ( ruleconfiguredtarget . actions_field_name ) ) { <nl> immutablelist . builder < actionanalysismetadata > actions = immutablelist . builder ( ) ; <nl> + / / only expose actions which are skylarkvalues . <nl> + <nl> for ( configuredaspect aspect : aspects ) { <nl> - actions . addall ( aspect . getactions ( ) ) ; <nl> + actions . addall ( <nl> + aspect . getactions ( ) . stream ( ) . filter ( action - > action instanceof actionapi ) . iterator ( ) ) ; <nl> } <nl> if ( base instanceof ruleconfiguredtarget ) { <nl> - actions . addall ( ( ( ruleconfiguredtarget ) base ) . getactions ( ) ) ; <nl> + actions . addall ( <nl> + ( ( ruleconfiguredtarget ) base ) <nl> + . getactions ( ) . stream ( ) . filter ( action - > action instanceof actionapi ) . iterator ( ) ) ; <nl> } <nl> return actions . build ( ) ; <nl> }
public abstract class nativedepshelper { <nl> fp . addstring ( input . getexecpathstring ( ) ) ; <nl> linkstampssize + + ; <nl> } <nl> + <nl> + string linkstampsstring = integer . tostring ( linkstampssize ) ; <nl> + if ( linkstampssize > num ) { <nl> + set < artifact > identityset = sets . newidentityhashset ( ) ; <nl> + iterables . addall ( identityset , linkstamps ) ; <nl> + if ( identityset . size ( ) < linkstampssize ) { <nl> + linkstampsstring + = " _ " + identityset . size ( ) ; <nl> + } <nl> + immutableset < artifact > uniquelinkstamps = immutableset . copyof ( linkstamps ) ; <nl> + if ( uniquelinkstamps . size ( ) < linkstampssize ) { <nl> + linkstampsstring + = " __ " + uniquelinkstamps . size ( ) ; <nl> + } <nl> + } <nl> int buildinfosize = num ; <nl> for ( artifact input : buildinfoartifacts ) { <nl> fp . addstring ( input . getexecpathstring ( ) ) ; <nl>
public final class packagefactory { <nl> continue ; <nl> } <nl>  <nl> + <nl> + if ( attr . getname ( ) . equals ( " python_version " ) ) { <nl> + / / python_version is guarded by experimental flags , which breaks the use case of copying <nl> + / / targets around using native . existing_rules . see # 7071 and ( google - internal ) b / 122596733 . <nl> + continue ; <nl> + } <nl> + <nl> try { <nl> object val = skylarkifyvalue ( cont . getattr ( attr . getname ( ) ) , target . getpackage ( ) ) ; <nl> if ( val = = null ) { <nl> mmm a / src / main / java / com / google / devtools / build / lib / rules / python / pythonoptions . java <nl> ppp b / src / main / java / com / google / devtools / build / lib / rules / python / pythonoptions . java <nl>
public class androidbinarytest extends androidbuildviewtestcase { <nl> @ test <nl> public void androidmanifestmergerorderalphabetical_mergeessortedbyexecpath ( ) throws exception { <nl> / / hack : avoid the android split transition by turning off fat_apk_cpu / android_cpu . <nl> + / / this is necessary because the transition would change the configuration directory , causing <nl> + / / the manifest paths in the assertion not to match . <nl> + <nl> useconfiguration ( <nl> " - - fat_apk_cpu = " , " - - android_cpu = " , " - - android_manifest_merger_order = alphabetical " ) ; <nl> scratch . overwritefile ( <nl>
public class androidbinarytest extends androidbuildviewtestcase { <nl> @ test <nl> public void androidmanifestmergerorderdependencies_mergeessortedbydeporder ( ) throws exception { <nl> / / hack : avoid the android split transition by turning off fat_apk_cpu / android_cpu . <nl> + / / this is necessary because the transition would change the configuration directory , causing <nl> + / / the manifest paths in the assertion not to match . <nl> + <nl> useconfiguration ( <nl> " - - fat_apk_cpu = " , " - - android_cpu = " , " - - android_manifest_merger_order = dependency " ) ; <nl> scratch . overwritefile (
eof <nl> expect_log " common using python num " <nl> } <nl>  <nl> + # <nl> + # a separate suite . <nl> + <nl> + # tests that a non - standard library module on the pythonpath added by bazel <nl> + # can override the standard library . this behavior is not necessarily ideal , but <nl> + # it is the current semantics ; see # 6532 about changing that . <nl> + function test_source_file_does_not_override_standard_library ( ) { <nl> + mkdir - p test <nl> + <nl> + cat > test / build < < eof <nl> + py_binary ( <nl> + name = " main " , <nl> + srcs = [ " main . py " ] , <nl> + deps = [ " : lib " ] , <nl> + # pass the empty string , to include the path to this package ( within <nl> + # runfiles ) on the pythonpath . <nl> + imports = [ " " ] , <nl> + ) <nl> + <nl> + py_library ( <nl> + name = " lib " , <nl> + # a src name that clashes with a standard library module , such that this <nl> + # local file can take precedence over the standard one depending on its <nl> + # order in pythonpath . not just any module name would work . for instance , <nl> + # " import sys " gets the built - in module regardless of whether there ' s some <nl> + # " sys . py " file on the pythonpath . this is probably because built - in modules <nl> + # ( i . e . , those implemented in c ) use a different loader than <nl> + # python - implemented ones , even though they ' re both part of the standard <nl> + # distribution of the interpreter . <nl> + srcs = [ " re . py " ] , <nl> + ) <nl> + eof <nl> + cat > test / main . py < < eof <nl> + import re <nl> + eof <nl> + cat > test / re . py < < eof <nl> + print ( " i am lib ! " ) <nl> + eof <nl> + <nl> + bazel run / / test : main \ <nl> + & > $ test_log | | fail " bazel run failed " <nl> + # indicates that the local module overrode the system one . <nl> + expect_log " i am lib ! " <nl> + } <nl> + <nl> run_suite " tests for how the python rules handle python num vs python num " <nl> mmm a / src / test / shell / integration / python_test . sh <nl> ppp b / src / test / shell / integration / python_test . sh <nl>
<nl> + / / copyright num the bazel authors . all rights reserved . <nl> + / / <nl> + / / licensed under the apache license , version num . 0 ( the " license " ) ; <nl> + / / you may not use this file except in compliance with the license . <nl> + / / you may obtain a copy of the license at <nl> + / / <nl> + / / http : / / www . apache . org / licenses / license - 2 . 0 <nl> + / / <nl> + / / unless required by applicable law or agreed to in writing , software <nl> + / / distributed under the license is distributed on an " as is " basis , <nl> + / / without warranties or conditions of any kind , either express or implied . <nl> + / / see the license for the specific language governing permissions and <nl> + / / limitations under the license . <nl> + package com . google . devtools . build . android . desugar . runtime ; <nl> + <nl> + import android . text . spannable ; <nl> + import android . view . textclassifier . textlinks ; <nl> + import java . util . function . function ; <nl> + <nl> + / * * <nl> + * conversion from desugared to built - in { @ link function } for calling built - in android apis ( see <nl> + * b / 79121791 ) . <nl> + * / <nl> + <nl> + @ suppresswarnings ( " androidjdklibschecker " ) <nl> + public final class functionwrapper < t , r > implements function < t , r > { <nl> + <nl> + private final j $ . util . function . function < t , r > wrapped ; <nl> + <nl> + private functionwrapper ( j $ . util . function . function < t , r > wrapped ) { <nl> + this . wrapped = wrapped ; <nl> + } <nl> + <nl> + @ override <nl> + public r apply ( t arg ) { <nl> + return wrapped . apply ( arg ) ; <nl> + } <nl> + <nl> + public static int apply ( <nl> + textlinks receiver , <nl> + spannable text , <nl> + int applystrategy , <nl> + j $ . util . function . function < textlinks . textlink , textlinks . textlinkspan > spanfactory ) { <nl> + return receiver . apply ( <nl> + text , <nl> + applystrategy , <nl> + spanfactory ! = null <nl> + ? new functionwrapper < textlinks . textlink , textlinks . textlinkspan > ( spanfactory ) <nl> + : null ) ; <nl> + } <nl> + }
public class androiddatabindingprocessorbuilder { <nl>  <nl> / / the order of these matter , the input root and the output root have to be matched up <nl> / / because the resource processor will iterate over them in pairs . <nl> + <nl> + / / is doing a sort of merge before the real resource merger runs . <nl> builder . addflag ( " - - resource_root " , resourceroot . tostring ( ) ) ; <nl> builder . addflag ( " - - output_resource_root " , outputresourceroot . tostring ( ) ) ; <nl> }
import com . google . common . base . function ; <nl> import com . google . common . base . functions ; <nl>  <nl> / * * catalog of possible cpu transformers . * / <nl> + <nl> public enum cputransformer { <nl> identity { <nl> @ override
int outputjar : : doit ( options * options ) { <nl> entryinfo { & build_properties_ } ) ; <nl> } <nl>  <nl> + <nl> build_properties_ . addproperty ( " build . target " , options_ - > output_jar . c_str ( ) ) ; <nl> if ( options_ - > verbose ) { <nl> fprintf ( stderr , " combined_file_name = % s\n " , options_ - > output_jar . c_str ( ) ) ;
public abstract class ccbinary implements ruleconfiguredtargetfactory { <nl> cccompilationcontext cccompilationcontext = compilationinfo . getcccompilationcontext ( ) ; <nl> cccompilationoutputs cccompilationoutputs = compilationinfo . getcccompilationoutputs ( ) ; <nl>  <nl> - / / we currently only want link the dynamic library generated for test code separately . <nl> + / / allows the dynamic library generated for code of default dynamic mode targets to be linked <nl> + / / separately . the main use case for default dynamic mode is the cc_test rule . the same behavior <nl> + / / can also be enabled specifically for tests with an experimental flag . <nl> + <nl> boolean linkcompileoutputseparately = <nl> - rulecontext . istesttarget ( ) <nl> - & & cppconfiguration . getlinkcompileoutputseparately ( ) <nl> - & & linkingmode = = linkingmode . dynamic ; <nl> + ( rulecontext . istesttarget ( ) <nl> + & & cppconfiguration . getlinkcompileoutputseparately ( ) <nl> + & & linkingmode = = linkingmode . dynamic ) <nl> + | | ( cppconfiguration . getdynamicmodeflag ( ) = = dynamicmode . default <nl> + & & rulecontext . getdisabledfeatures ( ) . contains ( static_link_srcs ) ) ; <nl> / / when linking the object files directly into the resulting binary , we do not need <nl> / / library - level link outputs ; thus , we do not let cccompilationhelper produce link outputs <nl> / / ( either shared object files or archives ) for a non - library link type [ * ] , and add <nl> mmm a / src / test / java / com / google / devtools / build / lib / rules / cpp / cpplinkactiontest . java <nl> ppp b / src / test / java / com / google / devtools / build / lib / rules / cpp / cpplinkactiontest . java <nl>
public class cpplinkactiontest extends buildviewtestcase { <nl> . containsexactly ( " bin x / b " ) ; <nl> } <nl>  <nl> + @ test <nl> + public void testcompilesdynamicmodesourceswithoutfeatureintodynamiclibrary ( ) throws exception { <nl> + if ( os . getcurrent ( ) = = os . windows ) { <nl> + / / skip the test on windows . <nl> + <nl> + return ; <nl> + } <nl> + scratch . file ( <nl> + " x / build " , <nl> + " cc_test ( name = ' a ' , srcs = [ ' a . cc ' ] , features = [ ' - static_link_srcs ' ] ) " , <nl> + " cc_binary ( name = ' b ' , srcs = [ ' a . cc ' ] ) " ) ; <nl> + scratch . file ( " x / a . cc " , " int main ( ) { } " ) ; <nl> + useconfiguration ( " - - force_pic " ) ; <nl> + <nl> + configuredtarget configuredtarget = getconfiguredtarget ( " / / x : a " ) ; <nl> + string cpu = crosstoolconfigurationhelper . defaultcpu ( ) ; <nl> + cpplinkaction linkaction = ( cpplinkaction ) getgeneratingaction ( configuredtarget , " x / a " ) ; <nl> + assertthat ( artifactstostrings ( linkaction . getinputs ( ) ) ) <nl> + . contains ( " bin _solib_ " + cpu + " / libx_sliba . ifso " ) ; <nl> + assertthat ( linkaction . getarguments ( ) ) <nl> + . contains ( <nl> + getbinartifactwithnoowner ( " _solib_ " + cpu + " / libx_sliba . ifso " ) . getexecpathstring ( ) ) ; <nl> + runfilesprovider runfilesprovider = configuredtarget . getprovider ( runfilesprovider . class ) ; <nl> + assertthat ( artifactstostrings ( runfilesprovider . getdefaultrunfiles ( ) . getartifacts ( ) ) ) <nl> + . contains ( " bin _solib_ " + cpu + " / libx_sliba . so " ) ; <nl> + <nl> + configuredtarget = getconfiguredtarget ( " / / x : b " ) ; <nl> + linkaction = ( cpplinkaction ) getgeneratingaction ( configuredtarget , " x / b " ) ; <nl> + assertthat ( artifactstostrings ( linkaction . getinputs ( ) ) ) . contains ( " bin x / _objs / b / a . pic . o " ) ; <nl> + runfilesprovider = configuredtarget . getprovider ( runfilesprovider . class ) ; <nl> + assertthat ( artifactstostrings ( runfilesprovider . getdefaultrunfiles ( ) . getartifacts ( ) ) ) <nl> + . containsexactly ( " bin x / b " ) ; <nl> + } <nl> + <nl> @ test <nl> public void testtoolchainfeatureenv ( ) throws exception { <nl> featureconfiguration featureconfiguration =
public class reducedclasspathjavalibrarybuilder extends simplejavalibrarybuilder <nl> return result . withstatistics ( stats . build ( ) ) ; <nl> } <nl>  <nl> + private blazejavacresult fallback ( javalibrarybuildrequest build , javacrunner javacrunner ) <nl> + throws ioexception { <nl> + <nl> + <nl> + / / reset output directories <nl> + preparesourcecompilation ( build ) ; <nl> + <nl> + / / fall back to the regular compile , but add extra checks to catch transitive uses <nl> + return javacrunner . invokejavac ( build . toblazejavacarguments ( build . getclasspath ( ) ) ) ; <nl> + } <nl> + <nl> private static boolean shouldfallback ( blazejavacresult result ) { <nl> if ( result . isok ( ) ) { <nl> return false ;
cc_test ( <nl> data = [ <nl> " data / empty . zip " , <nl> ] , <nl> + tags = [ <nl> + # <nl> + # https : / / github . com / bazelbuild / bazel / issues / 2241 <nl> + " no_windows " , <nl> + ] , <nl> deps = [ <nl> " : input_jar " , <nl> " : test_util " , <nl>
cc_test ( <nl> data = [ <nl> " : test1 " , <nl> ] , <nl> + tags = [ <nl> + # <nl> + # https : / / github . com / bazelbuild / bazel / issues / 2241 <nl> + " no_windows " , <nl> + ] , <nl> deps = [ <nl> " : input_jar " , <nl> " : test_util " , <nl>
cc_test ( <nl> " : test2 " , <nl> " @ bazel_tools / / tools / jdk : current_java_runtime " , <nl> ] , <nl> + tags = [ <nl> + # <nl> + # https : / / github . com / bazelbuild / bazel / issues / 2241 <nl> + " no_windows " , <nl> + ] , <nl> toolchains = [ " @ bazel_tools / / tools / jdk : current_java_runtime " ] , <nl> deps = [ <nl> " : input_jar " , <nl>
java_binary ( <nl> runtime_deps = [ " : turbine_main " ] , <nl> ) <nl>  <nl> + java_binary ( <nl> + name = " turbine_direct_binary " , <nl> + main_class = " com . google . turbine . main . main " , <nl> + runtime_deps = [ <nl> + " / / src / main / protobuf : deps_java_proto " , <nl> + " / / third_party : guava " , <nl> + " / / third_party : jsr305 " , <nl> + " / / third_party : turbine " , <nl> + ] , <nl> + ) <nl> + <nl> + filegroup ( <nl> + name = " turbine_direct " , <nl> + # <nl> + srcs = select ( { <nl> + " / / src / conditions : darwin " : [ " / / third_party : turbine_direct " ] , <nl> + " / / src / conditions : darwin_x86_64 " : [ " / / third_party : turbine_direct " ] , <nl> + " / / src / conditions : linux_x86_64 " : [ " / / third_party : turbine_direct " ] , <nl> + " / / conditions : default " : [ " turbine_direct_binary_deploy . jar " ] , <nl> + } ) , <nl> + visibility = [ <nl> + " / / : __subpackages__ " , <nl> + ] , <nl> + ) <nl> + <nl> java_library ( <nl> name = " turbine_main " , <nl> srcs = [ " turbine . java " ] , <nl> mmm a / tools / jdk / build <nl> ppp b / tools / jdk / build <nl>
public class objcruleclasses { <nl> . add ( <nl> attr ( " bundles " , label_list ) <nl> . direct_compile_time_input ( ) <nl> - . allowedruleclasses ( " objc_bundle " , " objc_bundle_library " ) <nl> + <nl> + / / path towards the end state is easier , as it will allow breaking the migration <nl> + / / into smaller chunks . <nl> + . allowedruleclasses ( <nl> + " apple_bundle_import " , <nl> + " apple_resource_bundle " , <nl> + " objc_bundle " , <nl> + " objc_bundle_library " ) <nl> . allowedfiletypes ( ) ) <nl> . build ( ) ; <nl> }
http_file ( <nl> ] , <nl> ) <nl>  <nl> + # used by ci to test bazel on platforms without an installed system jdk . <nl> + # <nl> + new_http_archive ( <nl> + name = " openjdk_linux_archive " , <nl> + sha256 = " <commit_id> " , <nl> + urls = [ <nl> + " https : / / mirror . bazel . build / openjdk / azul - zulu - 9 . 0 . 7 . 1 - jdk9 . 0 . 7 / zulu9 . 0 . 7 . 1 - jdk9 . 0 . 7 - linux_x64 - allmodules . tar . gz " , <nl> + ] , <nl> + strip_prefix = " zulu9 . 0 . 7 . 1 - jdk9 . 0 . 7 - linux_x64 - allmodules " , <nl> + build_file_content = " java_runtime ( name = ' runtime ' , srcs = glob ( [ ' * * ' ] ) , visibility = [ ' / / visibility : public ' ] ) " , <nl> + ) <nl> + <nl> http_file ( <nl> name = " openjdk_macos " , <nl> sha256 = " <commit_id> " ,
bool exportmiscenvvars ( const path & cwd ) { <nl> return true ; <nl> } <nl>  <nl> + bool openfileforwriting ( const std : : wstring & path , handle * result ) { <nl> + * result = createfilew ( bazel : : windows : : hasuncprefix ( path . c_str ( ) ) <nl> + ? path . c_str ( ) <nl> + : ( l " \ \ \ \ ? \ \ " + path ) . c_str ( ) , <nl> + generic_write , file_share_read | file_share_delete , <nl> + null , create_always , file_attribute_normal , null ) ; <nl> + if ( * result = = invalid_handle_value ) { <nl> + dword err = getlasterror ( ) ; <nl> + logerrorwithargandvalue ( __line__ , " failed to open file " , path . c_str ( ) , err ) ; <nl> + return false ; <nl> + } <nl> + return true ; <nl> + } <nl> + <nl> + bool touchfile ( const std : : wstring & path ) { <nl> + handle handle ; <nl> + if ( ! openfileforwriting ( path , & handle ) ) { <nl> + return false ; <nl> + } <nl> + closehandle ( handle ) ; <nl> + return true ; <nl> + } <nl> + <nl> + bool exportxmlpath ( const path & cwd ) { <nl> + path result ; <nl> + if ( ! getpathenv ( l " xml_output_file " , & result ) ) { <nl> + return false ; <nl> + } <nl> + result . absolutize ( cwd ) ; <nl> + std : : wstring unix_result = asmixedpath ( result . get ( ) ) ; <nl> + return setenv ( l " xml_output_file " , unix_result ) & & <nl> + <nl> + setenv ( l " gunit_output " , l " xml : " + unix_result ) & & <nl> + createdirectories ( result . dirname ( ) ) & & <nl> + touchfile ( result . get ( ) + l " . log " ) ; <nl> + } <nl> + <nl> bool getandunexportundeclaredoutputsenvvars ( const path & cwd , <nl> undeclaredoutputs * result ) { <nl> / / the test may only see test_undeclared_outputs_dir and <nl>
end_of_record " <nl> assert_contains ' name : " baseline . lcov " ' bep . txt <nl> } <nl>  <nl> + # <nl> + function skip_test_cc_test_coverage_gcov_virtual_includes ( ) { <nl> + local - r gcov_location = $ ( which gcov ) <nl> + if [ [ ! - x $ { gcov_location : - / usr / bin / gcov } ] ] ; then <nl> + echo " gcov not installed . skipping test . " <nl> + return <nl> + fi <nl> + <nl> + " $ gcov_location " - version | grep " llvm " & & \ <nl> + echo " gcov llvm version not supported . skipping test . " & & return <nl> + # gcov - v | grep " gcov " outputs a line that looks like this : <nl> + # gcov ( debian num . 3 . 0 - 5 ) num . 3 . 0 <nl> + local gcov_version = " $ ( gcov - v | grep " gcov " | cut - d " " - f num | cut - d " . " - f num ) " <nl> + [ " $ gcov_version " - lt num ] \ <nl> + & & echo " gcov version before num . 0 is not supported . skipping test . " \ <nl> + & & return <nl> + <nl> + # # # # # # # # # # # setup source files and build file # # # # # # # # # # # <nl> + mkdir - p examples / cpp <nl> + cat < < eof > examples / cpp / build <nl> + cc_library ( <nl> + name = " a_header " , <nl> + hdrs = [ " foo / bar / baz / a_header . h " ] , <nl> + strip_include_prefix = " foo " , <nl> + include_prefix = " yin / yang " , <nl> + ) <nl> + <nl> + cc_library ( <nl> + name = " hello - lib " , <nl> + srcs = [ " hello - lib . cc " ] , <nl> + hdrs = [ " hello - lib . h " ] , <nl> + deps = [ " : a_header " ] , <nl> + ) <nl> + <nl> + cc_test ( <nl> + name = " hello - world_test " , <nl> + srcs = [ " hello - world . cc " ] , <nl> + deps = [ " : hello - lib " ] , <nl> + ) <nl> + eof <nl> + mkdir - p examples / cpp / foo / bar / baz <nl> + cat < < eof > examples / cpp / foo / bar / baz / a_header . h <nl> + # include < iostream > <nl> + using namespace std ; <nl> + <nl> + class a { <nl> + public : <nl> + void cout_whatever ( ) const { <nl> + cout < < " whatever " ; <nl> + } <nl> + } ; <nl> + eof <nl> + <nl> + cat < < eof > examples / cpp / hello - lib . h <nl> + # ifndef examples_cpp_hello_lib_h_ <nl> + # define examples_cpp_hello_lib_h_ <nl> + <nl> + # include < string > <nl> + # include < memory > <nl> + # include " yin / yang / bar / baz / a_header . h " <nl> + <nl> + namespace hello { <nl> + <nl> + class hellolib { <nl> + public : <nl> + explicit hellolib ( const std : : string & greeting ) ; <nl> + <nl> + void greet ( const std : : string & thing ) ; <nl> + <nl> + private : <nl> + std : : auto_ptr < const std : : string > greeting_ ; <nl> + } ; <nl> + } / / namespace hello <nl> + # endif / / examples_cpp_hello_lib_h_ <nl> + eof <nl> + <nl> + cat < < eof > examples / cpp / hello - lib . cc <nl> + # include " examples / cpp / hello - lib . h " <nl> + <nl> + # include < iostream > <nl> + <nl> + using std : : cout ; <nl> + using std : : endl ; <nl> + using std : : string ; <nl> + <nl> + namespace hello { <nl> + <nl> + hellolib : : hellolib ( const string & greeting ) : greeting_ ( new string ( greeting ) ) { <nl> + } <nl> + <nl> + void hellolib : : greet ( const string & thing ) { <nl> + cout < < * greeting_ < < " " < < thing < < endl ; <nl> + a * a = new a ( ) ; <nl> + a - > cout_whatever ( ) ; <nl> + } <nl> + } / / namespace hello <nl> + eof <nl> + <nl> + cat < < eof > examples / cpp / hello - world . cc <nl> + # include " examples / cpp / hello - lib . h " <nl> + <nl> + # include < string > <nl> + <nl> + using hello : : hellolib ; <nl> + using std : : string ; <nl> + <nl> + int main ( int argc , char * * argv ) { <nl> + hellolib lib ( " hello " ) ; <nl> + string thing = " world " ; <nl> + if ( argc > num ) { <nl> + thing = argv [ 1 ] ; <nl> + } <nl> + lib . greet ( thing ) ; <nl> + return num ; <nl> + } <nl> + eof <nl> + <nl> + # # # # # # # # # # # run bazel coverage # # # # # # # # # # # <nl> + bazel coverage - - experimental_cc_coverage - - test_output = all / / examples / cpp : hello - world_test & > " $ test_log " \ <nl> + | | fail " coverage for / / examples / cpp : hello - world_test failed " <nl> + <nl> + # # # # # # # # # # # assert coverage results . # # # # # # # # # # # <nl> + local coverage_file_path = " $ ( get_coverage_file_path_from_test_log ) " <nl> + local expected_result_hello_lib = " sf : examples / cpp / hello - lib . cc <nl> + fn : 19 , _global__sub_i_hello_lib . cc <nl> + fn : 19 , _z41__static_initialization_and_destruction_0ii <nl> + fn : 14 , _zn5hello8hellolib5greeterknst7__cxx1112basic_stringicst11char_traitsicesaiceee <nl> + fn : 11 , _zn5hello8hellolibc2erknst7__cxx1112basic_stringicst11char_traitsicesaiceee <nl> + fnda : 1 , _global__sub_i_hello_lib . cc <nl> + fnda : 1 , _z41__static_initialization_and_destruction_0ii <nl> + fnda : 1 , _zn5hello8hellolib5greeterknst7__cxx1112basic_stringicst11char_traitsicesaiceee <nl> + fnda : 1 , _zn5hello8hellolibc2erknst7__cxx1112basic_stringicst11char_traitsicesaiceee <nl> + fnf : 4 <nl> + fnh : 4 <nl> + ba : 11 , 2 <nl> + ba : 19 , 2 <nl> + brf : 2 <nl> + brh : 2 <nl> + da : 11 , 1 <nl> + da : 12 , 1 <nl> + da : 14 , 1 <nl> + da : 15 , 1 <nl> + da : 16 , 1 <nl> + da : 17 , 1 <nl> + da : 18 , 1 <nl> + da : 19 , 3 <nl> + lh : 8 <nl> + lf : 8 <nl> + end_of_record " <nl> + assert_coverage_result " $ expected_result_hello_lib " " $ coverage_file_path " <nl> + <nl> + local expected_result_a_header = " sf : examples / cpp / foo / bar / baz / a_header . h <nl> + fn : 9 , _znk1a13cout_whateverev <nl> + fnda : 1 , _znk1a13cout_whateverev <nl> + fnf : 1 <nl> + fnh : 1 <nl> + da : 9 , 1 <nl> + da : 10 , 1 <nl> + da : 11 , 1 <nl> + lh : 3 <nl> + lf : 3 <nl> + end_of_record " <nl> + assert_coverage_result " $ expected_result_a_header " " $ coverage_file_path " <nl> + <nl> + local coverage_result_hello_lib_header = " sf : examples / cpp / hello - lib . h <nl> + fn : 12 , _zn5hello8hellolibd2ev <nl> + fnda : 1 , _zn5hello8hellolibd2ev <nl> + fnf : 1 <nl> + fnh : 1 <nl> + da : 12 , 1 <nl> + lh : 1 <nl> + lf : 1 <nl> + end_of_record " <nl> + assert_coverage_result " $ coverage_result_hello_lib_header " " $ coverage_file_path " <nl> + } <nl> + <nl> function test_cc_test_llvm_coverage_doesnt_fail ( ) { <nl> local - r llvmprofdata = $ ( which llvm - profdata ) <nl> if [ [ ! - x $ { llvmprofdata : - / usr / bin / llvm - profdata } ] ] ; then
public abstract class invalidatingnodevisitor < tgraph extends queryablegraph > { <nl> } <nl> } ) ; <nl> } <nl> - executor . awaitquiescence ( / * interruptworkers = * / true ) ; <nl> + try { <nl> + executor . awaitquiescence ( / * interruptworkers = * / true ) ; <nl> + } catch ( illegalstateexception e ) { <nl> + <nl> + throw new illegalstateexception ( e ) ; <nl> + } <nl>  <nl> / / note : implementations that do not support interruption also do not update pendingvisitations . <nl> preconditions . checkstate ( ! getsupportinterruptions ( ) | | pendingvisitations . isempty ( ) ,
<nl> + mmm <nl> + platforms : <nl> + ubuntu1404 : <nl> + shell_commands : <nl> + - sed - i . bak - e ' s / ^ # android_sdk_repository / android_sdk_repository / ' - e ' s / ^ # <nl> + android_ndk_repository / android_ndk_repository / ' workspace <nl> + - rm - f workspace . bak <nl> + build_targets : <nl> + - " / / src : bazel " <nl> + test_flags : <nl> + - " - - test_timeout = 1200 " <nl> + test_targets : <nl> + - " - - " <nl> + - " / / scripts / . . . " <nl> + - " / / src / test / . . . " <nl> + - " / / third_party / ijar / . . . " <nl> + - " / / tools / android / . . . " <nl> + # disable slow tests <nl> + - " - / / src / test / shell / bazel : bazel_determinism_test " <nl> + # re - enable once fixed : https : / / github . com / bazelbuild / bazel / issues / 4663 <nl> + - " - / / src / test / shell / bazel / android : android_ndk_integration_test " <nl> + # re - enable once fixed : https : / / github . com / bazelbuild / bazel / issues / 5888 <nl> + - " - / / src / test / java / com / google / devtools / build / android / ziputils : ziputils - tests " <nl> + macos : <nl> + shell_commands : <nl> + - sed - i . bak - e ' s / ^ # android_sdk_repository / android_sdk_repository / ' - e ' s / ^ # <nl> + android_ndk_repository / android_ndk_repository / ' workspace <nl> + - rm - f workspace . bak <nl> + build_targets : <nl> + - " / / src : bazel " <nl> + test_flags : <nl> + - " - - test_timeout = 1200 " <nl> + test_targets : <nl> + - " - - " <nl> + - " / / scripts / . . . " <nl> + - " / / src / test / . . . " <nl> + - " / / third_party / ijar / . . . " <nl> + - " / / tools / android / . . . " <nl> + # re - enable once fixed : https : / / github . com / bazelbuild / bazel / issues / 4663 <nl> + - " - / / src / test / shell / bazel / android : android_ndk_integration_test " <nl> + # the below tests have been disabled because they are too slow on macos . <nl> + # re - enable once fixed : https : / / github . com / bazelbuild / bazel / issues / 4684 <nl> + - " - / / src / test / shell / bazel : bazel_determinism_test " <nl> + - " - / / src / test / shell / bazel : bazel_java_test " <nl> + - " - / / src / test / shell / bazel : bazel_bootstrap_distfile_test " <nl> + - " - / / src / test / shell / bazel / remote : remote_execution_test " <nl> + - " - / / src / test / shell / bazel / remote : remote_execution_http_test " <nl> + - " - / / src / test / shell / bazel : skylark_git_repository_test " <nl> + - " - / / src / test / shell / bazel : external_path_test " <nl> + - " - / / src / test / py / bazel : runfiles_test " <nl> + - " - / / src / test / shell / bazel : git_repository_test " <nl> + - " - / / src / test / shell / bazel / android : aar_integration_test " <nl> + - " - / / src / test / shell / bazel / android : android_integration_test " <nl> + # re - enable once fixed : https : / / github . com / bazelbuild / bazel / issues / 5888 <nl> + - " - / / src / test / java / com / google / devtools / build / android / ziputils : ziputils - tests " <nl> + windows : <nl> + build_flags : <nl> + - " - - copt = - w " <nl> + - " - - host_copt = - w " <nl> + build_targets : <nl> + - " / / src : bazel " <nl> + test_flags : <nl> + - " - - copt = - w " <nl> + - " - - host_copt = - w " <nl> + - " - - test_env = java_home " <nl> + # <nl> + # remove this when release version bazel sets systemdrive <nl> + # on windows by default . <nl> + - " - - test_env = systemdrive " <nl> + - " - - test_timeout = 1200 " <nl> + test_targets : <nl> + - " - - " <nl> + - " / / src : all_windows_tests " <nl> + # re - enable once fixed : https : / / github . com / bazelbuild / bazel / issues / 5888 <nl> + - " - / / src / test / java / com / google / devtools / build / android / ziputils : ziputils - tests "
public final class commandhelper { <nl> for ( iterable < ? extends transitiveinfocollection > tools : toolslist ) { <nl> for ( transitiveinfocollection dep : tools ) { / / ( note : host configuration ) <nl> label label = aliasprovider . getdependencylabel ( dep ) ; <nl> + middlemanprovider toolmiddleman = dep . getprovider ( middlemanprovider . class ) ; <nl> + if ( toolmiddleman ! = null ) { <nl> + resolvedtoolsbuilder . addall ( toolmiddleman . getmiddlemanartifact ( ) ) ; <nl> + / / it is not obviously correct to skip potentially adding getfilestorun of the <nl> + / / filestorunprovider . however , for all tools that we know of that provide a middleman , <nl> + / / the middleman is equivalent to the list of files coming out of getfilestorun ( ) . <nl> + / / just adding all the files creates a substantial performance bottleneck . e . g . a c + + <nl> + / / toolchain might consist of thousands of files and tracking them one by one for each <nl> + / / action that uses them is inefficient . <nl> + continue ; <nl> + } <nl> + <nl> filestorunprovider tool = dep . getprovider ( filestorunprovider . class ) ; <nl> if ( tool = = null ) { <nl> continue ; <nl> } <nl>  <nl> + <nl> iterable < artifact > files = tool . getfilestorun ( ) ; <nl> resolvedtoolsbuilder . addall ( files ) ; <nl> artifact executableartifact = tool . getexecutable ( ) ; <nl> mmm a / src / main / java / com / google / devtools / build / lib / rules / cpp / cctoolchain . java <nl> ppp b / src / main / java / com / google / devtools / build / lib / rules / cpp / cctoolchain . java <nl>
<nl> / / see the license for the specific language governing permissions and <nl> / / limitations under the license . <nl>  <nl> - # ifdef _win32 <nl> - <nl> - # include " src / tools / singlejar / port . h " <nl> - <nl> - # ifndef win32_lean_and_mean <nl> - # define win32_lean_and_mean <nl> - # endif / / win32_lean_and_mean <nl> - # include < windows . h > <nl> - <nl> - ssize_t pread ( int fd , void * buf , size_t count , off64_t offset ) { <nl> - dword ret = - 1 ; <nl> - handle hfile = reinterpret_cast < handle > ( _get_osfhandle ( fd ) ) ; <nl> - if ( hfile ) { <nl> - overlapped overlap ; <nl> - memset ( & overlap , num , sizeof ( overlapped ) ) ; <nl> - overlap . offset = offset ; <nl> - if ( ! : : readfile ( hfile , buf , count , & ret , & overlap ) ) { <nl> - / / for this simple implementation , we don ' t update errno . <nl> - / / just return - 1 as error . <nl> - return - 1 ; <nl> - } <nl> - } <nl> - return ret ; <nl> - } <nl> - <nl> - # endif / / _win32 <nl> + <nl> mmm a / src / tools / singlejar / port . h <nl> ppp b / src / tools / singlejar / port . h <nl>
public final class maintest { <nl>  <nl> @ rule public final temporaryfolder tempfolder = new temporaryfolder ( ) ; <nl>  <nl> + @ ignore <nl> @ test <nl> public void usage ( ) throws exception { <nl> path lib = tempfolder . newfile ( " lib . jar " ) . topath ( ) ;
filegroup ( <nl> filegroup ( <nl> name = " singlejar " , <nl> srcs = select ( { <nl> - " / / src / conditions : remote " : [ " / / src / tools / singlejar : singlejar " ] , <nl> + " / / src / conditions : remote " : [ " : singlejar_remote " ] , <nl> " / / conditions : default " : glob ( [ " singlejar / * " ] ) , <nl> } ) , <nl> ) <nl>  <nl> + # this is a separate filegroup from : singlejar above since bazel doesn ' t <nl> + # support nested selects ( we need a logical " remote and windows " condition ) . <nl> + filegroup ( <nl> + name = " singlejar_remote " , <nl> + srcs = select ( { <nl> + # <nl> + # native singlejar works on windows . <nl> + " / / src / conditions : windows " : glob ( [ " singlejar / * " ] ) , <nl> + " / / conditions : default " : [ " / / src / tools / singlejar : singlejar " ] , <nl> + } ) , <nl> + ) <nl> + <nl> filegroup ( <nl> name = " genclass " , <nl> srcs = [ " / / tools / jdk : genclass_deploy . jar " ] ,
public class javacturbine implements autocloseable { <nl> return dependencymodulebuilder . build ( ) ; <nl> } <nl>  <nl> + <nl> + @ suppresswarnings ( " unchecked " ) <nl> + private static string gettargetlabel ( object targetlabel ) { <nl> + if ( targetlabel instanceof java . util . optional ) { <nl> + return ( ( java . util . optional < string > ) targetlabel ) . orelse ( null ) ; <nl> + } <nl> + if ( targetlabel instanceof com . google . common . base . optional ) { <nl> + return ( ( com . google . common . base . optional < string > ) targetlabel ) . ornull ( ) ; <nl> + } <nl> + throw new assertionerror ( targetlabel ) ; <nl> + } <nl> + <nl> / * * write the class output from a successful compilation to the output jar . * / <nl> private static void emitclassjar ( <nl> turbineoptions turbineoptions , map < string , byte [ ] > files , map < string , byte [ ] > transitive )
public class protoresourceusageanalyzer extends resourceusageanalyzer { <nl> / / graph on . <nl> apk . visitresources ( new resourcedeclarationvisitor ( model ( ) ) ) . tousagevisitor ( ) ) ; <nl>  <nl> - recordclassusages ( classes ) ; <nl> + try { <nl> + <nl> + final method recordmapping = <nl> + resourceusageanalyzer . class . getdeclaredmethod ( " recordmapping " , path . class ) ; <nl> + recordmapping . setaccessible ( true ) ; <nl> + recordmapping . invoke ( this , mapping ) ; <nl> + recordclassusages ( classes ) ; <nl> + } catch ( nosuchmethodexception | illegalaccessexception | invocationtargetexception e ) { <nl> + throw new runtimeexception ( e ) ; <nl> + } <nl>  <nl> / / have to give the model xml attributes with keep and discard urls . <nl> final namednodemap toolattributes = <nl>
public class applecrosstooltransition implements patchtransition { <nl> * / <nl> public static void setapplecrosstooltransitionconfiguration ( buildoptions from , <nl> buildoptions to , string cpu ) { <nl> - to . get ( buildconfiguration . options . class ) . cpu = cpu ; <nl> - to . get ( cppoptions . class ) . crosstooltop = <nl> - from . get ( applecommandlineoptions . class ) . applecrosstooltop ; <nl> + label crosstooltop = from . get ( applecommandlineoptions . class ) . applecrosstooltop ; <nl> + <nl> + buildconfiguration . options tooptions = to . get ( buildconfiguration . options . class ) ; <nl> + cppoptions tocppoptions = to . get ( cppoptions . class ) ; <nl> + <nl> + if ( tooptions . cpu . equals ( cpu ) & & tocppoptions . crosstooltop . equals ( crosstooltop ) <nl> + & & from . get ( applecommandlineoptions . class ) . applecrosstoolinoutputdirectoryname ) { <nl> + / / if neither the cpu nor the crosstool changes , do nothing . this is so that c + + to <nl> + / / objective - c dependencies work if the top - level configuration is already an apple one . <nl> + / / this is arguably a hack , but it helps with rolling out <nl> + / / - - apple_crosstool_in_output_directory_name , which in turn helps with removing the <nl> + / / configuration distinguisher ( which can ' t be set from the command line ) and putting the <nl> + / / platform type in the output directory name , which would obviate the need for this hack . <nl> + <nl> + return ; <nl> + } <nl> + <nl> + tooptions . cpu = cpu ; <nl> + tocppoptions . crosstooltop = crosstooltop ; <nl> to . get ( applecommandlineoptions . class ) . targetusesapplecrosstool = true ; <nl> if ( from . get ( applecommandlineoptions . class ) . applecrosstoolinoutputdirectoryname ) { <nl> to . get ( applecommandlineoptions . class ) . configurationdistinguisher = <nl> mmm a / src / test / java / com / google / devtools / build / lib / rules / objc / objclibrarytest . java <nl> ppp b / src / test / java / com / google / devtools / build / lib / rules / objc / objclibrarytest . java <nl>
public class artifactfactory implements artifactresolver { <nl> if ( artifact ! = null & & sourceroot . equals ( artifact . getroot ( ) . getroot ( ) ) ) { <nl> / / source root of existing artifact hasn ' t changed so we should mark corresponding entry in <nl> / / the cache as valid . <nl> - sourceartifactcache . markentryasvalid ( execpath ) ; <nl> + <nl> + synchronized ( this ) { <nl> + artifact validartifact = sourceartifactcache . getartifactifvalid ( execpath ) ; <nl> + if ( validartifact = = null ) { <nl> + / / wasn ' t previously known to be valid . <nl> + sourceartifactcache . markentryasvalid ( execpath ) ; <nl> + } else { <nl> + preconditions . checkstate ( <nl> + artifact . equals ( validartifact ) , <nl> + " mismatched artifacts : % s % s " , <nl> + artifact , <nl> + validartifact ) ; <nl> + } <nl> + } <nl> } else { <nl> / / must be a new artifact or artifact in the cache is stale , so create a new one . <nl> artifact = getsourceartifact ( execpath , sourceroot , artifactowner . nullartifactowner . instance ) ; <nl>
public class executionstatisticstestutil { <nl> duration usertimelowerbound = usertimetospend ; <nl> duration usertimeupperbound = usertimetospend . plusseconds ( 9 ) ; <nl> duration systemtimelowerbound = systemtimetospend ; <nl> - duration systemtimeupperbound = systemtimetospend . plusseconds ( 9 ) ; <nl> + <nl> + <nl>  <nl> command command = new command ( fullcommandline . toarray ( new string [ 0 ] ) ) ; <nl> commandresult commandresult = command . execute ( ) ; <nl>
public class executionstatisticstestutil { <nl>  <nl> duration systemtime = resourceusage . get ( ) . getsystemexecutiontime ( ) ; <nl> assertthat ( systemtime ) . isatleast ( systemtimelowerbound ) ; <nl> - assertthat ( systemtime ) . isatmost ( systemtimeupperbound ) ; <nl> + <nl> + <nl> } <nl> }
public final class javainfo extends nativeinfo implements javainfoapi < artifact > <nl> } <nl>  <nl> public javainfo build ( ) { <nl> + <nl> + / / deps we wrap the non strict provider instead . <nl> + if ( ! providermap . contains ( javastrictcompilationargsprovider . class ) <nl> + & & providermap . contains ( javacompilationargsprovider . class ) ) { <nl> + javastrictcompilationargsprovider javastrictcompilationargsprovider = <nl> + new javastrictcompilationargsprovider ( <nl> + providermap . getprovider ( javacompilationargsprovider . class ) ) ; <nl> + addprovider ( javastrictcompilationargsprovider . class , javastrictcompilationargsprovider ) ; <nl> + } <nl> return new javainfo ( providermap . build ( ) , runtimejars , neverlink , javaconstraints , location ) ; <nl> } <nl> }
public abstract class ccbinary implements ruleconfiguredtargetfactory { <nl> cccompilationinfobuilder . setcccompilationcontext ( cccompilationcontext ) ; <nl>  <nl> cclinkinginfo . builder cclinkinginfobuilder = cclinkinginfo . builder . create ( ) ; <nl> + <nl> + / / needed , but here we set it to avoid a null pointer exception in places where we ' re expecting <nl> + / / it . in the future cclinkparamsstore will be obligatory . <nl> + cclinkinginfobuilder . setcclinkparamsstore ( <nl> + new cclinkparamsstore ( <nl> + / * staticmodeparamsfordynamiclibrary = * / cclinkparams . empty , <nl> + / * staticmodeparamsforexecutable = * / cclinkparams . empty , <nl> + / * dynamicmodeparamsfordynamiclibrary = * / cclinkparams . empty , <nl> + / * dynamicmodeparamsforexecutable = * / cclinkparams . empty ) ) ; <nl> if ( cppconfiguration . enableccdynamiclibrariesforruntime ( ) ) { <nl> cclinkinginfobuilder . setccdynamiclibrariesforruntime ( <nl> new ccdynamiclibrariesforruntime ( <nl> mmm a / src / main / java / com / google / devtools / build / lib / rules / cpp / cclinkinginfo . java <nl> ppp b / src / main / java / com / google / devtools / build / lib / rules / cpp / cclinkinginfo . java <nl>
public abstract class ccbinary implements ruleconfiguredtargetfactory { <nl> cccompilationinfobuilder . setcccompilationcontext ( cccompilationcontext ) ; <nl>  <nl> cclinkinginfo . builder cclinkinginfobuilder = cclinkinginfo . builder . create ( ) ; <nl> + <nl> + / / needed , but here we set it to avoid a null pointer exception in places where we ' re expecting <nl> + / / it . in the future cclinkparamsstore will be obligatory . <nl> + cclinkinginfobuilder . setcclinkparamsstore ( <nl> + new cclinkparamsstore ( <nl> + / * staticmodeparamsfordynamiclibrary = * / cclinkparams . empty , <nl> + / * staticmodeparamsforexecutable = * / cclinkparams . empty , <nl> + / * dynamicmodeparamsfordynamiclibrary = * / cclinkparams . empty , <nl> + / * dynamicmodeparamsforexecutable = * / cclinkparams . empty ) ) ; <nl> if ( cppconfiguration . enableccdynamiclibrariesforruntime ( ) ) { <nl> cclinkinginfobuilder . setccdynamiclibrariesforruntime ( <nl> new ccdynamiclibrariesforruntime ( <nl> mmm a / src / main / java / com / google / devtools / build / lib / rules / cpp / cclinkinginfo . java <nl> ppp b / src / main / java / com / google / devtools / build / lib / rules / cpp / cclinkinginfo . java <nl>
toolchain { <nl> action : ' c - compile ' <nl> action : ' c + + - compile ' <nl> flag_group { <nl> - flag : " / o2 " <nl> + flag : " / o2 " # implies / og / oi / ot / oy / ob2 / gs / gf / gy <nl> + } <nl> + } <nl> + implies : ' frame_pointer ' <nl> + } <nl> + <nl> + # keep stack frames for debugging , even in opt mode . <nl> + # must come after / o1 , / o2 and / ox . <nl> + feature { <nl> + name : " frame_pointer " <nl> + flag_set { <nl> + action : " c - compile " <nl> + action : " c + + - compile " <nl> + flag_group { <nl> + flag : " / oy - " <nl> + } <nl> + } <nl> + } <nl> + <nl> + # remove assert / dchecks in opt mode . <nl> + # you can have them back with - - features = - disable_assertions . <nl> + feature { <nl> + name : ' disable_assertions ' <nl> + enabled : true <nl> + flag_set { <nl> + action : ' c - compile ' <nl> + action : ' c + + - compile ' <nl> + with_feature : { <nl> + feature : ' opt ' <nl> + } <nl> + flag_group { <nl> flag : " / dndebug " <nl> } <nl> } <nl> } <nl>  <nl> + feature { <nl> + name : " determinism " <nl> + enabled : true <nl> + flag_set { <nl> + action : " c - compile " <nl> + action : " c + + - compile " <nl> + flag_group { <nl> + # make c + + compilation deterministic . use linkstamping instead of these <nl> + # compiler symbols . <nl> + # <nl> + flag : " / wd4177 " # trying to define or undefine a predefined macro <nl> + flag : " - d__date__ = \ " redacted \ " " <nl> + flag : " - d__timestamp__ = \ " redacted \ " " <nl> + flag : " - d__time__ = \ " redacted \ " " <nl> + } <nl> + } <nl> + } <nl> + <nl> + feature { <nl> + name : ' treat_warnings_as_errors ' <nl> + flag_set { <nl> + action : ' c - compile ' <nl> + action : ' c + + - compile ' <nl> + flag_group { <nl> + flag : " / wx " <nl> + } <nl> + } <nl> + } <nl> + <nl> + # trade slower build time for smaller binary <nl> + feature { <nl> + name : ' smaller_binary ' <nl> + enabled : true <nl> + flag_set { <nl> + action : ' c - compile ' <nl> + action : ' c + + - compile ' <nl> + with_feature : { <nl> + feature : ' opt ' <nl> + } <nl> + flag_group { <nl> + flag : " / gy " # enable function - level linking ( - ffunction - sections ) <nl> + flag : " / gw " # optimize global data ( - fdata - sections ) <nl> + } <nl> + } <nl> + flag_set { <nl> + action : ' c + + - link - executable ' <nl> + action : ' c + + - link - dynamic - library ' , <nl> + action : ' c + + - link - nodeps - dynamic - library ' <nl> + with_feature : { <nl> + feature : ' opt ' <nl> + } <nl> + flag_group { <nl> + flag : ' / opt : icf ' # fold identical functions <nl> + flag : ' / opt : ref ' # eliminate unreferenced functions and data <nl> + } <nl> + } <nl> + } <nl> + <nl> + # suppress warnings that most users do not care <nl> + feature { <nl> + name : ' ignore_noisy_warnings ' <nl> + enabled : true <nl> + flag_set { <nl> + action : ' c + + - link - static - library ' <nl> + flag_group { <nl> + # suppress ' object file does not define any public symbols ' warning <nl> + flag : ' / ignore : 4221 ' <nl> + } <nl> + } <nl> + } <nl> + <nl> feature { <nl> name : ' user_compile_flags ' <nl> flag_set {
sh_test ( <nl> size = " medium " , <nl> srcs = [ " bazel_embedded_skylark_test . sh " ] , <nl> data = [ " : test - deps " ] , <nl> - tags = [ " no_windows " ] , <nl> + tags = [ <nl> + " no_windows " , # <nl> + ] , <nl> ) <nl>  <nl> sh_test ( <nl>
sh_test ( <nl> timeout = " eternal " , <nl> srcs = [ " bazel_java_test . sh " ] , <nl> data = [ " : test - deps " ] , <nl> - tags = [ " no_windows " ] , <nl> + tags = [ <nl> + # <nl> + # the java_common provider doesn ' t work on windows . <nl> + " no_windows " , <nl> + ] , <nl> ) <nl>  <nl> sh_test ( <nl> name = " bazel_build_event_stream_test " , <nl> size = " medium " , <nl> srcs = [ " bazel_build_event_stream_test . sh " ] , <nl> - data = [ " : test - deps " ] , <nl> + data = [ <nl> + " : test - deps " , <nl> + " @ bazel_tools / / tools / bash / runfiles " , <nl> + ] , <nl> tags = [ " no_windows " ] , <nl> ) <nl>  <nl> mmm a / src / test / shell / bazel / bazel_build_event_stream_test . sh <nl> ppp b / src / test / shell / bazel / bazel_build_event_stream_test . sh <nl>
public class skylarkinterfaceutils { <nl> } else if ( yclass . isassignablefrom ( xclass ) ) { <nl> return x ; <nl> } else { <nl> + / / if this exception occurs , it indicates the following error scenario : <nl> + / / <nl> + / / suppose class a is a subclass of both b and c , where b and c are annotated with <nl> + / / @ skylarkmodule annotations ( and are thus considered " skylark types " ) . if b is not a <nl> + / / subclass of c ( nor visa versa ) , then it ' s impossible to resolve whether a is of type <nl> + / / b or if a is of type c . it ' s both ! the way to resolve this is usually to have a be its own <nl> + / / type ( annotated with @ skylarkmodule ) , and thus have the explicit type of a be semantically <nl> + / / " b and c " . <nl> + <nl> throw new illegalargumentexception ( string . format ( <nl> - " expected one of % s and % s to be assignable to each other " , <nl> + " expected one of % s and % s to be a subclass of the other " , <nl> xclass , yclass ) ) ; <nl> } <nl> }
public class cppcompileaction extends abstractaction <nl> public extraactioninfo . builder getextraactioninfo ( actionkeycontext actionkeycontext ) { <nl> cppcompileinfo . builder info = cppcompileinfo . newbuilder ( ) ; <nl> info . settool ( compilecommandline . gettoolpath ( ) ) ; <nl> - for ( string option : getcompileroptions ( ) ) { <nl> + <nl> + / / computed in the codepaths leading here . <nl> + for ( string option : <nl> + compilecommandline . getcompileroptions ( getoverwrittenvariables ( getinputs ( ) ) ) ) { <nl> info . addcompileroption ( option ) ; <nl> } <nl> info . setoutputfile ( outputfile . getexecpathstring ( ) ) ;
public class bytestreamuploadertest { <nl> retryservice . shutdownnow ( ) ; <nl> } <nl>  <nl> + @ ignore <nl> @ test ( timeout = num ) <nl> public void singleblobuploadshouldwork ( ) throws exception { <nl> context prevcontext = withemptymetadata . attach ( ) ;
else <nl> test_path = " $ ( rlocation $ test_workspace / $ exe ) " <nl> fi <nl>  <nl> + # <nl> + # path to workaround a bug with long executable paths when executing remote <nl> + # tests on windows . <nl> + if [ ! - z " $ test_short_exec_path " ] ; then <nl> + # use a short path like " t0 " in the execution root . use the smallest numeric <nl> + # suffix that doesn ' t collide with an existing file or directory . <nl> + qualifier = 0 <nl> + while [ [ - e " $ { exec_root } / t $ { qualifier } " ] ] ; do <nl> + ( ( qualifier + + ) ) <nl> + done <nl> + ln - s " $ { test_path } " " $ { exec_root } / t $ { qualifier } " <nl> + test_path = " $ { exec_root } / t $ { qualifier } " <nl> + fi <nl> + <nl> exitcode = 0 <nl> signals = " $ ( trap - l | sed - e ' s / [ 0 - 9 ] + \ ) / / g ' ) " <nl> for signal in $ signals ; do
java_import ( <nl> " android_common / com . android . tools . build_builder - test - api_2 . 0 . 0 . jar " , <nl> " android_common / com . android . tools . build_manifest - merger_25 . 0 . 0 . jar " , <nl> " android_common / com . android . tools . external . lombok_lombok - ast_0 . 2 . 3 . jar " , <nl> - " android_common / com . android . tools . layoutlib_layoutlib_25 . 0 . 0 . jar " , <nl> + # layoutlib has been upgraded to num . 1 . 2 * just * for font resource support . <nl> + # we are unable to upgrade the other libraries yet due to internal <nl> + # constraints with blaze . see <nl> + # https : / / github . com / bazelbuild / bazel / issues / 4381 <nl> + # <nl> + # resolving internal constraint . <nl> + " android_common / com . android . tools . layoutlib_layoutlib_26 . 1 . 2 . jar " , <nl> " android_common / com . android . tools . lint_lint - api_25 . 0 . 0 . jar " , <nl> " android_common / com . android . tools . lint_lint - checks_25 . 0 . 0 . jar " , <nl> " android_common / com . android . tools_common_25 . 0 . 0 . jar " , <nl> binary files a / third_party / android_common / com . android . tools . layoutlib_layoutlib_25 . 0 . 0 . jar and / dev / null differ <nl> binary files / dev / null and b / third_party / android_common / com . android . tools . layoutlib_layoutlib_26 . 1 . 2 . jar differ
class classvsinterface { <nl> if ( result = = null ) { <nl> / / we could just load the outer class here , but this tolerates incomplete classpaths better . <nl> / / note the outer class should be in the jar we ' re desugaring , so it should always be there . <nl> - classreader outerclass = checknotnull ( classpath . readifknown ( outername ) , <nl> - " couldn ' t find outer class % s of % s " , outername , innername ) ; <nl> - result = bitflags . isinterface ( outerclass . getaccess ( ) ) ; <nl> + classreader outerclass = classpath . readifknown ( outername ) ; <nl> + if ( outerclass = = null ) { <nl> + system . err . printf ( " warning : couldn ' t find outer class % s of % s % n " , outername , innername ) ; <nl> + <nl> + result = false ; / / assume it ' s a class if we can ' t find it ( b / 79155927 ) <nl> + } else { <nl> + result = bitflags . isinterface ( outerclass . getaccess ( ) ) ; <nl> + } <nl> known . put ( outername , result ) ; <nl> } <nl> return result ;
public class skyqueryenvironment extends abstractblazequeryenvironment < target > <nl> pathfragment currentpathfragment ) { <nl> if ( originalfilefragment . equals ( currentpathfragment ) <nl> & & originalfilefragment . equals ( label . workspace_file_name ) ) { <nl> + <nl> preconditions . checkstate ( <nl> label . workspace_file_name . getparentdirectory ( ) . equals ( pathfragment . empty_fragment ) , <nl> label . workspace_file_name ) ; <nl>
public class aarimport implements ruleconfiguredtargetfactory { <nl>  <nl>  <nl> javaconfiguration javaconfig = rulecontext . getfragment ( javaconfiguration . class ) ; <nl> - nestedset < artifact > deps = <nl> - getcompiletimejarsfromcollection ( <nl> - targets , <nl> - javaconfig . getimportdepscheckinglevel ( ) = = importdepscheckinglevel . strict_error ) ; <nl> + <nl> + nestedset < artifact > directdeps = getcompiletimejarsfromcollection ( targets , / * isstrict = * / true ) ; <nl> nestedset < artifact > bootclasspath = getbootclasspath ( rulecontext ) ; <nl> artifact depscheckerresult = <nl> createaarartifact ( rulecontext , " aar_import_deps_checker_result . txt " ) ; <nl> artifact jdepsartifact = createaarartifact ( rulecontext , " jdeps . proto " ) ; <nl> importdepscheckactionbuilder . newbuilder ( ) <nl> . bootcalsspath ( bootclasspath ) <nl> - . declaredeps ( deps ) <nl> + . declaredeps ( directdeps ) <nl> . checkjars ( nestedsetbuilder . < artifact > stableorder ( ) . add ( mergedjar ) . build ( ) ) <nl> . outputartifiact ( depscheckerresult ) <nl> . importdepscheckinglevel ( javaconfig . getimportdepscheckinglevel ( ) ) <nl> mmm a / src / test / java / com / google / devtools / build / lib / rules / android / aarimporttest . java <nl> ppp b / src / test / java / com / google / devtools / build / lib / rules / android / aarimporttest . java <nl>
public final class targetcompleteevent <nl> return rootcauses ; <nl> } <nl>  <nl> + public iterable < artifact > getlegacyfilteredimportantartifacts ( ) { <nl> + <nl> + nestedsetbuilder < artifact > builder = new nestedsetbuilder < > ( outputs . getorder ( ) ) ; <nl> + for ( artifactsinoutputgroup artifactsinoutputgroup : outputs ) { <nl> + if ( artifactsinoutputgroup . areimportant ( ) ) { <nl> + builder . addtransitive ( artifactsinoutputgroup . getartifacts ( ) ) ; <nl> + } <nl> + } <nl> + return iterables . filter ( <nl> + builder . build ( ) , <nl> + ( artifact ) - > ! artifact . issourceartifact ( ) & & ! artifact . ismiddlemanartifact ( ) ) ; <nl> + } <nl> + <nl> @ override <nl> public buildeventid geteventid ( ) { <nl> label label = gettarget ( ) . getlabel ( ) ; <nl>
public class fasthotkeyatomiclongmap < t > { <nl> private final concurrentmap < t , atomiclong > map ; <nl>  <nl> public static < t > fasthotkeyatomiclongmap < t > create ( ) { <nl> - return new fasthotkeyatomiclongmap < > ( new mapmaker ( ) ) ; <nl> + return new fasthotkeyatomiclongmap < > ( ) ; <nl> } <nl>  <nl> - public static < t > fasthotkeyatomiclongmap < t > create ( int concurrencylevel ) { <nl> - return new fasthotkeyatomiclongmap < > ( new mapmaker ( ) . concurrencylevel ( concurrencylevel ) ) ; <nl> + <nl> + public static < t > fasthotkeyatomiclongmap < t > create ( int concurrencylevel / * ignored * / ) { <nl> + return new fasthotkeyatomiclongmap < > ( ) ; <nl> } <nl>  <nl> - private fasthotkeyatomiclongmap ( mapmaker mapmaker ) { <nl> - this . map = mapmaker . makemap ( ) ; <nl> + private fasthotkeyatomiclongmap ( ) { <nl> + this . map = new concurrenthashmap < > ( ) ; <nl> } <nl>  <nl> public long incrementandget ( t key ) { <nl> mmm a / src / main / java / com / google / devtools / build / lib / profiler / memory / allocationtracker . java <nl> ppp b / src / main / java / com / google / devtools / build / lib / profiler / memory / allocationtracker . java <nl>
public final class androidbinarymobileinstall { <nl>  <nl> javatargetattributes attributes = <nl> new javatargetattributes . builder ( javasemantics ) <nl> - . addruntimeclasspathentries ( provider . getruntimejars ( ) ) <nl> + <nl> + . addruntimeclasspathentries ( provider . getjavacompilationargs ( ) . getruntimejars ( ) ) <nl> . build ( ) ; <nl>  <nl> function < artifact , artifact > desugaredjars = functions . identity ( ) ; <nl> mmm a / src / main / java / com / google / devtools / build / lib / rules / android / dexarchiveaspect . java <nl> ppp b / src / main / java / com / google / devtools / build / lib / rules / android / dexarchiveaspect . java <nl>
public final class mockprotosupport { <nl> " licenses ( [ ' notice ' ] ) " , <nl> " py_library ( name = ' six ' , " , <nl> " srcs = [ ' __init__ . py ' ] ) " ) ; <nl> + <nl> + config . create ( <nl> + " third_party / java / jsr250_annotations / build " , <nl> + " package ( default_visibility = [ ' / / visibility : public ' ] ) " , <nl> + " licenses ( [ ' notice ' ] ) " , <nl> + " java_library ( name = ' jsr250_source_annotations ' , " , <nl> + " srcs = [ ' generated . java ' ] ) " ) ; <nl> } <nl>  <nl> / * * <nl> mmm a / src / test / java / com / google / devtools / build / lib / rules / java / proto / skylarkjavaliteprotolibrarytest . java <nl> ppp b / src / test / java / com / google / devtools / build / lib / rules / java / proto / skylarkjavaliteprotolibrarytest . java <nl>
public class skylarkjavaliteprotolibrarytest extends buildviewtestcase { <nl>  <nl> scratch . file ( " net / proto2 / compiler / public / build " , " exports_files ( [ ' protocol_compiler ' ] ) " ) ; <nl>  <nl> + <nl> + scratch . file ( <nl> + " third_party / java / jsr250_annotations / build " , <nl> + " package ( default_visibility = [ ' / / visibility : public ' ] ) " , <nl> + " licenses ( [ ' notice ' ] ) " , <nl> + " java_import ( name = ' jsr250_source_annotations ' , " , <nl> + " jars = [ ' jsr250_source_annotations . jar ' ] ) " ) ; <nl> + <nl> mocktoolchains ( ) ; <nl>  <nl> actionstestutil = actionstestutil ( ) ;
public class dynamiccodec implements objectcodec < object > { <nl> @ override <nl> public void serialize ( serializationcontext context , object obj , codedoutputstream codedout ) <nl> throws serializationexception , ioexception { <nl> + <nl> + context = context . getmemoizingcontext ( ) ; <nl> for ( map . entry < field , long > entry : offsets . entryset ( ) ) { <nl> serializefield ( context , codedout , obj , entry . getkey ( ) . gettype ( ) , entry . getvalue ( ) ) ; <nl> } <nl>
public class dynamiccodec implements objectcodec < object > { <nl> throw new serializationexception ( " could not instantiate object of type : " + type , e ) ; <nl> } <nl> context . registerinitialvalue ( instance ) ; <nl> + / / we start memoizing if we weren ' t already doing so . we can ' t start before registering the <nl> + / / initial value because the memoizer would get confused , since it doesn ' t have a tag for this <nl> + / / object . <nl> + <nl> + context = context . getmemoizingcontext ( ) ; <nl> for ( map . entry < field , long > entry : offsets . entryset ( ) ) { <nl> deserializefield ( context , codedin , instance , entry . getkey ( ) . gettype ( ) , entry . getvalue ( ) ) ; <nl> } <nl> mmm a / src / test / java / com / google / devtools / build / lib / skyframe / serialization / dynamiccodectest . java <nl> ppp b / src / test / java / com / google / devtools / build / lib / skyframe / serialization / dynamiccodectest . java <nl>
class arraycodec implements objectcodec < object [ ] > { <nl> public void serialize ( serializationcontext context , object [ ] obj , codedoutputstream codedout ) <nl> throws serializationexception , ioexception { <nl> codedout . writeint32notag ( obj . length ) ; <nl> - for ( object item : obj ) { <nl> - context . serialize ( item , codedout ) ; <nl> + try { <nl> + for ( object item : obj ) { <nl> + context . serialize ( item , codedout ) ; <nl> + } <nl> + } catch ( stackoverflowerror e ) { <nl> + <nl> + throw new serializationexception ( " stackoverflow serializing array " , e ) ; <nl> } <nl> } <nl>  <nl>
class arraycodec implements objectcodec < object [ ] > { <nl> public object [ ] deserialize ( deserializationcontext context , codedinputstream codedin ) <nl> throws serializationexception , ioexception { <nl> object [ ] result = new object [ codedin . readint32 ( ) ] ; <nl> - for ( int i = num ; i < result . length ; i + + ) { <nl> - result [ i ] = context . deserialize ( codedin ) ; <nl> + try { <nl> + for ( int i = num ; i < result . length ; i + + ) { <nl> + result [ i ] = context . deserialize ( codedin ) ; <nl> + } <nl> + } catch ( stackoverflowerror e ) { <nl> + <nl> + throw new serializationexception ( " stackoverflow deserializing array " , e ) ; <nl> } <nl> return result ; <nl> } <nl> mmm a / src / test / java / com / google / devtools / build / lib / skyframe / serialization / arraycodectest . java <nl> ppp b / src / test / java / com / google / devtools / build / lib / skyframe / serialization / arraycodectest . java <nl>
public class artifact <nl> return false ; <nl> } <nl>  <nl> + / * * only callable if issourceartifact ( ) is true . * / <nl> + public sourceartifact assourceartifact ( ) { <nl> + throw new illegalstateexception ( " not a source artifact ! " ) ; <nl> + } <nl> + <nl> + / * * { @ link artifact # issourceartifact ( ) is true . <nl> + * <nl> + * < p > source artifacts have the property that unlike for output artifacts , direct file system <nl> + * access for their contents should be safe , even in a distributed context . <nl> + * <nl> + * <nl> + * * / <nl> + @ autocodec <nl> + public static final class sourceartifact extends artifact { <nl> + @ autocodec . visibleforserialization <nl> + sourceartifact ( artifactroot root , pathfragment execpath , artifactowner owner ) { <nl> + super ( root , execpath , owner ) ; <nl> + } <nl> + <nl> + @ override <nl> + public sourceartifact assourceartifact ( ) { <nl> + return this ; <nl> + } <nl> + } <nl> + <nl> / * * <nl> * special artifact types . <nl> * <nl> mmm a / src / main / java / com / google / devtools / build / lib / actions / artifactfactory . java <nl> ppp b / src / main / java / com / google / devtools / build / lib / actions / artifactfactory . java <nl>
public class skyqueryenvironment extends abstractblazequeryenvironment < target > <nl> return dependentfiles ; <nl> } <nl>  <nl> + protected label getbuildfilelabel ( packageidentifier packageidentifier ) throws queryexception { <nl> + <nl> + path buildfileforload = null ; <nl> + try { <nl> + buildfileforload = pkgpath . getpackagebuildfile ( packageidentifier ) ; <nl> + } catch ( nosuchpackageexception e ) { <nl> + throw new queryexception ( packageidentifier + " does not exist in graph " ) ; <nl> + } <nl> + return label . createunvalidated ( packageidentifier , buildfileforload . getbasename ( ) ) ; <nl> + } <nl> + <nl> private static void addifuniquelabel ( target node , set < label > labels , set < target > nodes ) { <nl> if ( labels . add ( node . getlabel ( ) ) ) { <nl> nodes . add ( node ) ;
public class artifact <nl> return " [ " + root + " ] " + rootrelativepath ; <nl> } else { <nl> / / derived artifact : path and root are under execroot <nl> - pathfragment execroot = trimtail ( getpath ( ) . asfragment ( ) , execpath ) ; <nl> - return " [ [ " <nl> - + execroot <nl> - + " ] " <nl> - + root . getroot ( ) . aspath ( ) . asfragment ( ) . relativeto ( execroot ) <nl> - + " ] " <nl> - + rootrelativepath ; <nl> + / / <nl> + <nl> + return " [ [ < execution_root > ] " + root . getexecpath ( ) + " ] " + rootrelativepath ; <nl> } <nl> } <nl>  <nl> - / * * <nl> - * serializes this artifact to a string that has enough data to reconstruct the artifact . <nl> - * / <nl> - public final string serializetostring ( ) { <nl> - / / in theory , it should be enough to serialize execpath and rootrelativepath ( which is a suffix <nl> - / / of execpath ) . however , in practice there is code around that uses other attributes which <nl> - / / needs cleaning up . <nl> - string result = execpath + " / " + rootrelativepath . tostring ( ) . length ( ) ; <nl> - if ( getowner ( ) ! = null ) { <nl> - result + = " " + getowner ( ) ; <nl> - } <nl> - return result ; <nl> - } <nl> - <nl> / / - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - <nl> / / static methods to assist in working with artifacts <nl>  <nl> mmm a / src / test / java / com / google / devtools / build / lib / actions / artifacttest . java <nl> ppp b / src / test / java / com / google / devtools / build / lib / actions / artifacttest . java <nl>
public final class cccompilationhelper { <nl> return builder . build ( ) ; <nl> } <nl>  <nl> + / * * <nl> + * calculate outputnamemap for different source types separately . returns a merged outputnamemap <nl> + * for all artifacts . <nl> + * / <nl> + private immutablemap < artifact , string > calculateoutputnamemapbytype ( <nl> + set < cppsource > sources , string prefixdir ) { <nl> + immutablemap . builder < artifact , string > builder = immutablemap . builder ( ) ; <nl> + builder . putall ( <nl> + calculateoutputnamemap ( <nl> + getsourceartifactsbytype ( sources , cppsource . type . source ) , prefixdir ) ) ; <nl> + builder . putall ( <nl> + calculateoutputnamemap ( <nl> + getsourceartifactsbytype ( sources , cppsource . type . header ) , prefixdir ) ) ; <nl> + <nl> + builder . putall ( <nl> + calculateoutputnamemap ( <nl> + getsourceartifactsbytype ( sources , cppsource . type . clif_input_proto ) , prefixdir ) ) ; <nl> + return builder . build ( ) ; <nl> + } <nl> + <nl> + private nestedset < artifact > getsourceartifactsbytype ( <nl> + set < cppsource > sources , cppsource . type type ) { <nl> + nestedsetbuilder < artifact > result = nestedsetbuilder . stableorder ( ) ; <nl> + result . addall ( sources <nl> + . stream ( ) <nl> + . filter ( source - > source . gettype ( ) . equals ( type ) ) <nl> + . map ( cppsource : : getsource ) <nl> + . collect ( collectors . tolist ( ) ) ) ; <nl> + return result . build ( ) ; <nl> + } <nl> + <nl> / * * <nl> * constructs the c + + compiler actions . it generally creates one action for every specified source <nl> * file . it takes into account lipo , fake - ness , coverage , and pic , in addition to using the <nl>
cc_binary ( <nl> " / / conditions : default " : [ ] , <nl> } ) , <nl> linkstatic = num , <nl> + # <nl> visibility = [ " / / visibility : public " ] , <nl> deps = [ <nl> " options " , <nl>
import com . google . devtools . build . lib . concurrent . blazeinterners ; <nl> import com . google . devtools . build . lib . skyframe . serialization . autocodec . autocodec ; <nl> import com . google . devtools . build . lib . syntax . buildfileast ; <nl> import com . google . devtools . build . skyframe . abstractskykey ; <nl> + import com . google . devtools . build . skyframe . notcomparableskyvalue ; <nl> import com . google . devtools . build . skyframe . skyfunctionname ; <nl> - import com . google . devtools . build . skyframe . skyvalue ; <nl>  <nl> / * * <nl> * a value that represents an ast file lookup result . there are two subclasses : one for the case <nl> * where the file is found , and another for the case where the file is missing ( but there are no <nl> * other errors ) . <nl> * / <nl> - public abstract class astfilelookupvalue implements skyvalue { <nl> + / / in practice , if a astfilelookupvalue is re - computed ( i . e . not changed pruned ) , then it will <nl> + / / almost certainly be unequal to the previous value . this is because of ( i ) the change - pruning <nl> + / / semantics of the packagelookupvalue dep and the filevalue dep ; consider the latter : if the <nl> + / / filevalue for the bzl file has changed , then the contents of the bzl file probably changed and <nl> + / / ( ii ) we don ' t currently have skylark - semantic - equality in buildfileast , so two buildfileast <nl> + / / instances representing two different contents of a bzl file will be different . <nl> + <nl> + / / the bzl file . for a concrete example , the contents of comment lines do not currently impact <nl> + / / skylark semantics . <nl> + public abstract class astfilelookupvalue implements notcomparableskyvalue { <nl> public abstract boolean lookupsuccessful ( ) ; <nl> public abstract buildfileast getast ( ) ; <nl> public abstract string geterrormsg ( ) ;
eof <nl> | | fail " expected output ' hello world ' " <nl> } <nl>  <nl> + repo_with_local_path_reference ( ) { <nl> + # create , in the current working directory , a pacakge called <nl> + # withpath , that contains rule depending on hard - code path relative <nl> + # to the repository root . <nl> + mkdir - p withpath <nl> + cat > withpath / build < < ' eof ' <nl> + genrule ( <nl> + name = " it " , <nl> + srcs = [ " double . sh " , " data . txt " ] , <nl> + outs = [ " it . txt " ] , <nl> + cmd = " sh $ ( location double . sh ) > $ @ " , <nl> + visibility = [ " / / visibility : public " ] , <nl> + ) <nl> + eof <nl> + cat > withpath / double . sh < < ' eof ' <nl> + # ! / bin / sh <nl> + cat withpath / data . txt withpath / data . txt <nl> + eof <nl> + cat > withpath / data . txt < < ' eof ' <nl> + hello world <nl> + eof <nl> + } <nl> + <nl> + test_fixed_path_local ( ) { <nl> + # verify that hard - coded path relative to the repository root can <nl> + # be used in internal targets . <nl> + wrkdir = $ ( mktemp - d " $ { test_tmpdir } / testxxxxxx " ) <nl> + cd " $ { wrkdir } " <nl> + <nl> + mkdir main <nl> + cd main <nl> + touch workspace <nl> + repo_with_local_path_reference <nl> + <nl> + bazel build / / withpath : it | | fail " expected success " <nl> + } <nl> + <nl> + # <nl> + # to make this ( desirbale ) property true . <nl> + disabled_test_fixed_path_remote ( ) { <nl> + wrkdir = $ ( mktemp - d " $ { test_tmpdir } / testxxxxxx " ) <nl> + cd " $ { wrkdir } " <nl> + <nl> + mkdir remote <nl> + ( cd remote & & repo_with_local_path_reference ) <nl> + tar cvf remote . tar remote <nl> + rm - rf remote <nl> + <nl> + mkdir main <nl> + cd main <nl> + cat > workspace < < eof <nl> + load ( " @ bazel_tools / / tools / build_defs / repo : http . bzl " , " http_archive " ) <nl> + http_archive ( <nl> + name = " remote " , <nl> + strip_prefix = " remote " , <nl> + urls = [ " file : / / $ { wrkdir } / remote . tar " ] , <nl> + ) <nl> + eof <nl> + <nl> + bazel build @ remote / / withpath : it | | fail " expected success " <nl> + } <nl> repo_with_local_implicit_dependencies ( ) { <nl> # create , in the current working directory , a package called rule <nl> # that has an implicit dependency on a target in the same repository ;
java_library ( <nl> ] , <nl> ) <nl>  <nl> + # <nl> java_test ( <nl> name = " skylarktests " , <nl> timeout = " long " , <nl> srcs = glob ( [ <nl> " * . java " , <nl> ] ) , <nl> + flaky = num , <nl> test_class = " com . google . devtools . build . lib . alltests " , <nl> deps = [ <nl> " : testutil " ,
class runfilestest ( test_base . testbase ) : <nl> self . assertexitcode ( exit_code , num , stderr ) <nl> bazel_bin = stdout [ 0 ] <nl>  <nl> - exit_code , _ , stderr = self . runbazel ( [ " build " , " / / bar : all " ] ) <nl> + exit_code , _ , stderr = self . runbazel ( [ " build " , " / / bar : bar - java " ] ) <nl> self . assertexitcode ( exit_code , num , stderr ) <nl>  <nl> - for lang in [ ( " py " , " python " , " bar . py " ) , ( " java " , " java " , " bar . java " ) ] : <nl> + # <nl> + # https : / / github . com / bazelbuild / bazel / issues / 4878 is fixed . <nl> + for lang in [ ( " java " , " java " , " bar . java " ) ] : <nl> if test_base . testbase . iswindows ( ) : <nl> bin_path = os . path . join ( bazel_bin , " bar / bar - % s . exe " % lang [ 0 ] ) <nl> else : <nl> mmm a / tools / runfiles / build . tools <nl> ppp b / tools / runfiles / build . tools <nl>
class androiddatamerger { <nl> boolean checkequality ( datasource one , datasource two ) throws ioexception ; <nl> } <nl>  <nl> + / * * <nl> + * compares two paths for equality . does not check the contents of the files . <nl> + * <nl> + * < p > <nl> + * / <nl> + static class pathcomparingchecker implements sourcechecker { <nl> + <nl> + static sourcechecker create ( ) { <nl> + return new pathcomparingchecker ( ) ; <nl> + } <nl> + <nl> + @ override <nl> + public boolean checkequality ( datasource one , datasource two ) throws ioexception { <nl> + return one . getpath ( ) . equals ( two . getpath ( ) ) ; <nl> + } <nl> + } <nl> + <nl> / * * compares two paths by the contents of the files . * / <nl> static class contentcomparingchecker implements sourcechecker { <nl>  <nl>
public class androidresourcemerger { <nl> path primarymanifest , <nl> boolean allowprimaryoverrideall , <nl> androiddatadeserializer deserializer , <nl> - boolean throwonresourceconflict ) { <nl> + boolean throwonresourceconflict , <nl> + sourcechecker checker ) { <nl> stopwatch timer = stopwatch . createstarted ( ) ; <nl> + <nl> try { <nl> androiddatamerger merger = <nl> - androiddatamerger . createwithpathdeduplictor ( executorservice , deserializer ) ; <nl> + androiddatamerger . createwithpathdeduplictor ( executorservice , deserializer , checker ) ; <nl> return merger . loadandmerge ( <nl> transitive , <nl> direct , <nl>
import java . lang . annotation . target ; <nl> * not need to directly access the generated class . <nl> * / <nl> @ target ( elementtype . type ) <nl> + <nl> + @ retention ( retentionpolicy . runtime ) <nl> public @ interface autocodec { <nl> / * * <nl> * autocodec recursively derives a codec using the public interfaces of the class .
public class autocodecprocessor extends abstractprocessor { <nl> return serializebuilder . build ( ) ; <nl> } <nl>  <nl> + private boolean aretypesrelated ( typemirror t1 , typemirror t2 ) { <nl> + / / if either type is generic , they are considered related . <nl> + <nl> + if ( t1 . getkind ( ) . equals ( typekind . typevar ) | | t2 . getkind ( ) . equals ( typekind . typevar ) ) { <nl> + return true ; <nl> + } <nl> + return env . gettypeutils ( ) . isassignable ( t1 , t2 ) | | env . gettypeutils ( ) . isassignable ( t2 , t1 ) ; <nl> + } <nl> + <nl> private string findgetterforclass ( variableelement parameter , typeelement type ) { <nl> list < executableelement > methods = <nl> elementfilter . methodsin ( env . getelementutils ( ) . getallmembers ( type ) ) ; <nl>
class argtokenstream { <nl> class filetokenstream { <nl> public : <nl> filetokenstream ( const char * filename ) { <nl> + <nl> + / / https : / / github . com / google / protobuf / blob / <nl> + / / <commit_id> / <nl> + / / src / google / protobuf / stubs / io_win32 . cc <nl> + / / best would be to extract that library to a common location and use <nl> + / / here , in protobuf , and in bazel itself . <nl> if ( ! ( fp_ = fopen ( filename , " r " ) ) ) { <nl> diag_err ( 1 , " % s " , filename ) ; <nl> }
public abstract class ziputil { <nl> throws ioexception { <nl> zipentry entry = new zipentry ( name ) ; <nl> entry . setmethod ( zipentry . stored ) ; <nl> - entry . settime ( dos_epoch ) ; <nl> + <nl> + entry . settime ( default_timestamp ) ; <nl> entry . setsize ( content . length ) ; <nl> crc32 crc32 = new crc32 ( ) ; <nl> crc32 . update ( content ) ;
public class bazelruleclassprovider { <nl> immutableset . of ( <nl> / / rules defined before lipodatatransitionruleset will fail when trying to declare a data <nl> / / transition . <nl> + <nl> lipodatatransitionruleset . instance , <nl> bazel_setup , <nl> corerules . instance ,
class headerclassloader extends classloader { <nl> / / have asm compute maxs so we don ' t need to figure out how many formal parameters there are <nl> classwriter writer = new classwriter ( classwriter . compute_maxs ) ; <nl> immutablelist < fieldinfo > interfacefieldnames = getfieldsifreaderisinterface ( reader ) ; <nl> - reader . accept ( new codestubber ( writer , interfacefieldnames ) , num ) ; <nl> + <nl> + reader . accept ( new codestubber ( writer , interfacefieldnames ) , classreader . skip_debug ) ; <nl> bytecode = writer . tobytearray ( ) ; <nl> } catch ( ioexception e ) { <nl> throw new ioerror ( e ) ;
exports_files ( <nl> [ " hash . bzl " ] , <nl> visibility = [ " / / visibility : public " ] , <nl> ) <nl> + <nl> + sh_test ( <nl> + name = " sha256_test " , <nl> + size = " small " , <nl> + srcs = [ " sha256_test . sh " ] , <nl> + data = [ " sha256 " ] , <nl> + # <nl> + # https : / / github . com / bazelbuild / bazel / issues / 4460 is fixed for sh_ * <nl> + tags = [ " - no_windows " ] , <nl> + ) <nl> mmm a / tools / build_defs / hash / sha256 . py <nl> ppp b / tools / build_defs / hash / sha256 . py <nl>
py_test ( <nl> name = " launcher_test " , <nl> size = " medium " , <nl> srcs = [ " launcher_test . py " ] , <nl> + tags = [ " manual " ] , # <nl> deps = [ " : test_base " ] , <nl> )
public class configuredruleclassprovider implements ruleclassprovider { <nl>  <nl> / * * returns all skylark objects in global scope for this ruleclassprovider . * / <nl> public map < string , object > gettransitiveglobalbindings ( ) { <nl> - return globals . gettransitivebindings ( ) ; <nl> + <nl> + return immutablesortedmap . copyof ( globals . gettransitivebindings ( ) ) ; <nl> } <nl>  <nl> / * * returns all registered { @ link buildconfiguration . fragment } classes . * /
public abstract class skylarkinfo extends info implements concatable { <nl> } <nl>  <nl> / * * a { @ link skylarkinfo } implementation that stores its values in a map . * / <nl> - private static final class mapbackedskylarkinfo extends skylarkinfo { <nl> + <nl> + public static final class mapbackedskylarkinfo extends skylarkinfo { <nl>  <nl> private final immutablemap < string , object > values ;
java_test ( <nl> srcs = [ <nl> " desugarcorelibraryfunctionaltest . java " , <nl> ] , <nl> + # <nl> jvm_flags = [ " - xbootclasspath / p : $ ( location : testdata_desugared_core_library ) : $ ( location / / third_party / java / jacoco : blaze - agent ) " ] , <nl> tags = [ " no_windows " ] , <nl> deps = [ <nl>
public final class dependencymodule { <nl> collectdependenciesfromartifact ( depsartifact ) ; <nl> } <nl>  <nl> + <nl> + <nl> / / filter the initial classpath and keep the original order <nl> return originalclasspath <nl> . stream ( )
public class packagegroup implements target { <nl> this . containingpackage = pkg ; <nl> this . includes = immutablelist . copyof ( includes ) ; <nl>  <nl> + <nl> immutablelist . builder < packagespecification > packagesbuilder = immutablelist . builder ( ) ; <nl> for ( string packagespecification : packagespecifications ) { <nl> packagespecification specification = null ;
abstract class abstractsandboxspawnrunner implements spawnrunner { <nl> writablepaths . add ( sandboxexecroot ) ; <nl> string tmpdirstring = env . get ( " test_tmpdir " ) ; <nl> if ( tmpdirstring ! = null ) { <nl> - pathfragment testtmpdir = pathfragment . create ( tmpdirstring ) ; <nl> - if ( testtmpdir . isabsolute ( ) ) { <nl> - path p = filesystem . getpath ( testtmpdir ) ; <nl> - if ( ! p . exists ( ) ) { <nl> - / / if ` testtmpdir ` itself is a symlink , then adding it to ` writablepaths ` would result in <nl> - / / making the symlink itself writable , not what it points to . therefore we need to resolve <nl> - / / symlinks in ` testtmpdir ` , however for that we need ` testtmpdir ` to exist . <nl> - throw new ioexception ( <nl> - string . format ( <nl> - " cannot resolve symlinks in test_tmpdir , because it is a non - existent , " <nl> - + " absolute path : \ " % s \ " " , <nl> - p . getpathstring ( ) ) ) ; <nl> - } <nl> - writablepaths . add ( p . resolvesymboliclinks ( ) ) ; <nl> - } else { <nl> - / / we add this even though it is below sandboxexecroot ( and thus already writable as a <nl> + path p = sandboxexecroot . getrelative ( tmpdirstring ) ; <nl> + if ( p . startswith ( sandboxexecroot ) ) { <nl> + / / we add this path even though it is below sandboxexecroot ( and thus already writable as a <nl> / / subpath ) to take advantage of the side - effect that symlinkedexecroot also creates this <nl> / / needed directory if it doesn ' t exist yet . <nl> - writablepaths . add ( sandboxexecroot . getrelative ( testtmpdir ) ) ; <nl> + writablepaths . add ( p ) ; <nl> + } else if ( p . exists ( ) ) { <nl> + / / if ` p ` itself is a symlink , then adding it to ` writablepaths ` would result in making the <nl> + / / symlink itself writable , not what it points to . therefore we need to resolve symlinks in <nl> + / / ` p ` , however for that we need ` p ` to exist . <nl> + writablepaths . add ( p . resolvesymboliclinks ( ) ) ; <nl> + } else { <nl> + throw new ioexception ( <nl> + string . format ( <nl> + " cannot resolve symlinks in test_tmpdir because it doesn ' t exist : \ " % s \ " " , <nl> + p . getpathstring ( ) ) ) ; <nl> } <nl> } <nl>  <nl> + <nl> + / / adding a symlink to the writable paths , and not what the symlink points to . <nl> writablepaths . add ( tmpdir ) ; <nl>  <nl> for ( string writablepath : sandboxoptions . sandboxwritablepath ) {
public final class queryparser { <nl> * scan and parse the specified query expression . <nl> * / <nl> static queryexpression parse ( string query , queryenvironment < ? > env ) throws queryexception { <nl> - hashmap < string , queryfunction > functions = new hashmap < > ( ) ; <nl> - for ( queryfunction queryfunction : env . getfunctions ( ) ) { <nl> - functions . put ( queryfunction . getname ( ) , queryfunction ) ; <nl> - } <nl> - return parse ( query , functions ) ; <nl> - } <nl> - <nl> - public static queryexpression parse ( string query , hashmap < string , queryfunction > functions ) <nl> - throws queryexception { <nl> - queryparser parser = new queryparser ( lexer . scan ( query ) , functions ) ; <nl> + queryparser parser = new queryparser ( lexer . scan ( query ) , env ) ; <nl> queryexpression expr = parser . parseexpression ( ) ; <nl> if ( parser . token . kind ! = tokenkind . eof ) { <nl> throw new queryexception ( " unexpected token ' " + parser . token <nl> - + " ' after query expression ' " + expr + " ' " ) ; <nl> + + " ' after query expression ' " + expr + " ' " ) ; <nl> } <nl> return expr ; <nl> } <nl>  <nl> - public queryparser ( list < lexer . token > tokens , hashmap < string , queryfunction > functions ) { <nl> - this . functions = functions ; <nl> + private queryparser ( list < lexer . token > tokens , queryenvironment < ? > env ) { <nl> + <nl> + / / things , simpler . <nl> + this . functions = new hashmap < > ( ) ; <nl> + for ( queryfunction queryfunction : env . getfunctions ( ) ) { <nl> + this . functions . put ( queryfunction . getname ( ) , queryfunction ) ; <nl> + } <nl> this . tokens = tokens ; <nl> this . tokeniterator = tokens . iterator ( ) ; <nl> nexttoken ( ) ; <nl> mmm a / src / test / java / com / google / devtools / build / lib / analysis / util / analysistestcase . java <nl> ppp b / src / test / java / com / google / devtools / build / lib / analysis / util / analysistestcase . java <nl>
public class androidresourceprocessingaction { <nl>  <nl> logger . fine ( string . format ( " merging finished at % sms " , timer . elapsed ( timeunit . milliseconds ) ) ) ; <nl>  <nl> - final list < string > densitiestofilter = <nl> - options . prefilteredresources . isempty ( ) <nl> - ? options . densities <nl> - : collections . < string > emptylist ( ) ; <nl> final list < string > densitiesformanifest = <nl> - densitiestofilter . isempty ( ) ? options . densitiesformanifest : densitiestofilter ; <nl> + options . densities . isempty ( ) ? options . densitiesformanifest : options . densities ; <nl> + <nl> + <nl> + final list < string > densitiestofilter = densitiesformanifest ; <nl>  <nl> final densityfilteredandroiddata filtereddata = <nl> mergeddata . filter (
sh_test ( <nl> size = " large " , <nl> srcs = [ " toolchain_test . sh " ] , <nl> data = [ " : test - deps " ] , <nl> + # <nl> + flaky = num , <nl> shard_count = num , <nl> )
public class cppconfiguration extends buildconfiguration . fragment { <nl>  <nl> / * * <nl> * returns the gnu system name <nl> + * <nl> * / <nl> + <nl> @ skylarkcallable ( name = " target_gnu_system_name " , structfield = true , <nl> doc = " the gnu system name . " ) <nl> + @ deprecated <nl> public string gettargetgnusystemname ( ) { <nl> return cpptoolchaininfo . gettargetgnusystemname ( ) ; <nl> }
public class compilationsupport { <nl> collection < artifact > privatehdrs , <nl> collection < artifact > publichdrs , <nl> artifact pchhdr , <nl> + <nl> + iterable < ? extends transitiveinfocollection > deps , <nl> objccppsemantics semantics , <nl> string purpose ) <nl> throws ruleerrorexception , interruptedexception { <nl>
public class aapt2resourcepackagingaction { <nl> final path compiledresources = files . createdirectories ( tmp . resolve ( " compiled " ) ) ; <nl> final path linkedout = files . createdirectories ( tmp . resolve ( " linked " ) ) ; <nl>  <nl> - final list < string > densitiestofilter = <nl> - options . prefilteredresources . isempty ( ) <nl> - ? options . densities <nl> - : collections . < string > emptylist ( ) ; <nl> - <nl> - final list < string > densitiesformanifest = <nl> - densitiestofilter . isempty ( ) ? options . densitiesformanifest : densitiestofilter ; <nl> + final list < string > densities ; <nl> + if ( options . densities . isempty ( ) ) { <nl> + / / aapt2 always needs to filter on densities , as the resource filtering from analysis is <nl> + / / disregarded . <nl> + <nl> + densities = options . densitiesformanifest ; <nl> + } else { <nl> + densities = options . densities ; <nl> + } <nl>  <nl> profiler . recordendof ( " setup " ) . starttask ( " merging " ) ; <nl>  <nl>
public class windowsprocesses { <nl>  <nl> private static native int nativegetpid ( ) ; <nl>  <nl> + <nl> + / / more info : http : / / daviddeley . com / autohotkey / parameters / parameters . htm <nl> public static string quotecommandline ( list < string > argv ) { <nl> stringbuilder result = new stringbuilder ( ) ; <nl> for ( int iarg = num ; iarg < argv . size ( ) ; iarg + + ) { <nl>
<nl> } <nl> } , { <nl> " configurations " : [ <nl> - { " node " : " freebsd - 11 " } , <nl> - { " node " : " freebsd - 12 " } <nl> + { " node " : " freebsd - 11 " } / / , <nl> + <nl> ] , <nl> " parameters " : { <nl> / / as configure step , we redo the uses = shebangfix of the devel / bazel
public class applecommandlineoptions extends fragmentoptions { <nl> } <nl> } <nl>  <nl> + <nl> @ option ( <nl> name = " xcode_toolchain " , <nl> defaultvalue = " null " , <nl>
public abstract class skylarktype implements serializable { <nl> * throws evalexception if the type of the object is not allowed to be present in skylark . <nl> * / <nl> static void checktypeallowedinskylark ( object object , location loc ) throws evalexception { <nl> + <nl> + / / skylarklist , etc . <nl> if ( ! istypeallowedinskylark ( object ) ) { <nl> throw new evalexception ( <nl> - loc , " internal error : type ' " + object . getclass ( ) . getsimplename ( ) + " ' is not allowed " ) ; <nl> + loc , <nl> + " internal error : type ' " + object . getclass ( ) . getsimplename ( ) + " ' is not allowed as a " <nl> + + " skylark value ( checktypeallowedinskylark ( ) failed ) " ) ; <nl> } <nl> }
public final class errorproneplugin extends blazejavacompilerplugin { <nl> javacmessages . instance ( context ) . add ( " com . google . errorprone . errors " ) ; <nl> } <nl>  <nl> + private static final string compiling_test_only_code_arg = " - xepcompilingtestonlycode " ; <nl> + <nl> @ override <nl> public list < string > processargs ( list < string > args ) throws invalidcommandlineexception { <nl> + immutablelist . builder < string > epargs = immutablelist . < string > builder ( ) . addall ( args ) ; <nl> / / allow javacopts that reference unknown error - prone checks <nl> - return processepoptions ( <nl> - immutablelist . < string > builder ( ) . addall ( args ) . add ( " - xepignoreunknownchecknames " ) . build ( ) ) ; <nl> + epargs . add ( " - xepignoreunknownchecknames " ) ; <nl> + if ( testonly ( ) ) { <nl> + epargs . add ( compiling_test_only_code_arg ) ; <nl> + } <nl> + return processepoptions ( epargs . build ( ) ) <nl> + <nl> + / / remove this once the num p version is recent enough . <nl> + . stream ( ) <nl> + . filter ( arg - > ! arg . equals ( compiling_test_only_code_arg ) ) <nl> + . collect ( immutablelist . toimmutablelist ( ) ) ; <nl> } <nl>  <nl> private list < string > processepoptions ( list < string > args ) throws invalidcommandlineexception {
class actiontemptest ( test_base . testbase ) : <nl>  <nl> def _spawnstrategies ( self ) : <nl> " " " returns the list of supported - - spawn_strategy values . " " " <nl> - exit_code , _ , stderr = self . runbazel ( <nl> - [ ' build ' , ' - - color = no ' , ' - - curses = no ' , ' - - spawn_strategy = foo ' ] ) <nl> + # <nl> + exit_code , _ , stderr = self . runbazel ( [ <nl> + ' build ' , ' - - color = no ' , ' - - curses = no ' , ' - - spawn_strategy = foo ' , <nl> + ' - - noexperimental_ui ' <nl> + ] ) <nl> self . assertexitcode ( exit_code , num , stderr ) <nl> pattern = re . compile ( <nl> r ' ^ error : . * is an invalid value for . * valid values are : ( . * ) \ . $ ' ) <nl>
class actiontemptest ( test_base . testbase ) : <nl> self . assertexitcode ( exit_code , num , stderr ) <nl> bazel_bin = stdout [ 0 ] <nl>  <nl> + # <nl> exit_code , _ , stderr = self . runbazel ( [ <nl> - ' build ' , ' - - verbose_failures ' , <nl> + ' build ' , ' - - verbose_failures ' , ' - - noexperimental_ui ' , <nl> ' - - spawn_strategy = % s ' % strategy , ' / / foo : genrule ' , ' / / foo : skylark ' <nl> ] ) <nl> self . assertexitcode ( exit_code , num , stderr )
source " $ { current_dir } / remote_helpers . sh " \ <nl> function set_up ( ) { <nl> bazel clean - - expunge > & $ test_log <nl> repo_cache_dir = $ test_tmpdir / repository_cache <nl> + # <nl> + add_to_bazelrc " fetch - - noexperimental_ui " <nl> + add_to_bazelrc " build - - noexperimental_ui " <nl> + add_to_bazelrc " build - - noexperimental_skyframe_target_pattern_evaluator " <nl> } <nl>  <nl> function tear_down ( ) { <nl> mmm a / src / test / shell / bazel / bazel_test_test . sh <nl> ppp b / src / test / shell / bazel / bazel_test_test . sh <nl>
eof <nl> chmod + x true . sh flaky . sh false . sh <nl>  <nl> # we do not use sandboxing so we can trick to be deterministically flaky <nl> - bazel - - nomaster_bazelrc test - - spawn_strategy = standalone / / : flaky & > $ test_log \ <nl> + # <nl> + bazel - - nomaster_bazelrc test - - noexperimental_ui - - noexperimental_skyframe_target_pattern_evaluator - - spawn_strategy = standalone / / : flaky & > $ test_log \ <nl> | | fail " / / : flaky should have passed with flaky support " <nl> [ - f " $ { flake_file } " ] | | fail " flaky test should have created the flake - file ! " <nl>  <nl>
eof <nl> cat bazel - testlogs / flaky / test . log & > $ test_log <nl> assert_equals " pass " " $ ( tail - 1 bazel - testlogs / flaky / test . log ) " <nl>  <nl> - bazel - - nomaster_bazelrc test / / : pass & > $ test_log \ <nl> + # <nl> + bazel - - nomaster_bazelrc test - - noexperimental_ui - - noexperimental_skyframe_target_pattern_evaluator / / : pass & > $ test_log \ <nl> | | fail " / / : pass should have passed " <nl> expect_log_once " pass : / / : pass " <nl> expect_log_once passed <nl>
eof <nl> cat bazel - testlogs / flaky / test . log & > $ test_log <nl> assert_equals " pass " " $ ( tail - 1 bazel - testlogs / flaky / test . log ) " <nl>  <nl> - bazel - - nomaster_bazelrc test / / : fail & > $ test_log \ <nl> + # <nl> + bazel - - nomaster_bazelrc test - - noexperimental_ui - - noexperimental_skyframe_target_pattern_evaluator / / : fail & > $ test_log \ <nl> & & fail " / / : fail should have failed " \ <nl> | | true <nl> expect_log_n " fail : / / : fail ( . * / fail / test_attempts / attempt_ . . log ) " num <nl> mmm a / src / test / shell / bazel / local_repository_test . sh <nl> ppp b / src / test / shell / bazel / local_repository_test . sh <nl>
public final class commandenvironment { <nl> } <nl>  <nl> / * * <nl> - * returns the uuid that blaze uses to identify everything logged from the current build request . <nl> + * returns the id that blaze uses to identify everything logged from the current build request . <nl> + * <nl> * / <nl> - public uuid getbuildrequestid ( ) { <nl> + public string getbuildrequestid ( ) { <nl> return preconditions . checknotnull ( buildrequestid ) ; <nl> }
public class standalonespawnstrategytest { <nl>  <nl> @ test <nl> public void testcommandhonorsenvironment ( ) throws exception { <nl> + if ( os . getcurrent ( ) = = os . darwin ) { <nl> + / / <nl> + / / down where that env var is coming from . <nl> + return ; <nl> + } <nl> spawn spawn = new basespawn . local ( <nl> arrays . aslist ( " / usr / bin / env " ) , <nl> immutablemap . of ( " foo " , " bar " , " baz " , " boo " ) ,
public class evalexceptionwithstacktrace extends evalexception { <nl> addstackframe ( funcalldescription , location , false ) ; <nl> } <nl>  <nl> - / * * <nl> - * adds a line for the given frame . <nl> - * / <nl> + / * * adds a line for the given frame . * / <nl> private void addstackframe ( string label , location location , boolean canprint ) { <nl> - / / we have to watch out for duplicate since expressionstatements add themselves twice : <nl> - / / statement # exec ( ) calls expression # eval ( ) , both of which call this method . <nl> + <nl> + / / be better to eliminate the check and not create unwanted duplicates in the first place . <nl> + / / <nl> + / / the check is problematic because it suppresses tracebacks in the repl , where line numbers <nl> + / / can be reset within a single session . <nl> if ( mostrecentelement ! = null & & issamelocation ( location , mostrecentelement . getlocation ( ) ) ) { <nl> return ; <nl> } <nl> mostrecentelement = new stackframe ( label , location , mostrecentelement , canprint ) ; <nl> } <nl>  <nl> + private void addstackframe ( string label , location location ) { <nl> + addstackframe ( label , location , true ) ; <nl> + } <nl> + <nl> / * * <nl> * checks two locations for equality in paths and start offsets . <nl> * <nl>
public class cctoolchain implements ruleconfiguredtargetfactory { <nl> return null ; <nl> } <nl>  <nl> + <nl> string rawprofilefilename = " fdocontrolz_profile . profraw " ; <nl> + string cpu = cppconfiguration . gettargetcpu ( ) ; <nl> + if ( ! " k8 " . equals ( cpu ) ) { <nl> + rawprofilefilename = " fdocontrolz_profile - " + cpu + " . profraw " ; <nl> + } <nl> rawprofileartifact = <nl> rulecontext . getuniquedirectoryartifact ( <nl> " fdo " , rawprofilefilename , rulecontext . getbinorgenfilesdirectory ( ) ) ;
function tempdir ( ) { <nl> local dir = " $ ( mktemp - d " $ { tmp % % / } / bazel_xxxxxxxx " ) " <nl> mkdir - p " $ { dir } " <nl> local dirbase = $ ( basename " $ { dir } " ) <nl> - eval " cleanup_tempdir_ $ { dirbase } ( ) { rm - rf ' $ { dir } ' > & / dev / null | | true ; } " <nl> + # <nl> + # following command after we fixed https : / / github . com / bazelbuild / bazel / issues / 3618 . <nl> + eval " cleanup_tempdir_ $ { dirbase } ( ) { [ - n \ " \ $ test_tmpdir \ " ] & & echo \ " debug [ $ 0 ( \ $ ( date ) ) ] deleting ( $ dir ) \ " ; rm - rf ' $ { dir } ' > & / dev / null | | true ; } " <nl> atexit cleanup_tempdir_ $ { dirbase } <nl> new_tmpdir = " $ { dir } " <nl> } <nl> mmm a / src / test / shell / bazel / bazel_bootstrap_distfile_test . sh <nl> ppp b / src / test / shell / bazel / bazel_bootstrap_distfile_test . sh <nl>
static void extractdata ( const string & self_path ) { <nl> continue ; <nl> } <nl> if ( ! blaze_util : : canreadfile ( path ) ) { <nl> + <nl> + # if num <nl> + fprintf ( stderr , <nl> + " debug : corrupt installation : file ' % s ' missing . " <nl> + " dumping debug data . \n " , <nl> + path . c_str ( ) ) ; <nl> + string p = path ; <nl> + while ( ! p . empty ( ) ) { <nl> + fprintf ( stderr , " debug : p = ( % s ) , exists = % d , isdir = % d , canread = % d\n " , <nl> + p . c_str ( ) , blaze_util : : pathexists ( p ) ? num : num , <nl> + blaze_util : : isdirectory ( p ) ? num : num , <nl> + blaze_util : : canreadfile ( p ) ? num : num ) ; <nl> + string parent = blaze_util : : dirname ( p ) ; <nl> + if ( parent = = p ) { <nl> + break ; <nl> + } else { <nl> + p = parent ; <nl> + } <nl> + } <nl> + # endif <nl> die ( blaze_exit_code : : local_environmental_error , <nl> " error : corrupt installation : file ' % s ' missing . " <nl> " please remove ' % s ' and try again . " ,
public final class filesetentryfunction implements skyfunction { <nl>  <nl> / / check whether the symlink is excluded before attempting to resolve it . <nl> / / it may be dangling , but excluding it is still fine . <nl> - if ( exclusions . contains ( linkname . getpathstring ( ) ) ) { <nl> + <nl> + if ( linkname . segmentcount ( ) > num & & exclusions . contains ( linkname . getsegment ( 0 ) ) ) { <nl> continue ; <nl> } <nl>  <nl> mmm a / src / test / java / com / google / devtools / build / lib / skyframe / filesetentryfunctiontest . java <nl> ppp b / src / test / java / com / google / devtools / build / lib / skyframe / filesetentryfunctiontest . java <nl>
public class skylarkrepositorymodule { <nl> public object call ( <nl> object [ ] args , funcallexpression ast , com . google . devtools . build . lib . syntax . environment env ) <nl> throws evalexception , interruptedexception { <nl> - string ruleclassname = preconditions . checknotnull ( ast . getfunctionnameifpossible ( ) ) ; <nl> + string ruleclassname = null ; <nl> + expression function = ast . getfunction ( ) ; <nl> + if ( function instanceof identifier ) { <nl> + ruleclassname = ( ( identifier ) function ) . getname ( ) ; <nl> + } else if ( function instanceof dotexpression ) { <nl> + ruleclassname = ( ( dotexpression ) function ) . getfield ( ) . getname ( ) ; <nl> + } else { <nl> + <nl> + throw new illegalstateexception ( " function is not an identifier or method call " ) ; <nl> + } <nl> try { <nl> ruleclass ruleclass = builder . build ( ruleclassname ) ; <nl> packagecontext context = packagefactory . getcontext ( env , ast ) ; <nl> mmm a / src / main / java / com / google / devtools / build / lib / syntax / funcallexpression . java <nl> ppp b / src / main / java / com / google / devtools / build / lib / syntax / funcallexpression . java <nl>
public class objccppsemantics implements cppsemantics { <nl> actionbuilder . addmandatoryinputs ( <nl> immutablelist . of ( intermediateartifacts . headerslistfile ( sourcefile ) ) ) ; <nl> } <nl> + } else { <nl> + / / header thinning feature will make all generated files mandatory inputs to the <nl> + / / objcheaderscanning action so this is only required when that is disabled <nl> + <nl> + immutableset . builder < artifact > generatedheaders = immutableset . builder ( ) ; <nl> + for ( artifact header : objcprovider . get ( header ) ) { <nl> + if ( ! header . issourceartifact ( ) ) { <nl> + generatedheaders . add ( header ) ; <nl> + } <nl> + } <nl> + actionbuilder . addmandatoryinputs ( generatedheaders . build ( ) ) ; <nl> } <nl> }
public class testrunneraction extends abstractaction implements notifyonactionca <nl> env . put ( " coverage_manifest " , getcoveragemanifest ( ) . getexecpathstring ( ) ) ; <nl> env . put ( " coverage_dir " , getcoveragedirectory ( ) . getpathstring ( ) ) ; <nl> env . put ( " coverage_output_file " , getcoveragedata ( ) . getexecpathstring ( ) ) ; <nl> + <nl> + env . put ( " new_java_coverage_impl " , " true " ) ; <nl> } <nl> }
<nl>  <nl> out = $ 1 <nl> gendir = $ 2 <nl> - strip_prefix = $ 3 <nl>  <nl> - shift num <nl> + shift num <nl>  <nl> + # the bazel and google - internal locations of the bootclasspath entries are <nl> + # unfortunately subtly different . the " local_jdk " rewrite is for bazel , and <nl> + # the " third_party " rewrite is for google . <nl> + # <nl> bootclasspath = $ ( echo " $ * " | \ <nl> tr " " " \n " | \ <nl> sed " s | ^ $ { gendir } / | | " | \ <nl> - sed " s | external / | | " | \ <nl> - sed " s | ^ | $ { strip_prefix } | " | \ <nl> + sed " s | ^ . * local_jdk | local_jdk | " | \ <nl> + sed " s | ^ third_party | $ { pwd # # * / } / third_party | " | \ <nl> tr " \n " " : " | \ <nl> sed " s / : $ / / " <nl> )
string binarylauncherbase : : findmanifestfile ( const char * argv0 ) { <nl>  <nl> void binarylauncherbase : : parsemanifestfile ( manifestfilemap * manifest_file_map , <nl> const string & manifest_path ) { <nl> + <nl> + / / format , e . g . " \ \ \ \ ? \ \ c : \ \ imagine \ \ some \ \ very \ \ long \ \ path . txt " . <nl> ifstream manifest_file ( manifest_path . c_str ( ) ) ; <nl>  <nl> if ( ! manifest_file ) { <nl> mmm a / src / tools / launcher / util / launcher_util . cc <nl> ppp b / src / tools / launcher / util / launcher_util . cc <nl>
void printerror ( const char * format , . . . ) { <nl> } <nl>  <nl> bool doesfilepathexist ( const char * path ) { <nl> - dword dwattrib = getfileattributes ( path ) ; <nl> + <nl> + dword dwattrib = getfileattributesa ( path ) ; <nl>  <nl> return ( dwattrib ! = invalid_file_attributes & & <nl> ! ( dwattrib & file_attribute_directory ) ) ;
public abstract class skylarkapiprovider { <nl>  <nl> public final void init ( transitiveinfocollection info ) { <nl> if ( this . info ! = null ) { <nl> - / / allow multiple calls , but only consistent ones . <nl> - preconditions . checkstate ( info = = this . info ) ; <nl> + <nl> + <nl> + / / allow multiple calls . <nl> + / / it is possible for the skylark rule to get a skylarkapiprovider such as ` target . java ` <nl> + / / from its dependency and pass it on . it does not make a whole lot of sense , but we <nl> + / / shouldn ' t crash . <nl> return ; <nl> } <nl> this . info = preconditions . checknotnull ( info ) ; <nl> mmm a / src / test / java / com / google / devtools / build / lib / rules / java / javaskylarkapitest . java <nl> ppp b / src / test / java / com / google / devtools / build / lib / rules / java / javaskylarkapitest . java <nl>
import java . io . serializable ; <nl> * / <nl> @ usesonlycoretypes <nl> public class skylarksemanticsoptions extends optionsbase implements serializable { <nl> - / / used in an integration test to confirm that flags are visible to the interpreter . <nl> + <nl> + / * * used in an integration test to confirm that flags are visible to the interpreter . * / <nl> @ option ( <nl> name = " internal_skylark_flag_test_canary " , <nl> defaultvalue = " false " , <nl> documentationcategory = optiondocumentationcategory . undocumented , <nl> effecttags = { optioneffecttag . unknown } <nl> ) <nl> - public boolean skylarkflagtestcanary ; <nl> + public boolean internalskylarkflagtestcanary ; <nl> + <nl> + / * * <nl> + * used in testing to produce a truly minimalistic extension object for certain evaluation <nl> + * contexts . this flag is bazel - specific . <nl> + * / <nl> + <nl> + @ option ( <nl> + name = " internal_do_not_export_builtins " , <nl> + defaultvalue = " false " , <nl> + documentationcategory = optiondocumentationcategory . undocumented , <nl> + effecttags = { optioneffecttag . unknown } <nl> + ) <nl> + public boolean internaldonotexportbuiltins ; <nl>  <nl> @ option ( <nl> name = " incompatible_disallow_set_constructor " ,
public class cppconfiguration extends buildconfiguration . fragment { <nl> private final label crosstooltop ; <nl> private final string hostsystemname ; <nl> private final string compiler ; <nl> + <nl> + / / it here so that the output directory doesn ' t depend on the ctoolchain . when we will eventually <nl> + / / verify that the two are the same , we can remove one of desiredcpu and targetcpu . <nl> + private final string desiredcpu ; <nl> private final string targetcpu ; <nl> private final string targetsystemname ; <nl> private final string targetlibc ; <nl>
public class blazejavacmain { <nl> protected classloader getclassloader ( url [ ] urls ) { <nl> return new urlclassloader ( <nl> urls , <nl> - new classloader ( javacfilemanager . class . getclassloader ( ) ) { <nl> + new classloader ( null ) { <nl> @ override <nl> protected class < ? > findclass ( string name ) throws classnotfoundexception { <nl> - if ( name . startswith ( " com . google . errorprone . " ) ) { <nl> - return class . forname ( name ) ; <nl> - } else if ( name . startswith ( " org . checkerframework . dataflow . " ) ) { <nl> - return class . forname ( name ) ; <nl> - } else { <nl> - throw new classnotfoundexception ( name ) ; <nl> + class < ? > c = class . forname ( name ) ; <nl> + if ( name . startswith ( " com . google . errorprone . " ) <nl> + | | name . startswith ( " org . checkerframework . dataflow . " ) <nl> + | | name . startswith ( " com . sun . source . " ) <nl> + | | name . startswith ( " com . sun . tools . " ) ) { <nl> + return c ; <nl> } <nl> + if ( c . getclassloader ( ) = = null <nl> + | | objects . equals ( getclassloadername ( c . getclassloader ( ) ) , " platform " ) ) { <nl> + return c ; <nl> + } <nl> + throw new classnotfoundexception ( name ) ; <nl> } <nl> } ) ; <nl> } <nl> } <nl>  <nl> + <nl> + private static string getclassloadername ( classloader classloader ) { <nl> + method method ; <nl> + try { <nl> + method = classloader . class . getmethod ( " getname " ) ; <nl> + } catch ( nosuchmethodexception e ) { <nl> + / / classloader # getname doesn ' t exist in jdk num and earlier . <nl> + return null ; <nl> + } <nl> + try { <nl> + return ( string ) method . invoke ( classloader , new object [ ] { } ) ; <nl> + } catch ( reflectiveoperationexception e ) { <nl> + throw new linkageerror ( e . getmessage ( ) , e ) ; <nl> + } <nl> + } <nl> + <nl> private blazejavacmain ( ) { } <nl> }
<nl> package ( default_visibility = [ " / / visibility : public " ] ) <nl>  <nl> + # <nl> + load ( " / / tools / cpp : alias_rules . bzl " , " cc_toolchain_alias " ) <nl> + <nl> + cc_toolchain_alias ( name = " current_cc_toolchain " ) <nl> + <nl> cc_library ( <nl> name = " malloc " , <nl> ) <nl> mmm / dev / null <nl> ppp b / tools / cpp / alias_rules . bzl <nl>
<nl> package ( default_visibility = [ " / / visibility : public " ] ) <nl>  <nl> + # <nl> + # in a bazel release <nl> + load ( " / / tools / jdk : alias_rules . bzl " , " java_runtime_alias " , " java_toolchain_alias " ) <nl> + <nl> + java_runtime_alias ( name = " current_java_runtime " ) <nl> + <nl> + java_toolchain_alias ( name = " current_java_toolchain " ) <nl> + <nl> config_setting ( <nl> name = " jdk7 " , <nl> values = { " define " : " java_version = 1 . 7 " } , <nl>
public class printer { <nl> this . append ( o . tostring ( ) ) ; <nl>  <nl> } else { <nl> - / / other types of objects shouldn ' t be leaked to skylark , but if happens , their <nl> - / / . tostring method shouldn ' t be used because their return values are likely to contain <nl> - / / memory addresses or other nondeterministic information . <nl> - this . append ( " < unknown object " + o . getclass ( ) . getname ( ) + " > " ) ; <nl> + <nl> + this . append ( o . tostring ( ) ) ; <nl> } <nl>  <nl> return this ; <nl> mmm a / src / test / java / com / google / devtools / build / lib / skylark / skylarkstringrepresentationstest . java <nl> ppp b / src / test / java / com / google / devtools / build / lib / skylark / skylarkstringrepresentationstest . java <nl>
final class executionserver extends executionimplbase { <nl> this . workeroptions = workeroptions ; <nl> this . cache = cache ; <nl> this . operationscache = operationscache ; <nl> + this . executorservice = <nl> + moreexecutors . listeningdecorator ( <nl> + new threadpoolexecutor ( <nl> + num , workeroptions . jobs , / / always have one thread available , and use at most jobs <nl> + num , timeunit . seconds , / / shut down idle threads after num seconds <nl> + <nl> + new linkedblockingqueue < > ( ) ) ) ; / / no blocking , we can always take more <nl> } <nl>  <nl> @ override <nl> mmm a / src / tools / remote_worker / src / main / java / com / google / devtools / build / remote / remoteworkeroptions . java <nl> ppp b / src / tools / remote_worker / src / main / java / com / google / devtools / build / remote / remoteworkeroptions . java <nl>
function disabled_test_packages_cleared ( ) { <nl> [ [ " $ glob_count " - le num ] ] \ <nl> | | fail " glob count $ glob_count too high " <nl> env_count = " $ ( extract_histogram_count " $ histo_file " \ <nl> - ' environment \ $ extension $ ' ) " <nl> - [ [ " $ env_count " - le num ] ] \ <nl> + ' environment \ $ extension $ ' ) " <nl> + # <nl> + # a regression in . fix . <nl> + [ [ " $ env_count " - le num ] ] \ <nl> | | fail " env extension count $ env_count too high " <nl> }
public class actionexecutedevent implements buildevent { <nl> if ( action . getowner ( ) ! = null & & action . getowner ( ) . getlabel ( ) ! = null ) { <nl> actionbuilder . setlabel ( action . getowner ( ) . getlabel ( ) . tostring ( ) ) ; <nl> } <nl> + <nl> + if ( action . getowner ( ) ! = null ) { <nl> + actionbuilder . setconfiguration ( <nl> + buildeventstreamprotos . buildeventid . configurationid . newbuilder ( ) <nl> + . setid ( action . getowner ( ) . getconfigurationchecksum ( ) ) <nl> + . build ( ) ) ; <nl> + } <nl> if ( exception = = null ) { <nl> actionbuilder . setprimaryoutput ( <nl> buildeventstreamprotos . file . newbuilder ( ) <nl> mmm a / src / main / java / com / google / devtools / build / lib / buildeventstream / proto / build_event_stream . proto <nl> ppp b / src / main / java / com / google / devtools / build / lib / buildeventstream / proto / build_event_stream . proto <nl>
fi <nl> opts = " - - cpu = x64_windows_msys - - host_cpu = x64_windows_msys " <nl> msvc_label = " " <nl> if [ [ $ platform_name = = windows - msvc - x86_64 * ] ] ; then <nl> - opts = " - - cpu = x64_windows_msvc - - copt = / w " <nl> + opts = " " <nl> msvc_label = " - msvc " <nl> fi <nl>  <nl> export msys_no_pathconv = 1 <nl> export msys2_arg_conv_excl = " * " <nl>  <nl> + # <nl> + export no_msvc_wrapper = 1 <nl> + <nl> echo " bootstrap_bazel version : " <nl> $ { bootstrap_bazel } - - bazelrc = $ { bazelrc : - / dev / null } - - nomaster_bazelrc version
class testbase ( unittest . testcase ) : <nl> # and use those here instead of hardcoding paths . <nl> ' java_home ' : ' c : \ \ program files \ \ java \ \ ' + sorted ( result ) [ - 1 ] , <nl> ' bazel_sh ' : ' c : \ \ tools \ \ msys64 \ \ usr \ \ bin \ \ bash . exe ' , <nl> + # <nl> + # https : / / github . com / bazelbuild / bazel / issues / 3273 <nl> + ' cc_configure_debug ' : ' 1 ' , <nl> } <nl> else : <nl> env = { ' home ' : os . path . join ( self . _temp , ' home ' ) } <nl> mmm a / tools / cpp / cc_configure . bzl <nl> ppp b / tools / cpp / cc_configure . bzl <nl>
eof <nl> echo " $ histo_file " <nl> } <nl>  <nl> - function test_packages_cleared ( ) { <nl> + # <nl> + function disabled_test_packages_cleared ( ) { <nl> local histo_file = " $ ( prepare_histogram " - - nodiscard_analysis_cache " ) " <nl> local package_count = " $ ( extract_histogram_count " $ histo_file " \ <nl> ' devtools \ . build \ . lib \ . . * \ . package $ ' ) "
eof <nl> | | fail " remote cache generated different result " <nl> } <nl>  <nl> + function test_failing_cc_test ( ) { <nl> + mkdir - p a <nl> + cat > a / build < < eof <nl> + package ( default_visibility = [ " / / visibility : public " ] ) <nl> + cc_test ( <nl> + name = ' test ' , <nl> + srcs = [ ' test . cc ' ] , <nl> + ) <nl> + eof <nl> + cat > a / test . cc < < eof <nl> + # include < iostream > <nl> + int main ( ) { std : : cout < < " fail me ! " < < std : : endl ; return num ; } <nl> + eof <nl> + bazel - - host_jvm_args = - dbazel . digestfunction = sha1 test \ <nl> + - - spawn_strategy = remote \ <nl> + - - noremote_local_fallback \ <nl> + - - remote_executor = localhost : $ { worker_port } \ <nl> + - - remote_cache = localhost : $ { worker_port } \ <nl> + - - test_output = errors \ <nl> + / / a : test > & $ test_log \ <nl> + & & fail " expected test failure " | | exitcode = $ ? <nl> + # <nl> + } <nl> + <nl> # tests that the remote worker can return a num mb blob that requires chunking . <nl> # blob has to be that large in order to exceed the grpc default max message size . <nl> function test_genrule_large_output_chunking ( ) {
sh_test ( <nl> size = " small " , <nl> srcs = [ " skylark_flag_test . sh " ] , <nl> data = [ " : test - deps " ] , <nl> + # <nl> + tags = [ " manual " ] , <nl> ) <nl>  <nl> sh_test (
public class objccppsemantics implements cppsemantics { <nl> actionbuilder . addtransitivemandatoryinputs ( objcprovider . get ( static_framework_file ) ) ; <nl> actionbuilder . addtransitivemandatoryinputs ( objcprovider . get ( dynamic_framework_file ) ) ; <nl>  <nl> + immutableset . builder < artifact > generatedheaders = immutableset . builder ( ) ; <nl> + <nl> + <nl> + pathfragment genfilessegment = <nl> + rulecontext . getconfiguration ( ) . getgenfilesdirectory ( ) . getexecpath ( ) . getlastsegment ( ) ; <nl> + for ( artifact header : objcprovider . get ( header ) ) { <nl> + if ( genfilessegment . equals ( header . getroot ( ) . getexecpath ( ) . getlastsegment ( ) ) ) { <nl> + generatedheaders . add ( header ) ; <nl> + } <nl> + } <nl> + actionbuilder . addmandatoryinputs ( generatedheaders . build ( ) ) ; <nl> + <nl> if ( isheaderthinningenabled ) { <nl> artifact sourcefile = actionbuilder . getsourcefile ( ) ; <nl> if ( ! sourcefile . istreeartifact ( ) <nl> mmm a / src / main / java / com / google / devtools / build / lib / vfs / pathfragment . java <nl> ppp b / src / main / java / com / google / devtools / build / lib / vfs / pathfragment . java <nl>
public class resourcefilter { <nl> return filterbuilder . build ( ) ; <nl> } <nl>  <nl> + private static folderconfiguration getfolderconfiguration ( string filter ) { <nl> + / * <nl> + * aapt used to expect locale configurations of form ' en_us ' . it now also supports the correct <nl> + * ' en - rus ' format . for backwards comparability , use a regex to convert filters with locales in <nl> + * the old format to filters with locales of the correct format . <nl> + * <nl> + * the correct format for locales is defined at <nl> + * https : / / developer . android . com / guide / topics / resources / providing - resources . html # localequalifier <nl> + * <nl> + * <nl> + * replacement . <nl> + * <nl> + * the regex is a bit complicated to avoid modifying potential new qualifiers that contain <nl> + * underscores . specifically , it searches for the entire beginning of the resource qualifier , <nl> + * including ( optionally ) mcc and mnc , and then the locale itself . <nl> + * / <nl> + string fixedfilter = <nl> + filter . replacefirst ( " ^ ( ( mcc [ 0 - 9 ] { 3 } - ( mnc [ 0 - 9 ] { 3 } - ) ? ) ? [ a - z ] { 2 } ) _ ( [ a - z ] { 2 } ) " , " $ 1 - r $ 4 " ) ; <nl> + return folderconfiguration . getconfigforqualifierstring ( fixedfilter ) ; <nl> + } <nl> + <nl> private immutablelist < density > getdensities ( rulecontext rulecontext ) { <nl> immutablelist . builder < density > densitybuilder = immutablelist . builder ( ) ; <nl> for ( string density : densities ) { <nl> mmm a / src / test / java / com / google / devtools / build / lib / rules / android / androidbinarytest . java <nl> ppp b / src / test / java / com / google / devtools / build / lib / rules / android / androidbinarytest . java <nl>
eof <nl> expect_log " test is supposed to fail " <nl> } <nl>  <nl> - function test_reload_modified_classes ( ) { <nl> + # <nl> + function disabled_test_reload_modified_classes ( ) { <nl> setup_javatest_support <nl> mkdir - p java / testrunners | | fail " mkdir failed "
blaze_exit_code : : exitcode optionprocessor : : parseoptions ( <nl> if ( find_blazerc_exit_code ! = blaze_exit_code : : success ) { <nl> return find_blazerc_exit_code ; <nl> } <nl> - candidate_blazerc_paths . push_back ( user_blazerc_path ) ; <nl>  <nl> vector < string > deduped_blazerc_paths = <nl> internal : : dedupeblazercpaths ( candidate_blazerc_paths ) ; <nl> + <nl> + / / ( e . g . user rc coming from process substitution ) . <nl> + deduped_blazerc_paths . push_back ( user_blazerc_path ) ; <nl>  <nl> for ( const auto & blazerc_path : deduped_blazerc_paths ) { <nl> if ( ! blazerc_path . empty ( ) ) {
public final class analysistestutil { <nl> dummyworkspacestatusaction that = ( dummyworkspacestatusaction ) o ; <nl> return that . key . equals ( this . key ) ; <nl> } <nl> + <nl> + @ override <nl> + public int hashcode ( ) { <nl> + <nl> + return system . identityhashcode ( this ) ; <nl> + } <nl> } <nl>  <nl> @ executionstrategy ( contexttype = workspacestatusaction . context . class )
public class vanillajavabuilder implements closeable { <nl> return new string ( files . readallbytes ( path ) , utf_8 ) ; <nl> } <nl> } <nl> + <nl> + private static void createoutputdirectory ( path dir ) throws ioexception { <nl> + if ( files . exists ( dir ) ) { <nl> + try { <nl> + <nl> + files . walkfiletree ( <nl> + dir , <nl> + new simplefilevisitor < path > ( ) { <nl> + @ override <nl> + public filevisitresult visitfile ( path file , basicfileattributes attrs ) <nl> + throws ioexception { <nl> + files . delete ( file ) ; <nl> + return filevisitresult . continue ; <nl> + } <nl> + <nl> + @ override <nl> + public filevisitresult postvisitdirectory ( path dir , ioexception exc ) <nl> + throws ioexception { <nl> + files . delete ( dir ) ; <nl> + return filevisitresult . continue ; <nl> + } <nl> + } ) ; <nl> + } catch ( ioexception e ) { <nl> + throw new ioexception ( " cannot clean output directory ' " + dir + " ' " , e ) ; <nl> + } <nl> + } <nl> + files . createdirectories ( dir ) ; <nl> + } <nl> } <nl> mmm a / src / java_tools / buildjar / javatests / com / google / devtools / build / buildjar / vanillajavabuildertest . java <nl> ppp b / src / java_tools / buildjar / javatests / com / google / devtools / build / buildjar / vanillajavabuildertest . java <nl>
if [ $ do_srcs_test ] ; then <nl> | grep - v ' ^ derived ' \ <nl> | grep - ev " $ { srcs_excludes } " \ <nl> | grep - v ' ^ tools / defaults / build ' \ <nl> + # <nl> + | grep - v ' third_party / protobuf / 3 . 0 . 0 / ' \ <nl> | sort - u > " $ { output_dir } / srcs - find " <nl>  <nl> log " diffing " <nl> mmm a / src / main / protobuf / build <nl> ppp b / src / main / protobuf / build <nl>
public interface filestatus { <nl> / * * <nl> * returns the last modified time of this file ' s data ( milliseconds since <nl> * unix epoch ) . <nl> + * <nl> + * <nl> + * making use of this . <nl> * / <nl> long getlastmodifiedtime ( ) throws ioexception ; <nl>  <nl> / * * <nl> * returns the last change time of this file , where change means any change <nl> * to the file , including metadata changes ( milliseconds since unix epoch ) . <nl> - * <nl> - * note : unix uses seconds ! <nl> * / <nl> long getlastchangetime ( ) throws ioexception ; <nl>  <nl>
sh_test ( <nl> name = " bazel_coverage_test " , <nl> srcs = [ " bazel_coverage_test . sh " ] , <nl> data = [ " : test - deps " ] , <nl> - tags = [ " local " ] , <nl> + tags = [ <nl> + " jdk8 " , # <nl> + " local " , <nl> + ] , <nl> ) <nl>  <nl> sh_test (
sh_test ( <nl> " / / conditions : default " : [ " / / src / test / shell / bazel / testdata : bazel_toolchain_test_project_pkg " ] , <nl> } ) , <nl> tags = [ <nl> + " noci " , # <nl> " requires - network " , <nl> ] , <nl> )
void becomesubreaper ( ) { <nl> die ( " procctl " ) ; <nl> } <nl> # endif <nl> - # if defined ( __linux__ ) <nl> - if ( prctl ( pr_set_child_subreaper , num ) < num ) { <nl> - die ( " prctl " ) ; <nl> - } <nl> + # if defined ( pr_set_child_subreaper ) <nl> + / / the " child subreaper " feature needs linux num . 4 or higher . <nl> + <nl> + prctl ( pr_set_child_subreaper , num ) ; <nl> # endif <nl> }
public class objcruleclasses { <nl> < code > ios < / code > ( default ) : architectures gathered from < code > - - ios_multi_cpus < / code > . <nl> < / li > <nl> < li > <nl> - < code > watchos < / code > : architectures gathered from < code > - - watchos_multi_cpus < / code > <nl> + < code > macos < / code > : architectures gathered from < code > - - macos_cpus < / code > . <nl> + < / li > <nl> + < li > <nl> + < code > tvos < / code > : architectures gathered from < code > - - tvos_cpus < / code > . <nl> + < / li > <nl> + < li > <nl> + < code > watchos < / code > : architectures gathered from < code > - - watchos_cpus < / code > . <nl> < / li > <nl> < / ul > <nl> < ! - - # end_blaze_rule . attribute - - > * / <nl> + <nl> . add ( attr ( platform_type_attr_name , string ) <nl> . value ( platformtype . ios . tostring ( ) ) <nl> . nonconfigurable ( " determines the configuration transition on deps " ) )
xmlcombiner : : ~ xmlcombiner ( ) { } <nl> bool xmlcombiner : : merge ( const cdh * cdh , const lh * lh ) { <nl> if ( ! concatenator_ . get ( ) ) { <nl> concatenator_ . reset ( new concatenator ( filename_ , false ) ) ; <nl> - concatenator_ - > append ( " < " ) ; <nl> - concatenator_ - > append ( xml_tag_ ) ; <nl> - concatenator_ - > append ( " > \n " ) ; <nl> + concatenator_ - > append ( start_tag_ ) ; <nl> + concatenator_ - > append ( " \n " ) ; <nl> } <nl> - return concatenator_ - > merge ( cdh , lh ) ; <nl> + / / to ensure xml concatentation is idempotent , read in the entry being added <nl> + / / and remove the start and end tags if they are present . <nl> + transientbytes bytes_ ; <nl> + if ( z_no_compression = = lh - > compression_method ( ) ) { <nl> + bytes_ . readentrycontents ( lh ) ; <nl> + } else if ( z_deflated = = lh - > compression_method ( ) ) { <nl> + if ( ! inflater_ . get ( ) ) { <nl> + inflater_ . reset ( new inflater ( ) ) ; <nl> + } <nl> + bytes_ . decompressentrycontents ( cdh , lh , inflater_ . get ( ) ) ; <nl> + } else { <nl> + errx ( 2 , " % s is neither stored nor deflated " , filename_ . c_str ( ) ) ; <nl> + } <nl> + uint32_t checksum ; <nl> + char * buf = reinterpret_cast < char * > ( malloc ( bytes_ . data_size ( ) ) ) ; <nl> + <nl> + bytes_ . copyout ( reinterpret_cast < uint8_t * > ( buf ) , & checksum ) ; <nl> + int start_offset = num ; <nl> + if ( strncmp ( buf , start_tag_ . c_str ( ) , start_tag_ . length ( ) ) = = num ) { <nl> + start_offset = start_tag_ . length ( ) ; <nl> + } <nl> + int end = bytes_ . data_size ( ) ; <nl> + while ( end > = end_tag_ . length ( ) & & std : : isspace ( buf [ end - num ] ) ) end - - ; <nl> + if ( strncmp ( buf + end - end_tag_ . length ( ) , end_tag_ . c_str ( ) , <nl> + end_tag_ . length ( ) ) = = num ) { <nl> + end - = end_tag_ . length ( ) ; <nl> + } else { <nl> + / / leave trailing whitespace alone if we didn ' t find a match . <nl> + end = bytes_ . data_size ( ) ; <nl> + } <nl> + concatenator_ - > append ( buf + start_offset , end - start_offset ) ; <nl> + free ( buf ) ; <nl> + return true ; <nl> } <nl>  <nl> void * xmlcombiner : : outputentry ( bool compress ) { <nl> if ( ! concatenator_ . get ( ) ) { <nl> return nullptr ; <nl> } <nl> - concatenator_ - > append ( " < / " ) ; <nl> - concatenator_ - > append ( xml_tag_ ) ; <nl> - concatenator_ - > append ( " > \n " ) ; <nl> + concatenator_ - > append ( end_tag_ ) ; <nl> + concatenator_ - > append ( " \n " ) ; <nl> return concatenator_ - > outputentry ( compress ) ; <nl> } <nl>  <nl> mmm a / src / tools / singlejar / combiners . h <nl> ppp b / src / tools / singlejar / combiners . h <nl>
eof <nl> mkfifo $ testfifo $ sleepyfifo | | fail " couldn ' t create fifos under x " <nl>  <nl> set - m <nl> - bazel $ startup_opt build - - package_path . / / x : sleepy > & $ test_log & <nl> + # <nl> + bazel $ startup_opt build - - noexperimental_ui \ <nl> + - - package_path . / / x : sleepy > & $ test_log & <nl> local pid = $ ! <nl>  <nl> echo " $ { product_name } running in background with pid $ pid " <nl> mmm a / src / test / shell / integration / loading_phase_tests . sh <nl> ppp b / src / test / shell / integration / loading_phase_tests . sh <nl>
eof <nl>  <nl> chmod + x foo / bar / test . sh <nl>  <nl> - bazel test - - output_filter = " dummy " foo / bar : test num > stderr . txt <nl> + # <nl> + bazel test - - noexperimental_ui - - output_filter = " dummy " foo / bar : test num > stderr . txt <nl> grep " pass : / / foo / bar : test " stderr . txt | | fail " no passed message " <nl> } <nl>  <nl> mmm a / src / test / shell / integration / progress_reporting_test . sh <nl> ppp b / src / test / shell / integration / progress_reporting_test . sh <nl>
source " $ { current_dir } / . . / integration_test_setup . sh " \ <nl>  <nl> set - eu <nl>  <nl> + # <nl> + add_to_bazelrc " build - - noexperimental_ui " <nl> add_to_bazelrc " build - - workspace_status_command = " $ ( which true ) " - - nostamp " <nl> add_to_bazelrc " build - - show_progress_rate_limit = - 1 " <nl> add_to_bazelrc " build - - genrule_strategy = local "
public final class targetcompleteevent <nl> builder . addalltag ( gettags ( ) ) ; <nl> builder . addalloutputgroup ( getoutputfilesbygroup ( converters . artifactgroupnamer ( ) ) ) ; <nl>  <nl> + <nl> + for ( artifactsinoutputgroup group : outputs ) { <nl> + if ( group . areimportant ( ) ) { <nl> + for ( artifact artifact : group . getartifacts ( ) ) { <nl> + string name = artifact . getfilename ( ) ; <nl> + string uri = converters . pathconverter ( ) . apply ( artifact . getpath ( ) ) ; <nl> + builder . addimportantoutput ( file . newbuilder ( ) . setname ( name ) . seturi ( uri ) . build ( ) ) ; <nl> + } <nl> + } <nl> + } <nl> + <nl> buildeventstreamprotos . targetcomplete complete = builder . build ( ) ; <nl> return genericbuildevent . protochaining ( this ) . setcompleted ( complete ) . build ( ) ; <nl> } <nl> mmm a / src / main / java / com / google / devtools / build / lib / buildeventstream / proto / build_event_stream . proto <nl> ppp b / src / main / java / com / google / devtools / build / lib / buildeventstream / proto / build_event_stream . proto <nl>
function test_loading_failure_keep_going ( ) { <nl> expect_not_log ' aborted ' <nl> } <nl>  <nl> - function test_artifact_dedup ( ) { <nl> - bazel build - - experimental_build_event_text_file = $ test_log \ <nl> - pkg : innergroup pkg : outergroup \ <nl> - | | fail " bazel build failed " <nl> - expect_log_once " name . * sourcefilea " <nl> - expect_log_once " name . * sourcefileb " <nl> - expect_log_once " name . * sourcefilec " <nl> - expect_not_log ' aborted ' <nl> - } <nl> + # <nl> + # for every target completion <nl> + # <nl> + # function test_artifact_dedup ( ) { <nl> + # bazel build - - experimental_build_event_text_file = $ test_log \ <nl> + # pkg : innergroup pkg : outergroup \ <nl> + # | | fail " bazel build failed " <nl> + # expect_log_once " name . * sourcefilea " <nl> + # expect_log_once " name . * sourcefileb " <nl> + # expect_log_once " name . * sourcefilec " <nl> + # expect_not_log ' aborted ' <nl> + # } <nl>  <nl> run_suite " integration tests for the build event stream "
sh_test ( <nl> " / / external : android_ndk_for_testing " , <nl> " / / external : android_sdk_for_testing " , <nl> ] , <nl> + # <nl> + tags = [ " manual " ] , <nl> ) <nl>  <nl> sh_test ( <nl>
sh_test ( <nl> " / / src / test / shell / bazel : test - deps " , <nl> ] , <nl> # this test builds an android_binary with java num code . <nl> - tags = [ " jdk8 " ] , <nl> + # <nl> + tags = [ <nl> + " jdk8 " , <nl> + " manual " , <nl> + ] , <nl> )
public class multiarchsplittransitionprovider implements splittransitionprovider <nl> switch ( platformtype ) { <nl> case ios : <nl> cpus = buildoptions . get ( applecommandlineoptions . class ) . iosmulticpus ; <nl> - if ( cpus . isempty ( ) ) { <nl> + <nl> + if ( cpus . isempty ( ) & & minimumosversion . ispresent ( ) ) { <nl> cpus = immutablelist . of ( buildoptions . get ( applecommandlineoptions . class ) . ioscpu ) ; <nl> } <nl> configurationdistinguisher = configurationdistinguisher . applebin_ios ;
public class resourcejaractionbuilder { <nl> if ( ! classpathresources . isempty ( ) ) { <nl> command . addexecpaths ( " - - classpath_resources " , classpathresources ) ; <nl> } <nl> + <nl> + / / paramfilehelper # getparamsfilemaybe is expensive , so avoid doing that work if <nl> + / / we definitely don ' t need a params file . <nl> + / / this heuristic could be much more aggressive , but we don ' t ever want to skip <nl> + / / the params file in situations where it is required for - - min_param_file_size . <nl> + if ( sizegreaterthanorequal ( <nl> + iterables . concat ( messages , resources . values ( ) , resourcejars , classpathresources ) , num ) <nl> + | | rulecontext . getconfiguration ( ) . getminparamfilesize ( ) < num ) { <nl> + builder . useparameterfile ( parameterfiletype . shell_quoted ) ; <nl> + } <nl> rulecontext . registeraction ( <nl> builder <nl> . addoutput ( outputjar ) <nl>
public class javabinary implements ruleconfiguredtargetfactory { <nl> semantics . translate ( rulecontext , javaconfig , attributes . getmessages ( ) ) ) ; <nl> } <nl>  <nl> - if ( attributes . hassources ( ) | | attributes . hasresources ( ) ) { <nl> + <nl> + boolean hasresources = <nl> + ! attributes . getresources ( ) . isempty ( ) | | ! attributes . getclasspathresources ( ) . isempty ( ) ; <nl> + if ( attributes . hassources ( ) | | hasresources ) { <nl> / / we only want to add a jar to the classpath of a dependent rule if it has content . <nl> javaartifactsbuilder . addruntimejar ( classjar ) ; <nl> }
public class pathfragmentwindowstest { <nl> . isnotequalto ( pathfragment . create ( " c : " ) . getpathstring ( ) ) ; <nl> } <nl>  <nl> + @ test <nl> + public void testconfusingsemanticsofdrivelettersinrelativepaths ( ) { <nl> + / / this test serves to document the current confusing semantics of non - empty relative windows <nl> + / / paths that have drive letters . also note the above testemptyrelativepathtoemptypathwindows <nl> + / / which documents the confusing semantics of empty relative windows paths that have drive <nl> + / / letters . <nl> + / / <nl> + <nl> + pathfragment ccolonfoo = pathfragment . create ( " c : foo " ) ; <nl> + pathfragment dcolonfoo = pathfragment . create ( " d : foo " ) ; <nl> + pathfragment foo = pathfragment . create ( " foo " ) ; <nl> + assertthat ( ccolonfoo ) . isnotequalto ( dcolonfoo ) ; <nl> + assertthat ( ccolonfoo ) . isnotequalto ( foo ) ; <nl> + assertthat ( dcolonfoo ) . isnotequalto ( foo ) ; <nl> + assertthat ( ccolonfoo . segmentcount ( ) ) . isequalto ( dcolonfoo . segmentcount ( ) ) ; <nl> + assertthat ( ccolonfoo . segmentcount ( ) ) . isequalto ( foo . segmentcount ( ) ) ; <nl> + assertthat ( ccolonfoo . startswith ( dcolonfoo ) ) . istrue ( ) ; <nl> + assertthat ( ccolonfoo . startswith ( foo ) ) . istrue ( ) ; <nl> + assertthat ( foo . startswith ( ccolonfoo ) ) . istrue ( ) ; <nl> + assertthat ( ccolonfoo . getpathstring ( ) ) . isequalto ( " foo " ) ; <nl> + assertthat ( ccolonfoo . getpathstring ( ) ) . isequalto ( dcolonfoo . getpathstring ( ) ) ; <nl> + assertthat ( ccolonfoo . getpathstring ( ) ) . isequalto ( foo . getpathstring ( ) ) ; <nl> + } <nl> + <nl> @ test <nl> public void testwindowsvolumeuppercase ( ) { <nl> assertregular ( " c : / " , " c : / " ) ;
public class androidconfiguration extends buildconfiguration . fragment { <nl> help = " does most of the work for dexing separately for each jar file . " ) <nl> public boolean incrementaldexing ; <nl>  <nl> + <nl> @ option ( name = " host_incremental_dexing " , <nl> defaultvalue = " false " , <nl> category = " hidden " , <nl>
public class androidconfiguration extends buildconfiguration . fragment { <nl> / / do not use on the command line . <nl> / / the idea is that this option lets us gradually turn on incremental dexing for different <nl> / / binaries . users should rely on - - noincremental_dexing to turn it off . <nl> + <nl> @ option ( name = " incremental_dexing_binary_types " , <nl> - defaultvalue = " multidex_sharded " , <nl> + defaultvalue = " all " , <nl> category = " undocumented " , <nl> converter = androidbinarytypesconverter . class , <nl> implicitrequirements = " - - incremental_dexing " , <nl>
public class androidconfiguration extends buildconfiguration . fragment { <nl> public set < androidbinarytype > incrementaldexingbinaries ; <nl>  <nl> / * * <nl> - * whether to look for incrementally dex protos built with java_lite_proto_library . once this <nl> - * option works , we ' ll flip the default value in a config file , then once it is proven that it <nl> - * works , remove it from bazel and said config file . <nl> + * whether to look for incrementally dex protos built with java_lite_proto_library . <nl> * / <nl> + <nl> @ option ( <nl> name = " experimental_incremental_dexing_for_lite_protos " , <nl> - defaultvalue = " false " , <nl> + defaultvalue = " true " , <nl> category = " experimental " , <nl> help = " do not use . " ) <nl> public boolean incrementaldexingforliteprotos ; <nl>
public class protocompileactionbuildertest { <nl> . containsexactly ( " - ifoo / bar . proto = external / bla / foo / bar . proto " ) ; <nl> } <nl>  <nl> + <nl> + @ ignore <nl> + @ test <nl> public void directdependenciesonexternalfiles ( ) throws exception { <nl> immutablelist < artifact > protos = <nl> immutablelist . of ( artifact ( " @ bla / / foo : bar " , " external / bla / foo / bar . proto " ) ) ;
public final class skylarkrulecontext implements skylarkvalue { <nl> return rulecontext . getderivedartifact ( fragment , root ) ; <nl> } <nl>  <nl> + <nl> + @ skylarkcallable ( <nl> + name = " experimental_new_directory " , <nl> + documented = false , <nl> + parameters = { <nl> + @ param ( name = " name " , type = string . class ) , <nl> + @ param ( <nl> + name = " sibling " , <nl> + type = artifact . class , <nl> + defaultvalue = " none " , <nl> + noneable = true , <nl> + named = true <nl> + ) <nl> + } <nl> + ) <nl> + public artifact newdirectory ( string name , object siblingartifactunchecked ) throws evalexception { <nl> + checkmutable ( " experimental_new_directory " ) ; <nl> + if ( siblingartifactunchecked = = runtime . none ) { <nl> + return rulecontext . getpackagerelativetreeartifact ( new pathfragment ( name ) , newfileroot ( ) ) ; <nl> + } <nl> + artifact siblingartifact = ( artifact ) siblingartifactunchecked ; <nl> + pathfragment original = siblingartifact . getrootrelativepath ( ) ; <nl> + pathfragment fragment = original . replacename ( name ) ; <nl> + return rulecontext . gettreeartifact ( fragment , newfileroot ( ) ) ; <nl> + } <nl> + <nl> @ skylarkcallable ( documented = false ) <nl> public nestedset < artifact > middleman ( string attribute ) throws evalexception { <nl> checkmutable ( " middle_man " ) ; <nl> mmm a / src / test / java / com / google / devtools / build / lib / skylark / skylarkrulecontexttest . java <nl> ppp b / src / test / java / com / google / devtools / build / lib / skylark / skylarkrulecontexttest . java <nl>
eof <nl> expect_log " executing genrule / / : test failed : " <nl> } <nl>  <nl> - function test_sandbox_mount_customized_path ( ) { <nl> + # <nl> + function disabled_test_sandbox_mount_customized_path ( ) { <nl> # create build file <nl> cat > build < < ' eof ' <nl> package ( default_visibility = [ " / / visibility : public " ] )
pkg_tar ( <nl> for flavour in flavours <nl> ] <nl>  <nl> + # <nl> [ <nl> [ py_test ( <nl> name = " test_cc_configure - % s - % s " % ( flavour , mode ) , <nl>
public class crosstoolcompilationsupport extends compilationsupport { <nl> private static final string llvm_coverage_map_format = " llvm_coverage_map_format " ; <nl> / * * produce artifacts for coverage in gcc coverage mapping format . * / <nl> private static final string gcc_coverage_map_format = " gcc_coverage_map_format " ; <nl> + / * * <nl> + * enabled if this target ' s rule is not a test rule . binary stripping should not be applied in <nl> + * the link step . <nl> + * <nl> + * < p > note that the crosstool does not support feature negation in flagset . with_feature , which <nl> + * is the mechanism used to condition linker arguments here . therefore , we expose <nl> + * " is_not_test_target " instead of the more intuitive " is_test_target " . <nl> + * / <nl> + private static final string is_not_test_target_feature_name = " is_not_test_target " ; <nl>  <nl> private static final iterable < string > activated_actions = <nl> immutablelist . of ( <nl>
public class legacycompilationsupport extends compilationsupport { <nl> / / do not perform code stripping on tests because xctest binary is linked not as an executable <nl> / / but as a bundle without any entry point . <nl> boolean istesttarget = targetutils . istestrule ( rulecontext . getrule ( ) ) ; <nl> + <nl> if ( objcconfiguration . shouldstripbinary ( ) & & ! istesttarget ) { <nl> commandline . add ( " - dead_strip " ) . add ( " - no_dead_strip_inits_and_terms " ) ; <nl> }
function test_build_hello_world ( ) { <nl> } <nl>  <nl> function test_java_common_compile_sourcepath ( ) { <nl> + # <nl> + java_version = " 1 . $ ( bazel query - - output = build ' @ bazel_tools / / tools / jdk : toolchain ' | grep source_version | cut - d ' " ' - f num ) " <nl> + if [ " $ { java_version } " = " 1 . 7 " ] ; then <nl> + return num <nl> + fi <nl> mkdir - p g <nl> cat > g / a . java < < ' eof ' <nl> package g ;
public abstract class teststrategy implements testactioncontext { <nl> * - - test_tmpdir . this does not create the directory . <nl> * / <nl> public static path gettmproot ( path workspace , path execroot , executionoptions executionoptions ) { <nl> - return executionoptions . testtmpdir ! = null <nl> - ? workspace . getrelative ( executionoptions . testtmpdir ) . getrelative ( test_tmp_root ) <nl> - : execroot . getrelative ( test_tmp_root ) ; <nl> + if ( executionoptions . testtmpdir ! = null ) { <nl> + return workspace . getrelative ( executionoptions . testtmpdir ) . getrelative ( test_tmp_root ) ; <nl> + } <nl> + switch ( os . getcurrent ( ) ) { <nl> + case windows : <nl> + <nl> + / / limit of the windows api when running bazel inside shell integration tests . <nl> + return workspace . getfilesystem ( ) . getpath ( " c : / temp " ) ; <nl> + default : <nl> + return execroot . getrelative ( test_tmp_root ) ; <nl> + } <nl> } <nl>  <nl> / * * <nl> mmm a / src / test / shell / bazel / bazel_windows_example_test . sh <nl> ppp b / src / test / shell / bazel / bazel_windows_example_test . sh <nl>
function is_windows ( ) { <nl> fi <nl> } <nl>  <nl> - # set some enviornment variables needed on windows . <nl> + # set some environment variables needed on windows . <nl> if is_windows ; then <nl> - # changing test_tmpdir to avoid long path issue on windows <nl> - test_tmpdir = " / c / tmp " <nl> + # <nl> + # moving the windows - specific test_tmpdir into teststrategy . <nl> + test_tmpdir_basename = " $ ( basename " $ test_tmpdir " ) " <nl> + export test_tmpdir = " c : / temp / $ { test_tmpdir_basename } " <nl> + <nl> + # bazel ( tmpdir ) and windows ( temp , tmp ) have three envvars that specify the <nl> + # location of the temp directory . . . <nl> + export tmpdir = " $ test_tmpdir " <nl> + export temp = " $ test_tmpdir " <nl> + export tmp = " $ test_tmpdir " <nl> + <nl> export java_home = " $ ( ls - d c : / program \ files / java / jdk * | sort | tail - n num ) " <nl> export bazel_sh = " c : / tools / msys64 / usr / bin / bash . exe " <nl> export bazel_vc = " c : / program files ( x86 ) / microsoft visual studio num . 0 / vc " <nl> - export tmpdir = " c : / tmp " <nl> + if [ - x / c / python27 / python . exe ] ; then <nl> + export bazel_python = " c : / python27 / python . exe " <nl> + export path = " / c / python27 : $ path " <nl> + elif [ - x / c / python_27_amd64 / files / python . exe ] ; then <nl> + export bazel_python = " c : / python_27_amd64 / files / python . exe " <nl> + export path = " / c / python_27_amd64 / files : $ path " <nl> + fi <nl> fi <nl>  <nl> # make the command " bazel " available for tests .
bool isemacsterminal ( ) { <nl> / / environment variables ) . <nl> bool isstandardterminal ( ) { <nl> # ifdef compiler_msvc <nl> - for ( dword i : { std_output_handle , std_error_handle } ) { <nl> - dword mode = num ; <nl> - handle handle = : : getstdhandle ( i ) ; <nl> - / / handle may be invalid when std { out , err } is redirected <nl> - if ( handle = = invalid_handle_value | | ! : : getconsolemode ( handle , & mode ) | | <nl> - ! ( mode & enable_processed_output ) | | <nl> - ! ( mode & enable_wrap_at_eol_output ) | | <nl> - ! ( mode & enable_virtual_terminal_processing ) ) { <nl> - return false ; <nl> - } <nl> - } <nl> - return true ; <nl> + <nl> + return false ; <nl> # else / / not compiler_msvc <nl> string term = getenv ( " term " ) ; <nl> if ( term . empty ( ) | | term = = " dumb " | | term = = " emacs " | |
public class blazerulehelpprinter { <nl> return e . getmessage ( ) ; <nl> } <nl> } <nl> - / / every rule should be documented and this method should be called only <nl> - / / for existing rules ( a check is performed in helpcommand ) . <nl> - preconditions . checkstate ( ruledocmap . containskey ( rulename ) , string . format ( <nl> - " error : documentation of rule % s does not exist . " , rulename ) ) ; <nl> + <nl> + / / the bazel binary may not contain the rule sources , which means that the documentation <nl> + / / retrieval step would fail with an exception . <nl> + if ( ! ruledocmap . containskey ( rulename ) ) { <nl> + return string . format ( " documentation for rule % s is not part of the binary . \n " , rulename ) ; <nl> + } <nl> return " rule " + rulename + " : " <nl> + ruledocmap . get ( rulename ) . getcommandlinedocumentation ( ) + " \n " ; <nl> }
def create_android_device_rules ( system_image_dirs ) : <nl> for system_image_dir in system_image_dirs : <nl> name = " _ " . join ( system_image_dir . split ( " / " ) [ 1 : ] ) <nl>  <nl> + # <nl> + # updated to use the emulator_images_ % s filegroups instead . <nl> native . filegroup ( <nl> name = " % s_files " % name , <nl> srcs = native . glob ( [ " % s / * * " % system_image_dir ] ) , <nl> ) <nl> + <nl> + native . filegroup ( <nl> + name = " emulator_images_ % s " % name , <nl> + srcs = native . glob ( [ " % s / * * " % system_image_dir ] ) , <nl> + )
function test_java ( ) { <nl> assert_binary_run_from_subdir " bazel - bin / $ { java_pkg } / hello - world foo " " hello foo " <nl> } <nl>  <nl> - function test_java_test ( ) { <nl> - setup_javatest_support <nl> - local java_native_tests = / / examples / java - native / src / test / java / com / example / myproject <nl> - local java_native_main = / / examples / java - native / src / main / java / com / example / myproject <nl> - <nl> - assert_build " - - / / examples / java - native / . . . - $ { java_native_main } : hello - error - prone " <nl> - assert_build_fails " $ { java_native_main } : hello - error - prone " \ <nl> - " did you mean ' result = b = = - 1 ; ' ? " <nl> - assert_test_ok " $ { java_native_tests } : hello " <nl> - assert_test_ok " $ { java_native_tests } : custom " <nl> - assert_test_fails " $ { java_native_tests } : fail " <nl> - assert_test_fails " $ { java_native_tests } : resource - fail " <nl> - } <nl> + # <nl> + # function test_java_test ( ) { <nl> + # setup_javatest_support <nl> + # local java_native_tests = / / examples / java - native / src / test / java / com / example / myproject <nl> + # local java_native_main = / / examples / java - native / src / main / java / com / example / myproject <nl> + <nl> + # assert_build " - - / / examples / java - native / . . . - $ { java_native_main } : hello - error - prone " <nl> + # assert_build_fails " $ { java_native_main } : hello - error - prone " \ <nl> + # " did you mean ' result = b = = - 1 ; ' ? " <nl> + # assert_test_ok " $ { java_native_tests } : hello " <nl> + # assert_test_ok " $ { java_native_tests } : custom " <nl> + # assert_test_fails " $ { java_native_tests } : fail " <nl> + # assert_test_fails " $ { java_native_tests } : resource - fail " <nl> + # } <nl>  <nl> function test_native_python ( ) { <nl> # on windows , we build a python executable zip as the python binary
alias ( <nl> actual = " @ local_jdk / / : extdir " , <nl> ) <nl>  <nl> + # <nl> + alias ( <nl> + name = " extdir " , <nl> + actual = " @ local_jdk / / : extdir " , <nl> + ) <nl> + <nl> filegroup ( <nl> name = " langtools " , <nl> srcs = [ " / / third_party / java / jdk / langtools : javac_jar " ] ,
public class resourceusageanalyzer { <nl> } else if ( ! parent . isempty ( ) ) { <nl> string parentstyle = parent ; <nl> if ( ! parentstyle . startswith ( style_resource_prefix ) ) { <nl> - parentstyle = style_resource_prefix + parentstyle ; <nl> + / / fix ( see method comment ) : allow parent references to start with ' style / ' <nl> + / / as well as the more strict ' @ style / ' . <nl> + <nl> + if ( parentstyle . startswith ( reference_style ) ) { <nl> + parentstyle = " @ " + parentstyle ; <nl> + } else { <nl> + parentstyle = style_resource_prefix + parentstyle ; <nl> + } <nl> } <nl> resource ps = getresourcefromurl ( lintutils . getfieldname ( parentstyle ) ) ; <nl> if ( ps ! = null & & definition ! = null ) {
bind ( <nl> name = " bootclasspath " , <nl> actual = " @ local_jdk / / : bootclasspath " , <nl> ) <nl> + # <nl> bind ( <nl> name = " extdir " , <nl> actual = " @ local_jdk / / : extdir " , <nl> ) <nl> + bind ( <nl> + name = " extclasspath " , <nl> + actual = " @ local_jdk / / : extdir " , <nl> + ) <nl> bind ( <nl> name = " jni_header " , <nl> actual = " @ local_jdk / / : jni_header " , <nl> mmm a / src / main / tools / jdk . build <nl> ppp b / src / main / tools / jdk . build <nl>
filegroup ( <nl> srcs = [ " jre / lib / % s " % jar for jar in bootclass_jars ] , <nl> ) <nl>  <nl> + # <nl> filegroup ( <nl> name = " extdir " , <nl> srcs = glob ( [ " jre / lib / ext / * . jar " ] ) , <nl> ) <nl>  <nl> + filegroup ( <nl> + name = " extclasspath " , <nl> + srcs = glob ( [ " jre / lib / ext / * . jar " ] ) , <nl> + ) <nl> + <nl> filegroup ( <nl> name = " jre - bin " , <nl> srcs = select ( { <nl> mmm a / src / test / shell / bazel / build <nl> ppp b / src / test / shell / bazel / build <nl>
filegroup ( <nl> " / / third_party / java / jdk / langtools : test - srcs " , <nl> " / / tools : srcs " , <nl> " @ local_jdk / / : bootclasspath " , <nl> + # <nl> " @ local_jdk / / : extdir " , <nl> " @ local_jdk / / : jdk " , <nl> ] , <nl> mmm a / tools / jdk / build <nl> ppp b / tools / jdk / build <nl>
public class outputdirectorylinksutils { <nl>  <nl> private static final string no_create_symlinks_prefix = " / " ; <nl>  <nl> - public static string getoutputsymlinkname ( string productname ) { <nl> - return productname + " - out " ; <nl> + public static immutablelist < string > getoutputsymlinknames ( string productname , <nl> + string symlinkprefix ) { <nl> + immutablelist . builder < string > builder = immutablelist . < string > builder ( ) ; <nl> + <nl> + builder . add ( productname + " - out " ) ; <nl> + if ( ! productname . equals ( symlinkprefix ) ) { <nl> + builder . add ( symlinkprefix + " out " ) ; <nl> + } <nl> + return builder . build ( ) ; <nl> } <nl>  <nl> - private static string execrootsymlink ( string productname , string workspacename ) { <nl> - return productname + " - " + workspacename ; <nl> + private static string execrootsymlink ( string symlinkprefix , string workspacename ) { <nl> + return symlinkprefix + workspacename ; <nl> } <nl> / * * <nl> * attempts to create convenience symlinks in the workspacedirectory and in <nl>
public final class buildtool { <nl> } catch ( error e ) { <nl> catastrophe = true ; <nl> throw e ; <nl> + } catch ( invalidconfigurationexception e ) { <nl> + <nl> + / / created as part of the analysis phase they should report their error on the level of the <nl> + / / target ( s ) that triggered them . <nl> + catastrophe = true ; <nl> + throw e ; <nl> } finally { <nl> if ( ! catastrophe ) { <nl> / / delete dirty nodes to ensure that they do not accumulate indefinitely . <nl>
public final class buildtool { <nl> } catch ( invalidconfigurationexception e ) { <nl> exitcode = exitcode . command_line_error ; <nl> reportexceptionerror ( e ) ; <nl> + <nl> + / / created as part of the analysis phase they should report their error on the level of the <nl> + / / target ( s ) that triggered them . <nl> + result . setcatastrophe ( ) ; <nl> } catch ( abruptexitexception e ) { <nl> exitcode = e . getexitcode ( ) ; <nl> reportexceptionerror ( e ) ;
<nl> + / / copyright num the bazel authors . all rights reserved . <nl> + / / <nl> + / / licensed under the apache license , version num . 0 ( the " license " ) ; <nl> + / / you may not use this file except in compliance with the license . <nl> + / / you may obtain a copy of the license at <nl> + / / <nl> + / / http : / / www . apache . org / licenses / license - 2 . 0 <nl> + / / <nl> + / / unless required by applicable law or agreed to in writing , software <nl> + / / distributed under the license is distributed on an " as is " basis , <nl> + / / without warranties or conditions of any kind , either express or implied . <nl> + / / see the license for the specific language governing permissions and <nl> + / / limitations under the license . <nl> + <nl> + # include < iostream > <nl> + <nl> + int main ( int argc , char * * argv ) { <nl> + <nl> + std : : cout < < " error : build - runfiles is not ( yet ? ) implemented on windows . " <nl> + < < std : : endl <nl> + < < " called with args : " < < std : : endl ; <nl> + for ( int i = num ; i < argc ; + + i ) { <nl> + std : : cout < < " argv [ " < < i < < " ] = ( " < < argv [ i ] < < " ) " < < std : : endl ; <nl> + } <nl> + return num ; <nl> + } <nl> mmm / dev / null <nl> ppp b / src / main / tools / process - wrapper - windows . cc <nl>
<nl> + / / copyright num the bazel authors . all rights reserved . <nl> + / / <nl> + / / licensed under the apache license , version num . 0 ( the " license " ) ; <nl> + / / you may not use this file except in compliance with the license . <nl> + / / you may obtain a copy of the license at <nl> + / / <nl> + / / http : / / www . apache . org / licenses / license - 2 . 0 <nl> + / / <nl> + / / unless required by applicable law or agreed to in writing , software <nl> + / / distributed under the license is distributed on an " as is " basis , <nl> + / / without warranties or conditions of any kind , either express or implied . <nl> + / / see the license for the specific language governing permissions and <nl> + / / limitations under the license . <nl> + <nl> + # include < iostream > <nl> + <nl> + int main ( int argc , char * * argv ) { <nl> + <nl> + std : : cout < < " error : process - wrapper is not yet implemented on windows . " <nl> + < < std : : endl <nl> + < < " called with args : " < < std : : endl ; <nl> + for ( int i = num ; i < argc ; + + i ) { <nl> + std : : cout < < " argv [ " < < i < < " ] = ( " < < argv [ i ] < < " ) " < < std : : endl ; <nl> + } <nl> + return num ; <nl> + }
bool pathexists ( const string & path ) { <nl> return junctionresolver ( ) . resolve ( wpath . c_str ( ) , nullptr ) ; <nl> } <nl>  <nl> + # ifdef compiler_msvc <nl> + string makecanonical ( const char * path ) { <nl> + <nl> + pdie ( 255 , " blaze_util : : makecanonical is not implemented on windows " ) ; <nl> + return " " ; <nl> + } <nl> + # endif / / compiler_msvc <nl> + <nl> static bool canreadfilew ( const wstring & path ) { <nl> dword attrs = : : getfileattributesw ( path . c_str ( ) ) ; <nl> if ( ( attrs = = invalid_file_attributes ) | | <nl>
public class javaruntime implements ruleconfiguredtargetfactory { <nl> nestedset < artifact > middleman = <nl> compilationhelper . getaggregatingmiddleman ( <nl> rulecontext , actions . escapelabel ( rulecontext . getlabel ( ) ) , filestobuild ) ; <nl> + <nl> + runfiles runfiles = <nl> + new runfiles . builder ( rulecontext . getworkspacename ( ) ) <nl> + . addtransitiveartifacts ( filestobuild ) <nl> + . build ( ) ; <nl> return new ruleconfiguredtargetbuilder ( rulecontext ) <nl> - . addprovider ( runfilesprovider . class , runfilesprovider . empty ) <nl> + . addprovider ( runfilesprovider . class , runfilesprovider . simple ( runfiles ) ) <nl> . setfilestobuild ( filestobuild ) <nl> . addprovider ( javaruntimeprovider . class , javaruntimeprovider . create ( filestobuild ) ) <nl> . addprovider ( middlemanprovider . class , new middlemanprovider ( middleman ) )
bool changedirectory ( const string & path ) { <nl> return true ; <nl> } <nl>  <nl> + # ifdef compiler_msvc <nl> void foreachdirectoryentry ( const string & path , <nl> directoryentryconsumer * consume ) { <nl> - wstring wpath ; <nl> - if ( path . empty ( ) | | isdevnull ( path ) ) { <nl> - return ; <nl> - } <nl> - if ( ! aswindowspath ( path , & wpath ) ) { <nl> - pdie ( blaze_exit_code : : local_environmental_error , <nl> - " foreachdirectoryentry ( % s ) : aswindowspath failed " , path . c_str ( ) ) ; <nl> - } <nl> - <nl> - static const wstring kdot ( l " . " ) ; <nl> - static const wstring kdotdot ( l " . . " ) ; <nl> - <nl> - wpath = l " \ \ \ \ ? \ \ " + wpath + l " \ \ " ; <nl> - win32_find_dataw metadata ; <nl> - windows_util : : autohandle handle ( <nl> - findfirstfilew ( ( wpath + l " * " ) . c_str ( ) , & metadata ) ) ; <nl> - if ( handle . handle = = invalid_handle_value ) { <nl> - return ; / / directory does not exist or is empty <nl> - } <nl> - <nl> - do { <nl> - if ( kdot ! = metadata . cfilename & & kdotdot ! = metadata . cfilename ) { <nl> - wstring wname = wpath + metadata . cfilename ; <nl> - string name ( wstringtocstring ( / * omit prefix * / num + wname . c_str ( ) ) . get ( ) ) ; <nl> - bool is_dir = ( metadata . dwfileattributes & file_attribute_directory ) ! = num ; <nl> - consume - > consume ( name , is_dir ) ; <nl> - } <nl> - } while ( findnextfilew ( handle . handle , & metadata ) ) ; <nl> + <nl> + pdie ( 255 , " blaze_util : : foreachdirectoryentry is not implemented on windows " ) ; <nl> } <nl> + # else / / not compiler_msvc <nl> + # endif / / compiler_msvc <nl>  <nl> string normalizewindowspath ( string path ) { <nl> if ( path . empty ( ) ) { <nl> mmm a / src / test / cpp / util / file_test . cc <nl> ppp b / src / test / cpp / util / file_test . cc <nl>
public class reducedclasspathjavalibrarybuilder extends simplejavalibrarybuilder <nl> return false ; <nl> } <nl> for ( formatteddiagnostic diagnostic : result . diagnostics ( ) ) { <nl> - if ( hasrecognizederror ( diagnostic . getformatted ( ) ) ) { <nl> + system . err . println ( diagnostic . getcode ( ) ) ; <nl> + string code = diagnostic . getcode ( ) ; <nl> + if ( code . contains ( " doesnt . exist " ) <nl> + | | code . contains ( " cant . resolve " ) <nl> + | | code . contains ( " cant . access " ) ) { <nl> + return true ; <nl> + } <nl> + / / handle - xdoclint : reference errors , which don ' t have a diagnostic code <nl> + <nl> + if ( diagnostic . getformatted ( ) . contains ( " error : reference not found " ) ) { <nl> return true ; <nl> } <nl> } <nl>
public class skylarkjavaliteprotolibrarytest extends buildviewtestcase { <nl> } <nl> } <nl>  <nl> + / * * <nl> + * tests that a java_proto_library only provides direct jars corresponding on the proto_library <nl> + * rules it directly depends on , excluding anything that the proto_library rules depends on <nl> + * themselves . this does not concern strict - deps in the compilation of the generated java code <nl> + * itself , only compilation of regular code in java_library / java_binary and similar rules . <nl> + * <nl> + * < p > here , a java_lite_proto_library dependes on an alias proto . we make sure that the system <nl> + * behaves as if we depend directly on the aliased proto_library . <nl> + * / <nl> + @ test <nl> + @ ignore <nl> + <nl> + public void jplcorrectlydefinesdirectjars_strictdepsenabled_aliasproto ( ) throws exception { <nl> + scratch . file ( <nl> + " x / build " , <nl> + " load ( ' / / tools / build_rules / java_lite_proto_library : java_lite_proto_library . bzl ' , " , <nl> + " ' java_lite_proto_library ' ) " , <nl> + " java_lite_proto_library ( name = ' foo_java_proto_lite ' , deps = [ ' : foo_proto ' ] , " , <nl> + " strict_deps = num ) " , <nl> + " proto_library ( " , <nl> + " name = ' foo_proto ' , " , <nl> + " deps = [ ' : bar_proto ' ] , " , <nl> + " ) " , <nl> + " proto_library ( " , <nl> + " name = ' bar_proto ' , " , <nl> + " srcs = [ ' bar . proto ' ] , " , <nl> + " ) " ) ; <nl> + <nl> + javacompilationargsprovider compilationargsprovider = <nl> + getjavacompilationargsprovider ( getconfiguredtarget ( " / / x : foo_java_proto_lite " ) ) ; <nl> + <nl> + iterable < string > directjars = <nl> + prettyjarnames ( compilationargsprovider . getjavacompilationargs ( ) . getcompiletimejars ( ) ) ; <nl> + <nl> + assertthat ( directjars ) . containsexactly ( " x / libbar_proto - lite - hjar . jar " ) ; <nl> + } <nl> + <nl> private static javacompilationargsprovider getjavacompilationargsprovider ( <nl> configuredtarget target ) { <nl> skylarkproviders skylarkproviders = target . getprovider ( skylarkproviders . class ) ;
public class blazejavacmain { <nl> } <nl> } <nl> errwriter . flush ( ) ; <nl> - return new blazejavacresult ( result , diagnostics . build ( ) , erroutput . tostring ( ) , compiler ) ; <nl> + return new blazejavacresult ( <nl> + result , filterdiagnostics ( diagnostics . build ( ) ) , erroutput . tostring ( ) , compiler ) ; <nl> + } <nl> + <nl> + private static final immutableset < string > ignored_diagnostic_codes = <nl> + immutableset . of ( <nl> + " compiler . note . deprecated . filename " , <nl> + " compiler . note . deprecated . plural " , <nl> + " compiler . note . deprecated . recompile " , <nl> + " compiler . note . deprecated . filename . additional " , <nl> + " compiler . note . deprecated . plural . additional " , <nl> + " compiler . note . unchecked . filename " , <nl> + " compiler . note . unchecked . plural " , <nl> + " compiler . note . unchecked . recompile " , <nl> + " compiler . note . unchecked . filename . additional " , <nl> + " compiler . note . unchecked . plural . additional " , <nl> + " compiler . warn . sun . proprietary " ) ; <nl> + <nl> + private static immutablelist < formatteddiagnostic > filterdiagnostics ( <nl> + immutablelist < formatteddiagnostic > diagnostics ) { <nl> + <nl> + immutablelist . builder < formatteddiagnostic > result = immutablelist . builder ( ) ; <nl> + diagnostics <nl> + . stream ( ) <nl> + . filter ( d - > ! ignored_diagnostic_codes . contains ( d . getcode ( ) ) ) <nl> + . foreach ( result : : add ) ; <nl> + return result . build ( ) ; <nl> } <nl>  <nl> / * * processes plugin - specific arguments and removes them from the args array . * /
function create_artifact ( ) { <nl> local artifact_id = $ 2 <nl> local version = $ 3 <nl> local packaging = $ { 4 : - jar } <nl> + # <nl> + # finalize the implementation once the underlying tests are fixed . <nl> + local classifier = $ { 5 : - jar } <nl> if [ $ packaging = = " aar " ] ; then <nl> make_test_aar <nl> local artifact = $ test_aar <nl> mmm a / tools / build_defs / repo / maven_rules . bzl <nl> ppp b / tools / build_defs / repo / maven_rules . bzl <nl>
sh_test ( <nl> " : test - deps " , <nl> " / / src / test / java / com / google / devtools / build / lib : exampleworker_deploy . jar " , <nl> ] , <nl> + # <nl> + flaky = num , <nl> shard_count = num , <nl> tags = [ " jdk8 " ] , <nl> )
java_library ( <nl> " / / third_party : apache_commons_lang " , <nl> ] , <nl> ) <nl> + <nl> + genrule ( <nl> + name = " jacoco_jarjar " , <nl> + srcs = [ <nl> + " : jacococoverage_deploy . jar " , <nl> + " : jacococoverage . jarjar " , <nl> + ] , <nl> + outs = [ " jacococoverage_jarjar_deploy . jar " ] , <nl> + cmd = " \n " . join ( [ <nl> + # bazel num . 4 . 3 contains two bugs : a quoting bug in the java cmd . exe <nl> + # wrapper script that makes it unable to handle $ signs in paths ( # 2306 ) <nl> + # and one that makes it occasionally put $ signs in the output base <nl> + # ( # 2342 ) . <nl> + # <nl> + # these two collude to make it impossible to run built java binaries on <nl> + # windows if the output base happens to contain a $ sign . <nl> + # <nl> + # thus , don ' t call jarjar when on windows . this makes java coverage not <nl> + # work if the code under test uses libraries the test runner also does <nl> + # ( e . g . asm ) . <nl> + # <nl> + # <nl> + # these bugs is out . <nl> + " if [ [ $ $ ( uname - a ) = ~ msys ] ] ; then " , <nl> + " cp \ " $ ( location : jacococoverage_deploy . jar ) \ " \ " $ @ \ " ; " , <nl> + " else " , <nl> + " \ " $ ( location / / third_party / java / jarjar : jarjar_bin ) \ " process \ " $ ( location : jacococoverage . jarjar ) \ " \ " $ ( location : jacococoverage_deploy . jar ) \ " \ " $ @ \ " " , <nl> + " fi " , <nl> + ] ) , <nl> + tools = [ " / / third_party / java / jarjar : jarjar_bin " ] , <nl> + ) <nl> mmm / dev / null <nl> ppp b / src / java_tools / junitrunner / java / com / google / testing / coverage / jacococoverage . jarjar <nl>
cc_grpc_library ( <nl> src = " command_server . proto " , <nl> ) <nl>  <nl> + # <nl> java_proto_library ( <nl> name = " remote_protocol_java_proto " , <nl> src = " remote_protocol . proto " ,
def swiftc_args ( ctx ) : <nl> args . extend ( framework_args ) <nl> args . extend ( clang_args ) <nl> args . extend ( define_args ) <nl> + <nl> + # <nl> + if hasattr ( ctx . fragments , " swift " ) : <nl> + args . extend ( ctx . fragments . swift . copts ( ) ) <nl> + <nl> args . extend ( ctx . attr . copts ) <nl>  <nl> return args <nl>
eof <nl> | | true <nl> } <nl>  <nl> + # <nl> + function test_placeholder_until_real_tests_are_enabled ( ) { <nl> + echo " test_placeholder_until_real_tests_are_enabled " <nl> + } <nl>  <nl> - run_suite " persistent test runner tests " <nl> \ no newline at end of file <nl> + run_suite " persistent test runner tests "
public class multiarchsplittransitionprovider implements splittransitionprovider <nl>  <nl> splitoptions . get ( applecommandlineoptions . class ) . appleplatformtype = platformtype ; <nl> splitoptions . get ( applecommandlineoptions . class ) . applesplitcpu = cpu ; <nl> + / / if the new configuration does not use the apple crosstool , then it needs ios_cpu to be <nl> + / / to decide architecture . <nl> + <nl> + splitoptions . get ( applecommandlineoptions . class ) . ioscpu = cpu ; <nl> + <nl> if ( splitoptions . get ( objccommandlineoptions . class ) . enableccdeps ) { <nl> / / only set the ( cc - compilation ) cpu for dependencies if explicitly required by the user . <nl> / / this helps users of the ios rules who do not depend on cc rules as these cpu values <nl>
bool writefile ( const void * data , size_t size , const string & filename ) { <nl> # else / / not compiler_msvc <nl> # endif / / compiler_msvc <nl>  <nl> - static bool unlinkpathw ( const wstring & path ) { <nl> - dword attrs = : : getfileattributesw ( path . c_str ( ) ) ; <nl> - if ( attrs = = invalid_file_attributes ) { <nl> - / / path does not exist . <nl> - return false ; <nl> - } <nl> - if ( attrs & file_attribute_directory ) { <nl> - if ( ! ( attrs & file_attribute_reparse_point ) ) { <nl> - / / path is a directory ; unlink ( 2 ) also cannot remove directories . <nl> - return false ; <nl> - } <nl> - / / otherwise it ' s a junction , remove using removedirectoryw . <nl> - return : : removedirectoryw ( path . c_str ( ) ) = = true ; <nl> - } else { <nl> - / / otherwise it ' s a file , remove using deletefilew . <nl> - return : : deletefilew ( path . c_str ( ) ) = = true ; <nl> - } <nl> - } <nl> - <nl> + # ifdef compiler_msvc <nl> bool unlinkpath ( const string & file_path ) { <nl> - wstring wpath ; <nl> - if ( ! aswindowspathwithuncprefix ( file_path , & wpath ) ) { <nl> - return false ; <nl> - } <nl> - return unlinkpathw ( wpath ) ; <nl> + <nl> + pdie ( 255 , " blaze_util : : unlinkpath is not implemented on windows " ) ; <nl> + return false ; <nl> } <nl> + # else / / not compiler_msvc <nl> + # endif / / compiler_msvc <nl>  <nl> handle opendirectory ( const wchar * path , bool read_write ) { <nl> return : : createfilew ( <nl> mmm a / src / test / cpp / util / file_windows_test . cc <nl> ppp b / src / test / cpp / util / file_windows_test . cc <nl>
typedef struct { <nl> wchar pathbuffer [ anysize_array ] ; <nl> } reparse_mountpoint_data_buffer , * preparse_mountpoint_data_buffer ; <nl>  <nl> - / / defined by file_windows . cc <nl> - handle opendirectory ( const wchar * path , bool read_write ) ; <nl> + <nl> + / / https : / / github . com / bazelbuild / bazel / issues / 2181 . <nl> + handle opendirectory ( const string & path , bool readwrite ) { <nl> + handle result = : : createfilea ( <nl> + / * lpfilename * / path . c_str ( ) , <nl> + / * dwdesiredaccess * / readwrite ? ( generic_read | generic_write ) <nl> + : generic_read , <nl> + / * dwsharemode * / num , <nl> + / * lpsecurityattributes * / null , <nl> + / * dwcreationdisposition * / open_existing , <nl> + / * dwflagsandattributes * / file_flag_open_reparse_point | <nl> + file_flag_backup_semantics , <nl> + / * htemplatefile * / null ) ; <nl> + if ( result = = invalid_handle_value ) { <nl> + printerror ( " createfile ( " + path + " ) " ) ; <nl> + } <nl> + <nl> + return result ; <nl> + } <nl>  <nl> bool symlinkdirectories ( const string & posix_target , const string & posix_name ) { <nl> string target = convertpath ( posix_target ) ; <nl> string name = convertpath ( posix_name ) ; <nl> - wstring wname ; <nl> - <nl> - if ( ! blaze_util : : aswindowspath ( name , & wname ) ) { <nl> - printerror ( " symlinkdirectories : aswindowspath ( " + name + " ) " ) ; <nl> - return false ; <nl> - } <nl> - wname = wstring ( l " \ \ \ \ ? \ \ " ) + wname ; <nl>  <nl> / / junctions are directories , so create one <nl> if ( ! : : createdirectorya ( name . c_str ( ) , null ) ) { <nl>
def _swift_compilation_mode_flags ( ctx ) : <nl> mode = ctx . var [ " compilation_mode " ] <nl>  <nl> flags = [ ] <nl> - if mode = = " dbg " : <nl> - flags + = [ " - onone " , " - ddebug " , " - enable - testing " ] <nl> - elif mode = = " fastbuild " : <nl> - flags + = [ " - onone " , " - ddebug " , " - enable - testing " ] <nl> + if mode = = " dbg " or mode = = " fastbuild " : <nl> + # <nl> + flags + = [ <nl> + " - onone " , " - ddebug " , " - enable - testing " , " - xfrontend " , <nl> + " - serialize - debugging - options " <nl> + ] <nl> elif mode = = " opt " : <nl> flags + = [ " - o " , " - dndebug " ]
void executedaemon ( const string & exe , const std : : vector < string > & args_vector , <nl> sa . binherithandle = true ; <nl> sa . lpsecuritydescriptor = null ; <nl>  <nl> - handle output_file = createfilea ( <nl> - / * lpfilename * / convertpath ( daemon_output ) . c_str ( ) , <nl> + handle output_file = createfilew ( <nl> + / * lpfilename * / wdaemon_output . c_str ( ) , <nl> / * dwdesiredaccess * / generic_read | generic_write , <nl> / / so that the file can be read while the server is running <nl> + <nl> / * dwsharemode * / file_share_read , <nl> / * lpsecurityattributes * / & sa , <nl> / * dwcreationdisposition * / create_always , <nl>
java_test ( <nl> " vfs / * . java " , <nl> " vfs / inmemoryfs / * . java " , <nl> ] , <nl> - # java_rules_skylark doesn ' t support resource loading with <nl> - # qualified paths . <nl> exclude = [ <nl> + # <nl> + " concurrent / multisetsemaphoretest . java " , <nl> + # java_rules_skylark doesn ' t support resource loading with <nl> + # qualified paths . <nl> " util / resourcefileloadertest . java " , <nl> ] + all_windows_tests , <nl> ) ,
public class cpplinkactiontest extends buildviewtestcase { <nl>  <nl> @ test <nl> public void testcompilestestsourcesintodynamiclibrary ( ) throws exception { <nl> + if ( os . getcurrent ( ) = = os . windows ) { <nl> + / / skip the test on windows . <nl> + <nl> + return ; <nl> + } <nl> scratch . file ( " x / build " , " cc_test ( name = ' a ' , srcs = [ ' a . cc ' ] ) " ) ; <nl> scratch . file ( " x / a . cc " , " int main ( ) { } " ) ; <nl> useconfiguration ( " - - experimental_link_dynamic_binaries_separately " ) ;
function test_3_local_jobs ( ) { <nl> - - runs_per_test = 10 / / dir : test <nl> } <nl>  <nl> - function test_tmpdir ( ) { <nl> + # <nl> + function disabled_test_tmpdir ( ) { <nl> mkdir - p foo <nl> cat > foo / bar_test . sh < < ' eof ' <nl> # ! / bin / bash <nl>
public final class buildconfiguration { <nl> help = " the target cpu . " ) <nl> public string cpu ; <nl>  <nl> + / * * <nl> + * allows a configuration to record if - - experimental_multi_cpu was used to set a cpu value . <nl> + * this is necessary to ensure that a configuration transition that sets cpu does not erase <nl> + * the difference between a pair of configurations created by - - experimental_multi_cpu , leading <nl> + * to a crash when the configurations are treated as the same . <nl> + * <nl> + * < p > <nl> + * / <nl> + @ option ( name = " experimental multi cpu distinguisher " , <nl> + defaultvalue = " " , <nl> + category = " undocumented " ) <nl> + public string experimentalmulticpudistinguisher ; <nl> + <nl> @ option ( name = " min_param_file_size " , <nl> defaultvalue = " 32768 " , <nl> category = " undocumented " , <nl> mmm a / src / main / java / com / google / devtools / build / lib / skyframe / configurationcollectionfunction . java <nl> ppp b / src / main / java / com / google / devtools / build / lib / skyframe / configurationcollectionfunction . java <nl>
def _swift_library_impl ( ctx ) : <nl> swiftc_output_map_file . path , <nl> ] <nl>  <nl> - # when wmo is enabled , there ' s only one output , the module object file , which <nl> - # location should be explicitly given to the driver . <nl> if has_wmo : <nl> - args . extend ( [ " - o " , output_objs [ 0 ] . path ] ) <nl> + # wmo has two modes : threaded and not . we want the threaded mode because it <nl> + # will use the output map we generate . this leads to a better debug <nl> + # experience in lldb and xcode . <nl> + # <nl> + # we should get an interface in bazel to get core count . <nl> + args . extend ( [ " - num - threads " , " 12 " ] ) <nl>  <nl> xcrun_action ( <nl> ctx ,
ask - passphrase <nl> basedir . <nl> eof <nl>  <nl> - touch conf / override . stable <nl> - touch conf / override . testing <nl> + # <nl> + cat > conf / override . stable < < eof <nl> + bazel section contrib / devel <nl> + bazel priority optional <nl> + eof <nl> + cat > conf / override . testing < < eof <nl> + bazel section contrib / devel <nl> + bazel priority optional <nl> + eof <nl>  <nl> ensure_gpg_secret_key_imported <nl>  <nl>
current_dir = " $ ( cd " $ ( dirname " $ { bash_source [ 0 ] } " ) " & & pwd ) " <nl> source " $ { current_dir } / . . / integration_test_setup . sh " \ <nl> | | { echo " integration_test_setup . sh not found ! " > & 2 ; exit num ; } <nl>  <nl> - function test_java_test_coverage ( ) { <nl> + # <nl> + function disabled_test_java_test_coverage ( ) { <nl> mkdir java_test <nl>  <nl> cat < < eof > java_test / build <nl>
eof <nl> fi <nl> } <nl>  <nl> - run_suite " test tests " <nl> + # <nl> + # run_suite " test tests " <nl> mmm a / src / test / shell / bazel / bazel_test_test . sh <nl> ppp b / src / test / shell / bazel / bazel_test_test . sh <nl>
function test_3_local_jobs ( ) { <nl> - - runs_per_test = 10 / / dir : test <nl> } <nl>  <nl> - function test_tmpdir ( ) { <nl> + # <nl> + function disabled_test_tmpdir ( ) { <nl> mkdir - p foo <nl> cat > foo / bar_test . sh < < ' eof ' <nl> # ! / bin / bash
<nl> + # setup intellij for bazel development using the intellij bazel plugin . <nl> + # see https : / / github . com / bazelbuild / intellij for installation instructions . <nl> + directories : <nl> + src / main <nl> + src / test <nl> + <nl> + test_sources : <nl> + src / test / * <nl> + <nl> + targets : <nl> + / / src : bazel <nl> + / / src / test / . . . <nl> + <nl> + # <nl> + java_language_level : num <nl> +
public class constraintsemantics { <nl> / / note this reassignment means constraint violation errors reference the generating <nl> / / rule , not the file . this makes the source of the environmental mismatch more clear . <nl> dep = ( ( outputfileconfiguredtarget ) dep ) . getgeneratingrule ( ) ; <nl> + if ( dep = = null ) { <nl> + / / this shouldn ' t happen , but this is causing spurious bazel test failures because the <nl> + / / getprovider call below throws a nullpointerexception . see b / 33385302 for details . <nl> + <nl> + continue ; <nl> + } <nl> } <nl> / / input files don ' t support environments . we may subsequently opt them into constraint <nl> / / checking , but for now just pass them by .
string get_cwd ( ) { <nl> # endif / / compiler_msvc <nl> } <nl>  <nl> + bool make_dirs ( const char * path , mode_t mode ) { <nl> + # ifdef compiler_msvc <nl> + <nl> + fprintf ( stderr , " not yet implemented on windows\n " ) ; <nl> + return false ; <nl> + # else / / not compiler_msvc <nl> + / / directories created must have executable bit set and be owner writeable . <nl> + / / otherwise , we cannot write or create any file inside . <nl> + mode | = s_iwusr | s_ixusr ; <nl> + char path_ [ path_max ] ; <nl> + stat file_stat ; <nl> + strncpy ( path_ , path , path_max ) ; <nl> + path_ [ path_max - num ] = num ; <nl> + char * pointer = path_ ; <nl> + while ( ( pointer = strchr ( pointer , ' / ' ) ) ! = null ) { <nl> + if ( path_ ! = pointer ) { / / skip leading slash <nl> + * pointer = num ; <nl> + if ( ! stat_file ( path_ , & file_stat ) & & mkdir ( path_ , mode ) < num ) { <nl> + fprintf ( stderr , " cannot create folder % s : % s\n " , <nl> + path_ , strerror ( errno ) ) ; <nl> + return false ; <nl> + } <nl> + * pointer = ' / ' ; <nl> + } <nl> + pointer + + ; <nl> + } <nl> + return true ; <nl> + # endif / / compiler_msvc <nl> + } <nl> + <nl> } / / namespace devtools_ijar <nl> mmm a / third_party / ijar / platform_utils . h <nl> ppp b / third_party / ijar / platform_utils . h <nl>
bool read_file ( const char * path , void * buffer , size_t size ) { <nl> # endif / / compiler_msvc <nl> } <nl>  <nl> + string get_cwd ( ) { <nl> + # ifdef compiler_msvc <nl> + <nl> + fprintf ( stderr , " not yet implemented on windows\n " ) ; <nl> + return " " ; <nl> + # else / / not compiler_msvc <nl> + char cwd [ path_max ] ; <nl> + if ( getcwd ( cwd , path_max ) = = null ) { <nl> + fprintf ( stderr , " getcwd ( ) failed : % s\n " , strerror ( errno ) ) ; <nl> + return " " ; <nl> + } else { <nl> + return string ( cwd ) ; <nl> + } <nl> + # endif / / compiler_msvc <nl> + } <nl> + <nl> } / / namespace devtools_ijar <nl> mmm a / third_party / ijar / platform_utils . h <nl> ppp b / third_party / ijar / platform_utils . h <nl>
bool write_file ( const char * path , mode_t perm , const void * data , size_t size ) { <nl> # endif / / compiler_msvc <nl> } <nl>  <nl> + bool read_file ( const char * path , void * buffer , size_t size ) { <nl> + # ifdef compiler_msvc <nl> + <nl> + fprintf ( stderr , " not yet implemented on windows\n " ) ; <nl> + return false ; <nl> + # else / / not compiler_msvc <nl> + / / read the input file <nl> + int fd = open ( path , o_rdonly ) ; <nl> + if ( fd < num ) { <nl> + fprintf ( stderr , " can ' t open file % s for reading : % s\n " , <nl> + path , strerror ( errno ) ) ; <nl> + return false ; <nl> + } <nl> + bool result = true ; <nl> + size_t nb_read = num ; <nl> + while ( nb_read < size ) { <nl> + size_t to_read = size - nb_read ; <nl> + if ( to_read > num / * num k * / ) { <nl> + to_read = num ; <nl> + } <nl> + ssize_t r = read ( fd , static_cast < uint8_t * > ( buffer ) + nb_read , to_read ) ; <nl> + if ( r < num ) { <nl> + fprintf ( stderr , " can ' t read % zu bytes from file % s : % s\n " , <nl> + to_read , path , strerror ( errno ) ) ; <nl> + result = false ; <nl> + break ; <nl> + } <nl> + nb_read + = r ; <nl> + } <nl> + if ( close ( fd ) ) { <nl> + fprintf ( stderr , " cannot close file % s : % s\n " , path , strerror ( errno ) ) ; <nl> + result = false ; <nl> + } <nl> + return result ; <nl> + # endif / / compiler_msvc <nl> + } <nl> + <nl> } / / namespace devtools_ijar <nl> mmm a / third_party / ijar / platform_utils . h <nl> ppp b / third_party / ijar / platform_utils . h <nl>
bool stat_file ( const char * path , stat * result ) { <nl> # endif / / compiler_msvc <nl> } <nl>  <nl> + bool write_file ( const char * path , mode_t perm , const void * data , size_t size ) { <nl> + # ifdef compiler_msvc <nl> + <nl> + fprintf ( stderr , " not yet implemented on windows\n " ) ; <nl> + return false ; <nl> + # else / / not compiler_msvc <nl> + int fd = open ( path , o_creat | o_wronly , perm ) ; <nl> + if ( fd < num ) { <nl> + fprintf ( stderr , " cannot open file % s for writing : % s\n " , <nl> + path , strerror ( errno ) ) ; <nl> + return false ; <nl> + } <nl> + bool result = true ; <nl> + if ( write ( fd , data , size ) ! = size ) { <nl> + fprintf ( stderr , " cannot write % zu bytes to file % s : % s\n " , <nl> + size , path , strerror ( errno ) ) ; <nl> + result = false ; <nl> + } <nl> + if ( close ( fd ) ) { <nl> + fprintf ( stderr , " cannot close file % s : % s\n " , path , strerror ( errno ) ) ; <nl> + result = false ; <nl> + } <nl> + return result ; <nl> + # endif / / compiler_msvc <nl> + } <nl> + <nl> } / / namespace devtools_ijar <nl> mmm a / third_party / ijar / platform_utils . h <nl> ppp b / third_party / ijar / platform_utils . h <nl>
static void startserverandconnect ( blazeserver * server ) { <nl> " server directory ' % s ' could not be created " , server_dir . c_str ( ) ) ; <nl> } <nl>  <nl> + <nl> + / / bazel clients that used to write pid symlinks will probably no longer be in <nl> + / / use . <nl> + / / until then , defensively delete old pid symlinks that older clients may have <nl> + / / left behind . <nl> + string pid_symlink = blaze_util : : joinpath ( server_dir , kserverpidsymlink ) ; <nl> + remove ( pid_symlink . c_str ( ) ) ; <nl> + <nl> / / if we couldn ' t connect to the server check if there is still a pid file <nl> / / and if so , kill the server that wrote it . this can happen e . g . if the <nl> / / server is in a gc pause and therefore cannot respond to ping requests and <nl> mmm a / src / main / cpp / blaze_util . h <nl> ppp b / src / main / cpp / blaze_util . h <nl>
<nl> namespace blaze { <nl>  <nl> extern const char kserverpidfile [ ] ; <nl> + <nl> + <nl> + / / used to write pid symlinks will probably no longer be in use . <nl> extern const char kserverpidsymlink [ ] ; <nl>  <nl> std : : string getusername ( ) ; <nl> mmm a / src / main / cpp / blaze_util_posix . cc <nl> ppp b / src / main / cpp / blaze_util_posix . cc <nl>
public final class environment implements freezable { <nl>  <nl> private final string transitivehashcode ; <nl>  <nl> - / * * <nl> - * is this environment being evaluated during the loading phase ? <nl> - * this is fixed during environment setup , and enables various functions <nl> - * that are not available during the analysis or workspace phase . <nl> - * / <nl> - public phase getphase ( ) { <nl> - return phase ; <nl> - } <nl> - <nl> / * * <nl> * checks that the current environment is in the loading or the workspace phase . <nl> + * <nl> + * <nl> * @ param symbol name of the function being only authorized thus . <nl> * / <nl> public void checkloadingorworkspacephase ( string symbol , location loc ) throws evalexception { <nl>
public final class environment implements freezable { <nl>  <nl> / * * <nl> * checks that the current environment is in the loading phase . <nl> + * <nl> + * <nl> * @ param symbol name of the function being only authorized thus . <nl> * / <nl> public void checkloadingphase ( string symbol , location loc ) throws evalexception { <nl> mmm a / src / main / java / com / google / devtools / build / lib / syntax / skylarkutils . java <nl> ppp b / src / main / java / com / google / devtools / build / lib / syntax / skylarkutils . java <nl>
public class legacycompilationsupport extends compilationsupport { <nl> commandline . add ( " - filelist " ) . add ( inputfilelist . getexecpathstring ( ) ) ; <nl> } <nl>  <nl> + applebitcodemode bitcodemode = appleconfiguration . getbitcodemode ( ) ; <nl> + commandline . add ( bitcodemode . getcompileandlinkflags ( ) ) ; <nl> + <nl> + if ( bitcodemode = = applebitcodemode . embedded ) { <nl> + commandline . add ( " - xlinker " ) . add ( " - bitcode_verify " ) ; <nl> + commandline . add ( " - xlinker " ) . add ( " - bitcode_hide_symbols " ) ; <nl> + <nl> + } <nl> + <nl> commandline <nl> . add ( commonlinkandcompileflagsforclang ( objcprovider , objcconfiguration , appleconfiguration ) ) <nl> . add ( " - xlinker " ) <nl>
public class cppcompileaction extends abstractaction <nl> fingerprint f = new fingerprint ( ) ; <nl> f . adduuid ( actionclassid ) ; <nl> f . addstringmap ( getenvironment ( ) ) ; <nl> - f . addstrings ( getargv ( ) ) ; <nl> f . addstrings ( executionrequirements ) ; <nl>  <nl> + / / for the argv part of the cache key , ignore all compiler flags that explicitly denote module <nl> + / / file ( . pcm ) inputs . depending on input discovery , some of the unused ones are removed from <nl> + / / the command line . however , these actually don ' t have an influence on the compile itself and <nl> + / / so ignoring them for the cache key calculation does not affect correctness . the compile <nl> + / / itself is fully determined by the input source files and module maps . <nl> + / / a better long - term solution would be to make the compiler to find them automatically and <nl> + / / never hand in the . pcm files explicitly on the command line in the first place . <nl> + variables overwrittenvariables = this . overwrittenvariables ; <nl> + this . overwrittenvariables = getoverwrittenvariables ( immutablelist . < artifact > of ( ) ) ; <nl> + <nl> + f . addstrings ( getargv ( ) ) ; <nl> + this . overwrittenvariables = overwrittenvariables ; <nl> + <nl> / * <nl> * getargv ( ) above captures all changes which affect the compilation <nl> * command and hence the contents of the object file . but we need to <nl>
string getselfpath ( ) { <nl> if ( ! getmodulefilename ( 0 , buffer , sizeof ( buffer ) ) ) { <nl> pdie ( 255 , " error % u getting executable file name\n " , getlasterror ( ) ) ; <nl> } <nl> + <nl> + <nl> + if ( strlen ( buffer ) = = num | | buffer [ 0 ] = = ' \ \ ' ) { <nl> + printerror ( " getmodulefilename " ) ; <nl> + buffer [ path_max - num ] = ' \ 0 ' ; <nl> + pdie ( 255 , " error in getselfpath , buffer = ( % s ) " , buffer ) ; <nl> + } <nl> return string ( buffer ) ; <nl> } <nl>  <nl> string getoutputroot ( ) { <nl> - char * tmpdir = getenv ( " tmpdir " ) ; <nl> - if ( tmpdir = = num | | strlen ( tmpdir ) = = num ) { <nl> - return " / var / tmp " ; <nl> - } else { <nl> - return string ( tmpdir ) ; <nl> + # ifdef compiler_msvc <nl> + / / gettemppatha and getenvironmentvariablea only work properly when bazel <nl> + / / runs under cmd . exe , not when it ' s run from msys . <nl> + / / we don ' t know the reason for this ; what ' s sure is getenvironmentvariablea <nl> + / / returns nothing for temp under msys , though it can retrieve windir . <nl> + <nl> + char buf [ max_path + num ] ; <nl> + if ( ! gettemppatha ( sizeof ( buf ) , buf ) ) { <nl> + printerror ( " gettemppath " ) ; <nl> + pdie ( 255 , " could not retrieve the temp directory path " ) ; <nl> + } <nl> + return buf ; <nl> + # else / / not compiler_msvc <nl> + for ( const char * i : { " tmpdir " , " tempdir " , " tmp " , " temp " } ) { <nl> + char * tmpdir = getenv ( i ) ; <nl> + if ( tmpdir ! = null & & strlen ( tmpdir ) > num ) { <nl> + return tmpdir ; <nl> + } <nl> } <nl> + <nl> + return " / var / tmp " ; <nl> + # endif / / compiler_msvc <nl> } <nl>  <nl> uint64_t getmillisecondsmonotonic ( ) {
public class reducedclasspathjavalibrarybuilder extends simplejavalibrarybuilder <nl> return javacoutput . contains ( " error : cannot access " ) <nl> | | javacoutput . contains ( " error : cannot find symbol " ) <nl> | | javacoutput . contains ( " com . sun . tools . javac . code . symbol $ completionfailure " ) <nl> - | | missing_package . matcher ( javacoutput ) . find ( ) ; <nl> + | | missing_package . matcher ( javacoutput ) . find ( ) <nl> + <nl> + | | javacoutput . contains ( " error : reference not found " ) ; <nl> } <nl> }
public class artifact <nl> / * * <nl> * returns true iff this is a treeartifact representing a directory tree containing artifacts . <nl> * / <nl> + <nl> + @ skylarkcallable ( name = " is_directory " , structfield = true , documented = false ) <nl> public boolean istreeartifact ( ) { <nl> return false ; <nl> }
public final class binaryoperatorexpression extends expression { <nl> * < p > publicly accessible for reflection and compiled skylark code . <nl> * / <nl> public static object mult ( object lval , object rval , location location ) throws evalexception { <nl> - / / int * int <nl> - if ( lval instanceof integer & & rval instanceof integer ) { <nl> - return ( ( integer ) lval ) . intvalue ( ) * ( ( integer ) rval ) . intvalue ( ) ; <nl> - } <nl> - <nl> - / / string * int <nl> - if ( lval instanceof string & & rval instanceof integer ) { <nl> - return strings . repeat ( ( string ) lval , ( ( integer ) rval ) . intvalue ( ) ) ; <nl> + integer number = null ; <nl> + object otherfactor = null ; <nl> + <nl> + if ( lval instanceof integer ) { <nl> + number = ( integer ) lval ; <nl> + otherfactor = rval ; <nl> + } else if ( rval instanceof integer ) { <nl> + number = ( integer ) rval ; <nl> + otherfactor = lval ; <nl> } <nl>  <nl> - / / int * string <nl> - if ( lval instanceof integer & & rval instanceof string ) { <nl> - return strings . repeat ( ( string ) rval , ( ( integer ) lval ) . intvalue ( ) ) ; <nl> + if ( number ! = null ) { <nl> + if ( otherfactor instanceof integer ) { <nl> + return number . intvalue ( ) * ( ( integer ) otherfactor ) . intvalue ( ) ; <nl> + } else if ( otherfactor instanceof string ) { <nl> + / / similar to python , a factor < num leads to an empty string . <nl> + return strings . repeat ( ( string ) otherfactor , math . max ( 0 , number . intvalue ( ) ) ) ; <nl> + } <nl> + <nl> } <nl> throw typeexception ( lval , rval , operator . mult , location ) ; <nl> } <nl> mmm a / src / test / java / com / google / devtools / build / lib / syntax / evaluationtest . java <nl> ppp b / src / test / java / com / google / devtools / build / lib / syntax / evaluationtest . java <nl>
test_f ( blazeutiltest , makedirectories ) { <nl> assert_eq ( 0750 , filestat . st_mode & num ) ; <nl>  <nl> / / srcdir shouldn ' t be writable . <nl> - string srcdir = blaze_util : : joinpath ( test_src_dir , " x / y / z " ) ; <nl> - ok = makedirectories ( srcdir , num ) ; <nl> - assert_eq ( - 1 , ok ) ; <nl> - assert_eq ( eacces , errno ) ; <nl> + <nl> + / / ok = makedirectories ( srcdir , num ) ; <nl> + / / assert_eq ( - 1 , ok ) ; <nl> + / / assert_eq ( eacces , errno ) ; <nl>  <nl> / / can ' t make a dir out of a file . <nl> string non_dir = blaze_util : : joinpath ( dir , " w " ) ; <nl>
test_f ( blazeutiltest , makedirectories ) { <nl> assert_true ( symlink ( " / " , symlink ) ) ; <nl>  <nl> / / these perms will force a chmod ( ) <nl> - ok = makedirectories ( symlink , num ) ; <nl> - assert_eq ( - 1 , ok ) ; <nl> - assert_eq ( eperm , errno ) ; <nl> + <nl> + / / assert_eq ( - 1 , ok ) ; <nl> + / / assert_eq ( eperm , errno ) ; <nl>  <nl> / / edge cases . <nl> assert_eq ( - 1 , makedirectories ( " " , num ) ) ; <nl>
test_f ( blazeutiltest , hammermakedirectories ) { <nl> assert_strne ( tmp_dir , null ) ; <nl>  <nl> string path = blaze_util : : joinpath ( tmp_dir , " x / y / z " ) ; <nl> - assert_le ( 0 , fork ( ) ) ; <nl> - assert_eq ( 0 , makedirectories ( path , num ) ) ; <nl> + <nl> + / / assert_eq ( 0 , makedirectories ( path , num ) ) ; <nl> } <nl>  <nl> } / / namespace blaze
class xmloutputformatter extends abstractunorderedformatter { <nl> elem = doc . createelement ( " rule " ) ; <nl> elem . setattribute ( " class " , rule . getruleclass ( ) ) ; <nl> for ( attribute attr : rule . getattributes ( ) ) { <nl> - pair < iterable < object > , attributevaluesource > values = <nl> - getpossibleattributevaluesandsources ( rule , attr ) ; <nl> + pair < iterable < object > , attributevaluesource > values ; <nl> + if ( attr . gettype ( ) . equals ( buildtype . label_list ) ) { <nl> + / / avoid iterating over all possible values for a configurable label list , since all we <nl> + / / care about are the raw labels . this avoids potential memory overruns . for example , <nl> + / / given select ( { " : c " : [ " / / a : one " , " / / a : two " ] , " : d " : [ " / / a : two " ] ] } ) , all we really need is <nl> + / / [ " / / a : one " , " / / a : two " ] . we don ' t care how exactly what combination of labels gets <nl> + / / selected . <nl> + <nl> + <nl> + / / isn ' t trivial because bazel ' s label visitation logic includes special methods built <nl> + / / directly into type . <nl> + values = pair . < iterable < object > , attributevaluesource > of ( <nl> + immutablelist . < object > of ( <nl> + aggregatingattributemapper . of ( rule ) <nl> + . getreachablelabels ( attr . getname ( ) , / * includeselectkeys = * / false ) ) , <nl> + attributevaluesource . rule ) ; <nl> + } else { <nl> + values = getpossibleattributevaluesandsources ( rule , attr ) ; <nl> + } <nl> if ( values . second = = attributevaluesource . rule | | options . xmlshowdefaultvalues ) { <nl> element attrelem = createvalueelement ( doc , attr . gettype ( ) , values . first ) ; <nl> attrelem . setattribute ( " name " , attr . getname ( ) ) ;
public class javaoptions extends fragmentoptions { <nl> ) <nl> public boolean headercompilation ; <nl>  <nl> + <nl> + @ deprecated <nl> @ option ( <nl> name = " experimental_optimize_header_compilation_annotation_processing " , <nl> defaultvalue = " false " , <nl> category = " undocumented " , <nl> - help = " experimental : only run api - generating java_plugins during header compilation . " <nl> + help = " this flag is a noop and scheduled for removal . " <nl> ) <nl> public boolean optimizeheadercompilationannotationprocessing ;
eof <nl> err1nocolor = $ ( mktemp x / xxxxxx ) <nl> err2 = $ ( mktemp x / xxxxxx ) <nl>  <nl> + # <nl> + add_to_bazelrc common - - show_progress_rate_limit = 0 . 03 <nl> bazel run / / x : x - - color = yes > $ out1color num > $ err1raw_color | | fail " expected success " <nl> bazel run / / x : x - - color = no > $ out1nocolor num > $ err1raw_nocolor | | fail " expected success " <nl>  <nl>
public final class cleancommand implements blazecommand { <nl> return exitcode . command_line_error ; <nl> } <nl>  <nl> + <nl> + if ( cleanoptions . expunge_async & & os . getcurrent ( ) ! = os . linux ) { <nl> + env . getreporter ( ) . handle ( event . info ( null / * location * / , <nl> + " - - expunge_async cannot be used on non - linux platforms , falling back to - - expunge " ) ) ; <nl> + cleanoptions . expunge_async = false ; <nl> + cleanoptions . expunge = true ; <nl> + cleanoptions . cleanstyle = " expunge " ; <nl> + } <nl> + <nl> string cleanbanner = cleanoptions . expunge_async ? <nl> " starting clean . " : <nl> " starting clean ( this may take a while ) . " +
<nl> + # ! / bin / bash <nl> + # <nl> + # copyright num the bazel authors . all rights reserved . <nl> + # <nl> + # licensed under the apache license , version num . 0 ( the " license " ) ; <nl> + # you may not use this file except in compliance with the license . <nl> + # you may obtain a copy of the license at <nl> + # <nl> + # http : / / www . apache . org / licenses / license - 2 . 0 <nl> + # <nl> + # unless required by applicable law or agreed to in writing , software <nl> + # distributed under the license is distributed on an " as is " basis , <nl> + # without warranties or conditions of any kind , either express or implied . <nl> + # see the license for the specific language governing permissions and <nl> + # limitations under the license . <nl> + <nl> + # load test environment <nl> + source $ ( cd " $ ( dirname " $ { bash_source [ 0 ] } " ) " & & pwd ) / test - setup . sh \ <nl> + | | { echo " test - setup . sh not found ! " > & 2 ; exit num ; } <nl> + <nl> + function test_build_objc_tools ( ) { <nl> + # <nl> + bazel build @ bazel_tools / / tools / objc : make_hashed_objlist . py \ <nl> + | | fail " should build tools / objc / make_hashed_objlist . py " <nl> + } <nl> + <nl> + run_suite " bazel_tools test suite "
public class applecommandlineoptions extends fragmentoptions { <nl> ) <nl> public label xcodeversionconfig ; <nl>  <nl> + <nl> + @ option ( <nl> + name = " experimental_disable_native_swift_rules " , <nl> + defaultvalue = " false " , <nl> + category = " undocumented " , <nl> + help = " disables swift support in native objc_ rules . " <nl> + ) <nl> + public boolean disablenativeswiftrules ; <nl> + <nl> / * * <nl> * the default label of the build - wide { @ code xcode_config } configuration rule . this can be <nl> * changed from the default using the { @ code xcode_version_config } build flag . <nl> mmm a / src / main / java / com / google / devtools / build / lib / rules / apple / appleconfiguration . java <nl> ppp b / src / main / java / com / google / devtools / build / lib / rules / apple / appleconfiguration . java <nl>
sh_binary ( <nl> srcs = [ " fail . sh " ] , <nl> ) <nl>  <nl> + # <nl> + filegroup ( <nl> + name = " desugar_java8_extra_bootclasspath " , <nl> + srcs = [ ] , <nl> + visibility = [ " / / visibility : public " ] , <nl> + ) <nl> + <nl> alias ( <nl> name = " idlclass " , <nl> actual = " / / src / tools / android / java / com / google / devtools / build / android / idlclass : idlclass " ,
for opt in " $ { @ } " ; do <nl> prefix = " $ ( echo " $ opt " | cut - d ' = ' - f num - ) " <nl> ; ; <nl> - - bazelrc = * ) <nl> - bazelrc = " $ ( echo " $ opt " | cut - d ' = ' - f num - ) " <nl> + # <nl> + # this comment . <nl> ; ; <nl> - - bin = * ) <nl> bin = " $ ( echo " $ opt " | cut - d ' = ' - f num - ) " <nl>
mkdir - p " $ { tmpdir } " # mkdir does work with a path starting with ' c : / ' , wow <nl> # containing spaces seem to be passed properly . <nl> echo " bootstrapping bazel " <nl> retcode = 0 <nl> + source . / scripts / ci / build . sh <nl> + <nl> + # <nl> + # for other platform <nl> . / compile . sh " $ * " | | retcode = $ ? <nl> if ( ( $ retcode ! = num ) ) ; then <nl> echo " $ retcode " > . unstable <nl>
linkpatterns = [ <nl> ( ( ' - o ' , ' ( . + ) ' ) , [ ' / out : $ path0 ' ] ) , <nl> ( ' - b ( . + ) ' , [ ] ) , <nl> ( ' - lpthread ' , [ ] ) , <nl> - ( ' - l ( . + ) ' , [ ' lib $ 0 . so ' ] ) , <nl> ( ' - l ( . + ) ' , [ ' / libpath : $ path0 ' ] ) , <nl> ( ' - static ' , [ ] ) , <nl> ( ' - shared ' , [ ' / dll ' ] ) , <nl> - ( ' - whole - archive ' , [ ] ) , <nl> + # <nl> + # / wholearchive is supported in visual stuido num update num <nl> + ( ( ' - whole - archive ' , ' ( . + ) ' ) , [ ' / wholearchive : $ path0 ' ] ) , <nl> ( ' - no - whole - archive ' , [ ] ) , <nl> ( ' - rdynamic ' , [ ] ) , <nl> ( r ' - wl , ( . + ) \ . lib ' , [ ' $ 0 . lib ' ] ) ,
def _clang_compilation_mode_flags ( ctx ) : <nl>  <nl> return [ x for x in native_clang_flags if x ! = " - g " ] <nl>  <nl> + def _swift_bitcode_flags ( ctx ) : <nl> + " " " returns bitcode flags based on selected mode . " " " <nl> + # <nl> + if hasattr ( ctx . fragments . apple , " bitcode_mode " ) : <nl> + mode = str ( ctx . fragments . apple . bitcode_mode ) <nl> + if mode = = " embedded " : <nl> + return [ " - embed - bitcode " ] <nl> + elif mode = = " embedded_markers " : <nl> + return [ " - embed - bitcode - marker " ] <nl> + <nl> + return [ ] <nl> + <nl> def _module_name ( ctx ) : <nl> " " " returns a module name for the given rule context . " " " <nl> return ctx . label . package . lstrip ( " / / " ) . replace ( " / " , " _ " ) + " _ " + ctx . label . name <nl>
void startupoptions : : init ( ) { <nl> output_root = getoutputroot ( ) ; <nl> } <nl>  <nl> - string product_name_lower = product_name ; <nl> + <nl> + / / definitions . <nl> + product_name = product_name ; <nl> + string product_name_lower = product_name ; <nl> blaze_util : : tolower ( & product_name_lower ) ; <nl> output_user_root = blaze_util : : joinpath ( <nl> output_root , " _ " + product_name_lower + " _ " + getusername ( ) ) ; <nl> mmm a / src / main / cpp / startup_options . h <nl> ppp b / src / main / cpp / startup_options . h <nl>
public abstract class filesystem { <nl> } . hash ( hashing . md5 ( ) ) . asbytes ( ) ; <nl> } <nl>  <nl> + / * * <nl> + * returns the md5 digest of the file denoted by { @ code path } . see <nl> + * { @ link path # getmd5digest } for specification . <nl> + * / <nl> + protected byte [ ] getsha1digest ( final path path ) throws ioexception { <nl> + <nl> + return new bytesource ( ) { <nl> + @ override <nl> + public inputstream openstream ( ) throws ioexception { <nl> + return getinputstream ( path ) ; <nl> + } <nl> + } . hash ( hashing . sha1 ( ) ) . asbytes ( ) ; <nl> + } <nl> + <nl> / * * <nl> * returns true if " path " denotes an existing symbolic link . see <nl> * { @ link path # issymboliclink } for specification . <nl> mmm a / src / main / java / com / google / devtools / build / lib / vfs / path . java <nl> ppp b / src / main / java / com / google / devtools / build / lib / vfs / path . java <nl>
public class windowsfilesystem extends javaiofilesystem { <nl> } <nl> return super . isdirectory ( path , followsymlinks ) ; <nl> } <nl> + <nl> + <nl> + private static boolean isjunction ( java . nio . file . path p ) throws ioexception { <nl> + / / jury - rigged <nl> + return p . compareto ( p . torealpath ( ) ) ! = num ; <nl> + } <nl> }
public class aargeneratoraction { <nl> help = " path to write the archive . " ) <nl> public path aaroutput ; <nl>  <nl> + <nl> @ option ( name = " strictmerge " , <nl> defaultvalue = " true " , <nl> category = " option " , <nl>
def xcrun_action ( ctx , * * kw ) : <nl> this method takes the same keyword arguments as ctx . action , however you don ' t <nl> need to specify the executable . <nl> " " " <nl> - platform = ctx . fragments . apple . ios_cpu_platform ( ) <nl> + if hasattr ( ctx . fragments . apple , " single_arch_platform " ) : <nl> + platform = ctx . fragments . apple . single_arch_platform <nl> + else : <nl> + # <nl> + # by default . <nl> + platform = ctx . fragments . apple . ios_cpu_platform ( ) <nl> + <nl> action_env = ctx . fragments . apple . target_apple_env ( platform ) \ <nl> + ctx . fragments . apple . apple_host_system_env ( ) <nl> - env = kw . get ( ' env ' , { } ) <nl> + env = kw . get ( " env " , { } ) <nl> kw [ ' env ' ] = env + action_env <nl>  <nl> apple_action ( ctx , executable = ctx . executable . _xcrunwrapper , * * kw ) <nl> mmm a / tools / build_defs / apple / swift . bzl <nl> ppp b / tools / build_defs / apple / swift . bzl <nl>
def _intersperse ( separator , iterable ) : <nl>  <nl> return result <nl>  <nl> - def _swift_target ( cpu , sdk_version ) : <nl> + def _swift_target ( cpu , platform , sdk_version ) : <nl> " " " returns a target triplet for swift compiler . " " " <nl> - return " % s - apple - ios % s " % ( cpu , sdk_version ) <nl> + # <nl> + platform_string = none <nl> + if str ( platform ) . startswith ( " ios_ " ) : <nl> + platform_string = " ios " <nl> + elif str ( platform ) . startswith ( " watchos_ " ) : <nl> + platform_string = " watchos " <nl> + else : <nl> + fail ( " platform % s is not supported " ) <nl> + <nl> + return " % s - apple - % s % s " % ( cpu , platform_string , sdk_version ) <nl>  <nl> def _swift_compilation_mode_flags ( ctx ) : <nl> " " " returns additional swiftc flags for the current compilation mode . " " " <nl>
test_directory_expansion_in_subdir ( ) { <nl> ' build streamer2 / stuff / ' <nl> } <nl>  <nl> - test_target_expansion ( ) { <nl> + # <nl> + disabled_test_target_expansion ( ) { <nl> # ' test expansion of target names within packages ' <nl>  <nl> make_packages <nl> mmm a / src / test / shell / bazel / bazel_rules_test . sh <nl> ppp b / src / test / shell / bazel / bazel_rules_test . sh <nl>
eof <nl> expect_log " hello , world ! " <nl> } <nl>  <nl> - <nl> - function test_genrule_default_env ( ) { <nl> + # <nl> + function disabled_test_genrule_default_env ( ) { <nl> mkdir - p pkg <nl> cat < < ' eof ' > pkg / build <nl> genrule (
public final class releasebundlingsupport { <nl> if ( processingneeded ) { <nl> spawnaction . builder processaction = <nl> objcruleclasses . spawnbashondarwinactionbuilder ( actioncommandline ) <nl> + <nl> + . setenvironment ( objcruleclasses . appletoolchainenvironment ( appleconfiguration , <nl> + appleconfiguration . getmultiarchplatform ( platformtype . ios ) ) ) <nl> . setmnemonic ( " objcprocessipa " ) <nl> . setprogressmessage ( " processing ios ipa : " + rulecontext . getlabel ( ) ) <nl> . addtransitiveinputs ( inputs . build ( ) )
public class binaryoperatorexpression extends queryexpression { <nl> } <nl> return ; <nl> } <nl> - / / we cannot do differences with partial results . so we fully evaluate the operands <nl> - set < t > lhsvalue = queryutil . evalall ( env , context , operands . get ( 0 ) ) ; <nl> - for ( int i = num ; i < operands . size ( ) ; i + + ) { <nl> - set < t > rhsvalue = queryutil . evalall ( env , context , operands . get ( i ) ) ; <nl> - switch ( operator ) { <nl> - case intersect : <nl> - case caret : <nl> - lhsvalue . retainall ( rhsvalue ) ; <nl> - break ; <nl> - case except : <nl> - case minus : <nl> - lhsvalue . removeall ( rhsvalue ) ; <nl> - break ; <nl> - case union : <nl> - case plus : <nl> - default : <nl> - throw new illegalstateexception ( " operator = " + operator ) ; <nl> + <nl> + / / once we have fully evaluated the left - hand side , we can stream - process the right - hand side <nl> + / / for minus operations . note that this is suboptimal if the left - hand side results are very <nl> + / / large compared to the right - hand side . which is the case is hard to know before evaluating . <nl> + / / we could consider determining this dynamically , however , by evaluating both the left and <nl> + / / right hand side partially until one side finishes sooner . <nl> + final set < t > lhsvalue = queryutil . evalall ( env , context , operands . get ( 0 ) ) ; <nl> + if ( operator = = tokenkind . except | | operator = = tokenkind . minus ) { <nl> + for ( int i = num ; i < operands . size ( ) ; i + + ) { <nl> + env . eval ( operands . get ( i ) , context , <nl> + new callback < t > ( ) { <nl> + @ override <nl> + public void process ( iterable < t > partialresult ) <nl> + throws queryexception , interruptedexception { <nl> + for ( t target : partialresult ) { <nl> + lhsvalue . remove ( target ) ; <nl> + } <nl> + } <nl> + } ) ; <nl> } <nl> + callback . process ( lhsvalue ) ; <nl> + return ; <nl> + } <nl> + <nl> + / / intersection is not associative , so we are forced to pin both the left - hand and right - hand <nl> + / / side of the operation at the same time . <nl> + <nl> + preconditions . checkstate ( operator = = tokenkind . intersect | | operator = = tokenkind . caret , <nl> + operator ) ; <nl> + for ( int i = num ; i < operands . size ( ) ; i + + ) { <nl> + lhsvalue . retainall ( queryutil . evalall ( env , context , operands . get ( i ) ) ) ; <nl> } <nl> callback . process ( lhsvalue ) ; <nl> }
public abstract class dependencyresolver { <nl> return ; / / skip this round : this is either a loading error or unevaluated skyframe dep . <nl> } <nl> buildconfiguration . transitionapplier transitionapplier = config . gettransitionapplier ( ) ; <nl> + boolean applynulltransition = false ; <nl> if ( buildconfiguration . usesnullconfiguration ( totarget ) ) { <nl> transitionapplier . applytransition ( attribute . configurationtransition . null ) ; <nl> + applynulltransition = true ; <nl> } <nl> - dependency dep = iterables . getonlyelement ( transitionapplier . getdependencies ( deplabel , <nl> - requiredaspects ( aspect , attribute , totarget , rule ) ) ) ; <nl> + <nl> + immutableset < aspectdescriptor > aspects = requiredaspects ( aspect , attribute , totarget , rule ) ; <nl> + dependency dep ; <nl> + if ( config . usedynamicconfigurations ( ) & & ! applynulltransition ) { <nl> + / / since we feed a pre - prepared configuration directly to the dep , it won ' t get trimmed to <nl> + / / the dep ' s fragments . <nl> + <nl> + dep = dependency . withconfigurationandaspects ( deplabel , config , aspects ) ; <nl> + } else { <nl> + dep = iterables . getonlyelement ( transitionapplier . getdependencies ( deplabel , aspects ) ) ; <nl> + } <nl> + <nl> outgoingedges . put ( attribute , dep ) ; <nl> } <nl> } <nl> mmm a / src / main / java / com / google / devtools / build / lib / skyframe / configuredtargetfunction . java <nl> ppp b / src / main / java / com / google / devtools / build / lib / skyframe / configuredtargetfunction . java <nl>
final class configuredtargetfunction implements skyfunction { <nl> } <nl> set < class < ? extends buildconfiguration . fragment > > depfragments = <nl> transitivedepinfo . gettransitiveconfigfragments ( ) . toset ( ) ; <nl> + <nl> + checkformissingfragments ( env , ctgvalue , attributeandlabel . attribute . getname ( ) , dep , <nl> + depfragments ) ; <nl>  <nl> boolean samefragments = depfragments . equals ( ctgfragments ) ; <nl> attribute . transition transition = dep . gettransition ( ) ; <nl>
<nl> + # ! / bin / bash <nl> + # copyright num the bazel authors . all rights reserved . <nl> + # <nl> + # licensed under the apache license , version num . 0 ( the " license " ) ; <nl> + # you may not use this file except in compliance with the license . <nl> + # you may obtain a copy of the license at <nl> + # <nl> + # http : / / www . apache . org / licenses / license - 2 . 0 <nl> + # <nl> + # unless required by applicable law or agreed to in writing , software <nl> + # distributed under the license is distributed on an " as is " basis , <nl> + # without warranties or conditions of any kind , either express or implied . <nl> + # see the license for the specific language governing permissions and <nl> + # limitations under the license . <nl> + <nl> + # <nl> + exit num
public class androidconfiguration extends buildconfiguration . fragment { <nl> help = " enables resource shrinking for android_binary apks that use proguard . " ) <nl> public boolean useandroidresourceshrinking ; <nl>  <nl> + <nl> @ option ( name = " experimental_use_proguard_previous_obfuscation_map " , <nl> defaultvalue = " false " , <nl> category = " undocumented " , <nl> - help = " enables the use of an obfuscation map when generating the main dex jar file " ) <nl> + help = " does nothing ( obsolete ) . " ) <nl> public boolean useproguardpreviousobfuscationmap ; <nl>  <nl> @ option ( name = " android_manifest_merger " , <nl>
public final class compilationsupport { <nl> } <nl> } ; <nl>  <nl> - / * * <nl> - * predicate to remove ' . inc ' files from an iterable . <nl> - * / <nl> - private static final predicate < artifact > non_inc_files = <nl> + / * * predicate that matches all artifacts that can be used in a clang module map . * / <nl> + private static final predicate < artifact > module_map_header = <nl> new predicate < artifact > ( ) { <nl> @ override <nl> public boolean apply ( artifact artifact ) { <nl> - return ! artifact . getfilename ( ) . endswith ( " . inc " ) ; <nl> + / / the current clang ( clang - 600 . 0 . 57 ) on darwin doesn ' t support ' textual ' , so we can ' t <nl> + / / have ' . inc ' files in the module map ( since they ' re implictly textual ) . <nl> + <nl> + return artifact . getfilename ( ) . endswith ( " . h " ) ; <nl> } <nl> } ; <nl>  <nl> - / * * <nl> - * selects cc libraries that have alwayslink = 1 . <nl> - * / <nl> + / * * selects cc libraries that have alwayslink = 1 . * / <nl> private static final predicate < artifact > always_linked_cc_library = <nl> new predicate < artifact > ( ) { <nl> @ override <nl>
class optionsusage { <nl> usage . append ( " < br / > \n " ) ; <nl> stringbuilder expandsmsg = new stringbuilder ( " expands to : " ) ; <nl> for ( string exp : annotation . expansion ( ) ) { <nl> - expandsmsg . append ( " " ) . append ( exp ) ; <nl> + <nl> + expandsmsg . append ( " < code > " ) . append ( exp ) . append ( " < / code > " ) ; <nl> } <nl> usage . append ( paragraphfill ( escaper . escape ( expandsmsg . tostring ( ) ) , num , num ) ) ; / / ( indent , width ) <nl> usage . append ( ' \n ' ) ;
public class skyqueryenvironment extends abstractblazequeryenvironment < target > { <nl> / / errors here . <nl> eventhandler . reseterrors ( ) ; <nl> init ( ) ; <nl> - return super . evaluatequery ( expr , callback ) ; <nl> + <nl> + / / skyqueryenvironment batches callback invocations using a batchstreamedcallback , created here <nl> + / / so that there ' s one per top - level evaluatequery call . the batch size is large enough that <nl> + / / per - call costs of calling the original callback are amortized over a good number of targets , <nl> + / / and small enough that holding a batch of targets in memory doesn ' t risk an oom error . <nl> + / / <nl> + / / this flushes the batched callback prior to constructing the queryevalresult in the unlikely <nl> + / / case of a race between the original callback and the eventhandler . <nl> + final batchstreamedcallback aggregator = <nl> + new batchstreamedcallback ( callback , batch_callback_size , createuniquifier ( ) ) ; <nl> + <nl> + final atomicboolean empty = new atomicboolean ( true ) ; <nl> + try ( final autoprofiler p = autoprofiler . logged ( " evaluating query " , log ) ) { <nl> + <nl> + / / in the - - nokeep_going case , errors are reported in the order in which the patterns are <nl> + / / specified ; using a linked hash set here makes sure that the left - most error is reported . <nl> + set < string > targetpatternset = new linkedhashset < > ( ) ; <nl> + expr . collecttargetpatterns ( targetpatternset ) ; <nl> + <nl> + <nl> + try { <nl> + preloadorthrow ( expr , targetpatternset ) ; <nl> + } catch ( targetparsingexception e ) { <nl> + / / unfortunately , by evaluating the patterns in parallel , we lose some location information . <nl> + throw new queryexception ( expr , e . getmessage ( ) ) ; <nl> + } <nl> + <nl> + try { <nl> + expr . eval ( <nl> + this , <nl> + new callback < target > ( ) { <nl> + @ override <nl> + public void process ( iterable < target > partialresult ) <nl> + throws queryexception , interruptedexception { <nl> + empty . compareandset ( true , iterables . isempty ( partialresult ) ) ; <nl> + aggregator . process ( partialresult ) ; <nl> + } <nl> + } ) ; <nl> + } catch ( queryexception e ) { <nl> + throw new queryexception ( e , expr ) ; <nl> + } <nl> + <nl> + aggregator . processlastpending ( ) ; <nl> + } <nl> + <nl> + if ( eventhandler . haserrors ( ) ) { <nl> + if ( ! keepgoing ) { <nl> + / / this case represents loading - phase errors reported during evaluation <nl> + / / of target patterns that don ' t cause evaluation to fail per se . <nl> + throw new queryexception ( " evaluation of query \ " " + expr <nl> + + " \ " failed due to build file errors " ) ; <nl> + } else { <nl> + eventhandler . handle ( event . warn ( " - - keep_going specified , ignoring errors . " <nl> + + " results may be inaccurate " ) ) ; <nl> + } <nl> + } <nl> + <nl> + return new queryevalresult ( ! eventhandler . haserrors ( ) , empty . get ( ) ) ; <nl> } <nl>  <nl> private map < target , collection < target > > maketargetsmap ( map < skykey , iterable < skykey > > input ) { <nl>
public final class parallelevaluator implements evaluator { <nl> / / always the last dep ) . <nl> state . addtemporarydirectdepsgrouptodirtyentry ( directdepstocheck ) ; <nl>  <nl> + <nl> for ( map . entry < skykey , nodeentry > e <nl> : graph . createifabsentbatch ( directdepstocheck ) . entryset ( ) ) { <nl> skykey directdep = e . getkey ( ) ; <nl>
public class buildviewtest extends buildviewtestbase { <nl> assertcontainsevent ( " and referenced by ' / / foo : bad ' " ) ; <nl> assertcontainsevent ( " in sh_library rule / / foo " ) ; <nl> assertcontainsevent ( " cycle in dependency graph " ) ; <nl> - asserteventcount ( 3 , eventcollector ) ; <nl> + / / dynamic configurations trigger this error both in configuration trimming ( which visits <nl> + / / the transitive target closure ) and in the normal configured target cycle detection path . <nl> + / / so we get an additional instance of this check ( which varies depending on whether skyframe <nl> + / / loading phase is enabled ) . <nl> + <nl> + if ( ! gettargetconfiguration ( ) . usedynamicconfigurations ( ) ) { <nl> + asserteventcount ( 3 , eventcollector ) ; <nl> + } <nl> } <nl>  <nl> @ test
toolchain { <nl>  <nl> supports_interface_shared_objects : true <nl> } <nl> + <nl> + toolchain { <nl> + abi_version : " local " <nl> + abi_libc_version : " local " <nl> + builtin_sysroot : " " <nl> + compiler : " windows_msys64 " <nl> + host_system_name : " local " <nl> + needspic : false <nl> + target_libc : " local " <nl> + target_cpu : " x64_windows " <nl> + target_system_name : " local " <nl> + toolchain_identifier : " local_windows_msys64 " <nl> + <nl> + tool_path { name : " ar " path : " c : / tools / msys64 / usr / bin / ar " } <nl> + tool_path { name : " compat - ld " path : " c : / tools / msys64 / usr / bin / ld " } <nl> + tool_path { name : " cpp " path : " c : / tools / msys64 / usr / bin / cpp " } <nl> + tool_path { name : " dwp " path : " c : / tools / msys64 / usr / bin / dwp " } <nl> + # use gcc instead of g + + so that c will compile correctly . <nl> + tool_path { name : " gcc " path : " c : / tools / msys64 / usr / bin / gcc " } <nl> + cxx_flag : " - std = gnu + + 0x " <nl> + linker_flag : " - lstdc + + " <nl> + # <nl> + # used by gcc . that works because bazel currently doesn ' t track files at <nl> + # absolute locations and has no remote execution , yet . however , this will need <nl> + # to be fixed , maybe with auto - detection ? <nl> + cxx_builtin_include_directory : " c : / tools / msys64 / " <nl> + cxx_builtin_include_directory : " / usr / " <nl> + tool_path { name : " gcov " path : " c : / tools / msys64 / usr / bin / gcov " } <nl> + tool_path { name : " ld " path : " c : / tools / msys64 / usr / bin / ld " } <nl> + tool_path { name : " nm " path : " c : / tools / msys64 / usr / bin / nm " } <nl> + tool_path { name : " objcopy " path : " c : / tools / msys64 / usr / bin / objcopy " } <nl> + objcopy_embed_flag : " - i " <nl> + objcopy_embed_flag : " binary " <nl> + tool_path { name : " objdump " path : " c : / tools / msys64 / usr / bin / objdump " } <nl> + tool_path { name : " strip " path : " c : / tools / msys64 / usr / bin / strip " } <nl> + linking_mode_flags { mode : dynamic } <nl> + } <nl> + <nl> mmm a / src / test / java / com / google / devtools / build / lib / packages / util / bazelmockccsupport . java <nl> ppp b / src / test / java / com / google / devtools / build / lib / packages / util / bazelmockccsupport . java <nl>
public class aggregatingattributemapper extends abstractattributemapper { <nl> / / have no impact on the dependency structure . <nl>  <nl> if ( selectors . isempty ( ) ) { <nl> - valuesbuilder . add ( preconditions . checknotnull ( currentvaluesofar ) ) ; <nl> + if ( currentvaluesofar ! = null ) { <nl> + / / null values arise when a none is used as the value of a selector for a type without a <nl> + / / default value . <nl> + <nl> + valuesbuilder . add ( currentvaluesofar ) ; <nl> + } <nl> } else { <nl> selector < t > firstselector = selectors . get ( 0 ) ; <nl> list < selector < t > > remainingselectors = selectors . sublist ( 1 , selectors . size ( ) ) ;
eof <nl> / / ios : swift_lib > $ test_log num > & 1 | | fail " should build " <nl> } <nl>  <nl> + function test_swift_tests ( ) { <nl> + make_app <nl> + <nl> + cat > ios / tests . swift < < eof <nl> + import xctest <nl> + <nl> + class footest : xctestcase { <nl> + func testfoo ( ) { xctassertequal ( 2 , num ) } <nl> + } <nl> + eof <nl> + <nl> + cat > ios / build < < eof <nl> + load ( " / / tools / build_defs / apple : swift . bzl " , " swift_library " ) <nl> + <nl> + swift_library ( name = " swiftmain " , <nl> + srcs = [ " app . swift " ] ) <nl> + <nl> + objc_binary ( name = " bin " , <nl> + # <nl> + # uses_swift flag on objcprovider and should not be necessary . <nl> + srcs = [ ' dummy . swift ' ] , <nl> + deps = [ " : swiftmain " ] ) <nl> + <nl> + ios_application ( name = " app " , <nl> + binary = ' : bin ' , <nl> + infoplist = ' app - info . plist ' ) <nl> + <nl> + swift_library ( name = " swifttest " , <nl> + srcs = [ " tests . swift " ] ) <nl> + <nl> + ios_test ( name = " app_test " , <nl> + srcs = [ ' dummy . swift ' ] , <nl> + deps = [ " : swifttest " ] , <nl> + xctest_app = " app " ) <nl> + eof <nl> + <nl> + bazel build - - verbose_failures - - ios_sdk_version = $ ios_sdk_version \ <nl> + / / ios : app_test > $ test_log num > & 1 | | fail " should build " <nl> + <nl> + otool - lv bazel - bin / ios / app_test_bin \ <nl> + | grep @ executable_path / frameworks - sq \ <nl> + | | fail " expected test binary to contain @ executable_path in lc_rpath " <nl> + <nl> + otool - lv bazel - bin / ios / app_test_bin \ <nl> + | grep @ loader_path / frameworks - sq \ <nl> + | | fail " expected test binary to contain @ executable_path in lc_rpath " <nl> + <nl> + } <nl> + <nl> run_suite " apple_tests "
for opt in " $ { @ } " ; do <nl> prefix = " $ ( echo " $ opt " | cut - d ' = ' - f num - ) " <nl> ; ; <nl> - - bazelrc = * ) <nl> - bazelrc = " $ ( echo " $ opt " | cut - d ' = ' - f num - ) " <nl> + # <nl> + # this comment . <nl> ; ; <nl> - - bin = * ) <nl> bin = " $ ( echo " $ opt " | cut - d ' = ' - f num - ) " <nl>
<nl>  <nl> # installation and etc prefix can be overriden from command line <nl> install_prefix = $ { 1 : - " / usr / local " } <nl> + # <nl> + bazelrc = $ { 2 : - " / etc / bazel . bazelrc " } <nl>  <nl> progname = " $ 0 " <nl>  <nl>
public final class repositorydelegatorfunction implements skyfunction { <nl> return new fingerprint ( ) <nl> . addbytes ( ruleserializer . serializerule ( rule ) . build ( ) . tobytearray ( ) ) <nl> . addbytes ( rulespecificdata ) <nl> + / / this is to make the fingerprint different after adding names to the generated <nl> + / / workspace files so they will get re - created , because otherwise there are <nl> + / / annoying warnings for all of them . <nl> + <nl> + . addint ( 1 ) <nl> . digestandreset ( ) ; <nl> }
function test_build_app ( ) { <nl> ls bazel - bin / ios / app . ipa | | fail " should generate app . ipa " <nl> } <nl>  <nl> + function test_objc_depends_on_swift ( ) { <nl> + rm - rf ios <nl> + mkdir - p ios <nl> + <nl> + touch ios / dummy . swift <nl> + <nl> + cat > ios / main . swift < < eof <nl> + import foundation <nl> + <nl> + @ objc public class foo : nsobject { <nl> + public func bar ( ) - > int { return num ; } <nl> + } <nl> + eof <nl> + <nl> + cat > ios / app . m < < eof <nl> + # import < uikit / uikit . h > <nl> + # import " ios / swiftmain - swift . h " <nl> + <nl> + int main ( int argc , char * argv [ ] ) { <nl> + @ autoreleasepool { <nl> + nslog ( @ " % d " , [ [ [ foo alloc ] init ] bar ] ) ; <nl> + return uiapplicationmain ( argc , argv , nil , nil ) ; <nl> + } <nl> + } <nl> + eof <nl> + <nl> + cat > ios / build < < eof <nl> + load ( " / / tools / build_defs / apple : swift . bzl " , " swift_library " ) <nl> + <nl> + swift_library ( name = " swiftmain " , <nl> + srcs = [ " main . swift " ] ) <nl> + <nl> + objc_binary ( name = " bin " , <nl> + # <nl> + # uses_swift flag on objcprovider and should not be necessary . <nl> + srcs = [ ' app . m ' , ' dummy . swift ' ] , <nl> + deps = [ " : swiftmain " ] ) <nl> + eof <nl> + <nl> + bazel build - - verbose_failures - - ios_sdk_version = $ ios_sdk_version \ <nl> + / / ios : bin > $ test_log num > & 1 | | fail " should build " <nl> + } <nl> + <nl> run_suite " apple_tests " <nl> mmm a / tools / build_defs / apple / swift . bzl <nl> ppp b / tools / build_defs / apple / swift . bzl <nl>
fi <nl> function set_up ( ) { <nl> copy_examples <nl> setup_objc_test_support <nl> - } <nl>  <nl> - function test_swift_library ( ) { <nl> + # allow access to / / external : xcrunwrapper . <nl> rm workspace <nl> ln - sv $ { workspace_file } workspace <nl> + } <nl> + <nl> + function make_app ( ) { <nl> + rm - rf ios <nl> + mkdir - p ios <nl> + <nl> + touch ios / dummy . swift <nl> + <nl> + cat > ios / app . swift < < eof <nl> + import uikit <nl> + <nl> + @ uiapplicationmain <nl> + class appdelegate : uiresponder , uiapplicationdelegate { <nl> + var window : uiwindow ? <nl> + func application ( application : uiapplication , didfinishlaunchingwithoptions launchoptions : [ nsobject : anyobject ] ? ) - > bool { <nl> + nslog ( " hello , world " ) <nl> + return true <nl> + } <nl> + } <nl> + eof <nl> + <nl> + cat > ios / app - info . plist < < eof <nl> + < plist version = " 1 . 0 " > <nl> + < dict > <nl> + < key > cfbundleexecutable < / key > <nl> + < string > app < / string > <nl> + < key > cfbundlename < / key > <nl> + < string > app < / string > <nl> + < key > cfbundledisplayname < / key > <nl> + < string > app < / string > <nl> + < key > cfbundlepackagetype < / key > <nl> + < string > appl < / string > <nl> + < key > cfbundleidentifier < / key > <nl> + < string > com . google . app < / string > <nl> + < key > cfbundlesignature < / key > <nl> + < string > ? ? ? ? < / string > <nl> + < key > cfbundleversion < / key > <nl> + < string > 1 . 0 < / string > <nl> + < key > lsrequiresiphoneos < / key > <nl> + < true / > <nl> + < / dict > <nl> + < / plist > <nl> + eof <nl>  <nl> + cat > ios / build < < eof <nl> + load ( " / / tools / build_defs / apple : swift . bzl " , " swift_library " ) <nl> + <nl> + swift_library ( name = " swiftmain " , <nl> + srcs = [ " app . swift " ] ) <nl> + <nl> + objc_binary ( name = " bin " , <nl> + # <nl> + # uses_swift flag on objcprovider and should not be necessary . <nl> + srcs = [ ' dummy . swift ' ] , <nl> + deps = [ " : swiftmain " ] ) <nl> + <nl> + ios_application ( name = " app " , <nl> + binary = ' : bin ' , <nl> + infoplist = ' app - info . plist ' ) <nl> + eof <nl> + } <nl> + <nl> + function test_swift_library ( ) { <nl> local swift_lib_pkg = examples / swift <nl> assert_build_output . / bazel - bin / $ { swift_lib_pkg } / swift_lib . a \ <nl> $ { swift_lib_pkg } : swift_lib - - ios_sdk_version = $ ios_sdk_version <nl>
mkdir - p " $ { tmpdir } " # mkdir does work with a path starting with ' c : / ' , wow <nl> # containing spaces seem to be passed properly . <nl> echo " bootstrapping bazel " <nl> . / compile . sh " $ * " | | exit $ ? <nl> + <nl> + # run the only windows - specific test we have . <nl> + # <nl> + echo " running tests " <nl> + retcode = 0 <nl> + . / output / bazel test - - test_output = all / / src / test / shell / bazel : bazel_windows_cpp_test | | retcode = $ ? <nl> + # exit for failure except for test failures ( exit code num ) . <nl> + if ( ( $ retcode ! = num & & $ retcode ! = num ) ) ; then <nl> + exit $ retcode <nl> + fi
public class javabinary implements ruleconfiguredtargetfactory { <nl>  <nl> rulecontext . checksrcssamepackage ( true ) ; <nl> boolean createexecutable = rulecontext . attributes ( ) . get ( " create_executable " , type . boolean ) ; <nl> + <nl> + if ( ! createexecutable ) { <nl> + <nl> + label launcherattribute = rulecontext . attributes ( ) . get ( " launcher " , buildtype . label ) ; <nl> + if ( launcherattribute ! = null <nl> + & & ! launcherattribute . equals ( semantics . getjdklauncherlabel ( ) ) ) { <nl> + rulecontext . ruleerror ( " launcher specified but create_executable is false " ) ; <nl> + } <nl> + } <nl> + <nl> list < transitiveinfocollection > deps = <nl> / / do not remove < transitiveinfocollection > : workaround for java num type inference . <nl> lists . < transitiveinfocollection > newarraylist ( <nl> mmm a / src / main / java / com / google / devtools / build / lib / rules / java / javahelper . java <nl> ppp b / src / main / java / com / google / devtools / build / lib / rules / java / javahelper . java <nl>
public final class objcprovider extends skylarkclassobject implements transitive <nl> return ! get ( xcassets_dir ) . isempty ( ) ; <nl> } <nl>  <nl> + @ skylarkcallable ( <nl> + name = " include " , <nl> + structfield = true , <nl> + doc = " returns a set of include search paths . " <nl> + ) <nl> + public skylarknestedset getincludedirs ( ) { <nl> + <nl> + nestedsetbuilder < string > includes = nestedsetbuilder . stableorder ( ) ; <nl> + for ( pathfragment path : get ( include ) ) { <nl> + includes . add ( path . getsafepathstring ( ) ) ; <nl> + } <nl> + return skylarknestedset . of ( string . class , includes . build ( ) ) ; <nl> + } <nl> + <nl> / * * <nl> * a builder for this context with an api that is optimized for collecting information from <nl> * several transitive dependencies .
def _swift_library_impl ( ctx ) : <nl> progress_message = ( " compiling swift module % s ( % d files ) " <nl> % ( ctx . label . name , len ( ctx . files . srcs ) ) ) ) <nl>  <nl> + struct_kw = { } <nl> + if hasattr ( apple_common , ' new_objc_provider ' ) : <nl> + struct_kw [ ' objc ' ] = apple_common . new_objc_provider ( <nl> + library = set ( [ output_lib ] + dep_libs ) ) <nl> + <nl> + else : <nl> + # <nl> + struct_kw [ ' objc_export ' ] = struct ( library = set ( [ output_lib ] + dep_libs ) ) <nl> + <nl> return struct ( <nl> swift = struct ( <nl> library = output_lib , <nl> module = output_module , <nl> transitive_libs = dep_libs , <nl> - transitive_modules = dep_modules ) , <nl> - objc_export = struct ( <nl> - library = set ( [ output_lib ] + dep_libs ) , <nl> - ) <nl> - ) <nl> + transitive_modules = dep_modules ) , * * struct_kw ) <nl>  <nl> swift_library = rule ( <nl> _swift_library_impl ,
def create_android_sdk_rules ( name , build_tools_version , api_level ) : <nl> " # ! / bin / bash - eu " , <nl> # the tools under build - tools / version require the libraries under build - tools / version / lib , <nl> # so we can ' t simply depend on them as a file like we do with aapt . <nl> - " sdk = $ $ { 0 } . runfiles / external / % s " % name , <nl> + # <nl> + " sdk = $ $ { 0 } . runfiles / % s / external / % s " % ( workspace_name , name ) , <nl> " exec $ $ { sdk } / build - tools / % s / % s $ $ * " % ( build_tools_version , tool ) , <nl> " eof\n " ] ) , <nl> ) for tool in [ " aapt " , " aidl " , " zipalign " ] ]
static int startserver ( ) { <nl> } <nl>  <nl> daemonize ( ) ; <nl> + <nl> + <nl> + if ( ! writefile ( tostring ( getpid ( ) ) , server_dir + " / server . pid " ) ) { <nl> + / / the exit code does not matter because we are already in the daemonized <nl> + / / server . the output of this operation will end up in jvm . out . <nl> + pdie ( 0 , " cannot write pid file " ) ; <nl> + } <nl> + <nl> executeprogram ( exe , jvm_args_vector ) ; <nl> pdie ( blaze_exit_code : : internal_error , " execv of ' % s ' failed " , exe . c_str ( ) ) ; <nl> return - 1 ; <nl> mmm a / src / main / java / com / google / devtools / build / lib / server / rpcserver . java <nl> ppp b / src / main / java / com / google / devtools / build / lib / server / rpcserver . java <nl>
static void writefiletostreamordie ( file * stream , const char * file_name ) { <nl> static int getserverpid ( const string & pid_file ) { <nl> / / note : there is no race here on startup since the server creates <nl> / / the pid file strictly before it binds the socket . <nl> - char buf [ 16 ] ; <nl> - auto len = readlink ( pid_file . c_str ( ) , buf , sizeof ( buf ) - num ) ; <nl> - if ( len > num ) { <nl> - buf [ len ] = ' \ 0 ' ; <nl> - return atoi ( buf ) ; <nl> - } else { <nl> + <nl> + char buf [ 33 ] ; <nl> + <nl> + / / the server writes a file , but we need to handle old servers that still <nl> + / / write a symlink . <nl> + <nl> + int len ; <nl> + len = readlink ( pid_file . c_str ( ) , buf , sizeof ( buf ) - num ) ; <nl> + if ( len < num ) { <nl> + int fd = open ( pid_file . c_str ( ) , o_rdonly ) ; <nl> + if ( fd < num ) { <nl> + return - 1 ; <nl> + } <nl> + len = read ( fd , buf , num ) ; <nl> + close ( fd ) ; <nl> + if ( len < num ) { <nl> + return - 1 ; <nl> + } <nl> + } <nl> + <nl> + int result ; <nl> + buf [ len ] = num ; <nl> + if ( ! blaze_util : : safe_strto32 ( string ( buf ) , & result ) ) { <nl> return - 1 ; <nl> - pdie ( blaze_exit_code : : local_environmental_error , <nl> - " can ' t get server pid from connection " ) ; <nl> } <nl> + <nl> + return result ; <nl> } <nl>  <nl> / / connects to the blaze server , returning the socket , or - 1 if no <nl> mmm a / src / main / java / com / google / devtools / build / lib / server / rpcserver . java <nl> ppp b / src / main / java / com / google / devtools / build / lib / server / rpcserver . java <nl>
mkdir - p " $ { tmpdir } " # mkdir does work with a path starting with ' c : / ' , wow <nl>  <nl> # even though there are no quotes around $ * in the . bat file , arguments <nl> # containing spaces seem to be passed properly . <nl> - exec . / compile . sh " $ * " <nl> + . / compile . sh " $ * " | | exit $ ? <nl> + <nl> + # run the only windows - specific test we have . <nl> + # <nl> + exec . / output / bazel - - batch test / / src / test / shell / bazel : bazel_windows_cpp_test
public final class androidruleclasses { <nl> " cc_library " , <nl> " java_import " , <nl> " java_library " , <nl> - " proto_library " } ; <nl> + " proto_library " <nl> + } ; <nl>  <nl> public static final safeimplicitoutputsfunction android_binary_implicit_outputs = <nl> new safeimplicitoutputsfunction ( ) { <nl> mmm a / src / main / java / com / google / devtools / build / lib / rules / java / javasemantics . java <nl> ppp b / src / main / java / com / google / devtools / build / lib / rules / java / javasemantics . java <nl>
public final class converters { <nl> @ override <nl> public fullrevision convert ( string input ) throws optionsparsingexception { <nl> try { <nl> + <nl> + / / upgrading to the lastest version will take time . since we don ' t <nl> + / / currently need to distinguish between preview and non - preview build <nl> + / / tools , for now just remove the suffix . <nl> + input = input . replace ( " - preview " , " " ) ; <nl> return fullrevision . parserevision ( input ) ; <nl> } catch ( numberformatexception e ) { <nl> throw new optionsparsingexception ( e . getmessage ( ) ) ;
gensrcjar = rule ( <nl> outputs = { " srcjar " : " lib % { name } . srcjar " } , <nl> ) <nl>  <nl> - def cc_grpc_library ( name , src ) : <nl> - basename = src [ : - len ( " . proto " ) ] <nl> - <nl> - native . genrule ( <nl> - name = name + " _codegen " , <nl> - srcs = [ src ] , <nl> - tools = [ " / / third_party / protobuf : protoc " , " / / third_party / grpc : cpp_plugin " ] , <nl> - cmd = " \ \ \n " . join ( [ <nl> - " $ ( location / / third_party / protobuf : protoc ) " , <nl> - " - - plugin = protoc - gen - grpc = $ ( location / / third_party / grpc : cpp_plugin ) " , <nl> - " - - cpp_out = $ ( gendir ) " , <nl> - " - - grpc_out = $ ( gendir ) " , <nl> - " $ ( location " + src + " ) " ] ) , <nl> - outs = [ basename + " . grpc . pb . h " , basename + " . grpc . pb . cc " , basename + " . pb . cc " , basename + " . pb . h " ] ) <nl> - <nl> - native . cc_library ( <nl> - name = name , <nl> - srcs = [ basename + " . grpc . pb . cc " , basename + " . pb . cc " ] , <nl> - hdrs = [ basename + " . grpc . pb . h " , basename + " . pb . h " ] , <nl> - deps = [ " / / third_party / grpc : grpc + + " ] , <nl> - includes = [ " . " ] ) <nl> - <nl> - def java_proto_library ( name , src , use_grpc_plugin = false ) : <nl> - grpc_java_plugin = none <nl> - if use_grpc_plugin : <nl> - grpc_java_plugin = " / / third_party / grpc : grpc - java - plugin " <nl> - <nl> - gensrcjar ( name = name + " _srcjar " , src = src , grpc_java_plugin = grpc_java_plugin ) <nl> - deps = [ " / / third_party / protobuf " ] <nl> - if use_grpc_plugin : <nl> - deps + = [ " / / third_party / grpc : grpc - jar " , " / / third_party : guava " ] <nl> + # <nl> + def java_proto_library ( name , src ) : <nl> + gensrcjar ( name = name + " _srcjar " , src = src ) <nl> native . java_library ( <nl> name = name , <nl> srcs = [ name + " _srcjar " ] , <nl> - deps = deps , <nl> + deps = [ " @ bazel_tools / / third_party / protobuf " ] , <nl> # the generated code has lots of ' rawtypes ' warnings . <nl> javacopts = [ " - xlint : - rawtypes " ] , <nl> ) <nl> mmm a / tools / build_rules / gensrcjar . sh <nl> ppp b / tools / build_rules / gensrcjar . sh <nl>
public class javaoptions extends fragmentoptions { <nl> host . javacextdir = javacextdir ; <nl> host . headercompilation = headercompilation ; <nl> host . javabuildertop = javabuildertop ; <nl> + <nl> host . javatoolchain = javatoolchain ; <nl> host . singlejartop = singlejartop ; <nl> host . genclasstop = genclasstop ;
public class javacturbine implements autocloseable { <nl> static void filterjavacopts ( <nl> immutablelist . builder < string > javacargs , iterable < string > defaultjavacopts ) { <nl> for ( string opt : defaultjavacopts ) { <nl> + <nl> + <nl> + opt = charmatcher . is ( ' \ ' ' ) . trimfrom ( opt ) ; <nl> + <nl> if ( iserrorproneflag ( opt ) ) { <nl> / / drop error prone ' s fake javacopts <nl> continue ;
public class cppoptions extends fragmentoptions { <nl> ) <nl> public boolean skipstaticoutputs ; <nl>  <nl> + / / add all sources of transitively found modules . although they are also embedded in the . pcm <nl> + / / files , clang currently verifies that all files specified in a cppmap do exist . <nl> + <nl> + @ option ( <nl> + name = " send_transitive_header_module_srcs " , <nl> + defaultvalue = " true " , <nl> + category = " semantics " , <nl> + help = <nl> + " this flag is only used for a transition and will go away . " <nl> + + " if true , treat all headers mentioned in transitive . cppmap files as mandatory " <nl> + + " inputs . " <nl> + ) <nl> + public boolean sendtransitiveheadermodulesrcs ; <nl> + <nl> @ option ( <nl> name = " process_headers_in_dependencies " , <nl> defaultvalue = " false " ,
public final class cccommon { <nl> rulecontext . attributeerror ( " includes " , <nl> " path references a path above the execution root . " ) ; <nl> } <nl> + if ( ! includespath . startswith ( packagefragment ) ) { <nl> + rulecontext . attributewarning ( <nl> + " includes " , <nl> + " ' " <nl> + + includesattr <nl> + + " ' resolves to ' " <nl> + + includespath <nl> + + " ' not below the relative path of its package ' " <nl> + + packagefragment <nl> + + " ' . this will be an error in the future " ) ; <nl> + <nl> + } <nl> result . add ( includespath ) ; <nl> result . add ( rulecontext . getconfiguration ( ) . getgenfilesfragment ( ) . getrelative ( includespath ) ) ; <nl> } <nl> mmm a / src / test / java / com / google / devtools / build / lib / rules / cpp / cccommonconfiguredtargettest . java <nl> ppp b / src / test / java / com / google / devtools / build / lib / rules / cpp / cccommonconfiguredtargettest . java <nl>
public class abstractqueuevisitortest { <nl> counter . awaitquiescence ( / * interruptworkers = * / false ) ; <nl> assertsame ( 10 , counter . getcount ( ) ) ; <nl> assertsame ( 0 , counter . activeparalleltasks ( ) ) ; <nl> - assertsame ( 1 , counter . getmaxrunningconcurrently ( ) ) ; <nl> + <nl> } <nl>  <nl> @ test
public class skylarkexecutionresult { <nl> this . stderr = stderr ; <nl> } <nl>  <nl> + private skylarkexecutionresult ( commandresult result ) { <nl> + <nl> + / / exception when reaching a specific size . <nl> + this . stdout = new string ( result . getstdout ( ) , standardcharsets . utf_8 ) ; <nl> + this . stderr = new string ( result . getstderr ( ) , standardcharsets . utf_8 ) ; <nl> + this . returncode = result . getterminationstatus ( ) . getexitcode ( ) ; <nl> + } <nl> + <nl> @ skylarkcallable ( <nl> name = " return_code " , <nl> structfield = true , <nl>
public final class skylarkrulecontext { <nl> if ( provider ! = null & & provider . getexecutable ( ) ! = null ) { <nl> artifact executable = provider . getexecutable ( ) ; <nl> executablebuilder . put ( skyname , executable ) ; <nl> - executablerunfilesbuilder . put ( executable , provider ) ; <nl> + if ( ! seenexecutables . contains ( executable ) ) { <nl> + <nl> + / / the executable ( this provider is later used to build the spawn ) . <nl> + / / however ideally we should associate a provider with the attribute name , <nl> + / / and pass the correct filestorunprovider to the spawn depending on <nl> + / / what attribute is used to access the executable . <nl> + executablerunfilesbuilder . put ( executable , provider ) ; <nl> + seenexecutables . add ( executable ) ; <nl> + } <nl> } else { <nl> executablebuilder . put ( skyname , runtime . none ) ; <nl> } <nl> mmm a / src / test / java / com / google / devtools / build / lib / skylark / skylarkaspectstest . java <nl> ppp b / src / test / java / com / google / devtools / build / lib / skylark / skylarkaspectstest . java <nl>
def _impl ( ctx ) : <nl> print ( ctx . os . environ [ " foo " ] ) <nl> # symlink so a repository is created <nl> ctx . symlink ( ctx . path ( " $ repo2 " ) , ctx . path ( " " ) ) <nl> - repo = repository_rule ( implementation = _impl , local = true ) <nl> + repo = repository_rule ( implementation = _impl , local = false ) <nl> eof <nl>  <nl> - bazel shutdown <nl> + # <nl> + bazel clean - - expunge <nl> foo = bar bazel build @ foo / / : bar > & $ test_log | | fail " failed to build " <nl> expect_log " bar " <nl>  <nl> - foo = bar bazel clean > & $ test_log <nl> + foo = bar bazel clean - - expunge > & $ test_log <nl> foo = bar bazel info > & $ test_log <nl>  <nl> foo = baz bazel build @ foo / / : bar > & $ test_log | | fail " failed to build " <nl> expect_log " baz " <nl> + <nl> + # test that we don ' t re - run on server restart . <nl> + foo = bez bazel build @ foo / / : bar > & $ test_log | | fail " failed to build " <nl> + expect_not_log " bez " <nl> + bazel shutdown > & $ test_log <nl> + foo = bez bazel build @ foo / / : bar > & $ test_log | | fail " failed to build " <nl> + expect_not_log " bez " <nl> + <nl> + # test modifying test . bzl invalidate the repository <nl> + cat > test . bzl < < eof <nl> + def _impl ( ctx ) : <nl> + print ( ctx . os . environ [ " bar " ] ) <nl> + # symlink so a repository is created <nl> + ctx . symlink ( ctx . path ( " $ repo2 " ) , ctx . path ( " " ) ) <nl> + repo = repository_rule ( implementation = _impl , local = true ) <nl> + eof <nl> + bar = bez bazel build @ foo / / : bar > & $ test_log | | fail " failed to build " <nl> + expect_log " bez " <nl> + <nl> + # shutdown and modify again <nl> + bazel shutdown <nl> + cat > test . bzl < < eof <nl> + def _impl ( ctx ) : <nl> + print ( ctx . os . environ [ " baz " ] ) <nl> + # symlink so a repository is created <nl> + ctx . symlink ( ctx . path ( " $ repo2 " ) , ctx . path ( " " ) ) <nl> + repo = repository_rule ( implementation = _impl , local = true ) <nl> + eof <nl> + baz = boz bazel build @ foo / / : bar > & $ test_log | | fail " failed to build " <nl> + expect_log " boz " <nl> } <nl>  <nl> function tear_down ( ) {
static void ensurecorrectrunningversion ( ) { <nl> / / installation is running . <nl> string installation_path = globals - > options . output_base + " / install " ; <nl> char prev_installation [ path_max + num ] = " " ; / / nuls the whole array <nl> + <nl> if ( readlink ( installation_path . c_str ( ) , <nl> prev_installation , path_max ) = = - 1 | | <nl> prev_installation ! = globals - > options . install_base ) { <nl>
public class basejavacompilationhelper { <nl> . addinput ( inputjar ) <nl> . addoutput ( interfacejar ) <nl> . setexecutable ( ijartarget ) <nl> + / / on windows , ijar . exe needs msys - 2 . 0 . dll and zlib1 . dll in path . <nl> + / / use default shell environment so that those can be found . <nl> + <nl> + . usedefaultshellenvironment ( ) <nl> . addargument ( inputjar . getexecpathstring ( ) ) <nl> . addargument ( interfacejar . getexecpathstring ( ) ) <nl> . setprogressmessage ( " extracting interface " + rulecontext . getlabel ( ) )
cc_binary ( <nl> ] , <nl> ) <nl>  <nl> - # hack for mac : copy libunix . so to libunix . dylib . we ' ll need to come up with a <nl> - # way to support platform - specific dynamic library extensions . <nl> + # <nl> + # library extensions . this is issue # 914 . <nl> genrule ( <nl> name = " mac - compat " , <nl> srcs = [ " libunix . so " ] ,
public class cppcompileaction extends abstractaction implements includescannable <nl> for ( artifact artifact : getinputs ( ) ) { <nl> result . addall ( includeresolver . getinputsforincludedfile ( artifact , artifactresolver ) ) ; <nl> } <nl> + <nl> + resolvedinputs = immutablelist . copyof ( result ) ; <nl> if ( result . isempty ( ) ) { <nl> result = initialresult ; <nl> } else { <nl>
public class cppcompileaction extends abstractaction implements includescannable <nl> addfilteredoptions ( options , <nl> featureconfiguration . getcommandline ( getactionname ( ) , variables ) ) ; <nl>  <nl> + <nl> + / / split out file . until then , keep this before the user - provided copts so it can be <nl> + / / overwritten . <nl> + if ( cppconfiguration . usefission ( ) ) { <nl> + options . add ( " - gsplit - dwarf " ) ; <nl> + } <nl> + <nl> / / users don ' t expect the explicit copts to be filtered by coptsfilter , add them verbatim . <nl> / / make sure these are added after the options from the feature configuration , so that <nl> / / those options can be overriden . <nl>
void executeprogram ( const string & exe , const vector < string > & args_vector ) { <nl> startupinfo startupinfo = { 0 } ; <nl> process_information pi = { 0 } ; <nl>  <nl> + / / propagate bazel_sh environment variable to a sub - process . <nl> + <nl> + setenvironmentvariable ( " bazel_sh " , getenv ( " bazel_sh " ) ) ; <nl> + <nl> bool success = createprocess ( <nl> nullptr , / / _in_opt_ lpctstr lpapplicationname , <nl> actual_line , / / _inout_opt_ lptstr lpcommandline ,
java_library ( <nl> srcs = glob ( [ <nl> " unix / * . java " , <nl> ] ) + [ " unixjniloader . java " ] , <nl> - resources = [ " / / src / main / native : libunix . so " ] , <nl> + resources = select ( { <nl> + # <nl> + " / / src : windows " : [ ] , <nl> + " / / conditions : default " : [ " / / src / main / native : libunix . so " ] , <nl> + } ) , <nl> deps = [ <nl> " : common " , <nl> " : shell " ,
public final class packagefactory { <nl> * returns null if we don ' t want to export the value . <nl> * <nl> * < p > all of the types returned are immutable . if we want , we can change this to <nl> - * immutable in the future , but this is the safe choice for now . o <nl> + * immutable in the future , but this is the safe choice for now . <nl> * / <nl> @ nullable <nl> private static object skylarkifyvalue ( object val , package pkg ) throws notrepresentableexception { <nl> + <nl> if ( val = = null ) { <nl> return null ; <nl> } <nl>
public abstract class buildviewtestcase extends foundationtestcase { <nl> ruleclassprovider . getconfigurationoptions ( ) ) ) ; <nl> try { <nl> list < string > configurationargs = new arraylist < > ( ) ; <nl> + <nl> + configurationargs . add ( " - - stamp " ) ; / / stamp is now defaulted to false . <nl> configurationargs . add ( " - - experimental_extended_sanity_checks " ) ; <nl> configurationargs . addall ( getanalysismock ( ) . getoptionoverrides ( ) ) ;
public class skylarkruleclassfunctions { <nl> } <nl> } ; <nl>  <nl> + @ skylarksignature ( name = " output_group " , <nl> + documented = false , <nl> + objecttype = transitiveinfocollection . class , <nl> + returntype = skylarknestedset . class , <nl> + mandatorypositionals = { <nl> + @ param ( name = " self " , type = transitiveinfocollection . class , doc = <nl> + " this target " <nl> + ) , <nl> + @ param ( name = " group_name " , type = string . class , doc = <nl> + " output group name " <nl> + ) <nl> + } <nl> + ) <nl> + public static final builtinfunction output_group = new builtinfunction ( " output_group " ) { <nl> + public skylarknestedset invoke ( transitiveinfocollection self , string group ) { <nl> + outputgroupprovider provider = self . getprovider ( outputgroupprovider . class ) ; <nl> + nestedset < artifact > result = provider ! = null <nl> + ? provider . getoutputgroup ( group ) <nl> + : nestedsetbuilder . < artifact > emptyset ( order . stable_order ) ; <nl> + return skylarknestedset . of ( artifact . class , result ) ; <nl> + } <nl> + } ; <nl> + <nl> static { <nl> skylarksignatureprocessor . configureskylarkfunctions ( skylarkruleclassfunctions . class ) ; <nl> }
<nl> + / / copyright num the bazel authors . all rights reserved . <nl> + / / <nl> + / / licensed under the apache license , version num . 0 ( the " license " ) ; <nl> + / / you may not use this file except in compliance with the license . <nl> + / / you may obtain a copy of the license at <nl> + / / <nl> + / / http : / / www . apache . org / licenses / license - 2 . 0 <nl> + / / <nl> + / / unless required by applicable law or agreed to in writing , software <nl> + / / distributed under the license is distributed on an " as is " basis , <nl> + / / without warranties or conditions of any kind , either express or implied . <nl> + / / see the license for the specific language governing permissions and <nl> + / / limitations under the license . <nl> + package com . google . devtools . build . lib . util ; <nl> + <nl> + / * * utilities for dealing with { @ link runnable } s that may call into uncontrolled code . * / <nl> + public class runnables { <nl> + private runnables ( ) { } <nl> + <nl> + / * * <nl> + * a { @ link runnable } that terminates the jvm instead of throwing an unchecked exception in <nl> + * { @ link runnable # run } . <nl> + * <nl> + * < p > this is useful if the { @ link runnable } may be executed by code outside of our control , e . g . <nl> + * if we call into library code that silently swallows { @ link runtimeexception } s from our code . <nl> + * / <nl> + <nl> + public abstract static class abstractcrashterminatingrunnable implements runnable { <nl> + protected abstract void runimpl ( ) ; <nl> + <nl> + @ override <nl> + public final void run ( ) { <nl> + try { <nl> + runimpl ( ) ; <nl> + } catch ( throwable t ) { <nl> + runtimeutils . halt ( t ) ; <nl> + } <nl> + } <nl> + } <nl> + } <nl> mmm / dev / null <nl> ppp b / src / main / java / com / google / devtools / build / lib / util / runtimeutils . java <nl>
public class nosuchtargetexception extends nosuchthingexception { <nl> private final boolean hastarget ; <nl>  <nl> public nosuchtargetexception ( string message ) { <nl> - this ( null , message ) ; <nl> + this ( <nl> + message , <nl> + / * label = * / null , <nl> + / * hastarget = * / false ) ; <nl> } <nl>  <nl> - public nosuchtargetexception ( @ nullable label label , string message ) { <nl> - this ( ( label ! = null ? " no such target ' " + label + " ' : " : " " ) + message , label , null , null ) ; <nl> + public nosuchtargetexception ( label label , string message ) { <nl> + this ( <nl> + " no such target ' " + label + " ' : " + message , <nl> + label , <nl> + / * hastarget = * / false ) ; <nl> } <nl>  <nl> - public nosuchtargetexception ( target targetinerror , packageidentifier packageinerror ) { <nl> - this ( string . format ( " target ' % s ' contains an error and its package is in error " , <nl> - targetinerror . getlabel ( ) ) , targetinerror . getlabel ( ) , targetinerror , packageinerror ) ; <nl> + public nosuchtargetexception ( target targetinerror ) { <nl> + this ( <nl> + " target ' " + targetinerror . getlabel ( ) + " ' contains an error and its package is in error " , <nl> + targetinerror . getlabel ( ) , <nl> + / * hastarget = * / true ) ; <nl> } <nl>  <nl> - private nosuchtargetexception ( string message , @ nullable label label , @ nullable target target , <nl> - @ nullable packageidentifier packageinerror ) { <nl> + public nosuchtargetexception ( string message , @ nullable label label , boolean hastarget ) { <nl> + <nl> super ( message , <nl> - packageinerror = = null ? null : new buildfilecontainserrorsexception ( packageinerror ) ) ; <nl> + hastarget ? new buildfilecontainserrorsexception ( label . getpackageidentifier ( ) ) : null ) ; <nl> this . label = label ; <nl> - this . hastarget = ( target ! = null ) ; <nl> + this . hastarget = hastarget ; <nl> } <nl>  <nl> @ nullable <nl>
public final class skyframebuildview { <nl> if ( config = = null | | ! config . usedynamicconfigurations ( ) ) { <nl> return toplevelhostconfiguration ; <nl> } <nl> + <nl> + / / the latter may be a proper subset of the former . <nl> + / / <nl> + / / configurationfactory . getconfiguration provides the reason why : if a declared required <nl> + / / fragment is evaluated and returns null , it never gets added to the configuration . so if we <nl> + / / use the configuration ' s fragments as the source of truth , that excludes required fragments <nl> + / / that never made it in . <nl> + / / <nl> + / / if we ' re just trimming an existing configuration , this is no big deal ( if the original <nl> + / / configuration doesn ' t need the fragment , the trimmed one doesn ' t either ) . but this method <nl> + / / trims a host configuration to the same scope as a target configuration . since their options <nl> + / / are different , the host instance may actually be able to produce the fragment . so it ' s <nl> + / / wrong and potentially dangerous to unilaterally exclude it . <nl> set < class < ? extends buildconfiguration . fragment > > fragmentclasses = config . fragmentclasses ( ) ; <nl> buildconfiguration hostconfig = hostconfigurationcache . get ( fragmentclasses ) ; <nl> if ( hostconfig ! = null ) {
public final class commandenvironment { <nl> buildoptions , runtime . getdirectories ( ) , immutableset . < string > of ( ) , keepgoing ) ; <nl> } <nl>  <nl> + <nl> + private boolean loadforconfigurations ( eventhandler eventhandler , <nl> + set < label > labelstoload , boolean keepgoing ) throws interruptedexception { <nl> + / / use a new label visitor here to avoid erasing the cache on the existing one . <nl> + transitivepackageloader transitivepackageloader = <nl> + runtime . getskyframeexecutor ( ) . getpackagemanager ( ) . newtransitiveloader ( ) ; <nl> + boolean loadingsuccessful = transitivepackageloader . sync ( <nl> + eventhandler , immutableset . < target > of ( ) , <nl> + labelstoload , keepgoing , / * parallelthreads = * / 10 , <nl> + / * maxdepth = * / integer . max_value ) ; <nl> + return loadingsuccessful ; <nl> + } <nl> + <nl> / * * <nl> * hook method called by the blazecommanddispatcher right before the dispatch <nl> * of each command ends ( while its outcome can still be modified ) .
toolchain { <nl> linker_flag : " - lstdc + + " <nl> linker_flag : " - undefined " <nl> linker_flag : " dynamic_lookup " <nl> - cxx_builtin_include_directory : " / usr / include " <nl> - cxx_builtin_include_directory : " / applications / xcode . app / contents / developer / toolchains / xcodedefault . xctoolchain " <nl> - cxx_builtin_include_directory : " / applications / xcode . app / contents / developer / platforms / macosx . platform / developer / sdks " <nl> - cxx_builtin_include_directory : " / opt / local / include " <nl> - cxx_builtin_include_directory : " / usr / local / include " <nl> - cxx_builtin_include_directory : " / library / developer / commandlinetools " <nl> - cxx_builtin_include_directory : " / system / library / frameworks " <nl> - cxx_builtin_include_directory : " / library / frameworks " <nl> + # <nl> + # setting from the local compiler , and also how to make incremental builds correct . <nl> + cxx_builtin_include_directory : " / " <nl> tool_path { name : " gcov " path : " / usr / bin / gcov " } <nl> tool_path { name : " ld " path : " / usr / bin / ld " } <nl> tool_path { name : " nm " path : " / usr / bin / nm " }
<nl> # script for building bazel from scratch without bazel <nl>  <nl> proto_files = $ ( ls src / main / protobuf / * . proto ) <nl> + # <nl> library_jars = $ ( find third_party - name ' * . jar ' | tr " \n " " " ) <nl> dirs = $ ( echo src / { java_tools / singlejar / java / com / google / devtools / build / zip , main / java , tools / xcode - common / java / com / google / devtools / build / xcode / { common , util } } $ { output_dir } / src ) <nl>  <nl>
public class plistmerging extends value < plistmerging > { <nl> } <nl> } <nl>  <nl> + / / info . plist files must contain a valid cfbundleversion and a valid cfbundleshortversionstring , <nl> + / / or it will be rejected by apple . <nl> + / / a valid bundle version is num characters or less , and only contains [ 0 - 9 . ] <nl> + <nl> + pattern versionpattern = pattern . compile ( " [ ^ 0 - 9 . ] " ) ; <nl> + if ( ! merged . containskey ( bundle_version_plist_key ) ) { <nl> + merged . put ( bundle_version_plist_key , bundle_version_default ) ; <nl> + } else { <nl> + nsobject nsversion = merged . get ( bundle_version_plist_key ) ; <nl> + string version = ( string ) nsversion . tojavaobject ( ) ; <nl> + if ( version . length ( ) > num | | versionpattern . matcher ( version ) . find ( ) ) { <nl> + merged . put ( bundle_version_plist_key , bundle_version_default ) ; <nl> + } <nl> + } <nl> + if ( ! merged . containskey ( bundle_short_version_string_plist_key ) ) { <nl> + merged . put ( bundle_short_version_string_plist_key , bundle_short_version_string_default ) ; <nl> + } else { <nl> + nsobject nsversion = merged . get ( bundle_short_version_string_plist_key ) ; <nl> + string version = ( string ) nsversion . tojavaobject ( ) ; <nl> + if ( version . length ( ) > num | | versionpattern . matcher ( version ) . find ( ) ) { <nl> + merged . put ( bundle_short_version_string_plist_key , bundle_short_version_string_default ) ; <nl> + } <nl> + } <nl> + <nl> return new plistmerging ( merged ) ; <nl> } <nl>  <nl>
public class plistmerging extends value < plistmerging > { <nl> * / <nl> public plistmerging setbundleidentifier ( string primaryidentifier , string fallbackidentifier ) { <nl> nsstring bundleidentifier = ( nsstring ) merged . get ( bundle_identifier_plist_key ) ; <nl> - <nl> + <nl> if ( primaryidentifier ! = null ) { <nl> merged . put ( bundle_identifier_plist_key , primaryidentifier ) ; <nl> - } else if ( bundleidentifier = = null & & fallbackidentifier ! = null ) { <nl> - merged . put ( bundle_identifier_plist_key , fallbackidentifier ) ; <nl> + } else if ( bundleidentifier = = null ) { <nl> + if ( fallbackidentifier ! = null ) { <nl> + merged . put ( bundle_identifier_plist_key , fallbackidentifier ) ; <nl> + } else { <nl> + <nl> + merged . put ( bundle_identifier_plist_key , bundle_identifier_default ) ; <nl> + } <nl> } <nl>  <nl> return this ;
static void sendserverrequest ( void ) { <nl> int socket = - 1 ; <nl> while ( true ) { <nl> socket = connecttoserver ( true ) ; <nl> - <nl> / / check for deleted server cwd : <nl> string server_cwd = getprocesscwd ( globals - > server_pid ) ; <nl> - if ( server_cwd . empty ( ) | | / / getprocesscwd failed <nl> - server_cwd ! = globals - > workspace | | / / changed <nl> - server_cwd . find ( " ( deleted ) " ) ! = string : : npos ) { / / deleted . <nl> + <nl> + / / anymore . iow , the client finds the server based on the output base , <nl> + / / so if a server is found , it should be by definition at the correct output <nl> + / / base . <nl> + / / <nl> + / / if server_cwd is empty , getprocesscwd failed . this notably occurs when <nl> + / / running under docker because then readlink ( / proc / [ pid ] / cwd ) returns <nl> + / / eperm . <nl> + / / docker issue # 6687 ( https : / / github . com / docker / docker / issues / 6687 ) fixed <nl> + / / this , but one still needs the - - cap - add sys_ptrace command line flag , at <nl> + / / least according to the discussion on docker issue # 6800 <nl> + / / ( https : / / github . com / docker / docker / issues / 6687 ) , and even then , it ' s a <nl> + / / non - default docker flag . given that this occurs only in very weird <nl> + / / cases , it ' s better to assume that everything is alright if we can ' t get <nl> + / / the cwd . <nl> + <nl> + if ( ! server_cwd . empty ( ) & & <nl> + ( server_cwd ! = globals - > workspace | | / / changed <nl> + server_cwd . find ( " ( deleted ) " ) ! = string : : npos ) ) { / / deleted . <nl> / / there ' s a distant possibility that the two paths look the same yet are <nl> / / actually different because the two processes have different mount <nl> / / tables .
public class bazelconfigurationcollection implements configurationcollectionfact <nl> / / not necessarily the configuration actually applied to the rule . we should correlate the <nl> / / two . however , doing so requires faithfully reflecting the configuration transitions that <nl> / / might happen as we traverse the dependency chain . <nl> + <nl> for ( list < label > labelsforconfiguration : <nl> aggregatingattributemapper . of ( rule ) . visitattribute ( " srcs " , buildtype . label_list ) ) { <nl> for ( label label : labelsforconfiguration ) { <nl> - collecttransitiveclosure ( packageprovider , reachablelabels , label ) ; <nl> + collecttransitiveclosure ( packageprovider , reachablelabels , <nl> + from . resolverepositoryrelative ( label ) ) ; <nl> } <nl> } <nl> } <nl> mmm a / src / main / java / com / google / devtools / build / lib / cmdline / label . java <nl> ppp b / src / main / java / com / google / devtools / build / lib / cmdline / label . java <nl>
public class buildview { <nl> collection < target > targets = loadingresult . gettargets ( ) ; <nl> eventbus . post ( new analysisphasestartedevent ( targets ) ) ; <nl>  <nl> - skyframecachewasinvalidated = false ; <nl> - / / clear all cached configuredtargets on configuration change . we need to do this explicitly <nl> - / / because we need to make sure that the legacy action graph does not contain multiple actions <nl> - / / with different versions of the same ( target / host / etc . ) configuration . <nl> - / / in the future the action graph will be probably be keyed by configurations , which should <nl> - / / obviate the need for this workaround . <nl> + / / clear all cached configuredtargets on configuration change . <nl> + <nl> / / <nl> / / also if - - discard_analysis_cache was used in the last build we want to clear the legacy <nl> / / data . <nl> if ( ( this . configurations ! = null & & ! configurations . equals ( this . configurations ) ) <nl> | | skyframeanalysiswasdiscarded ) { <nl> log . info ( " discarding analysis cache : configurations have changed . " ) ; <nl> - <nl> skyframeexecutor . dropconfiguredtargets ( ) ; <nl> - skyframecachewasinvalidated = true ; <nl> } <nl> skyframeanalysiswasdiscarded = false ; <nl> this . configurations = configurations ;
public class xcodeprojgeneration { <nl> projbuildconfigmap . put ( " gcc_version " , " com . apple . compilers . llvm . clang . 1_0 " ) ; <nl> projbuildconfigmap . put ( " code_sign_identity [ sdk = iphoneos * ] " , " iphone developer " ) ; <nl>  <nl> + / / disable bitcode for now . <nl> + <nl> + projbuildconfigmap . put ( " enable_bitcode " , " no " ) ; <nl> + <nl> for ( xcodeprojbuildsetting projectsetting : control . getbuildsettinglist ( ) ) { <nl> projbuildconfigmap . put ( projectsetting . getname ( ) , projectsetting . getvalue ( ) ) ; <nl> } <nl>
tests = ( ) # a subset or " working set " of test <nl> # default , all tests called test_ * are <nl> # run . <nl> if [ $ # - gt num ] ; then <nl> - tests = ( $ ( for i in $ @ ; do echo $ i ; done | grep ^ test_ ) ) <nl> + # legacy behavior is to ignore missing regexp , but with errexit <nl> + # the following line fails without | | true . <nl> + # <nl> + # test with that framework ( use bazel ' s environment variable instead ) . <nl> + tests = ( $ ( for i in $ @ ; do echo $ i ; done | grep ^ test_ | | true ) ) <nl> + if ( ( $ { # tests [ @ ] } = = num ) ) ; then <nl> + echo " warning : arguments do not specifies tests ! " > & 2 <nl> + fi <nl> fi <nl>  <nl> test_verbose = true # whether or not to be verbose . a
test_f ( blazeutiltest , makedirectories ) { <nl> } <nl>  <nl> test_f ( blazeutiltest , hammermakedirectories ) { <nl> - string path = blaze_util : : joinpath ( flags_test_tmpdir , " x / y / z " ) ; <nl> - assert_le ( 0 , fork ( ) ) ; <nl> - assert_eq ( 0 , makedirectories ( path , num ) ) ; <nl> + const char * tmp_dir = getenv ( " test_tmpdir " ) ; <nl> + assert_strne ( tmp_dir , null ) ; <nl> + <nl> + string path = blaze_util : : joinpath ( tmp_dir , " x / y / z " ) ; <nl> + <nl> + / / assert_eq ( 0 , makedirectories ( path , num ) ) ; <nl> } <nl>  <nl> } / / namespace blaze
public abstract class basefunction { <nl> } <nl> / / if there ' s a kwparam , it ' s empty . <nl> if ( haskwparam ) { <nl> + <nl> arguments [ kwparamindex ] = immutablemap . < string , object > of ( ) ; <nl> } <nl> } else if ( haskwparam & & numnamedparams = = num ) { <nl>
public abstract class basefunction { <nl> / / note that * starparam and * * kwparam themselves don ' t count as named . <nl> / / also note that no named parameters means no mandatory parameters that weren ' t passed , <nl> / / and no missing optional parameters for which to use a default . thus , no loops . <nl> + <nl> arguments [ kwparamindex ] = kwargs ; / / nb : not num a means kwarg isn ' t null <nl> } else { <nl> / / hard general case ( 2c ) : some keyword arguments may correspond to named parameters <nl>
public abstract class basefunction { <nl> } <nl> } <nl> if ( haskwparam ) { <nl> + <nl> arguments [ kwparamindex ] = immutablemap . copyof ( kwarg ) ; <nl> }
public class androidconfiguration extends buildconfiguration . fragment { <nl> help = " enables sanity checks for jack and jill compilation . " ) <nl> public boolean jacksanitychecks ; <nl>  <nl> + <nl> + @ option ( <nl> + name = " treat_srcjars_as_srcs_for_strict_deps " , <nl> + defaultvalue = " false " , <nl> + category = " semantics " , <nl> + help = " causes deps of android_library rules with . srcjars ( but no java srcs ) " <nl> + + " to be promoted to exports . " <nl> + ) <nl> + public boolean treatsrcjarsassrcsforstrictdeps ; <nl> + <nl> @ override <nl> public void addalllabels ( multimap < string , label > labelmap ) { <nl> if ( proguard ! = null ) { <nl>
public final class jvmconfigurationloader implements configurationfragmentfactor <nl> public jvm create ( configurationenvironment env , buildoptions buildoptions ) <nl> throws invalidconfigurationexception { <nl> javaoptions javaoptions = buildoptions . get ( javaoptions . class ) ; <nl> + if ( javaoptions . disablejvm ) { <nl> + <nl> + return null ; <nl> + } <nl> string javahome = javaoptions . javabase ; <nl> string cpu = cpusupplier . getjavacpu ( buildoptions , env ) ; <nl> if ( cpu = = null ) {
public class packagedeserializer { <nl> return attrpb . haslicense ( ) ? deserializelicense ( attrpb . getlicense ( ) ) : null ; <nl>  <nl> case string_dict : { <nl> + / / building an immutable map will fail if the builder was given duplicate keys . these entry <nl> + / / lists may contain duplicate keys if the serialized map value was configured ( e . g . via <nl> + / / the select function ) and the different configuration values had keys in common . this is <nl> + / / because serialization flattens configurable map - valued attributes . <nl> + / / <nl> + / / as long as serialization does this flattening , to avoid failure during deserialization , <nl> + / / we dedupe entries in the list by their keys . <nl> + <nl> immutablemap . builder < string , string > builder = immutablemap . builder ( ) ; <nl> + hashset < string > keysseensofar = sets . newhashset ( ) ; <nl> for ( build . stringdictentry entry : attrpb . getstringdictvaluelist ( ) ) { <nl> - builder . put ( entry . getkey ( ) , entry . getvalue ( ) ) ; <nl> + string key = entry . getkey ( ) ; <nl> + if ( keysseensofar . add ( key ) ) { <nl> + builder . put ( key , entry . getvalue ( ) ) ; <nl> + } <nl> } <nl> return builder . build ( ) ; <nl> } <nl>  <nl> case string_dict_unary : { <nl> + / / see string_dict case ' s comment about why this dedupes entries by their keys . <nl> immutablemap . builder < string , string > builder = immutablemap . builder ( ) ; <nl> + hashset < string > keysseensofar = sets . newhashset ( ) ; <nl> for ( stringdictunaryentry entry : attrpb . getstringdictunaryvaluelist ( ) ) { <nl> - builder . put ( entry . getkey ( ) , entry . getvalue ( ) ) ; <nl> + string key = entry . getkey ( ) ; <nl> + if ( keysseensofar . add ( key ) ) { <nl> + builder . put ( key , entry . getvalue ( ) ) ; <nl> + } <nl> } <nl> return builder . build ( ) ; <nl> } <nl>
public final class cpplinkaction extends abstractaction { <nl> return getcppconfiguration ( ) . gethostsystemname ( ) ; <nl> } <nl>  <nl> + public immutablemap < string , string > getenvironment ( ) { <nl> + if ( os . getcurrent ( ) = = os . windows ) { <nl> + <nl> + / / the other hand , windows documentation says that the directory of the executable <nl> + / / is always searched for dlls first . not sure what to make of it . <nl> + / / other options are to forward the system path ( brittle ) , or to add a path field to <nl> + / / the crosstool file . <nl> + / / <nl> + / / @ see com . google . devtools . build . lib . rules . cpp . cppcompileaction # getenvironment . <nl> + return immutablemap . of ( <nl> + " path " , <nl> + cppconfiguration . gettoolpathfragment ( cppconfiguration . tool . gcc ) . getparentdirectory ( ) <nl> + . getpathstring ( ) <nl> + ) ; <nl> + } <nl> + return immutablemap . of ( ) ; <nl> + } <nl> + <nl> / * * <nl> * returns the link configuration ; for correctness you should not call this method during <nl> * execution - only the argv is part of the action cache key , and we therefore don ' t guarantee <nl> mmm a / src / main / java / com / google / devtools / build / lib / rules / cpp / locallinkstrategy . java <nl> ppp b / src / main / java / com / google / devtools / build / lib / rules / cpp / locallinkstrategy . java <nl>
public class objccommandlineoptions extends fragmentoptions { <nl> + " built with - - cpu set to \ " ios_ < - - ios_cpu > \ " for any values in - - ios_multi_cpu . " ) <nl> public boolean enableccdeps ; <nl>  <nl> + <nl> + @ option ( name = " experimental_objc_fastbuild_options " , <nl> + defaultvalue = " - o0 " , <nl> + category = " undocumented " , <nl> + converter = commaseparatedoptionlistconverter . class , <nl> + help = " adds these strings to fastbuild compiler options . " ) <nl> + public list < string > fastbuildoptions ; <nl> + <nl> @ option ( name = " objc_enable_binary_stripping " , <nl> defaultvalue = " false " , <nl> category = " flags " , <nl> mmm a / src / main / java / com / google / devtools / build / lib / rules / objc / objcconfiguration . java <nl> ppp b / src / main / java / com / google / devtools / build / lib / rules / objc / objcconfiguration . java <nl>
public abstract class buildviewtestcase extends foundationtestcase { <nl> return view . getdirectprerequisites ( target ) ; <nl> } <nl>  <nl> + / * * <nl> + * asserts that a target ' s prerequisites contain the given dependency . <nl> + * / <nl> + <nl> + / / this means that getconfiguredtarget ( " / / go : two " ) returns a different configuration than <nl> + / / requesting " / / go : two " as a dependency . so the configured targets aren ' t considered " equal " . <nl> + / / once we apply dynamic configs to top - level targets this discrepancy will go away . <nl> + protected void assertdirectprerequisitescontain ( configuredtarget target , configuredtarget dep ) { <nl> + iterable < configuredtarget > prereqs = getdirectprerequisites ( target ) ; <nl> + buildconfiguration depconfig = dep . getconfiguration ( ) ; <nl> + for ( configuredtarget contained : prereqs ) { <nl> + if ( contained . getlabel ( ) . equals ( dep . getlabel ( ) ) ) { <nl> + buildconfiguration containedconfig = contained . getconfiguration ( ) ; <nl> + if ( containedconfig = = null & & depconfig = = null ) { <nl> + return ; <nl> + } else if ( containedconfig ! = null <nl> + & & depconfig ! = null <nl> + & & containedconfig . cloneoptions ( ) . equals ( depconfig . cloneoptions ( ) ) ) { <nl> + return ; <nl> + } <nl> + } <nl> + } <nl> + fail ( " cannot find " + target . tostring ( ) + " in " + prereqs . tostring ( ) ) ; <nl> + } <nl> + <nl> + / * * <nl> + * asserts that two configurations are the same . <nl> + * <nl> + * < p > historically this meant they contained the same object reference . but with upcoming dynamic <nl> + * configurations that may no longer be true ( for example , they may have the same values but not <nl> + * the same { @ link buildconfiguration . fragment } s . so this method abstracts the <nl> + * " configuration equivalency " checking into one place , where the implementation logic can evolve <nl> + * as needed . <nl> + * / <nl> + protected void assertconfigurationsequal ( buildconfiguration config1 , buildconfiguration config2 ) { <nl> + / / buildoptions and crosstool files determine a configuration ' s content . within the context <nl> + / / of these tests only the former actually change . <nl> + assertequals ( config1 . cloneoptions ( ) , config2 . cloneoptions ( ) ) ; <nl> + } <nl> + <nl> / * * <nl> * creates and returns a rule context that is equivalent to the one that was used to create the <nl> * given configured target .
public class blazecommandeventhandler implements eventhandler { <nl> } catch ( ioexception e ) { <nl> / / this can happen in server mode if the blaze client has exited , <nl> / / or if output is redirected to a file and the disk is full , etc . <nl> - / / ignore . <nl> + <nl> + bugreport . sendbugreport ( e , immutablelist . of ( " failed to write event " ) ) ; <nl> } <nl> }
public final class cccommon { <nl> } <nl>  <nl> public immutablelist < string > getcopts ( ) { <nl> - return copts ; <nl> + preconditions . checkstate ( hasattribute ( " copts " , type . string_list ) ) ; <nl> + <nl> + list < string > tokens = new arraylist < > ( ) ; <nl> + for ( string str : rulecontext . attributes ( ) . get ( " copts " , type . string_list ) ) { <nl> + tokens . clear ( ) ; <nl> + try { <nl> + shellutils . tokenize ( tokens , str ) ; <nl> + if ( tokens . size ( ) > num ) { <nl> + rulecontext . attributewarning ( " copts " , <nl> + " each item in the list should contain only one option " ) ; <nl> + } <nl> + } catch ( shellutils . tokenizationexception e ) { <nl> + / / ignore , the error is reported in the getattributecopts call <nl> + } <nl> + } <nl> + <nl> + pattern nocopts = getnocopts ( rulecontext ) ; <nl> + if ( nocopts ! = null & & nocopts . matcher ( " - wno - future - warnings " ) . matches ( ) ) { <nl> + rulecontext . attributewarning ( " nocopts " , <nl> + " regular expression ' " + nocopts . pattern ( ) + " ' is too general ; for example , it matches " <nl> + + " ' - wno - future - warnings ' . thus it might * re - enable * compiler warnings we wish to " <nl> + + " disable globally . to disable all compiler warnings , add ' - w ' to copts instead " ) ; <nl> + } <nl> + <nl> + return immutablelist . < string > builder ( ) <nl> + . addall ( getpackagecopts ( rulecontext ) ) <nl> + . addall ( cpphelper . getattributecopts ( rulecontext , " copts " ) ) <nl> + . build ( ) ; <nl> } <nl>  <nl> private boolean hasattribute ( string name , type < ? > type ) { <nl>
public final class packageidentifier implements comparable < packageidentifier > , s <nl> return name . isempty ( ) ; <nl> } <nl>  <nl> + / * * <nl> + * returns the repository name , with leading " { @ literal @ } " ( or " " for the default repository ) . <nl> + * / <nl> + <nl> + public string getname ( ) { <nl> + return name ; <nl> + } <nl> + <nl> / * * <nl> * returns the repository name , with leading " { @ literal @ } " ( or " " for the default repository ) . <nl> * /
public final class querycommand implements blazecommand { <nl> result = env . evaluatequery ( expr ) ; <nl> } catch ( queryexception | interruptedexception e ) { <nl> / / keep consistent with reportbuildfileerror ( ) <nl> - runtime . getreporter ( ) . handle ( event . error ( e . getmessage ( ) ) ) ; <nl> + runtime <nl> + . getreporter ( ) <nl> + <nl> + . handle ( event . error ( e . getmessage ( ) = = null ? e . tostring ( ) : e . getmessage ( ) ) ) ; <nl> return exitcode . analysis_failure ; <nl> }
rm - f " $ { base_workspace } / examples " & & ln - s " $ ( pwd ) / examples " " $ { base_workspace } <nl> rm - rf " $ { base_workspace } / src " <nl> mkdir - p $ { base_workspace } / src / tools <nl> ln - s $ ( pwd ) / src / tools / android $ { base_workspace } / src / tools / android <nl> + # <nl> + # don ' t depend on src / main / java : options . <nl> + mkdir - p $ { base_workspace } / src / main <nl> + ln - s $ ( pwd ) / src / main / java $ { base_workspace } / src / main / java <nl>  <nl> # create a bazelrc file with the base_workspace directory in the package path . <nl> bazelrc = ' build - - package_path % workspace % : ' $ { base_workspace }
public final class bundlemerging { <nl> if ( zipinentry = = null ) { <nl> break ; <nl> } <nl> + <nl> + string name = entrynamesprefix + zipinentry . getname ( ) ; <nl> + if ( zipinentry . isdirectory ( ) ) { <nl> + / / if we already have a directory entry with this name then don ' t attempt to <nl> + / / add it again . it ' s not an error to attempt to merge in two zip files that contain <nl> + / / the same directories . it ' s only an error to attempt to merge in two zip files with the <nl> + / / same leaf files . <nl> + if ( ! combiner . containsfile ( name ) ) { <nl> + combiner . adddirectory ( name , dos_epoch ) ; <nl> + } <nl> + continue ; <nl> + } <nl> integer externalfileattr = externalfileattributes . get ( zipinentry . getname ( ) ) ; <nl> if ( externalfileattr = = null ) { <nl> externalfileattr = zipinputentry . default_external_file_attribute ; <nl> } <nl> - zipfileentry zipoutentry = new zipfileentry ( entrynamesprefix + zipinentry . getname ( ) ) ; <nl> + zipfileentry zipoutentry = new zipfileentry ( name ) ; <nl> zipoutentry . settime ( dos_epoch . gettime ( ) ) ; <nl> zipoutentry . setversion ( zipinputentry . made_by_version ) ; <nl> zipoutentry . setexternalattributes ( externalfileattr ) ; <nl> mmm a / src / tools / xcode - common / java / com / google / devtools / build / xcode / zip / zipinputentry . java <nl> ppp b / src / tools / xcode - common / java / com / google / devtools / build / xcode / zip / zipinputentry . java <nl>
public class skylarknativemodule { <nl> useast = true , useenvironment = true ) <nl> private static final builtinfunction glob = new builtinfunction ( " glob " ) { <nl> public globlist < string > invoke ( <nl> - skylarklist includes , skylarklist excludes , integer excludedirectories , <nl> - funcallexpression ast , environment env ) <nl> + skylarklist include , skylarklist exclude , skylarklist excludes , <nl> + integer excludedirectories , funcallexpression ast , environment env ) <nl> throws evalexception , conversionexception , interruptedexception { <nl> + <nl> + if ( exclude . size ( ) = = num ) { <nl> + exclude = excludes ; <nl> + } <nl> return packagefactory . callglob ( <nl> - null , false , includes , excludes , excludedirectories ! = num , ast , env ) ; <nl> + null , false , include , exclude , excludedirectories ! = num , ast , env ) ; <nl> } <nl> } ;
atexit " if [ - f $ { phasefile } ] ; then echo > & 2 ; cat $ { phasefile } > & 2 ; fi " <nl>  <nl> function run_silent ( ) { <nl> echo " $ { @ } " > $ { errfile } <nl> - " $ { @ } " > > $ { errfile } num > & 1 <nl> + # <nl> + # even though errexit is set . <nl> + " $ { @ } " > > $ { errfile } num > & 1 | | exit $ ? <nl> rm $ { errfile } <nl> }
public class standaloneteststrategy extends teststrategy { <nl> } <nl> } <nl>  <nl> - private map < string , string > getenv ( testrunneraction action , path runfilesdir , path tmpdir ) { <nl> + private map < string , string > getenv ( <nl> + testrunneraction action , <nl> + path runfilesdir , <nl> + path tmpdir , <nl> + testrunneraction . resolvedpaths resolvedpaths ) { <nl> map < string , string > vars = getdefaulttestenvironment ( action ) ; <nl> buildconfiguration config = action . getconfiguration ( ) ; <nl>  <nl> vars . putall ( config . getdefaultshellenvironment ( ) ) ; <nl> vars . putall ( action . gettestenv ( ) ) ; <nl> + <nl> + / * <nl> + * <nl> + * making test actions impossible to cache remotely . <nl> + * / <nl> vars . put ( " test_srcdir " , runfilesdir . getpathstring ( ) ) ; <nl> vars . put ( " test_tmpdir " , tmpdir . getpathstring ( ) ) ; <nl> + vars . put ( " xml_output_file " , resolvedpaths . getxmloutputpath ( ) . getpathstring ( ) ) ; <nl>  <nl> return vars ; <nl> }
public class zipfunction implements skyfunction { <nl> if ( isdirectory ) { <nl> filesystemutils . createdirectoryandparents ( outputpath ) ; <nl> } else { <nl> + <nl> + / / the zip file is not re - unzipped when the workspace file is changed ( because it is assumed <nl> + / / to be immutable ) but is on server restart ( which is a bug ) . <nl> + if ( outputpath . exists ( ) ) { <nl> + outputpath . delete ( ) ; <nl> + } <nl> file outputfile = outputpath . getpathfile ( ) ; <nl> files . copy ( reader . getinputstream ( entry ) , outputfile . topath ( ) ) ; <nl> outputpath . chmod ( permissions ) ;
if [ - z " $ { travis_os_name + x } " ] ; then <nl> fi <nl>  <nl> if [ [ $ travis_os_name = ' osx ' ] ] ; then <nl> - brew install protobuf <nl> + # <nl> else <nl> sudo apt - get update - qq <nl> - sudo apt - get install - y protobuf - compiler netcat - traditional <nl> + sudo apt - get install - y netcat - traditional <nl> sudo update - alternatives - - set nc / bin / nc . traditional <nl> export java_home = / usr / lib / jvm / java - 8 - oracle <nl> export java_opts = " - xmx3000m " <nl> mmm a / site / docs / install . md <nl> ppp b / site / docs / install . md <nl>
public class cppcompileaction extends abstractaction implements includescannable <nl>  <nl> @ override <nl> public list < pathfragment > getsystemincludedirs ( ) { <nl> + <nl> + / / system_includes attribute in cc_toolchain ) ; note that that would disallow users from <nl> + / / specifying system include paths via the copts attribute . <nl> + / / currently , this works together with the include_paths features because getcommandline ( ) will <nl> + / / get the system include paths from the cppcompilationcontext instead . <nl> immutablelist . builder < pathfragment > result = immutablelist . builder ( ) ; <nl> - result . addall ( context . getsystemincludedirs ( ) ) ; <nl> - for ( string opt : cppcompilecommandline . copts ) { <nl> - if ( opt . startswith ( " - isystem " ) & & opt . length ( ) > num ) { <nl> - / / we insist on the combined form " - isystemdir " . <nl> - result . add ( new pathfragment ( opt . substring ( 8 ) ) ) ; <nl> + list < string > compileroptions = getcompileroptions ( ) ; <nl> + for ( int i = num ; i < compileroptions . size ( ) ; i + + ) { <nl> + string opt = compileroptions . get ( i ) ; <nl> + if ( opt . startswith ( " - isystem " ) ) { <nl> + if ( opt . length ( ) > num ) { <nl> + result . add ( new pathfragment ( opt . substring ( 8 ) . trim ( ) ) ) ; <nl> + } else if ( i + num < compileroptions . size ( ) ) { <nl> + i + + ; <nl> + result . add ( new pathfragment ( compileroptions . get ( i ) ) ) ; <nl> + } else { <nl> + system . err . println ( " warning : dangling - isystem flag in options for " + prettyprint ( ) ) ; <nl> + } <nl> } <nl> } <nl> return result . build ( ) ; <nl>
public class constraintsemantics { <nl> for ( string attr : attributes . getattributenames ( ) ) { <nl> attribute attrdef = attributes . getattributedefinition ( attr ) ; <nl> type < ? > attrtype = attributes . getattributetype ( attr ) ; <nl> + <nl> + <nl> if ( ( attrtype ! = type . label & & attrtype ! = type . label_list ) <nl> | | ruleclass . isconstraintattribute ( attr ) <nl> | | attr . equals ( " visibility " ) <nl> | | attrdef . isimplicit ( ) <nl> - | | attrdef . islatebound ( ) ) { <nl> + | | attrdef . islatebound ( ) <nl> + / / we can ' t identify host deps by calling buildconfiguration . ishostconfiguration ( ) <nl> + / / because - - nodistinct_host_configuration subverts that call . <nl> + | | attrdef . getconfigurationtransition ( ) = = attribute . configurationtransition . host ) { <nl> continue ; <nl> } <nl>  <nl>
public class xcodegen { <nl>  <nl> iterator < string > srclist = allsourcefilepaths ( controlpb ) . iterator ( ) ; <nl> path workspaceroot ; <nl> - if ( ! srclist . hasnext ( ) ) { <nl> + <nl> + <nl> + if ( controlpb . hasworkspaceroot ( ) ) { <nl> + workspaceroot = filesystem . getpath ( controlpb . getworkspaceroot ( ) ) ; <nl> + } else if ( ! srclist . hasnext ( ) ) { <nl> workspaceroot = xcodeprojgeneration . relativeworkspaceroot ( pbxprojpath ) ; <nl> } else { <nl> / / get the absolute path to the workspace root .
public final class selectorlist { <nl> immutablelist . builder < object > builder = immutablelist . builder ( ) ; <nl> class < ? > type1 = addvalue ( value1 , builder ) ; <nl> class < ? > type2 = addvalue ( value2 , builder ) ; <nl> - if ( type1 ! = type2 ) { <nl> + if ( ! canconcatenate ( type1 , type2 ) ) { <nl> throw new evalexception ( location , " ' + ' operator applied to incompatible types " ) ; <nl> } <nl> return new selectorlist ( type1 , builder . build ( ) ) ; <nl> } <nl>  <nl> + <nl> + private static final class < ? > native_list_type = arraylist . class ; <nl> + <nl> private static class < ? > addvalue ( object value , immutablelist . builder < object > builder ) { <nl> if ( value instanceof selectorlist ) { <nl> selectorlist selectorlist = ( selectorlist ) value ; <nl>
public final class selectorlist { <nl> } else if ( value instanceof selectorvalue ) { <nl> builder . add ( value ) ; <nl> return ( ( selectorvalue ) value ) . gettype ( ) ; <nl> + } else if ( value instanceof globlist ) { <nl> + builder . add ( ( ( globlist < ? > ) value ) . delegate ( ) ) ; <nl> + <nl> + return arraylist . class ; <nl> } else { <nl> builder . add ( value ) ; <nl> return value . getclass ( ) ;
public class blazecommanddispatcher { <nl> } <nl>  <nl> path workspace = runtime . getworkspace ( ) ; <nl> + <nl> + if ( workspace . getpathstring ( ) . contains ( " " ) ) { <nl> + outerr . printerrln ( constants . product_name + " does not currently work properly from paths " <nl> + + " containing spaces ( " + workspace + " ) . " ) ; <nl> + return exitcode . local_environmental_error ; <nl> + } <nl> + <nl> path donotbuild = workspace . getparentdirectory ( ) . getrelative ( <nl> blazeruntime . do_not_build_file_name ) ; <nl> if ( donotbuild . exists ( ) ) { <nl> mmm / dev / null <nl> ppp b / src / test / shell / bazel / workspace_path_test . sh <nl>
if [ [ " $ ( uname ) " ! = darwin ] ] ; then <nl> exit num <nl> fi <nl>  <nl> - readonly sdk_version = " % sdk_version % " <nl> - readonly sim_device = " % sim_device % " <nl> + # <nl> + readonly sdk_version = ' 8 . 1 ' <nl> + readonly sim_device = ' iphone num ' <nl> readonly app_dir = $ ( mktemp - d - t extracted_app ) <nl>  <nl> args = ( )
public class methodlibrary { <nl> } <nl> } <nl>  <nl> + / * * <nl> + * collect global functions for the validation environment . <nl> + * / <nl> public static void setupvalidationenvironment ( <nl> map < skylarktype , map < string , skylarktype > > builtin ) { <nl> map < string , skylarktype > global = builtin . get ( skylarktype . global ) ; <nl> - setupvalidationenvironment ( skylarkglobalfunctions , global ) ; <nl> - <nl> - map < string , skylarktype > dict = new hashmap < > ( ) ; <nl> - setupvalidationenvironment ( dictfunctions , dict ) ; <nl> - builtin . put ( skylarktype . of ( map . class ) , dict ) ; <nl>  <nl> - map < string , skylarktype > string = new hashmap < > ( ) ; <nl> - setupvalidationenvironment ( stringfunctions , string ) ; <nl> - builtin . put ( skylarktype . string , string ) ; <nl> - <nl> - map < string , skylarktype > list = new hashmap < > ( ) ; <nl> - setupvalidationenvironment ( listpurefunctions , list ) ; <nl> - builtin . put ( skylarktype . list , list ) ; <nl> + <nl> + for ( map . entry < function , skylarktype > function : skylarkglobalfunctions . entryset ( ) ) { <nl> + string name = function . getkey ( ) . getname ( ) ; <nl> + global . put ( name , skylarkfunctiontype . of ( name , function . getvalue ( ) ) ) ; <nl> + } <nl> } <nl> }
<nl> + # ! / bin / bash <nl> + <nl> + # copyright num google inc . all rights reserved . <nl> + # <nl> + # licensed under the apache license , version num . 0 ( the " license " ) ; <nl> + # you may not use this file except in compliance with the license . <nl> + # you may obtain a copy of the license at <nl> + # <nl> + # http : / / www . apache . org / licenses / license - 2 . 0 <nl> + # <nl> + # unless required by applicable law or agreed to in writing , software <nl> + # distributed under the license is distributed on an " as is " basis , <nl> + # without warranties or conditions of any kind , either express or implied . <nl> + # see the license for the specific language governing permissions and <nl> + # limitations under the license . <nl> + <nl> + set - eux <nl> + <nl> + # remove all of the files the build generated that we don ' t want uploaded <nl> + # to s3 . <nl> + # <nl> + mv output / bazel bazel <nl> + rm - rf output <nl> + rm - rf bazel - *
<nl> + / / copyright num google inc . all rights reserved . <nl> + / / <nl> + / / licensed under the apache license , version num . 0 ( the " license " ) ; <nl> + / / you may not use this file except in compliance with the license . <nl> + / / you may obtain a copy of the license at <nl> + / / <nl> + / / http : / / www . apache . org / licenses / license - 2 . 0 <nl> + / / <nl> + / / unless required by applicable law or agreed to in writing , software <nl> + / / distributed under the license is distributed on an " as is " basis , <nl> + / / without warranties or conditions of any kind , either express or implied . <nl> + / / see the license for the specific language governing permissions and <nl> + / / limitations under the license . <nl> + package com . google . devtools . build . skyframe ; <nl> + <nl> + import org . junit . before ; <nl> + import org . junit . test ; <nl> + <nl> + / * * base class for concurrency sanity tests on { @ link evaluablegraph } implementations . * / <nl> + public abstract class graphconcurrencytest { <nl> + <nl> + private static final skyfunctionname sky_function_name = <nl> + new skyfunctionname ( " graphconcurrencytestkey " , / * iscomputed = * / false ) ; <nl> + private processablegraph graph ; <nl> + <nl> + protected abstract processablegraph getgraph ( ) ; <nl> + <nl> + @ before <nl> + public void init ( ) { <nl> + this . graph = getgraph ( ) ; <nl> + } <nl> + <nl> + private skykey key ( string name ) { <nl> + return new skykey ( sky_function_name , name ) ; <nl> + } <nl> + <nl> + @ test <nl> + public void createifabsentsanity ( ) { <nl> + graph . createifabsent ( key ( " cat " ) ) ; <nl> + } <nl> + <nl> + <nl> + } <nl> mmm / dev / null <nl> ppp b / src / test / java / com / google / devtools / build / skyframe / inmemorygraphconcurrencytest . java <nl>
import java . util . list ; <nl> public class testcommand implements blazecommand { <nl> private ansiterminalprinter printer ; <nl>  <nl> + / * * returns the name of the command to ask the project file for . * / <nl> + <nl> + protected string commandname ( ) { <nl> + return " test " ; <nl> + } <nl> + <nl> @ override <nl> public void editoptions ( blazeruntime runtime , optionsparser optionsparser ) <nl> throws abruptexitexception { <nl> - projectfilesupport . handleprojectfiles ( runtime , optionsparser , " test " ) ; <nl> + projectfilesupport . handleprojectfiles ( runtime , optionsparser , commandname ( ) ) ; <nl>  <nl> testoutputformat testoutput = optionsparser . getoptions ( executionoptions . class ) . testoutput ;
cat < < eof <nl> eof <nl>  <nl> # find java paths <nl> - for path in $ ( find src - name " * . java " | sed " s | / com / google / . * $ | | " | sort - u ) ; do <nl> + java_paths = " $ ( find src - name " * . java " | sed " s | / com / google / . * $ | | " | sort - u ) " <nl> + # <nl> + # if [ " $ ( uname - s | tr ' a - z ' ' a - z ' ) " ! = " darwin " ] ; then <nl> + java_paths = " $ ( echo " $ { java_paths } " | fgrep - v " / objc_tools / " ) " <nl> + # fi <nl> + for path in $ { java_paths } ; do <nl> echo " < classpathentry kind = \ " src \ " path = \ " $ path \ " / > " <nl> done <nl>  <nl>
<nl> + # ! / bin / bash <nl> + <nl> + # copyright num google inc . all rights reserved . <nl> + # <nl> + # licensed under the apache license , version num . 0 ( the " license " ) ; <nl> + # you may not use this file except in compliance with the license . <nl> + # you may obtain a copy of the license at <nl> + # <nl> + # http : / / www . apache . org / licenses / license - 2 . 0 <nl> + # <nl> + # unless required by applicable law or agreed to in writing , software <nl> + # distributed under the license is distributed on an " as is " basis , <nl> + # without warranties or conditions of any kind , either express or implied . <nl> + # see the license for the specific language governing permissions and <nl> + # limitations under the license . <nl> + <nl> + set - e <nl> + <nl> + if [ [ " $ ( uname ) " ! = darwin ] ] ; then <nl> + echo " cannot run ios targets on a non - mac machine . " <nl> + exit num <nl> + fi <nl> + <nl> + # <nl> + readonly sdk_version = ' 8 . 1 ' <nl> + readonly sim_device = ' iphone num ' <nl> + readonly app_dir = $ ( mktemp - d - t extracted_app ) <nl> + <nl> + args = ( ) <nl> + # pass environment variables prefixed with ios_ to the simulator , stripping <nl> + # the prefix . <nl> + while read - r envvar ; do <nl> + if [ [ " $ { envvar } " = = ios_ * ] ] ; then <nl> + args + = ( - e " $ { envvar # ios_ } " ) <nl> + fi <nl> + done < < ( env ) <nl> + <nl> + unzip - qq ' % ipa_file % ' - d " $ { app_dir } " <nl> + % iossim % - d " $ { sim_device } " - s " $ { sdk_version } " \ <nl> + " $ { args [ @ ] } " \ <nl> + " $ { app_dir } / payload / % app_name % . app " \ <nl> + " $ @ "
public class objcruleclasses { <nl> } <nl> } ) <nl> . allowedfiletypes ( ) <nl> - . allowedruleclasses ( " objc_binary " ) ) <nl> + <nl> + . allowedruleclasses ( " objc_binary " , " ios_application " ) ) <nl> . override ( attr ( " infoplist " , label ) <nl> . value ( new attribute . computeddefault ( iostest . is_xctest ) { <nl> @ override <nl> mmm a / src / main / java / com / google / devtools / build / lib / rules / objc / releasebundlingsupport . java <nl> ppp b / src / main / java / com / google / devtools / build / lib / rules / objc / releasebundlingsupport . java <nl>
public class skylarkruleimplementationfunctions { <nl> } <nl> } ; <nl>  <nl> - <nl> + / / deprecated function . <nl> + / / use the new ctx . var field , which is a dictionary . <nl> + <nl> @ skylarkbuiltin ( name = " var " , <nl> doc = " get the value bound to a configuration variable in the context " , <nl> + hidden = true , <nl> objecttype = skylarkrulecontext . class , <nl> mandatoryparams = { <nl> @ param ( name = " name " , type = string . class , doc = " the name of the variable " )
public class <nl> defaultvalue = default_options_name , <nl> category = " undocumented " , <nl> help = " specifies the name of the build settings to use . " ) <nl> + <nl> public string xcodeoptions ; <nl>  <nl> @ option ( name = " objc_generate_debug_symbols " , <nl> mmm a / src / tools / xcode - common / java / com / google / devtools / build / xcode / common / buildoptionsutil . java <nl> ppp b / src / tools / xcode - common / java / com / google / devtools / build / xcode / common / buildoptionsutil . java <nl>
public abstract class mixedmodefunction extends abstractfunction { <nl> this ( name , functionsignature . withvalues . < object , skylarktype > create ( signature ) , null ) ; <nl> } <nl>  <nl> + <nl> + private static < e > arraylist < e > listdifference ( list < e > plus , list < e > minus ) { <nl> + final arraylist < e > list = new arraylist < > ( ) ; <nl> + list . addall ( plus ) ; <nl> + list . removeall ( minus ) ; <nl> + return list ; <nl> + } <nl> + <nl> @ override <nl> public object call ( list < object > args , <nl> map < string , object > kwargs , <nl>
public class parallelevaluatortest { <nl>  <nl> @ test <nl> public void raceconditionwithnokeepgoingerrors_inflighterror ( ) throws exception { <nl> + if ( system . getproperty ( " os . name " ) . tolowercase ( ) . indexof ( " mac " ) > = num ) { <nl> + <nl> + return ; <nl> + } <nl> + <nl> final countdownlatch errorcommitted = new countdownlatch ( 1 ) ; <nl> final trackingawaiter trackingawaiterforerror = new trackingawaiter ( ) ; <nl> final countdownlatch otherdone = new countdownlatch ( 1 ) ;
public class objcconfiguration extends buildconfiguration . fragment { <nl> " - fstack - protector " , " - fstack - protector - all " , " - d_glibcxx_debug_pedantic " , " - d_glibcxx_debug " , <nl> " - d_glibcpp_concept_checks " ) ; <nl>  <nl> + <nl> @ visiblefortesting <nl> - static final immutablelist < string > fastbuild_copts = immutablelist . of ( " - o0 " , " - ddebug = 1 " ) ; <nl> + static final immutablelist < string > fastbuild_copts = immutablelist . of ( " - o0 " ) ; <nl>  <nl> @ visiblefortesting <nl> static final immutablelist < string > opt_copts =
public final class extraaction extends spawnaction { <nl> } <nl> } <nl>  <nl> + private static immutablemap < pathfragment , artifact > getmanifests ( action shadowedaction ) { <nl> + / / if the shadowed action is a spawnaction , then we also add the input manifests to this <nl> + / / action ' s input manifests . <nl> + <nl> + if ( shadowedaction instanceof spawnaction ) { <nl> + return ( ( spawnaction ) shadowedaction ) . getinputmanifests ( ) ; <nl> + } <nl> + return immutablemap . of ( ) ; <nl> + } <nl> + <nl> @ override <nl> public boolean discoversinputs ( ) { <nl> return shadowedaction . discoversinputs ( ) ;
public class zipkinhttpconfiguration { <nl> / / better error messages where possible . <nl> sb . requesttimeout ( duration . ofseconds ( 11 ) ) ; <nl>  <nl> - / / because https : / / github . com / openzipkin / zipkin / issues / 2286 <nl> - sb . routedecorator ( ) <nl> - . methods ( httpmethod . trace ) <nl> - . pathprefix ( " / " ) <nl> - . build ( ( delegate , ctx , req ) - > httpresponse . of ( httpstatus . method_not_allowed ) ) ; <nl> + / / block trace requests because https : / / github . com / openzipkin / zipkin / issues / 2286 <nl> + sb . routedecorator ( ) . trace ( " prefix : / " ) <nl> + . build ( ( delegate , ctx , req ) - > { <nl> + if ( req . method ( ) = = httpmethod . trace ) { <nl> + return httpresponse . of ( httpstatus . method_not_allowed ) ; <nl> + } <nl> + return delegate . serve ( ctx , req ) ; <nl> + } ) ; <nl> } ; <nl> }
eof <nl>  <nl> mkdir / kafka / logs <nl>  <nl> + echo " * * * cleaning up " <nl> + apk del jq curl - - purge <nl> + # <nl> + # https : / / issues . apache . org / jira / browse / kafka - 10380 <nl> + rm - rf kafka_ $ scala_version - $ kafka_version site - docs bin / windows <nl> + <nl> echo " * * * image build complete " <nl> mmm a / zipkin - collector / kafka / pom . xml <nl> ppp b / zipkin - collector / kafka / pom . xml <nl>
import org . junit . jupiter . api . extension . registerextension ; <nl> class itelasticsearchstoragev7 extends itelasticsearchstorage { <nl>  <nl> @ registerextension elasticsearchstorageextension backend = new elasticsearchstorageextension ( <nl> - " openzipkin / zipkin - elasticsearch7 : 2 . 21 . 4 " ) ; <nl> + " openzipkin / zipkin - elasticsearch7 : 2 . 21 . 0 " ) ; <nl>  <nl> @ override elasticsearchstorageextension backend ( ) { <nl> return backend ;
final class mysqlspanconsumer implements spanconsumer { <nl> inserts . add ( insert . onduplicatekeyignore ( ) ) ; <nl> } <nl> } <nl> + <nl> create . batch ( inserts ) . execute ( ) ; <nl> return null ; <nl> }
public class httpclientfactory implements function < endpoint , httpclient > , closea <nl> if ( httplogging ! = httplogging . none ) { <nl> loggingclientbuilder loggingbuilder = new loggingclientbuilder ( ) <nl> . requestloglevel ( loglevel . info ) <nl> - . successfulresponseloglevel ( loglevel . info ) ; <nl> + . successfulresponseloglevel ( loglevel . info ) <nl> + . requestheaderssanitizer ( headers - > { <nl> + if ( ! headers . contains ( httpheadernames . authorization ) ) { <nl> + return headers ; <nl> + } <nl> + <nl> + return headers . tobuilder ( ) . set ( httpheadernames . authorization , " * * * * " ) . build ( ) ; <nl> + } ) ; <nl> switch ( httplogging ) { <nl> case headers : <nl> loggingbuilder . contentsanitizer ( unused - > " " ) ;
<nl> < system > github < / system > <nl> < url > https : / / github . com / openzipkin / zipkin / issues < / url > <nl> < / issuemanagement > <nl> - <nl> < dependencymanagement > <nl> + < ! - - <nl> < dependencies > <nl> + < dependency > <nl> + < groupid > com . fasterxml . jackson < / groupid > <nl> + < artifactid > jackson - bom < / artifactid > <nl> + < version > 2 . 9 . 9 . 20190807 < / version > <nl> + < type > pom < / type > <nl> + < scope > import < / scope > <nl> + < / dependency > <nl> < dependency > <nl> < groupid > javax . annotation < / groupid > <nl> < artifactid > javax . annotation - api < / artifactid >
public final class httpcall < v > extends call . base < v > { <nl> } <nl>  <nl> @ override protected v doexecute ( ) throws ioexception { <nl> + <nl> + for ( eventexecutor eventloop : httpclient . factory ( ) . eventloopgroup ( ) ) { <nl> + if ( eventloop . ineventloop ( ) ) { <nl> + throw new runtimeexception ( " attempting to make a blocking request from an event loop . " <nl> + + " either use doenqueue ( ) or run this in a separate thread . " ) ; <nl> + } <nl> + } <nl> aggregatedhttpresponse response = sendrequest ( ) . join ( ) ; <nl> return parseresponse ( response , bodyconverter ) ; <nl> }
<nl> + import { <nl> + convertv2tov1 <nl> + } from ' . . / . . / js / component_ui / uploadtrace ' ; <nl> + import { mergev2byid } from ' . . / . . / js / spancleaner ' ; <nl> + import { span_v1 } from ' . . / . . / js / spanconverter ' ; <nl> + import { httptrace } from ' . . / component_ui / tracetesthelpers ' ; <nl> + <nl> + chai . config . truncatethreshold = num ; <nl> + <nl> + describe ( ' convertv2tov1 ' , ( ) = > { <nl> + <nl> + it ( ' should convert to v1 format ' , ( ) = > { <nl> + const v1trace = convertv2tov1 ( httptrace ) ; <nl> + <nl> + expect ( v1trace ) . to . deep . equal ( span_v1 . converttrace ( mergev2byid ( httptrace ) ) ) ; <nl> + } ) ; <nl> + <nl> + it ( ' should raise error if not a list ' , ( ) = > { <nl> + let error ; <nl> + try { <nl> + convertv2tov1 ( ) ; <nl> + } catch ( err ) { <nl> + error = err ; <nl> + } <nl> + <nl> + expect ( error . message ) . to . eql ( ' input is not a list ' ) ; <nl> + <nl> + try { <nl> + convertv2tov1 ( { traceid : ' a ' , id : ' b ' } ) ; <nl> + } catch ( err ) { <nl> + expect ( err . message ) . to . eql ( error . message ) ; <nl> + } <nl> + } ) ; <nl> + <nl> + it ( ' should raise error if missing trace id or span id ' , ( ) = > { <nl> + let error ; <nl> + try { <nl> + convertv2tov1 ( [ { traceid : ' a ' } ] ) ; <nl> + } catch ( err ) { <nl> + error = err ; <nl> + } <nl> + <nl> + expect ( error . message ) . to . eql ( ' list < span > implies at least traceid and id fields ' ) ; <nl> + <nl> + try { <nl> + convertv2tov1 ( [ { id : ' b ' } ] ) ; <nl> + } catch ( err ) { <nl> + expect ( err . message ) . to . eql ( error . message ) ; <nl> + } <nl> + } ) ; <nl> + <nl> + it ( ' should raise error if in v1 format ' , ( ) = > { <nl> + let error ; <nl> + try { <nl> + convertv2tov1 ( [ { traceid : ' a ' , id : ' b ' , binaryannotations : [ ] } ] ) ; <nl> + } catch ( err ) { <nl> + error = err ; <nl> + } <nl> + <nl> + expect ( error . message ) . to . eql ( <nl> + ' v1 format is not supported . for help , contact https : / / gitter . im / openzipkin / zipkin ' ) ; <nl> + } ) ; <nl> + } ) ;
export default component ( function spanpanel ( ) { <nl> } <nl> $ row . find ( ' td ' ) . each ( function ( ) { <nl> const $ this = $ ( this ) ; <nl> - $ this . text ( anno [ $ this . data ( ' key ' ) ] ) ; <nl> + const maybeobject = anno [ $ this . data ( ' key ' ) ] ; <nl> + / / in case someone is storing escaped json as an annotation value <nl> + <nl> + $ this . text ( $ . type ( maybeobject ) = = = ' object ' ? json . stringify ( maybeobject ) : maybeobject ) ; <nl> } ) ; <nl> $ annobody . append ( $ row ) ; <nl> } ) ;
export default component ( function spanpanel ( ) { <nl> const $ row = self . $ binaryannotationtemplate . clone ( ) ; <nl> $ row . find ( ' td ' ) . each ( function ( ) { <nl> const $ this = $ ( this ) ; <nl> - $ this . text ( anno [ $ this . data ( ' key ' ) ] ) ; <nl> + const maybeobject = anno [ $ this . data ( ' key ' ) ] ; <nl> + / / in case someone is storing escaped json as binary annotation values <nl> + <nl> + $ this . text ( $ . type ( maybeobject ) = = = ' object ' ? json . stringify ( maybeobject ) : maybeobject ) ; <nl> } ) ; <nl> $ binannobody . append ( $ row ) ; <nl> } ) ;
public class zipkinserverconfiguration { <nl> @ qualifier ( " jdbctracelistenerprovider " ) <nl> executelistenerprovider listener ; <nl>  <nl> - @ bean <nl> - @ conditionalonmissingbean ( datasource . class ) <nl> - datasource datasource ( ) { <nl> + @ bean jdbcspanstore jdbcspanstore ( ) { <nl> + <nl> + if ( datasource = = null ) { <nl> + datasource = initializefrommysqlproperties ( ) ; <nl> + } <nl> + return new jdbcspanstore ( datasource , new settings ( ) . withrenderschema ( false ) , listener ) ; <nl> + } <nl> + <nl> + datasource initializefrommysqlproperties ( ) { <nl> stringbuilder url = new stringbuilder ( " jdbc : mysql : / / " ) ; <nl> url . append ( mysql . gethost ( ) ) . append ( " : " ) . append ( mysql . getport ( ) ) ; <nl> url . append ( " / " ) . append ( mysql . getdb ( ) ) ; <nl>
<nl> + package com . alibaba . druid . support . clickhouse ; <nl> + <nl> + import ru . yandex . clickhouse . balancedclickhousedatasource ; <nl> + <nl> + import java . sql . connection ; <nl> + import java . sql . driverpropertyinfo ; <nl> + import java . sql . sqlexception ; <nl> + import java . sql . sqlfeaturenotsupportedexception ; <nl> + import java . util . properties ; <nl> + import java . util . logging . logger ; <nl> + <nl> + public class balancedclickhousedriver implements java . sql . driver { <nl> + private final string url ; <nl> + private balancedclickhousedatasource datasource ; <nl> + <nl> + public balancedclickhousedriver ( final string url , properties properties ) { <nl> + this . url = url ; <nl> + this . datasource = new balancedclickhousedatasource ( url , properties ) ; <nl> + } <nl> + <nl> + @ override <nl> + public connection connect ( string url , properties info ) throws sqlexception { <nl> + if ( ! acceptsurl ( url ) ) { <nl> + throw new sqlexception ( " <nl> + } <nl> + <nl> + return datasource . getconnection ( ) ; <nl> + } <nl> + <nl> + @ override <nl> + public boolean acceptsurl ( string url ) throws sqlexception { <nl> + return this . url . equals ( url ) ; <nl> + } <nl> + <nl> + @ override <nl> + public driverpropertyinfo [ ] getpropertyinfo ( string url , properties info ) throws sqlexception { <nl> + return new driverpropertyinfo [ 0 ] ; <nl> + } <nl> + <nl> + @ override <nl> + public int getmajorversion ( ) { <nl> + return num ; <nl> + } <nl> + <nl> + @ override <nl> + public int getminorversion ( ) { <nl> + return num ; <nl> + } <nl> + <nl> + @ override <nl> + public boolean jdbccompliant ( ) { <nl> + return false ; <nl> + } <nl> + <nl> + @ override <nl> + public logger getparentlogger ( ) throws sqlfeaturenotsupportedexception { <nl> + return null ; <nl> + } <nl> + }
public class mysqlexceptionsorter implements exceptionsorter { <nl> return false ; <nl> } <nl>  <nl> + @ override <nl> + public void configfromproperties ( properties properties ) { <nl> + <nl> + <nl> + } <nl> + <nl> }
public class druiddatasource extends druidabstractdatasource implements druiddat <nl> final string factoryname = classname + " factory " ; / / xxx : not robust <nl> reference ref = new reference ( classname , factoryname , null ) ; <nl> ref . add ( new stringrefaddr ( " instancekey " , instancekey ) ) ; <nl> + ref . add ( new stringrefaddr ( " url " , this . geturl ( ) ) ) ; <nl> + ref . add ( new stringrefaddr ( " username " , this . getusername ( ) ) ) ; <nl> + ref . add ( new stringrefaddr ( " password " , this . getpassword ( ) ) ) ; <nl> + <nl> return ref ; <nl> }
<nl> + package com . alibaba . druid . support . monitor ; <nl> + <nl> + import javax . servlet . servletcontextevent ; <nl> + import javax . servlet . servletcontextlistener ; <nl> + <nl> + import com . alibaba . druid . support . logging . log ; <nl> + import com . alibaba . druid . support . logging . logfactory ; <nl> + <nl> + public class pushservicelistener implements servletcontextlistener { <nl> + <nl> + private final static log log = logfactory . getlog ( pushservicelistener . class ) ; <nl> + <nl> + private final static string monitor_server_url = " monitorserverurl " ; <nl> + <nl> + @ override <nl> + public void contextinitialized ( servletcontextevent sce ) { <nl> + pushservice pushservice = pushservice . getinstance ( ) ; <nl> + string serverurl = sce . getservletcontext ( ) . getinitparameter ( monitor_server_url ) ; <nl> + if ( serverurl = = null ) { <nl> + log . error ( monitor_server_url + " can ' t be null " ) ; <nl> + return ; <nl> + } <nl> + <nl> + if ( log . isdebugenabled ( ) ) { <nl> + log . debug ( monitor_server_url + " = " + serverurl ) ; <nl> + } <nl> + pushservice . setserverurl ( serverurl ) ; <nl> + pushservice . start ( ) ; <nl> + <nl> + } <nl> + <nl> + @ override <nl> + public void contextdestroyed ( servletcontextevent sce ) { <nl> + <nl> + <nl> + } <nl> + <nl> + } <nl> mmm a / src / main / java / com / alibaba / druid / util / httpclientutils . java <nl> ppp b / src / main / java / com / alibaba / druid / util / httpclientutils . java <nl>
public class hbasepreparedstatement extends preparedstatementbase implements pre <nl> throw new sqlexception ( " not support multi - statement " ) ; <nl> } <nl>  <nl> - sqlselectstatement stmt = ( sqlselectstatement ) stmtlist . get ( 0 ) ; <nl> - sqlselectqueryblock selectqueryblock = ( sqlselectqueryblock ) stmt . getselect ( ) . getquery ( ) ; <nl> + sqlstatement sqlstmt = stmtlist . get ( 0 ) ; <nl> + if ( sqlstmt instanceof sqlselectstatement ) { <nl> + sqlselectstatement selectstmt = ( sqlselectstatement ) sqlstmt ; <nl>  <nl> - sqlexprtablesource tablesource = ( sqlexprtablesource ) selectqueryblock . getfrom ( ) ; <nl> - string tablename = ( ( sqlidentifierexpr ) tablesource . getexpr ( ) ) . getname ( ) ; <nl> + sqlselectqueryblock selectqueryblock = ( sqlselectqueryblock ) selectstmt . getselect ( ) . getquery ( ) ; <nl>  <nl> - singletablequeryexecuteplan singletablequeryexecueteplan = new singletablequeryexecuteplan ( ) ; <nl> - singletablequeryexecueteplan . settablename ( tablename ) ; <nl> + sqlexprtablesource tablesource = ( sqlexprtablesource ) selectqueryblock . getfrom ( ) ; <nl> + string tablename = ( ( sqlidentifierexpr ) tablesource . getexpr ( ) ) . getname ( ) ; <nl>  <nl> - this . executeplan = singletablequeryexecueteplan ; <nl> + singletablequeryexecuteplan singletablequeryexecueteplan = new singletablequeryexecuteplan ( ) ; <nl> + singletablequeryexecueteplan . settablename ( tablename ) ; <nl> + <nl> + this . executeplan = singletablequeryexecueteplan ; <nl> + } else { <nl> + throw new sqlexception ( " <nl> + } <nl> } <nl>  <nl> public executeplan getexecuteplan ( ) { <nl>
class emptyimmutablelistmultimap extends immutablelistmultimap < object , object > { <nl> super ( immutablemap . < object , immutablelist < object > > of ( ) , num ) ; <nl> } <nl>  <nl> + / * <nl> + * <nl> + * mainline as when compiling the backport , and ideally find a nicer way to accomplish that . <nl> + * / <nl> + @ override <nl> + public immutablemap < object , collection < object > > asmap ( ) { <nl> + return super . asmap ( ) ; <nl> + } <nl> + <nl> private object readresolve ( ) { <nl> return instance ; / / preserve singleton property <nl> } <nl> mmm a / android / guava / src / com / google / common / collect / emptyimmutablesetmultimap . java <nl> ppp b / android / guava / src / com / google / common / collect / emptyimmutablesetmultimap . java <nl>
class emptyimmutablesetmultimap extends immutablesetmultimap < object , object > { <nl> super ( immutablemap . < object , immutableset < object > > of ( ) , num , null ) ; <nl> } <nl>  <nl> + / * <nl> + * <nl> + * mainline as when compiling the backport , and ideally find a nicer way to accomplish that . <nl> + * / <nl> + @ override <nl> + public immutablemap < object , collection < object > > asmap ( ) { <nl> + return super . asmap ( ) ; <nl> + } <nl> + <nl> private object readresolve ( ) { <nl> return instance ; / / preserve singleton property <nl> } <nl> mmm a / guava / src / com / google / common / collect / emptyimmutablelistmultimap . java <nl> ppp b / guava / src / com / google / common / collect / emptyimmutablelistmultimap . java <nl>
class emptyimmutablelistmultimap extends immutablelistmultimap < object , object > { <nl> super ( immutablemap . < object , immutablelist < object > > of ( ) , num ) ; <nl> } <nl>  <nl> + / * <nl> + * <nl> + * mainline as when compiling the backport , and ideally find a nicer way to accomplish that . <nl> + * / <nl> + @ override <nl> + public immutablemap < object , collection < object > > asmap ( ) { <nl> + return super . asmap ( ) ; <nl> + } <nl> + <nl> private object readresolve ( ) { <nl> return instance ; / / preserve singleton property <nl> } <nl> mmm a / guava / src / com / google / common / collect / emptyimmutablesetmultimap . java <nl> ppp b / guava / src / com / google / common / collect / emptyimmutablesetmultimap . java <nl>
class emptyimmutablesetmultimap extends immutablesetmultimap < object , object > { <nl> super ( immutablemap . < object , immutableset < object > > of ( ) , num , null ) ; <nl> } <nl>  <nl> + / * <nl> + * <nl> + * mainline as when compiling the backport , and ideally find a nicer way to accomplish that . <nl> + * / <nl> + @ override <nl> + public immutablemap < object , collection < object > > asmap ( ) { <nl> + return super . asmap ( ) ; <nl> + } <nl> + <nl> private object readresolve ( ) { <nl> return instance ; / / preserve singleton property <nl> }
public interface cache < k , v > { <nl> * @ since num . 0 <nl> * / <nl> @ checkfornull <nl> + @ canignorereturnvalue <nl> v getifpresent ( @ compatiblewith ( " k " ) object key ) ; <nl>  <nl> / * * <nl> mmm a / android / guava / src / com / google / common / cache / loadingcache . java <nl> ppp b / android / guava / src / com / google / common / cache / loadingcache . java <nl>
public interface loadingcache < k , v > extends cache < k , v > , function < k , v > { <nl> * value <nl> * @ throws executionerror if an error was thrown while loading the value <nl> * / <nl> + @ canignorereturnvalue <nl> v get ( k key ) throws executionexception ; <nl>  <nl> / * * <nl> mmm a / guava - gwt / src - super / com / google / common / cache / super / com / google / common / cache / localcache . java <nl> ppp b / guava - gwt / src - super / com / google / common / cache / super / com / google / common / cache / localcache . java <nl>
public interface cache < k , v > { <nl> * @ since num . 0 <nl> * / <nl> @ checkfornull <nl> + @ canignorereturnvalue <nl> v getifpresent ( @ compatiblewith ( " k " ) object key ) ; <nl>  <nl> / * * <nl> mmm a / guava / src / com / google / common / cache / loadingcache . java <nl> ppp b / guava / src / com / google / common / cache / loadingcache . java <nl>
public interface loadingcache < k , v > extends cache < k , v > , function < k , v > { <nl> * value <nl> * @ throws executionerror if an error was thrown while loading the value <nl> * / <nl> + @ canignorereturnvalue <nl> v get ( k key ) throws executionexception ; <nl>  <nl> / * *
public final class immutableclasstoinstancemap < b > extends forwardingmap < class < ? <nl> @ override <nl> @ donotcall ( " always throws unsupportedoperationexception " ) <nl> @ checkfornull <nl> + @ suppresswarnings ( " nullness " ) <nl> public < t extends b > t putinstance ( class < t > type , t value ) { <nl> throw new unsupportedoperationexception ( ) ; <nl> } <nl> mmm a / guava / src / com / google / common / collect / immutableclasstoinstancemap . java <nl> ppp b / guava / src / com / google / common / collect / immutableclasstoinstancemap . java <nl>
public final class immutableclasstoinstancemap < b > extends forwardingmap < class < ? <nl> @ override <nl> @ donotcall ( " always throws unsupportedoperationexception " ) <nl> @ checkfornull <nl> + @ suppresswarnings ( " nullness " ) <nl> public < t extends b > t putinstance ( class < t > type , t value ) { <nl> throw new unsupportedoperationexception ( ) ; <nl> }
<nl> + version : num <nl> + updates : <nl> + # <nl> + # easily import the generated prs into our internal repo . <nl> + # - package - ecosystem : " maven " <nl> + # directory : " / " <nl> + # schedule : <nl> + # interval : " daily " <nl> + # - package - ecosystem : " maven " <nl> + # directory : " / android " <nl> + # schedule : <nl> + # interval : " daily " <nl> + - package - ecosystem : " github - actions " <nl> + directory : " / " <nl> + schedule : <nl> + interval : " daily "
public class immutablelistmultimaptest extends testcase { <nl> } <nl> } <nl>  <nl> + <nl> + public void testtoimmutablelistmultimap_java7_combine ( ) { <nl> + immutablelistmultimap . builder < string , integer > zis = <nl> + immutablelistmultimap . < string , integer > builder ( ) . put ( " a " , num ) . put ( " b " , num ) ; <nl> + immutablelistmultimap . builder < string , integer > zat = <nl> + immutablelistmultimap . < string , integer > builder ( ) . put ( " a " , num ) . put ( " c " , num ) ; <nl> + immutablelistmultimap < string , integer > multimap = zis . combine ( zat ) . build ( ) ; <nl> + assertthat ( multimap . keyset ( ) ) . containsexactly ( " a " , " b " , " c " ) . inorder ( ) ; <nl> + assertthat ( multimap . values ( ) ) . containsexactly ( 1 , num , num , num ) . inorder ( ) ; <nl> + assertthat ( multimap . get ( " a " ) ) . containsexactly ( 1 , num ) . inorder ( ) ; <nl> + assertthat ( multimap . get ( " b " ) ) . containsexactly ( 2 ) ; <nl> + assertthat ( multimap . get ( " c " ) ) . containsexactly ( 4 ) ; <nl> + } <nl> + <nl> public void testemptymultimapreads ( ) { <nl> multimap < string , integer > multimap = immutablelistmultimap . of ( ) ; <nl> assertfalse ( multimap . containskey ( " foo " ) ) ; <nl> mmm a / android / guava - tests / test / com / google / common / collect / immutablesetmultimaptest . java <nl> ppp b / android / guava - tests / test / com / google / common / collect / immutablesetmultimaptest . java <nl>
public class immutablesetmultimaptest extends testcase { <nl> } <nl> } <nl>  <nl> + <nl> + public void testtoimmutablesetmultimap_java7_combine ( ) { <nl> + immutablesetmultimap . builder < string , integer > zis = <nl> + immutablesetmultimap . < string , integer > builder ( ) . put ( " a " , num ) . put ( " b " , num ) ; <nl> + immutablesetmultimap . builder < string , integer > zat = <nl> + immutablesetmultimap . < string , integer > builder ( ) . put ( " a " , num ) . put ( " c " , num ) ; <nl> + immutablesetmultimap < string , integer > multimap = zis . combine ( zat ) . build ( ) ; <nl> + assertthat ( multimap . keyset ( ) ) . containsexactly ( " a " , " b " , " c " ) . inorder ( ) ; <nl> + assertthat ( multimap . values ( ) ) . containsexactly ( 1 , num , num , num ) . inorder ( ) ; <nl> + assertthat ( multimap . get ( " a " ) ) . containsexactly ( 1 , num ) . inorder ( ) ; <nl> + assertthat ( multimap . get ( " b " ) ) . containsexactly ( 2 ) ; <nl> + assertthat ( multimap . get ( " c " ) ) . containsexactly ( 4 ) ; <nl> + } <nl> + <nl> public void testemptymultimapreads ( ) { <nl> multimap < string , integer > multimap = immutablesetmultimap . of ( ) ; <nl> assertfalse ( multimap . containskey ( " foo " ) ) ; <nl> mmm a / android / guava / src / com / google / common / collect / immutablelistmultimap . java <nl> ppp b / android / guava / src / com / google / common / collect / immutablelistmultimap . java <nl>
public class immutabletabletest extends abstracttablereadtest { <nl> return builder . build ( ) ; <nl> } <nl>  <nl> + <nl> + public void testtoimmutabletable_java7_combine ( ) { <nl> + immutabletable . builder < string , string , integer > zis = <nl> + immutabletable . < string , string , integer > builder ( ) . put ( " one " , " uno " , num ) . put ( " two " , " dos " , num ) ; <nl> + immutabletable . builder < string , string , integer > zat = <nl> + immutabletable . < string , string , integer > builder ( ) <nl> + . put ( " one " , " eins " , num ) <nl> + . put ( " two " , " twei " , num ) ; <nl> + immutabletable < string , string , integer > table = zis . combine ( zat ) . build ( ) ; <nl> + immutabletable < string , string , integer > expected = <nl> + immutabletable . < string , string , integer > builder ( ) <nl> + . put ( " one " , " uno " , num ) <nl> + . put ( " two " , " dos " , num ) <nl> + . put ( " one " , " eins " , num ) <nl> + . put ( " two " , " twei " , num ) <nl> + . build ( ) ; <nl> + assertthat ( table ) . isequalto ( expected ) ; <nl> + } <nl> + <nl> public void testbuilder ( ) { <nl> immutabletable . builder < character , integer , string > builder = new immutabletable . builder < > ( ) ; <nl> assertequals ( immutabletable . of ( ) , builder . build ( ) ) ; <nl> mmm a / android / guava / src / com / google / common / collect / immutabletable . java <nl> ppp b / android / guava / src / com / google / common / collect / immutabletable . java <nl>
public class immutablelisttest extends testcase { <nl> } catch ( nullpointerexception expected ) { <nl> } <nl> } <nl> + <nl> + <nl> + public void testtoimmutablelist_java7_combine ( ) { <nl> + immutablelist . builder < string > zis = immutablelist . < string > builder ( ) . add ( " a " , " b " ) ; <nl> + immutablelist . builder < string > zat = immutablelist . < string > builder ( ) . add ( " c " , " d " ) ; <nl> + immutablelist < string > list = zis . combine ( zat ) . build ( ) ; <nl> + assertequals ( aslist ( " a " , " b " , " c " , " d " ) , list ) ; <nl> + } <nl> } <nl>  <nl> @ gwtincompatible / / reflection <nl> mmm a / android / guava - tests / test / com / google / common / collect / immutablesettest . java <nl> ppp b / android / guava - tests / test / com / google / common / collect / immutablesettest . java <nl>
public class immutablesettest extends abstractimmutablesettest { <nl> assertnotsame ( sortedset , copy ) ; <nl> } <nl>  <nl> + <nl> + public void testtoimmutableset_java7 ( ) { <nl> + immutableset . builder < string > zis = immutableset . < string > builder ( ) . add ( " a " , " b " , " a " ) ; <nl> + immutableset . builder < string > zat = immutableset . < string > builder ( ) . add ( " c " , " b " , " d " , " c " ) ; <nl> + immutableset < string > set = zis . combine ( zat ) . build ( ) ; <nl> + assertthat ( set ) . containsexactly ( " a " , " b " , " c " , " d " ) . inorder ( ) ; <nl> + } <nl> + <nl> @ gwtincompatible / / gwt is single threaded <nl> public void testcopyof_threadsafe ( ) { <nl> verifythreadsafe ( ) ; <nl> mmm a / android / guava / src / com / google / common / collect / immutablecollection . java <nl> ppp b / android / guava / src / com / google / common / collect / immutablecollection . java <nl>
public final class closingfuture < v > { <nl> * . closing ( executor ) ; <nl> * } < / pre > <nl> * / <nl> + <nl> + @ com . google . errorprone . annotations . donotmock ( <nl> + " use closingfuture . whenallsucceed ( ) or . whenallcomplete ( ) instead . " ) <nl> public static class combiner { <nl>  <nl> private final closeablelist closeables = new closeablelist ( ) ; <nl> mmm a / guava / src / com / google / common / util / concurrent / closingfuture . java <nl> ppp b / guava / src / com / google / common / util / concurrent / closingfuture . java <nl>
public final class closingfuture < v > { <nl> * . closing ( executor ) ; <nl> * } < / pre > <nl> * / <nl> + <nl> + @ com . google . errorprone . annotations . donotmock ( <nl> + " use closingfuture . whenallsucceed ( ) or . whenallcomplete ( ) instead . " ) <nl> public static class combiner { <nl>  <nl> private final closeablelist closeables = new closeablelist ( ) ;
public class rangetest extends testcase { <nl> . testequals ( ) ; <nl> } <nl>  <nl> + @ gwtincompatible <nl> public void testlegacycomparable ( ) { <nl> range < legacycomparable > range = range . closed ( legacycomparable . x , legacycomparable . y ) ; <nl> } <nl> mmm a / guava - gwt / test / com / google / common / collect / rangetest_gwt . java <nl> ppp b / guava - gwt / test / com / google / common / collect / rangetest_gwt . java <nl>
public class rangetest extends testcase { <nl> . testequals ( ) ; <nl> } <nl>  <nl> + @ gwtincompatible <nl> public void testlegacycomparable ( ) { <nl> range < legacycomparable > range = range . closed ( legacycomparable . x , legacycomparable . y ) ; <nl> }
final class types { <nl> * typeresolver # resolvetype } will not be able to call { @ code getannotatedbounds ( ) } on it , but that <nl> * should hopefully be rare . <nl> * <nl> + * < p > <nl> + * annotatedelement } , which { @ code typevariable } began to extend only in java num . those methods <nl> + * refer only to types present in java num , so we could implement them in { @ code typevariableimpl } <nl> + * today . ( we could probably then make { @ code typevariableimpl } implement { @ code annotatedelement } <nl> + * so that we get partial compile - time checking . ) <nl> + * <nl> * < p > this workaround should be removed at a distant future time when we no longer support java <nl> * versions earlier than num . <nl> * / <nl> mmm a / guava / src / com / google / common / reflect / types . java <nl> ppp b / guava / src / com / google / common / reflect / types . java <nl>
final class types { <nl> * typeresolver # resolvetype } will not be able to call { @ code getannotatedbounds ( ) } on it , but that <nl> * should hopefully be rare . <nl> * <nl> + * < p > <nl> + * annotatedelement } , which { @ code typevariable } began to extend only in java num . those methods <nl> + * refer only to types present in java num , so we could implement them in { @ code typevariableimpl } <nl> + * today . ( we could probably then make { @ code typevariableimpl } implement { @ code annotatedelement } <nl> + * so that we get partial compile - time checking . ) <nl> + * <nl> * < p > this workaround should be removed at a distant future time when we no longer support java <nl> * versions earlier than num . <nl> * /
public final class queues { <nl> return new synchronousqueue < e > ( ) ; <nl> } <nl>  <nl> + / * * <nl> + * drains the queue as { @ link blockingqueue # drainto ( collection , int ) } , but if the requested { @ code <nl> + * numelements } elements are not available , it will wait for them up to the specified timeout . <nl> + * <nl> + * @ param q the blocking queue to be drained <nl> + * @ param buffer where to add the transferred elements <nl> + * @ param numelements the number of elements to be waited for <nl> + * @ param timeout how long to wait before giving up <nl> + * @ return the number of elements transferred <nl> + * @ throws interruptedexception if interrupted while waiting <nl> + * @ since next <nl> + * / <nl> + @ beta <nl> + @ canignorereturnvalue <nl> + @ gwtincompatible / / blockingqueue <nl> + public static < e > int drain ( <nl> + blockingqueue < e > q , collection < ? super e > buffer , int numelements , java . time . duration timeout ) <nl> + throws interruptedexception { <nl> + <nl> + return drain ( q , buffer , numelements , timeout . tonanos ( ) , timeunit . nanoseconds ) ; <nl> + } <nl> + <nl> / * * <nl> * drains the queue as { @ link blockingqueue # drainto ( collection , int ) } , but if the requested { @ code <nl> * numelements } elements are not available , it will wait for them up to the specified timeout . <nl>
public final class queues { <nl> return added ; <nl> } <nl>  <nl> + / * * <nl> + * drains the queue as { @ linkplain # drain ( blockingqueue , collection , int , duration ) } , but with a <nl> + * different behavior in case it is interrupted while waiting . in that case , the operation will <nl> + * continue as usual , and in the end the thread ' s interruption status will be set ( no { @ code <nl> + * interruptedexception } is thrown ) . <nl> + * <nl> + * @ param q the blocking queue to be drained <nl> + * @ param buffer where to add the transferred elements <nl> + * @ param numelements the number of elements to be waited for <nl> + * @ param timeout how long to wait before giving up <nl> + * @ return the number of elements transferred <nl> + * @ since next <nl> + * / <nl> + @ beta <nl> + @ canignorereturnvalue <nl> + @ gwtincompatible / / blockingqueue <nl> + public static < e > int drainuninterruptibly ( <nl> + blockingqueue < e > q , <nl> + collection < ? super e > buffer , <nl> + int numelements , <nl> + java . time . duration timeout ) { <nl> + <nl> + return drainuninterruptibly ( q , buffer , numelements , timeout . tonanos ( ) , timeunit . nanoseconds ) ; <nl> + } <nl> + <nl> / * * <nl> * drains the queue as { @ linkplain # drain ( blockingqueue , collection , int , long , timeunit ) } , but <nl> * with a different behavior in case it is interrupted while waiting . in that case , the operation
abstract class abstracttransformfuture < i , o , f , t > extends fluentfuture . trustedf <nl> * <nl> * contrast this to the situation we have if setresult ( ) throws , a situation described below . <nl> * / <nl> - <nl> i sourceresult ; <nl> try { <nl> sourceresult = getdone ( localinputfuture ) ; <nl> } catch ( cancellationexception e ) { <nl> + <nl> / / cancel this future and return . <nl> / / at this point , inputfuture is cancelled and outputfuture doesn ' t exist , so the value of <nl> / / mayinterruptifrunning is irrelevant . <nl> mmm a / guava / src / com / google / common / util / concurrent / abstracttransformfuture . java <nl> ppp b / guava / src / com / google / common / util / concurrent / abstracttransformfuture . java <nl>
abstract class abstracttransformfuture < i , o , f , t > extends fluentfuture . trustedf <nl> * <nl> * contrast this to the situation we have if setresult ( ) throws , a situation described below . <nl> * / <nl> - <nl> i sourceresult ; <nl> try { <nl> sourceresult = getdone ( localinputfuture ) ; <nl> } catch ( cancellationexception e ) { <nl> + <nl> / / cancel this future and return . <nl> / / at this point , inputfuture is cancelled and outputfuture doesn ' t exist , so the value of <nl> / / mayinterruptifrunning is irrelevant .
public abstract class immutablemultiset < e > extends immutablemultisetgwtserializa <nl> } <nl> } <nl>  <nl> - @ weakouter <nl> static final class elementset < e > extends immutableset . indexed < e > { <nl> private final list < entry < e > > entries ; <nl> + <nl> private final multiset < e > delegate ; <nl>  <nl> elementset ( list < entry < e > > entries , multiset < e > delegate ) {
public class throwablestest extends testcase { <nl> @ androidincompatible / / no getjavalangaccess in android ( at least not in the version we use ) . <nl> @ gwtincompatible / / lazystacktraceislazy ( ) <nl> public void testlazystacktraceworksinprod ( ) { <nl> + <nl> + if ( java_specification_version . value ( ) . equals ( " 9 " ) ) { <nl> + return ; <nl> + } <nl> / / obviously this isn ' t guaranteed in every environment , but it works well enough for now : <nl> asserttrue ( lazystacktraceislazy ( ) ) ; <nl> } <nl> mmm a / guava - tests / test / com / google / common / base / throwablestest . java <nl> ppp b / guava - tests / test / com / google / common / base / throwablestest . java <nl>
public class throwablestest extends testcase { <nl> @ androidincompatible / / no getjavalangaccess in android ( at least not in the version we use ) . <nl> @ gwtincompatible / / lazystacktraceislazy ( ) <nl> public void testlazystacktraceworksinprod ( ) { <nl> + <nl> + if ( java_specification_version . value ( ) . equals ( " 9 " ) ) { <nl> + return ; <nl> + } <nl> / / obviously this isn ' t guaranteed in every environment , but it works well enough for now : <nl> asserttrue ( lazystacktraceislazy ( ) ) ; <nl> }
public class closertest extends testcase { <nl> } <nl> } <nl>  <nl> + @ androidincompatible <nl> + private static string javaversion ( ) { <nl> + string javaversion = system . getproperty ( " java . version " ) ; <nl> + list < string > parts = splitter . on ( ' . ' ) . splittolist ( javaversion ) ; <nl> + / / format varies by version : http : / / openjdk . java . net / jeps / 223 <nl> + if ( parts . size ( ) = = num ) { <nl> + / / java num style : majorversion - foo <nl> + string major = getonlyelement ( parts ) ; <nl> + return major . replacefirst ( " - . * " , " " ) ; <nl> + } else { <nl> + / / pre - java num style : num . majorversion <nl> + return parts . get ( 1 ) ; <nl> + } <nl> + } <nl> + <nl> public void testnoexceptionsthrown ( ) throws ioexception { <nl> closer closer = new closer ( suppressor ) ; <nl>  <nl> mmm a / guava - tests / test / com / google / common / io / closertest . java <nl> ppp b / guava - tests / test / com / google / common / io / closertest . java <nl>
public class closertest extends testcase { <nl> } <nl> } <nl>  <nl> + @ androidincompatible <nl> + private static string javaversion ( ) { <nl> + string javaversion = system . getproperty ( " java . version " ) ; <nl> + list < string > parts = splitter . on ( ' . ' ) . splittolist ( javaversion ) ; <nl> + / / format varies by version : http : / / openjdk . java . net / jeps / 223 <nl> + if ( parts . size ( ) = = num ) { <nl> + / / java num style : majorversion - foo <nl> + string major = getonlyelement ( parts ) ; <nl> + return major . replacefirst ( " - . * " , " " ) ; <nl> + } else { <nl> + / / pre - java num style : num . majorversion <nl> + return parts . get ( 1 ) ; <nl> + } <nl> + } <nl> + <nl> public void testnoexceptionsthrown ( ) throws ioexception { <nl> closer closer = new closer ( suppressor ) ;
import javax . annotation . nullable ; <nl> * <nl> * @ author mike nonemacher <nl> * / <nl> + @ suppresswarnings ( " guardedby " ) <nl> class cachetesting { <nl>  <nl> / * * <nl> mmm a / guava - tests / test / com / google / common / cache / localcachetest . java <nl> ppp b / guava - tests / test / com / google / common / cache / localcachetest . java <nl>
import junit . framework . testsuite ; <nl> / * * <nl> * @ author charles fry <nl> * / <nl> + @ suppresswarnings ( " guardedby " ) <nl> public class localcachetest extends testcase { <nl> private static class teststringcachegenerator extends teststringmapgenerator { <nl> private final cachebuilder < ? super string , ? super string > builder ; <nl> mmm a / guava / src / com / google / common / collect / mapmakerinternalmap . java <nl> ppp b / guava / src / com / google / common / collect / mapmakerinternalmap . java <nl>
import javax . annotation . concurrent . immutable ; <nl> * / <nl> @ beta <nl> @ gwtincompatible <nl> + @ suppresswarnings ( " guardedby " ) <nl> public abstract class abstractservice implements service { <nl> private static final callback < listener > starting_callback = <nl> new callback < listener > ( " starting ( ) " ) { <nl> mmm a / guava / src / com / google / common / util / concurrent / monitor . java <nl> ppp b / guava / src / com / google / common / util / concurrent / monitor . java <nl>
import javax . annotation . concurrent . guardedby ; <nl> * / <nl> @ beta <nl> @ gwtincompatible <nl> + @ suppresswarnings ( " guardedby " ) <nl> public final class servicemanager { <nl> private static final logger logger = logger . getlogger ( servicemanager . class . getname ( ) ) ; <nl> private static final callback < listener > healthy_callback =
import junit . framework . testcase ; <nl> / * * <nl> * unit tests for { @ link hashing } . <nl> * <nl> + * < p > <nl> + * tests to reference them from there . <nl> + * <nl> * @ author dimitris andreou <nl> * @ author kurt alfred kluever <nl> * /
class standardtable < r , c , v > extends abstracttable < r , c , v > implements serializa <nl> } <nl> } ; <nl> } <nl> + <nl> + entry < c , v > wrapentry ( final entry < c , v > entry ) { <nl> + return new forwardingmapentry < c , v > ( ) { <nl> + @ override <nl> + protected entry < c , v > delegate ( ) { <nl> + return entry ; <nl> + } <nl> + <nl> + @ override <nl> + public v setvalue ( v value ) { <nl> + return super . setvalue ( checknotnull ( value ) ) ; <nl> + } <nl> + <nl> + @ override <nl> + public boolean equals ( object object ) { <nl> + <nl> + return standardequals ( object ) ; <nl> + } <nl> + } ; <nl> + } <nl> } <nl>  <nl> / * *
public final class classpath { <nl> } <nl>  <nl> private void scanfrom ( file file , classloader classloader ) throws ioexception { <nl> - if ( ! file . exists ( ) ) { <nl> + try { <nl> + if ( ! file . exists ( ) ) { <nl> + return ; <nl> + } <nl> + } catch ( securityexception e ) { <nl> + logger . warning ( " cannot access " + file + " : " + e ) ; <nl> + <nl> return ; <nl> } <nl> if ( file . isdirectory ( ) ) {
public final class graphs { <nl> * of the transitive closure of { @ code graph } . in other words , the returned { @ link graph } will not <nl> * be updated after modifications to { @ code graph } . <nl> * / <nl> + <nl> public static < n > graph < n > transitiveclosure ( graph < n > graph ) { <nl> mutablegraph < n > transitiveclosure = graphbuilder . from ( graph ) . allowsselfloops ( true ) . build ( ) ; <nl> / / every node is , at a minimum , reachable from itself . since the resulting transitive closure <nl>
public final class graphs { <nl> predicate < ? super n > nodepredicate ) { <nl> checknotnull ( graph , " graph " ) ; <nl> checknotnull ( nodepredicate , " nodepredicate " ) ; <nl> + <nl> checkargument ( ! ( ( graph instanceof network ) & & ( ( network < n , ? > ) graph ) . allowsparalleledges ( ) ) , <nl> network_with_parallel_edge ) ; <nl> mutablegraph < n > copy = graphbuilder . from ( graph ) . expectednodecount ( graph . nodes ( ) . size ( ) ) . build ( ) ; <nl> mmm a / guava / src / com / google / common / graph / immutablegraph . java <nl> ppp b / guava / src / com / google / common / graph / immutablegraph . java <nl>
public final class immutablegraph < n > extends abstractconfigurablegraph < n > { <nl> * / <nl> @ suppresswarnings ( " unchecked " ) <nl> public static < n > immutablegraph < n > copyof ( graph < n > graph ) { <nl> + <nl> checkargument ( ! ( ( graph instanceof network ) & & ( ( network < n , ? > ) graph ) . allowsparalleledges ( ) ) , <nl> network_with_parallel_edge ) ; <nl> return ( graph instanceof immutablegraph )
import com . google . common . collect . testing . abstractcollectiontester ; <nl> * / <nl> @ gwtcompatible <nl> public class collectionequalstester < e > extends abstractcollectiontester < e > { <nl> + <nl> + <nl> + @ suppresswarnings ( " selfequals " ) <nl> public void testequals_self ( ) { <nl> asserttrue ( " an object should be equal to itself . " , collection . equals ( collection ) ) ; <nl> }
public final class iterators { <nl> * @ throws illegalargumentexception if the iterator contains multiple <nl> * elements . the state of the iterator is unspecified . <nl> * / <nl> + @ canignorereturnvalue <nl> public static < t > t getonlyelement ( iterator < t > iterator ) { <nl> t first = iterator . next ( ) ; <nl> if ( ! iterator . hasnext ( ) ) { <nl>
public final class iterators { <nl> * @ throws illegalargumentexception if the iterator contains multiple <nl> * elements . the state of the iterator is unspecified . <nl> * / <nl> + @ canignorereturnvalue <nl> @ nullable <nl> public static < t > t getonlyelement ( iterator < ? extends t > iterator , @ nullable t defaultvalue ) { <nl> return iterator . hasnext ( ) ? getonlyelement ( iterator ) : defaultvalue ; <nl>
import org . junit . runners . junit4 ; <nl>  <nl> / * * <nl> * tests for { @ link incidentnodes } . <nl> + * <nl> + * <nl> * / <nl> @ runwith ( junit4 . class ) <nl> public final class incidentnodestest { <nl>
<nl> + # <nl> + <nl> + namespace com . google . common . collect . testing <nl> + namespace com . google . common . collect . testing . google <nl> + namespace com . google . common . escape <nl> + namespace com . google . common . escape . testing <nl> + namespace com . google . common . io <nl> + namespace com . google . common . net <nl> + namespace com . google . common . testing <nl> + <nl> + # whitelist our dependencies for now . <nl> + namespace junit . framework <nl> + namespace org . junit <nl> + <nl> + # * * * * * real cycles * * * * * <nl> + # inverses ( currently not solvable by weakening a reference ) <nl> + field com . google . common . base . converter . reverse <nl> + field com . google . common . collect . abstractbimap . inverse <nl> + field com . google . common . collect . hashbimap . inverse <nl> + field com . google . common . collect . immutablelistmultimap . inverse <nl> + field com . google . common . collect . immutablesetmultimap . inverse <nl> + field com . google . common . collect . mapconstraints . constrainedbimap . inverse <nl> + field com . google . common . collect . maps . filteredentrybimap . inverse <nl> + field com . google . common . collect . maps . unmodifiablebimap . inverse <nl> + field com . google . common . collect . regularimmutablebimap . inverse <nl> + field com . google . common . collect . singletonimmutablebimap . inverse <nl> + field com . google . common . collect . synchronized . synchronizedbimap . inverse <nl> + <nl> + # * * * * * false positives * * * * * <nl> + <nl> + # the runnable type is so generic that it produces too many false positives . <nl> + type java . lang . runnable <nl> + <nl> + field com . google . common . collect . abstractbimap . entryset . iterator . $ . entry com . google . common . collect . abstractbimap . entryset . iterator . $ . next . $ <nl> + field com . google . common . collect . abstractmapbasedmultimap . map <nl> + field com . google . common . collect . abstractmultimap . asmap com . google . common . collect . abstractmapbasedmultimap . navigableasmap <nl> + field com . google . common . collect . abstractmultimap . values com . google . common . collect . linkedlistmultimap . get . $ <nl> + field com . google . common . collect . abstractmultimap . values com . google . common . collect . multimaps . mapmultimap . get . $ <nl> + field com . google . common . collect . abstractmultiset . entryset com . google . common . collect . filteredentrymultimap . keys . entryset . $ <nl> + field com . google . common . collect . concurrenthashmultiset . countmap <nl> + field com . google . common . collect . immutablecollection . aslist <nl> + field com . google . common . collect . immutablerangemap . ranges <nl> + field com . google . common . collect . immutablerangeset . ranges <nl> + field com . google . common . collect . maps . filteredmapvalues . unfiltered <nl> + field com . google . common . collect . sets . subset . inputset <nl> + field com . google . common . collect . treetraverser . postordernode . childiterator <nl> + field com . google . common . collect . treetraverser . preorderiterator . stack <nl> + field com . google . common . util . concurrent . abstractfuture . listener . task <nl> + field com . google . common . util . concurrent . abstractservice . listeners <nl> + field java . util . abstractmap . keyset com . google . common . collect . abstractmapbasedmultimap . navigablekeyset <nl> + field java . util . abstractmap . keyset com . google . common . collect . maps . filteredentrynavigablemap . navigablekeyset . $ <nl> + field java . util . abstractmap . keyset com . google . common . collect . treerangemap . subrangemap . subrangemapasmap . keyset . $ <nl> + field java . util . abstractmap . valuescollection com . google . common . collect . treerangemap . subrangemap . subrangemapasmap . values . $ <nl> + outer com . google . common . collect . standardtable . row <nl> + outer com . google . common . collect . treebasedtable . treerow
public class quantilestest extends testcase { <nl> * dataset . <nl> * / <nl> private static void assertdatasetinorder ( collection < double > expected , double [ ] actual ) { <nl> + <nl> assertthat ( actual ) . hasvalueswithin ( 0 . 0 ) . of ( doubles . toarray ( expected ) ) ; <nl> }
public abstract class baseencoding { <nl> } <nl> } <nl>  <nl> + / * * <nl> + * determines whether the specified character sequence is a valid encoded string according to this <nl> + * encoding . <nl> + * / <nl> + @ checkreturnvalue <nl> + public final boolean candecode ( charsequence chars ) { <nl> + <nl> + try { <nl> + decodechecked ( chars ) ; <nl> + return true ; <nl> + } catch ( decodingexception badinput ) { <nl> + return false ; <nl> + } <nl> + } <nl> + <nl> / * * <nl> * decodes the specified character sequence , and returns the resulting { @ code byte [ ] } . <nl> * this is the inverse operation to { @ link # encode ( byte [ ] ) } . <nl>
public abstract class baseencoding { <nl> * @ throws illegalargumentexception if the input is not a valid encoded string according to this <nl> * encoding . <nl> * / <nl> - public final byte [ ] decode ( charsequence chars ) { <nl> + public final byte [ ] decode ( charsequence chars ) { <nl> try { <nl> return decodechecked ( chars ) ; <nl> } catch ( decodingexception badinput ) { <nl>
public abstract class baseencoding { <nl> * @ throws decodingexception if the input is not a valid encoded string according to this <nl> * encoding . <nl> * / final byte [ ] decodechecked ( charsequence chars ) <nl> - throws decodingexception { <nl> + throws decodingexception { <nl> chars = padding ( ) . trimtrailingfrom ( chars ) ; <nl> byte [ ] tmp = new byte [ maxdecodedsize ( chars . length ( ) ) ] ; <nl> int len = decodeto ( tmp , chars ) ;
import org . junit . runners . parameterized . parameters ; <nl> import java . util . arrays ; <nl> import java . util . collection ; <nl>  <nl> + @ androidincompatible <nl> + <nl> @ runwith ( parameterized . class ) <nl> public final class graphequalstest { <nl> private static final integer n1 = num ;
public class hashingtest extends testcase { <nl> } <nl> } <nl>  <nl> + @ androidincompatible <nl> / / goodfasthash ( 32 ) uses murmur3_32 . use the same epsilon bounds . <nl> public void testgoodfasthash32 ( ) { <nl> hashtestutils . check2bitavalanche ( hashing . goodfasthash ( 32 ) , num , num . 20 ) ;
public final class mapmaker extends genericmapmaker < object , object > { <nl> * expiration comes ) . we also want to avoid removing an entry prematurely if the entry was set <nl> * to the same value again . <nl> * / <nl> - timer timer = new timer ( ) { <nl> + settimeout ( new callback ( ) { <nl> @ override <nl> public void run ( ) { <nl> remove ( key , value ) ; <nl> } <nl> - } ; <nl> - timer . schedule ( ( int ) expirationmillis ) ; <nl> + } , ( int ) expirationmillis ) ; <nl> + } <nl> + <nl> + @ jsfunction <nl> + private interface callback { <nl> + void run ( ) ; <nl> } <nl>  <nl> + <nl> + @ jsmethod ( name = " settimeout " , namespace = jspackage . global ) <nl> + private static native void settimeout ( callback callback , int delayinms ) ; <nl> + <nl> @ override <nl> public v get ( object k ) { <nl> / / from customconcurrenthashmap <nl> mmm a / guava - gwt / src - super / com / google / common / collect / super / com / google / common / collect / platform . java <nl> ppp b / guava - gwt / src - super / com / google / common / collect / super / com / google / common / collect / platform . java <nl>
final class platform { <nl> return clone ; <nl> } <nl>  <nl> - private static native void resizearray ( object array , int newsize ) / * - { <nl> - array . length = newsize ; <nl> - } - * / ; <nl> - <nl> + private static void resizearray ( object array , int newsize ) { <nl> + ( ( nativearray ) array ) . setlength ( newsize ) ; <nl> + } <nl> + <nl> + <nl> + @ jstype ( isnative = true , name = " array " , namespace = jspackage . global ) <nl> + private interface nativearray { <nl> + @ jsproperty <nl> + void setlength ( int length ) ; <nl> + } <nl> + <nl> / * <nl> * regarding newsetformap ( ) and setfrommap : <nl> * <nl>
public abstract class abstractbimaptester < k , v > extends abstractmaptester < k , v > <nl> for ( entry < k , v > entry : entries ) { <nl> entry < v , k > reversed = reverseentry ( entry ) ; <nl> bimap < v , k > inv = getmap ( ) . inverse ( ) ; <nl> - assertfalse ( " inverse should not contain entry " + reversed , <nl> - inv . entryset ( ) . contains ( entry ) ) ; <nl> - assertfalse ( " inverse should not contain key " + entry . getvalue ( ) , <nl> - inv . containskey ( entry . getvalue ( ) ) ) ; <nl> - assertfalse ( " inverse should not contain value " + entry . getkey ( ) , <nl> - inv . containsvalue ( entry . getkey ( ) ) ) ; <nl> - assertnull ( " inverse should not return a mapping for key " + entry . getvalue ( ) , <nl> - getmap ( ) . get ( entry . getvalue ( ) ) ) ; <nl> + assertfalse ( <nl> + " inverse should not contain entry " + reversed , inv . entryset ( ) . contains ( reversed ) ) ; <nl> + assertfalse ( <nl> + " inverse should not contain key " + reversed . getkey ( ) , <nl> + inv . containskey ( reversed . getkey ( ) ) ) ; <nl> + assertfalse ( <nl> + " inverse should not contain value " + reversed . getvalue ( ) , <nl> + inv . containsvalue ( reversed . getvalue ( ) ) ) ; <nl> + / * <nl> + * <nl> + * someothervalue > pair . <nl> + * / <nl> + assertnull ( <nl> + " inverse should not return a mapping for key " + reversed . getkey ( ) , <nl> + inv . get ( reversed . getkey ( ) ) ) ; <nl> } <nl> } <nl>  <nl> mmm a / guava / src / com / google / common / reflect / typeresolver . java <nl> ppp b / guava / src / com / google / common / reflect / typeresolver . java <nl>
public class hashingtest extends testcase { <nl> assertequals ( " hashing . murmur3_128 ( 0 ) " , hashing . murmur3_128 ( ) . tostring ( ) ) ; <nl> } <nl>  <nl> + @ androidincompatible <nl> public void testmurmur3_32 ( ) { <nl> hashtestutils . check2bitavalanche ( hashing . murmur3_32 ( ) , num , num . 20 ) ; <nl> hashtestutils . checkavalanche ( hashing . murmur3_32 ( ) , num , num . 17 ) ;
public abstract class abstractfuture < v > implements listenablefuture < v > { <nl> * <nl> * < p > this is called exactly once , after all listeners have executed . by default it does nothing . <nl> * / <nl> + <nl> void done ( ) { } <nl>  <nl> / * * <nl> mmm a / guava / src / com / google / common / util / concurrent / abstracttransformfuture . java <nl> ppp b / guava / src / com / google / common / util / concurrent / abstracttransformfuture . java <nl>
public final class moreexecutors { <nl> / * * <nl> * an implementation of { @ link executorservice # invokeany } for { @ link listeningexecutorservice } <nl> * implementations . <nl> - * / static < t > t invokeanyimpl ( listeningexecutorservice executorservice , <nl> + * / <nl> + @ gwtincompatible ( " <nl> collection < ? extends callable < t > > tasks , boolean timed , long nanos ) <nl> throws interruptedexception , executionexception , timeoutexception { <nl> checknotnull ( executorservice ) ;
public class machashfunctiontest extends testcase { <nl> hashing . hmacmd5 ( badkey ) ; <nl> fail ( ) ; <nl> } catch ( illegalargumentexception expected ) { <nl> + } catch ( nullpointerexception toleratedonandroid ) { <nl> + <nl> } <nl> }
public class doublestest extends testcase { <nl> private static void checktryparse ( string input ) { <nl> double expected = referencetryparse ( input ) ; <nl> assertequals ( expected , doubles . tryparse ( input ) ) ; <nl> - assertequals ( expected ! = null , <nl> - doubles . floating_point_pattern . matcher ( input ) . matches ( ) ) ; <nl> + if ( expected ! = null & & ! doubles . floating_point_pattern . matcher ( input ) . matches ( ) ) { <nl> + <nl> + stringbuilder escapedinput = new stringbuilder ( ) ; <nl> + for ( char c : input . tochararray ( ) ) { <nl> + if ( c > = num x20 & & c < = num x7e ) { <nl> + escapedinput . append ( c ) ; <nl> + } else { <nl> + escapedinput . append ( string . format ( " \ \ u % 04x " , ( int ) c ) ) ; <nl> + } <nl> + } <nl> + fail ( " floating_point_pattern should have matched valid input < " + escapedinput + " > " ) ; <nl> + } <nl> } <nl>  <nl> @ gwtincompatible ( " doubles . tryparse " )
public final class jdkfutureadapters { <nl> return ; <nl> } <nl>  <nl> + <nl> adapterexecutor . execute ( new runnable ( ) { <nl> @ override <nl> public void run ( ) { <nl>
public abstract class abstractscheduledservice implements service { <nl> / / because the service does not monitor the state of the future so if the exception is not <nl> / / caught and forwarded to the service the task would stop executing but the service would <nl> / / have no idea . <nl> - service . notifyfailed ( e ) ; <nl> + <nl> + / / but it would help with some of these lock ordering issues . <nl> + schedulefailure = e ; <nl> } finally { <nl> lock . unlock ( ) ; <nl> } <nl> + / / call notifyfailed outside the lock to avoid lock ordering issues . <nl> + if ( schedulefailure ! = null ) { <nl> + service . notifyfailed ( schedulefailure ) ; <nl> + } <nl> } <nl>  <nl> / / n . b . only protect cancel and iscancelled because those are the only methods that are
public class futurestest extends testcase { <nl> } <nl> } <nl>  <nl> + @ gwtincompatible ( " testloghandler " ) <nl> + public void testallaslist_logging_seenexceptionupdateracebuggy ( ) throws exception { <nl> + final myexception sameinstance = new myexception ( ) ; <nl> + settablefuture < object > firstfuture = settablefuture . create ( ) ; <nl> + final settablefuture < object > secondfuture = settablefuture . create ( ) ; <nl> + listenablefuture < list < object > > bulkfuture = allaslist ( firstfuture , secondfuture ) ; <nl> + <nl> + bulkfuture . addlistener ( new runnable ( ) { <nl> + @ override <nl> + public void run ( ) { <nl> + / * <nl> + * firstfuture just completed , but aggregatefuture hasn ' t yet had time to record the <nl> + * exception in seenexceptions . when we complete secondfuture with the same exception , <nl> + * aggregatefuture will think that it ' s new . <nl> + * / <nl> + secondfuture . setexception ( sameinstance ) ; <nl> + } <nl> + } , directexecutor ( ) ) ; <nl> + firstfuture . setexception ( sameinstance ) ; <nl> + <nl> + try { <nl> + bulkfuture . get ( ) ; <nl> + fail ( ) ; <nl> + } catch ( executionexception expected ) { <nl> + asserttrue ( expected . getcause ( ) instanceof myexception ) ; <nl> + <nl> + assertequals ( 1 , combinedfutureloghandler . getstoredlogrecords ( ) . size ( ) ) ; <nl> + } <nl> + } <nl> + <nl> / * * <nl> * different exceptions happening on multiple futures with the same cause should not be logged . <nl> * /
public class futurestest extends testcase { <nl> asserttrue ( input . wasinterrupted ( ) ) ; <nl> } <nl>  <nl> + @ gwtincompatible ( " threads " ) <nl> + <nl> + public void testtransformasync_interruptpropagatestotransformingthread ( ) throws exception { <nl> + settablefuture < string > input = settablefuture . create ( ) ; <nl> + final countdownlatch infunction = new countdownlatch ( 1 ) ; <nl> + final countdownlatch shouldcompletefunction = new countdownlatch ( 1 ) ; <nl> + final countdownlatch gotexception = new countdownlatch ( 1 ) ; <nl> + asyncfunction < string , string > function = new asyncfunction < string , string > ( ) { <nl> + @ override <nl> + public listenablefuture < string > apply ( string s ) throws exception { <nl> + infunction . countdown ( ) ; <nl> + try { <nl> + shouldcompletefunction . await ( ) ; <nl> + } catch ( interruptedexception expected ) { <nl> + gotexception . countdown ( ) ; <nl> + throw expected ; <nl> + } <nl> + return immediatefuture ( " a " ) ; <nl> + } <nl> + } ; <nl> + <nl> + listenablefuture < string > futureresult = <nl> + futures . transformasync ( input , function , newsinglethreadexecutor ( ) ) ; <nl> + <nl> + input . set ( " value " ) ; <nl> + infunction . await ( ) ; <nl> + futureresult . cancel ( true ) ; <nl> + shouldcompletefunction . countdown ( ) ; <nl> + try { <nl> + futureresult . get ( ) ; <nl> + fail ( ) ; <nl> + } catch ( cancellationexception expected ) { } <nl> + <nl> + assertequals ( 1 , gotexception . getcount ( ) ) ; <nl> + / / gotexception . await ( ) ; <nl> + } <nl> + <nl> public void testtransformasync_cancelpropagatestoasyncoutput ( ) throws exception { <nl> listenablefuture < foo > immediate = futures . immediatefuture ( new foo ( ) ) ; <nl> final settablefuture < bar > secondary = settablefuture . create ( ) ; <nl>
public class futurestest extends testcase { <nl> } <nl> } <nl>  <nl> + @ gwtincompatible ( " threads " ) <nl> + <nl> + public void testcatchingasync_interruptpropagatestotransformingthread ( ) throws exception { <nl> + settablefuture < string > input = settablefuture . create ( ) ; <nl> + final countdownlatch infunction = new countdownlatch ( 1 ) ; <nl> + final countdownlatch shouldcompletefunction = new countdownlatch ( 1 ) ; <nl> + final countdownlatch gotexception = new countdownlatch ( 1 ) ; <nl> + asyncfunction < throwable , string > function = new asyncfunction < throwable , string > ( ) { <nl> + @ override <nl> + public listenablefuture < string > apply ( throwable t ) throws exception { <nl> + infunction . countdown ( ) ; <nl> + try { <nl> + shouldcompletefunction . await ( ) ; <nl> + } catch ( interruptedexception expected ) { <nl> + gotexception . countdown ( ) ; <nl> + throw expected ; <nl> + } <nl> + return immediatefuture ( " a " ) ; <nl> + } <nl> + } ; <nl> + <nl> + listenablefuture < string > futureresult = <nl> + futures . catchingasync ( input , exception . class , function , newsinglethreadexecutor ( ) ) ; <nl> + <nl> + input . setexception ( new exception ( ) ) ; <nl> + infunction . await ( ) ; <nl> + futureresult . cancel ( true ) ; <nl> + shouldcompletefunction . countdown ( ) ; <nl> + try { <nl> + futureresult . get ( ) ; <nl> + fail ( ) ; <nl> + } catch ( cancellationexception expected ) { } <nl> + <nl> + assertequals ( 1 , gotexception . getcount ( ) ) ; <nl> + / / gotexception . await ( ) ; <nl> + } <nl> + <nl> / / catching tests cloned from the old withfallback tests : <nl>  <nl> public void testcatching_inputdoesnotraiseexception ( ) throws exception {
public abstract class abstractfuture < v > implements listenablefuture < v > { <nl> } <nl>  <nl> private void notifyandclearlisteners ( ) { <nl> + <nl> for ( listener listener : listeners ) { <nl> listener . execute ( ) ; <nl> } <nl>
public final class predicates { <nl> } <nl>  <nl> @ override public string tostring ( ) { <nl> - return p . tostring ( ) + " ( " + f . tostring ( ) + " ) " ; <nl> + <nl> + return p + " ( " + f + " ) " ; <nl> } <nl>  <nl> private static final long serialversionuid = num ; <nl> mmm a / guava / src / com / google / common / base / functions . java <nl> ppp b / guava / src / com / google / common / base / functions . java <nl>
public final class functions { <nl> } <nl>  <nl> @ override public string tostring ( ) { <nl> - return " formap ( " + map + " , defaultvalue = " + defaultvalue + " ) " ; <nl> + <nl> + return " functions . formap ( " + map + " , defaultvalue = " + defaultvalue + " ) " ; <nl> } <nl>  <nl> private static final long serialversionuid = num ; <nl>
public final class functions { <nl> } <nl>  <nl> @ override public string tostring ( ) { <nl> + <nl> return g + " ( " + f + " ) " ; <nl> } <nl>  <nl>
public final class predicates { <nl> } <nl>  <nl> @ override public string tostring ( ) { <nl> - return p . tostring ( ) + " ( " + f . tostring ( ) + " ) " ; <nl> + <nl> + return p + " ( " + f + " ) " ; <nl> } <nl>  <nl> private static final long serialversionuid = num ;
public class servicemanagertest extends testcase { <nl> servicemanager . startasync ( ) . awaithealthy ( ) ; <nl> immutablemap < service , long > startuptimes = servicemanager . startuptimes ( ) ; <nl> assertequals ( 2 , startuptimes . size ( ) ) ; <nl> - assertthat ( startuptimes . get ( a ) ) . isinclusivelyinrange ( 150 , long . max_value ) ; <nl> + <nl> + asserttrue ( startuptimes . get ( a ) > = num ) ; <nl> / / service b startup takes at least num millis , but starting the timer is delayed by at least <nl> / / num milliseconds . so in a perfect world the timing would be num - 150 = 203ms , but since either <nl> / / of our sleep calls can be arbitrarily delayed we should just assert that there is a time
import java . util . map ; <nl> * <nl> * @ author kevin bourrillion <nl> * / <nl> + / * <nl> + * <nl> + * under jdk7 <nl> + * / <nl> public class openjdk6maptests extends testsformapsinjavautil { <nl> public static test suite ( ) { <nl> return new openjdk6maptests ( ) . alltests ( ) ; <nl>
public abstract class ratelimiter { <nl> return create ( sleepingstopwatch . createfromsystemtimer ( ) , permitspersecond ) ; <nl> } <nl>  <nl> + / * <nl> + * <nl> + * overloads follow the usual convention : foo ( int ) , foo ( int , sleepingstopwatch ) <nl> + * / <nl> @ visiblefortesting <nl> static ratelimiter create ( sleepingstopwatch stopwatch , double permitspersecond ) { <nl> ratelimiter ratelimiter = new smoothbursty ( stopwatch , num . 0 / * maxburstseconds * / ) ; <nl>
<nl> < inherits name = " com . google . common . primitives . primitives " / > <nl> < inherits name = " com . google . common . util . concurrent . concurrent " / > <nl> < inherits name = " com . google . common . xml . xml " / > <nl> + < inherits name = " com . google . thirdparty . publicsuffix . publicsuffixpatterns " / > <nl> + < inherits name = " com . google . thirdparty . publicsuffix . publicsuffixtype " / > <nl> + < ! - - <nl> + <nl> + particular , should we be including user in the . gwt . xml of some of our <nl> + modules ? <nl> + - - > <nl> < inherits name = " com . google . gwt . user . user " / > <nl>  <nl> < ! - - com . google . common . testing . testing is located in <nl> mmm a / guava - gwt / test / com / google / common / guavatests . gwt . xml <nl> ppp b / guava - gwt / test / com / google / common / guavatests . gwt . xml <nl>
public abstract class converter < a , b > implements function < a , b > { <nl> * <nl> * < p > the returned converter is serializable if { @ code this } converter is . <nl> * / <nl> + <nl> public converter < b , a > reverse ( ) { <nl> - return new reverseconverter < a , b > ( this ) ; <nl> + converter < b , a > result = reverse ; <nl> + return ( result = = null ) ? reverse = new reverseconverter < a , b > ( this ) : result ; <nl> } <nl>  <nl> private static final class reverseconverter < a , b >
public abstract class cacheloader < k , v > { <nl> return new suppliertocacheloader < v > ( supplier ) ; <nl> } <nl>  <nl> + <nl> + <nl> private static final class suppliertocacheloader < v > <nl> extends cacheloader < object , v > implements serializable { <nl> private final supplier < v > computingsupplier ; <nl>
public abstract class cacheloader < k , v > { <nl> return new suppliertocacheloader < v > ( supplier ) ; <nl> } <nl>  <nl> + <nl> + <nl> / * * <nl> * returns a { @ code cacheloader } which wraps { @ code loader } , executing calls to <nl> * { @ link cacheloader # reload } using { @ code executor } . <nl>
public abstract class converter < a , b > implements function < a , b > { <nl>  <nl> b correcteddoforward ( a a ) { <nl> if ( handlenullautomatically ) { <nl> + <nl> return a = = null ? null : checknotnull ( doforward ( a ) ) ; <nl> } else { <nl> return doforward ( a ) ; <nl>
public abstract class converter < a , b > implements function < a , b > { <nl>  <nl> a correcteddobackward ( b b ) { <nl> if ( handlenullautomatically ) { <nl> + <nl> return b = = null ? null : checknotnull ( dobackward ( b ) ) ; <nl> } else { <nl> return dobackward ( b ) ; <nl>
public abstract class immutablesortedset < e > <nl> / / which overrides immutableset & which immutablesortedset extends . <nl> / / it is necessary here because otherwise the builder ( ) method <nl> / / would be inherited from the emulated immutableset . <nl> + <nl> @ deprecated public static < e > immutablesortedset . builder < e > builder ( ) { <nl> throw new unsupportedoperationexception ( ) ; <nl> } <nl> mmm a / guava - testlib / src / com / google / common / testing / platform . java <nl> ppp b / guava - testlib / src / com / google / common / testing / platform . java <nl>
<nl> < artifactid > javax . inject < / artifactid > <nl> < optional > true < / optional > < ! - - needed only for annotations - - > <nl> < / dependency > <nl> + < ! - - <nl> < / dependencies > <nl> < build > <nl> < plugins > <nl>
<nl> < plugin > <nl> < artifactid > maven - source - plugin < / artifactid > <nl> < / plugin > <nl> + < ! - - <nl> < plugin > <nl> - < artifactid > maven - javadoc - plugin < / artifactid > <nl> + < artifactid > maven - dependency - plugin < / artifactid > <nl> + < executions > <nl> + < execution > <nl> + < id > unpack - jdk - sources < / id > <nl> + < phase > site < / phase > <nl> + < goals > < goal > unpack - dependencies < / goal > < / goals > <nl> + < configuration > <nl> + < includeartifactids > srczip < / includeartifactids > <nl> + < overwrite > true < / overwrite > <nl> + < outputdirectory > $ { project . build . directory } / jdk - sources < / outputdirectory > <nl> + < silent > false < / silent > <nl> + < / configuration > <nl> + < / execution > <nl> + < / executions > <nl> < / plugin > <nl> < plugin > <nl> < groupid > org . codehaus . mojo < / groupid > <nl>
<nl> < links > <nl> < link > http : / / jsr - 305 . googlecode . com / svn / trunk / javadoc < / link > <nl> < / links > <nl> + < ! - - <nl> + < sourcepath > $ { project . build . sourcedirectory } : $ { project . build . directory } / jdk - sources < / sourcepath > <nl> + < subpackages > com . google . common < / subpackages > <nl> < / configuration > <nl> < executions > <nl> < execution > <nl>
public final class hashing { <nl> } <nl>  <nl> / / lazy initialization holder class idiom . <nl> + <nl>  <nl> / * * <nl> * assigns to { @ code hashcode } a " bucket " in the range { @ code [ 0 , buckets ) } , in a uniform
<nl> < / execution > <nl> < / executions > <nl> < / plugin > <nl> + < ! - - <nl> < plugin > <nl> < groupid > org . codehaus . mojo < / groupid > <nl> < artifactid > build - helper - maven - plugin < / artifactid > <nl>
import javax . annotation . nullable ; <nl> * @ author sven mawson <nl> * @ since num . 0 <nl> * / <nl> - public final class listenablefuturetask < v > extends futuretask < v > <nl> + public class listenablefuturetask < v > extends futuretask < v > <nl> implements listenablefuture < v > { <nl> + <nl> + / / would be nice to make it final to avoid unintended usage . <nl>  <nl> / / the execution list to hold our listeners . <nl> private final executionlist executionlist = new executionlist ( ) ; <nl>
public enum caseformat { <nl> * behavior of this method is undefined but we make a reasonable effort at converting anyway . <nl> * / <nl> public string to ( caseformat format , string s ) { <nl> - if ( format = = null ) { <nl> - throw new nullpointerexception ( ) ; <nl> - } <nl> - if ( s = = null ) { <nl> - throw new nullpointerexception ( ) ; <nl> - } <nl> + checknotnull ( format ) ; <nl> + checknotnull ( s ) ; <nl>  <nl> if ( format = = this ) { <nl> return s ; <nl> } <nl>  <nl> - / * optimize cases where no camel conversion is required * / <nl> + <nl> + <nl> + / / optimize cases where no camel conversion is required <nl> switch ( this ) { <nl> case lower_hyphen : <nl> switch ( format ) { <nl>
public class nullpointertestertest extends testcase { <nl> shouldpass ( instance , visibility . public ) ; <nl> } <nl>  <nl> + <nl> + <nl> private static void shouldfail ( object instance , visibility visibility ) { <nl> try { <nl> new nullpointertester ( ) . testinstancemethods ( instance , visibility ) ; <nl>
final class murmur3_32hashfunction extends abstractstreaminghashfunction impleme <nl> @ override public hashcode hashint ( int input ) { <nl> int k1 = mixk1 ( input ) ; <nl> int h1 = mixh1 ( seed , k1 ) ; <nl> + <nl> return fmix ( h1 , ints . bytes ) ; <nl> } <nl>  <nl> + @ override public hashcode hashlong ( long input ) { <nl> + int low = ( int ) input ; <nl> + int high = ( int ) ( input > > > num ) ; <nl> + <nl> + int k1 = mixk1 ( low ) ; <nl> + int h1 = mixh1 ( seed , k1 ) ; <nl> + <nl> + k1 = mixk1 ( high ) ; <nl> + h1 = mixh1 ( h1 , k1 ) ; <nl> + <nl> + return fmix ( h1 , longs . bytes ) ; <nl> + } <nl> + <nl> + <nl> + <nl> private static int mixk1 ( int k1 ) { <nl> k1 * = c1 ; <nl> k1 = integer . rotateleft ( k1 , num ) ;
<nl> + / * <nl> + * copyright ( c ) num the guava authors <nl> + * <nl> + * licensed under the apache license , version num . 0 ( the " license " ) ; <nl> + * you may not use this file except in compliance with the license . <nl> + * you may obtain a copy of the license at <nl> + * <nl> + * http : / / www . apache . org / licenses / license - 2 . 0 <nl> + * <nl> + * unless required by applicable law or agreed to in writing , software <nl> + * distributed under the license is distributed on an " as is " basis , <nl> + * without warranties or conditions of any kind , either express or implied . <nl> + * see the license for the specific language governing permissions and <nl> + * limitations under the license . <nl> + * / <nl> + <nl> + package com . google . common . collect ; <nl> + <nl> + / * * <nl> + * even though { @ link forwardingimmutableset } cannot be instantiated , we still <nl> + * need a custom field serializer . <nl> + * <nl> + * @ author hayward chan <nl> + * / <nl> + public final class forwardingimmutableset_customfieldserializer { }
<nl> + / * <nl> + * copyright ( c ) num the guava authors <nl> + * <nl> + * licensed under the apache license , version num . 0 ( the " license " ) ; <nl> + * you may not use this file except in compliance with the license . <nl> + * you may obtain a copy of the license at <nl> + * <nl> + * http : / / www . apache . org / licenses / license - 2 . 0 <nl> + * <nl> + * unless required by applicable law or agreed to in writing , software <nl> + * distributed under the license is distributed on an " as is " basis , <nl> + * without warranties or conditions of any kind , either express or implied . <nl> + * see the license for the specific language governing permissions and <nl> + * limitations under the license . <nl> + * / <nl> + <nl> + package com . google . common . collect ; <nl> + <nl> + / * * <nl> + * even though { @ link forwardingimmutablelist } cannot be instantiated , we still <nl> + * need a custom field serializer . <nl> + * <nl> + * @ author hayward chan <nl> + * / <nl> + public final class forwardingimmutablelist_customfieldserializer { } <nl> mmm / dev / null <nl> ppp b / guava - gwt / src / com / google / common / collect / immutableaslist_customfieldserializer . java <nl>
<nl> + / * <nl> + * copyright ( c ) num the guava authors <nl> + * <nl> + * licensed under the apache license , version num . 0 ( the " license " ) ; <nl> + * you may not use this file except in compliance with the license . <nl> + * you may obtain a copy of the license at <nl> + * <nl> + * http : / / www . apache . org / licenses / license - 2 . 0 <nl> + * <nl> + * unless required by applicable law or agreed to in writing , software <nl> + * distributed under the license is distributed on an " as is " basis , <nl> + * without warranties or conditions of any kind , either express or implied . <nl> + * see the license for the specific language governing permissions and <nl> + * limitations under the license . <nl> + * / <nl> + <nl> + package com . google . common . collect ; <nl> + <nl> + / * * <nl> + * even though { @ link immutableaslist } cannot be instantiated , we still need <nl> + * a custom field serializer . <nl> + * <nl> + * @ author hayward chan <nl> + * / <nl> + public final class immutableaslist_customfieldserializer { } <nl> mmm a / guava / src / com / google / common / collect / forwardingimmutablelist . java <nl> ppp b / guava / src / com / google / common / collect / forwardingimmutablelist . java <nl>
public class localloadingcachetest extends testcase { <nl> assertequals ( empty_stats , cache . stats ( ) ) ; <nl> } <nl>  <nl> - public void testdisablestats ( ) { <nl> + public void testnostats ( ) { <nl> cachebuilder < object , object > builder = createcachebuilder ( ) <nl> . concurrencylevel ( 1 ) <nl> - . maximumsize ( 2 ) <nl> - . disablestats ( ) ; <nl> + . maximumsize ( 2 ) ; <nl> + <nl> + builder . statscountersupplier = cachebuilder . null_stats_counter ; <nl> localloadingcache < object , object > cache = makecache ( builder , identityloader ( ) ) ; <nl> assertequals ( empty_stats , cache . stats ( ) ) ; <nl>  <nl> mmm a / guava / src / com / google / common / cache / cachebuilder . java <nl> ppp b / guava / src / com / google / common / cache / cachebuilder . java <nl>
public final class cachebuilder < k , v > { <nl> } <nl>  <nl> / * * <nl> - * disable the accumulation of { @ link cachestats } during the operation of the cache . <nl> + * enable the accumulation of { @ link cachestats } during the operation of the cache . without this <nl> + * { @ link cache # stats } will return zero for all statistics . note that recording stats requires <nl> + * bookkeeping to be performed with each operation , and thus imposes a performance penalty on <nl> + * cache operation . <nl> + * <nl> + * @ since num . 0 ( previously , stats collection was automatic ) <nl> * / <nl> - cachebuilder < k , v > disablestats ( ) { <nl> - checkstate ( statscountersupplier = = cache_stats_counter ) ; <nl> - statscountersupplier = null_stats_counter ; <nl> + public cachebuilder < k , v > recordstats ( ) { <nl> + <nl> + statscountersupplier = cache_stats_counter ; <nl> return this ; <nl> }
import java . util . arrays ; <nl> public class filebackedoutputstreamtest extends iotestcase { <nl>  <nl> public void testthreshold ( ) throws exception { <nl> - testthreshold ( 0 , num , true ) ; <nl> - testthreshold ( 10 , num , true ) ; <nl> - testthreshold ( 100 , num , true ) ; <nl> - testthreshold ( 1000 , num , true ) ; <nl> - testthreshold ( 0 , num , false ) ; <nl> - testthreshold ( 10 , num , false ) ; <nl> - testthreshold ( 100 , num , false ) ; <nl> - testthreshold ( 1000 , num , false ) ; <nl> + testthreshold ( 0 , num , true , false ) ; <nl> + testthreshold ( 10 , num , true , false ) ; <nl> + testthreshold ( 100 , num , true , false ) ; <nl> + testthreshold ( 1000 , num , true , false ) ; <nl> + testthreshold ( 0 , num , false , false ) ; <nl> + testthreshold ( 10 , num , false , false ) ; <nl> + testthreshold ( 100 , num , false , false ) ; <nl> + testthreshold ( 1000 , num , false , false ) ; <nl> } <nl>  <nl> - private void testthreshold ( int filethreshold , int datasize , boolean singlebyte ) <nl> - throws exception { <nl> + <nl> + / / on finalize <nl> + <nl> + public void testthreshold_resetonfinalize ( ) throws exception { <nl> + testthreshold ( 0 , num , true , true ) ; <nl> + testthreshold ( 10 , num , true , true ) ; <nl> + testthreshold ( 100 , num , true , true ) ; <nl> + testthreshold ( 1000 , num , true , true ) ; <nl> + testthreshold ( 0 , num , false , true ) ; <nl> + testthreshold ( 10 , num , false , true ) ; <nl> + testthreshold ( 100 , num , false , true ) ; <nl> + testthreshold ( 1000 , num , false , true ) ; <nl> + } <nl> + <nl> + private void testthreshold ( int filethreshold , int datasize , boolean singlebyte , <nl> + boolean resetonfinalize ) throws ioexception { <nl> byte [ ] data = newprefilledbytearray ( datasize ) ; <nl> - filebackedoutputstream out = new filebackedoutputstream ( filethreshold ) ; <nl> + filebackedoutputstream out = new filebackedoutputstream ( filethreshold , resetonfinalize ) ; <nl> inputsupplier < inputstream > supplier = out . getsupplier ( ) ; <nl> int chunk1 = math . min ( datasize , filethreshold ) ; <nl> int chunk2 = datasize - chunk1 ;
import com . google . common . annotations . visiblefortesting ; <nl> / * * <nl> * utilities for { @ code double } primitives . some of these are exposed in jdk num , <nl> * but we can ' t depend on them there . <nl> - * <nl> + * <nl> * @ author louis wasserman <nl> * / <nl> final class doubleutils { <nl> + <nl> + <nl> private doubleutils ( ) { <nl> } <nl>  <nl>
public abstract class optional < t > implements baseholder < t > , serializable { <nl>  <nl> private optional ( ) { } <nl>  <nl> + / * * <nl> + * returns { @ code true } if this holder contains a ( non - null ) instance . <nl> + * / <nl> + public abstract boolean ispresent ( ) ; <nl> + <nl> + <nl> + <nl> + / * * <nl> + * returns the contained instance , which must be present . if the instance might be <nl> + * absent , use { @ link # or ( object ) } or { @ link # ornull } instead . <nl> + * <nl> + * @ throws illegalstateexception if the instance is absent ( { @ link # ispresent } returns <nl> + * { @ code false } ) <nl> + * / <nl> + public abstract t get ( ) ; <nl> + <nl> + / * * <nl> + * returns the contained instance if it is present ; { @ code defaultvalue } otherwise . if <nl> + * no default value should be required because the instance is known to be present , use <nl> + * { @ link # get ( ) } instead . for a default value of { @ code null } , use { @ link # ornull } . <nl> + * / <nl> + public abstract t or ( t defaultvalue ) ; <nl> + <nl> / * * <nl> * returns this { @ code optional } if it has a value present ; { @ code secondchoice } <nl> * otherwise . <nl>
public final class discretedomains { <nl> private static final long serialversionuid = num ; <nl> } <nl>  <nl> + / * * <nl> + * returns the discrete domain for values of type { @ code biginteger } . <nl> + * / <nl> + <nl> static discretedomain < biginteger > bigintegers ( ) { <nl> - return bigintegers . instance ; <nl> + return bigintegerdomain . instance ; <nl> } <nl>  <nl> - private static final class bigintegers extends discretedomain < biginteger > <nl> + private static final class bigintegerdomain extends discretedomain < biginteger > <nl> implements serializable { <nl> - private static final bigintegers instance = new bigintegers ( ) ; <nl> + private static final bigintegerdomain instance = new bigintegerdomain ( ) ; <nl>  <nl> private static final biginteger min_long = <nl> biginteger . valueof ( long . min_value ) ;
public class internetdomainname { <nl>  <nl> private static final string dot_regex = " \ \ . " ; <nl>  <nl> + / * * <nl> + * maximum parts ( labels ) in a domain name . <nl> + * <nl> + * < p > <nl> + * / <nl> + private static final int max_parts = num ; <nl> + <nl> + / * * <nl> + * maximum length of a full domain name , including separators , and <nl> + * leaving room for the root label . see <nl> + * < a href = " http : / / www . ietf . org / rfc / rfc2181 . txt " > rfc num < / a > part num . <nl> + * / <nl> + private static final int max_length = num ; <nl> + <nl> + / * * <nl> + * maximum size of a single part of a domain name . see <nl> + * < a href = " http : / / www . ietf . org / rfc / rfc2181 . txt " > rfc num < / a > part num . <nl> + * / <nl> + private static final int max_domain_part_length = num ; <nl> + <nl> / * * <nl> * the full domain name , converted to lower case . <nl> * / <nl>
public class internetdomainname { <nl>  <nl> private static final string dot_regex = " \ \ . " ; <nl>  <nl> + / * * <nl> + * maximum parts ( labels ) in a domain name . <nl> + * <nl> + * < p > <nl> + * / <nl> + private static final int max_parts = num ; <nl> + <nl> + / * * <nl> + * maximum length of a full domain name , including separators , and <nl> + * leaving room for the root label . see <nl> + * < a href = " http : / / www . ietf . org / rfc / rfc2181 . txt " > rfc num < / a > part num . <nl> + * / <nl> + private static final int max_length = num ; <nl> + <nl> + / * * <nl> + * maximum size of a single part of a domain name . see <nl> + * < a href = " http : / / www . ietf . org / rfc / rfc2181 . txt " > rfc num < / a > part num . <nl> + * / <nl> + private static final int max_domain_part_length = num ; <nl> + <nl> / * * <nl> * the full domain name , converted to lower case . <nl> * / <nl>
class customconcurrenthashmap < k , v > extends abstractmap < k , v > <nl> * / <nl> boolean advanceto ( referenceentry < k , v > entry ) { <nl> k key = entry . getkey ( ) ; <nl> - v value = getlivevalue ( entry ) ; <nl> - if ( key ! = null & & value ! = null ) { <nl> + <nl> + v value = entry . getvaluereference ( ) . get ( ) ; <nl> + if ( key ! = null & & value ! = null & & <nl> + ! ( expires ( ) & & isexpired ( entry ) ) ) { <nl> nextexternal = new writethroughentry ( key , value ) ; <nl> return true ; <nl> } else {
import java . util . concurrent . timeunit ; <nl> * / <nl> public class mapmaker extends genericmapmaker < object , object > { <nl>  <nl> + <nl> + / / this will all be replaced soon anyways , so leaving it as is for now . <nl> private static class expiringcomputingmap < k , v > <nl> extends linkedhashmap < k , v > implements concurrentmap < k , v > { <nl> private final long expirationmillis ; <nl> mmm / dev / null <nl> ppp b / src / com / google / common / base / enums . java <nl>
public abstract class forwardingfuture < v > extends forwardingobject <nl> throws interruptedexception , executionexception , timeoutexception { <nl> return delegate ( ) . get ( timeout , unit ) ; <nl> } <nl> + <nl> + <nl> + / * * <nl> + * a simplified version of { @ link forwardingfuture } where subclasses <nl> + * can pass in an already constructed { @ link future } as the delegate . <nl> + * <nl> + * @ since num <nl> + * / <nl> + @ beta <nl> + public abstract static class simpleforwardingfuture < v > <nl> + extends forwardingfuture < v > { <nl> + private final future < v > delegate ; <nl> + <nl> + protected simpleforwardingfuture ( future < v > delegate ) { <nl> + this . delegate = preconditions . checknotnull ( delegate ) ; <nl> + } <nl> + <nl> + @ override <nl> + protected final future < v > delegate ( ) { <nl> + return delegate ; <nl> + } <nl> + <nl> + } <nl> } <nl> mmm a / src / com / google / common / util / concurrent / forwardinglistenablefuture . java <nl> ppp b / src / com / google / common / util / concurrent / forwardinglistenablefuture . java <nl>
public abstract class forwardinglistenablefuture < v > extends forwardingfuture < v > <nl> public void addlistener ( runnable listener , executor exec ) { <nl> delegate ( ) . addlistener ( listener , exec ) ; <nl> } <nl> + <nl> + <nl> + / * * <nl> + * a simplified version of { @ link forwardinglistenablefuture } where subclasses <nl> + * can pass in an already constructed { @ link listenablefuture } <nl> + * as the delegate . <nl> + * <nl> + * @ since num <nl> + * / <nl> + @ beta <nl> + public abstract static class simpleforwardinglistenablefuture < v > <nl> + extends forwardinglistenablefuture < v > { <nl> + private final listenablefuture < v > delegate ; <nl> + <nl> + protected simpleforwardinglistenablefuture ( listenablefuture < v > delegate ) { <nl> + this . delegate = preconditions . checknotnull ( delegate ) ; <nl> + } <nl> + <nl> + @ override <nl> + protected final listenablefuture < v > delegate ( ) { <nl> + return delegate ; <nl> + } <nl> + } <nl> }
<nl> + / * <nl> + * copyright ( c ) num google inc . <nl> + * <nl> + * licensed under the apache license , version num . 0 ( the " license " ) ; <nl> + * you may not use this file except in compliance with the license . <nl> + * you may obtain a copy of the license at <nl> + * <nl> + * http : / / www . apache . org / licenses / license - 2 . 0 <nl> + * <nl> + * unless required by applicable law or agreed to in writing , software <nl> + * distributed under the license is distributed on an " as is " basis , <nl> + * without warranties or conditions of any kind , either express or implied . <nl> + * see the license for the specific language governing permissions and <nl> + * limitations under the license . <nl> + * / <nl> + <nl> + package com . google . common . util . concurrent ; <nl> + <nl> + import com . google . common . annotations . beta ; <nl> + import com . google . common . base . preconditions ; <nl> + <nl> + import java . util . concurrent . timeunit ; <nl> + import java . util . concurrent . timeoutexception ; <nl> + <nl> + / * * <nl> + * a future which forwards all its method calls to another future . subclasses <nl> + * should override one or more methods to modify the behavior of the backing <nl> + * future as desired per the < a href = <nl> + * " http : / / en . wikipedia . org / wiki / decorator_pattern " > decorator pattern < / a > . <nl> + * <nl> + * < p > most subclasses can simply extend { @ link simpleforwadingcheckedfuture } . <nl> + * <nl> + * @ param < v > the result type returned by this future ' s { @ code get } method <nl> + * @ param < x > the type of the exception thrown by the future ' s <nl> + * { @ code checkedget } method <nl> + * <nl> + * @ author azana @ google . com ( anthony zana ) <nl> + * @ since num <nl> + * / <nl> + @ beta <nl> + public abstract class forwardingcheckedfuture < v , x extends exception > <nl> + extends forwardinglistenablefuture < v > implements checkedfuture < v , x > { <nl> + <nl> + @ override <nl> + public v checkedget ( ) throws x { <nl> + return delegate ( ) . checkedget ( ) ; <nl> + } <nl> + <nl> + @ override <nl> + public v checkedget ( long timeout , timeunit unit ) throws timeoutexception , x { <nl> + return delegate ( ) . checkedget ( timeout , unit ) ; <nl> + } <nl> + <nl> + @ override <nl> + protected abstract checkedfuture < v , x > delegate ( ) ; <nl> + <nl> + <nl> + / * * <nl> + * a simplified version of { @ link forwardingcheckedfuture } where subclasses <nl> + * can pass in an already constructed { @ link checkedfuture } as the delegate . <nl> + * <nl> + * @ since num <nl> + * / <nl> + @ beta <nl> + public abstract static class simpleforwadingcheckedfuture < <nl> + v , x extends exception > extends forwardingcheckedfuture < v , x > { <nl> + private final checkedfuture < v , x > delegate ; <nl> + <nl> + protected simpleforwadingcheckedfuture ( checkedfuture < v , x > delegate ) { <nl> + this . delegate = preconditions . checknotnull ( delegate ) ; <nl> + } <nl> + <nl> + @ override <nl> + protected final checkedfuture < v , x > delegate ( ) { <nl> + return delegate ; <nl> + } <nl> + } <nl> + }
class computingconcurrenthashmap < k , v > extends customconcurrenthashmap < k , v > <nl> try { <nl> / / try again - - an entry could have materialized in the interim . <nl> expireentries ( ) ; <nl> + <nl> + processpendingcleanup ( ) ; <nl>  <nl> / / getfirst , but remember the index <nl> atomicreferencearray < referenceentry < k , v > > table = this . table ; <nl>
class computingconcurrenthashmap < k , v > extends customconcurrenthashmap < k , v > <nl>  <nl> v compute ( k key , int hash ) { <nl> outer : while ( true ) { <nl> + <nl> referenceentry < k , v > entry = getliveentry ( key , hash ) ; <nl> if ( entry ! = null ) { <nl> / / current entry is live , and read was already recorded <nl> - return entry . getvaluereference ( ) . get ( ) ; <nl> + v value = entry . getvaluereference ( ) . get ( ) ; <nl> + if ( value ! = null ) { <nl> + return value ; <nl> + } <nl> } <nl>  <nl> / / entry is absent , invalid , or computing <nl>
<nl> + # ! / bin / bash <nl> + # <nl> + # this script checks the java version and bails if it ' s less <nl> + # than java6 ( because we use @ override annotations on interface <nl> + # overriding methods . it then proceeds to do a maven build that <nl> + # first cleans , then builds the normal lifecycle through compilation <nl> + # unit testing ( if available ) up to packaging . it then packages <nl> + # the source , javadocs , and maven site . it then signs the <nl> + # artifacts with whatever pgp signature is the default of the <nl> + # user executing it , and then deploys to the repository contained <nl> + # in the distributionmanagement section of the pom . <nl> + # <nl> + # author : cgruber @ google . com ( christian edward gruber ) <nl> + # <nl> + if [ [ - n $ { java_home } ] ] ; then <nl> + java_cmd = $ { java_home } / bin / java <nl> + else <nl> + java_cmd = java <nl> + fi <nl> + java_version = " $ ( $ { java_cmd } - version num > & 1 | grep - e ' java version ' | awk ' { print $ 3 } ' ) " <nl> + <nl> + # this test sucks , but it ' s short term <nl> + # <nl> + greater_than_java5 = " $ ( echo $ { java_version } | grep - e ' ^ " 1 . [ 67 ] ' ) " <nl> + <nl> + if [ [ - z $ { greater_than_java5 } ] ] ; then <nl> + echo " your java version is $ { java_version } . " <nl> + echo " you must use at least a java num jvm to build and deploy this software . " <nl> + exit num <nl> + else <nl> + echo " building with java $ { java_version } " <nl> + fi <nl> + <nl> + if [ [ $ # > num ] ] ; then <nl> + params + = " - dgpg . keyname = $ { 1 } " <nl> + fi <nl> + cmd = " mvn clean package source : jar site : jar javadoc : jar gpg : sign deploy $ { params } " <nl> + echo " executing $ { cmd } " <nl> + $ { cmd }
<nl> + # ! / bin / bash <nl> + # <nl> + # this script checks the java version and bails if it ' s less <nl> + # than java6 ( because we use @ override annotations on interface <nl> + # overriding methods . it then proceeds to do a maven build that <nl> + # first cleans , then builds the normal lifecycle through compilation <nl> + # unit testing ( if available ) up to packaging . it then packages <nl> + # the source , javadocs , and maven site . it then signs the <nl> + # artifacts with whatever pgp signature is the default of the <nl> + # user executing it , and then deploys to the repository contained <nl> + # in the distributionmanagement section of the pom . <nl> + # <nl> + # author : cgruber @ google . com ( christian edward gruber ) <nl> + # <nl> + if [ [ - n $ { java_home } ] ] ; then <nl> + java_cmd = $ { java_home } / bin / java <nl> + else <nl> + java_cmd = java <nl> + fi <nl> + java_version = " $ ( $ { java_cmd } - version num > & 1 | grep - e ' java version ' | awk ' { print $ 3 } ' ) " <nl> + <nl> + # this test sucks , but it ' s short term <nl> + # <nl> + greater_than_java5 = " $ ( echo $ { java_version } | grep - e ' ^ " 1 . [ 67 ] ' ) " <nl> + <nl> + if [ [ - z $ { greater_than_java5 } ] ] ; then <nl> + echo " your java version is $ { java_version } . " <nl> + echo " you must use at least a java num jvm to build and deploy this software . " <nl> + exit num <nl> + else <nl> + echo " building with java $ { java_version } " <nl> + fi <nl> + mvn clean package source : jar site : jar javadoc : jar gpg : sign deploy
class socketservertest { <nl> * buffered receive . <nl> * / <nl> @ test <nl> + @ disabled <nl> def remoteclosewithoutbufferedreceives ( ) : unit = { <nl> verifyremoteclosewithbufferedreceives ( numcomplete = num , hasincomplete = false ) <nl> } <nl>
class socketservertest { <nl> * the channel must be closed after pending receives are processed . <nl> * / <nl> @ test <nl> + @ disabled <nl> def closingchannelwithbufferedreceives ( ) : unit = { <nl> verifyremoteclosewithbufferedreceives ( numcomplete = num , hasincomplete = false , makeclosing = true ) <nl> }
public class listvaluestore <nl> } <nl> } <nl>  <nl> - return oldvalue ; <nl> + <nl> + / / would not need the actual value at all ; the changelogging wrapper would not call this function <nl> + return null ; <nl> } <nl>  <nl> / / this function assumes the addedvalue is not null ; callers should check null themselves
import java . util . list ; <nl> import org . apache . kafka . metadata . apimessageandversion ; <nl>  <nl>  <nl> + / * * <nl> + * the no - op snapshot writer which does nothing . <nl> + * <nl> + * <nl> + * implementation of the snapshot writer . <nl> + * / <nl> public final class noopsnapshotwriter implements snapshotwriter { <nl> private final long epoch ; <nl>  <nl> mmm a / metadata / src / main / java / org / apache / kafka / controller / quorumcontroller . java <nl> ppp b / metadata / src / main / java / org / apache / kafka / controller / quorumcontroller . java <nl>
public class sslutils { <nl> public static sslcontextfactory createclientsidesslcontextfactory ( workerconfig config ) { <nl> map < string , object > sslconfigvalues = config . valueswithprefixallornothing ( " listeners . https . " ) ; <nl>  <nl> - final sslcontextfactory . client ssl = new sslcontextfactory . client ( ) ; <nl> + / / override this method in order to avoid running into <nl> + / / https : / / github . com / eclipse / jetty . project / issues / 4385 , which would otherwise cause this to <nl> + / / break when the keystore contains multiple certificates . <nl> + / / the override here matches the bug fix in jetty for that issue : <nl> + / / https : / / github . com / eclipse / jetty . project / pull / 4404 / files # diff - <commit_id> r2188 - r2193 <nl> + <nl> + final sslcontextfactory . client ssl = new sslcontextfactory . client ( ) { <nl> + @ override <nl> + @ suppresswarnings ( " deprecation " ) <nl> + protected x509extendedkeymanager newsnix509extendedkeymanager ( x509extendedkeymanager keymanager ) { <nl> + return keymanager ; <nl> + } <nl> + } ; <nl>  <nl> configuresslcontextfactorykeystore ( ssl , sslconfigvalues ) ; <nl> configuresslcontextfactorytruststore ( ssl , sslconfigvalues ) ;
public class internaltopicmanager { <nl> . configs ( topicconfig ) ) ; <nl> } <nl>  <nl> + <nl> int remainingretries = retries ; <nl> boolean retry ; <nl> do { <nl>
public class internaltopicmanager { <nl> * / <nl> / / visible for testing <nl> protected map < string , integer > getnumpartitions ( final set < string > topics ) { <nl> + log . debug ( " trying to check if topics { } have been created with expected number of partitions . " , topics ) ; <nl> + <nl> + <nl> int remainingretries = retries ; <nl> boolean retry ; <nl> do { <nl> mmm a / streams / src / main / java / org / apache / kafka / streams / processor / internals / streamspartitionassignor . java <nl> ppp b / streams / src / main / java / org / apache / kafka / streams / processor / internals / streamspartitionassignor . java <nl>
<nl> see < a href = " # streams_api_changes_0101 " > below < / a > a complete list of num . 10 . 1 api changes that allow you to advance your application and / or simplify your code base , including the usage of new features . <nl> < / p > <nl>  <nl> + < ! - - <nl> + < h3 > < a id = " streams_api_changes_120 " href = " # streams_api_changes_120 " > streams api changes in num . 2 . 0 < / a > < / h3 > <nl> + < p > <nl> + we have added support for methods in < code > readonlywindowstore < / code > which allows for querying a single window ' s key - value pair . <nl> + for users who have customized window store implementations on the above interface , they ' d need to update their code to implement the newly added method as well . <nl> + for more details , see < a href = " https : / / cwiki . apache . org / confluence / display / kafka / kip - 261 % 3a + add + single + value + fetch + in + window + stores " > kip - 261 < / a > . <nl> + < / p > <nl> + <nl> < h3 > < a id = " streams_api_changes_110 " href = " # streams_api_changes_110 " > streams api changes in num . 1 . 0 < / a > < / h3 > <nl> < p > <nl> - we have added support for methods in < code > readonlywindowstore < / code > which allows for querying < code > windowstore < / code > s without the neccesity of providing keys . <nl> + we have added support for methods in < code > readonlywindowstore < / code > which allows for querying < code > windowstore < / code > s without the necessity of providing keys . <nl> + for users who have customized window store implementations on the above interface , they ' d need to update their code to implement the newly added method as well . <nl> + for more details , see < a href = " https : / / cwiki . apache . org / confluence / display / kafka / kip - 205 % 3a + add + all % 28 % 29 + and + range % 28 % 29 + api + to + readonlywindowstore " > kip - 205 < / a > . <nl> < / p > <nl>  <nl> - <nl> < p > <nl> there is a new artifact < code > kafka - streams - test - utils < / code > providing a < code > topologytestdriver < / code > , < code > consumerrecordfactory < / code > , and < code > outputverifier < / code > class . <nl> you can include the new artifact as a regular dependency to your unit tests and use the test driver to test your business logic of your kafka streams application .
public class streamthread extends thread { <nl> firstexception . compareandset ( null , flushallstate ( ) ) ; <nl> / / only commit after all state has been flushed and there hasn ' t been an exception <nl> if ( firstexception . get ( ) = = null ) { <nl> - firstexception . set ( commitoffsets ( ) ) ; <nl> + <nl> + commitoffsets ( ) ; <nl> } <nl> / / remove the changelog partitions from restore consumer <nl> firstexception . compareandset ( null , unassignchangelogpartitions ( ) ) ;
<nl> + # licensed to the apache software foundation ( asf ) under one or more <nl> + # contributor license agreements . see the notice file distributed with <nl> + # this work for additional information regarding copyright ownership . <nl> + # the asf licenses this file to you under the apache license , version num . 0 <nl> + # ( the " license " ) ; you may not use this file except in compliance with <nl> + # the license . you may obtain a copy of the license at <nl> + # <nl> + # http : / / www . apache . org / licenses / license - 2 . 0 <nl> + # <nl> + # unless required by applicable law or agreed to in writing , software <nl> + # distributed under the license is distributed on an " as is " basis , <nl> + # without warranties or conditions of any kind , either express or implied . <nl> + # see the license for the specific language governing permissions and <nl> + # limitations under the license . <nl> + <nl> + from ducktape . mark import parametrize <nl> + from ducktape . utils . util import wait_until <nl> + <nl> + from kafkatest . services . zookeeper import zookeeperservice <nl> + from kafkatest . services . kafka import kafkaservice <nl> + from kafkatest . services . verifiable_producer import verifiableproducer <nl> + from kafkatest . services . console_consumer import consoleconsumer <nl> + from kafkatest . tests . produce_consume_validate import produceconsumevalidatetest <nl> + from kafkatest . utils import is_int_with_prefix <nl> + from kafkatest . version import trunk , v_0_10_0_0 , kafkaversion <nl> + <nl> + class testproducerconsumercompat ( produceconsumevalidatetest ) : <nl> + " " " <nl> + these tests validate that we can use a new client to consume from older <nl> + brokers . <nl> + " " " <nl> + <nl> + def __init__ ( self , test_context ) : <nl> + " " " : type test_context : ducktape . tests . test . testcontext " " " <nl> + super ( testproducerconsumercompat , self ) . __init__ ( test_context = test_context ) <nl> + <nl> + self . topic = " test_topic " <nl> + self . zk = zookeeperservice ( test_context , num_nodes = 3 ) <nl> + self . kafka = kafkaservice ( test_context , num_nodes = 3 , zk = self . zk , topics = { self . topic : { <nl> + " partitions " : num , <nl> + " replication - factor " : num } } ) <nl> + self . num_partitions = num <nl> + self . timeout_sec = num <nl> + self . producer_throughput = num <nl> + self . num_producers = num <nl> + self . messages_per_producer = num <nl> + self . num_consumers = num <nl> + <nl> + def setup ( self ) : <nl> + self . zk . start ( ) <nl> + <nl> + def min_cluster_size ( self ) : <nl> + # override this since we ' re adding services outside of the constructor <nl> + return super ( testproducerconsumercompat , self ) . min_cluster_size ( ) + self . num_producers + self . num_consumers <nl> + <nl> + # <nl> + @ parametrize ( broker_version = str ( trunk ) ) <nl> + def test_produce_consume ( self , broker_version ) : <nl> + print ( " running producer_consumer_compat with broker_version = % s " % broker_version ) <nl> + self . kafka . set_version ( kafkaversion ( broker_version ) ) <nl> + self . kafka . security_protocol = " plaintext " <nl> + self . kafka . interbroker_security_protocol = self . kafka . security_protocol <nl> + self . producer = verifiableproducer ( self . test_context , self . num_producers , self . kafka , <nl> + self . topic , throughput = self . producer_throughput , <nl> + message_validator = is_int_with_prefix ) <nl> + self . consumer = consoleconsumer ( self . test_context , self . num_consumers , self . kafka , self . topic , <nl> + consumer_timeout_ms = 60000 , <nl> + message_validator = is_int_with_prefix ) <nl> + self . kafka . start ( ) <nl> + <nl> + self . run_produce_consume_validate ( lambda : wait_until ( <nl> + lambda : self . producer . each_produced_at_least ( self . messages_per_producer ) = = true , <nl> + timeout_sec = 120 , backoff_sec = 1 , <nl> + err_msg = " producer did not produce all messages in reasonable amount of time " ) ) <nl> +
public abstract class abstractcoordinator implements closeable { <nl> } <nl>  <nl> protected synchronized requestfuture < void > lookupcoordinator ( ) { <nl> - if ( findcoordinatorfuture = = null ) <nl> - findcoordinatorfuture = sendgroupcoordinatorrequest ( ) ; <nl> + if ( findcoordinatorfuture = = null ) { <nl> + / / find a node to ask about the coordinator <nl> + node node = this . client . leastloadednode ( ) ; <nl> + if ( node = = null ) { <nl> + <nl> + return requestfuture . nobrokersavailable ( ) ; <nl> + } else <nl> + findcoordinatorfuture = sendgroupcoordinatorrequest ( node ) ; <nl> + } <nl> return findcoordinatorfuture ; <nl> } <nl>  <nl>
public class processorstatemanager { <nl> retry - - ; <nl> lock = lockstatedirectory ( channel ) ; <nl> } <nl> + <nl> if ( lock = = null ) { <nl> channel . close ( ) ; <nl> } <nl>
public abstract class abstracttask { <nl> return collections . emptymap ( ) ; <nl> } <nl>  <nl> + protected void initializeoffsetlimits ( ) { <nl> + for ( topicpartition partition : partitions ) { <nl> + offsetandmetadata metadata = consumer . committed ( partition ) ; <nl> + statemgr . putoffsetlimit ( partition , metadata ! = null ? metadata . offset ( ) : num l ) ; <nl> + } <nl> + } <nl> + <nl> } <nl> mmm a / streams / src / main / java / org / apache / kafka / streams / processor / internals / standbytask . java <nl> ppp b / streams / src / main / java / org / apache / kafka / streams / processor / internals / standbytask . java <nl>
public class processorcontextimpl implements processorcontext , recordcollector . s <nl> if ( node = = null ) <nl> throw new topologybuilderexception ( " accessing from an unknown node " ) ; <nl>  <nl> - if ( ! node . statestores . contains ( name ) ) <nl> - throw new topologybuilderexception ( " processor " + node . name ( ) + " has no access to statestore " + name ) ; <nl> + <nl> + / / throw new topologybuilderexception ( " processor " + node . name ( ) + " has no access to statestore " + name ) ; <nl>  <nl> return statemgr . getstore ( name ) ; <nl> }
public class fetcher < k , v > { <nl> log . debug ( " fetched offset { } for partition { } " , offset , topicpartition ) ; <nl> return offset ; <nl> } else if ( errorcode = = errors . not_leader_for_partition . code ( ) <nl> - | | errorcode = = errors . leader_not_available . code ( ) ) { <nl> + | | errorcode = = errors . unknown_topic_or_partition . code ( ) ) { <nl> log . warn ( " attempt to fetch offsets for partition { } failed due to obsolete leadership information , retrying . " , <nl> topicpartition ) ; <nl> awaitmetadataupdate ( ) ; <nl> } else { <nl> + <nl> errors . forcode ( errorcode ) . maybethrow ( ) ; <nl> } <nl> } <nl> mmm a / clients / src / main / java / org / apache / kafka / common / requests / listoffsetresponse . java <nl> ppp b / clients / src / main / java / org / apache / kafka / common / requests / listoffsetresponse . java <nl>
object log { <nl> / * * a temporary file used when swapping files into the log * / <nl> val swapfilesuffix = " . swap " <nl>  <nl> + / * * clean shutdown file that indicates the broker was cleanly shutdown in num . 8 . this is required to maintain backwards compatibility <nl> + * with num . 8 and avoid unnecessary log recovery when upgrading from num . 8 to num . 8 . 1 * / <nl> + / * * <nl> + val cleanshutdownfile = " . kafka_cleanshutdown " <nl> + <nl> / * * <nl> * make log segment file name from offset bytes . all this does is pad out the offset number with zeros <nl> * so that ls sorts the files numerically . <nl> mmm a / core / src / main / scala / kafka / log / logmanager . scala <nl> ppp b / core / src / main / scala / kafka / log / logmanager . scala <nl>
private [ kafka ] class zookeeperconsumerconnector ( val config : consumerconfig , <nl>  <nl> } <nl>  <nl> + class zktopicpartitionchangelistener ( val loadbalancerlistener : zkrebalancerlistener ) <nl> + extends izkdatalistener { <nl> + <nl> + def handledatachange ( datapath : string , data : object ) { <nl> + try { <nl> + info ( " topic info for path " + datapath + " changed to " + data . tostring + " , triggering rebalance " ) <nl> + / / explicitly trigger load balancing for this consumer <nl> + loadbalancerlistener . syncedrebalance ( ) <nl> + <nl> + / / there is no need to re - subscribe the watcher since it will be automatically <nl> + / / re - registered upon firing of this event by zkclient <nl> + } catch { <nl> + case e : throwable = > error ( " error while handling topic partition change for data path " + datapath , e ) <nl> + } <nl> + } <nl> + <nl> + @ throws ( classof [ exception ] ) <nl> + def handledatadeleted ( datapath : string ) { <nl> + <nl> + warn ( " topic for path " + datapath + " gets deleted , which should not happen at this time " ) <nl> + } <nl> + } <nl> + <nl> class zkrebalancerlistener ( val group : string , val consumeridstring : string , <nl> val kafkamessageandmetadatastreams : mutable . map [ string , list [ kafkastream [ _ , _ ] ] ] ) <nl> extends izkchildlistener { <nl>
<nl> + package org . nd4j . autodiff . listeners . debugging ; <nl> + <nl> + import lombok . nonnull ; <nl> + import org . nd4j . autodiff . listeners . at ; <nl> + import org . nd4j . autodiff . listeners . baselistener ; <nl> + import org . nd4j . autodiff . listeners . operation ; <nl> + import org . nd4j . autodiff . samediff . samediff ; <nl> + import org . nd4j . autodiff . samediff . internal . samediffop ; <nl> + import org . nd4j . base . preconditions ; <nl> + import org . nd4j . linalg . api . ndarray . indarray ; <nl> + import org . nd4j . linalg . dataset . api . multidataset ; <nl> + import org . nd4j . linalg . factory . nd4j ; <nl> + <nl> + import java . io . file ; <nl> + import java . io . ioexception ; <nl> + import java . util . hashmap ; <nl> + import java . util . list ; <nl> + import java . util . map ; <nl> + <nl> + public class arraysavinglistener extends baselistener { <nl> + <nl> + protected final file dir ; <nl> + protected int count = num ; <nl> + <nl> + public arraysavinglistener ( @ nonnull file dir ) { <nl> + <nl> + if ( ! dir . exists ( ) ) { <nl> + dir . mkdir ( ) ; <nl> + } <nl> + <nl> + if ( dir . listfiles ( ) ! = null & & dir . listfiles ( ) . length > num ) { <nl> + throw new illegalstateexception ( " directory is not empty : " + dir . getabsolutepath ( ) ) ; <nl> + } <nl> + <nl> + this . dir = dir ; <nl> + } <nl> + <nl> + @ override <nl> + public boolean isactive ( operation operation ) { <nl> + return true ; <nl> + } <nl> + <nl> + <nl> + @ override <nl> + public void opexecution ( samediff sd , at at , multidataset batch , samediffop op , indarray [ ] outputs ) { <nl> + list < string > outnames = op . getoutputsofop ( ) ; <nl> + for ( int i = 0 ; i < outputs . length ; i + + ) { <nl> + string filename = ( count + + ) + " _ " + outnames . get ( i ) . replaceall ( " / " , " __ " ) + " . bin " ; <nl> + file outfile = new file ( dir , filename ) ; <nl> + <nl> + indarray arr = outputs [ i ] ; <nl> + try { <nl> + nd4j . savebinary ( arr , outfile ) ; <nl> + system . out . println ( outfile . getabsolutepath ( ) ) ; <nl> + } catch ( ioexception e ) { <nl> + throw new runtimeexception ( e ) ; <nl> + } <nl> + } <nl> + } <nl> + <nl> + public static void compare ( file dir1 , file dir2 , double eps ) throws exception { <nl> + file [ ] files1 = dir1 . listfiles ( ) ; <nl> + file [ ] files2 = dir2 . listfiles ( ) ; <nl> + preconditions . checknotnull ( files1 , " no files in directory num : % s " , dir1 ) ; <nl> + preconditions . checknotnull ( files2 , " no files in directory num : % s " , dir2 ) ; <nl> + preconditions . checkstate ( files1 . length = = files2 . length , " different number of files : % s vs % s " , files1 . length , files2 . length ) ; <nl> + <nl> + map < string , file > m1 = tomap ( files1 ) ; <nl> + map < string , file > m2 = tomap ( files2 ) ; <nl> + <nl> + for ( file f : files1 ) { <nl> + string name = f . getname ( ) ; <nl> + string varname = name . substring ( name . indexof ( ' _ ' ) + num , name . length ( ) - 4 ) ; / / strip " x_ " and " . bin " <nl> + file f2 = m2 . get ( varname ) ; <nl> + <nl> + indarray arr1 = nd4j . readbinary ( f ) ; <nl> + indarray arr2 = nd4j . readbinary ( f2 ) ; <nl> + <nl> + <nl> + boolean eq = arr1 . equalswitheps ( arr2 , eps ) ; <nl> + if ( eq ) { <nl> + system . out . println ( " equals : " + varname . replaceall ( " __ " , " / " ) ) ; <nl> + } else { <nl> + indarray sub = arr1 . sub ( arr2 ) ; <nl> + indarray diff = nd4j . math . abs ( sub ) ; <nl> + double maxdiff = diff . maxnumber ( ) . doublevalue ( ) ; <nl> + system . out . println ( " fails : " + varname . replaceall ( " __ " , " / " ) + " - max difference = " + maxdiff ) ; <nl> + system . out . println ( " \ t " + f . getabsolutepath ( ) ) ; <nl> + system . out . println ( " \ t " + f2 . getabsolutepath ( ) ) ; <nl> + sub . close ( ) ; <nl> + diff . close ( ) ; ; <nl> + } <nl> + arr1 . close ( ) ; <nl> + arr2 . close ( ) ; <nl> + } <nl> + } <nl> + <nl> + private static map < string , file > tomap ( file [ ] files ) { <nl> + map < string , file > ret = new hashmap < > ( ) ; <nl> + for ( file f : files ) { <nl> + string name = f . getname ( ) ; <nl> + string varname = name . substring ( name . indexof ( ' _ ' ) + num , name . length ( ) - num ) ; / / strip " x_ " and " . bin " <nl> + ret . put ( varname , f ) ; <nl> + } <nl> + return ret ; <nl> + } <nl> + }
<nl>  <nl> < modules > <nl> < module > servicecomb - java - chassis - 0 . x - plugin < / module > <nl> + < ! - - <nl> + < ! - - after apache servicecomb released , we will put it back - - > <nl> + < ! - - <nl> < module > servicecomb - java - chassis - 1 . x - plugin < / module > <nl> + - - > <nl> < / modules > <nl> < packaging > pom < / packaging > <nl>  <nl> mmm a / apm - sniffer / apm - sdk - plugin / servicecomb - plugin / servicecomb - java - chassis - 1 . x - plugin / pom . xml <nl> ppp b / apm - sniffer / apm - sdk - plugin / servicecomb - plugin / servicecomb - java - chassis - 1 . x - plugin / pom . xml <nl>
<nl> < scope > provided < / scope > <nl> < / dependency > <nl> < / dependencies > <nl> + < ! - - <nl> < repositories > <nl> < repository > <nl> < id > apache - servicecomb < / id >
public class datattlkeepertimer { <nl> } <nl>  <nl> public void start ( ) { <nl> - executors . newsinglethreadscheduledexecutor ( ) . scheduleatfixedrate ( this : : delete , num , num , timeunit . hours ) ; <nl> + <nl> } <nl>  <nl> private void delete ( ) {
public class indexdbconnector { <nl> return " jdbc : hsqldb : file : " + basepath + " / " + timestamp + " / " + dbfilename ; <nl> } <nl> } <nl> + <nl> + public void close ( ) { <nl> + <nl> + } <nl> } <nl> mmm a / skywalking - storage - center / skywalking - storage / src / main / java / com / a / eye / skywalking / storage / data / index / indexmetacollection . java <nl> ppp b / skywalking - storage - center / skywalking - storage / src / main / java / com / a / eye / skywalking / storage / data / index / indexmetacollection . java <nl>
public abstract class hystrixcommandmetrics extends hystrixmetrics { <nl> * <nl> * @ return { @ link healthcounts } <nl> * / <nl> - public final healthcounts gethealthcounts ( ) { <nl> + <nl> + public healthcounts gethealthcounts ( ) { <nl> / / we put an interval between snapshots so high - volume commands don ' t <nl> / / spend too much unnecessary time calculating metrics in very small time periods <nl> long lasttime = lasthealthcountssnapshot . get ( ) ;
public abstract class snapshotmigrationtestbase extends testlogger { <nl>  <nl> clusterclient < ? > client = miniclusterresource . getclusterclient ( ) ; <nl>  <nl> + <nl> + if ( snapshottype = = snapshottype . savepoint_native ) { <nl> + env . enablechangelogstatebackend ( false ) ; <nl> + } <nl> + <nl> / / submit the job <nl> jobgraph jobgraph = env . getstreamgraph ( ) . getjobgraph ( ) ;
class zookeepermultiplecomponentleaderelectiondrivertest { <nl> electiondriver : : hasleadership , collectors . toset ( ) ) ) ; <nl>  <nl> assertthat ( leaderandrest . get ( true ) ) . hassize ( 1 ) ; <nl> + <nl> + <nl> + / / condition if a child node , participating in the leader election , is removed too <nl> + / / fast . this results in a different code branch being executed which triggers a <nl> + / / reset of the leaderlatch instead of re - collecting the children to determine the <nl> + / / next leader . <nl> + / / the issue occurs because leaderlatch # checkleadership is not executed <nl> + / / transactionally , i . e . retrieving the children and setting up the watcher for the <nl> + / / predecessor is not done atomically . this leads to the race condition where a <nl> + / / children ( the previous leader ' s node ) is removed before setting up the watcher <nl> + / / which results in an invalid handling of the situation using reset . <nl> + / / adding some sleep here ( simulating the leader actually doing something ) will <nl> + / / reduce the risk of falling into the race condition because it will give the <nl> + / / concurrently running leaderlatch instances more time to set up the watchers <nl> + / / properly . <nl> + thread . sleep ( 100 ) ; <nl> + <nl> iterables . getonlyelement ( leaderandrest . get ( true ) ) . close ( ) ; <nl>  <nl> electiondrivers = leaderandrest . get ( false ) ;
public class restartpipelinedregionfailoverstrategy implements failoverstrategy <nl> failedpartitions . remove ( resultpartitionid ) ; <nl> } <nl>  <nl> - private boolean isresultpartitionisreconsumableorpipelinedapproximate ( <nl> + private boolean isresultpartitioncanbeconsumedrepeatedly ( <nl> intermediateresultpartitionid resultpartitionid ) { <nl> resultpartitiontype resultpartitiontype = <nl> resultpartitiontyperetriever . apply ( resultpartitionid ) ; <nl> return resultpartitiontype . isreconsumable ( ) <nl> - | | resultpartitiontype = = resultpartitiontype . pipelined_approximate ; <nl> + | | resultpartitiontype = = resultpartitiontype . pipelined_approximate <nl> + <nl> + | | resultpartitiontype = = resultpartitiontype . hybrid_full ; <nl> } <nl> } <nl>  <nl> mmm a / flink - runtime / src / main / java / org / apache / flink / runtime / io / network / partition / resultpartitiontype . java <nl> ppp b / flink - runtime / src / main / java / org / apache / flink / runtime / io / network / partition / resultpartitiontype . java <nl>
public enum resultpartitiontype { <nl> * <nl> * < p > hybrid partitions can be consumed any time , whether fully produced or not . <nl> * <nl> - * < p > hybrid_full partitions is re - consumable , so double calculation can be avoided during <nl> + * < p > hybrid_full partitions can be consumed repeatedly , but it does not support concurrent <nl> + * consumption . so re - consumable is false , but double calculation can be avoided during <nl> * failover . <nl> * / <nl> - hybrid_full ( true , false , false , consumingconstraint . can_be_pipelined , releaseby . scheduler ) , <nl> + <nl> + hybrid_full ( false , false , false , consumingconstraint . can_be_pipelined , releaseby . scheduler ) , <nl>  <nl> / * * <nl> - * hybrid_selective partitions are similar to { @ link # hybrid_full } partitions , but it is not <nl> - * re - consumable . <nl> + * hybrid_selective partitions are similar to { @ link # hybrid_full } partitions , but it cannot be <nl> + * consumed repeatedly . <nl> * / <nl> hybrid_selective ( <nl> false , false , false , consumingconstraint . can_be_pipelined , releaseby . scheduler ) ; <nl> mmm a / flink - streaming - java / src / main / java / org / apache / flink / streaming / api / transformations / streamexchangemode . java <nl> ppp b / flink - streaming - java / src / main / java / org / apache / flink / streaming / api / transformations / streamexchangemode . java <nl>
public class buffertimeoutitcase extends abstracttestbase { <nl> * which should not fill an entire buffer , thus it should not never reach the sink . we check the <nl> * sink has not seen any records after num times the default buffer timeout . <nl> * / <nl> + <nl> + @ ignore <nl> @ test <nl> public void testdisablingbuffertimeout ( ) throws exception { <nl> final streamexecutionenvironment env = streamexecutionenvironment . getexecutionenvironment ( ) ;
export class monacoeditorcomponent implements afterviewinit , ondestroy { <nl>  <nl> ngafterviewinit ( ) { <nl> if ( ( window as any ) . monaco ) { <nl> - this . setupmonaco ( ) ; <nl> + <nl> + settimeout ( ( ) = > this . setupmonaco ( ) ) ; <nl> } else { <nl> const script = document . createelement ( ' script ' ) ; <nl> script . type = ' text / javascript ' ;
public class processingtimeserviceutil { <nl> * / <nl> public static long getprocessingtimedelay ( long processingtimestamp , long currenttimestamp ) { <nl>  <nl> - / / delay the firing of the timer by num ms to align the semantics with watermark . a watermark <nl> - / / t says we won ' t see elements in the future with a timestamp smaller or equal to t . <nl> - / / with processing time , we therefore need to delay firing the timer by one ms . <nl> - return math . max ( processingtimestamp - currenttimestamp , num ) + num ; <nl> + / / two cases of timers here : <nl> + / / ( 1 ) future / now timers ( processingtimestamp > = currenttimestamp ) : delay the firing of the <nl> + / / timer by num ms to align the semantics with watermark . a watermark t says we won ' t see <nl> + / / elements in the future with a timestamp smaller or equal to t . with processing time , we <nl> + / / therefore need to delay firing the timer by one ms . <nl> + / / ( 2 ) past timers ( processingtimestamp < currenttimestamp ) : do not need to delay the firing <nl> + / / because currenttimestamp is larger than processingtimestamp pluses the num ms offset . <nl> + <nl> + if ( processingtimestamp > = currenttimestamp ) { <nl> + return processingtimestamp - currenttimestamp + num ; <nl> + } else { <nl> + return num ; <nl> + } <nl> } <nl> }
public final class changelogstatehandlestreamimpl implements changelogstatehandl <nl>  <nl> @ override <nl> public void discardstate ( ) { <nl> - handlesandoffsets . foreach ( <nl> - handleandoffset - > stateregistry . unregisterreference ( getkey ( handleandoffset . f0 ) ) ) ; <nl> + if ( stateregistry = = null ) { <nl> + <nl> + / / by invalidating checkpoints on abortion <nl> + } else { <nl> + handlesandoffsets . foreach ( <nl> + handleandoffset - > <nl> + stateregistry . unregisterreference ( getkey ( handleandoffset . f0 ) ) ) ; <nl> + } <nl> } <nl>  <nl> @ override
public class jdbcexactlyoncesinke2etest extends jdbctestbase { <nl>  <nl> private static final logger log = loggerfactory . getlogger ( jdbcexactlyoncesinke2etest . class ) ; <nl>  <nl> + <nl> + @ classrule <nl> + public static final loglevelrule test_log_level_rule = <nl> + new loglevelrule ( ) <nl> + . set ( jdbcexactlyoncesinke2etest . class , trace ) <nl> + . set ( xafacadeimpl . class , trace ) ; <nl> + <nl> private interface jdbcexactlyoncesinktestenv { <nl> void start ( ) ; <nl>  <nl> mmm a / flink - connectors / flink - connector - jdbc / src / test / resources / log4j2 - test . properties <nl> ppp b / flink - connectors / flink - connector - jdbc / src / test / resources / log4j2 - test . properties <nl>
public class sinkitcase extends abstracttestbase { <nl>  <nl> env . execute ( ) ; <nl>  <nl> + <nl> + / / we do not need to verify this matter . after the final checkpoint becomes ready in the <nl> + / / future , <nl> + / / the verification of " end of input " would be restored . <nl> + global_commit_queue . remove ( end_of_input_str ) ; <nl> + <nl> assertthat ( <nl> commit_queue , <nl> containsinanyorder ( expected_committed_data_in_streaming_mode . toarray ( ) ) ) ; <nl>
public class sinkitcase extends abstracttestbase { <nl> . build ( ) ) ; <nl>  <nl> env . execute ( ) ; <nl> + <nl> + <nl> + / / we do not need to verify this matter . after the final checkpoint becomes ready in the <nl> + / / future , <nl> + / / the verification of " end of input " would be restored . <nl> + global_commit_queue . remove ( end_of_input_str ) ; <nl> + <nl> assertthat ( <nl> getsplittedglobalcommitteddata ( ) , <nl> containsinanyorder ( expected_global_committed_data_in_streaming_mode . toarray ( ) ) ) ;
import java . util . function . supplier ; <nl> @ internal <nl> public interface subtaskcheckpointcoordinator extends closeable { <nl>  <nl> + / * * <nl> + * <nl> + * removed in the last pr . <nl> + * / <nl> + void setenablecheckpointaftertasksfinished ( boolean enablecheckpointaftertasksfinished ) ; <nl> + <nl> / * * initialize new checkpoint . * / <nl> void initinputscheckpoint ( long id , checkpointoptions checkpointoptions ) <nl> throws checkpointexception ; <nl> mmm a / flink - streaming - java / src / main / java / org / apache / flink / streaming / runtime / tasks / subtaskcheckpointcoordinatorimpl . java <nl> ppp b / flink - streaming - java / src / main / java / org / apache / flink / streaming / runtime / tasks / subtaskcheckpointcoordinatorimpl . java <nl>
class subtaskcheckpointcoordinatorimpl implements subtaskcheckpointcoordinator { <nl>  <nl> private static final int checkpoint_execution_delay_log_threshold_ms = num _000 ; <nl>  <nl> + / * * <nl> + * <nl> + * removed in the last pr . <nl> + * / <nl> + private boolean enablecheckpointaftertasksfinished ; <nl> + <nl> private final cachingcheckpointstorageworkerview checkpointstorage ; <nl> private final string taskname ; <nl> private final executorservice asyncoperationsthreadpool ; <nl>
import static org . apache . flink . util . preconditions . checkstate ; <nl> import static org . junit . assert . asserttrue ; <nl>  <nl> / * * a simple end - to - end test for { @ link jdbcxasinkfunction } . * / <nl> + <nl> + @ ignore <nl> public class jdbcexactlyoncesinke2etest extends jdbctestbase { <nl>  <nl> private static final class pgxadb extends postgresqlcontainer < pgxadb > {
public class checkpointstoreitcase extends testlogger { <nl>  <nl> @ test <nl> public void testrestartonrecoveryfailure ( ) throws exception { <nl> + assumefalse ( <nl> + <nl> + " adaptive scheduler doesn ' t retry after failures on recovery " , <nl> + clusteroptions . getschedulertype ( configuration ) = = adaptive ) ; <nl> streamexecutionenvironment env = streamexecutionenvironment . getexecutionenvironment ( ) ; <nl> env . enablecheckpointing ( 10 ) ; <nl> env . setrestartstrategy ( fixeddelayrestart ( 2 / * failure on processing + on recovery * / , num ) ) ;
<nl> + / * <nl> + * licensed to the apache software foundation ( asf ) under one <nl> + * or more contributor license agreements . see the notice file <nl> + * distributed with this work for additional information <nl> + * regarding copyright ownership . the asf licenses this file <nl> + * to you under the apache license , version num . 0 ( the <nl> + * " license " ) ; you may not use this file except in compliance <nl> + * with the license . you may obtain a copy of the license at <nl> + * <nl> + * http : / / www . apache . org / licenses / license - 2 . 0 <nl> + * <nl> + * unless required by applicable law or agreed to in writing , software <nl> + * distributed under the license is distributed on an " as is " basis , <nl> + * without warranties or conditions of any kind , either express or implied . <nl> + * see the license for the specific language governing permissions and <nl> + * limitations under the license . <nl> + * / <nl> + <nl> + package org . apache . flink . state . changelog ; <nl> + <nl> + import org . apache . flink . runtime . state . keygroupedinternalpriorityqueue ; <nl> + import org . apache . flink . util . closeableiterator ; <nl> + <nl> + import javax . annotation . nullable ; <nl> + <nl> + import java . util . collection ; <nl> + import java . util . set ; <nl> + <nl> + / * * <nl> + * a { @ link keygroupedinternalpriorityqueue } that keeps state on the underlying delegated { @ link <nl> + * keygroupedinternalpriorityqueue } as well as on the state change log . <nl> + * / <nl> + public class changelogkeygroupedpriorityqueue < t > implements keygroupedinternalpriorityqueue < t > { <nl> + private final keygroupedinternalpriorityqueue < t > delegatedpriorityqueue ; <nl> + <nl> + public changelogkeygroupedpriorityqueue ( <nl> + keygroupedinternalpriorityqueue < t > delegatedpriorityqueue ) { <nl> + this . delegatedpriorityqueue = delegatedpriorityqueue ; <nl> + } <nl> + <nl> + @ override <nl> + public set < t > getsubsetforkeygroup ( int keygroupid ) { <nl> + return delegatedpriorityqueue . getsubsetforkeygroup ( keygroupid ) ; <nl> + } <nl> + <nl> + @ nullable <nl> + @ override <nl> + public t poll ( ) { <nl> + return delegatedpriorityqueue . poll ( ) ; <nl> + } <nl> + <nl> + @ nullable <nl> + @ override <nl> + public t peek ( ) { <nl> + return delegatedpriorityqueue . peek ( ) ; <nl> + } <nl> + <nl> + @ override <nl> + public boolean add ( t toadd ) { <nl> + return delegatedpriorityqueue . add ( toadd ) ; <nl> + } <nl> + <nl> + @ override <nl> + public boolean remove ( t toremove ) { <nl> + return delegatedpriorityqueue . remove ( toremove ) ; <nl> + } <nl> + <nl> + @ override <nl> + public boolean isempty ( ) { <nl> + return delegatedpriorityqueue . isempty ( ) ; <nl> + } <nl> + <nl> + @ override <nl> + public int size ( ) { <nl> + return delegatedpriorityqueue . size ( ) ; <nl> + } <nl> + <nl> + @ override <nl> + public void addall ( @ nullable collection < ? extends t > toadd ) { <nl> + delegatedpriorityqueue . addall ( toadd ) ; <nl> + } <nl> + <nl> + @ override <nl> + public closeableiterator < t > iterator ( ) { <nl> + <nl> + return delegatedpriorityqueue . iterator ( ) ; <nl> + } <nl> + } <nl> mmm a / flink - state - backends / flink - statebackend - changelog / src / main / java / org / apache / flink / state / changelog / changelogkeyedstatebackend . java <nl> ppp b / flink - state - backends / flink - statebackend - changelog / src / main / java / org / apache / flink / state / changelog / changelogkeyedstatebackend . java <nl>
class streampandasudafittests ( pyflinkblinkstreamtabletestcase ) : <nl> " + i [ 3 , num - 03 - 11 num : 30 : 00 . 0 , num - 03 - 11 num : 30 : 00 . 0 , num . 0 ] " ] ) <nl> os . remove ( source_path ) <nl>  <nl> + def test_sliding_group_window_over_proctime ( self ) : <nl> + self . t_env . get_config ( ) . get_configuration ( ) . set_string ( " parallelism . default " , " 1 " ) <nl> + from pyflink . table . window import slide <nl> + self . t_env . register_function ( " mean_udaf " , mean_udaf ) <nl> + <nl> + source_table = " " " <nl> + create table source_table ( <nl> + a int , <nl> + proctime as proctime ( ) <nl> + ) with ( <nl> + ' connector ' = ' datagen ' , <nl> + ' rows - per - second ' = ' 1 ' , <nl> + ' fields . a . kind ' = ' sequence ' , <nl> + ' fields . a . start ' = ' 1 ' , <nl> + ' fields . a . end ' = ' 10 ' <nl> + ) <nl> + " " " <nl> + self . t_env . execute_sql ( source_table ) <nl> + t = self . t_env . from_path ( " source_table " ) <nl> + iterator = t . select ( " a , proctime " ) \ <nl> + . window ( slide . over ( " 1 . seconds " ) . every ( " 1 . seconds " ) . on ( " proctime " ) . alias ( " w " ) ) \ <nl> + . group_by ( " a , w " ) \ <nl> + . select ( " mean_udaf ( a ) as b , w . start " ) . execute ( ) . collect ( ) <nl> + result = [ i for i in iterator ] <nl> + # if the windowassigner . iseventtime ( ) does not return false , <nl> + # the w . start would be num - 01 - 01 <nl> + # <nl> + # flip - 162 ) , we should replace it with a more accurate assertion . <nl> + self . asserttrue ( result [ 0 ] [ 1 ] . year > num ) <nl> + <nl> def test_sliding_group_window_over_count ( self ) : <nl> self . t_env . get_config ( ) . get_configuration ( ) . set_string ( " parallelism . default " , " 1 " ) <nl> # create source file path <nl> mmm a / flink - table / flink - table - planner - blink / src / main / java / org / apache / flink / table / planner / plan / nodes / exec / stream / streamexecpythongroupwindowaggregate . java <nl> ppp b / flink - table / flink - table - planner - blink / src / main / java / org / apache / flink / table / planner / plan / nodes / exec / stream / streamexecpythongroupwindowaggregate . java <nl>
import java . util . list ; <nl> * / <nl> public interface execnode < t > { <nl>  <nl> + / * * <nl> + * returns a string which describes this node . <nl> + * <nl> + * because relnode already has ` getdescription ` method . <nl> + * / <nl> + string getdesc ( ) ; <nl> + <nl> + / * * <nl> + * returns the output { @ link rowtype } of this node . <nl> + * / <nl> + rowtype getoutputtype ( ) ; <nl> + <nl> / * * <nl> * returns a list of this node ' s input nodes . <nl> * if there are no inputs , returns an empty list , not null . <nl>
public abstract class streamtask < out , op extends streamoperator < out > > <nl> actionexecutor . runthrowing ( ( ) - > { <nl>  <nl> sequentialchannelstatereader reader = getenvironment ( ) . gettaskstatemanager ( ) . getsequentialchannelstatereader ( ) ; <nl> - reader . readoutputdata ( getenvironment ( ) . getallwriters ( ) , ! configuration . isgraphcontainingloops ( ) ) ; <nl> + <nl> + reader . readoutputdata ( getenvironment ( ) . getallwriters ( ) , false ) ; <nl>  <nl> operatorchain . initializestateandopenoperators ( createstreamtaskstateinitializer ( ) ) ;
public class gcloudemulatormanager { <nl> private static string dockeripaddress = " 127 . 0 . 0 . 1 " ; <nl>  <nl> public static final string internal_pubsub_port = " 22222 " ; <nl> - public static final string docker_image_name = " google / cloud - sdk : latest " ; <nl> + <nl> + public static final string docker_image_name = " google / cloud - sdk : 313 . 0 . 0 " ; <nl>  <nl> private static string pubsubport ; <nl>  <nl>
public class pipelinedsubpartition extends resultsubpartition { <nl> @ override <nl> public boolean add ( bufferconsumer bufferconsumer , boolean ispriorityevent ) throws ioexception { <nl> if ( ispriorityevent ) { <nl> - if ( readview ! = null & & readview . notifypriorityevent ( bufferconsumer ) ) { <nl> - bufferconsumer . close ( ) ; <nl> - return true ; <nl> - } <nl> + <nl> return add ( bufferconsumer , false , true ) ; <nl> } <nl> return add ( bufferconsumer , false , false ) ; <nl> mmm a / flink - runtime / src / test / java / org / apache / flink / runtime / io / network / partition / pipelinedsubpartitionwithreadviewtest . java <nl> ppp b / flink - runtime / src / test / java / org / apache / flink / runtime / io / network / partition / pipelinedsubpartitionwithreadviewtest . java <nl>
jobs : <nl> - script : . / tools / azure - pipelines / setup_kubernetes . sh <nl> - script : m2_home = / home / vsts / maven_cache / apache - maven - 3 . 2 . 5 / path = / home / vsts / maven_cache / apache - maven - 3 . 2 . 5 / bin : $ path $ { { parameters . environment } } stage = compile . / tools / azure_controller . sh compile <nl> displayname : build <nl> + # <nl> + - script : flink_dir = build - target . / flink - end - to - end - tests / run - pre - commit - tests . sh <nl> + displayname : test - precommit <nl> - script : flink_dir = ` pwd ` / build - target flink - end - to - end - tests / run - nightly - tests . sh <nl> displayname : run nightly e2e tests
updates to that state . <nl> see [ restart strategies ] ( { { site . baseurl } } { % link dev / task_failure_recovery . md <nl> % } # restart - strategies ) for more information . <nl>  <nl> + # # # state backends <nl> + <nl> + ` <nl> + <nl> # # # exactly once vs . at least once <nl>  <nl> the alignment step may add latency to the streaming program . usually , this <nl>
repartitioning / shuffle ) . because of that , dataflows with only embarrassingly <nl> parallel streaming operations ( ` map ( ) ` , ` flatmap ( ) ` , ` filter ( ) ` , . . . ) actually <nl> give * exactly once * guarantees even in * at least once * mode . <nl>  <nl> - <nl> { % top % } <nl>  <nl> + # # end - to - end exactly - once programs <nl> + <nl> + ` <nl> + <nl> # # state and fault tolerance in batch programs <nl>  <nl> flink executes [ batch programs ] ( . . / dev / batch / index . html ) as a special case of
as many key groups as the defined maximum parallelism . during execution each <nl> parallel instance of a keyed operator works with the keys for one or more key <nl> groups . <nl>  <nl> + ` <nl> + <nl> # # operator state <nl>  <nl> * operator state * ( or * non - keyed state * ) is state that is is bound to one <nl>
object builtinmethods { <nl> classof [ long ] , classof [ int ] ) <nl> val truncate_dec = types . lookupmethod ( classof [ sqlfunctionutils ] , " struncate " , <nl> classof [ decimal ] , classof [ int ] ) <nl> + <nl> + <nl> + val unix_date_ceil = types . lookupmethod ( classof [ sqldatetimeutils ] , " unixdateceil " , <nl> + classof [ timeunitrange ] , classof [ int ] ) <nl> } <nl> mmm a / flink - table / flink - table - planner - blink / src / main / scala / org / apache / flink / table / planner / codegen / calls / functiongenerator . scala <nl> ppp b / flink - table / flink - table - planner - blink / src / main / scala / org / apache / flink / table / planner / codegen / calls / functiongenerator . scala <nl>
object functiongenerator { <nl> builtinmethod . floor . method , <nl> some ( builtinmethods . timestamp_floor_time_zone ) ) ) <nl>  <nl> + <nl> addsqlfunction ( <nl> ceil , <nl> seq ( date , any ) , <nl> new floorceilcallgen ( <nl> builtinmethod . ceil . method , <nl> - some ( builtinmethod . unix_date_ceil . method ) ) ) <nl> + some ( builtinmethods . unix_date_ceil ) ) ) <nl>  <nl> addsqlfunction ( <nl> ceil , <nl> mmm a / flink - table / flink - table - runtime - blink / src / main / java / org / apache / flink / table / runtime / functions / sqldatetimeutils . java <nl> ppp b / flink - table / flink - table - runtime - blink / src / main / java / org / apache / flink / table / runtime / functions / sqldatetimeutils . java <nl>
public class sqldatetimeutils { <nl> return r ; <nl> } <nl>  <nl> + <nl> + public static long unixdateceil ( timeunitrange range , long date ) { <nl> + return juliandatefloor ( range , ( int ) date + epoch_julian , false ) ; <nl> + } <nl> + <nl> }
object builtinmethods { <nl> classof [ long ] , classof [ int ] ) <nl> val truncate_dec = types . lookupmethod ( classof [ sqlfunctions ] , " struncate " , <nl> classof [ jbigdecimal ] , classof [ int ] ) <nl> + <nl> + <nl> + val unix_date_ceil = types . lookupmethod ( classof [ scalarfunctions ] , " unixdateceil " , <nl> + classof [ timeunitrange ] , classof [ int ] ) <nl> } <nl> mmm a / flink - table / flink - table - planner / src / main / scala / org / apache / flink / table / codegen / calls / functiongenerator . scala <nl> ppp b / flink - table / flink - table - planner / src / main / scala / org / apache / flink / table / codegen / calls / functiongenerator . scala <nl>
object functiongenerator { <nl> builtinmethod . floor . method , <nl> some ( builtinmethod . unix_timestamp_floor . method ) ) ) <nl>  <nl> + <nl> addsqlfunction ( <nl> ceil , <nl> seq ( sqltimetypeinfo . date , new generictypeinfo ( classof [ timeunitrange ] ) ) , <nl> new floorceilcallgen ( <nl> builtinmethod . ceil . method , <nl> - some ( builtinmethod . unix_date_ceil . method ) ) ) <nl> + some ( builtinmethods . unix_date_ceil ) ) ) <nl>  <nl> addsqlfunction ( <nl> ceil , <nl> mmm a / flink - table / flink - table - planner / src / main / scala / org / apache / flink / table / runtime / functions / scalarfunctions . scala <nl> ppp b / flink - table / flink - table - planner / src / main / scala / org / apache / flink / table / runtime / functions / scalarfunctions . scala <nl>
object scalarfunctions { <nl> * / <nl> def repeat ( base : string , n : int ) : string = encodingutils . repeat ( base , n ) <nl>  <nl> + <nl> + def unixdateceil ( range : timeunitrange , date : int ) : long = <nl> + juliandatefloor ( range , date + epoch_julian , false ) <nl> + <nl> + private def juliandatefloor ( range : timeunitrange , julian : int , floor : boolean ) : int = { <nl> + / / this shifts the epoch back to astronomical year - 4800 instead of the <nl> + / / start of the christian era in year ad num of the proleptic gregorian <nl> + / / calendar . <nl> + val j : int = julian + num <nl> + val g : int = j / num <nl> + val dg : int = j % num <nl> + val c : int = ( dg / num + num ) * num / num <nl> + val dc : int = dg - c * num <nl> + val b : int = dc / num <nl> + val db : int = dc % num <nl> + val a : int = ( db / num + num ) * num / num <nl> + val da : int = db - a * num <nl> + / / integer number of full years elapsed since march num , num bc <nl> + val y : int = g * num + c * num + b * num + a <nl> + / / integer number of full months elapsed since the last march num <nl> + val m : int = ( da * num + num ) / num - num <nl> + / / number of days elapsed since day num of the month <nl> + val d : int = da - ( m + num ) * num / num + num <nl> + var year : int = y - num + ( m + num ) / num <nl> + var month : int = ( m + num ) % num + num <nl> + val day : int = d + num <nl> + range match { <nl> + case year = > <nl> + if ( ! ( floor ) & & ( month > num | | day > num ) ) { <nl> + year + = num <nl> + } <nl> + return ymdtounixdate ( year , num , num ) <nl> + case month = > <nl> + if ( ! ( floor ) & & day > num ) { <nl> + month + = num <nl> + } <nl> + return ymdtounixdate ( year , month , num ) <nl> + case _ = > <nl> + throw new assertionerror ( range ) <nl> + } <nl> + } <nl> + <nl> }
public class batchabstracttestbase { <nl> new miniclusterresourceconfiguration . builder ( ) <nl> . setconfiguration ( getconfiguration ( ) ) <nl> . setnumbertaskmanagers ( 1 ) <nl> - . setnumberslotspertaskmanager ( default_parallelism ) <nl> + . setnumberslotspertaskmanager ( default_parallelism * num ) <nl> . build ( ) ) ; <nl>  <nl> @ classrule <nl> mmm a / flink - table / flink - table - planner - blink / src / test / scala / org / apache / flink / table / planner / runtime / batch / sql / agg / aggregateitcasebase . scala <nl> ppp b / flink - table / flink - table - planner - blink / src / test / scala / org / apache / flink / table / planner / runtime / batch / sql / agg / aggregateitcasebase . scala <nl>
public final class memorysegmentfactory { <nl> * @ return a new memory segment , backed by off - heap unsafe memory . <nl> * / <nl> public static memorysegment allocateoffheapunsafememory ( int size , object owner ) { <nl> - long address = memoryutils . allocateunsafe ( size ) ; <nl> - bytebuffer offheapbuffer = memoryutils . wrapunsafememorywithbytebuffer ( address , size ) ; <nl> - return new hybridmemorysegment ( offheapbuffer , owner , memoryutils . creatememorygccleaner ( offheapbuffer , address ) ) ; <nl> + <nl> + return allocateunpooledoffheapmemory ( size , owner ) ; <nl> } <nl>  <nl> / * * <nl> mmm a / flink - core / src / main / java / org / apache / flink / core / memory / memoryutils . java <nl> ppp b / flink - core / src / main / java / org / apache / flink / core / memory / memoryutils . java <nl>
public class memoryutils { <nl> * / <nl> @ suppresswarnings ( " useofsunclasses " ) <nl> static runnable creatememorygccleaner ( object owner , long address ) { <nl> + <nl> / / the release call is wrapped with the sun . misc . cleaner <nl> / / which will schedule it before gc is run for the owner object ( not reachable in user code ) . <nl> / / but only if sun . misc . cleaner : : clean has not been already called explicitly by user before . <nl> / / if sun . misc . cleaner : : clean is called after gc it will not call the release . <nl> / / this way we guarantee that there will always be a release at some point but only once . <nl> - return sun . misc . cleaner . create ( owner , ( ) - > releaseunsafe ( address ) ) : : clean ; <nl> + return null ; / / sun . misc . cleaner . create ( owner , ( ) - > releaseunsafe ( address ) ) : : clean ; <nl> } <nl>  <nl> private static void releaseunsafe ( long address ) {
import static org . mockito . mockito . when ; <nl> * tests for the { @ link remotestreamenvironment } . <nl> * / <nl> @ runwith ( powermockrunner . class ) <nl> - @ preparefortest ( { remotestreamenvironment . class } ) <nl> + <nl> + @ preparefortest ( { remotestreamenvironment . class , remoteexecutor . class } ) <nl> public class remotestreamexecutionenvironmenttest extends testlogger { <nl>  <nl> / * * <nl>
public class miniclusteritcase extends testlogger { <nl> } catch ( jobexecutionexception e ) { <nl> asserttrue ( findthrowablewithmessage ( e , " job execution failed . " ) . ispresent ( ) ) ; <nl> asserttrue ( findthrowable ( e , noresourceavailableexception . class ) . ispresent ( ) ) ; <nl> - asserttrue ( findthrowablewithmessage ( e , " slots required : num , slots allocated : num " ) . ispresent ( ) ) ; <nl> + <nl> + <nl> + final string legacyschedulererrormessage = " slots required : num , slots allocated : num " ; <nl> + final string ngschedulererrormessage = " could not allocate the required slot within slot request timeout " ; <nl> + asserttrue ( findthrowablewithmessage ( e , legacyschedulererrormessage ) . ispresent ( ) | | <nl> + findthrowablewithmessage ( e , ngschedulererrormessage ) . ispresent ( ) ) ; <nl> } <nl> } <nl>  <nl>
public class miniclusteritcase extends testlogger { <nl> } catch ( jobexecutionexception e ) { <nl> asserttrue ( findthrowablewithmessage ( e , " job execution failed . " ) . ispresent ( ) ) ; <nl> asserttrue ( findthrowable ( e , noresourceavailableexception . class ) . ispresent ( ) ) ; <nl> - asserttrue ( findthrowablewithmessage ( e , " could not allocate enough slots " ) . ispresent ( ) ) ; <nl> + <nl> + <nl> + final string legacyschedulererrormessage = " could not allocate enough slots " ; <nl> + final string ngschedulererrormessage = " could not allocate the required slot within slot request timeout " ; <nl> + asserttrue ( findthrowablewithmessage ( e , legacyschedulererrormessage ) . ispresent ( ) | | <nl> + findthrowablewithmessage ( e , ngschedulererrormessage ) . ispresent ( ) ) ; <nl> } <nl> }
public final class streamtwoinputprocessor < in1 , in2 > implements streaminputproce <nl> } <nl>  <nl> private void checkandsetavailable ( int inputindex ) { <nl> - streamtaskinput input = getinput ( inputindex ) ; <nl> inputstatus status = ( inputindex = = num ? firstinputstatus : secondinputstatus ) ; <nl> - if ( status ! = inputstatus . end_of_input & & input . isavailable ( ) . isdone ( ) ) { <nl> + if ( status = = inputstatus . end_of_input ) { <nl> + return ; <nl> + } <nl> + completablefuture < ? > inputavailable = getinput ( inputindex ) . isavailable ( ) ; <nl> + <nl> + / / once per every record . this might be optimized to only check once per processed networkbuffer <nl> + if ( inputavailable = = available | | inputavailable . isdone ( ) ) { <nl> inputselectionhandler . setavailableinput ( inputindex ) ; <nl> } <nl> }
public class streamsqltestprogram { <nl> string tumblequery = string . format ( <nl> " select " + <nl> " key , " + <nl> - " case sum ( cnt ) / count ( * ) when num then num else num end as correct , " + <nl> + <nl> + " case sum ( cnt ) / count ( * ) when num then num when - 1 then null else num end as correct , " + <nl> " tumble_start ( rowtime , interval ' % d ' second ) as wstart , " + <nl> " tumble_rowtime ( rowtime , interval ' % d ' second ) as rowtime " + <nl> " from ( % s ) " +
public abstract class nettymessage { <nl> msg . release ( ) ; <nl> } <nl> } <nl> + <nl> + @ override <nl> + protected bytebuf extractframe ( channelhandlercontext ctx , bytebuf buffer , int index , int length ) { <nl> + if ( restoreoldnettybehaviour ) { <nl> + / * <nl> + * for non - credit based code paths with netty > = num . 0 . 28 . final : <nl> + * these versions contain an improvement by netty , which slices a netty buffer <nl> + * instead of doing a memory copy [ 1 ] in the <nl> + * lengthfieldbasedframedecoder . in some situations , this <nl> + * interacts badly with our netty pipeline leading to outofmemory <nl> + * errors . <nl> + * <nl> + * [ 1 ] https : / / github . com / netty / netty / issues / 3704 <nl> + * <nl> + * <nl> + * / <nl> + bytebuf frame = ctx . alloc ( ) . buffer ( length ) ; <nl> + frame . writebytes ( buffer , index , length ) ; <nl> + return frame ; <nl> + } else { <nl> + return super . extractframe ( ctx , buffer , index , length ) ; <nl> + } <nl> + } <nl> } <nl>  <nl> / / - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - <nl> mmm a / flink - runtime / src / main / java / org / apache / flink / runtime / io / network / netty / nettyprotocol . java <nl> ppp b / flink - runtime / src / main / java / org / apache / flink / runtime / io / network / netty / nettyprotocol . java <nl>
public class flinkyarnsessioncli extends abstractcustomcommandline < applicationid <nl> throw new illegalargumentexception ( " missing required argument " + container . getopt ( ) ) ; <nl> } <nl>  <nl> - int numbertaskmanagers = integer . valueof ( cmd . getoptionvalue ( container . getopt ( ) ) ) ; <nl> + <nl> + final int numbertaskmanagers ; <nl> + <nl> + if ( cmd . hasoption ( container . getopt ( ) ) ) { <nl> + numbertaskmanagers = integer . valueof ( cmd . getoptionvalue ( container . getopt ( ) ) ) ; <nl> + } else { <nl> + numbertaskmanagers = num ; <nl> + } <nl>  <nl> / / jobmanager memory <nl> final int jobmanagermemorymb = configuration . getinteger ( jobmanageroptions . job_manager_heap_memory ) ; <nl>
public abstract class restserverendpoint { <nl> childgroupfuture . completeexceptionally ( finished . cause ( ) ) ; <nl> } <nl> } ) ; <nl> + } else { <nl> + childgroupfuture . complete ( null ) ; <nl> } <nl> + <nl> bootstrap = null ; <nl> } else { <nl> / / complete the group futures since there is nothing to stop <nl> groupfuture . complete ( null ) ; <nl> childgroupfuture . complete ( null ) ; <nl> } <nl> - } ) ; <nl>  <nl> - final completablefuture < void > channelterminationfuture = futureutils . completeall ( <nl> - arrays . aslist ( groupfuture , childgroupfuture ) ) ; <nl> + completablefuture < void > combinedfuture = futureutils . completeall ( arrays . aslist ( groupfuture , childgroupfuture ) ) ; <nl> + <nl> + <nl> + futureutils . ortimeout ( combinedfuture , graceperiod . tomilliseconds ( ) , timeunit . milliseconds ) ; <nl> + <nl> + combinedfuture <nl> + . exceptionally ( <nl> + ( throwable throwable ) - > { <nl> + if ( throwable instanceof timeoutexception ) { <nl> + / / we ignore timeout exceptions because they indicate that netty ' s shut down deadlocked <nl> + log . info ( " could not properly shut down netty . continue shut down of restserverendpoint . " ) ; <nl> + return null ; <nl> + } else { <nl> + throw new completionexception ( exceptionutils . stripcompletionexception ( throwable ) ) ; <nl> + } <nl> + } ) <nl> + . whencomplete ( <nl> + ( void ignored , throwable throwable ) - > { <nl> + if ( throwable ! = null ) { <nl> + channelterminationfuture . completeexceptionally ( throwable ) ; <nl> + } else { <nl> + channelterminationfuture . complete ( null ) ; <nl> + } <nl> + } ) ; <nl> + } ) ; <nl>  <nl> return futureutils . runafterwards ( <nl> channelterminationfuture ,
public class datainputdeserializer implements datainputview , java . io . serializabl <nl> this . buffer = buffer . array ( ) ; <nl> this . position = buffer . arrayoffset ( ) + buffer . position ( ) ; <nl> this . end = this . position + buffer . remaining ( ) ; <nl> - } else if ( buffer . isdirect ( ) ) { <nl> + } else if ( buffer . isdirect ( ) | | buffer . isreadonly ( ) ) { <nl> + <nl> this . buffer = new byte [ buffer . remaining ( ) ] ; <nl> this . position = num ; <nl> this . end = this . buffer . length ;
public class sharedstateregistry implements autocloseable { <nl> / / we do the small optimization to not issue discards for placeholders , which are nops . <nl> if ( streamstatehandle ! = null & & ! isplaceholder ( streamstatehandle ) ) { <nl> log . trace ( " scheduled delete of state handle { } . " , streamstatehandle ) ; <nl> - asyncdisposalexecutor . execute ( <nl> - new sharedstateregistry . asyncdisposalrunnable ( streamstatehandle ) ) ; <nl> + asyncdisposalrunnable asyncdisposalrunnable = new asyncdisposalrunnable ( streamstatehandle ) ; <nl> + try { <nl> + asyncdisposalexecutor . execute ( asyncdisposalrunnable ) ; <nl> + } catch ( rejectedexecutionexception ex ) { <nl> + <nl> + / / this leads to rejectedexecutionexception once the async deletes are triggered by zk . we need to <nl> + / / wait for all pending zk deletes before closing the i / o executor pool . we can simply call # run ( ) <nl> + / / because we are already in the async zk thread that disposes the handles . <nl> + asyncdisposalrunnable . run ( ) ; <nl> + } <nl> } <nl> }
class testingcluster ( <nl> result match { <nl> case success : checkpointrequestsuccess = > success . path <nl> case fail : checkpointrequestfailure = > { <nl> - if ( fail . cause . getmessage . contains ( " tasks not ready " ) ) { <nl> - / / retry if the tasks are not ready yet . <nl> - thread . sleep ( 50 ) <nl> - requestcheckpoint ( jobid , options ) <nl> - } else { <nl> - throw new ioexception ( fail . cause ) <nl> + <nl> + / / testingjobmanagermessages . waitforallverticestoberunning ( . . . ) works <nl> + / / properly . <nl> + if ( fail . cause ! = null ) { <nl> + val innercause = fail . cause . getcause <nl> + if ( innercause ! = null <nl> + & & innercause . getmessage . contains ( " tasks not ready " ) ) { <nl> + / / retry if the tasks are not ready yet . <nl> + thread . sleep ( 50 ) <nl> + return requestcheckpoint ( jobid , options ) <nl> + } <nl> } <nl> + throw new ioexception ( fail . cause ) <nl> } <nl> case _ = > throw new illegalstateexception ( " trigger checkpoint failed " ) <nl> }
public abstract class abstractoperatorrestoretestbase extends testlogger { <nl> / / trigger savepoint <nl> file targetdirectory = tmpfolder . newfolder ( ) ; <nl> msg = new jobmanagermessages . canceljobwithsavepoint ( jobtomigrate . getjobid ( ) , targetdirectory . getabsolutepath ( ) ) ; <nl> - future < object > future = jobmanager . ask ( msg , timeout ) ; <nl> - result = await . result ( future , timeout ) ; <nl> + <nl> + / / flink - 6918 : retry cancel with savepoint message in case that streamtasks were not running <nl> + <nl> + boolean retry = true ; <nl> + for ( int i = num ; retry & & i < num ; i + + ) { <nl> + future < object > future = jobmanager . ask ( msg , timeout ) ; <nl> + result = await . result ( future , timeout ) ; <nl> + <nl> + if ( result instanceof jobmanagermessages . cancellationfailure ) { <nl> + thread . sleep ( 50l ) ; <nl> + } else { <nl> + retry = false ; <nl> + } <nl> + } <nl>  <nl> if ( result instanceof jobmanagermessages . cancellationfailure ) { <nl> jobmanagermessages . cancellationfailure failure = ( jobmanagermessages . cancellationfailure ) result ;
public interface kinesisdeserializationschema < t > extends serializable , resulttyp <nl> * @ param nextelement the element to test for the end - of - stream signal <nl> * @ return true if the element signals end of stream , false otherwise <nl> * / <nl> - boolean isendofstream ( t nextelement ) ; <nl> + <nl> } <nl> mmm a / flink - streaming - connectors / flink - connector - kinesis / src / main / java / org / apache / flink / streaming / connectors / kinesis / serialization / kinesisdeserializationschemawrapper . java <nl> ppp b / flink - streaming - connectors / flink - connector - kinesis / src / main / java / org / apache / flink / streaming / connectors / kinesis / serialization / kinesisdeserializationschemawrapper . java <nl>
public abstract class tezprogramtestbase extends abstracttestbase { <nl> / / test entry point <nl> / / - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - <nl>  <nl> + / / ignored due to deadlocks in tez num . 6 . 1 ( https : / / s3 . amazonaws . com / archive . travis - ci . org / jobs / 67848151 / log . txt ) <nl> + <nl> + @ ignore <nl> @ test <nl> public void testjob ( ) throws exception { <nl> / / pre - submit
public class execution { <nl> @ override <nl> public taskoperationresult call ( ) throws exception { <nl> instance instance = slot . getinstance ( ) ; <nl> - return instance . submittask ( deployment ) ; <nl> + / / return instance . submittask ( deployment ) ; <nl> + <nl> + <nl> + return ( taskoperationresult ) patterns . ask ( instance . gettaskmanager ( ) , new taskmanagermessages <nl> + . submittask ( deployment ) , akkautils . future_timeout ( ) ) ; <nl> } <nl> } , akkautils . globalexecutioncontext ( ) ) ; <nl>  <nl> mmm a / flink - runtime / src / main / java / org / apache / flink / runtime / jobmanager / web / jobmanagerinfoservlet . java <nl> ppp b / flink - runtime / src / main / java / org / apache / flink / runtime / jobmanager / web / jobmanagerinfoservlet . java <nl>
public class streamrecord implements ioreadablewritable , serializable { <nl> } <nl>  <nl> private void writetuple ( tuple tuple , dataoutput out ) { <nl> + <nl> class [ ] basictypes = new class [ tuple . getarity ( ) ] ; <nl> stringbuilder basictypenames = new stringbuilder ( ) ; <nl>  <nl> + <nl> for ( int i = num ; i < basictypes . length ; i + + ) { <nl> basictypes [ i ] = tuple . getfield ( i ) . getclass ( ) ; <nl> basictypenames . append ( basictypes [ i ] . getname ( ) + " , " ) ; <nl> mmm a / flink - addons / flink - streaming / src / test / java / eu / stratosphere / streaming / api / streamcomponent / streamcomponenttest . java <nl> ppp b / flink - addons / flink - streaming / src / test / java / eu / stratosphere / streaming / api / streamcomponent / streamcomponenttest . java <nl>
public class faulttolerancebuffer { <nl> public void addrecord ( streamrecord streamrecord ) { <nl> string id = streamrecord . getid ( ) ; <nl> recordbuffer . put ( id , streamrecord . copy ( ) ) ; <nl> - ackcounter . put ( id , numberofoutputs ) ; <nl> + ackcounter . put ( id , numberofchannels ) ; <nl>  <nl> - ackmap . put ( id , numberofoutputchannels . clone ( ) ) ; <nl> + <nl> + / / <nl> + / / for ( int i = num ; i < numberofoutputchannels . length ; i + + ) { <nl> + / / ackcounts [ i + num ] = numberofoutputchannels [ i ] ; <nl> + / / } <nl> + / / <nl> + / / ackmap . put ( id , ackcounts ) ; <nl>  <nl> addtimestamp ( id ) ; <nl> log . trace ( " record added to buffer : " + id ) ; <nl>
public class logutils { <nl> public static void initializedefaultconsolelogger ( level loglevel , level rootlevel ) { <nl> logger logger = logger . getlogger ( " eu . stratosphere . streaming " ) ; <nl> logger . removeallappenders ( ) ; <nl> - patternlayout layout = new patternlayout ( <nl> - " % d { hh : mm : ss , sss } % - 5p % - 60c % x - % m % n " ) ; <nl> + patternlayout layout = new patternlayout ( ) ; <nl> + / / layout . setconversionpattern ( " % highlight { % d { hh : mm : ss , sss } % - 5p % - 60c % x - % m % n } " ) ; <nl> + <nl> + layout . setconversionpattern ( " % d { hh : mm : ss , sss } % - 5p % - 60c % x - % m % n " ) ; <nl> consoleappender appender = new consoleappender ( layout , " system . err " ) ; <nl> logger . addappender ( appender ) ; <nl> logger . setlevel ( loglevel ) ;
public abstract class streaminvokable { <nl> public final void emit ( record record ) { <nl> for ( recordwriter < record > output : outputs ) { <nl> try { <nl> - output . emit ( streamrecordprovider . adduuid ( record ) ) ; <nl> + <nl> + long uuid = streamrecordprovider . adduuid ( record ) ; <nl> + output . emit ( record ) ; <nl> } catch ( exception e ) { <nl> system . out . println ( " emit error " ) ; <nl> }
public class crossitcase extends javaprogramtestbase { <nl> " 4 , hallo welt wiehallo welt wie\n " ; <nl>  <nl> } <nl> + <nl> / / case num : { <nl> / / <nl> / / / * <nl>
public class crossitcase extends javaprogramtestbase { <nl> / / " 4 , 3 , hallo welt wiehallo welt\n " + <nl> / / " , 44 , hallo welt wiehallo welt wie\n " ; <nl> / / } <nl> + <nl> / / case num : { <nl> / / <nl> / / / * <nl>
public class typeextractor { <nl> tuplesubtypes [ i ] = createtypeinfo ( subtypes [ i ] ) ; <nl> } <nl>  <nl> - return new tupletypeinfo ( tuplesubtypes ) ; <nl> + <nl> + / / we might want to add an extendedtupleserializer for that . <nl> + <nl> + return new tupletypeinfo ( ( ( class < ? extends tuple > ) t ) , tuplesubtypes ) ; <nl> } <nl> }
public abstract class fileinputformat < ot > implements inputformat < ot , fileinputsp <nl> if ( filepath = = null ) <nl> throw new illegalargumentexception ( " file path may not be null . " ) ; <nl>  <nl> + <nl> + / / this situation and we should fix this . <nl> + if ( filepath . isempty ( ) ) { <nl> + setfilepath ( new path ( ) ) ; <nl> + return ; <nl> + } <nl> + <nl> setfilepath ( new path ( filepath ) ) ; <nl> } <nl>  <nl> mmm a / pact / pact - tests / src / test / java / eu / stratosphere / pact / compiler / plandump / previewplandumptest . java <nl> ppp b / pact / pact - tests / src / test / java / eu / stratosphere / pact / compiler / plandump / previewplandumptest . java <nl>
public final class rpcservice { <nl> / / request is no longer pending <nl> this . pendingrequests . remove ( messageid ) ; <nl>  <nl> + <nl> + <nl> packets = messagetopackets ( remotesocketaddress , new rpccleanup ( request . getmessageid ( ) ) ) ; <nl> sendpackets ( packets ) ; <nl>  <nl>
public final class rpcservice { <nl>  <nl> this . pendingrequests . remove ( messageid ) ; <nl>  <nl> + <nl> + <nl> throw new ioexception ( " unable to complete rpc of method " + request . getmethodname ( ) + " on " <nl> + remotesocketaddress ) ; <nl> } <nl> mmm / dev / null <nl> ppp b / nephele / nephele - common / src / main / java / eu / stratosphere / nephele / rpc / rpcstatistics . java <nl>
public final class envelopeconsumptionlog { <nl> log . debug ( " initial log entries : " + this . numberofinitiallogentries + " , announced " <nl> + this . numberofannouncedenvelopes ) ; <nl> log . debug ( " outstanding buffer : " + this . outstandingenvelopesasintbuffer . remaining ( ) ) ; <nl> - showoustandingenvelopelog ( ) ; <nl> + <nl> } <nl>  <nl> if ( ! this . outstandingenvelopesasintbuffer . hasremaining ( ) ) {
public class fixedsizeclustercostestimator extends costestimator { <nl> costs . setsecondarystoragecost ( - 1 ) ; <nl> } <nl>  <nl> - } else { <nl> - / / if data distribution is given , no extra sampling has to be done = > same cost as hashpartitioning <nl> - <nl> - if ( conn . getsourcepact ( ) . getestimatedoutputsize ( ) ! = - 1 ) { <nl> - long estoutshipsize = ( long ) conn . getreplicationfactor ( ) * conn . getsourcepact ( ) . getestimatedoutputsize ( ) ; <nl> - costs . setnetworkcost ( estoutshipsize ) ; <nl> - } else { <nl> - / / no costs known <nl> - costs . setnetworkcost ( - 1 ) ; <nl> - } <nl> - costs . setsecondarystoragecost ( 0 ) ; <nl> + <nl> + / / / / if data distribution is given , no extra sampling has to be done = > same cost as hashpartitioning <nl> + / / <nl> + / / if ( conn . getsourcepact ( ) . getestimatedoutputsize ( ) ! = - 1 ) { <nl> + / / long estoutshipsize = ( long ) conn . getreplicationfactor ( ) * conn . getsourcepact ( ) . getestimatedoutputsize ( ) ; <nl> + / / costs . setnetworkcost ( estoutshipsize ) ; <nl> + / / } else { <nl> + / / / / no costs known <nl> + / / costs . setnetworkcost ( - 1 ) ; <nl> + / / } <nl> + / / costs . setsecondarystoragecost ( 0 ) ; <nl>  <nl> } <nl> }
<nl> + package eu . stratosphere . pact . runtime . iterative . task ; <nl> + <nl> + import eu . stratosphere . nephele . io . mutablerecordreader ; <nl> + import eu . stratosphere . nephele . template . abstractoutputtask ; <nl> + import eu . stratosphere . pact . common . type . pactrecord ; <nl> + import eu . stratosphere . pact . common . util . mutableobjectiterator ; <nl> + import eu . stratosphere . pact . runtime . iterative . event . allworkersdoneevent ; <nl> + import eu . stratosphere . pact . runtime . iterative . io . interruptingmutableobjectiterator ; <nl> + import eu . stratosphere . pact . runtime . task . regularpacttask ; <nl> + import eu . stratosphere . pact . runtime . task . util . pactrecordnephelereaderiterator ; <nl> + import eu . stratosphere . pact . runtime . task . util . readerinterruptionbehaviors ; <nl> + import eu . stratosphere . pact . runtime . task . util . taskconfig ; <nl> + import org . apache . commons . logging . log ; <nl> + import org . apache . commons . logging . logfactory ; <nl> + <nl> + import java . io . ioexception ; <nl> + import java . util . concurrent . atomic . atomicboolean ; <nl> + <nl> + public class bulkiterationsynchronizationsink extends abstractoutputtask implements terminable { <nl> + <nl> + private taskconfig taskconfig ; <nl> + <nl> + private mutableobjectiterator < pactrecord > recorditerator ; <nl> + private mutablerecordreader < pactrecord > reader ; <nl> + <nl> + private int numiterations ; <nl> + <nl> + private final atomicboolean terminated = new atomicboolean ( false ) ; <nl> + <nl> + / / this task will never see any records , just events <nl> + private static final pactrecord dummy = new pactrecord ( ) ; <nl> + <nl> + private static final log log = logfactory . getlog ( bulkiterationsynchronizationsink . class ) ; <nl> + <nl> + @ override <nl> + public void registerinputoutput ( ) { <nl> + <nl> + string name = getenvironment ( ) . gettaskname ( ) + " ( " + ( getenvironment ( ) . getindexinsubtaskgroup ( ) + num ) + ' / ' + <nl> + getenvironment ( ) . getcurrentnumberofsubtasks ( ) + " ) " ; <nl> + int numberofeventsuntilinterrupt = taskconfig . getnumberofeventsuntilinterruptiniterativegate ( 0 ) ; <nl> + <nl> + reader = new mutablerecordreader < pactrecord > ( this ) ; <nl> + recorditerator = new interruptingmutableobjectiterator < pactrecord > ( new pactrecordnephelereaderiterator ( reader , <nl> + readerinterruptionbehaviors . false_on_interrupt ) , numberofeventsuntilinterrupt , name , this ) ; <nl> + } <nl> + <nl> + @ override <nl> + public boolean isterminated ( ) { <nl> + return terminated . get ( ) ; <nl> + } <nl> + <nl> + @ override <nl> + public void terminate ( ) { <nl> + if ( log . isinfoenabled ( ) ) { <nl> + log . info ( formatlogstring ( " marked as terminated . " ) ) ; <nl> + } <nl> + terminated . set ( true ) ; <nl> + } <nl> + <nl> + @ override <nl> + public void invoke ( ) throws exception { <nl> + <nl> + while ( ! isterminated ( ) ) { <nl> + <nl> + if ( log . isinfoenabled ( ) ) { <nl> + log . info ( formatlogstring ( " starting iteration [ " + numiterations + " ] " ) ) ; <nl> + } <nl> + <nl> + readinput ( ) ; <nl> + <nl> + if ( log . isinfoenabled ( ) ) { <nl> + log . info ( formatlogstring ( " finishing iteration [ " + numiterations + " ] " ) ) ; <nl> + } <nl> + <nl> + if ( ! isterminated ( ) ) { <nl> + if ( log . isinfoenabled ( ) ) { <nl> + log . info ( formatlogstring ( " signaling that all workers are done in iteration [ " + numiterations + " ] " ) ) ; <nl> + } <nl> + <nl> + signalallworkersdone ( ) ; <nl> + } <nl> + <nl> + numiterations + + ; <nl> + } <nl> + <nl> + } <nl> + <nl> + private void readinput ( ) throws ioexception { <nl> + boolean recordfound ; <nl> + while ( recordfound = recorditerator . next ( dummy ) ) { <nl> + if ( recordfound ) { <nl> + throw new illegalstateexception ( " synchronization task shall never see any records ! " ) ; <nl> + } <nl> + } <nl> + } <nl> + <nl> + private void signalallworkersdone ( ) throws ioexception , interruptedexception { <nl> + reader . publishevent ( new allworkersdoneevent ( ) ) ; <nl> + } <nl> + <nl> + <nl> + public string formatlogstring ( string message ) { <nl> + return regularpacttask . constructlogstring ( message , getenvironment ( ) . gettaskname ( ) , this ) ; <nl> + } <nl> + <nl> + }
public class pactconnection { <nl> if ( source . getdegreeofparallelism ( ) > target . getdegreeofparallelism ( ) ) { <nl> gp . setordering ( null ) ; <nl> } <nl> + <nl> + if ( gp . getpartitioning ( ) = = partitionproperty . none ) { <nl> + if ( source . getuniquefields ( ) . size ( ) > num ) { <nl> + fieldlist partitionedfields = new fieldlist ( ) ; <nl> + <nl> + for ( integer field : source . getuniquefields ( ) . iterator ( ) . next ( ) ) { <nl> + partitionedfields . add ( field ) ; <nl> + } <nl> + gp . setpartitioning ( partitionproperty . any , partitionedfields ) ; <nl> + } <nl> + } <nl> + <nl> / / nothing else changes <nl> break ; <nl> case none : <nl>
public class pactconnection { <nl> else { <nl> lp . reset ( ) ; <nl> } <nl> + <nl> + if ( lp . isgrouped ( ) = = false & & shipmode ! = shipstrategy . broadcast & & shipmode ! = shipstrategy . sfr ) { <nl> + if ( source . getuniquefields ( ) . size ( ) > num ) { <nl> + <nl> + lp . setgrouped ( true , source . getuniquefields ( ) . iterator ( ) . next ( ) ) ; <nl> + } <nl> + } <nl>  <nl> return lp ; <nl> }
public final class defaultdeserializer extends abstractdeserializer { <nl> this . lastdeserializedsourceid = getdeserializedsourceid ( ) ; <nl> } <nl>  <nl> - setbuffer ( this . bufferprovider . requestemptybufferblocking ( getsizeofbuffer ( ) ) ) ; <nl> + final buffer buf = this . bufferprovider . requestemptybuffer ( getsizeofbuffer ( ) ) ; <nl>  <nl> - if ( getbuffer ( ) = = null ) { <nl> + if ( buf = = null ) { <nl>  <nl> - thread . sleep ( 100 ) ; <nl> - / / wait for num milliseconds , so the nio thread won ' t do busy <nl> + <nl> + thread . sleep ( 1 ) ; <nl> + / / wait for num milliseconds , so the nio thread won ' t do busy <nl> / / waiting . . . <nl>  <nl> return true ; <nl> } <nl> + <nl> + setbuffer ( buf ) ; <nl> + <nl> } catch ( interruptedexception e ) { <nl> return true ; <nl> }
<nl> + package eu . stratosphere . pact . common . contract ; <nl> + <nl> + import eu . stratosphere . pact . common . plan . visitor ; <nl> + <nl> + <nl> + / * * <nl> + * <nl> + * <nl> + * @ author stephan ewen <nl> + * / <nl> + public class iteration extends contract <nl> + { <nl> + <nl> + <nl> + <nl> + public void setinitialpartialsolution ( contract input ) <nl> + { } <nl> + <nl> + public void setiterationresult ( contract result ) <nl> + { } <nl> + <nl> + public contract getiterationinput ( ) <nl> + { <nl> + return null ; <nl> + } <nl> + <nl> + public void setterminationcriterion ( contract criterion ) <nl> + { } <nl> + <nl> + public void setnumberofiteration ( int num ) <nl> + { } <nl> + <nl> + / * ( non - javadoc ) <nl> + * @ see eu . stratosphere . pact . common . plan . visitable # accept ( eu . stratosphere . pact . common . plan . visitor ) <nl> + * / <nl> + @ override <nl> + public void accept ( visitor < contract > visitor ) { <nl> + <nl> + <nl> + } <nl> + <nl> + / * ( non - javadoc ) <nl> + * @ see eu . stratosphere . pact . common . contract . contract # getusercodeclass ( ) <nl> + * / <nl> + @ override <nl> + public class < ? > getusercodeclass ( ) <nl> + { <nl> + return null ; <nl> + } <nl> + }
public final class bytebufferedchannelmanager implements transferenvelopedispatc <nl>  <nl> final channelcontext cc = this . registeredchannels . get ( localreceiver ) ; <nl> if ( cc = = null ) { <nl> - throw new ioexception ( " cannot find channel context for local receiver " + localreceiver ) ; <nl> + <nl> + if ( this . recentlyremovedchannelidset . contains ( localreceiver ) ) { <nl> + <nl> + return ; <nl> + } else { <nl> + throw new ioexception ( " cannot find channel context for local receiver " + localreceiver ) ; <nl> + } <nl> } <nl>  <nl> if ( ! cc . isinputchannel ( ) ) { <nl> mmm a / nephele / nephele - server / src / main / java / eu / stratosphere / nephele / taskmanager / bytebuffered / inputchannelcontext . java <nl> ppp b / nephele / nephele - server / src / main / java / eu / stratosphere / nephele / taskmanager / bytebuffered / inputchannelcontext . java <nl>
public class taskmanager implements taskoperationprotocol { <nl> public serializablearraylist < checkpointreplayresult > replaycheckpoints ( final list < executionvertexid > vertexids ) <nl> throws ioexception { <nl>  <nl> + <nl> + <nl> final serializablearraylist < checkpointreplayresult > checkpointresultlist = new serializablearraylist < checkpointreplayresult > ( ) ; <nl>  <nl> for ( final executionvertexid vertexid : vertexids ) { <nl> mmm a / nephele / nephele - server / src / main / java / eu / stratosphere / nephele / taskmanager / bytebuffered / bytebufferedchannelmanager . java <nl> ppp b / nephele / nephele - server / src / main / java / eu / stratosphere / nephele / taskmanager / bytebuffered / bytebufferedchannelmanager . java <nl>
public class pactrecordtest { <nl> / / public void testunion ( ) { <nl> / / } <nl>  <nl> + @ test <nl> + public void testupdatebinaryrepresentations ( ) { <nl> + <nl> + <nl> + pactrecord r = new pactrecord ( ) ; <nl> + <nl> + pactinteger i1 = new pactinteger ( 1 ) ; <nl> + pactinteger i2 = new pactinteger ( 2 ) ; <nl> + <nl> + try { <nl> + r . setfield ( 1 , i1 ) ; <nl> + r . setfield ( 3 , i2 ) ; <nl> + <nl> + r . setnumfields ( 5 ) ; <nl> + <nl> + r . updatebinaryrepresenation ( ) ; <nl> + <nl> + i1 = new pactinteger ( 3 ) ; <nl> + i2 = new pactinteger ( 4 ) ; <nl> + <nl> + r . setfield ( 7 , i1 ) ; <nl> + r . setfield ( 8 , i2 ) ; <nl> + <nl> + r . updatebinaryrepresenation ( ) ; <nl> + <nl> + asserttrue ( r . getfield ( 1 , pactinteger . class ) . getvalue ( ) = = num ) ; <nl> + asserttrue ( r . getfield ( 3 , pactinteger . class ) . getvalue ( ) = = num ) ; <nl> + asserttrue ( r . getfield ( 7 , pactinteger . class ) . getvalue ( ) = = num ) ; <nl> + asserttrue ( r . getfield ( 8 , pactinteger . class ) . getvalue ( ) = = num ) ; <nl> + } catch ( runtimeexception re ) { <nl> + fail ( " error updating binary representation : " + re . getmessage ( ) ) ; <nl> + } <nl> + <nl> + } <nl> + <nl> @ test <nl> public void testdeserialization ( ) { <nl> pactstring origvalue1 = new pactstring ( " hello world ! " ) ;
<nl> + package eu . stratosphere . pact . runtime . task . chaining ; <nl> + <nl> + import java . util . arraylist ; <nl> + import java . util . iterator ; <nl> + import java . util . list ; <nl> + <nl> + import junit . framework . assert ; <nl> + <nl> + import org . apache . commons . logging . log ; <nl> + import org . apache . commons . logging . logfactory ; <nl> + import org . junit . test ; <nl> + <nl> + import eu . stratosphere . nephele . configuration . configuration ; <nl> + import eu . stratosphere . pact . common . stubs . collector ; <nl> + import eu . stratosphere . pact . common . stubs . reducestub ; <nl> + import eu . stratosphere . pact . common . type . pactrecord ; <nl> + import eu . stratosphere . pact . common . type . base . pactinteger ; <nl> + import eu . stratosphere . pact . runtime . task . maptask ; <nl> + import eu . stratosphere . pact . runtime . task . maptasktest . mockmapstub ; <nl> + import eu . stratosphere . pact . runtime . task . reducetasktest . mockreducestub ; <nl> + import eu . stratosphere . pact . runtime . task . util . taskconfig ; <nl> + import eu . stratosphere . pact . runtime . task . util . taskconfig . localstrategy ; <nl> + import eu . stratosphere . pact . runtime . test . util . regularlygeneratedinputgenerator ; <nl> + import eu . stratosphere . pact . runtime . test . util . tasktestbase ; <nl> + <nl> + / * * <nl> + * <nl> + * @ author enijkamp <nl> + * <nl> + * / <nl> + @ suppresswarnings ( " javadoc " ) <nl> + public class chaintasktest extends tasktestbase { <nl> + <nl> + private static final log log = logfactory . getlog ( chaintasktest . class ) ; <nl> + <nl> + list < pactrecord > outlist = new arraylist < pactrecord > ( ) ; <nl> + <nl> + @ suppresswarnings ( " unchecked " ) <nl> + @ test <nl> + public void testmaptask ( ) { <nl> + <nl> + int keycnt = num ; <nl> + int valcnt = num ; <nl> + <nl> + / / environment <nl> + { <nl> + super . initenvironment ( 3 * 1024 * 1024 ) ; <nl> + super . addinput ( new regularlygeneratedinputgenerator ( keycnt , valcnt , false ) , num ) ; <nl> + super . addoutput ( this . outlist ) ; <nl> + } <nl> + <nl> + / / chained combine config <nl> + { <nl> + configuration config = new configuration ( ) ; <nl> + config . addall ( super . getconfiguration ( ) , " " ) ; <nl> + taskconfig combineconfig = new taskconfig ( config ) ; <nl> + <nl> + combineconfig . setstubclass ( mockreducestub . class ) ; <nl> + combineconfig . setlocalstrategy ( localstrategy . combiningsort ) ; <nl> + combineconfig . setmemorysize ( 3 * num * num ) ; <nl> + combineconfig . setnumfilehandles ( 2 ) ; <nl> + combineconfig . setlocalstrategykeytypes ( 0 , new int [ ] { 0 } ) ; <nl> + combineconfig . setlocalstrategykeytypes ( new class [ ] { pactinteger . class } ) ; <nl> + <nl> + super . gettaskconfig ( ) . addchainedtask ( chainedcombinetask . class , combineconfig , " combine " ) ; <nl> + } <nl> + <nl> + / / chained map + combine <nl> + { <nl> + maptask testtask = new maptask ( ) ; <nl> + <nl> + super . registertask ( testtask , mockmapstub . class ) ; <nl> + <nl> + try { <nl> + testtask . invoke ( ) ; <nl> + } catch ( exception e ) { <nl> + log . debug ( e ) ; <nl> + assert . fail ( " invoke method caused exception . " ) ; <nl> + } <nl> + } <nl> + <nl> + assert . assertequals ( keycnt , this . outlist . size ( ) ) ; <nl> + <nl> + } <nl> + <nl> + / * * <nl> + * <nl> + * num . chainedcombinetask . collect gets called <nl> + * num . chainedcombinetask . collect calls done . . . combing takes a while . . . <nl> + * num . chainedcombinetask . combinerthread sets chainedcombinetask . exception <nl> + * num . additional call to chainedcombinetask . collect ( which triggers exception throwing ) is missing <nl> + * / <nl> + @ suppresswarnings ( " unchecked " ) <nl> + @ test <nl> + public void testfailingmaptask ( ) { <nl> + <nl> + int keycnt = num ; <nl> + int valcnt = num ; <nl> + <nl> + / / environment <nl> + { <nl> + super . initenvironment ( 3 * 1024 * 1024 ) ; <nl> + super . addinput ( new regularlygeneratedinputgenerator ( keycnt , valcnt , false ) , num ) ; <nl> + super . addoutput ( this . outlist ) ; <nl> + } <nl> + <nl> + / / chained combine config <nl> + { <nl> + configuration config = new configuration ( ) ; <nl> + config . addall ( super . getconfiguration ( ) , " " ) ; <nl> + taskconfig combineconfig = new taskconfig ( config ) ; <nl> + <nl> + combineconfig . setstubclass ( mockfailingcombinestub . class ) ; <nl> + combineconfig . setlocalstrategy ( localstrategy . combiningsort ) ; <nl> + combineconfig . setmemorysize ( 3 * num * num ) ; <nl> + combineconfig . setnumfilehandles ( 2 ) ; <nl> + combineconfig . setlocalstrategykeytypes ( 0 , new int [ ] { 0 } ) ; <nl> + combineconfig . setlocalstrategykeytypes ( new class [ ] { pactinteger . class } ) ; <nl> + <nl> + super . gettaskconfig ( ) . addchainedtask ( chainedcombinetask . class , combineconfig , " combine " ) ; <nl> + } <nl> + <nl> + / / chained map + combine <nl> + { <nl> + maptask testtask = new maptask ( ) ; <nl> + <nl> + super . registertask ( testtask , mockmapstub . class ) ; <nl> + <nl> + boolean stubfailed = false ; <nl> + <nl> + try { <nl> + testtask . invoke ( ) ; <nl> + } catch ( exception e ) { <nl> + stubfailed = true ; <nl> + } <nl> + <nl> + assert . asserttrue ( " stub exception was not forwarded . " , stubfailed ) ; <nl> + } <nl> + } <nl> + <nl> + public static class mockfailingcombinestub extends reducestub { <nl> + <nl> + int cnt = num ; <nl> + <nl> + @ override <nl> + public void reduce ( iterator < pactrecord > records , collector out ) <nl> + throws exception { <nl> + if ( + + this . cnt > = 5 ) { <nl> + throw new runtimeexception ( " expected test exception " ) ; <nl> + } <nl> + while ( records . hasnext ( ) ) <nl> + out . collect ( records . next ( ) ) ; <nl> + } <nl> + <nl> + } <nl> + <nl> + }
public final class checkpointdecisioncoordinator { <nl> / / propagate checkpoint decisions <nl> this . decisionpropagator . propagatecheckpointdecisions ( checkpointdecisions ) ; <nl> } <nl> + <nl> + private boolean getdecision ( final executionvertex vertex , final resourceutilizationsnapshot rus ) { <nl> + / / this implementation always creates the checkpoint <nl> + if ( rus . getforced ( ) = = null ) { <nl> + if ( rus . gettotalinputamount ( ) ! = num & & ( rus . gettotaloutputamount ( ) * num . 0 / rus . gettotalinputamount ( ) > num . 0 ) ) { <nl> + / / estimated size of checkpoint <nl> + <nl> + log . info ( " chechpoint to large selektivity " + ( rus . gettotaloutputamount ( ) * num . 0 / rus . gettotalinputamount ( ) > num . 0 ) ) ; <nl> + return false ; <nl> + <nl> + } <nl> + if ( rus . getusercpu ( ) > = num ) { <nl> + log . info ( " cpu - bottleneck " ) ; <nl> + / / cpu bottleneck <nl> + return true ; <nl> + } <nl> + <nl> + if ( vertex . getnumberofsuccessors ( ) ! = num <nl> + & & vertex . getnumberofpredecessors ( ) * num . 0 / vertex . getnumberofsuccessors ( ) > num . 5 ) { <nl> + log . info ( " vertex . getnumberofpredecessors ( ) / vertex . getnumberofsuccessors ( ) > num . 5 " ) ; <nl> + / / less output - channels than input - channels <nl> + / / checkpoint at this position probably saves network - traffic <nl> + return true ; <nl> + } <nl>  <nl> + } else { <nl> + / / checkpoint decision was forced by the user <nl> + return rus . getforced ( ) ; <nl> + } <nl> + / / fixme always create checkpoint for testing <nl> + return true ; <nl> + } <nl> + <nl> }
public class task implements executionobserver { <nl> * / <nl> public void initialexecutionresourcesexhausted ( ) { <nl>  <nl> - if ( this . environment . getexecutingthread ( ) ! = thread . currentthread ( ) ) { <nl> + <nl> + / * if ( this . environment . getexecutingthread ( ) ! = thread . currentthread ( ) ) { <nl> throw new concurrentmodificationexception ( <nl> " initialexecutionresourcesexhausted must be called from the task that executes the user code " ) ; <nl> - } <nl> + } * / <nl>  <nl> / / construct a resource utilization snapshot <nl> final long timestamp = system . currenttimemillis ( ) ;
public class tpchquery10 implements planassembler , planassemblerdescription { <nl> public groupkey ( ) { <nl> super ( ) ; <nl> } <nl> + <nl> + public boolean equals ( object other ) { <nl> + return compareto ( ( key ) other ) = = num ; <nl> + } <nl> + <nl> + public int hashcode ( ) { <nl> + <nl> + return tostring ( ) . hashcode ( ) ; <nl> + } <nl>  <nl> @ override <nl> public int compareto ( key o ) {
public final class bytebufferedchannelmanager implements transferenvelopedispatc <nl>  <nl> final channelcontext cc = this . registeredchannels . get ( localreceiver ) ; <nl> if ( cc = = null ) { <nl> - throw new ioexception ( " cannot find channel context for local receiver " + localreceiver ) ; <nl> + <nl> + log . warn ( " cannot find channel context for local receiver " + localreceiver ) ; <nl> + continue ; <nl> } <nl>  <nl> if ( ! cc . isinputchannel ( ) ) {
public abstract class abstractinvokable { <nl> * <nl> * @ return the environment of this task or < code > null < / code > if the environment has not yet been set <nl> * / <nl> - public final environment getenvironment ( ) { <nl> + <nl> + public environment getenvironment ( ) { <nl> return this . environment ; <nl> }
public class unilateralsortmerger < k extends key , v extends value > implements sor <nl> / / set lazy iterator <nl> setresultiterator ( iterators . size ( ) = = num ? iterators . get ( 0 ) : <nl> new mergeiterator < k , v > ( iterators , keycomparator ) ) ; <nl> + <nl> + <nl> + printfinishmsg ( ) ; <nl> + <nl> return ; <nl> } <nl>  <nl>
public abstract class abstractbytebufferedinputchannel < t extends record > extends <nl> } <nl> } <nl>  <nl> + / * * <nl> + * { @ inheritdoc } <nl> + * / <nl> @ override <nl> public void activate ( ) throws ioexception , interruptedexception { <nl>  <nl> transferevent ( new bytebufferedchannelactivateevent ( ) ) ; <nl> } <nl> + <nl> + / * * <nl> + * { @ inheritdoc } <nl> + * / <nl> + @ override <nl> + public long getamountofdatatransmitted ( ) { <nl> + <nl> + <nl> + return num l ; <nl> + } <nl> } <nl> mmm a / nephele / nephele - common / src / main / java / eu / stratosphere / nephele / io / channels / bytebuffered / abstractbytebufferedoutputchannel . java <nl> ppp b / nephele / nephele - common / src / main / java / eu / stratosphere / nephele / io / channels / bytebuffered / abstractbytebufferedoutputchannel . java <nl>
public class environmentlistenerimpl implements executionlistener { <nl>  <nl> this . taskmanagerprofiler . registeruserthreadforcpuprofiling ( ee , userthread ) ; <nl> } <nl> + <nl> + / * * <nl> + * { @ inheritdoc } <nl> + * / <nl> + @ override <nl> + public void initialexecutionresourcesexhausted ( environment ee ) { <nl> + <nl> + <nl> + } <nl> }
public final class ec2cloudmanager extends timertask implements instancemanager <nl> final map < instancetype , instancetypedescription > availableinstances = new serializablehashmap < instancetype , instancetypedescription > ( ) ; <nl>  <nl> for ( final instancetype t : this . availableinstancetypes ) { <nl> - availableinstances . put ( t , instancetypedescriptionfactory . construct ( t , estimatehardwaredescription ( t ) , - 1 ) ) ; <nl> + <nl> + availableinstances <nl> + . put ( t , instancetypedescriptionfactory . construct ( t , estimatehardwaredescription ( t ) , num ) ) ; <nl> } <nl>  <nl> return availableinstances ;
public final class bytebufferedchannelmanager implements transferenvelopedispatc <nl> continue ; <nl> } <nl>  <nl> - final boolean isactive = activeoutputchannels . contains ( bboc . getid ( ) ) ; <nl> + final boolean isactive = / * activeoutputchannels . contains ( bboc . getid ( ) ) * / true ; <nl>  <nl> log . info ( " registering byte buffered output channel " + bboc . getid ( ) + " ( " <nl> + ( isactive ? " active " : " inactive " ) + " ) " ) ;
<nl> + / * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * <nl> + * <nl> + * copyright ( c ) num by the stratosphere project ( http : / / stratosphere . eu ) <nl> + * <nl> + * licensed under the apache license , version num . 0 ( the " license " ) ; you may not use this file except in compliance with <nl> + * the license . you may obtain a copy of the license at <nl> + * <nl> + * http : / / www . apache . org / licenses / license - 2 . 0 <nl> + * <nl> + * unless required by applicable law or agreed to in writing , software distributed under the license is distributed on <nl> + * an " as is " basis , without warranties or conditions of any kind , either express or implied . see the license for the <nl> + * specific language governing permissions and limitations under the license . <nl> + * <nl> + * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * / <nl> + <nl> + package eu . stratosphere . nephele . util ; <nl> + <nl> + import java . io . datainput ; <nl> + import java . io . dataoutput ; <nl> + import java . io . ioexception ; <nl> + import java . util . hashset ; <nl> + import java . util . iterator ; <nl> + <nl> + import eu . stratosphere . nephele . io . ioreadablewritable ; <nl> + import eu . stratosphere . nephele . types . stringrecord ; <nl> + <nl> + / * * <nl> + * this class extends a standard { @ link java . util . hashset } by implementing the <nl> + * { @ link eu . stratosphere . nephele . io . ioreadablewritable } interface . as a result , hash sets of this type can be used <nl> + * with nephele ' s rpc system . <nl> + * < p > <nl> + * this class is not thread - safe . <nl> + * <nl> + * @ author warneke <nl> + * @ param < t > <nl> + * the type used in this hash set <nl> + * / <nl> + public class serializablehashset < t extends ioreadablewritable > extends hashset < t > implements ioreadablewritable { <nl> + <nl> + / * * <nl> + * the generated serial version uid . <nl> + * / <nl> + private static final long serialversionuid = - 4615823301768215807l ; <nl> + <nl> + / * * <nl> + * { @ inheritdoc } <nl> + * / <nl> + @ override <nl> + public void write ( final dataoutput out ) throws ioexception { <nl> + <nl> + out . writeint ( size ( ) ) ; <nl> + <nl> + final iterator < t > it = iterator ( ) ; <nl> + <nl> + while ( it . hasnext ( ) ) { <nl> + <nl> + final t entry = it . next ( ) ; <nl> + stringrecord . writestring ( out , entry . getclass ( ) . getname ( ) ) ; <nl> + entry . write ( out ) ; <nl> + } <nl> + } <nl> + <nl> + / * * <nl> + * { @ inheritdoc } <nl> + * / <nl> + @ suppresswarnings ( " unchecked " ) <nl> + <nl> + @ override <nl> + public void read ( final datainput in ) throws ioexception { <nl> + <nl> + final int numberofmapentries = in . readint ( ) ; <nl> + <nl> + for ( int i = num ; i < numberofmapentries ; i + + ) { <nl> + <nl> + final string type = stringrecord . readstring ( in ) ; <nl> + class < t > clazz = null ; <nl> + try { <nl> + clazz = ( class < t > ) class . forname ( type ) ; <nl> + } catch ( classnotfoundexception e ) { <nl> + throw new ioexception ( stringutils . stringifyexception ( e ) ) ; <nl> + } <nl> + <nl> + t entry = null ; <nl> + try { <nl> + entry = clazz . newinstance ( ) ; <nl> + } catch ( exception e ) { <nl> + throw new ioexception ( stringutils . stringifyexception ( e ) ) ; <nl> + } <nl> + <nl> + entry . read ( in ) ; <nl> + <nl> + add ( entry ) ; <nl> + } <nl> + <nl> + } <nl> + <nl> + }
<nl> + package eu . stratosphere . pact . runtime . task . util ; <nl> + <nl> + import java . util . arrays ; <nl> + <nl> + import eu . stratosphere . pact . common . contract . order ; <nl> + import eu . stratosphere . pact . common . type . key ; <nl> + <nl> + public class histogrampartitionfunction implements partitionfunction { <nl> + private final key [ ] splitborders ; <nl> + private final order partitionorder ; <nl> + private final int [ ] channels = new int [ 1 ] ; <nl> + <nl> + public histogrampartitionfunction ( key [ ] splitborders , order partitionorder ) { <nl> + this . splitborders = splitborders ; <nl> + this . partitionorder = partitionorder ; <nl> + } <nl> + <nl> + @ override <nl> + public int [ ] selectchannels ( key data , int numchannels ) { <nl> + <nl> + int pos = arrays . binarysearch ( splitborders , data ) ; <nl> + if ( pos < num ) { <nl> + pos + + ; <nl> + pos = - pos ; <nl> + } <nl> + <nl> + if ( partitionorder = = order . ascending | | partitionorder = = order . any ) { <nl> + channels [ 0 ] = pos ; <nl> + } else { <nl> + channels [ 0 ] = splitborders . length - pos ; <nl> + } <nl> + <nl> + return channels ; <nl> + } <nl> + } <nl> mmm / dev / null <nl> ppp b / pact / pact - runtime / src / main / java / eu / stratosphere / pact / runtime / task / util / partitionfunction . java <nl>
public class pactcompiler { <nl>  <nl> for ( pactconnection conn : visitable . getoutgoingconnections ( ) ) { <nl> if ( conn . getshipstrategy ( ) = = shipstrategy . partition_range ) { <nl> + / / one memory consumer for the histogram <nl> memoryconsumers + = visitable . getinstancespermachine ( ) ; <nl> + / / reduce available memory because of temp task to avoid spilling <nl> + this . memoryperinstance - = pactcompiler . default_temp_task_memory * <nl> + conn . getsourcepact ( ) . getdegreeofparallelism ( ) ; <nl> + <nl> + log . debug ( " memory reduced to " + memoryperinstance + " due to temptask " ) ; <nl> } <nl> } <nl>  <nl> mmm a / pact / pact - compiler / src / main / java / eu / stratosphere / pact / compiler / jobgen / jobgraphgenerator . java <nl> ppp b / pact / pact - compiler / src / main / java / eu / stratosphere / pact / compiler / jobgen / jobgraphgenerator . java <nl>
public class queuescheduler extends abstractscheduler implements jobstatuslisten <nl> / / register the scheduler as an execution stage listener <nl> executiongraph . registerexecutionstagelistener ( this ) ; <nl>  <nl> + / / add job to the job queue ( important to add job to queue before requesting instances ) <nl> + synchronized ( this . jobqueue ) { <nl> + this . jobqueue . add ( executiongraph ) ; <nl> + } <nl> + <nl> / / request resources for the first stage of the job <nl> final executionstage executionstage = executiongraph . getcurrentexecutionstage ( ) ; <nl> try { <nl> requestinstances ( executionstage ) ; <nl> } catch ( instanceexception e ) { <nl> - throw new schedulingexception ( stringutils . stringifyexception ( e ) ) ; <nl> - } <nl> - <nl> - synchronized ( this . jobqueue ) { <nl> - this . jobqueue . add ( executiongraph ) ; <nl> + <nl> + log . error ( stringutils . stringifyexception ( e ) ) ; <nl> } <nl> } <nl>  <nl>
public class queuescheduler extends abstractscheduler implements jobstatuslisten <nl> try { <nl> requestinstances ( executionstage ) ; <nl> } catch ( instanceexception e ) { <nl> + <nl> log . error ( stringutils . stringifyexception ( e ) ) ; <nl> } <nl>  <nl> mmm a / nephele / nephele - server / src / main / java / eu / stratosphere / nephele / jobmanager / scheduler / local / localscheduler . java <nl> ppp b / nephele / nephele - server / src / main / java / eu / stratosphere / nephele / jobmanager / scheduler / local / localscheduler . java <nl>
public class localscheduler extends abstractscheduler implements jobstatuslisten <nl> / / register the scheduler as an execution stage listener <nl> executiongraph . registerexecutionstagelistener ( this ) ; <nl>  <nl> + / / add job to the job queue ( important to add job to queue before requesting instances ) <nl> + synchronized ( this . jobqueue ) { <nl> + this . jobqueue . add ( executiongraph ) ; <nl> + } <nl> + <nl> / / request resources for the first stage of the job <nl> final executionstage executionstage = executiongraph . getcurrentexecutionstage ( ) ; <nl> try { <nl> requestinstances ( executionstage ) ; <nl> } catch ( instanceexception e ) { <nl> - throw new schedulingexception ( stringutils . stringifyexception ( e ) ) ; <nl> - } <nl> - <nl> - synchronized ( this . jobqueue ) { <nl> - this . jobqueue . add ( executiongraph ) ; <nl> + <nl> + log . error ( stringutils . stringifyexception ( e ) ) ; <nl> } <nl> } <nl>  <nl>
public class localscheduler extends abstractscheduler implements jobstatuslisten <nl> try { <nl> requestinstances ( executionstage ) ; <nl> } catch ( instanceexception e ) { <nl> + <nl> log . error ( stringutils . stringifyexception ( e ) ) ; <nl> }
public abstract class abstractinvokable { <nl> * <nl> * @ return the environment of this task or < code > null < / code > if the environment has not yet been set <nl> * / <nl> - public final environment getenvironment ( ) { <nl> + <nl> + public environment getenvironment ( ) { <nl> return this . environment ; <nl> }
public class executiongroupedge { <nl> throw new graphconversionexception ( " cannot overwrite user defined channel type " ) ; <nl> } <nl>  <nl> + this . executiongraph . unwire ( this . sourcevertex , this . indexofoutputgate , this . targetvertex , this . indexofinputgate ) ; <nl> + this . executiongraph . wire ( this . sourcevertex , this . indexofoutputgate , this . targetvertex , this . indexofinputgate , <nl> + newchanneltype , this . compressionlevel ) ; <nl> + <nl> + <nl> / / make sure update is applied to all edges connecting the two vertices <nl> - final list < executiongroupedge > edges = this . getsourcevertex ( ) . getforwardedges ( this . gettargetvertex ( ) ) ; <nl> - final iterator < executiongroupedge > it = edges . iterator ( ) ; <nl> - while ( it . hasnext ( ) ) { <nl> - <nl> - final executiongroupedge edge = it . next ( ) ; <nl> - <nl> - / / update channel type <nl> - compressionlevel cl = null ; <nl> - synchronized ( edge ) { <nl> - edge . channeltype = newchanneltype ; <nl> - cl = edge . compressionlevel ; <nl> - } <nl> - <nl> - this . executiongraph . unwire ( edge . sourcevertex , edge . indexofoutputgate , edge . targetvertex , <nl> - edge . indexofinputgate ) ; <nl> - this . executiongraph . wire ( edge . sourcevertex , edge . indexofoutputgate , edge . targetvertex , <nl> - edge . indexofinputgate , newchanneltype , cl ) ; <nl> - } <nl> + / * <nl> + * final list < executiongroupedge > edges = this . getsourcevertex ( ) . getforwardedges ( this . gettargetvertex ( ) ) ; <nl> + * final iterator < executiongroupedge > it = edges . iterator ( ) ; <nl> + * while ( it . hasnext ( ) ) { <nl> + * final executiongroupedge edge = it . next ( ) ; <nl> + * / / update channel type <nl> + * compressionlevel cl = null ; <nl> + * synchronized ( edge ) { <nl> + * system . out . println ( " chaning channel2 type from " + edge . channeltype + " to " + newchanneltype ) ; <nl> + * edge . channeltype = newchanneltype ; <nl> + * cl = edge . compressionlevel ; <nl> + * } <nl> + * this . executiongraph . unwire ( edge . sourcevertex , edge . indexofoutputgate , edge . targetvertex , <nl> + * edge . indexofinputgate ) ; <nl> + * } <nl> + * / <nl>  <nl> / / changing the channels may require to reassign the stages <nl> this . executiongraph . repairstages ( ) ; <nl> mmm a / nephele / nephele - server / src / test / java / eu / stratosphere / nephele / executiongraph / executiongraphtest . java <nl> ppp b / nephele / nephele - server / src / test / java / eu / stratosphere / nephele / executiongraph / executiongraphtest . java <nl>
public class unilateralsortmerger < k extends key , v extends value > implements sor <nl>  <nl> list < iterator < keyvaluepair < k , v > > > iterators = new arraylist < iterator < keyvaluepair < k , v > > > ( ) ; <nl>  <nl> + <nl> + <nl> / / iterate buffers and collect a set of iterators <nl> - for ( circularelement cached : cache ) <nl> + iterator < circularelement > iter = cache . iterator ( ) ; <nl> + while ( iter . hasnext ( ) ) <nl> { <nl> - / / note : the yielded iterator only operates on the buffer heap ( and disregards the stack ) <nl> - iterators . add ( cached . buffer . getiterator ( ) ) ; <nl> + circularelement cached = iter . next ( ) ; <nl> + if ( cached ! = sentinel ) <nl> + { <nl> + / / note : the yielded iterator only operates on the buffer heap ( and disregards the stack ) <nl> + iterators . add ( cached . buffer . getiterator ( ) ) ; <nl> + } <nl> } <nl>  <nl> / / release sort - buffers <nl>
import eu . stratosphere . pact . example . relational . util . tuple ; <nl> * match " filtered_parts " and " suppliers " on " suppkey " - > " partlist " with ( nation , o_year ) as key <nl> * group " partlist " by ( nation , o_year ) , calculate sum ( amount ) <nl> * <nl> + * <nl> + * <nl> * @ author dennis schneider < dschneid @ informatik . hu - berlin . de > <nl> * /
<nl> + package eu . stratosphere . nephele . types ; <nl> + <nl> + import static org . hamcrest . matcherassert . assertthat ; <nl> + import static org . hamcrest . matchers . is ; <nl> + import static org . hamcrest . matchers . not ; <nl> + import static org . hamcrest . matchers . nullvalue ; <nl> + import static org . junit . assert . assertequals ; <nl> + import static org . junit . assert . fail ; <nl> + import static org . mockito . mockito . when ; <nl> + import static org . mockito . mockitoannotations . initmocks ; <nl> + <nl> + import java . io . datainput ; <nl> + import java . io . ioexception ; <nl> + <nl> + import org . junit . before ; <nl> + import org . junit . test ; <nl> + import org . mockito . mock ; <nl> + <nl> + import eu . stratosphere . nephele . util . commontestutils ; <nl> + <nl> + / * * <nl> + * <nl> + * @ author mathias peters < mathias . peters @ informatik . hu - berlin . de > <nl> + * <nl> + * / <nl> + public class stringrecordtest { <nl> + <nl> + <nl> + @ mock <nl> + private datainput inputmock ; <nl> + <nl> + <nl> + @ before <nl> + public void setup ( ) <nl> + { <nl> + initmocks ( this ) ; <nl> + } <nl> + <nl> + / * * <nl> + * tests the serialization / deserialization of the { @ link stringrecord } class . <nl> + * / <nl> + @ test <nl> + public void teststringrecord ( ) { <nl> + <nl> + final stringrecord orig = new stringrecord ( " test record " ) ; <nl> + <nl> + try { <nl> + <nl> + final stringrecord copy = ( stringrecord ) commontestutils . createcopy ( orig ) ; <nl> + <nl> + assertequals ( orig . getlength ( ) , copy . getlength ( ) ) ; <nl> + assertequals ( orig . tostring ( ) , copy . tostring ( ) ) ; <nl> + assertequals ( orig , copy ) ; <nl> + assertequals ( orig . hashcode ( ) , copy . hashcode ( ) ) ; <nl> + <nl> + } catch ( ioexception ioe ) { <nl> + fail ( ioe . getmessage ( ) ) ; <nl> + } <nl> + } <nl> + <nl> + @ test <nl> + public void shouldreadproperinputs ( ) throws ioexception <nl> + { <nl> + when ( inputmock . readboolean ( ) ) . thenreturn ( true ) ; <nl> + when ( inputmock . readint ( ) ) . thenreturn ( 10 ) ; <nl> + <nl> + string readstring = stringrecord . readstring ( inputmock ) ; <nl> + assertthat ( readstring , is ( not ( nullvalue ( ) ) ) ) ; <nl> + <nl> + <nl> + } <nl> + <nl> + <nl> + @ test <nl> + public void shouldreadnegativeinputs ( ) throws ioexception <nl> + { <nl> + when ( inputmock . readboolean ( ) ) . thenreturn ( true ) ; <nl> + when ( inputmock . readint ( ) ) . thenreturn ( - 1 ) ; <nl> + <nl> + string readstring = stringrecord . readstring ( inputmock ) ; <nl> + assertthat ( readstring , is ( nullvalue ( ) ) ) ; <nl> + } <nl> + } <nl> mmm a / nephele / nephele - common / src / test / java / eu / stratosphere / nephele / types / typetest . java <nl> ppp b / nephele / nephele - common / src / test / java / eu / stratosphere / nephele / types / typetest . java <nl>
public class blockresettableiterator < t extends record > implements memoryblockite <nl> finishedtasks . add ( in ) ; / / unbound buffer signals completion <nl> } <nl>  <nl> + } <nl> + <nl> + @ override <nl> + public t lastreturned ( ) { <nl> + <nl> + throw new unsupportedoperationexception ( ) ; <nl> } <nl>  <nl> } <nl> mmm a / pact / pact - runtime / src / main / java / eu / stratosphere / pact / runtime / resettable / spillingresettableiterator . java <nl> ppp b / pact / pact - runtime / src / main / java / eu / stratosphere / pact / runtime / resettable / spillingresettableiterator . java <nl>
public class spillingresettableiterator < t extends record > implements resettablei <nl> throw new unsupportedoperationexception ( ) ; <nl> } <nl>  <nl> + @ override <nl> + public t lastreturned ( ) { <nl> + <nl> + throw new unsupportedoperationexception ( ) ; <nl> + } <nl> + <nl> }
public class taskmanager implements taskoperationprotocol { <nl> this . profiler . unregisterexecutionlistener ( id ) ; <nl> } <nl>  <nl> + <nl> + <nl> / / check if there are still vertices running that belong to the same job <nl> int numberofverticesbelongingtothisjob = num ; <nl> synchronized ( this . runningtasks ) {
public class pactconnection { <nl> * the shipping strategy to be applied to this connection . <nl> * / <nl> public void setshipstrategy ( shipstrategy strategy ) { <nl> - / / this check is for debugging purposes : it checks , that a ship strategy ( other than none ) <nl> - / / is not changed by the compiler <nl> - if ( this . shipstrategy ! = shipstrategy . none & & this . shipstrategy ! = strategy ) { <nl> - throw new compilerexception ( " internal error : compiler attempts to change a fixed shipping strategy . " ) ; <nl> - } <nl> + <nl> + / / / / is not changed by the compiler <nl> + / / if ( this . shipstrategy ! = shipstrategy . none & & this . shipstrategy ! = strategy ) { <nl> + / / throw new compilerexception ( " internal error : compiler attempts to change a fixed shipping strategy . " ) ; <nl> + / / } <nl>  <nl> this . shipstrategy = strategy ; <nl> }
public class pactconnection { <nl> * the shipping strategy to be applied to this connection . <nl> * / <nl> public void setshipstrategy ( shipstrategy strategy ) { <nl> - / / this check is for debugging purposes : it checks , that a ship strategy ( other than none ) <nl> - / / is not changed by the compiler <nl> - if ( this . shipstrategy ! = shipstrategy . none & & this . shipstrategy ! = strategy ) { <nl> - throw new compilerexception ( " internal error : compiler attempts to change a fixed shipping strategy . " ) ; <nl> - } <nl> + <nl> + / / / / is not changed by the compiler <nl> + / / if ( this . shipstrategy ! = shipstrategy . none & & this . shipstrategy ! = strategy ) { <nl> + / / throw new compilerexception ( " internal error : compiler attempts to change a fixed shipping strategy . " ) ; <nl> + / / } <nl>  <nl> this . shipstrategy = strategy ; <nl> }
final class decodedbitstreamparser { <nl> case numeric_compaction_mode_latch : <nl> codeindex = numericcompaction ( codewords , codeindex , result ) ; <nl> break ; <nl> + case eci_charset : <nl> + characterseteci charseteci = <nl> + characterseteci . getcharactersetecibyvalue ( codewords [ codeindex + + ] ) ; <nl> + charset charset = charset . forname ( charseteci . name ( ) ) ; <nl> + <nl> + break ; <nl> + case eci_general_purpose : <nl> + / / can ' t do anything with generic eci ; skip its num characters <nl> + codeindex + = num ; <nl> + break ; <nl> + case eci_user_defined : <nl> + / / can ' t do anything with user eci ; skip its num character <nl> + codeindex + + ; <nl> + break ; <nl> case begin_macro_pdf417_control_block : <nl> codeindex = decodemacroblock ( codewords , codeindex , resultmetadata ) ; <nl> break ;
<nl> + < ? xml version = " 1 . 0 " encoding = " utf - 8 " ? > <nl> + < ! - - <nl> + copyright ( c ) num zxing authors <nl> + <nl> + licensed under the apache license , version num . 0 ( the " license " ) ; <nl> + you may not use this file except in compliance with the license . <nl> + you may obtain a copy of the license at <nl> + <nl> + http : / / www . apache . org / licenses / license - 2 . 0 <nl> + <nl> + unless required by applicable law or agreed to in writing , software <nl> + distributed under the license is distributed on an " as is " basis , <nl> + without warranties or conditions of any kind , either express or implied . <nl> + see the license for the specific language governing permissions and <nl> + limitations under the license . <nl> + - - > <nl> + < project xmlns = " http : / / maven . apache . org / pom / 4 . 0 . 0 " xmlns : xsi = " http : / / www . w3 . org / 2001 / xmlschema - instance " xsi : schemalocation = " http : / / maven . apache . org / pom / 4 . 0 . 0 http : / / maven . apache . org / maven - v4_0_0 . xsd " > <nl> + <nl> + < parent > <nl> + < groupid > com . google . zxing < / groupid > <nl> + < artifactid > zxing < / artifactid > <nl> + < version > 2 . 2 - snapshot < / version > <nl> + < / parent > <nl> + <nl> + < modelversion > 4 . 0 . 0 < / modelversion > <nl> + < artifactid > zxing . appspot . com < / artifactid > <nl> + < packaging > jar < / packaging > <nl> + < name > zxing appspot - based encoder < / name > <nl> + < version > 2 . 2 - snapshot < / version > <nl> + < description > gwt - based encoder app hosted at zxing . appspot . com < / description > <nl> + <nl> + < dependencies > <nl> + < dependency > <nl> + < groupid > com . google . gwt < / groupid > <nl> + < artifactid > gwt - user < / artifactid > <nl> + < version > 2 . 5 . 1 < / version > <nl> + < / dependency > <nl> + < dependency > <nl> + < groupid > com . google . gwt < / groupid > <nl> + < artifactid > gwt - incubator < / artifactid > <nl> + < version > 2 . 0 . 1 < / version > <nl> + < / dependency > <nl> + < / dependencies > <nl> + <nl> + < ! - - <nl> + <nl> + < / project >
public final class historymanager { <nl> while ( cursor . movetonext ( ) ) { <nl> db . delete ( dbhelper . table_name , dbhelper . id_col + ' = ' + cursor . getstring ( 0 ) , null ) ; <nl> } <nl> + } catch ( sqliteexception sqle ) { <nl> + / / we ' re seeing an error here when called in captureactivity . oncreate ( ) in rare cases <nl> + / / and don ' t understand it . first theory is that it ' s transient so can be safely ignored . <nl> + <nl> + log . w ( tag , sqle ) ; <nl> + / / continue <nl> } finally { <nl> close ( cursor , db ) ; <nl> }
void formatinformationtest : : testbitsdiffering ( ) { <nl> void formatinformationtest : : testdecode ( ) { <nl> / / normal case <nl> ref < formatinformation > expected = <nl> - formatinformation : : decodeformatinformation ( 0x2bed ^ num x5412 ) ; <nl> + formatinformation : : decodeformatinformation ( masked_test_format_info , masked_test_format_info ) ; <nl> cppunit_assert_equal ( ( unsigned char ) num x07 , expected - > getdatamask ( ) ) ; <nl> cppunit_assert_equal ( & errorcorrectionlevel : : q , <nl> & expected - > geterrorcorrectionlevel ( ) ) ; <nl> / / where the code forgot the mask ! <nl> assertequals ( expected , <nl> - formatinformation : : decodeformatinformation ( 0x2bed ) ) ; <nl> + formatinformation : : decodeformatinformation ( unmasked_test_format_info , masked_test_format_info ) ) ; <nl> + <nl> + <nl>  <nl> / / num , 2 , 3 , 4 bits difference <nl> - assertequals ( expected , <nl> - formatinformation : : decodeformatinformation ( 0x2bef ^ num x5412 ) ) ; <nl> - assertequals ( expected , <nl> - formatinformation : : decodeformatinformation ( 0x2bee ^ num x5412 ) ) ; <nl> - assertequals ( expected , <nl> - formatinformation : : decodeformatinformation ( 0x2bea ^ num x5412 ) ) ; <nl> - cppunit_assert_equal ( true , formatinformation : : <nl> - decodeformatinformation ( 0x2be2 ^ num x5412 ) = = num ) ; <nl> + assertequals ( expected , formatinformation : : decodeformatinformation ( <nl> + masked_test_format_info ^ num x01 , masked_test_format_info ^ num x01 ) ) ; <nl> + assertequals ( expected , formatinformation : : decodeformatinformation ( <nl> + masked_test_format_info ^ num x03 , masked_test_format_info ^ num x03 ) ) ; <nl> + assertequals ( expected , formatinformation : : decodeformatinformation ( <nl> + masked_test_format_info ^ num x07 , masked_test_format_info ^ num x07 ) ) ; <nl> + <nl> + ref < formatinformation > expectednull ( null ) ; <nl> + assertequals ( expectednull , formatinformation : : decodeformatinformation ( <nl> + masked_test_format_info ^ num x0f , masked_test_format_info ^ num x0f ) ) ; <nl> + <nl> + / / withmisread <nl> + assertequals ( expected , formatinformation : : decodeformatinformation ( <nl> + masked_test_format_info ^ num x03 , masked_test_format_info ^ num x0f ) ) ; <nl> } <nl> } <nl> }
import java . util . hashmap ; <nl> * / <nl> public final class localemanager { <nl> private static final string default_tld = " com " ; <nl> + <nl> + / / locales where google web search is available . these should be kept in sync with our <nl> + / / translations . the format for the manual countries is : <nl> + / / language , country , unused , google domain suffix <nl> private static final map < locale , string > google_country_tld ; <nl> static { <nl> google_country_tld = new hashmap < locale , string > ( ) ; <nl> + google_country_tld . put ( new locale ( " en " , " au " , " " ) , " com . au " ) ; / / australia <nl> + google_country_tld . put ( new locale ( " bg " , " bg " , " " ) , " com . br " ) ; / / bulgaria <nl> google_country_tld . put ( locale . canada , " ca " ) ; <nl> google_country_tld . put ( locale . china , " cn " ) ; <nl> + google_country_tld . put ( new locale ( " cs " , " cz " , " " ) , " cz " ) ; / / czech republic <nl> + google_country_tld . put ( new locale ( " da " , " dk " , " " ) , " dk " ) ; / / denmark <nl> + google_country_tld . put ( new locale ( " fi " , " fi " , " " ) , " fi " ) ; / / finland <nl> google_country_tld . put ( locale . france , " fr " ) ; <nl> google_country_tld . put ( locale . germany , " de " ) ; <nl> + google_country_tld . put ( new locale ( " hu " , " hu " , " " ) , " hu " ) ; / / hungary <nl> + google_country_tld . put ( new locale ( " he " , " il " , " " ) , " co . il " ) ; / / israel <nl> google_country_tld . put ( locale . italy , " it " ) ; <nl> google_country_tld . put ( locale . japan , " co . jp " ) ; <nl> google_country_tld . put ( locale . korea , " co . kr " ) ; <nl> + google_country_tld . put ( new locale ( " nl " , " nl " , " " ) , " nl " ) ; / / netherlands <nl> + google_country_tld . put ( new locale ( " pl " , " pl " , " " ) , " pl " ) ; / / poland <nl> + google_country_tld . put ( new locale ( " pt " , " pt " , " " ) , " pt " ) ; / / portugal <nl> + google_country_tld . put ( new locale ( " ru " , " ru " , " " ) , " nl " ) ; / / russia <nl> + google_country_tld . put ( new locale ( " sk " , " sk " , " " ) , " sk " ) ; / / slovak republic <nl> + google_country_tld . put ( new locale ( " sl " , " si " , " " ) , " si " ) ; / / slovenia <nl> + google_country_tld . put ( new locale ( " es " , " es " , " " ) , " es " ) ; / / spain <nl> + google_country_tld . put ( new locale ( " sv " , " se " , " " ) , " se " ) ; / / sweden <nl> google_country_tld . put ( locale . taiwan , " de " ) ; <nl> + google_country_tld . put ( new locale ( " tr " , " tr " , " " ) , " com . tr " ) ; / / turkey <nl> google_country_tld . put ( locale . uk , " co . uk " ) ; <nl> } <nl>  <nl> - / / google product search for mobile is available in fewer countries than web search . <nl> + / / google product search for mobile is available in fewer countries than web search . see here : <nl> + / / http : / / www . google . com / support / merchants / bin / answer . py ? answer = 160619 <nl> private static final map < locale , string > google_product_search_country_tld ; <nl> static { <nl> google_product_search_country_tld = new hashmap < locale , string > ( ) ; <nl> - google_product_search_country_tld . put ( locale . uk , " co . uk " ) ; <nl> + google_product_search_country_tld . put ( new locale ( " en " , " au " , " " ) , " com . au " ) ; / / australia <nl> + google_product_search_country_tld . put ( locale . china , " cn " ) ; <nl> + google_product_search_country_tld . put ( locale . france , " fr " ) ; <nl> google_product_search_country_tld . put ( locale . germany , " de " ) ; <nl> + google_product_search_country_tld . put ( locale . italy , " it " ) ; <nl> + google_product_search_country_tld . put ( locale . japan , " co . jp " ) ; <nl> + google_product_search_country_tld . put ( new locale ( " nl " , " nl " , " " ) , " nl " ) ; / / netherlands <nl> + google_product_search_country_tld . put ( new locale ( " es " , " es " , " " ) , " es " ) ; / / spain <nl> + google_product_search_country_tld . put ( locale . uk , " co . uk " ) ; <nl> } <nl>  <nl> + <nl> private static final map < locale , string > google_book_search_country_tld ; <nl> static { <nl> google_book_search_country_tld = new hashmap < locale , string > ( ) ;
final class qrcodeencoder { <nl> return contents ! = null & & contents . length ( ) > num ; <nl> } <nl>  <nl> - / / handles send intents from the contacts app , retrieving a contact as a vcard . <nl> + / / handles send intents from multitude of android applications <nl> private boolean encodecontentsfromshareintent ( intent intent ) { <nl> + / / check if this is a plain text encoding , or contact <nl> + if ( intent . hasextra ( intent . extra_text ) ) { <nl> + return encodecontentsfromshareintentplaintext ( intent ) ; <nl> + } <nl> + / / attempt default sharing . <nl> + return encodecontentsfromshareintentdefault ( intent ) ; <nl> + } <nl> + <nl> + private boolean encodecontentsfromshareintentplaintext ( intent intent ) { <nl> + / / notice : google maps shares both url and details in one text , bummer ! <nl> + contents = intent . getstringextra ( intent . extra_text ) ; <nl> + / / we only support non - empty and non - blank texts . <nl> + / / trim text to avoid url breaking . <nl> + if ( contents = = null ) { <nl> + return false ; <nl> + } <nl> + contents = contents . trim ( ) ; <nl> + if ( contents . length ( ) = = num ) { <nl> + return false ; <nl> + } <nl> + / / we only do qr code . <nl> + format = barcodeformat . qr_code ; <nl> + <nl> + displaycontents = contents ; <nl> + title = activity . getstring ( r . string . contents_text ) ; <nl> + return true ; <nl> + } <nl> + <nl> + / / handles send intents from the contacts app , retrieving a contact as a vcard . <nl> + / / note : does not work on htc devices due to broken custom contacts application . <nl> + private boolean encodecontentsfromshareintentdefault ( intent intent ) { <nl> format = barcodeformat . qr_code ; <nl> try { <nl> uri uri = ( uri ) intent . getextras ( ) . getparcelable ( intent . extra_stream ) ;
localblockbinarizer : : localblockbinarizer ( ref < luminancesource > source ) : <nl> localblockbinarizer : : ~ localblockbinarizer ( ) { <nl> } <nl>  <nl> + ref < bitarray > localblockbinarizer : : estimateblackrow ( int y , ref < bitarray > row ) { <nl> + <nl> + return ref < bitarray > ( ) ; <nl> + } <nl> + <nl> / / calculates the final bitmatrix once for all requests . this could be called once from the <nl> / / constructor instead , but there are some advantages to doing it lazily , such as making <nl> / / profiling easier , and not doing heavy lifting when callers don ' t expect it . <nl> mmm a / cpp / core / src / zxing / common / localblockbinarizer . h <nl> ppp b / cpp / core / src / zxing / common / localblockbinarizer . h <nl>
public final class interleavedyuv422luminancesource extends baseluminancesource <nl> / / not currently needed . <nl> @ override <nl> public bitmap renderfullcolorbitmap ( boolean halfsize ) { <nl> - return null ; <nl> + <nl> + int width = getwidth ( ) ; <nl> + int height = getheight ( ) ; <nl> + int [ ] pixels = new int [ width * height ] ; <nl> + byte [ ] yuv = yuvdata ; <nl> + int datawidth = this . datawidth ; <nl> + int inputoffset = ( top * datawidth + left ) < < num ; <nl> + <nl> + for ( int y = num ; y < height ; y + + ) { <nl> + int outputoffset = y * width ; <nl> + for ( int x = num ; x < width ; x + = num ) { <nl> + int localoffset = inputoffset + ( x < < num ) ; <nl> + int y1 = yuv [ localoffset ] & num xff ; <nl> + int u = yuv [ localoffset + num ] & num xff ; <nl> + int y2 = yuv [ localoffset + num ] & num xff ; <nl> + int v = yuv [ localoffset + num ] & num xff ; <nl> + int rgb1 = yuvtorgb ( y1 , u , v ) ; <nl> + int rgb2 = yuvtorgb ( y2 , u , v ) ; <nl> + pixels [ outputoffset + x ] = opaque_alpha | rgb1 ; <nl> + pixels [ outputoffset + x + num ] = opaque_alpha | rgb2 ; <nl> + } <nl> + inputoffset + = ( datawidth < < num ) ; <nl> + } <nl> + <nl> + bitmap bitmap = bitmap . createbitmap ( width , height , bitmap . config . argb_8888 ) ; <nl> + bitmap . setpixels ( pixels , num , width , num , num , width , height ) ; <nl> + return bitmap ; <nl> } <nl> + <nl> + / * * <nl> + * @ link http : / / en . wikipedia . org / wiki / yuv # y . 27uv444 <nl> + * / <nl> + private static int yuvtorgb ( int y , int u , int v ) { <nl> + int c = y - num ; <nl> + int d = u - num ; <nl> + int e = v - num ; <nl> + int c298 = num * c ; <nl> + int r = clip ( ( c298 + num * e + num ) > > num ) ; <nl> + int g = clip ( ( c298 - num * d - num * e + num ) > > num ) ; <nl> + int b = clip ( ( c298 + num * d + num ) > > num ) ; <nl> + return ( r < < num ) | ( g < < num ) | b ; <nl> + } <nl> + <nl> + private static int clip ( int x ) { <nl> + return x < num ? num : x & num xff ; <nl> + } <nl> + <nl> } <nl> mmm a / android / src / com / google / zxing / client / android / planaryuvluminancesource . java <nl> ppp b / android / src / com / google / zxing / client / android / planaryuvluminancesource . java <nl>
import java . util . vector ; <nl> * markers at three corners of a qr code . < / p > <nl> * <nl> * < p > this class is not thread - safe and should not be reused . < / p > <nl> + * <nl> * <nl> * < p > in contrast to { @ link finderpatternfinder } , this class will return an array of all possible <nl> * qr code locations in the image . < / p > <nl> mmm a / core / src / com / google / zxing / qrcode / detector / alignmentpatternfinder . java <nl> ppp b / core / src / com / google / zxing / qrcode / detector / alignmentpatternfinder . java <nl>
import java . util . vector ; <nl> * some code . < / p > <nl> * <nl> * < p > this class is not thread - safe . < / p > <nl> + * <nl> * <nl> * @ author sean owen <nl> * / <nl> mmm a / core / src / com / google / zxing / qrcode / detector / finderpatternfinder . java <nl> ppp b / core / src / com / google / zxing / qrcode / detector / finderpatternfinder . java <nl>
import java . util . vector ; <nl> * markers at three corners of a qr code . < / p > <nl> * <nl> * < p > this class is not thread - safe and should not be reused . < / p > <nl> + * <nl> * <nl> * @ author sean owen <nl> * /
public final class itfblackbox1testcase extends abstractblackboxtestcase { <nl> addtest ( 9 , num , num . 0f ) ; <nl> } <nl>  <nl> - } <nl> \ no newline at end of file <nl> + <nl> + / / else . unfortunately this list is fragile . the right thing to do is profile itf for performance , <nl> + / / and if it doesn ' t impose significant overhead , turn it on by default . then this method can be <nl> + / / removed completely . <nl> + @ override <nl> + protected hashtable < decodehinttype , object > gethints ( ) { <nl> + hashtable < decodehinttype , object > hints = new hashtable < decodehinttype , object > ( 3 ) ; <nl> + vector < barcodeformat > vector = new vector < barcodeformat > ( ) ; <nl> + vector . addelement ( barcodeformat . upc_a ) ; <nl> + vector . addelement ( barcodeformat . upc_e ) ; <nl> + vector . addelement ( barcodeformat . ean_13 ) ; <nl> + vector . addelement ( barcodeformat . ean_8 ) ; <nl> + vector . addelement ( barcodeformat . code_39 ) ; <nl> + vector . addelement ( barcodeformat . code_128 ) ; <nl> + vector . addelement ( barcodeformat . itf ) ; <nl> + vector . addelement ( barcodeformat . qr_code ) ; <nl> + hints . put ( decodehinttype . possible_formats , vector ) ; <nl> + return hints ; <nl> + } <nl> + <nl> + }
import java . io . file ; <nl> public final class itf14blackbox1testcase extends abstractblackboxtestcase { <nl>  <nl> public itf14blackbox1testcase ( ) { <nl> - super ( new file ( " test / data / blackbox / itf14 - 1 " ) , new multiformatreader ( ) , barcodeformat . itf_14 ) ; <nl> - addtest ( 0 , num , num . 0f ) ; <nl> - addtest ( 0 , num , num . 0f ) ; <nl> + <nl> + super ( new file ( " test / data / blackbox / itf14 - 1 " ) , new itf14reader ( ) , barcodeformat . itf_14 ) ; <nl> + addtest ( 2 , num , num . 0f ) ; <nl> + addtest ( 2 , num , num . 0f ) ; <nl> } <nl>  <nl> } <nl> \ no newline at end of file
public abstract class resulthandler { <nl>  <nl> public static final int max_button_count = num ; <nl>  <nl> + / / these are new constants in contacts . intents . insert for android num . 1 . <nl> + <nl> + private static final string secondary_phone = " secondary_phone " ; <nl> + private static final string tertiary_phone = " tertiary_phone " ; <nl> + private static final string secondary_email = " secondary_email " ; <nl> + private static final string tertiary_email = " tertiary_email " ; <nl> + <nl> + private static final string [ ] phone_intents = { <nl> + contacts . intents . insert . phone , secondary_phone , tertiary_phone <nl> + } ; <nl> + <nl> + private static final string [ ] email_intents = { <nl> + contacts . intents . insert . email , secondary_email , tertiary_email <nl> + } ; <nl> + <nl> protected final parsedresult mresult ; <nl> private final activity mactivity ; <nl>  <nl>
public final class qrcodewriter implements writer { <nl> if ( encoder . encode ( new bytearray ( contents ) , errorcorrectionlevel , code ) ) { <nl> return renderresult ( code , width , height ) ; <nl> } else { <nl> - throw new illegalstateexception ( " could not generate a qr code " ) ; <nl> + <nl> + throw new runtimeexception ( " could not generate a qr code " ) ; <nl> } <nl> } <nl>  <nl> mmm a / core / src / com / google / zxing / qrcode / encoder / debug . java <nl> ppp b / core / src / com / google / zxing / qrcode / encoder / debug . java <nl>
package com . google . zxing . qrcode . encoder ; <nl> public class debug { <nl>  <nl> public static void log_error ( string message ) { <nl> - throw new illegalstateexception ( message ) ; <nl> + / / can ' t use illegalstateexception unfortunately in j2me <nl> + <nl> + throw new runtimeexception ( message ) ; <nl> } <nl>  <nl> public static void log_info ( string message ) { <nl> - throw new illegalstateexception ( message ) ; <nl> + throw new runtimeexception ( message ) ; <nl> } <nl>  <nl> public static void dcheck ( boolean condition ) { <nl> if ( ! condition ) { <nl> - throw new illegalstateexception ( ) ; <nl> + throw new runtimeexception ( ) ; <nl> } <nl> }
<nl> optimize = " true " <nl> debug = " $ { generate - debug } " <nl> deprecation = " true " <nl> - fork = " true " / > <nl> + fork = " true " > <nl> + < ! - - <nl> + < exclude name = " com / google / zxing / qrcode / encoder / * * " / > <nl> + < / javac > <nl> < jar jarfile = " core . jar " basedir = " build " > <nl> < ! - - these entries allow core . jar to function as an osgi bundle , and also specifices <nl> additional attributes for compatibility with buglabs ' s bug platform .
package com . google . zxing ; <nl> * <nl> * @ author srowen @ google . com ( sean owen ) <nl> * / <nl> - public final class readerexception extends exception { <nl> + <nl> + <nl> + / / and latency on continuous scan clients . in the future , we should change all the decoders not to <nl> + / / throw exceptions for routine events , like not finding a barcode on a given row . instead , we <nl> + / / should return error codes back to the callers , and simply delete this class . in the mean time , i <nl> + / / have altered this class to be as lightweight as possible , by ignoring the exception string , and <nl> + / / by disabling the generation of stack traces , which is especially time consuming . these are just <nl> + / / temporary measures , pending the big cleanup . <nl> + public final class readerexception extends java . lang . throwable { <nl>  <nl> public readerexception ( string message ) { <nl> - super ( message ) ; <nl> + / / do not pass message to throwable , let it get optimized out <nl> + } <nl> + <nl> + / / prevent stack traces from being taken <nl> + public throwable fillinstacktrace ( ) { <nl> + return null ; <nl> } <nl>  <nl> }
package com . google . zxing . common ; <nl> * / <nl> public final class bitarray { <nl>  <nl> - private int [ ] bits ; <nl> - private final int size ; <nl> + <nl> + / / resulting binary at runtime on android . if we find a solution to this , these should be changed <nl> + / / back to private . <nl> + public int [ ] bits ; <nl> + public final int size ; <nl>  <nl> public bitarray ( int size ) { <nl> if ( size < num ) {
public abstract class resulthandler { <nl> } <nl> } <nl>  <nl> + <nl> private static void putextra ( intent intent , string key , string [ ] value ) { <nl> if ( value ! = null & & value . length > num ) { <nl> putextra ( intent , key , value [ 0 ] ) ;
public final class multiformatreader implements reader { <nl> if ( possibleformats . contains ( barcodeformat . qr_code ) ) { <nl> readers . addelement ( new qrcodereader ( ) ) ; <nl> } <nl> - if ( possibleformats . contains ( barcodeformat . datamatrix ) ) { <nl> - readers . addelement ( new datamatrixreader ( ) ) ; <nl> - } <nl> + <nl> + / / readers . addelement ( new datamatrixreader ( ) ) ; <nl> + / / } <nl> / / at end in " try harder " mode <nl> if ( addonedreader & & tryharder ) { <nl> readers . addelement ( new multiformatonedreader ( ) ) ;
public final class lcduiimagemonochromebitmapsource implements monochromebitmaps <nl> } else { <nl> row . clear ( ) ; <nl> } <nl> - for ( int i = num , offset = y * width + startx ; i < getwidth ; i + + , offset + + ) { <nl> - if ( computergbluminance ( rgbpixels [ offset ] ) < blackpoint ) { <nl> - row . set ( i ) ; <nl> + <nl> + / / if the current decoder calculated the blackpoint based on one row , assume we ' re trying to <nl> + / / decode a num d barcode , and apply some sharpening . <nl> + <nl> + if ( lastmethod . equals ( blackpointestimationmethod . row_sampling ) ) { <nl> + int offset = y * width + startx ; <nl> + int left = computergbluminance ( rgbpixels [ offset ] ) ; <nl> + offset + + ; <nl> + int center = computergbluminance ( rgbpixels [ offset ] ) ; <nl> + for ( int i = num ; i < getwidth - num ; i + + , offset + + ) { <nl> + int right = computergbluminance ( rgbpixels [ offset + num ] ) ; <nl> + / / simple - 1 num - 1 box filter with a weight of num <nl> + int luminance = ( ( center < < num ) - left - right ) > > num ; <nl> + if ( luminance < blackpoint ) { <nl> + row . set ( i ) ; <nl> + } <nl> + left = center ; <nl> + center = right ; <nl> + } <nl> + } else { <nl> + for ( int i = num , offset = y * width + startx ; i < getwidth ; i + + , offset + + ) { <nl> + if ( computergbluminance ( rgbpixels [ offset ] ) < blackpoint ) { <nl> + row . set ( i ) ; <nl> + } <nl> } <nl> } <nl> return row ;
public final class multiformatreader implements reader { <nl> if ( readers . isempty ( ) ) { <nl> readers . addelement ( new multiformatonedreader ( ) ) ; <nl> readers . addelement ( new qrcodereader ( ) ) ; <nl> - readers . addelement ( new datamatrixreader ( ) ) ; <nl> + <nl> } <nl>  <nl> for ( int i = num ; i < readers . size ( ) ; i + + ) { <nl> mmm a / core / test / src / com / google / zxing / datamatrix / datamatrixblackbox1testcase . java <nl> ppp b / core / test / src / com / google / zxing / datamatrix / datamatrixblackbox1testcase . java <nl>
import java . io . file ; <nl> public final class datamatrixblackbox1testcase extends abstractblackboxtestcase { <nl>  <nl> public datamatrixblackbox1testcase ( ) { <nl> + <nl> super ( new file ( " test / data / blackbox / datamatrix - 1 " ) , new datamatrixreader ( ) , num . 0 , barcodeformat . datamatrix ) ; <nl> }
public final class zxingmidlet extends midlet implements commandlistener { <nl> display . setcurrent ( alert , display . getcurrent ( ) ) ; <nl> } <nl>  <nl> - private static class videocanvas extends canvas { <nl> + private class videocanvas extends canvas implements commandlistener { <nl> + private final command decode = new command ( " decode " , command . screen , num ) ; <nl> + private final command exit = new command ( " exit " , command . exit , num ) ; <nl> + private videocanvas ( ) { <nl> + addcommand ( decode ) ; <nl> + addcommand ( exit ) ; <nl> + setcommandlistener ( this ) ; <nl> + } <nl> protected void paint ( graphics graphics ) { <nl> / / do nothing <nl> } <nl> + protected void keypressed ( int keycode ) { <nl> + if ( fire = = getgameaction ( keycode ) ) { <nl> + new snapshotthread ( ) . start ( ) ; <nl> + } <nl> + } <nl> + public void commandaction ( command command , displayable displayable ) { <nl> + if ( command . equals ( decode ) ) { <nl> + new snapshotthread ( ) . start ( ) ; <nl> + } else if ( command . equals ( exit ) ) { <nl> + destroyapp ( false ) ; <nl> + notifydestroyed ( ) ; <nl> + } <nl> + } <nl> } <nl>  <nl> + <nl> private class snapshotthread extends thread { <nl> public void run ( ) { <nl> try {
public final class multiformatreader implements reader { <nl> throws readerexception { <nl> hashtable possibleformats = <nl> hints = = null ? null : ( hashtable ) hints . get ( decodehinttype . possible_formats ) ; <nl> + <nl> if ( possibleformats = = null | | possibleformats . contains ( barcodeformat . qr_code ) ) { <nl> return new qrcodereader ( ) . decode ( image , hints ) ; <nl> } else {
<nl> + # how to debug lombok running in eclipse <nl> + <nl> + # # overview <nl> + <nl> + lombok ' s build scripting can generate a target for you , that lets you run the same eclipse installation inside eclipse , in debug mode . now you can add breakpoints . <nl> + <nl> + as lombok is an agent , lombok __must__ load from a jar file . <nl> + nevertheless , lombok can be hot - code - replaced in the debugger . <nl> + this works via the loader : the lombok agent has its own classloading architecture , and this architecture is capable of loading lombok ' s class files from a location of your choosing . choose the / bin dir from your eclipse project which will help with debugging ; eclipse will then be able to apply hcr to the eclipse - running - in - eclipse . unless there are issues with the loader architecture itself , of course . <nl> + <nl> + the end goal is that you can make some changes to the lombok sources in your eclipse , then click the ' debug ' button , and a new ' test eclipse ' starts up using lombok as you wrote it just now . you can now make changes to lombok sources in the original eclipse , hit ' save ' , and these changes now get automatically applied to the ' test eclipse ' , as long as you aren ' t making any changes to signatures ( add or remove methods / fields / types , or change return types , param types , etc ) . <nl> + <nl> + if you have the sources to eclipse itself , you can open them , set breakpoints , and step through , though be aware that lombok ' s agent injection system does cause some issues here ; we move methods into different classes and eclipse ' s debugger naturally doesn ' t understand this , so you can ' t breakpoint lombok ' s own patch methods , and stepping through them ' works ' but looks bizarre in the debugger as the debugger now thinks your source file clearly cannot possibly match the class file currently running . just keep going ( ' step out ' ) , eclipse will figure it out again once you ' re back in un - instrumented eclipse code . <nl> + <nl> + <nl> + <nl> + <nl> + describe in detail : <nl> + <nl> + * which ant tasks to run to create the targets <nl> + * how to modify this target , if needed , to point at your bin dir <nl> + <nl> mmm / dev / null <nl> ppp b / doc / debug - insights / vscode . txt <nl>
public class handleequalsandhashcode extends eclipseannotationhandler < equalsandh <nl> method . returntype = typereference . basetypereference ( typeids . t_int , num ) ; <nl> setgeneratedby ( method . returntype , source ) ; <nl> annotation overrideannotation = makemarkerannotation ( typeconstants . java_lang_override , source ) ; <nl> + <nl> if ( getcheckerframeworkversion ( type ) . generatesideeffectfree ( ) ) { <nl> method . annotations = new annotation [ ] { overrideannotation , generatenamedannotation ( source , checkerframeworkversion . name__side_effect_free ) } ; <nl> } else { <nl> mmm a / src / core / lombok / javac / handlers / handleequalsandhashcode . java <nl> ppp b / src / core / lombok / javac / handlers / handleequalsandhashcode . java <nl>
<nl> + package com . sun . tools . javac . comp ; <nl> + <nl> + public class <nl> \ no newline at end of file <nl> mmm / dev / null <nl> ppp b / src / stubsstubs / com / sun / tools / javac / util / context . java <nl>
final class lombokfileobjects { <nl> } <nl> throw new illegalargumentexception ( sb . tostring ( ) ) ; <nl> } <nl> + <nl> + static class basefilemanagerwrapper extends basefilemanager { <nl> + javafilemanager manager ; <nl> + <nl> + public basefilemanagerwrapper ( javafilemanager manager ) { <nl> + super ( standardcharsets . utf_8 ) ; <nl> + this . manager = manager ; <nl> + } <nl> + <nl> + @ override <nl> + public int issupportedoption ( string option ) { <nl> + return manager . issupportedoption ( option ) ; <nl> + } <nl> + <nl> + @ override <nl> + public classloader getclassloader ( location location ) { <nl> + return manager . getclassloader ( location ) ; <nl> + } <nl> + <nl> + @ override <nl> + public iterable < javafileobject > list ( location location , string packagename , set < kind > kinds , boolean recurse ) throws ioexception { <nl> + return manager . list ( location , packagename , kinds , recurse ) ; <nl> + } <nl> + <nl> + @ override <nl> + public string inferbinaryname ( location location , javafileobject file ) { <nl> + return manager . inferbinaryname ( location , file ) ; <nl> + } <nl> + <nl> + @ override <nl> + public boolean issamefile ( fileobject a , fileobject b ) { <nl> + return manager . issamefile ( a , b ) ; <nl> + } <nl> + <nl> + @ override <nl> + public boolean handleoption ( string current , iterator < string > remaining ) { <nl> + return manager . handleoption ( current , remaining ) ; <nl> + } <nl> + <nl> + @ override <nl> + public boolean haslocation ( location location ) { <nl> + return manager . haslocation ( location ) ; <nl> + } <nl> + <nl> + @ override <nl> + public javafileobject getjavafileforinput ( location location , string classname , kind kind ) throws ioexception { <nl> + return manager . getjavafileforinput ( location , classname , kind ) ; <nl> + } <nl> + <nl> + @ override <nl> + public javafileobject getjavafileforoutput ( location location , string classname , kind kind , fileobject sibling ) throws ioexception { <nl> + return manager . getjavafileforoutput ( location , classname , kind , sibling ) ; <nl> + } <nl> + <nl> + @ override <nl> + public fileobject getfileforinput ( location location , string packagename , string relativename ) throws ioexception { <nl> + return manager . getfileforinput ( location , packagename , relativename ) ; <nl> + } <nl> + <nl> + @ override <nl> + public fileobject getfileforoutput ( location location , string packagename , string relativename , fileobject sibling ) throws ioexception { <nl> + return manager . getfileforoutput ( location , packagename , relativename , sibling ) ; <nl> + } <nl> + <nl> + @ override <nl> + public void flush ( ) throws ioexception { <nl> + manager . flush ( ) ; <nl> + } <nl> + <nl> + @ override <nl> + public void close ( ) throws ioexception { <nl> + manager . close ( ) ; <nl> + } <nl> + } <nl>  <nl> static javafileobject createempty ( compiler compiler , string name , kind kind ) { <nl> return compiler . wrap ( new emptylombokfileobject ( name , kind ) ) ; <nl> mmm a / src / stubs / com / sun / tools / javac / file / basefilemanager . java <nl> ppp b / src / stubs / com / sun / tools / javac / file / basefilemanager . java <nl>
import java . util . map ; <nl> import javax . tools . diagnosticlistener ; <nl> import javax . tools . javafileobject ; <nl>  <nl> + import lombok . lombok ; <nl> import lombok . javac . commentcatcher ; <nl> import lombok . javac . lombokoptions ; <nl>  <nl> + import com . sun . tools . javac . comp . <nl> import com . sun . tools . javac . main . javacompiler ; <nl> import com . sun . tools . javac . main . optionname ; <nl> import com . sun . tools . javac . tree . jctree . jccompilationunit ; <nl>
public class delombok { <nl> return true ; <nl> } <nl>  <nl> + private static method attributemethod ; <nl> + / * * method is needed because the call signature has changed between javac6 and javac7 ; no matter what we compile against , using delombok in the other means verifyerrors . * / <nl> + private static object callattributemethodonjavacompiler ( javacompiler compiler , <nl> + if ( attributemethod = = null ) { <nl> + try { <nl> + attributemethod = javacompiler . class . getdeclaredmethod ( " attribute " , java . util . queue . class ) ; <nl> + } catch ( nosuchmethodexception e ) { <nl> + try { <nl> + attributemethod = javacompiler . class . getdeclaredmethod ( " attribute " , com . sun . tools . javac . util . listbuffer . class ) ; <nl> + } catch ( nosuchmethodexception e2 ) { <nl> + throw lombok . sneakythrow ( e2 ) ; <nl> + } <nl> + } <nl> + } <nl> + try { <nl> + return attributemethod . invoke ( compiler , arg ) ; <nl> + } catch ( exception e ) { <nl> + if ( e instanceof invocationtargetexception ) throw lombok . sneakythrow ( e . getcause ( ) ) ; <nl> + throw lombok . sneakythrow ( e ) ; <nl> + } <nl> + } <nl> + <nl> + private static method flowmethod ; <nl> + / * * method is needed because the call signature has changed between javac6 and javac7 ; no matter what we compile against , using delombok in the other means verifyerrors . * / <nl> + private static void callflowmethodonjavacompiler ( javacompiler compiler , object arg ) { <nl> + if ( flowmethod = = null ) { <nl> + try { <nl> + flowmethod = javacompiler . class . getdeclaredmethod ( " flow " , java . util . queue . class ) ; <nl> + } catch ( nosuchmethodexception e ) { <nl> + try { <nl> + flowmethod = javacompiler . class . getdeclaredmethod ( " flow " , com . sun . tools . javac . util . list . class ) ; <nl> + } catch ( nosuchmethodexception e2 ) { <nl> + throw lombok . sneakythrow ( e2 ) ; <nl> + } <nl> + } <nl> + } <nl> + try { <nl> + flowmethod . invoke ( compiler , arg ) ; <nl> + } catch ( exception e ) { <nl> + if ( e instanceof invocationtargetexception ) throw lombok . sneakythrow ( e . getcause ( ) ) ; <nl> + throw lombok . sneakythrow ( e ) ; <nl> + } <nl> + } <nl> + <nl> private static string canonical ( file dir ) { <nl> try { <nl> return dir . getcanonicalpath ( ) ;
public class delombok { <nl> } <nl>  <nl> javacompiler delegate = compiler . processannotations ( compiler . entertrees ( tojavaclist ( roots ) ) ) ; <nl> + delegate . flow ( delegate . attribute ( delegate . <nl> for ( jccompilationunit unit : roots ) { <nl> delombokresult result = new delombokresult ( catcher . getcomments ( unit ) , unit , force | | options . ischanged ( unit ) ) ; <nl> if ( verbose ) feedback . printf ( " file : % s [ % s ] \n " , unit . sourcefile . getname ( ) , result . ischanged ( ) ? " delomboked " : " unchanged " ) ;
public class handlesynchronized extends eclipseannotationhandler < synchronized > { <nl> fielddecl . type = new qualifiedtypereference ( typeconstants . java_lang_object , new long [ ] { num , num , num } ) ; <nl> eclipse . setgeneratedby ( fielddecl . type , source ) ; <nl> fielddecl . initialization = arrayalloc ; <nl> - injectfieldsuppresswarnings ( annotationnode . up ( ) . up ( ) , fielddecl ) ; <nl> + <nl> + injectfield ( annotationnode . up ( ) . up ( ) , fielddecl ) ; <nl> } <nl>  <nl> return lockname ;
public class patchdelegate { <nl> return false ; <nl> } <nl>  <nl> + private static void removeexistingmethods ( list < methodbinding > list , typedeclaration decl , classscope scope ) { <nl> + for ( abstractmethoddeclaration methoddecl : decl . methods ) { <nl> + if ( ! ( methoddecl instanceof methoddeclaration ) ) continue ; <nl> + methoddeclaration md = ( methoddeclaration ) methoddecl ; <nl> + char [ ] name = md . selector ; <nl> + typebinding [ ] args = md . arguments = = null ? new typebinding [ 0 ] : new typebinding [ md . arguments . length ] ; <nl> + for ( int i = num ; i < args . length ; i + + ) { <nl> + typereference clone = eclipse . copytype ( md . arguments [ i ] . type , md . arguments [ i ] ) ; <nl> + args [ i ] = clone . resolvetype ( scope ) . erasure ( ) ; <nl> + } <nl> + iterator < methodbinding > it = list . iterator ( ) ; <nl> + methods : <nl> + while ( it . hasnext ( ) ) { <nl> + methodbinding mb = it . next ( ) ; <nl> + if ( ! arrays . equals ( mb . selector , name ) ) continue ; <nl> + int paramlen = mb . parameters = = null ? num : mb . parameters . length ; <nl> + if ( paramlen ! = args . length ) continue ; <nl> + <nl> + for ( int i = num ; i < paramlen ; i + + ) { <nl> + if ( ! mb . parameters [ i ] . erasure ( ) . isequivalentto ( args [ i ] ) ) continue methods ; <nl> + } <nl> + it . remove ( ) ; / / method already exists in this class - don ' t create a delegating implementation . <nl> + } <nl> + } <nl> + } <nl> + <nl> private static void generatedelegatemethods ( typedeclaration type , list < methodbinding > methods , char [ ] delegate , astnode source ) { <nl> for ( methodbinding binding : methods ) { <nl> methoddeclaration method = generatedelegatemethod ( delegate , binding , type . compilationresult , source ) ;
public class patchfixes { <nl>  <nl> public static void addtasklistenerwhencallingjavac ( javactaskimpl task , <nl> @ suppresswarnings ( " unused " ) / * will come in handy later * / classpathinfo cpinfo ) throws exception { <nl> + if ( task = = null ) return ; <nl> class < ? > entrypoint = javactaskimpl . class . getclassloader ( ) . loadclass ( " lombok . netbeans . agent . netbeansentrypoint " ) ; <nl> - task . settasklistener ( ( tasklistener ) entrypoint . getconstructor ( context . class ) . newinstance ( task . getcontext ( ) ) ) ; <nl> + if ( entrypoint = = null ) { <nl> + / * <nl> + system . err . println ( " [ lombok ] classloader not patched correctly . " ) ; <nl> + } else { <nl> + task . settasklistener ( ( tasklistener ) entrypoint . getconstructor ( context . class ) . newinstance ( task . getcontext ( ) ) ) ; <nl> + } <nl> } <nl>  <nl> public static iterator < jctree > filtergenerated ( final iterator < jctree > it ) {
class handlegetter_javac extends handlerforcompiler < getter > { <nl>  <nl> private methodtree creategetter ( element field , treemaker treemaker , name . table nametable ) { <nl> jcstatement returnstatement = treemaker . return ( treemaker . ident ( ( symbol ) field ) ) ; <nl> + <nl> + <nl> + <nl> jcblock methodbody = treemaker . block ( 0 , list . of ( returnstatement ) ) ; <nl> name methodname = name . fromstring ( nametable , pkg . togettername ( field ) ) ; <nl> jcexpression methodtype = treemaker . type ( ( type ) field . astype ( ) ) ; <nl> mmm a / src / lombok / apt / pkg . java <nl> ppp b / src / lombok / apt / pkg . java <nl>
package org . thoughtcrime . securesms . fonts <nl>  <nl> import android . content . context <nl> import android . graphics . typeface <nl> + import android . os . build <nl> import org . signal . imageeditor . core . renderer <nl> import org . signal . imageeditor . core . renderercontext <nl> - import org . thoughtcrime . securesms . util . futuretasklistener <nl> - import java . util . locale <nl> - import java . util . concurrent . executionexception <nl>  <nl> / * * <nl> * rendercontext typefaceprovider that provides typefaces using textfont . <nl> * / <nl> object fonttypefaceprovider : renderercontext . typefaceprovider { <nl> override fun getselectedtypeface ( context : context , renderer : renderer , invalidate : renderercontext . invalidate ) : typeface { <nl> - return when ( val fontresult = fonts . resolvefont ( context , locale . getdefault ( ) , textfont . bold ) ) { <nl> - is fonts . fontresult . immediate - > fontresult . typeface <nl> - is fonts . fontresult . async - > { <nl> - fontresult . future . addlistener ( object : futuretasklistener < typeface > { <nl> - override fun onsuccess ( result : typeface ? ) { <nl> - invalidate . oninvalidate ( renderer ) <nl> - } <nl> - <nl> - override fun onfailure ( exception : executionexception ? ) = unit <nl> - } ) <nl> + return gettypeface ( ) <nl> + <nl> + / / is fonts . fontresult . immediate - > fontresult . typeface <nl> + / / is fonts . fontresult . async - > { <nl> + / / fontresult . future . addlistener ( object : futuretasklistener < typeface > { <nl> + / / override fun onsuccess ( result : typeface ? ) { <nl> + / / invalidate . oninvalidate ( renderer ) <nl> + / / } <nl> + / / <nl> + / / override fun onfailure ( exception : executionexception ? ) = unit <nl> + / / } ) <nl> + / / <nl> + / / fontresult . placeholder <nl> + / / } <nl> + / / } <nl> + } <nl>  <nl> - fontresult . placeholder <nl> - } <nl> + private fun gettypeface ( ) : typeface { <nl> + return if ( build . version . sdk_int < num ) { <nl> + typeface . create ( typeface . default , typeface . bold ) <nl> + } else { <nl> + typeface . builder ( " " ) <nl> + . setfallback ( " sans - serif " ) <nl> + . setweight ( 900 ) <nl> + . build ( ) <nl> } <nl> } <nl> } <nl> mmm a / app / src / main / java / org / thoughtcrime / securesms / stories / storytextpostview . kt <nl> ppp b / app / src / main / java / org / thoughtcrime / securesms / stories / storytextpostview . kt <nl>
class mystoriesfragment : dslsettingsfragment ( <nl> custompref ( <nl> mystoriesitem . model ( <nl> distributionstory = conversationmessage , <nl> + onclick = { <nl> + <nl> + startactivity ( storyvieweractivity . createintent ( requirecontext ( ) , recipient . self ( ) . id ) ) <nl> + } , <nl> onsaveclick = { <nl> storycontextmenu . save ( requirecontext ( ) , it . distributionstory . messagerecord ) <nl> } , <nl> mmm a / app / src / main / java / org / thoughtcrime / securesms / stories / my / mystoriesitem . kt <nl> ppp b / app / src / main / java / org / thoughtcrime / securesms / stories / my / mystoriesitem . kt <nl>
public final class signalcallmanager implements callmanager . observer , groupcall . <nl> } <nl> } <nl>  <nl> + @ override <nl> + public void onaudiolevels ( remote remote , int capturedlevel , int receivedlevel ) { <nl> + <nl> + } <nl> + <nl> @ override <nl> public void oncallconcluded ( @ nullable remote remote ) { <nl> if ( ! ( remote instanceof remotepeer ) ) { <nl>
public final class signalcallmanager implements callmanager . observer , groupcall . <nl> process ( ( s , p ) - > p . handlegrouplocaldevicestatechanged ( s ) ) ; <nl> } <nl>  <nl> + @ override <nl> + public void onaudiolevels ( @ nonnull groupcall groupcall ) { <nl> + <nl> + } <nl> + <nl> @ override <nl> public void onremotedevicestateschanged ( @ nonnull groupcall groupcall ) { <nl> process ( ( s , p ) - > p . handlegroupremotedevicestatechanged ( s ) ) ; <nl> mmm a / dependencies . gradle <nl> ppp b / dependencies . gradle <nl>
class googlepayapi ( <nl> put ( " merchantinfo " , merchantinfo ) <nl> put ( " allowedpaymentmethods " , jsonarray ( ) . put ( cardpaymentmethod ( ) ) ) <nl> put ( " transactioninfo " , gettransactioninfo ( price , label ) ) <nl> - put ( " emailrequired " , true ) <nl> + <nl> + put ( " emailrequired " , false ) <nl> put ( " shippingaddressrequired " , false ) <nl> } <nl> } <nl> mmm a / donations / lib / src / main / java / org / signal / donations / stripeapi . kt <nl> ppp b / donations / lib / src / main / java / org / signal / donations / stripeapi . kt <nl>
class stripeapi ( <nl> " payment_method " to paymentmethodid <nl> ) <nl>  <nl> - val email = paymentsource . email ( ) <nl> - if ( email ! = null ) { <nl> - parameters [ " receipt_email " ] = email <nl> - } <nl> + <nl> + / / if ( email ! = null ) { <nl> + / / parameters [ " receipt_email " ] = email <nl> + / / } <nl>  <nl> postform ( " payment_intents / $ { paymentintent . id } / confirm " , parameters ) <nl> } . subscribeon ( schedulers . io ( ) ) <nl>
class stripeapi ( <nl> " type " to " card " , <nl> ) <nl>  <nl> - val email = paymentsource . email ( ) <nl> - if ( email ! = null ) { <nl> - parameters [ " billing_details [ email ] " ] = email <nl> - } <nl> + <nl> + / / if ( email ! = null ) { <nl> + / / parameters [ " billing_details [ email ] " ] = email <nl> + / / } <nl>  <nl> return postform ( " payment_methods " , parameters ) <nl> }
public enum databasesessionlock implements signalsessionlock { <nl>  <nl> @ override <nl> public lock acquire ( ) { <nl> - if ( featureflags . internaluser ( ) ) { <nl> - sqlitedatabase db = databasefactory . getinstance ( applicationdependencies . getapplication ( ) ) . getrawdatabase ( ) ; <nl> - <nl> - if ( db . isdblockedbycurrentthread ( ) ) { <nl> - return ( ) - > { } ; <nl> - } <nl> - <nl> - db . begintransaction ( ) ; <nl> - <nl> - ownerthreadid = thread . currentthread ( ) . getid ( ) ; <nl> + legacy_lock . lock ( ) ; <nl> + return legacy_lock : : unlock ; <nl>  <nl> - return ( ) - > { <nl> - ownerthreadid = - 1 ; <nl> - db . settransactionsuccessful ( ) ; <nl> - db . endtransaction ( ) ; <nl> - } ; <nl> - } else { <nl> - legacy_lock . lock ( ) ; <nl> - return legacy_lock : : unlock ; <nl> - } <nl> + <nl> + / / <nl> + / / if ( db . isdblockedbycurrentthread ( ) ) { <nl> + / / return ( ) - > { } ; <nl> + / / } <nl> + / / <nl> + / / db . begintransaction ( ) ; <nl> + / / <nl> + / / ownerthreadid = thread . currentthread ( ) . getid ( ) ; <nl> + / / <nl> + / / return ( ) - > { <nl> + / / ownerthreadid = - 1 ; <nl> + / / db . settransactionsuccessful ( ) ; <nl> + / / db . endtransaction ( ) ; <nl> + / / } ; <nl> } <nl>  <nl> / * * <nl> mmm a / app / src / main / java / org / thoughtcrime / securesms / messages / incomingmessageprocessor . java <nl> ppp b / app / src / main / java / org / thoughtcrime / securesms / messages / incomingmessageprocessor . java <nl>
public final class conversationupdateitem extends framelayout <nl>  <nl> / * * after a short delay , if the main data hasn ' t shown yet , then a loading message is displayed . * / <nl> private @ nonnull livedata < spannable > loading ( @ nonnull livedata < spannable > string ) { <nl> - return livedatautil . until ( string , livedatautil . delay ( 250 , new spannablestring ( getcontext ( ) . getstring ( r . string . conversationupdateitem_loading ) ) ) ) ; <nl> + <nl> + return string ; <nl> + / / return livedatautil . until ( string , livedatautil . delay ( 250 , new spannablestring ( getcontext ( ) . getstring ( r . string . conversationupdateitem_loading ) ) ) ) ; <nl> } <nl>  <nl> @ override
public class signalservicemessagesender { <nl> quotebuilder . setauthoruuid ( message . getquote ( ) . get ( ) . getauthor ( ) . getuuid ( ) . get ( ) . tostring ( ) ) ; <nl> } <nl>  <nl> + <nl> + if ( message . getquote ( ) . get ( ) . getauthor ( ) . getnumber ( ) . ispresent ( ) ) { <nl> + quotebuilder . setauthore164 ( message . getquote ( ) . get ( ) . getauthor ( ) . getnumber ( ) . get ( ) ) ; <nl> + } <nl> + <nl> if ( ! message . getquote ( ) . get ( ) . getmentions ( ) . isempty ( ) ) { <nl> for ( signalservicedatamessage . mention mention : message . getquote ( ) . get ( ) . getmentions ( ) ) { <nl> quotebuilder . addbodyranges ( datamessage . bodyrange . newbuilder ( ) <nl> mmm a / libsignal / service / src / main / java / org / whispersystems / signalservice / api / messages / signalservicecontent . java <nl> ppp b / libsignal / service / src / main / java / org / whispersystems / signalservice / api / messages / signalservicecontent . java <nl>
public class conversationlistfragment extends mainfragment implements loadermana <nl> @ override <nl> public void onstart ( ) { <nl> super . onstart ( ) ; <nl> - conversationfragment . prepare ( requirecontext ( ) ) ; <nl> + <nl> } <nl>  <nl> @ override
public final class storagesynchelpertest { <nl> signalgroupv1record merge4 = groupv1 ( 222 , num , true , true ) ; <nl>  <nl> assertequals ( setof ( remote3 ) , result . getlocalcontactinserts ( ) ) ; <nl> - assertequals ( setof ( contactupdate ( local2 , merge2 ) ) , result . getlocalcontactupdates ( ) ) ; <nl> + <nl> assertequals ( setof ( groupv1update ( local4 , merge4 ) ) , result . getlocalgroupv1updates ( ) ) ; <nl> assertequals ( setof ( signalstoragerecord . forcontact ( local3 ) ) , result . getremoteinserts ( ) ) ; <nl> - assertequals ( setof ( recordupdate ( remote1 , merge1 ) , recordupdate ( remote2 , merge2 ) , recordupdate ( remote4 , merge4 ) ) , result . getremoteupdates ( ) ) ; <nl> + / / assertequals ( setof ( recordupdate ( remote1 , merge1 ) , recordupdate ( remote2 , merge2 ) , recordupdate ( remote4 , merge4 ) ) , result . getremoteupdates ( ) ) ; <nl> assertequals ( setof ( unknownremote ) , result . getlocalunknowninserts ( ) ) ; <nl> assertequals ( setof ( unknownlocal ) , result . getlocalunknowndeletes ( ) ) ; <nl> }
public abstract class passphraserequiredactionbaractivity extends baseactionbara <nl> } <nl>  <nl> private boolean usermustsetkbspin ( ) { <nl> - return ! signalstore . registrationvalues ( ) . isregistrationcomplete ( ) & & ! pinutil . userhaspin ( this ) ; <nl> + <nl> + return false ; <nl> } <nl>  <nl> private boolean usermustsetprofilename ( ) { <nl> mmm a / app / src / main / java / org / thoughtcrime / securesms / keyvalue / kbsvalues . java <nl> ppp b / app / src / main / java / org / thoughtcrime / securesms / keyvalue / kbsvalues . java <nl>
public final class registrationvalues { <nl> public synchronized void onnewinstall ( ) { <nl> store . beginwrite ( ) <nl> . putboolean ( registration_complete , false ) <nl> - . putboolean ( pin_required , true ) <nl> + <nl> . commit ( ) ; <nl> } <nl>  <nl> mmm a / app / src / main / java / org / thoughtcrime / securesms / megaphone / pinsforallschedule . java <nl> ppp b / app / src / main / java / org / thoughtcrime / securesms / megaphone / pinsforallschedule . java <nl>
public class signalservicecipher { <nl> } else if ( e164address ! = null & & store . containssession ( e164address ) ) { <nl> return e164address ; <nl> } else { <nl> - return new signalprotocoladdress ( address . getidentifier ( ) , sourcedevice ) ; <nl> + <nl> + string preferred ; <nl> + <nl> + if ( address . getnumber ( ) . ispresent ( ) ) { <nl> + preferred = address . getnumber ( ) . get ( ) ; <nl> + } else if ( address . getuuid ( ) . ispresent ( ) ) { <nl> + preferred = address . getuuid ( ) . get ( ) . tostring ( ) ; <nl> + } else { <nl> + throw new assertionerror ( " given the constrains of creating a signalserviceaddress , this should not be possible . " ) ; <nl> + } <nl> + <nl> + return new signalprotocoladdress ( preferred , sourcedevice ) ; <nl> } <nl> } <nl>  <nl> mmm a / libsignal / service / src / main / java / org / whispersystems / signalservice / api / push / signalserviceaddress . java <nl> ppp b / libsignal / service / src / main / java / org / whispersystems / signalservice / api / push / signalserviceaddress . java <nl>
class mediasendviewmodel extends viewmodel { <nl> buttonstate = ( recipient ! = null ) ? buttonstate . send : buttonstate . continue ; <nl>  <nl> if ( revealstate = = revealstate . gone & & revealsupported ( ) ) { <nl> - revealstate = textsecurepreferences . isrevealablemessageenabled ( application ) ? revealstate . enabled : revealstate . disabled ; <nl> + <nl> + revealstate = revealstate . gone ; <nl> } else if ( ! revealsupported ( ) ) { <nl> revealstate = revealstate . gone ; <nl> }
final class stickermanagementadapter extends recyclerview . adapter { <nl> actionbuttonimage . setimageresource ( r . drawable . ic_x ) ; <nl> actionbutton . setonclicklistener ( v - > eventlistener . onstickerpackuninstallclicked ( stickerpack . getpackid ( ) , stickerpack . getpackkey ( ) ) ) ; <nl>  <nl> - sharebutton . setvisibility ( view . visible ) ; <nl> - sharebuttonimage . setvisibility ( view . visible ) ; <nl> - sharebutton . setonclicklistener ( v - > eventlistener . onstickerpackshareclicked ( stickerpack . getpackid ( ) , stickerpack . getpackkey ( ) ) ) ; <nl> + <nl> + / / sharebuttonimage . setvisibility ( view . visible ) ; <nl> + / / sharebutton . setonclicklistener ( v - > eventlistener . onstickerpackshareclicked ( stickerpack . getpackid ( ) , stickerpack . getpackkey ( ) ) ) ; <nl> } else { <nl> actionbuttonimage . setimageresource ( r . drawable . ic_arrow_down ) ; <nl> actionbutton . setonclicklistener ( v - > eventlistener . onstickerpackinstallclicked ( stickerpack . getpackid ( ) , stickerpack . getpackkey ( ) ) ) ; <nl>
final class stickermanagementadapter extends recyclerview . adapter { <nl> sharebutton . setonclicklistener ( null ) ; <nl> } <nl>  <nl> + <nl> + sharebutton . setvisibility ( view . gone ) ; <nl> + sharebuttonimage . setvisibility ( view . gone ) ; <nl> + <nl> itemview . setonclicklistener ( v - > eventlistener . onstickerpackclicked ( stickerpack . getpackid ( ) , stickerpack . getpackkey ( ) ) ) ; <nl> } <nl>  <nl> mmm a / src / org / thoughtcrime / securesms / stickers / stickerpackpreviewactivity . java <nl> ppp b / src / org / thoughtcrime / securesms / stickers / stickerpackpreviewactivity . java <nl>
public final class stickerpackpreviewactivity extends passphraserequiredactionba <nl> if ( manifest . ispresent ( ) ) { <nl> presentmanifest ( manifest . get ( ) . getmanifest ( ) ) ; <nl> presentbutton ( manifest . get ( ) . isinstalled ( ) ) ; <nl> - presentsharebutton ( manifest . get ( ) . isinstalled ( ) , manifest . get ( ) . getmanifest ( ) . getpackid ( ) , manifest . get ( ) . getmanifest ( ) . getpackkey ( ) ) ; <nl> + <nl> } else { <nl> presenterror ( ) ; <nl> }
public class conversationadaptertest extends baseunittest { <nl> } <nl>  <nl> @ test <nl> + @ ignore ( " <nl> public void testgetitemidequals ( ) throws exception { <nl> when ( cursor . getstring ( anyint ( ) ) ) . thenreturn ( null ) . thenreturn ( " sms : : 1 : : 1 " ) ; <nl> long firstid = adapter . getitemid ( cursor ) ;
public class conversationactivity extends passphraserequiredactionbaractivity <nl> setmedia ( data . getdata ( ) , mediatype . audio ) ; <nl> break ; <nl> case pick_contact : <nl> - if ( issecuretext & & ! issmsforced ( ) ) { <nl> - opencontactshareeditor ( data . getdata ( ) ) ; <nl> - } else { <nl> - addattachmentcontactinfo ( data . getdata ( ) ) ; <nl> - } <nl> + <nl> + addattachmentcontactinfo ( data . getdata ( ) ) ; <nl> + / / if ( issecuretext & & ! issmsforced ( ) ) { <nl> + / / opencontactshareeditor ( data . getdata ( ) ) ; <nl> + / / } else { <nl> + / / addattachmentcontactinfo ( data . getdata ( ) ) ; <nl> + / / } <nl> break ; <nl> case get_contact_details : <nl> sendsharedcontact ( data . getparcelablearraylistextra ( contactshareeditactivity . key_contacts ) ) ; <nl>
public class conversationactivity extends passphraserequiredactionbaractivity <nl> private void setmedia ( @ nullable uri uri , @ nonnull mediatype mediatype , int width , int height ) { <nl> if ( uri = = null ) return ; <nl>  <nl> - if ( mediatype . vcard . equals ( mediatype ) & & issecuretext ) { <nl> - opencontactshareeditor ( uri ) ; <nl> - } else { <nl> - attachmentmanager . setmedia ( gliderequests , uri , mediatype , getcurrentmediaconstraints ( ) , width , height ) ; <nl> - } <nl> + <nl> + attachmentmanager . setmedia ( gliderequests , uri , mediatype , getcurrentmediaconstraints ( ) , width , height ) ; <nl> + / / if ( mediatype . vcard . equals ( mediatype ) & & issecuretext ) { <nl> + / / opencontactshareeditor ( uri ) ; <nl> + / / } else { <nl> + / / attachmentmanager . setmedia ( gliderequests , uri , mediatype , getcurrentmediaconstraints ( ) , width , height ) ; <nl> + / / } <nl> } <nl>  <nl> private void opencontactshareeditor ( uri contacturi ) {
public abstract class legacymmsconnection { <nl> if ( response . getstatusline ( ) . getstatuscode ( ) = = num ) { <nl> return parseresponse ( response . getentity ( ) . getcontent ( ) ) ; <nl> } <nl> + } catch ( nullpointerexception npe ) { <nl> + <nl> + throw new ioexception ( npe ) ; <nl> } finally { <nl> if ( response ! = null ) response . close ( ) ; <nl> if ( client ! = null ) client . close ( ) ;
public class mmsdatabase extends database implements mmssmscolumns { <nl> } <nl> } <nl>  <nl> - if ( encodedtolist ! = null ) { <nl> + if ( encodedtolist ! = null & & ( encodedtolist . length > num | | group . size ( ) > num ) ) { <nl> string localnumber = util . getdevicee164number ( context ) ; <nl>  <nl> + if ( localnumber = = null ) { <nl> + localnumber = textsecurepreferences . getlocalnumber ( context ) ; <nl> + } <nl> + <nl> for ( encodedstringvalue encodedto : encodedtolist ) { <nl> string to = new string ( encodedto . gettextstring ( ) , charactersets . mimename_iso_8859_1 ) ; <nl>  <nl> - if ( ! localnumber . equals ( to ) ) { <nl> + / <nl> + if ( localnumber = = null | | ! localnumber . equals ( to ) ) { <nl> group . add ( to ) ; <nl> } <nl> }
public class disruptortest <nl> assertthat ( integer . valueof ( executor . getexecutioncount ( ) ) , equalto ( integer . valueof ( 2 ) ) ) ; <nl> } <nl>  <nl> - @ test <nl> + <nl> public void shouldmakeentriesavailabletofirsthandlersimmediately ( ) throws exception <nl> { <nl> countdownlatch countdownlatch = new countdownlatch ( 2 ) ; <nl>
import java . util . treeset ; <nl> / * * <nl> * created by stardust on num / 2 / 17 . <nl> * / <nl> - <nl> + <nl> public class codecompletion implements textwatcher { <nl>  <nl>  <nl>
android { <nl> sourcecompatibility rootproject . ext . sourcecompatibility <nl> targetcompatibility rootproject . ext . sourcecompatibility <nl> } <nl> + <nl> + <nl> + libraryvariants . all { <nl> + it . generatebuildconfig . enabled = false <nl> + } <nl> } <nl>  <nl> dependencies {
<nl> + package com . baeldung . compiletimeconstants ; <nl> + <nl> + public class annotations { <nl> + <nl> + private final string deprecateddate = " 20 - 02 - 14 " ; <nl> + private final string deprecatedtime = " 22 : 00 " ; <nl> + <nl> + / / @ deprecated ( since = deprecateddate + " " + deprecatedtime ) <nl> + public void deprecatedmethod ( ) { } <nl> + <nl> + } <nl> mmm / dev / null <nl> ppp b / core - java - modules / core - java - lang - 4 / src / main / java / com / baeldung / compiletimeconstants / classconstants . java <nl>
<nl> + = = = = = = = = = <nl> + <nl> + # # core java collections cookbooks and examples <nl> + <nl> + # # # relevant articles : <nl> + <nl> + - <nl> mmm / dev / null <nl> ppp b / core - java - modules / core - java - collections - 4 / pom . xml <nl>
<nl> < module > twilio < / module > <nl> < module > twitter4j < / module > <nl>  <nl> - < module > undertow < / module > <nl> + < ! - - < module > undertow < / module > - - > < ! - - num . 11 . 2019 - disabling temporarily as it ' s causing a major issue with the build ( <nl>  <nl> < module > vertx < / module > <nl> < module > vertx - and - rxjava < / module >
<nl> < module > twilio < / module > <nl> < module > twitter4j < / module > <nl>  <nl> - < module > undertow < / module > <nl> + < ! - - < module > undertow < / module > - - > < ! - - num . 11 . 2019 - disabling temporarily as it ' s causing a major issue with the build ( <nl>  <nl> < module > vertx < / module > <nl> < module > vertx - and - rxjava < / module >
<nl> + enum class currency { <nl> + dollars , euro <nl> + } <nl> + <nl> + class money ( val amount : bigdecimal , val currency : currency ) : comparable < money > { <nl> + <nl> + override fun compareto ( other : money ) : int = <nl> + convert ( currency . dollars ) . compareto ( other . convert ( currency . dollars ) ) <nl> + <nl> + fun convert ( currency : currency ) : bigdecimal = <nl> + <nl> + override fun equals ( other : any ? ) : boolean { <nl> + if ( this = = = other ) return true <nl> + if ( other ! is money ) return false <nl> + <nl> + if ( amount ! = other . amount ) return false <nl> + if ( currency ! = other . currency ) return false <nl> + <nl> + return true <nl> + } <nl> + <nl> + override fun hashcode ( ) : int { <nl> + var result = amount . hashcode ( ) <nl> + result = num * result + currency . hashcode ( ) <nl> + return result <nl> + } <nl> + } <nl> \ no newline at end of file <nl> mmm / dev / null <nl> ppp b / core - kotlin / src / main / kotlin / com / baeldung / operators / page . kt <nl>
<nl> < target > 1 . 8 < / target > <nl> < / configuration > <nl> < / plugin > <nl> + < ! - - <nl> < plugin > <nl> < groupid > org . apache . maven . plugins < / groupid > <nl> < artifactid > maven - pmd - plugin < / artifactid > <nl>
<nl> < module > spring - integration < / module > <nl> < module > spring - jenkins - pipeline < / module > <nl> < module > spring - jersey < / module > <nl> - < module > jmeter < / module > <nl> + < ! - - < module > jmeter < / module > - - > < ! - - <nl> < module > spring - jms < / module > <nl> < module > spring - jooq < / module > <nl> < module > persistence - modules / spring - jpa < / module >
<nl> < module > httpclient < / module > <nl> < module > hystrix < / module > <nl>  <nl> - < module > image - processing < / module > <nl> + < ! - - < module > image - processing < / module > - - > < ! - - <nl> < module > immutables < / module > <nl> < module > influxdb < / module >
import org . junit . test ; <nl>  <nl> public class whenusingtreeset { <nl>  <nl> + private static class element { <nl> + private integer id ; <nl> + <nl> + public integer getid ( ) { <nl> + return id ; <nl> + } <nl> + <nl> + public void setid ( integer id ) { <nl> + this . id = id ; <nl> + } <nl> + <nl> + @ override <nl> + public string tostring ( ) { <nl> + <nl> + return id . tostring ( ) ; <nl> + } <nl> + } <nl> + <nl> + private comparator < element > comparator = ( ele1 , ele2 ) - > { <nl> + return ele1 . getid ( ) <nl> + . compareto ( ele2 . getid ( ) ) ; <nl> + } ; <nl> + <nl> @ test <nl> public void whenaddingelement_shouldaddelement ( ) { <nl> set < string > treeset = new treeset < > ( ) ; <nl>
public class buildermethods { <nl> system . out . println ( simple1 . getname ( ) ) ; <nl> system . out . println ( simple1 . hashcode ( ) ) ; <nl> system . out . println ( simple1 . tostring ( ) ) ; <nl> + <nl> + samplelazyinitializer samplelazyinitializer = new samplelazyinitializer ( ) ; <nl> + <nl> + try { <nl> + samplelazyinitializer . get ( ) ; <nl> + } catch ( concurrentexception e1 ) { <nl> + <nl> + e1 . printstacktrace ( ) ; <nl> + } <nl> + <nl> + samplebackgroundinitializer samplebackgroundinitializer = new samplebackgroundinitializer ( ) ; <nl> + samplebackgroundinitializer . start ( ) ; <nl> + <nl> + / / proceed with other tasks instead of waiting for the samplebackgroundinitializer task to finish . <nl> + <nl> + try { <nl> + object result = samplebackgroundinitializer . get ( ) ; <nl> + } catch ( concurrentexception e ) { <nl> + e . printstacktrace ( ) ; <nl> + } <nl> + } <nl> + } <nl> + <nl> + class samplebackgroundinitializer extends backgroundinitializer < string > { <nl> + <nl> + @ override <nl> + protected string initialize ( ) throws exception { <nl> + return null ; <nl> } <nl> + <nl> + / / any complex task that takes some time <nl> + <nl> } <nl> mmm a / libraries / src / test / java / com / baeldung / commons / lang3 / lang3utilstest . java <nl> ppp b / libraries / src / test / java / com / baeldung / commons / lang3 / lang3utilstest . java <nl>
<nl>  <nl> < module > handling - spring - static - resources < / module > <nl> < module > hazelcast < / module > <nl> - < ! - - < module > hbase < / module > - - > <nl> + < ! - - < module > hbase < / module > <nl> < module > httpclient < / module > <nl> < module > hystrix < / module > <nl>  <nl>
<nl> < module > selenium - junit - testng < / module > <nl> < module > solr - fulltext - search < / module > <nl> < module > spark - java < / module > <nl> - < module > spring - 5 < / module > <nl> + < ! - - < module > spring - 5 < / module > <nl> < module > spring - akka < / module > <nl> < module > spring - amqp < / module > <nl> < module > spring - all < / module >
public class antcolonyoptimization { <nl> * / <nl> private void moveants ( ) { <nl> intstream . range ( currentindex , numberofcities - num ) . foreach ( i - > { <nl> - ants . stream ( ) . foreach ( ant - > { <nl> - ant . visitcity ( currentindex , selectnextcity ( ant ) ) ; <nl> - } ) ; <nl> + ants . foreach ( ant - > ant . visitcity ( currentindex , selectnextcity ( ant ) ) ) ; <nl> currentindex + + ; <nl> } ) ; <nl> } <nl>  <nl> / * * <nl> * select next city for each ant <nl> - * <nl> - * @ param ant <nl> - * @ return <nl> * / <nl> private int selectnextcity ( ant ant ) { <nl> int t = random . nextint ( numberofcities - currentindex ) ; <nl> if ( random . nextdouble ( ) < randomfactor ) { <nl> - intstream . range ( 0 , numberofcities ) . filter ( i - > i = = t & & ! ant . visited ( i ) ) . findfirst ( ) ; <nl> + intstream . range ( 0 , numberofcities ) . filter ( i - > i = = t & & ! ant . visited ( i ) ) . findfirst ( ) ; <nl> } <nl> calculateprobabilities ( ant ) ; <nl> double r = random . nextdouble ( ) ; <nl>
<nl> + package com . baeldung . jmx ; <nl> + <nl> + import java . lang . management . managementfactory ; <nl> + import javax . management . instancealreadyexistsexception ; <nl> + import javax . management . mbeanregistrationexception ; <nl> + import javax . management . mbeanserver ; <nl> + import javax . management . malformedobjectnameexception ; <nl> + import javax . management . notcompliantmbeanexception ; <nl> + import javax . management . objectname ; <nl> + <nl> + public class jmxtutorialmainlauncher { <nl> + <nl> + public static void main ( string [ ] args ) { <nl> + <nl> + <nl> + system . out . println ( " this is basic jmx tutorial " ) ; <nl> + objectname objectname = null ; <nl> + try { <nl> + objectname = new objectname ( " com . baeldung . tutorial : type = basic , name = game " ) ; <nl> + } catch ( malformedobjectnameexception e ) { <nl> + e . printstacktrace ( ) ; <nl> + } <nl> + mbeanserver server = managementfactory . getplatformmbeanserver ( ) ; <nl> + game gameobj = new game ( ) ; <nl> + try { <nl> + server . registermbean ( gameobj , objectname ) ; <nl> + } catch ( instancealreadyexistsexception | mbeanregistrationexception | notcompliantmbeanexception e ) { <nl> + e . printstacktrace ( ) ; <nl> + } <nl> + system . out . println ( " registration for game mbean with the platform server is successfull " ) ; <nl> + system . out . println ( " please open jconsole to access game mbean " ) ; <nl> + while ( true ) { <nl> + / / to ensure application does not terminate <nl> + } <nl> + } <nl> + <nl> + }
public class productinforepositoryintegrationtest { <nl> private static final string expected_price = " 50 " ; <nl>  <nl> @ before <nl> + @ ignore <nl> public void setup ( ) throws exception { <nl>  <nl> try { <nl>
public class productinforepositoryintegrationtest { <nl> } <nl>  <nl> @ test <nl> + @ ignore <nl> public void givenitemwithexpectedcost_whenrunfindall_thenitemisfound ( ) { <nl>  <nl> productinfo productinfo = new productinfo ( expected_cost , expected_price ) ;
<nl> < modules > <nl> < module > assertj < / module > <nl> < module > apache - cxf < / module > <nl> - < module > apache - fop < / module > <nl> + < ! - - < module > apache - fop < / module > - - > < ! - - <nl> < module > autovalue - tutorial < / module > <nl> + <nl> < module > cdi < / module > <nl> < module > core - java < / module > <nl> < module > core - java - 8 < / module > <nl> < module > couchbase - sdk - intro < / module > <nl> < module > couchbase - sdk - spring - service < / module > <nl>  <nl> + < module > dozer < / module > <nl> < module > dependency - injection < / module > <nl> < module > deltaspike < / module > <nl> < ! - - < module > gatling < / module > - - > < ! - - not meant to run as part of the standard build - - > <nl>
public class javatimerunittest { <nl> thread . sleep ( delay * num ) ; <nl> } <nl>  <nl> + @ test <nl> + public void givenusingtimer_whenstoppingthread_thentimertaskiscancelled ( ) throws interruptedexception { <nl> + final timertask task = new timertask ( ) { <nl> + @ override <nl> + public void run ( ) { <nl> + system . out . println ( " task performed on " + new date ( ) ) ; <nl> + <nl> + } <nl> + } ; <nl> + final timer timer = new timer ( " timer " ) ; <nl> + <nl> + timer . scheduleatfixedrate ( task , num l , num l ) ; <nl> + <nl> + thread . sleep ( 1000l * num ) ; <nl> + } <nl> + <nl> @ test <nl> public void givenusingtimer_whencancelingtimer_thencorrect ( ) throws interruptedexception { <nl> final timertask task = new timertask ( ) {
public class dfatest { <nl> list < string > all = tree . matchall ( " aaaaaaat - iobbbbbbb " ) ; <nl> assert . assertequals ( all , collectionutil . newarraylist ( " t - io " ) ) ; <nl> } <nl> + <nl> + @ test <nl> + public void atest ( ) { <nl> + wordtree tree = new wordtree ( ) ; <nl> + tree . addword ( " women " ) ; <nl> + string text = " a women <nl> + list < string > matchall = tree . matchall ( text , - 1 , false , false ) ; <nl> + assert . assertequals ( " [ women ] " , matchall . tostring ( ) ) ; <nl> + } <nl>  <nl> / / - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - <nl> / * *
<nl> < notes > < ! [ cdata [ <nl> file name : htrace - core4 - 4 . 0 . 1 - incubating . jar ( shaded : com . fasterxml . jackson . core : jackson - databind : 2 . 4 . 0 ) <nl> ] ] > < / notes > <nl> - < packageurl regex = " true " > ^ pkg : maven / com \ . fasterxml \ . jackson \ . core / jackson \ - databind @ . * $ < / packageurl > <nl> - < cve > cve - 2017 - 7525 < / cve > <nl> - < cve > cve - 2017 - 15095 < / cve > <nl> - < cve > cve - 2017 - 17485 < / cve > <nl> - < cve > cve - 2018 - 5968 < / cve > <nl> - < cve > cve - 2018 - 7489 < / cve > <nl> - < cve > cve - 2018 - 11307 < / cve > <nl> - < cve > cve - 2018 - 14718 < / cve > <nl> - < cve > cve - 2018 - 14719 < / cve > <nl> - < cve > cve - 2018 - 14720 < / cve > <nl> - < cve > cve - 2018 - 14721 < / cve > <nl> - < cve > cve - 2018 - 19360 < / cve > <nl> - < cve > cve - 2018 - 19361 < / cve > <nl> - < cve > cve - 2018 - 19362 < / cve > <nl> - < cve > cve - 2019 - 14540 < / cve > <nl> - < cve > cve - 2019 - 16335 < / cve > <nl> - < cve > cve - 2019 - 16942 < / cve > <nl> - < cve > cve - 2019 - 16943 < / cve > <nl> - < cve > cve - 2019 - 17267 < / cve > <nl> - < cve > cve - 2019 - 17531 < / cve > <nl> - < cve > cve - 2019 - 20330 < / cve > <nl> - < cve > cve - 2020 - 8840 < / cve > <nl> + < packageurl regex = " true " > ^ pkg : maven / com \ . fasterxml \ . jackson \ . core / jackson \ - databind @ 2 . 4 . 0 $ < / packageurl > <nl> + < cve > cve - 2018 - 14721 < / cve > < ! - - cvss of num . 0 - - > <nl> + < cvssbelow > 10 < / cvssbelow > < ! - - suppress all cves for jackson - databind : 2 . 4 . 0 since it is via htrace - core4 - - > <nl> + < / suppress > <nl> + < suppress > <nl> + < ! - - <nl> + ~ <nl> + - - > <nl> + < notes > < ! [ cdata [ <nl> + file name : parquet - jackson - 1 . 11 . 0 . jar ( shaded : com . fasterxml . jackson . core : jackson - databind : 2 . 9 . 10 ) <nl> + ] ] > < / notes > <nl> + < packageurl regex = " true " > ^ pkg : maven / com \ . fasterxml \ . jackson \ . core / jackson \ - databind @ 2 . 9 . 10 $ < / packageurl > <nl> + < cvssbelow > 10 < / cvssbelow > < ! - - suppress all cves for jackson - databind : 2 . 9 . 0 since it is via parquet transitive dependencies - - > <nl> < / suppress > <nl> < / suppressions >
public class protobufinputrowparser implements bytebufferinputrowparser <nl> @ override <nl> public inputrow parse ( bytebuffer input ) <nl> { <nl> - <nl> + <nl> map < string , object > themap = buildstringkeymap ( input ) ; <nl>  <nl> return inputrowcreator . parse ( themap ) ;
public class rabbitmqfirehosefactory implements firehosefactory { <nl>  <nl> @ override <nl> public boolean hasmore ( ) { <nl> + delivery = null ; <nl> try { <nl> delivery = consumer . nextdelivery ( ) ; <nl> lastdeliverytag = delivery . getenvelope ( ) . getdeliverytag ( ) ; <nl>  <nl> log . debug ( " got new message " ) ; <nl> } catch ( interruptedexception e ) { <nl> + <nl> + / / as if there are no more messages ( return false ) ? <nl> log . wtf ( e , " don ' t know if this is supposed to ever happen . " ) ; <nl> - return false ; <nl> } <nl>  <nl> if ( delivery ! = null ) { <nl> + / / if delivery is non - null , we report that there is something more to process . <nl> return true ; <nl> } <nl>  <nl> - / / shouldn ' t ever get here but in case we ' ll assume there is no more stuff . <nl> - log . wtf ( " we shouldn ' t be here ! " ) ; <nl> + / / this means that delivery is null so we have nothing more to process . <nl> return false ; <nl> } <nl>  <nl> @ override <nl> public inputrow nextrow ( ) { <nl> - log . debug ( " consuming new message " ) ; <nl> + if ( delivery = = null ) { <nl> + / / just making sure . <nl> + log . wtf ( " i have nothing in delivery . method hasmore ( ) should have returned false . " ) ; <nl> + return null ; <nl> + } <nl>  <nl> return parser . parse ( new string ( delivery . getbody ( ) ) ) ; <nl> }
public class mastermain <nl>  <nl> final lifecycle lifecycle = injector . getinstance ( lifecycle . class ) ; <nl>  <nl> - final druidnodeconfig nodeconfig = injector . getinstance ( druidnodeconfig . class ) ; <nl> + final supplier < druidnodeconfig > nodeconfig = injector . getinstance ( key . get ( new typeliteral < supplier < druidnodeconfig > > ( ) { } ) ) ; <nl>  <nl> final serviceannouncer serviceannouncer = injector . getinstance ( serviceannouncer . class ) ; <nl>  <nl> try { <nl> - initialization . announcedefaultservice ( nodeconfig , serviceannouncer , lifecycle ) ; <nl> + <nl> + initialization . announcedefaultservice ( nodeconfig . get ( ) , serviceannouncer , lifecycle ) ; <nl> lifecycle . start ( ) ; <nl> } <nl> catch ( throwable t ) {
public class executormain <nl> system . exit ( 2 ) ; <nl> } <nl>  <nl> + / / spawn monitor thread to keep a watch on our parent process <nl> + / / if stdin reaches eof , the parent is gone , and we should shut down <nl> + final executorservice parentmonitorexec = executors . newsinglethreadexecutor ( <nl> + new threadfactorybuilder ( ) <nl> + . setnameformat ( " parent - monitor - % d " ) <nl> + . setdaemon ( true ) <nl> + . build ( ) <nl> + ) ; <nl> + <nl> + parentmonitorexec . submit ( <nl> + new runnable ( ) <nl> + { <nl> + @ override <nl> + public void run ( ) <nl> + { <nl> + int b = - 1 ; <nl> + try { <nl> + b = system . in . read ( ) ; <nl> + } catch ( exception e ) { <nl> + log . error ( e , " failed to read from stdin " ) ; <nl> + } <nl> + <nl> + <nl> + system . exit ( 2 ) ; <nl> + } <nl> + } <nl> + ) ; <nl> + <nl> try { <nl> final task task = node . getjsonmapper ( ) . readvalue ( new file ( args [ 0 ] ) , task . class ) ;
public class s3segmentkiller implements segmentkiller <nl> @ override <nl> public list < datasegment > kill ( final string datasource , final interval interval ) throws serviceexception <nl> { <nl> + <nl> + <nl> list < datasegment > matchingsegments = dbi . withhandle ( <nl> new handlecallback < list < datasegment > > ( ) <nl> {
druid . paths . segmentinfocache = / tmp / rand_realtime / segmentinfocache <nl> # path to schema definition file <nl> druid . request . logging . dir = / tmp / rand_realtime / log <nl>  <nl> + # <nl> + # unknown # druid . realtime . datasources = <nl> + # unknown # druid . realtime . index . maxsize = 500000 <nl> + # unknown # druid . realtime . persistperiod = pt600s <nl> + # unknown # druid . realtime . scheduledexec . threads = 1 <nl> + # unknown # druid . realtime . uploadperiod = pt3600s <nl> + # unknown # druid . realtime . windowperiod = pt600s <nl> + <nl> # druid . server . maxsize = 0 <nl> druid . server . maxsize = 300000000000 <nl> # = realtime or = historical ( default ) <nl>
public class androidinputimpl implements androidinput , onkeylistener , ontouchlis <nl> return true ; <nl> } <nl>  <nl> - / * * called in { @ link androidlivewallpaperservice } on tap <nl> - * @ param x <nl> - * @ param y * / <nl> - public void ontap ( int x , int y ) { <nl> - posttap ( x , y ) ; <nl> - } <nl> - <nl> - / * * called in { @ link androidlivewallpaperservice } on drop <nl> - * @ param x <nl> - * @ param y * / <nl> - public void ondrop ( int x , int y ) { <nl> - posttap ( x , y ) ; <nl> - } <nl> - <nl> - protected void posttap ( int x , int y ) { <nl> - synchronized ( this ) { <nl> - touchevent event = usedtouchevents . obtain ( ) ; <nl> - event . timestamp = system . nanotime ( ) ; <nl> - event . pointer = num ; <nl> - event . x = x ; <nl> - event . y = y ; <nl> - event . type = touchevent . touch_down ; <nl> - touchevents . add ( event ) ; <nl> - <nl> - event = usedtouchevents . obtain ( ) ; <nl> - event . timestamp = system . nanotime ( ) ; <nl> - event . pointer = num ; <nl> - event . x = x ; <nl> - event . y = y ; <nl> - event . type = touchevent . touch_up ; <nl> - touchevents . add ( event ) ; <nl> - } <nl> - gdx . app . getgraphics ( ) . requestrendering ( ) ; <nl> - } <nl> + <nl> + / / * @ param x <nl> + / / * @ param y * / <nl> + / / public void ontap ( int x , int y ) { <nl> + / / posttap ( x , y ) ; <nl> + / / } <nl> + / / <nl> + / / / * * called in { @ link androidlivewallpaperservice } on drop <nl> + / / * @ param x <nl> + / / * @ param y * / <nl> + / / public void ondrop ( int x , int y ) { <nl> + / / posttap ( x , y ) ; <nl> + / / } <nl> + / / <nl> + / / protected void posttap ( int x , int y ) { <nl> + / / synchronized ( this ) { <nl> + / / touchevent event = usedtouchevents . obtain ( ) ; <nl> + / / event . timestamp = system . nanotime ( ) ; <nl> + / / event . pointer = num ; <nl> + / / event . x = x ; <nl> + / / event . y = y ; <nl> + / / event . type = touchevent . touch_down ; <nl> + / / touchevents . add ( event ) ; <nl> + / / <nl> + / / event = usedtouchevents . obtain ( ) ; <nl> + / / event . timestamp = system . nanotime ( ) ; <nl> + / / event . pointer = num ; <nl> + / / event . x = x ; <nl> + / / event . y = y ; <nl> + / / event . type = touchevent . touch_up ; <nl> + / / touchevents . add ( event ) ; <nl> + / / } <nl> + / / gdx . app . getgraphics ( ) . requestrendering ( ) ; <nl> + / / } <nl>  <nl> @ override <nl> public boolean onkey ( view v , int keycode , android . view . keyevent e ) {
public class lwjgl3debugstarter { <nl>  <nl> @ override <nl> public void create ( ) { <nl> + new thread ( new runnable ( ) { <nl> + @ override <nl> + public void run ( ) { <nl> + while ( true ) { <nl> + try { <nl> + thread . sleep ( 1000 ) ; <nl> + } catch ( interruptedexception e ) { <nl> + <nl> + e . printstacktrace ( ) ; <nl> + } <nl> + } <nl> + } <nl> + } ) . start ( ) ; <nl> batch = new spritebatch ( ) ; <nl> font = new bitmapfont ( ) ; <nl> gdx . input . setinputprocessor ( new inputadapter ( ) { <nl>
public class paytest extends gdxtest { <nl>  <nl> / / throw error <nl> throw new gdxruntimeexception ( e ) ; <nl> - } <nl> + } <nl> + @ override <nl> + public void handlepurchase ( transaction transaction ) { <nl> + message ( " - purchased : " + transaction . getidentifier ( ) + " \n " ) ; <nl> + <nl> + / / dispose the purchase system <nl> + gdx . app . postrunnable ( new runnable ( ) { <nl> + @ override <nl> + public void run ( ) { <nl> + message ( " - disposing the purchase manager . \n " ) ; <nl> + purchasesystem . dispose ( ) ; <nl> + message ( " testing inapp system : completed\n " ) ; <nl> + } <nl> + } ) ; <nl> + } <nl> + @ override <nl> + public void handlepurchaseerror ( throwable e ) { <nl> + message ( " - error purchasing : " + e + " \n " ) ; <nl> + / / throw error <nl> + throw new gdxruntimeexception ( e ) ; <nl> + } <nl> + @ override <nl> + public void handlepurchasecanceled ( ) { <nl> + <nl> + <nl> + } <nl> } , config ) ; <nl>  <nl> / / restore purchases ! <nl>
public class polyline { <nl> this . y + = y ; <nl> dirty = true ; <nl> } <nl> + <nl> + @ override <nl> + public boundingbox getaabb ( ) { <nl> + rectangle rect ; <nl> + float xmin = num , ymin = num , xmax = num , ymax = num ; <nl> + for ( int i = 0 ; i < worldvertices . length ; i + = 2 ) <nl> + { <nl> + float x = worldvertices [ i ] , <nl> + y = worldvertices [ i + 1 ] ; <nl> + <nl> + if ( x > = xmax ) <nl> + xmax = x ; <nl> + else <nl> + xmin = x ; <nl> + <nl> + if ( y > = ymax ) <nl> + ymax = y ; <nl> + else <nl> + ymin = y ; <nl> + } <nl> + rect = new rectangle ( xmin , ymin , xmax - xmin , ymax - ymin ) ; <nl> + <nl> + return new boundingbox ( new vector3 ( rect . x , rect . y , 0 ) , new vector3 ( rect . x + rect . width , rect . y + rect . height , 0 ) ) ; <nl> + } <nl> + <nl> + @ override <nl> + public sphere getboundingsphere ( ) { <nl> + <nl> + return null ; <nl> + } <nl> + <nl> + @ override <nl> + public class getshapetype ( ) { <nl> + return polyline . class ; <nl> + } <nl> + <nl> + @ override <nl> + / / taken from http : / / paulbourke . net / geometry / polygonmesh / polygonutilities . java <nl> + public vector3 getcenter ( ) { <nl> + float cx = num , cy = num ; <nl> + polygon poly = new polygon ( worldvertices ) ; <nl> + float area = poly . area ( ) ; <nl> + <nl> + vector2 [ ] polypoints = new vector2 [ worldvertices . length / 2 ] ; <nl> + for ( int i = 0 ; i < worldvertices . length ; i + = 2 ) <nl> + polypoints [ i / 2 ] = new vector2 ( worldvertices [ i ] , worldvertices [ i + 1 ] ) ; <nl> + <nl> + int i , j , n = polypoints . length ; <nl> + <nl> + float factor = num ; <nl> + for ( i = num ; i < n ; i + + ) { <nl> + j = ( i + num ) % n ; <nl> + factor = ( polypoints [ i ] . x * polypoints [ j ] . y <nl> + - polypoints [ j ] . x * polypoints [ i ] . y ) ; <nl> + cx + = ( polypoints [ i ] . x + polypoints [ j ] . y ) * factor ; <nl> + cy + = ( polypoints [ i ] . x + polypoints [ j ] . y ) * factor ; <nl> + } <nl> + area * = num . 0f ; <nl> + factor = num / area ; <nl> + cx * = factor ; <nl> + cy * = factor ; <nl> + <nl> + return new vector3 ( cx , cy , num ) ; <nl> + } <nl> }
public class polygon { <nl> public float getscaley ( ) { <nl> return scaley ; <nl> } <nl> + <nl> + @ override <nl> + public boundingbox getaabb ( ) { <nl> + rectangle rect = this . getboundingrectangle ( ) ; <nl> + return new boundingbox ( new vector3 ( rect . x , rect . y , 0 ) , new vector3 ( rect . x + rect . width , rect . y + rect . height , 0 ) ) ; <nl> + } <nl> + <nl> + @ override <nl> + public sphere getboundingsphere ( ) { <nl> + <nl> + return null ; <nl> + } <nl> + <nl> + @ override <nl> + public class getshapetype ( ) { <nl> + return polygon . class ; <nl> + } <nl> + <nl> + @ override <nl> + / / taken from http : / / paulbourke . net / geometry / polygonmesh / polygonutilities . java <nl> + public vector3 getcenter ( ) { <nl> + float cx = num , cy = num ; <nl> + float area = area ( ) ; <nl> + <nl> + vector2 [ ] polypoints = new vector2 [ worldvertices . length / 2 ] ; <nl> + for ( int i = 0 ; i < worldvertices . length ; i + = 2 ) <nl> + polypoints [ i / 2 ] = new vector2 ( worldvertices [ i ] , worldvertices [ i + 1 ] ) ; <nl> + <nl> + int i , j , n = polypoints . length ; <nl> + <nl> + float factor = num ; <nl> + for ( i = num ; i < n ; i + + ) { <nl> + j = ( i + num ) % n ; <nl> + factor = ( polypoints [ i ] . x * polypoints [ j ] . y <nl> + - polypoints [ j ] . x * polypoints [ i ] . y ) ; <nl> + cx + = ( polypoints [ i ] . x + polypoints [ j ] . y ) * factor ; <nl> + cy + = ( polypoints [ i ] . x + polypoints [ j ] . y ) * factor ; <nl> + } <nl> + area * = num . 0f ; <nl> + factor = num / area ; <nl> + cx * = factor ; <nl> + cy * = factor ; <nl> + <nl> + return new vector3 ( cx , cy , num ) ; <nl> + } <nl> }
public final class androidgraphics implements graphics , renderer { <nl> pause = true ; <nl> while ( pause ) { <nl> try { <nl> - synch . wait ( ) ; <nl> + <nl> + / / android anr time is num seconds , so wait up to num seconds before assuming <nl> + / / deadlock and killing process . this can easily be triggered by openning the <nl> + / / recent apps list and then double - tapping the recent apps button with <nl> + / / ~ 500ms between taps . <nl> + synch . wait ( 4000 ) ; <nl> + if ( pause ) { <nl> + gdx . app . error ( " androidgraphics " , " waiting for pause synchronization took too " <nl> + + " long ; assuming deadlock and killing " ) ; <nl> + android . os . process . killprocess ( android . os . process . mypid ( ) ) ; <nl> + } <nl> } catch ( interruptedexception ignored ) { <nl> gdx . app . log ( " androidgraphics " , " waiting for pause synchronization failed ! " ) ; <nl> }
public final class earclippingtriangulator { <nl> / / the vertex is strictly inside the triangle if all three signs are the same . <nl> / / if it ' s on one or more edges , one or more of the signs will be num . <nl> / / so it ' s inside or on the edge if no two signs are opposite . <nl> + <nl> if ( ! ( ( areasign1 > num | | areasign2 > num | | areasign3 > num ) & & ( areasign1 < num | | areasign2 < num | | areasign3 < num ) ) ) { <nl> return false ; <nl> }
public final class earclippingtriangulator { <nl> this . concavevertexcount = num ; <nl>  <nl> / * ensure vertices are in clockwise order . * / <nl> + <nl> if ( ! areverticesclockwise ( pvertices ) ) { <nl> collections . reverse ( pvertices ) ; <nl> } <nl>
public final class earclippingtriangulator { <nl> return ( int ) math . signum ( area ) ; <nl> } <nl>  <nl> - / * * @ return < code > true < / code > when the triangles contains one or more vertices , < code > false < / code > otherwise . * / <nl> - private static boolean isanyvertexintriangle ( final arraylist < vector2 > pvertices , final int [ ] pvertextypes , final vector2 p1 , <nl> - final vector2 p2 , final vector2 p3 ) { <nl> - int i = num ; <nl> - <nl> - final int vertexcount = pvertices . size ( ) ; <nl> - while ( i < vertexcount - num ) { <nl> - if ( ( pvertextypes [ i ] = = concave ) ) { <nl> - final vector2 currentvertex = pvertices . get ( i ) ; <nl> - <nl> - final int areasign1 = earclippingtriangulator . computespannedareasign ( p1 , p2 , currentvertex ) ; <nl> - final int areasign2 = earclippingtriangulator . computespannedareasign ( p2 , p3 , currentvertex ) ; <nl> - final int areasign3 = earclippingtriangulator . computespannedareasign ( p3 , p1 , currentvertex ) ; <nl> - <nl> - if ( areasign1 > num & & areasign2 > num & & areasign3 > num ) { <nl> - return true ; <nl> - } else if ( areasign1 < = num & & areasign2 < = num & & areasign3 < = num ) { <nl> - return true ; <nl> - } <nl> - } <nl> - i + + ; <nl> - } <nl> - return false ; <nl> - } <nl> - <nl> private boolean iseartip ( final arraylist < vector2 > pvertices , final int peartipindex , final int [ ] pvertextypes ) { <nl> + <nl> if ( this . concavevertexcount ! = num ) { <nl> - final vector2 previousvertex = pvertices . get ( earclippingtriangulator . computepreviousindex ( pvertices , peartipindex ) ) ; <nl> - final vector2 currentvertex = pvertices . get ( peartipindex ) ; <nl> - final vector2 nextvertex = pvertices . get ( earclippingtriangulator . computenextindex ( pvertices , peartipindex ) ) ; <nl> - <nl> - if ( earclippingtriangulator . isanyvertexintriangle ( pvertices , pvertextypes , previousvertex , currentvertex , nextvertex ) ) { <nl> - return false ; <nl> - } else { <nl> - return true ; <nl> + final vector2 p1 = pvertices . get ( earclippingtriangulator . computepreviousindex ( pvertices , peartipindex ) ) ; <nl> + final vector2 p2 = pvertices . get ( peartipindex ) ; <nl> + final vector2 p3 = pvertices . get ( earclippingtriangulator . computenextindex ( pvertices , peartipindex ) ) ; <nl> + <nl> + final int vertexcount = pvertices . size ( ) ; <nl> + for ( int i = num ; i < vertexcount ; i + + ) { <nl> + if ( ( pvertextypes [ i ] = = concave ) ) { <nl> + final vector2 v = pvertices . get ( i ) ; <nl> + <nl> + final int areasign1 = earclippingtriangulator . computespannedareasign ( p1 , p2 , v ) ; <nl> + final int areasign2 = earclippingtriangulator . computespannedareasign ( p2 , p3 , v ) ; <nl> + final int areasign3 = earclippingtriangulator . computespannedareasign ( p3 , p1 , v ) ; <nl> + <nl> + if ( areasign1 > num & & areasign2 > num & & areasign3 > num ) { <nl> + return false ; <nl> + } else if ( areasign1 < = num & & areasign2 < = num & & areasign3 < = num ) { <nl> + return false ; <nl> + } <nl> + } <nl> + i + + ; <nl> } <nl> - } else { <nl> - return true ; <nl> } <nl> + return true ; <nl> } <nl>  <nl> private void cuteartip ( final arraylist < vector2 > pvertices , final int peartipindex , final arraylist < vector2 > ptriangles ) {
public class circularbuffer { <nl> static private void combine ( short [ ] src , int srcpos , short [ ] dest , int destpos , int length ) { <nl> for ( int i = num ; i < length ; i + + ) { <nl> int destindex = destpos + i ; <nl> - short a = src [ srcpos + i ] ; <nl> - short b = dest [ destindex ] ; <nl> - dest [ destindex ] = mathutils . clamp ( ( short ) ( a + b - a * b / short . max_value ) , ( short ) 0 , short . max_value ) ; <nl> - / / dest [ destindex ] = ( short ) ( a + b / num ) ; <nl> + int a = src [ srcpos + i ] ; <nl> + int b = dest [ destindex ] ; <nl> + <nl> + dest [ destindex ] = ( short ) ( 0 . 5f * ( a + b ) ) ; <nl> } <nl> }
<nl> + / * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * <nl> + * copyright num see authors file . <nl> + * <nl> + * licensed under the apache license , version num . 0 ( the " license " ) ; <nl> + * you may not use this file except in compliance with the license . <nl> + * you may obtain a copy of the license at <nl> + * <nl> + * http : / / www . apache . org / licenses / license - 2 . 0 <nl> + * <nl> + * unless required by applicable law or agreed to in writing , software <nl> + * distributed under the license is distributed on an " as is " basis , <nl> + * without warranties or conditions of any kind , either express or implied . <nl> + * see the license for the specific language governing permissions and <nl> + * limitations under the license . <nl> + * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * / <nl> + <nl> + package com . badlogic . gdx . math ; <nl> + <nl> + / * * encapsulates a general vector . allows chaining operations by returning a reference to itself in all modification methods . <nl> + * see { @ link vector2 } and { @ link vector3 } for specific implementations . <nl> + * @ author xoppa * / <nl> + public interface vector < t extends vector > { <nl> + / * * @ return a copy of this vector * / <nl> + t cpy ( ) ; <nl> + / * * @ return the euclidian length * / <nl> + float len ( ) ; <nl> + / * * @ return the squared euclidian length * / <nl> + float len2 ( ) ; <nl> + / * * sets this vector from the given vector <nl> + * @ param v the vector <nl> + * @ return this vector for chaining * / <nl> + t set ( t v ) ; <nl> + / * * substracts the given vector from this vector . <nl> + * @ param v the vector <nl> + * @ return this vector for chaining * / <nl> + t sub ( t v ) ; <nl> + / * * normalizes this vector <nl> + * @ return this vector for chaining * / <nl> + t nor ( ) ; <nl> + / * * adds the given vector to this vector <nl> + * @ param v the vector <nl> + * @ return this vector for chaining * / <nl> + t add ( t v ) ; <nl> + / * * @ param v the other vector <nl> + * @ return the dot product between this and the other vector * / <nl> + float dot ( t v ) ; <nl> + / * * multiplies this vector by a scalar <nl> + * @ param scalar the scalar <nl> + * @ return this vector for chaining * / <nl> + t mul ( float scalar ) ; <nl> + / * * multiplies this vector by another vector <nl> + * @ return this vector for chaining * / <nl> + t mul ( t v ) ; <nl> + t div ( float scalar ) ; <nl> + t div ( t v ) ; <nl> + / * * @ param v the other vector <nl> + * @ return the distance between this and the other vector * / <nl> + float dst ( t v ) ; <nl> + / * * @ param v the other vector <nl> + * @ return the squared distance between this and the other vector * / <nl> + float dst2 ( t v ) ; <nl> + / * * never ever save this reference ! do not use this unless you are aware of the side - effects , e . g . other methods might call this <nl> + * as well . <nl> + * <nl> + * @ return a temporary copy of this vector . use with care as this is backed by a single static vector instance . v1 . tmp ( ) . add ( <nl> + * v2 . tmp ( ) ) will not work ! * / <nl> + t tmp ( ) ; <nl> + / * * linearly interpolates between this vector and the target vector by alpha which is in the range [ 0 , 1 ] . the result is stored <nl> + * in this vector . <nl> + * <nl> + * @ param target the target vector <nl> + * @ param alpha the interpolation coefficient <nl> + * @ return this vector for chaining . * / <nl> + t lerp ( t target , float alpha ) ; <nl> + <nl> + <nl> + } <nl> mmm a / gdx / src / com / badlogic / gdx / math / vector2 . java <nl> ppp b / gdx / src / com / badlogic / gdx / math / vector2 . java <nl>
package com . badlogic . gdx . graphics . g3d . xoppa . materials ; <nl> import com . badlogic . gdx . graphics . color ; <nl> import com . badlogic . gdx . graphics . texture ; <nl>  <nl> - public interface newmaterial { <nl> - / * * returns a bitwise mask indicating the properties of this material * / <nl> - long getmask ( ) ; <nl> - <nl> - public static interface blendingmaterial extends newmaterial { <nl> - public final static long mask = num < < num ; <nl> - public final static string flag = " blendingflag " ; <nl> - <nl> - int getblendsourcefunction ( ) ; <nl> - int getblenddestfunction ( ) ; <nl> - } <nl> - <nl> - public static interface diffusecolormaterial extends newmaterial { <nl> - public final static long mask = num < < num ; <nl> - public final static string flag = " diffusecolorflag " ; <nl> - public final static string uniform = " diffusecolor " ; <nl> - <nl> - color getdiffusecolor ( ) ; <nl> - } <nl> - <nl> - public static interface specularcolormaterial extends newmaterial { <nl> - public final static long mask = num < < num ; <nl> - public final static string flag = " specularcolorflag " ; <nl> - public final static string uniform = " specularcolor " ; <nl> - <nl> - color getspecularcolor ( ) ; <nl> - } <nl> - <nl> - public static interface emmisivecolormaterial extends newmaterial { <nl> - public final static long mask = num < < num ; <nl> - public final static string flag = " emmisivecolorflag " ; <nl> - public final static string uniform = " emmisivecolor " ; <nl> - <nl> - color getemmisivecolor ( ) ; <nl> - } <nl> - <nl> - public static interface diffusetexturematerial extends newmaterial { <nl> - public final static long mask = num < < num ; <nl> - public final static string flag = " diffusetextureflag " ; <nl> - public final static string uniform = " diffusetexture " ; <nl> - <nl> - texture getdiffusetexture ( ) ; <nl> + public class newmaterial { <nl> + private static long currentid = num ; <nl> + protected final static long newmask ( ) { <nl> + return num l < < currentid + + ; <nl> + } <nl> + <nl> + public final static long blending = newmask ( ) ; <nl> + public final static long diffusecolor = newmask ( ) ; <nl> + public final static long specularcolor = newmask ( ) ; <nl> + public final static long emmisivecolor = newmask ( ) ; <nl> + public final static long diffusetexture = newmask ( ) ; <nl> + <nl> + protected long mask ; <nl> + <nl> + protected final void enable ( final long mask ) { <nl> + this . mask | = mask ; <nl> + } <nl> + protected final void disable ( final long mask ) { <nl> + this . mask & = - 1 ^ mask ; <nl> + } <nl> + protected final void toggle ( final long mask , boolean enabled ) { <nl> + if ( enabled ) enable ( mask ) ; <nl> + else disable ( mask ) ; <nl> + } <nl> + <nl> + public final long getmask ( ) { <nl> + return mask ; <nl> + } <nl> + / * * @ return true if this material has the specified property * / <nl> + public final boolean has ( final long mask ) { <nl> + return ( this . mask & mask ) = = mask ; <nl> + } <nl> + <nl> + / / blending <nl> + protected int blendsourcefunction ; <nl> + protected int blenddestfunction ; <nl> + public void setblending ( boolean enabled , int sfunc , int dfunc ) { <nl> + toggle ( blending , enabled ) ; <nl> + blendsourcefunction = sfunc ; <nl> + blenddestfunction = dfunc ; <nl> + } <nl> + / * * only applicable if this material { @ link # has ( long ) } { @ link # blending } * / <nl> + public final int getblendsourcefunction ( ) { <nl> + return blendsourcefunction ; <nl> + } <nl> + / * * only applicable if this material { @ link # has ( long ) } { @ link # blending } * / <nl> + public final int getblenddestfunction ( ) { <nl> + return blenddestfunction ; <nl> + } <nl> + <nl> + / / diffusecolor <nl> + protected color diffusecolor = null ; <nl> + public void setdiffusecolor ( color color ) { <nl> + if ( color ! = null ) { <nl> + enable ( diffusecolor ) ; <nl> + if ( diffusecolor = = null ) <nl> + diffusecolor = new color ( ) ; <nl> + diffusecolor . set ( color ) ; <nl> + } else <nl> + disable ( diffusecolor ) ; <nl> + } <nl> + / * * only applicable if this material { @ link # has ( long ) } { @ link # diffusecolor } * / <nl> + public final color getdiffusecolor ( ) { <nl> + return diffusecolor ; <nl> + } <nl> + <nl> + / / diffusetexture <nl> + <nl> + protected texture diffusetexture = null ; <nl> + public void setdiffusetexture ( texture texture ) { <nl> + toggle ( diffusetexture , texture ! = null ) ; <nl> + diffusetexture = texture ; <nl> + } <nl> + / * * only applicable if this material { @ link # has ( long ) } { @ link # diffusetexture } * / <nl> + public final texture getdiffusetexture ( ) { <nl> + return diffusetexture ; <nl> } <nl>  <nl> / / etc . . .
enable_pooled_typemap ( bttransform , matrix4 , " lcom / badlogic / gdx / math / matrix4 ; " ) ; <nl> # include < bulletsoftbody / btsoftsoftcollisionalgorithm . h > <nl> % } <nl> % include " bulletsoftbody / btsoftsoftcollisionalgorithm . h " <nl> - * / <nl> \ no newline at end of file <nl> + <nl> + <nl> + / * disabled stuff below here ( <nl> + <nl> + / * <nl> + * btserializer needs some typemap customization for sbulletdnastr and friends . <nl> + * swig doesn ' t know how to pass the unsized arrays back . <nl> + * / <nl> + / * <nl> + % { <nl> + # include < linearmath / btserializer . h > <nl> + % } <nl> + % include " linearmath / btserializer . h " <nl> + * / <nl> + <nl> + / * <nl> + * btwheelinfo doesn ' t compile because it doesnt have a num - arg constructor for <nl> + * btalignedobjectarray to call , so i disabled the vehicle stuff . <nl> + * / <nl> + <nl> + % { <nl> + # include < bulletdynamics / vehicle / btvehicleraycaster . h > <nl> + % } <nl> + % include " bulletdynamics / vehicle / btvehicleraycaster . h " <nl> + <nl> + % { <nl> + # include < bulletdynamics / vehicle / btwheelinfo . h > <nl> + % } <nl> + % include " bulletdynamics / vehicle / btwheelinfo . h " <nl> + <nl> + / * has nested classes or structs * / <nl> + % include " custom / btraycastvehicle . i " <nl> + <nl> + <nl> + / * <nl> + * because c + + templates are compile - time , we must pre - define all the <nl> + * template classes to generate in java . this is at the bottom <nl> + * so we can reference all the other types . <nl> + * / <nl> + <nl> + % template ( btcollisionobjectarray ) btalignedobjectarray < btcollisionobject * > ; <nl> + <nl> + / * <nl> + * include dummy methods for ones bullet declares but doesn ' t <nl> + * implement . at the bottom so we can reference other types . <nl> + * / <nl> + % include " gdxmissingbulletmethods . i " <nl> \ no newline at end of file
swig_javabody_typewrapper ( protected , protected , public , swigtype ) <nl> % } <nl> % include " bulletdynamics / constraintsolver / bthinge2constraint . h " <nl>  <nl> - / * experimental code ( not suitable for android ) <nl> + / * disabled stuff below here ( <nl> + <nl> + / * <nl> + * btserializer needs some typemap customization for sbulletdnastr and friends . <nl> + * swig doesn ' t know how to pass the unsized arrays back . <nl> + * / <nl> + / * <nl> + % { <nl> + # include < linearmath / btserializer . h > <nl> + % } <nl> + % include " linearmath / btserializer . h " <nl> + * / <nl> + <nl> + / * <nl> + * btwheelinfo doesn ' t compile because it doesnt have a num - arg constructor for <nl> + * btalignedobjectarray to call , so i disabled the vehicle stuff . <nl> + * / <nl> + <nl> + % { <nl> + # include < bulletdynamics / vehicle / btvehicleraycaster . h > <nl> + % } <nl> + % include " bulletdynamics / vehicle / btvehicleraycaster . h " <nl> + <nl> + % { <nl> + # include < bulletdynamics / vehicle / btwheelinfo . h > <nl> + % } <nl> + % include " bulletdynamics / vehicle / btwheelinfo . h " <nl> + <nl> + / * has nested classes or structs * / <nl> + % include " custom / btraycastvehicle . i " <nl> + <nl> + <nl> + / * <nl> + * because c + + templates are compile - time , we must pre - define all the <nl> + * template classes to generate in java . this is at the bottom <nl> + * so we can reference all the other types . <nl> + * / <nl> + <nl> + % template ( btcollisionobjectarray ) btalignedobjectarray < btcollisionobject * > ; <nl> + <nl> + / * <nl> + * include dummy methods for ones bullet declares but doesn ' t <nl> + * implement . at the bottom so we can reference other types . <nl> + * / <nl> + % include " gdxmissingbulletmethods . i " <nl> + <nl> + / * softbody code ( not suitable for android ) <nl> % { <nl> # include < bulletsoftbody / btsoftbodysolvers . h > <nl> % } <nl>
public class openalsound implements sound { <nl> public float duration ( ) { <nl> return duration ; <nl> } <nl> + <nl> + @ override <nl> + public void setpriority ( long soundid , int priority ) { <nl> + <nl> + } <nl> } <nl> mmm a / gdx / src / com / badlogic / gdx / audio / sound . java <nl> ppp b / gdx / src / com / badlogic / gdx / audio / sound . java <nl>
public class joglinput implements input , mousemotionlistener , mouselistener , mou <nl> public long getcurrenteventtime ( ) { <nl> return currenteventtimestamp ; <nl> } <nl> + <nl> + @ override <nl> + public void getrotationmatrix ( float [ ] matrix ) { <nl> + <nl> + <nl> + } <nl> } <nl> mmm a / backends / gdx - backend - lwjgl / src / com / badlogic / gdx / backends / lwjgl / lwjglinput . java <nl> ppp b / backends / gdx - backend - lwjgl / src / com / badlogic / gdx / backends / lwjgl / lwjglinput . java <nl>
final class lwjglinput implements input { <nl> public long getcurrenteventtime ( ) { <nl> return currenteventtimestamp ; <nl> } <nl> + <nl> + @ override <nl> + public void getrotationmatrix ( float [ ] matrix ) { <nl> + <nl> + <nl> + } <nl> } <nl> mmm a / gdx / src / com / badlogic / gdx / input . java <nl> ppp b / gdx / src / com / badlogic / gdx / input . java <nl>
public class joglinput implements input , mousemotionlistener , mouselistener , mou <nl> robot . mousemove ( canvas . getlocationonscreen ( ) . x + x , canvas . getlocationonscreen ( ) . y + y ) ; <nl> } <nl> } <nl> + <nl> + @ override <nl> + public void setcatchmenukey ( boolean catchmenu ) { <nl> + <nl> + <nl> + } <nl> } <nl> mmm a / backends / gdx - backend - lwjgl / src / com / badlogic / gdx / backends / lwjgl / lwjglinput . java <nl> ppp b / backends / gdx - backend - lwjgl / src / com / badlogic / gdx / backends / lwjgl / lwjglinput . java <nl>
final class lwjglinput implements input { <nl> @ override public void setcursorposition ( int x , int y ) { <nl> mouse . setcursorposition ( x , y ) ; <nl> } <nl> + <nl> + @ override <nl> + public void setcatchmenukey ( boolean catchmenu ) { <nl> + <nl> + <nl> + } <nl> } <nl> mmm a / backends / gdx - backends - angle / src / com / badlogic / gdx / backends / angle / angleinput . java <nl> ppp b / backends / gdx - backends - angle / src / com / badlogic / gdx / backends / angle / angleinput . java <nl>
public class remoteinput implements runnable , input { <nl>  <nl> @ override public void setcursorposition ( int x , int y ) { <nl> } <nl> + <nl> + @ override <nl> + public void setcatchmenukey ( boolean catchmenu ) { <nl> + <nl> + <nl> + } <nl> }
<nl> + package com . badlogic . gdx . tests ; <nl> + <nl> + import com . badlogic . gdx . gdx ; <nl> + import com . badlogic . gdx . graphics . gl10 ; <nl> + import com . badlogic . gdx . graphics . mesh ; <nl> + import com . badlogic . gdx . graphics . vertexattribute ; <nl> + import com . badlogic . gdx . graphics . vertexattributes . usage ; <nl> + import com . badlogic . gdx . tests . utils . gdxtest ; <nl> + <nl> + public class myfirsttriangle extends gdxtest { <nl> + private mesh mesh ; <nl> + <nl> + @ override <nl> + public void create ( ) { <nl> + if ( mesh = = null ) { <nl> + mesh = new mesh ( true , num , num , <nl> + new vertexattribute ( usage . position , num , " a_position " ) ) ; <nl> + <nl> + mesh . setvertices ( new float [ ] { - 0 . 5f , - 0 . 5f , num , <nl> + num . 5f , - 0 . 5f , num , <nl> + num , num . 5f , num } ) ; <nl> + mesh . setindices ( new short [ ] { num , num , num } ) ; <nl> + } <nl> + } <nl> + <nl> + @ override <nl> + public void dispose ( ) { } <nl> + <nl> + @ override <nl> + public void pause ( ) { } <nl> + <nl> + @ override <nl> + public void render ( ) { <nl> + gdx . gl10 . glclear ( gl10 . gl_color_buffer_bit ) ; <nl> + mesh . render ( gl10 . gl_triangles , num , num ) ; <nl> + } <nl> + <nl> + @ override <nl> + public void resize ( int width , int height ) { } <nl> + <nl> + @ override <nl> + public void resume ( ) { } <nl> + <nl> + @ override <nl> + public boolean needsgl20 ( ) { <nl> + <nl> + return false ; <nl> + } <nl> + } <nl> \ no newline at end of file <nl> mmm a / tests / gdx - tests / src / com / badlogic / gdx / tests / utils / gdxtests . java <nl> ppp b / tests / gdx - tests / src / com / badlogic / gdx / tests / utils / gdxtests . java <nl>
<nl> + package com . badlogic . gdx . tests ; <nl> + <nl> + import com . badlogic . gdx . gdx ; <nl> + import com . badlogic . gdx . renderlistener ; <nl> + import com . badlogic . gdx . graphics . gl10 ; <nl> + import com . badlogic . gdx . graphics . mesh ; <nl> + import com . badlogic . gdx . graphics . pixmap ; <nl> + import com . badlogic . gdx . graphics . texture ; <nl> + import com . badlogic . gdx . graphics . vertexattribute ; <nl> + import com . badlogic . gdx . graphics . vertexattributes ; <nl> + import com . badlogic . gdx . graphics . pixmap . format ; <nl> + import com . badlogic . gdx . graphics . texture . texturefilter ; <nl> + import com . badlogic . gdx . graphics . texture . texturewrap ; <nl> + <nl> + public class meshmultitexturetest implements renderlistener <nl> + { <nl> + texture tex1 ; <nl> + texture tex2 ; <nl> + mesh mesh ; <nl> + <nl> + @ override <nl> + public void dispose ( ) { <nl> + <nl> + <nl> + } <nl> + <nl> + @ override <nl> + public void render ( ) <nl> + { <nl> + gl10 gl = gdx . graphics . getgl10 ( ) ; <nl> + gl . glenable ( gl10 . gl_texture_2d ) ; <nl> + gl . glactivetexture ( gl10 . gl_texture0 ) ; <nl> + tex1 . bind ( ) ; <nl> + gl . glactivetexture ( gl10 . gl_texture1 ) ; <nl> + tex2 . bind ( ) ; <nl> + mesh . render ( gl10 . gl_triangles ) ; <nl> + } <nl> + <nl> + @ override <nl> + public void surfacechanged ( int width , int height ) <nl> + { <nl> + <nl> + } <nl> + <nl> + @ override <nl> + public void surfacecreated ( ) <nl> + { <nl> + pixmap pixmap = gdx . graphics . newpixmap ( 256 , num , format . rgba8888 ) ; <nl> + pixmap . setcolor ( 1 , num , num , num ) ; <nl> + pixmap . fill ( ) ; <nl> + pixmap . setcolor ( 0 , num , num , num ) ; <nl> + pixmap . drawline ( 0 , num , num , num ) ; <nl> + pixmap . drawline ( 256 , num , num , num ) ; <nl> + tex1 = gdx . graphics . newunmanagedtexture ( pixmap , texturefilter . linear , texturefilter . linear , texturewrap . clamptoedge , texturewrap . clamptoedge ) ; <nl> + <nl> + pixmap = gdx . graphics . newpixmap ( num , num , format . rgba8888 ) ; <nl> + pixmap . setcolor ( num , num , num , num ) ; <nl> + pixmap . fill ( ) ; <nl> + pixmap . setcolor ( num , num , num , num ) ; <nl> + pixmap . drawline ( num , num , num , num ) ; <nl> + tex2 = gdx . graphics . newunmanagedtexture ( pixmap , texturefilter . linear , texturefilter . linear , texturewrap . clamptoedge , texturewrap . clamptoedge ) ; <nl> + <nl> + mesh = new mesh ( true , false , num , num , new vertexattribute ( vertexattributes . usage . color , num , " a_color " ) , <nl> + new vertexattribute ( vertexattributes . usage . texturecoordinates , num , " a_texcoords1 " ) , <nl> + new vertexattribute ( vertexattributes . usage . texturecoordinates , num , " a_texcoords2 " ) , <nl> + new vertexattribute ( vertexattributes . usage . position , num , " a_position " ) ) ; <nl> + <nl> + mesh . setvertices ( new float [ ] { <nl> + num , num , num , num , <nl> + num , num , <nl> + num , num , <nl> + - 0 . 5f , - 0 . 5f , num , <nl> + <nl> + num , num , num , num , <nl> + num , num , <nl> + num , num , <nl> + num . 5f , - 0 . 5f , num , <nl> + <nl> + num , num , num , num , <nl> + num . 5f , num , <nl> + num . 5f , num , <nl> + num , num . 5f , num , <nl> + } ) ; <nl> + } <nl> + <nl> + }
public class matrix3 <nl> " [ " + vals [ 2 ] + " | " + vals [ 5 ] + " | " + vals [ 8 ] + " ] " ; <nl> } <nl>  <nl> + / * * <nl> + * @ return the determinant of this matrix <nl> + * / <nl> + public float det ( ) <nl> + { <nl> + return vals [ 0 ] * vals [ 4 ] * vals [ 8 ] + <nl> + vals [ 3 ] * vals [ 7 ] * vals [ 2 ] + <nl> + vals [ 6 ] * vals [ 1 ] * vals [ 5 ] - <nl> + vals [ 0 ] * vals [ 7 ] * vals [ 5 ] - <nl> + vals [ 3 ] * vals [ 1 ] * vals [ 8 ] - <nl> + vals [ 6 ] * vals [ 4 ] * vals [ 2 ] ; <nl> + } <nl> + <nl> + / * * <nl> + * inverts this matrix given that the determinant is ! = num <nl> + * @ return this matrix <nl> + * / <nl> + public matrix3 inv ( ) <nl> + { <nl> + float det = det ( ) ; <nl> + if ( det = = num ) <nl> + throw new gdxruntimeexception ( " can ' t invert a singular matrix " ) ; <nl> + <nl> + <nl> + <nl> + return this ; <nl> + } <nl> + <nl> public static void main ( string [ ] argv ) <nl> { <nl> float refx = num , refy = - 50 ; <nl>
public class soundtest implements renderlistener , inputlistener <nl> @ override <nl> public void render ( application app ) <nl> { <nl> - <nl> + try { <nl> + thread . sleep ( num ) ; <nl> + } catch ( interruptedexception e ) { <nl> + <nl> + e . printstacktrace ( ) ; <nl> + } <nl> } <nl>  <nl> @ override
<nl> + package com . badlogic . gdx . samples ; <nl> + <nl> + import com . badlogic . gdx . application ; <nl> + import com . badlogic . gdx . mesh ; <nl> + import com . badlogic . gdx . perspectivecamera ; <nl> + import com . badlogic . gdx . renderlistener ; <nl> + import com . badlogic . gdx . mesh . primitivetype ; <nl> + <nl> + public class accelerometertest implements renderlistener <nl> + { <nl> + mesh mesh ; <nl> + perspectivecamera camera ; <nl> + <nl> + @ override <nl> + public void setup ( application application ) <nl> + { <nl> + camera = new perspectivecamera ( ) ; <nl> + camera . getposition ( ) . set ( num , num , num ) ; <nl> + camera . setfov ( num ) ; <nl> + <nl> + mesh = application . newmesh ( num , false , false , false , false , num , true ) ; <nl> + mesh . vertex ( - 0 . 5f , - 0 . 5f , num ) ; <nl> + mesh . vertex ( num . 5f , - 0 . 5f , num ) ; <nl> + mesh . vertex ( num , num . 5f , num ) ; <nl> + } <nl> + <nl> + @ override <nl> + public void render ( application application ) <nl> + { <nl> + application . clear ( true , false , false ) ; <nl> + camera . setmatrices ( application ) ; <nl> + application . rotate ( num * application . getaccelerometery ( ) / num , num , num , num ) ; <nl> + <nl> + mesh . render ( primitivetype . triangles ) ; <nl> + <nl> + } <nl> + <nl> + @ override <nl> + public void dispose ( application application ) { <nl> + <nl> + <nl> + } <nl> + }
public class contextchain implements parcelable { <nl>  <nl> private @ nullable string mserializedstring ; <nl>  <nl> + @ deprecated <nl> public static void setusedeepequals ( boolean usedeepequals ) { <nl> - susedeepequals = usedeepequals ; <nl> + <nl> } <nl>  <nl> public contextchain ( <nl>
<nl> + / * <nl> + * copyright ( c ) facebook , inc . and its affiliates . <nl> + * <nl> + * this source code is licensed under the mit license found in the <nl> + * license file in the root directory of this source tree . <nl> + * / <nl> + <nl> + package com . facebook . fresco . vito . draweesupport ; <nl> + <nl> + import androidx . annotation . nullable ; <nl> + import com . facebook . drawee . generic . roundingparams ; <nl> + import com . facebook . fresco . vito . options . borderoptions ; <nl> + import com . facebook . fresco . vito . options . roundingoptions ; <nl> + import com . facebook . infer . annotation . nullsafe ; <nl> + <nl> + @ nullsafe ( nullsafe . mode . local ) <nl> + public class roundingparamswrapper { <nl> + <nl> + @ nullable <nl> + public static roundingoptions roundingoptionsfromroundingparams ( <nl> + @ nullable roundingparams roundingparams ) { <nl> + if ( roundingparams = = null ) { <nl> + return null ; <nl> + } <nl> + if ( roundingparams . getroundascircle ( ) ) { <nl> + return roundingoptions . ascircle ( true ) ; <nl> + } <nl> + if ( roundingparams . getcornersradii ( ) ! = null ) { <nl> + return roundingoptions . forcornerradii ( roundingparams . getcornersradii ( ) , true ) ; <nl> + } <nl> + <nl> + return null ; / / probably only used for borders <nl> + } <nl> + <nl> + @ nullable <nl> + public static borderoptions borderoptionsfromroundingparams ( <nl> + @ nullable roundingparams roundingparams ) { <nl> + if ( roundingparams = = null | | roundingparams . getborderwidth ( ) < = num f ) { <nl> + return null ; <nl> + } <nl> + return borderoptions . create ( <nl> + roundingparams . getbordercolor ( ) , <nl> + roundingparams . getborderwidth ( ) , <nl> + roundingparams . getpadding ( ) , <nl> + roundingparams . getscaledowninsideborders ( ) ) ; <nl> + } <nl> + }
public abstract class abstractadaptivecountingmemorycache < k , v > <nl> return clientref ; <nl> } <nl>  <nl> + @ override <nl> + public @ nullable v inspect ( k key ) { <nl> + return null ; <nl> + } <nl> + <nl> / * * <nl> * probes whether the object corresponding to the key is in the cache . note that the act of <nl> * probing touches the item ( if present in cache ) , thus changing its lru timestamp . <nl> mmm a / imagepipeline - base / src / main / java / com / facebook / imagepipeline / cache / lrucountingmemorycache . java <nl> ppp b / imagepipeline - base / src / main / java / com / facebook / imagepipeline / cache / lrucountingmemorycache . java <nl>
public class frescocontrollerimpl implements frescocontroller { <nl> } <nl> } <nl> } <nl> + <nl> + private void setuprequestlistener ( frescostate frescostate , imagerequest imagerequest ) { <nl> + <nl> + if ( imagerequest = = null ) { <nl> + return ; <nl> + } <nl> + final requestlistener requestlistener = <nl> + mfrescocontext <nl> + . getimagepipeline ( ) <nl> + . getrequestlistenerforrequest ( imagerequest , frescostate . getimageoriginlistener ( ) ) ; <nl> + frescostate . setrequestlistener ( requestlistener ) ; <nl> + } <nl> }
public class showcaseruntest { <nl> } <nl>  <nl> @ test <nl> + @ ignore / * <nl> public void testshowimage ( ) { <nl> openscreenfrommenu ( r . string . drawee_simple_title ) ; <nl> onview ( withid ( r . id . drawee_view ) ) . perform ( waitfor ( 5000 ) ) ;
public class draweeholder < dh extends draweehierarchy > implements visibilitycallb <nl> private boolean misvisible = true ; <nl> private boolean misactivitystarted = true ; <nl> private dh mhierarchy ; <nl> + <nl> + <nl> private draweecontroller mcontroller = null ; <nl> - private final activitylistener mactivitylistener ; <nl> + <nl> private final draweeeventtracker meventtracker = new draweeeventtracker ( ) ; <nl>  <nl> / * * <nl>
public class draweeholder < dh extends draweehierarchy > implements visibilitycallb <nl> if ( hierarchy ! = null ) { <nl> sethierarchy ( hierarchy ) ; <nl> } <nl> + / * <nl> + <nl> mactivitylistener = new baseactivitylistener ( ) { <nl> @ override <nl> public void onstart ( activity activity ) { <nl>
public class resizeandrotateproducer <nl> getscalenumerator ( request , metadata ) ! = jpegtranscoder . scale_denominator ) ; <nl> } <nl>  <nl> + @ visiblefortesting static float determineresizeratio ( <nl> + resizeoptions resizeoptions , <nl> + int width , <nl> + int height ) { <nl> + final float widthratio = ( ( float ) resizeoptions . width ) / width ; <nl> + final float heightratio = ( ( float ) resizeoptions . height ) / height ; <nl> + float ratio = math . max ( widthratio , heightratio ) ; <nl> + <nl> + <nl> + if ( width * ratio > max_bitmap_size ) { <nl> + ratio = max_bitmap_size / width ; <nl> + } <nl> + if ( height * ratio > max_bitmap_size ) { <nl> + ratio = max_bitmap_size / height ; <nl> + } <nl> + return ratio ; <nl> + } <nl> + <nl> @ visiblefortesting static int roundnumerator ( float maxratio ) { <nl> return ( int ) ( 0 . 75f + maxratio * jpegtranscoder . scale_denominator ) ; <nl> } <nl>
import org . thingsboard . server . common . data . id . tenantid ; <nl> import org . thingsboard . server . common . data . id . userid ; <nl>  <nl> public class entitiestenantidasyncloader { <nl> - <nl> + <nl> public static listenablefuture < tenantid > findentityidasync ( tbcontext ctx , entityid original ) { <nl>  <nl> switch ( original . getentitytype ( ) ) {
public abstract class redistbtransactionalcache < k extends serializable , v extend <nl> return new redistbcachetransaction < > ( this , connection ) ; <nl> } <nl>  <nl> + redisconnection getconnection ( byte [ ] rawkey ) { <nl> + redisconnection connection = connectionfactory . getclusterconnection ( ) ; <nl> + if ( ! ( connection instanceof jedisclusterconnection ) ) { <nl> + return connection ; <nl> + } <nl> + <nl> + int slotnum = jedisclustercrc16 . getslot ( rawkey ) ; <nl> + jedis jedis = ( ( jedisclusterconnection ) connection ) . getnativeconnection ( ) . getconnectionfromslot ( slotnum ) ; <nl> + <nl> + jedisconnection jedisconnection = new jedisconnection ( jedis , mock_pool , jedis . getdb ( ) ) ; <nl> + jedisconnection . setconvertpipelineandtxresults ( connectionfactory . getconvertpipelineandtxresults ( ) ) ; <nl> + <nl> + return jedisconnection ; <nl> + } <nl> + <nl> private redisconnection watch ( byte [ ] [ ] rawkeyslist ) { <nl> - var connection = connectionfactory . getconnection ( ) ; <nl> + <nl> + redisconnection connection = getconnection ( rawkeyslist [ 0 ] ) ; <nl> try { <nl> connection . watch ( rawkeyslist ) ; <nl> connection . multi ( ) ;
public class defaulttbtenantservice implements tbtenantservice { <nl>  <nl> tenantprofile oldtenantprofile = oldtenant ! = null ? tenantprofileservice . findtenantprofilebyid ( tenantid . sys_tenant_id , oldtenant . gettenantprofileid ( ) ) : null ; <nl> tenantprofile newtenantprofile = tenantprofileservice . findtenantprofilebyid ( tenantid . sys_tenant_id , savedtenant . gettenantprofileid ( ) ) ; <nl> + <nl> tbqueueservice . updatequeuesbytenants ( collections . singletonlist ( savedtenant . gettenantid ( ) ) , newtenantprofile , oldtenantprofile ) ; <nl> return savedtenant ; <nl> } <nl> mmm a / common / queue / src / main / java / org / thingsboard / server / queue / discovery / hashpartitionservice . java <nl> ppp b / common / queue / src / main / java / org / thingsboard / server / queue / discovery / hashpartitionservice . java <nl>
public class hashpartitionservice implements partitionservice { <nl> mypartitions . remove ( queuekey ) ; <nl> partitiontopicsmap . remove ( queuekey ) ; <nl> partitionsizesmap . remove ( queuekey ) ; <nl> + <nl> + removetenant ( tenantid ) ; <nl> } <nl>  <nl> @ override <nl>
abstract public class baseedgetest extends abstractcontrollertest { <nl>  <nl> testrpccall ( ) ; <nl>  <nl> - testtimeserieswithfailures ( ) ; <nl> + <nl> + / / 2021 - 12 - 13 num : 59 : 52 , 501 [ grpc - default - executor - 1 ] warn o . t . edge . rpc . edgegrpcclient - we had reached maximum of termination attempts . force closing channel <nl> + / / java . lang . assertionerror < 3 internal lines > <nl> + / / at org . thingsboard . server . edge . baseedgetest . testtimeserieswithfailures ( baseedgetest . java : 1146 ) <nl> + / / at org . thingsboard . server . edge . baseedgetest . test ( baseedgetest . java : 220 ) <nl> + / / <nl> + / / testtimeserieswithfailures ( ) ; <nl>  <nl> testsendmessagestocloud ( ) ; <nl> }
arator_path ) [ 2 ] ) ; <nl> - } <nl> + sendrequeststoclient ( lwm2mclient , typeoper , clientobjects , result , params ) ; <nl> + } <nl> + <nl> + private void sendrequeststoclient ( lwm2mclient lwm2mclient , lwm2mtypeoper operationtype , set < string > supportedobjectids , set < string > desiredobjectids , concurrenthashmap < string , object > params ) { <nl> + if ( desiredobjectids ! = null & & ! desiredobjectids . isempty ( ) ) { <nl> + set < string > targetobjectids = desiredobjectids . stream ( ) . filter ( target - > issupportedtargetid ( supportedobjectids , target ) <nl> ) . collect ( collectors . tounmodifiableset ( ) ) ; <nl> - if ( ! pathsend . isempty ( ) ) { <nl> - lwm2mclient . getpendingreadrequests ( ) . addall ( pathsend ) ; <nl> - concurrenthashmap < string , object > finalparams = params ; <nl> - pathsend . foreach ( target - > { <nl> - lwm2mtransportrequest . sendallrequest ( lwm2mclient , target , typeoper , <nl> - finalparams ! = null ? finalparams . get ( target ) : null , this . config . gettimeout ( ) , null ) ; <nl> + if ( ! targetobjectids . isempty ( ) ) { <nl> + <nl> + lwm2mclient . getpendingreadrequests ( ) . addall ( targetobjectids ) ; <nl> + targetobjectids . foreach ( target - > { <nl> + object additionalparams = params ! = null ? params . get ( target ) : null ; <nl> + lwm2mtransportrequest . sendallrequest ( lwm2mclient , target , operationtype , additionalparams , this . config . gettimeout ( ) , null ) ; <nl> } ) ; <nl> - if ( observe . equals ( typeoper ) ) { <nl> + if ( observe . equals ( operationtype ) ) { <nl> lwm2mclient . initreadvalue ( this , null ) ; <nl> } <nl> } <nl> } <nl> } <nl>  <nl> + private boolean issupportedtargetid ( set < string > supportedids , string targetid ) { <nl> + string [ ] targetidparts = targetid . split ( lwm2m_
public class tblwm2mredisregistrationstore implements californiumregistrationsto <nl> } <nl> } <nl>  <nl> + <nl> private void removeaddrindex ( redisconnection connection , registration registration ) { <nl> / / watch the key to remove . <nl> byte [ ] regaddrkey = toregaddrkey ( registration . getsocketaddress ( ) ) ; <nl> - connection . watch ( regaddrkey ) ; <nl> + / / connection . watch ( regaddrkey ) ; <nl>  <nl> byte [ ] epfromaddr = connection . get ( regaddrkey ) ; <nl> / / delete the key if needed . <nl> if ( arrays . equals ( epfromaddr , registration . getendpoint ( ) . getbytes ( utf_8 ) ) ) { <nl> / / try to delete the key <nl> - connection . multi ( ) ; <nl> + / / connection . multi ( ) ; <nl> connection . del ( regaddrkey ) ; <nl> - connection . exec ( ) ; <nl> + / / connection . exec ( ) ; <nl> / / if transaction failed this is not an issue as the socket address is probably reused and we don ' t neeed to <nl> / / delete it anymore . <nl> } else { <nl> / / the key must not be deleted . <nl> - connection . unwatch ( ) ; <nl> + / / connection . unwatch ( ) ; <nl> } <nl> }
jsinvokemessageprocessor . prototype . sendresponse = function ( requestid , responset <nl> var tstartsending = performance . now ( ) ; <nl> var remoteresponse = createremoteresponse ( requestid , compileresponse , invokeresponse , releaseresponse ) ; <nl> var rawresponse = buffer . from ( json . stringify ( remoteresponse ) , ' utf8 ' ) ; <nl> - this . producer . send ( responsetopic , scriptid , rawresponse , headers ) . then ( <nl> - ( ) = > { <nl> - logger . debug ( ' [ % s ] response sent to queue , took [ % s ] ms , scriptid : [ % s ] ' , requestid , ( performance . now ( ) - tstartsending ) , scriptid ) ; <nl> - } , <nl> - ( err ) = > { <nl> - if ( err ) { <nl> - logger . error ( ' [ % s ] failed to send response to queue : % s ' , requestid , err . message ) ; <nl> - logger . error ( err . stack ) ; <nl> - } <nl> - } <nl> - ) ; <nl> + logger . debug ( ' [ % s ] sending response to queue , scriptid : [ % s ] ' , requestid , scriptid ) ; <nl> + this . producer . send ( responsetopic , scriptid , rawresponse , headers ) ; <nl> + <nl> + / / ( ) = > { <nl> + / / logger . info ( ' [ % s ] response sent to queue , took [ % s ] ms , scriptid : [ % s ] ' , requestid , ( performance . now ( ) - tstartsending ) , scriptid ) ; <nl> + / / } , <nl> + / / ( err ) = > { <nl> + / / if ( err ) { <nl> + / / logger . error ( ' [ % s ] failed to send response to queue : % s ' , requestid , err . message ) ; <nl> + / / logger . error ( err . stack ) ; <nl> + / / } <nl> + / / } <nl> + / / ) ; <nl> } <nl>  <nl> jsinvokemessageprocessor . prototype . getorcompilescript = function ( scriptid , scriptbody ) { <nl> mmm a / msa / js - executor / queue / kafkatemplate . js <nl> ppp b / msa / js - executor / queue / kafkatemplate . js <nl>
async function disconnectproducer ( ) { <nl> var _producer = producer ; <nl> producer = null ; <nl> try { <nl> + logger . info ( ' stopping loop . . . ' ) ; <nl> + <nl> + clearinterval ( loopsend ) ; <nl> + sendproducermsg ( ) ; <nl> await _producer . disconnect ( ) ; <nl> logger . info ( ' kafka producer stopped . ' ) ; <nl> } catch ( e ) {
public class tblwm2mredisregistrationstore implements californiumregistrationsto <nl> } <nl> } <nl>  <nl> + <nl> private void removeaddrindex ( redisconnection connection , registration registration ) { <nl> / / watch the key to remove . <nl> byte [ ] regaddrkey = toregaddrkey ( registration . getsocketaddress ( ) ) ; <nl> - connection . watch ( regaddrkey ) ; <nl> + / / connection . watch ( regaddrkey ) ; <nl>  <nl> byte [ ] epfromaddr = connection . get ( regaddrkey ) ; <nl> / / delete the key if needed . <nl> if ( arrays . equals ( epfromaddr , registration . getendpoint ( ) . getbytes ( utf_8 ) ) ) { <nl> / / try to delete the key <nl> - connection . multi ( ) ; <nl> + / / connection . multi ( ) ; <nl> connection . del ( regaddrkey ) ; <nl> - connection . exec ( ) ; <nl> + / / connection . exec ( ) ; <nl> / / if transaction failed this is not an issue as the socket address is probably reused and we don ' t neeed to <nl> / / delete it anymore . <nl> } else { <nl> / / the key must not be deleted . <nl> - connection . unwatch ( ) ; <nl> + / / connection . unwatch ( ) ; <nl> } <nl> }
class devicestate { <nl> } <nl> } <nl>  <nl> + private boolean processdeviceactivityevent ( tbcontext ctx , tbmsg msg ) throws executionexception , interruptedexception { <nl> + <nl> + return processattributesupdate ( ctx , msg , msg . getmetadata ( ) . getvalue ( " scope " ) ) ; <nl> + } <nl> + <nl> private boolean processalarmclearnotification ( tbcontext ctx , tbmsg msg ) { <nl> boolean statechanged = false ; <nl> alarm alarmnf = jacksonutil . fromstring ( msg . getdata ( ) , alarm . class ) ; <nl>
public class telemetryprocessor extends baseprocessor { <nl> list < listenablefuture < void > > result = new arraylist < > ( ) ; <nl> entityid entityid = constructentityid ( entitydata ) ; <nl> if ( ( entitydata . haspostattributesmsg ( ) | | entitydata . hasposttelemetrymsg ( ) | | entitydata . hasattributesupdatedmsg ( ) ) & & entityid ! = null ) { <nl> - tbmsgmetadata metadata = constructbasemsgmetadata ( tenantid , entityid ) ; <nl> + <nl> + tbmsgmetadata metadata = new tbmsgmetadata ( ) ; <nl> metadata . putvalue ( dataconstants . msg_source_key , dataconstants . edge_msg_source ) ; <nl> if ( entitydata . haspostattributesmsg ( ) ) { <nl> result . add ( processpostattributes ( tenantid , entityid , entitydata . getpostattributesmsg ( ) , metadata ) ) ;
public class defaultsyncedgeservice implements syncedgeservice { <nl> log . trace ( " [ { } ] [ { } ] staring edge sync process " , edge . gettenantid ( ) , edge . getid ( ) ) ; <nl> try { <nl> syncwidgetsbundleandwidgettypes ( edge ) ; <nl> - syncadminsettings ( edge ) ; <nl> + <nl> syncrulechains ( edge ) ; <nl> syncusers ( edge ) ; <nl> syncdevices ( edge ) ;
abstract public class baseedgetest extends abstractcontrollertest { <nl> senddevicecredentialsrequest ( ) ; <nl> senddevicerpcresponse ( ) ; <nl> senddevicecredentialsupdate ( ) ; <nl> - sendattributesrequest ( ) ; <nl> + <nl> log . info ( " messages were sent successfully " ) ; <nl> }
abstract public class baseedgetest extends abstractcontrollertest { <nl> edgeimitator . senduplinkmsg ( uplinkmsgbuilder . build ( ) ) ; <nl> edgeimitator . waitforresponses ( ) ; <nl>  <nl> - abstractmessage latestmessage = edgeimitator . getlatestmessage ( ) ; <nl> - assert . asserttrue ( latestmessage instanceof deviceupdatemsg ) ; <nl> - deviceupdatemsg deviceupdatemsg = ( deviceupdatemsg ) latestmessage ; <nl> + <nl>  <nl> - uuid saveddeviceid = new uuid ( deviceupdatemsg . getidmsb ( ) , deviceupdatemsg . getidlsb ( ) ) ; <nl> - <nl> - device device = doget ( " / api / device / " + saveddeviceid , device . class ) ; <nl> - assert . assertnotnull ( device ) ; <nl> - assert . assertequals ( " edge device num " , device . getname ( ) ) ; <nl> + / / device device = doget ( " / api / device / " + uuid . tostring ( ) , device . class ) ; <nl> + / / assert . assertnotnull ( device ) ; <nl> + / / assert . assertequals ( " edge device num " , device . getname ( ) ) ; <nl> } <nl>  <nl> private void sendrelationrequest ( ) throws exception {
public class tbmsgpushtoedgenode implements tbnode { <nl> } <nl> } <nl>  <nl> + private string getscope ( map < string , string > metadata ) { <nl> + string scope = metadata . get ( scope ) ; <nl> + if ( stringutils . isempty ( scope ) ) { <nl> + <nl> + scope = dataconstants . server_scope ; <nl> + } <nl> + return scope ; <nl> + } <nl> + <nl> private edgeevent buildedgeevent ( tenantid tenantid , edgeeventactiontype edgeeventaction , uuid entityid , edgeeventtype edgeeventtype , jsonnode entitybody ) { <nl> edgeevent edgeevent = new edgeevent ( ) ; <nl> edgeevent . settenantid ( tenantid ) ; <nl> mmm a / rule - engine / rule - engine - components / src / main / java / org / thingsboard / rule / engine / telemetry / tbmsgattributesnode . java <nl> ppp b / rule - engine / rule - engine - components / src / main / java / org / thingsboard / rule / engine / telemetry / tbmsgattributesnode . java <nl>
export class eventtableconfig extends entitytableconfig < event , timepagelink > { <nl> this . columns . push ( <nl> new entitytablecolumn < event > ( ' type ' , ' event . type ' , ' 100 % ' , <nl> ( entity ) = > entity . type , entity = > ( { } ) , false ) , <nl> - ) ; <nl> + new entitytablecolumn < event > ( ' action ' , ' event . action ' , ' 100 % ' , <nl> + ( entity ) = > entity . action , entity = > ( { } ) , false ) , <nl> + new entitytablecolumn < event > ( ' entityid ' , ' event . entityid ' , ' 100 % ' , <nl> + ( entity ) = > entity . id . id , entity = > ( { } ) , false ) <nl> + ) ; <nl> break ; <nl> case debugeventtype . debug_rule_node : <nl> case debugeventtype . debug_rule_chain : <nl> mmm a / ui - ngx / src / app / shared / models / event . models . ts <nl> ppp b / ui - ngx / src / app / shared / models / event . models . ts <nl>
export interface event extends basedata < eventid > { <nl> type : string ; <nl> uid : string ; <nl> body : eventbody ; <nl> + action : string ; <nl> }
public class baseentityservice extends abstractentityservice implements entityse <nl> return this . entityquerydao . findentitydatabyquery ( tenantid , customerid , query ) ; <nl> } <nl>  <nl> + <nl> @ override <nl> public listenablefuture < string > fetchentitynameasync ( tenantid tenantid , entityid entityid ) { <nl> log . trace ( " executing fetchentitynameasync [ { } ] " , entityid ) ; <nl> mmm a / dao / src / main / java / org / thingsboard / server / dao / sql / event / jpabaseeventdao . java <nl> ppp b / dao / src / main / java / org / thingsboard / server / dao / sql / event / jpabaseeventdao . java <nl>
public class oauth2serviceimpl implements oauth2service { <nl> return clientsparams . get ( tenantid ) ; <nl> } <nl>  <nl> - private map < tenantid , oauth2clientsparams > getalloauth2clientsparams ( ) { <nl> + <nl> + @ override <nl> + public map < tenantid , oauth2clientsparams > getalloauth2clientsparams ( ) { <nl> oauth2clientsparams systemoauth2clientsparams = getsystemoauth2clientsparamsfromdb ( ) ; <nl> listenablefuture < map < string , string > > jsonfuture = getalloauth2clientsparamsattribute ( ) ; <nl> try {
public abstract class basecontroller { <nl> } <nl> if ( e = = null ) { <nl> pushentityactiontoruleengine ( entityid , entity , user , customerid , actiontype , additionalinfo ) ; <nl> + <nl> } <nl> auditlogservice . logentityaction ( user . gettenantid ( ) , customerid , user . getid ( ) , user . getname ( ) , entityid , entity , actiontype , e , additionalinfo ) ; <nl> } <nl>
public abstract class basecontroller { <nl> case unassigned_from_edge : <nl> msgtype = dataconstants . entity_unassigned_from_edge ; <nl> break ; <nl> + case credentials_updated : <nl> + <nl> + msgtype = dataconstants . entity_updated ; <nl> + break ; <nl> } <nl> if ( ! stringutils . isempty ( msgtype ) ) { <nl> try { <nl> mmm a / application / src / main / java / org / thingsboard / server / service / edge / rpc / constructor / deviceupdatemsgconstructor . java <nl> ppp b / application / src / main / java / org / thingsboard / server / service / edge / rpc / constructor / deviceupdatemsgconstructor . java <nl>
export function parsetemplate ( template : string , data : object , translatefn ? : ( key <nl> } <nl> const expressions = template . match ( / \ { ( . * ? ) \ } / g ) ; <nl> if ( expressions ) { <nl> - const clearmatches = template . match ( / ( ? < = \ { ) ( . + ? ) ( ? = ( \ } | \ : ) ) / g ) ; <nl> + <nl> + const clearmatches = template . match ( / \ { ( . + ? ) ( \ } | \ : ) / g ) ; <nl> for ( const key in data ) { <nl> if ( ! key . includes ( ' | ' ) ) <nl> variables + = ` let $ { key } = ' $ { clearmatches [ key ] ? padvalue ( data [ key ] , + clearmatches [ key ] ) : data [ key ] } ' ; ` ; <nl> mmm a / ui - ngx / src / browserslist <nl> ppp b / ui - ngx / src / browserslist <nl>
public class consistenthashpartitionservice implements partitionservice { <nl> int hash = hashfunction . newhasher ( ) <nl> . putlong ( entityid . getid ( ) . getmostsignificantbits ( ) ) <nl> . putlong ( entityid . getid ( ) . getleastsignificantbits ( ) ) . hash ( ) . asint ( ) ; <nl> - int partition = math . abs ( hash % partitionsizes . get ( servicequeue ) ) ; <nl> + integer partitionsize = partitionsizes . get ( servicequeue ) ; <nl> + int partition ; <nl> + if ( partitionsize ! = null ) { <nl> + partition = math . abs ( hash % partitionsize ) ; <nl> + } else { <nl> + <nl> + partition = num ; <nl> + } <nl> boolean isolatedtenant = isisolated ( servicequeue , tenantid ) ; <nl> topicpartitioninfokey cachekey = new topicpartitioninfokey ( servicequeue , isolatedtenant ? tenantid : null , partition ) ; <nl> return tpicache . computeifabsent ( cachekey , key - > buildtopicpartitioninfo ( servicequeue , tenantid , partition ) ) ;
public abstract class basetimeseriesservicetest extends abstractservicetest { <nl> assert . assertequals ( totsentry ( ts , stringkventry ) , entries . get ( 0 ) ) ; <nl> } <nl>  <nl> - @ test <nl> + <nl> + / * @ test <nl> public void testdeletedevicetsdata ( ) throws exception { <nl> deviceid deviceid = new deviceid ( uuids . timebased ( ) ) ; <nl>  <nl>
function dashboardutils ( types , utils , timeservice ) { <nl> delete datasource . devicealiasid ; <nl> } <nl> } ) ; <nl> + <nl> + if ( widget . issystemtype & & widget . bundlealias = = ' charts ' & & widget . typealias = = ' timeseries ' ) { <nl> + widget . typealias = ' basic_timeseries ' ; <nl> + } <nl> return widget ; <nl> } <nl>  <nl>
export default function widgetcontroller ( $ scope , $ timeout , $ window , $ element , $ q <nl>  <nl>  <nl> function onredraw ( delay , dataupdate ) { <nl> - if ( ! visible ) { <nl> + <nl> + / * if ( ! visible ) { <nl> return ; <nl> - } <nl> + } * / <nl> if ( angular . isundefined ( delay ) ) { <nl> delay = num ; <nl> }
public class snihandlertest { <nl> try { <nl> / / push the handshake message . <nl> ch . writeinbound ( unpooled . wrappedbuffer ( message ) ) ; <nl> - fail ( ) ; <nl> + <nl> + / / fail ( ) ; <nl> } catch ( exception e ) { <nl> / / expected <nl> }
public class amazoncorrettosslenginetest extends sslenginetest { <nl> @ override <nl> public void testmutualauthvalidclientcertchaintoolongfailrequireclientauth ( ) { <nl> } <nl> + <nl> + @ override <nl> + protected boolean mysetupmutualauthserverisvalidexception ( throwable cause ) { <nl> + <nl> + return super . mysetupmutualauthserverisvalidexception ( cause ) | | causedbysslexception ( cause ) ; <nl> + } <nl> }
public class http2multiplexcodec extends http2framecodec { <nl> promise . setsuccess ( ) ; <nl> } else { <nl> throwable error = wrapstreamclosederror ( cause ) ; <nl> - if ( error instanceof closedchannelexception ) { <nl> + / / to make it more consistent with abstractchannel we handle all ioexceptions here . <nl> + if ( error instanceof ioexception ) { <nl> if ( config . isautoclose ( ) ) { <nl> / / close channel if needed . <nl> closeforcibly ( ) ; <nl> } else { <nl> + <nl> outboundclosed = true ; <nl> } <nl> }
public final class selfsignedcertificate { <nl> logger . debug ( " failed to generate a self - signed x . 509 certificate using bouncy castle : " , t2 ) ; <nl> throw new certificateexception ( <nl> " no provider succeeded to generate a self - signed certificate . " + <nl> - " see debug log for the root cause . " ) ; <nl> + " see debug log for the root cause . " , t2 ) ; <nl> + <nl> } <nl> }
public interface websocketserverextension extends websocketextension { <nl> * <nl> * @ return the acknowledged extension configuration . <nl> * / <nl> + <nl> websocketextensiondata newreponsedata ( ) ; <nl>  <nl> }
public class defaultthreadfactory implements threadfactory { <nl> return t ; <nl> } <nl>  <nl> + <nl> protected thread newthread ( runnable r , string name ) { <nl> - return new fastthreadlocalthread ( r , name ) ; <nl> + return new fastthreadlocalthread ( threadgroup , r , name ) ; <nl> } <nl>  <nl> private static final class defaultrunnabledecorator implements runnable {
final class websocketutil { <nl> * @ return the hashed data <nl> * / <nl> static byte [ ] md5 ( byte [ ] data ) { <nl> - try { <nl> - / / try to get a messagedigest that uses md5 <nl> - messagedigest md = messagedigest . getinstance ( " md5 " ) ; <nl> - / / hash the data <nl> - return md . digest ( data ) ; <nl> - } catch ( nosuchalgorithmexception e ) { <nl> - / / this shouldn ' t happen ! how old is the computer ? <nl> - throw new internalerror ( " md5 not supported on this platform - outdated ? " ) ; <nl> - } <nl> + <nl> + return md5 . get ( ) . digest ( data ) ; <nl> } <nl>  <nl> / * * <nl>
final class websocketutil { <nl> * @ return the hashed data <nl> * / <nl> static byte [ ] sha1 ( byte [ ] data ) { <nl> - try { <nl> - / / attempt to get a messagedigest that uses sha1 <nl> - messagedigest md = messagedigest . getinstance ( " sha1 " ) ; <nl> - / / hash the data <nl> - return md . digest ( data ) ; <nl> - } catch ( nosuchalgorithmexception e ) { <nl> - / / alright , you might have an old system . <nl> - throw new internalerror ( " sha - 1 is not supported on this platform - outdated ? " ) ; <nl> - } <nl> + <nl> + return sha1 . get ( ) . digest ( data ) ; <nl> } <nl>  <nl> / * *
public abstract class recycler < t > { <nl>  <nl> private static final internallogger logger = internalloggerfactory . getinstance ( recycler . class ) ; <nl>  <nl> + @ suppresswarnings ( " rawtypes " ) <nl> + private static final handle noop_handle = new handle ( ) { <nl> + @ override <nl> + public void recycle ( object object ) { <nl> + / / noop <nl> + } <nl> + } ; <nl> private static final atomicinteger id_generator = new atomicinteger ( integer . min_value ) ; <nl> private static final int own_thread_id = id_generator . getandincrement ( ) ; <nl> + <nl> + private static final int default_initial_max_capacity = num ; <nl> private static final int default_max_capacity ; <nl> private static final int initial_capacity ; <nl>  <nl>
public class epollreuseaddrtest { <nl> } <nl>  <nl> @ test ( timeout = num ) <nl> + @ ignore <nl> public void testmultiplebinddatagramchannel ( ) throws exception { <nl> resourceleakdetector . setlevel ( resourceleakdetector . level . advanced ) ; <nl> assume . assumetrue ( versioneqorgt ( 3 , num , num ) ) ;
import java . util . map ; <nl> * / <nl> public abstract class recycler < t > { <nl>  <nl> + private static final internallogger logger = internalloggerfactory . getinstance ( recycler . class ) ; <nl> + <nl> + private static final int default_max_capacity ; <nl> + private static final int initial_capacity ; <nl> + <nl> + <nl> + static { <nl> + / / in the future , we might have different maxcapacity for different object types . <nl> + / / e . g . io . netty . recycler . maxcapacity . writetask <nl> + / / io . netty . recycler . maxcapacity . outboundbuffer <nl> + int maxcapacity = systempropertyutil . getint ( " io . netty . recycler . maxcapacity . default " , num ) ; <nl> + if ( maxcapacity < = num ) { <nl> + <nl> + maxcapacity = num ; <nl> + } <nl> + <nl> + default_max_capacity = maxcapacity ; <nl> + if ( logger . isdebugenabled ( ) ) { <nl> + logger . debug ( " - dio . netty . recycler . maxcapacity . default : { } " , default_max_capacity ) ; <nl> + } <nl> + <nl> + initial_capacity = math . min ( default_max_capacity , num ) ; <nl> + } <nl> + <nl> + private final int maxcapacity ; <nl> + <nl> private final threadlocal < stack < t > > threadlocal = new threadlocal < stack < t > > ( ) { <nl> @ override <nl> protected stack < t > initialvalue ( ) { <nl> - return new stack < t > ( recycler . this , thread . currentthread ( ) ) ; <nl> + return new stack < t > ( recycler . this , thread . currentthread ( ) , maxcapacity ) ; <nl> } <nl> } ; <nl>  <nl> + protected recycler ( ) { <nl> + this ( default_max_capacity ) ; <nl> + } <nl> + <nl> + protected recycler ( int maxcapacity ) { <nl> + if ( maxcapacity < = num ) { <nl> + maxcapacity = num ; <nl> + } <nl> + this . maxcapacity = maxcapacity ; <nl> + } <nl> + <nl> public final t get ( ) { <nl> stack < t > stack = threadlocal . get ( ) ; <nl> t o = stack . pop ( ) ; <nl>
public class defaultchannelconfig implements channelconfig { <nl> } <nl> this . channel = channel ; <nl>  <nl> - if ( channel instanceof serverchannel ) { <nl> - / / accept as many incoming connections as possible . <nl> + if ( channel instanceof serverchannel | | channel instanceof abstractniobytechannel ) { <nl> + / / server channels : accept as many incoming connections as possible . <nl> + / / nio byte channels : implemented to reduce unnecessary system calls even if it ' s > num . <nl> + / / see https : / / github . com / netty / netty / issues / 2079 <nl> + <nl> maxmessagesperread = num ; <nl> } else { <nl> maxmessagesperread = num ;
public class socketsslechotest extends abstractsockettest { <nl>  <nl> for ( int i = first_message_size ; i < data . length ; ) { <nl> int length = math . min ( random . nextint ( 1024 * num ) , data . length - i ) ; <nl> - cc . write ( unpooled . wrappedbuffer ( data , i , length ) ) ; <nl> + channelfuture future = cc . write ( unpooled . wrappedbuffer ( data , i , length ) ) ; <nl> + <nl> + if ( ! chunkwritehandler ) { <nl> + future . sync ( ) ; <nl> + } <nl> i + = length ; <nl> }
public class querystringencoder { <nl> } <nl>  <nl> private static string encodecomponent ( string s , charset charset ) { <nl> + <nl> try { <nl> return urlencoder . encode ( s , charset . name ( ) ) . replace ( " + " , " % 20 " ) ; <nl> } catch ( unsupportedencodingexception e ) {
import java . util . map . entry ; <nl>  <nl> final class sockettestpermutation { <nl>  <nl> + <nl> + private static final boolean test_aio = ! platformdependent . iswindows ( ) ; <nl> + <nl> static list < entry < factory < serverbootstrap > , factory < bootstrap > > > socket ( ) { <nl> list < entry < factory < serverbootstrap > , factory < bootstrap > > > list = <nl> new arraylist < entry < factory < serverbootstrap > , factory < bootstrap > > > ( ) ; <nl>
public final class channelhandlerutil { <nl> * / <nl> public static void freemessage ( object msg ) throws exception { <nl> if ( msg instanceof freeable ) { <nl> - ( ( freeable ) msg ) . free ( ) ; <nl> + try { <nl> + ( ( freeable ) msg ) . free ( ) ; <nl> + } catch ( unsupportedoperationexception e ) { <nl> + / / this can happen for derived buffers <nl> + <nl> + } <nl> } <nl> }
public class defaultchannelpipeline implements channelpipeline { <nl> public channelbuf newoutboundbuffer ( channelhandlercontext ctx ) throws exception { <nl> switch ( channel . metadata ( ) . buffertype ( ) ) { <nl> case byte : <nl> + <nl> return unpooled . buffer ( ) ; <nl> case message : <nl> return unpooled . messagebuffer ( ) ;
public class nioserversocketchannel extends abstractniomessagechannel <nl> private final class nioserversocketunsafe extends abstractniomessageunsafe { <nl> @ override <nl> public void suspendread ( ) { <nl> - selectionkey ( ) . interestops ( selectionkey ( ) . interestops ( ) & ~ selectionkey . op_accept ) ; <nl> + selectionkey ( ) . cancel ( ) ; <nl> } <nl>  <nl> @ override <nl> public void resumeread ( ) { <nl> - selectionkey ( ) . interestops ( selectionkey ( ) . interestops ( ) | selectionkey . op_accept ) ; <nl> + try { <nl> + doregister ( ) ; <nl> + } catch ( exception e ) { <nl> + <nl> + e . printstacktrace ( ) ; <nl> + } <nl> } <nl> } <nl> }
public class lengthfieldbasedframedecoder extends framedecoder { <nl> return frame ; <nl> } <nl>  <nl> + private void failifnecessary ( channelhandlercontext ctx ) { <nl> + if ( bytestodiscard = = num ) { <nl> + / / reset to the initial state and tell the handlers that <nl> + / / the frame was too large . <nl> + <nl> + long toolongframelength = this . toolongframelength ; <nl> + this . toolongframelength = num ; <nl> + discardingtoolongframe = false ; <nl> + fail ( ctx , toolongframelength ) ; <nl> + } else { <nl> + / / keep discarding . <nl> + } <nl> + } <nl> + <nl> / * * <nl> * extract the sub - region of the specified buffer . this method is called by <nl> * { @ link # decode ( channelhandlercontext , channel , channelbuffer ) } for each <nl> mmm / dev / null <nl> ppp b / src / test / java / org / jboss / netty / handler / codec / frame / lengthfieldbasedframedecodertest . java <nl>
public class hashedwheeltimer implements timer { <nl>  <nl> @ override <nl> public void cancel ( ) { <nl> - if ( isexpired ( ) ) { <nl> + if ( ! state . compareandset ( st_init , st_cancelled ) ) { <nl> + <nl> return ; <nl> } <nl> - <nl> - cancelled = true ; <nl> - <nl> - / / might be called more than once , but doesn ' t matter . <nl> + <nl> wheel [ stopindex ] . remove ( this ) ; <nl> } <nl>  <nl> @ override <nl> public boolean iscancelled ( ) { <nl> - return cancelled ; <nl> + return state . get ( ) = = st_cancelled ; <nl> } <nl>  <nl> @ override <nl> public boolean isexpired ( ) { <nl> - return cancelled | | system . currenttimemillis ( ) > deadline ; <nl> + return state . get ( ) ! = st_init ; <nl> } <nl>  <nl> public void expire ( ) { <nl> - if ( cancelled ) { <nl> + if ( ! state . compareandset ( st_init , st_expired ) ) { <nl> return ; <nl> }
final class defaultlocalchannel extends abstractchannel implements localchannel <nl> super ( parent , factory , pipeline , sink ) ; <nl> this . pairedchannel = pairedchannel ; <nl> config = new defaultchannelconfig ( ) ; <nl> + <nl> + <nl> + getclosefuture ( ) . addlistener ( new channelfuturelistener ( ) { <nl> + public void operationcomplete ( channelfuture future ) throws exception { <nl> + state . set ( st_closed ) ; <nl> + } <nl> + } ) ; <nl> + <nl> firechannelopen ( this ) ; <nl> } <nl>  <nl>
class niosocketchannel extends abstractchannel <nl> this . socket = socket ; <nl> this . worker = worker ; <nl> config = new defaultniosocketchannelconfig ( socket . socket ( ) ) ; <nl> + <nl> + <nl> + getclosefuture ( ) . addlistener ( new channelfuturelistener ( ) { <nl> + public void operationcomplete ( channelfuture future ) throws exception { <nl> + state = st_closed ; <nl> + } <nl> + } ) ; <nl> } <nl>  <nl> @ override <nl>
import org . jboss . netty . util . internal . threadlocalboolean ; <nl> * / <nl> final class defaultlocalchannel extends abstractchannel implements localchannel { <nl>  <nl> + <nl> + private static final int st_open = num ; <nl> + private static final int st_bound = num ; <nl> + private static final int st_connected = num ; <nl> + private static final int st_closed = - 1 ; <nl> + private final atomicinteger state = new atomicinteger ( st_open ) ; <nl> + <nl> private final channelconfig config ; <nl> private final threadlocalboolean delivering = new threadlocalboolean ( ) ; <nl> - final atomicboolean bound = new atomicboolean ( ) ; <nl> + <nl> final queue < messageevent > writebuffer = new linkedtransferqueue < messageevent > ( ) ; <nl>  <nl> volatile defaultlocalchannel pairedchannel ; <nl>
public class lengthfieldbasedframedecoder extends framedecoder { <nl> if ( bytestodiscard = = num ) { <nl> / / reset to the initial state and tell the handlers that <nl> / / the frame was too large . <nl> - discardingtoolongframe = false ; <nl> + <nl> long toolongframelength = this . toolongframelength ; <nl> this . toolongframelength = num ; <nl> - throw new toolongframeexception ( <nl> - " adjusted frame length exceeds " + maxframelength + <nl> - " : " + toolongframelength ) ; <nl> + fail ( ctx , toolongframelength ) ; <nl> } else { <nl> / / keep discarding . <nl> - return null ; <nl> } <nl> + return null ; <nl> } <nl>  <nl> if ( buffer . readablebytes ( ) < lengthfieldendoffset ) { <nl>
public class delimiterbasedframedecoder extends framedecoder { <nl>  <nl> if ( discardingtoolongframe ) { <nl> / / we ' ve just finished discarding a very large frame . <nl> - / / throw an exception and go back to the initial state . <nl> - long toolongframelength = this . toolongframelength ; <nl> - this . toolongframelength = num l ; <nl> + / / go back to the initial state . <nl> discardingtoolongframe = false ; <nl> buffer . skipbytes ( minframelength + mindelimlength ) ; <nl> - fail ( toolongframelength + minframelength + mindelimlength ) ; <nl> + <nl> + <nl> + int toolongframelength = this . toolongframelength ; <nl> + this . toolongframelength = num ; <nl> + fail ( ctx , toolongframelength ) ; <nl> + return null ; <nl> } <nl>  <nl> if ( minframelength > maxframelength ) { <nl> / / discard read frame . <nl> buffer . skipbytes ( minframelength + mindelimlength ) ; <nl> - fail ( minframelength ) ; <nl> + fail ( ctx , minframelength ) ; <nl> + return null ; <nl> } <nl>  <nl> if ( stripdelimiter ) { <nl>
import com . google . protobuf . codedinputstream ; <nl> * / <nl> public class protobufvarint32framedecoder extends framedecoder { <nl>  <nl> + <nl> + <nl> / * * <nl> * creates a new instance . <nl> * /
import org . jboss . netty . util . internal . concurrentidentityweakkeyhashmap ; <nl> public class orderedmemoryawarethreadpoolexecutor extends <nl> memoryawarethreadpoolexecutor { <nl>  <nl> + <nl> + <nl> private final concurrentmap < object , executor > childexecutors = newchildexecutormap ( ) ; <nl>  <nl> / * *
public class httpheaders { <nl> return defaultvalue ; <nl> } <nl>  <nl> + <nl> + <nl> public static void setcontentlength ( httpmessage message , long value ) { <nl> message . setheader ( names . content_length , value ) ; <nl> }
import java . nio . charset . unsupportedcharsetexception ; <nl> * @ apiviz . landmark <nl> * / <nl> public interface channelbuffer extends comparable < channelbuffer > { <nl> + <nl>  <nl> / * * <nl> * returns the factory which creates a { @ link channelbuffer } whose <nl> mmm a / src / main / java / org / jboss / netty / buffer / channelbuffers . java <nl> ppp b / src / main / java / org / jboss / netty / buffer / channelbuffers . java <nl>
import org . jboss . netty . util . charsetutil ; <nl> * @ apiviz . has org . jboss . netty . buffer . channelbuffer oneway - - creates <nl> * / <nl> public class channelbuffers { <nl> + <nl>  <nl> / * * <nl> * big endian byte order .
<nl> + / * <nl> + * copyright num red hat , inc . <nl> + * <nl> + * red hat licenses this file to you under the apache license , version num . 0 <nl> + * ( the " license " ) ; you may not use this file except in compliance with the <nl> + * license . you may obtain a copy of the license at : <nl> + * <nl> + * http : / / www . apache . org / licenses / license - 2 . 0 <nl> + * <nl> + * unless required by applicable law or agreed to in writing , software <nl> + * distributed under the license is distributed on an " as is " basis , without <nl> + * warranties or conditions of any kind , either express or implied . see the <nl> + * license for the specific language governing permissions and limitations <nl> + * under the license . <nl> + * / <nl> + package org . jboss . netty . channel . socket . nio ; <nl> + <nl> + import java . net . inetsocketaddress ; <nl> + import java . net . serversocket ; <nl> + import java . net . socket ; <nl> + import java . util . concurrent . executors ; <nl> + <nl> + import org . jboss . netty . bootstrap . clientbootstrap ; <nl> + import org . jboss . netty . channel . channelfuture ; <nl> + import org . jboss . netty . util . dummyhandler ; <nl> + import org . junit . test ; <nl> + <nl> + / * * <nl> + * tests if netty works around the infamous <nl> + * < a href = " http : / / bugs . sun . com / bugdatabase / view_bug . do ? bug_id = 6403933 " > ' spinning selector ' bug < / a > . <nl> + * <nl> + * @ author the netty project ( netty - dev @ lists . jboss . org ) <nl> + * @ author daniel bevenius ( dbevenius @ jboss . com ) <nl> + * @ version $ rev $ , $ date $ <nl> + * / <nl> + public class spinningselectorbugtest { <nl> + <nl> + @ test ( timeout = num ) <nl> + public void test ( ) throws exception { <nl> + serversocket ss = new serversocket ( 0 ) ; <nl> + <nl> + clientbootstrap cb = new clientbootstrap ( new nioclientsocketchannelfactory ( <nl> + executors . newcachedthreadpool ( ) , executors . newcachedthreadpool ( ) ) ) ; <nl> + cb . getpipeline ( ) . addlast ( " dummy " , new dummyhandler ( ) ) ; <nl> + channelfuture cf = cb . connect ( new inetsocketaddress ( " 127 . 0 . 0 . 1 " , ss . getlocalport ( ) ) ) ; <nl> + socket s = ss . accept ( ) ; <nl> + cf . awaituninterruptibly ( ) ; <nl> + <nl> + try { <nl> + thread . sleep ( 1000 ) ; <nl> + } catch ( interruptedexception e ) { <nl> + / / ignore <nl> + } <nl> + <nl> + / / send rst to trigger selector to spin . <nl> + s . setsolinger ( true , num ) ; <nl> + s . close ( ) ; <nl> + <nl> + / / if selector spins , the client side selector will not notice the closure . <nl> + cf . getchannel ( ) . getclosefuture ( ) . awaituninterruptibly ( ) ; <nl> + <nl> + cb . releaseexternalresources ( ) ; <nl> + } <nl> + }
import org . jboss . netty . util . caseignoringcomparator ; <nl> * @ version $ rev $ , $ date $ <nl> * / <nl> public class httpcookiedecoder { <nl> - private final static string semicolon = " ; " ; <nl>  <nl> + <nl> + private final static string semicolon = " ; " ; <nl> private final static string equals = " = " ; <nl>  <nl> public map < string , httpcookie > decode ( string header ) { <nl> mmm a / src / main / java / org / jboss / netty / handler / codec / http / httpcookieencoder . java <nl> ppp b / src / main / java / org / jboss / netty / handler / codec / http / httpcookieencoder . java <nl>
import org . jboss . netty . util . caseignoringcomparator ; <nl> * / <nl> public class httpcookieencoder { <nl>  <nl> + <nl> private final map < string , httpcookie > cookies = new treemap < string , httpcookie > ( caseignoringcomparator . instance ) ; <nl>  <nl> public void addcookie ( string name , string val ) {
package org . jboss . netty . handler . codec . http ; <nl>  <nl> / * * <nl> * @ author < a href = " mailto : andy . taylor @ jboss . org " > andy taylor < / a > <nl> + * @ author trustin lee ( tlee @ redhat . com ) <nl> * / <nl> - public class httpcookie { <nl> + public class httpcookie implements comparable < httpcookie > { <nl>  <nl> + <nl> private final string name ; <nl> - <nl> private final string value ; <nl>  <nl> public httpcookie ( string name , string value ) { <nl> + if ( name = = null ) { <nl> + throw new nullpointerexception ( " name " ) ; <nl> + } <nl> + if ( value = = null ) { <nl> + throw new nullpointerexception ( " value " ) ; <nl> + } <nl> + <nl> this . name = name ; <nl> this . value = value ; <nl> } <nl>
package org . jboss . netty . handler . codec . http ; <nl> * @ version $ rev $ , $ date $ <nl> * / <nl> public class httpheaders { <nl> + <nl> public static final string host = " host " ; <nl>  <nl> public static final string content_length = " content - length " ;
<nl> + / * <nl> + * jboss , home of professional open source <nl> + * <nl> + * copyright num , red hat middleware llc , and individual contributors <nl> + * by the @ author tags . see the copyright . txt in the distribution for a <nl> + * full listing of individual contributors . <nl> + * <nl> + * this is free software ; you can redistribute it and / or modify it <nl> + * under the terms of the gnu lesser general public license as <nl> + * published by the free software foundation ; either version num . 1 of <nl> + * the license , or ( at your option ) any later version . <nl> + * <nl> + * this software is distributed in the hope that it will be useful , <nl> + * but without any warranty ; without even the implied warranty of <nl> + * merchantability or fitness for a particular purpose . see the gnu <nl> + * lesser general public license for more details . <nl> + * <nl> + * you should have received a copy of the gnu lesser general public <nl> + * license along with this software ; if not , write to the free <nl> + * software foundation , inc . , num franklin st , fifth floor , boston , ma <nl> + * num - 1301 usa , or see the fsf site : http : / / www . fsf . org . <nl> + * / <nl> + package org . jboss . netty . handler . codec . frame ; <nl> + <nl> + import static org . jboss . netty . buffer . channelbuffers . * ; <nl> + <nl> + import org . jboss . netty . buffer . channelbuffer ; <nl> + import org . jboss . netty . channel . channel ; <nl> + import org . jboss . netty . channel . channelhandlercontext ; <nl> + import org . jboss . netty . handler . codec . oneone . onetooneencoder ; <nl> + <nl> + / * * <nl> + * <nl> + * <nl> + * @ author the netty project ( netty - dev @ lists . jboss . org ) <nl> + * @ author trustin lee ( tlee @ redhat . com ) <nl> + * @ version $ rev $ , $ date $ <nl> + * / <nl> + public class lengthfieldprepender extends onetooneencoder { <nl> + <nl> + private final int lengthfieldlength ; <nl> + <nl> + public lengthfieldprepender ( int lengthfieldlength ) { <nl> + if ( lengthfieldlength ! = num & & lengthfieldlength ! = num & & <nl> + lengthfieldlength ! = num & & lengthfieldlength ! = num & & <nl> + lengthfieldlength ! = num ) { <nl> + throw new illegalargumentexception ( <nl> + " lengthfieldlength must be either num , num , num , num , or num : " + <nl> + lengthfieldlength ) ; <nl> + } <nl> + <nl> + this . lengthfieldlength = lengthfieldlength ; <nl> + } <nl> + <nl> + @ override <nl> + protected object encode ( <nl> + channelhandlercontext ctx , channel channel , object msg ) throws exception { <nl> + channelbuffer header = channel . getconfig ( ) . getbufferfactory ( ) . getbuffer ( lengthfieldlength ) ; <nl> + channelbuffer body = ( channelbuffer ) msg ; <nl> + <nl> + switch ( lengthfieldlength ) { <nl> + case num : <nl> + header . writebyte ( ( byte ) body . readablebytes ( ) ) ; <nl> + break ; <nl> + case num : <nl> + header . writeshort ( ( short ) body . readablebytes ( ) ) ; <nl> + break ; <nl> + case num : <nl> + header . writemedium ( body . readablebytes ( ) ) ; <nl> + break ; <nl> + case num : <nl> + header . writeint ( body . readablebytes ( ) ) ; <nl> + break ; <nl> + case num : <nl> + header . writelong ( body . readablebytes ( ) ) ; <nl> + break ; <nl> + default : <nl> + throw new error ( " should not reach here " ) ; <nl> + } <nl> + return wrappedbuffer ( header , body ) ; <nl> + } <nl> + } <nl> \ no newline at end of file
public abstract class abstractchannelbuffer implements channelbuffer { <nl> if ( length = = num ) { <nl> return channelbuffers . empty_buffer ; <nl> } <nl> + <nl> channelbuffer buf = channelbuffers . buffer ( order ( ) , length ) ; <nl> buf . writebytes ( this , readerindex , length ) ; <nl> readerindex + = length ; <nl>
import org . jboss . netty . channel . simplechannelhandler ; <nl> * { @ link clientbootstrap } instances as you want to apply different settings <nl> * for different { @ link channel } s . <nl> * <nl> + * <nl> + * <nl> * @ author the netty project ( netty - dev @ lists . jboss . org ) <nl> * @ author trustin lee ( tlee @ redhat . com ) <nl> * <nl> mmm a / src / main / java / org / jboss / netty / bootstrap / serverbootstrap . java <nl> ppp b / src / main / java / org / jboss / netty / bootstrap / serverbootstrap . java <nl>
import org . jboss . netty . channel . simplechannelhandler ; <nl> * { @ link serverbootstrap } instances as you want to apply different settings <nl> * for different { @ link channel } s . <nl> * <nl> + * <nl> + * <nl> * @ author the netty project ( netty - dev @ lists . jboss . org ) <nl> * @ author trustin lee ( tlee @ redhat . com ) <nl> *
public class downloaddialog extends dialogfragment <nl> / / instance creation <nl> / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / / * / <nl>  <nl> + public downloaddialog ( ) { <nl> + / / just an empty default no - arg ctor to keep fragment . instantiate ( ) happy <nl> + / / otherwise instantiationexception will be thrown when fragment is recreated <nl> + <nl> + } <nl> + <nl> / * * <nl> * create a new download dialog with the video , audio and subtitle streams from the provided <nl> * stream info . video streams and video - only streams will be put into a single list menu ,
public final class player implements <nl> final boolean ismuted = intent . getbooleanextra ( is_muted , ismuted ( ) ) ; <nl>  <nl> / * <nl> + * <nl> * there are num situations when playback shouldn ' t be started from scratch ( zero timestamp ) : <nl> * num . user pressed on a timestamp link and the same video should be rewound to the timestamp <nl> * num . user changed a player from , for example . main to popup , or from audio to main , etc
public abstract class tab { <nl>  <nl> @ override <nl> public string gettabname ( final context context ) { <nl> - return " newpipe " ; / / context . getstring ( r . string . blank_page_summary ) ; <nl> + <nl> + return " newpipe " ; / / context . getstring ( r . string . blank_page_summary ) ; <nl> } <nl>  <nl> @ drawableres <nl>
class feedfragment : basestatefragment < feedstate > ( ) { <nl> } <nl> } <nl>  <nl> + <nl> + fun redrawcontent ( ) { <nl> + groupadapter . notifyitemrangechanged ( 0 , int . max_value ) <nl> + } <nl> + <nl> fun setuplistviewmode ( ) { <nl> / / does everything needed to setup the layouts for grid or list modes <nl> groupadapter . spancount = if ( shouldusegridlayout ( context ) ) getgridspancountstreams ( context ) else num <nl> mmm a / app / src / main / java / org / schabi / newpipe / util / streamdialogentry . java <nl> ppp b / app / src / main / java / org / schabi / newpipe / util / streamdialogentry . java <nl>
public enum streamdialogentry { <nl> . setuploaderurl ( serviceid , url , result . getuploaderurl ( ) ) <nl> . subscribeon ( schedulers . io ( ) ) . subscribe ( ) ; <nl> openchannelfragment ( fragment , item , result . getuploaderurl ( ) ) ; <nl> - } , throwable - > toast . maketext ( <nl> + } , throwable - > toast . maketext ( <nl> fragment . getcontext ( ) , <nl> r . string . error_show_channel_details , <nl> toast . length_short <nl> mmm a / app / src / main / res / values / strings . xml <nl> ppp b / app / src / main / res / values / strings . xml <nl>
public abstract class playqueue implements serializable { <nl> public synchronized void setindex ( final int index ) { <nl> final int oldindex = getindex ( ) ; <nl>  <nl> - int newindex = index ; <nl> + final int newindex ; <nl> + <nl> if ( <nl> newindex = num ; <nl> + } else if ( <nl> + / / regular assignment for <nl> + newindex = index ; <nl> + } else if ( streams . isempty ( ) ) { <nl> + / / out of bounds from here on <nl> + / / need to check if stream is empty to prevent arithmetic error and negative index <nl> + newindex = num ; <nl> + } else if ( iscomplete ( ) ) { <nl> + / / circular indexing <nl> + newindex = <nl> + } else { <nl> + / / index of last element <nl> + newindex = streams . size ( ) - num ; <nl> } <nl> - if ( <nl> - newindex = iscomplete ( ) ? <nl> - } <nl> + <nl> + queueindex . set ( newindex ) ; <nl> + <nl> if ( oldindex ! = newindex ) { <nl> history . add ( streams . get ( newindex ) ) ; <nl> } <nl>  <nl> - queueindex . set ( newindex ) ; <nl> + / * <nl> + <nl> + different from the old one but this is emitted regardless ? not sure what this what it does <nl> + exactly so i won ' t touch it <nl> + * / <nl> broadcast ( new selectevent ( oldindex , newindex ) ) ; <nl> }
public final class player implements <nl> if ( exoplayerisnull ( ) ) { <nl> return ; <nl> } <nl> + / / use duration of currentitem for non - live streams , <nl> + / / because hls streams are fragmented <nl> + / / and thus the whole duration is not available to the player <nl> + <nl> + final int duration ; <nl> + if ( currentitem ! = null <nl> + & & currentitem . getstreamtype ( ) ! = streamtype . audio_live_stream <nl> + & & currentitem . getstreamtype ( ) ! = streamtype . live_stream ) { <nl> + / / convert seconds to milliseconds <nl> + duration = ( int ) ( currentitem . getduration ( ) * num ) ; <nl> + } else { <nl> + duration = ( int ) simpleexoplayer . getduration ( ) ; <nl> + } <nl> onupdateprogress ( <nl> math . max ( ( int ) simpleexoplayer . getcurrentposition ( ) , num ) , <nl> - ( int ) simpleexoplayer . getduration ( ) , <nl> + duration , <nl> simpleexoplayer . getbufferedpercentage ( ) <nl> ) ; <nl> }
public class subscriptionentity { <nl> item . setdescription ( getdescription ( ) ) ; <nl> return item ; <nl> } <nl> + <nl> + <nl> + <nl> + @ override <nl> + @ suppresswarnings ( " equalsreplaceablebyobjectscall " ) <nl> + public boolean equals ( final object o ) { <nl> + if ( this = = o ) { <nl> + return true ; <nl> + } <nl> + if ( o = = null | | getclass ( ) ! = o . getclass ( ) ) { <nl> + return false ; <nl> + } <nl> + <nl> + final subscriptionentity that = ( subscriptionentity ) o ; <nl> + <nl> + if ( uid ! = that . uid ) { <nl> + return false ; <nl> + } <nl> + if ( serviceid ! = that . serviceid ) { <nl> + return false ; <nl> + } <nl> + if ( ! url . equals ( that . url ) ) { <nl> + return false ; <nl> + } <nl> + if ( name ! = null ? ! name . equals ( that . name ) : that . name ! = null ) { <nl> + return false ; <nl> + } <nl> + if ( avatarurl ! = null ? ! avatarurl . equals ( that . avatarurl ) : that . avatarurl ! = null ) { <nl> + return false ; <nl> + } <nl> + if ( subscribercount ! = null <nl> + ? ! subscribercount . equals ( that . subscribercount ) <nl> + : that . subscribercount ! = null ) { <nl> + return false ; <nl> + } <nl> + return description ! = null <nl> + ? description . equals ( that . description ) <nl> + : that . description = = null ; <nl> + } <nl> + <nl> + @ override <nl> + public int hashcode ( ) { <nl> + int result = ( int ) ( uid ^ ( uid > > > num ) ) ; <nl> + result = num * result + serviceid ; <nl> + result = num * result + url . hashcode ( ) ; <nl> + result = num * result + ( name ! = null ? name . hashcode ( ) : num ) ; <nl> + result = num * result + ( avatarurl ! = null ? avatarurl . hashcode ( ) : num ) ; <nl> + result = num * result + ( subscribercount ! = null ? subscribercount . hashcode ( ) : num ) ; <nl> + result = num * result + ( description ! = null ? description . hashcode ( ) : num ) ; <nl> + return result ; <nl> + } <nl> }
android { <nl> archivesbasename = ' newpipe_ ' + normalizedworkingbranch <nl> } <nl> } <nl> + <nl> + / / keep the release build type at the end of the list to override ' archivesbasename ' of <nl> + / / debug build . this seems to be a gradle bug , therefore <nl> + <nl> + release { <nl> + minifyenabled true <nl> + shrinkresources true <nl> + proguardfiles getdefaultproguardfile ( ' proguard - android . txt ' ) , ' proguard - rules . pro ' <nl> + archivesbasename = ' app ' <nl> + } <nl> } <nl>  <nl> lintoptions {
public class selectkioskfragment extends dialogfragment { <nl> int serviceid ; <nl> string kioskid ; <nl> string kioskname ; <nl> - } ; <nl> + } <nl>  <nl> private list < entry > kiosklist = new vector < > ( ) ; <nl>  <nl> public selectkioskadapter ( ) <nl> throws exception { <nl> + <nl> for ( streamingservice service : newpipe . getservices ( ) ) { <nl> for ( string kioskid : service . getkiosklist ( ) . getavailablekisoks ( ) ) { <nl> + string name = service . getserviceinfo ( ) . name ; <nl> + name + = " / " ; <nl> + name + = kiosktranslator . gettranslatedkioskname ( kioskid , getcontext ( ) ) ; <nl> kiosklist . add ( new entry ( <nl> serviceiconmapper . geticonresource ( service . getserviceid ( ) ) , <nl> service . getserviceid ( ) , <nl> kioskid , <nl> - kiosktranslator . gettranslatedkioskname ( kioskid , getcontext ( ) ) ) ) ; <nl> + name ) ) ; <nl> } <nl> } <nl> } <nl>  <nl> public int getitemcount ( ) { <nl> - return kiosklist . size ( ) ; <nl> + <nl> + return num ; <nl> } <nl>  <nl> public selectkioskitemholder oncreateviewholder ( viewgroup parent , int type ) {
public class videoitemdetailfragment extends fragment { <nl> } <nl> } ) ; <nl>  <nl> + <nl> + thumbnailview . setonclicklistener ( new view . onclicklistener ( ) { <nl> + @ override <nl> + public void onclick ( view v ) { <nl> + playvideo ( info ) ; <nl> + } <nl> + } ) ; <nl> + <nl> if ( info . channel_url ! = null & & info . channel_url ! = " " ) { <nl> channelbutton . setonclicklistener ( new view . onclicklistener ( ) { <nl> @ override
public class videoitemdetailfragment extends fragment { <nl>  <nl> progressbar . setvisibility ( view . gone ) ; <nl> if ( info . next_video ! = null ) { <nl> - infoitembuilder . setonitemselectedlistener ( new infoitembuilder . onitemselectedlistener ( ) { <nl> - @ override <nl> - public void selected ( string url ) { <nl> - openstreamurl ( url ) ; <nl> - } <nl> - } ) ; <nl> + <nl> + nextstreamview . setvisibility ( view . gone ) ; <nl> } else { <nl> nextstreamview . setvisibility ( view . gone ) ; <nl> activity . findviewbyid ( r . id . detail_similar_title ) . setvisibility ( view . gone ) ; <nl>
public class videoitemlistactivity extends appcompatactivity <nl> " user_report " , r . string . user_report ) ) ; <nl> return true ; <nl> } <nl> + case r . id . action_show_downloads : { <nl> + <nl> + return true ; <nl> + } <nl> default : <nl> return videofragment . onoptionsitemselected ( item ) | | <nl> super . onoptionsitemselected ( item ) ; <nl> mmm a / app / src / main / java / org / schabi / newpipe / download / downloaddialog . java <nl> ppp b / app / src / main / java / org / schabi / newpipe / download / downloaddialog . java <nl>
public class downloaddialog extends dialogfragment { <nl>  <nl> string fname = name . gettext ( ) . tostring ( ) . trim ( ) ; <nl>  <nl> + <nl> while ( mbinder = = null ) ; <nl>  <nl> if ( audio . ischecked ( ) ) { <nl> mmm a / app / src / main / java / org / schabi / newpipe / download / mainactivity . java <nl> ppp b / app / src / main / java / org / schabi / newpipe / download / mainactivity . java <nl>
<nl> + <nl> + package org . schabi . newpipe ; <nl> + <nl> + import android . annotation . suppresslint ; <nl> + import android . app . activity ; <nl> + import android . content . intent ; <nl> + import android . os . build ; <nl> + import android . os . bundle ; <nl> + <nl> + public class panicresponderactivity extends activity { <nl> + <nl> + public static final string panic_trigger_action = " info . guardianproject . panic . action . trigger " ; <nl> + <nl> + @ suppresslint ( " newapi " ) <nl> + @ override <nl> + protected void oncreate ( bundle savedinstancestate ) { <nl> + super . oncreate ( savedinstancestate ) ; <nl> + <nl> + intent intent = getintent ( ) ; <nl> + if ( intent ! = null & & panic_trigger_action . equals ( intent . getaction ( ) ) ) { <nl> + <nl> + exitactivity . exitandremovefromrecentapps ( this ) ; <nl> + } <nl> + <nl> + if ( build . version . sdk_int > = num ) { <nl> + finishandremovetask ( ) ; <nl> + } else { <nl> + finish ( ) ; <nl> + } <nl> + } <nl> + }
public class downloaddialog extends dialogfragment { <nl> default : <nl> log . d ( tag , " lolz " ) ; <nl> } <nl> + / / to avoid hard - coded string like " / storage / emulated / 0 / newpipe " <nl> + final file dir = new file ( defaultpreferences . getstring ( <nl> + " download_path_preference " , <nl> + environment . getexternalstoragedirectory ( ) . getabsolutepath ( ) + " / newpipe " ) ) ; <nl> + if ( ! dir . exists ( ) ) { <nl> + boolean mkdir = dir . mkdir ( ) ; / / attempt to create directory <nl> + if ( ! mkdir & & ! dir . isdirectory ( ) ) { <nl> + log . e ( tag , " cant ' create directory named " + dir . tostring ( ) ) ; <nl> + <nl> + } <nl> + } <nl> downloadmanager dm = ( downloadmanager ) context . getsystemservice ( context . download_service ) ; <nl> downloadmanager . request request = new downloadmanager . request ( <nl> uri . parse ( url ) ) ;
public class videoitemdetailfragment extends fragment { <nl> @ override <nl> public void onclick ( view v ) { <nl> intent intent = new intent ( activity , videoitemlistactivity . class ) ; <nl> - intent . putextra ( videoitemlistactivity . video_info_items , currentvideoinfo . relatedvideos ) ; <nl> + <nl> + arraylist < videopreviewinfo > toparcel = new arraylist < > ( currentvideoinfo . relatedvideos ) ; <nl> + / / why oh why does the parcelable array put method have to be so damn specific <nl> + / / about the class of its argument ? <nl> + / / why not a list < ? extends parcelable > ? <nl> + intent . putparcelablearraylistextra ( videoitemlistactivity . video_info_items , toparcel ) ; <nl> activity . startactivity ( intent ) ; <nl> } <nl> } ) ; <nl> mmm a / app / src / main / java / org / schabi / newpipe / services / youtube / youtubeextractor . java <nl> ppp b / app / src / main / java / org / schabi / newpipe / services / youtube / youtubeextractor . java <nl>
public class youtubeextractor extends extractor { <nl> relatedvideos . add ( extractvideopreviewinfo ( li ) ) ; <nl> } <nl> } <nl> - videoinfo . relatedvideos = relatedvideos . toarray ( new videopreviewinfo [ relatedvideos . size ( ) ] ) ; <nl> + <nl> + videoinfo . relatedvideos = relatedvideos ; <nl> + / / videoinfo . relatedvideos = relatedvideos . toarray ( new videopreviewinfo [ relatedvideos . size ( ) ] ) ; <nl> return videoinfo ; <nl> }
public class youtubeextractor implements extractor { <nl> document doc = jsoup . parse ( site , siteurl ) ; <nl>  <nl> videoinfo . id = matchgroup1 ( " v = ( [ 0 - 9a - za - z_ - ] { 11 } ) " , siteurl ) ; <nl> + string timestamp = matchgroup1 ( " ( ( # | & ) t = \ \ d { 0 , 3 } h ? \ \ d { 0 , 3 } m ? \ \ d { 1 , 3 } s ) " , siteurl ) ; <nl> + log . i ( tag , " time stamp : " + timestamp ) ; <nl> + / / videoinfo . startposition <nl> + <nl> + <nl> + if ( timestamp . length ( ) > num ) { <nl> + string secondsstring = matchgroup1 ( " ( \ \ d { 1 , 3 } ) s " , timestamp ) ; <nl> + string minutesstring = matchgroup1 ( " ( \ \ d { 1 , 3 } ) m " , timestamp ) ; <nl> + string hoursstring = matchgroup1 ( " ( \ \ d { 1 , 3 } ) h " , timestamp ) ; <nl> + <nl> + int seconds = ( secondsstring . length ( ) > num ? integer . parseint ( secondsstring ) : num ) ; <nl> + int minutes = ( minutesstring . length ( ) > num ? integer . parseint ( minutesstring ) : num ) ; <nl> + int hours = ( hoursstring . length ( ) > num ? integer . parseint ( hoursstring ) : num ) ; <nl> + <nl> + videoinfo . startposition = seconds + ( 60 * minutes ) + ( 3600 * hours ) ; / / don ' t trust bodmas ! <nl> + / / the ordering varies internationally <nl> + } / / else , leave videoinfo . startposition as default num <nl>  <nl> videoinfo . age_limit = num ; <nl> videoinfo . webpage_url = siteurl ; <nl>
public class youtubeextractor implements extractor { <nl> . select ( " img " ) . first ( ) <nl> . attr ( " abs : data - thumb " ) ; <nl>  <nl> - / / view count <nl> + <nl> videoinfo . view_count = doc . select ( " meta [ itemprop = interactioncount ] " ) . attr ( " content " ) ; <nl>  <nl> / / next video
public class youtubesearchengine implements searchengine { <nl> string url = builder . build ( ) . tostring ( ) ; <nl>  <nl> string response = downloader . download ( url ) ; <nl> - documentbuilderfactory dbfactory <nl> - = documentbuilderfactory . newinstance ( ) ; <nl> - documentbuilder dbuilder = null ; <nl> - try { <nl> - dbuilder = dbfactory . newdocumentbuilder ( ) ; <nl> - } catch ( parserconfigurationexception e ) { <nl> - e . printstacktrace ( ) ; <nl> - } <nl> + <nl> + <nl> + documentbuilderfactory dbfactory = documentbuilderfactory . newinstance ( ) ; <nl> + documentbuilder dbuilder ; <nl> org . w3c . dom . document doc = null ; <nl> + <nl> try { <nl> + dbuilder = dbfactory . newdocumentbuilder ( ) ; <nl> doc = dbuilder . parse ( new inputsource ( new bytearrayinputstream ( response . getbytes ( " utf - 8 " ) ) ) ) ; <nl> - } catch ( saxexception e ) { <nl> - e . printstacktrace ( ) ; <nl> - } catch ( ioexception e ) { <nl> + doc . getdocumentelement ( ) . normalize ( ) ; <nl> + } catch ( parserconfigurationexception | saxexception | ioexception e ) { <nl> e . printstacktrace ( ) ; <nl> } <nl> - doc . getdocumentelement ( ) . normalize ( ) ; <nl>  <nl> - nodelist nlist = doc . getelementsbytagname ( " completesuggestion " ) ; <nl> - for ( int temp = num ; temp < nlist . getlength ( ) ; temp + + ) { <nl> + if ( doc ! = null ) { <nl> + nodelist nlist = doc . getelementsbytagname ( " completesuggestion " ) ; <nl> + for ( int temp = num ; temp < nlist . getlength ( ) ; temp + + ) { <nl>  <nl> - nodelist nlist1 = doc . getelementsbytagname ( " suggestion " ) ; <nl> - node nnode1 = nlist1 . item ( temp ) <nl> - ; <nl> - if ( nnode1 . getnodetype ( ) = = node . element_node ) { <nl> - org . w3c . dom . element eelement = ( org . w3c . dom . element ) nnode1 ; <nl> - suggestions . add ( eelement . getattribute ( " data " ) ) ; <nl> + nodelist nlist1 = doc . getelementsbytagname ( " suggestion " ) ; <nl> + node nnode1 = nlist1 . item ( temp ) ; <nl> + if ( nnode1 . getnodetype ( ) = = node . element_node ) { <nl> + org . w3c . dom . element eelement = ( org . w3c . dom . element ) nnode1 ; <nl> + suggestions . add ( eelement . getattribute ( " data " ) ) ; <nl> + } <nl> } <nl> + } else { <nl> + log . e ( tag , " great fucking error " ) ; <nl> } <nl> return suggestions ; <nl> }
public class clientbeatchecktask implements runnable { <nl> } <nl>  <nl> private void deleteip ( instance instance ) { <nl> + <nl> try { <nl> namingproxy . request request = namingproxy . request . newrequest ( ) ; <nl> request . appendparam ( " ip " , instance . getip ( ) ) <nl> mmm / dev / null <nl> ppp b / naming / src / main / java / com / alibaba / nacos / naming / web / candistro . java <nl>
<nl> + / * * <nl> + * copyright num netflix , inc . <nl> + * <nl> + * licensed under the apache license , version num . 0 ( the " license " ) ; you may not use this file except in <nl> + * compliance with the license . you may obtain a copy of the license at <nl> + * <nl> + * http : / / www . apache . org / licenses / license - 2 . 0 <nl> + * <nl> + * unless required by applicable law or agreed to in writing , software distributed under the license is <nl> + * distributed on an " as is " basis , without warranties or conditions of any kind , either express or implied . see <nl> + * the license for the specific language governing permissions and limitations under the license . <nl> + * / <nl> + <nl> + package io . reactivex . internal . operators ; <nl> + <nl> + import org . reactivestreams . * ; <nl> + <nl> + import io . reactivex . observable . operator ; <nl> + import io . reactivex . internal . subscriptions . subscriptionarbiter ; <nl> + <nl> + public final class operatorswitchifempty < t > implements operator < t , t > { <nl> + final publisher < ? extends t > other ; <nl> + public operatorswitchifempty ( publisher < ? extends t > other ) { <nl> + this . other = other ; <nl> + } <nl> + <nl> + @ override <nl> + public subscriber < ? super t > apply ( subscriber < ? super t > t ) { <nl> + <nl> + switchifemptysubscriber < t > parent = new switchifemptysubscriber < > ( t , other ) ; <nl> + t . onsubscribe ( parent . arbiter ) ; <nl> + return parent ; <nl> + } <nl> + <nl> + static final class switchifemptysubscriber < t > implements subscriber < t > { <nl> + final subscriber < ? super t > actual ; <nl> + final publisher < ? extends t > other ; <nl> + final subscriptionarbiter arbiter ; <nl> + <nl> + boolean empty ; <nl> + <nl> + public switchifemptysubscriber ( subscriber < ? super t > actual , publisher < ? extends t > other ) { <nl> + this . actual = actual ; <nl> + this . other = other ; <nl> + this . empty = true ; <nl> + this . arbiter = new subscriptionarbiter ( ) ; <nl> + } <nl> + <nl> + @ override <nl> + public void onsubscribe ( subscription s ) { <nl> + arbiter . setsubscription ( s ) ; <nl> + } <nl> + <nl> + @ override <nl> + public void onnext ( t t ) { <nl> + if ( empty ) { <nl> + empty = false ; <nl> + } <nl> + actual . onnext ( t ) ; <nl> + } <nl> + <nl> + @ override <nl> + public void onerror ( throwable t ) { <nl> + actual . onerror ( t ) ; <nl> + } <nl> + <nl> + @ override <nl> + public void oncomplete ( ) { <nl> + if ( empty ) { <nl> + empty = false ; <nl> + other . subscribe ( this ) ; <nl> + } else { <nl> + actual . oncomplete ( ) ; <nl> + } <nl> + } <nl> + } <nl> + }
public final class operatorreplay < t > extends connectableobservable < t > { <nl> * @ param source <nl> * @ return <nl> * / <nl> + <nl> @ suppresswarnings ( " unchecked " ) <nl> - public static < t > connectableobservable < t > create ( observable < ? extends t > source ) { <nl> + public static < t > connectableobservable < t > createfrom ( observable < ? extends t > source ) { <nl> return create ( source , default_unbounded_factory ) ; <nl> } <nl>  <nl>
public class rxringbuffer implements subscription { <nl>  <nl> public static rxringbuffer getspscinstance ( ) { <nl> if ( unsafeaccess . isunsafeavailable ( ) ) { <nl> - / / using synchronizedqueue until issues are solved with spscarrayqueue offer rejection <nl> - / / rxringbufferspmctest . testconcurrency occasionally fails with a <nl> - / / backpressureexception when using spscarrayqueue <nl> - / / return new rxringbuffer ( spsc_pool , size ) ; / / this is the one we were trying to use <nl> - / / return new rxringbuffer ( new spscarrayqueue < object > ( size ) , size ) ; <nl> - / / the performance of this is sufficient ( actually faster in some cases ) <nl> - return new rxringbuffer ( new synchronizedqueue < object > ( size ) , size ) ; <nl> + <nl> + return new rxringbuffer ( spmc_pool , size ) ; <nl> } else { <nl> return new rxringbuffer ( ) ; <nl> } <nl>
public class blockingoperatortoiterator { <nl>  <nl> private notification < ? extends t > take ( ) { <nl> try { <nl> + <nl> notification < ? extends t > n = notifications . poll ( 10000 , timeunit . milliseconds ) ; <nl> if ( n = = null ) { <nl> system . err . println ( " timed out waiting for value . file a bug at github . com / netflix / rxjava " ) ;
public final class operatorconcat < t > implements operator < t , observable < ? extends <nl> subscribenext ( ) ; <nl> } <nl> } <nl> + <nl> void completeinner ( ) { <nl> + request ( 1 ) ; <nl> if ( wip_updater . decrementandget ( this ) > num ) { <nl> subscribenext ( ) ; <nl> } <nl> } <nl> + <nl> void subscribenext ( ) { <nl> object o = queue . poll ( ) ; <nl> if ( nl . iscompleted ( o ) ) { <nl> s . oncompleted ( ) ; <nl> - } else <nl> - if ( o ! = null ) { <nl> + } else if ( o ! = null ) { <nl> observable < ? extends t > obs = nl . getvalue ( o ) ; <nl> subscriber < t > sourcesub = new subscriber < t > ( ) { <nl>  <nl> @ override <nl> public void onnext ( t t ) { <nl> + <nl> s . onnext ( t ) ; <nl> } <nl>  <nl> mmm a / rxjava - core / src / main / java / rx / internal / operators / operatorwindowwithsize . java <nl> ppp b / rxjava - core / src / main / java / rx / internal / operators / operatorwindowwithsize . java <nl>
<nl> ( is ( = [ ] <nl> ( b / into [ ] ( rx / first ( rx / empty ) ) ) ) ) ) <nl>  <nl> + ( deftest test - group - by <nl> + ( let [ xs [ { : k : a : v num } { : k : b : v num } { : k : a : v num } { : k : c : v num } ] ] <nl> + ( testing " with just a key - fn " <nl> + ( is ( = [ [ : a { : k : a : v num } ] <nl> + [ : b { : k : b : v num } ] <nl> + [ : a { : k : a : v num } ] <nl> + [ : c { : k : c : v num } ] ] <nl> + ( - > > xs <nl> + ( rx / seq - > o ) <nl> + ( rx / group - by : k ) <nl> + ( rx / mapcat ( fn [ [ k vo : as me ] ] <nl> + ( is ( instance ? clojure . lang . mapentry me ) ) <nl> + ( rx / map # ( vector k % ) vo ) ) ) <nl> + ( b / into [ ] ) ) ) ) ) <nl> + <nl> + ; <nl> + ; see https : / / github . com / netflix / rxjava / commit / <commit_id> <nl> + # _ ( testing " with a val - fn " <nl> + ( is ( = [ [ : a num ] <nl> + [ : b num ] <nl> + [ : a num ] <nl> + [ : c num ] ] <nl> + ( - > > xs <nl> + ( rx / seq - > o ) <nl> + ( rx / group - by : k : v ) <nl> + ( rx / mapcat ( fn [ [ k vo : as me ] ] <nl> + ( is ( instance ? clojure . lang . mapentry me ) ) <nl> + ( rx / map # ( vector k % ) vo ) ) ) <nl> + ( b / into [ ] ) ) ) ) ) <nl> + ) ) <nl> ( deftest test - interpose <nl> ( is ( = ( interpose \ , [ 1 num num ] ) <nl> ( b / into [ ] ( rx / interpose \ , ( rx / seq - > o [ 1 num num ] ) ) ) ) ) )
<nl> ( set ! * warn - on - reflection * true ) <nl>  <nl> ( defn chunk <nl> - " same as rx . observable . merge ( observable < observable < t > > ) but the input observables <nl> + " extremely experimental and subject to change or deletion <nl> + <nl> + <nl> + <nl> + same as rx . observable . merge ( observable < observable < t > > ) but the input observables <nl> are \ " chunked \ " so that at most chunk - size of them are \ " in flight \ " at any given <nl> time . <nl>  <nl>
import rx . subscriptions . subscriptions ; <nl> * you can use this to prevent errors from propagating or to supply fallback data should errors be <nl> * encountered . <nl> * / <nl> - public final class operationonerrorresumenextviafunction < t > { <nl> + public final class operatoronerrorresumenextviafunction < t > implements operator < t , t > { <nl>  <nl> - public static < t > onsubscribefunc < t > onerrorresumenextviafunction ( observable < ? extends t > originalsequence , func1 < throwable , ? extends observable < ? extends t > > resumefunction ) { <nl> - return new onerrorresumenextviafunction < t > ( originalsequence , resumefunction ) ; <nl> + private final func1 < throwable , ? extends observable < ? extends t > > resumefunction ; <nl> + <nl> + operatoronerrorresumenextviafunction ( func1 < throwable , ? extends observable < ? extends t > > f ) { <nl> + this . resumefunction = f ; <nl> + } <nl> + <nl> + @ override <nl> + public subscriber < ? super t > call ( subscriber < ? super t > t1 ) { <nl> + <nl> + return null ; <nl> } <nl>  <nl> private static class onerrorresumenextviafunction < t > implements onsubscribefunc < t > { <nl>
public class operatorparalleltest { <nl>  <nl> @ override <nl> public integer [ ] call ( integer t ) { <nl> + try { <nl> + / / randomize to try and force non - determinism <nl> + / / if we see these tests fail randomly then we have a problem with merging it all back together <nl> + thread . sleep ( ( int ) ( math . random ( ) * num ) ) ; <nl> + } catch ( interruptedexception e ) { <nl> + system . out . println ( " * * * * * * * * * * * error ! ! ! ! ! ! ! " ) ; <nl> + e . printstacktrace ( ) ; <nl> + <nl> + throw new runtimeexception ( e ) ; <nl> + } <nl> + / / system . out . println ( " v : " + t + " thread : " + thread . currentthread ( ) ) ; <nl> + innercount . incrementandget ( ) ; <nl> return new integer [ ] { t , t * num } ; <nl> } <nl>  <nl> } ) ; <nl> } <nl> - } ) . toblockingobservable ( ) . foreach ( new action1 < integer [ ] > ( ) { <nl> + } ) <nl> + . toblockingobservable ( ) . foreach ( new action1 < integer [ ] > ( ) { <nl> + <nl> + @ override <nl> + public void call ( integer [ ] v ) { <nl> + count . incrementandget ( ) ; <nl> + / / system . out . println ( " v : " + v [ 0 ] + " r : " + v [ 1 ] + " thread : " + thread . currentthread ( ) ) ; <nl> + } <nl> + <nl> + } ) ; <nl> + system . out . println ( " parallel test completed - - - - - - - - - - " ) ; <nl> + <nl> + / / just making sure we finish and get the number we expect <nl> + assertequals ( " innercount " , num , innercount . get ( ) ) ; <nl> + assertequals ( " finalcount " , num , count . get ( ) ) ; <nl> + } <nl> + <nl> + @ test <nl> + public void testparallelwithnestedasyncwork ( ) { <nl> + int num = num ; <nl> + final atomicinteger count = new atomicinteger ( ) ; <nl> + observable . range ( 1 , num ) . parallel ( <nl> + new func1 < observable < integer > , observable < string > > ( ) { <nl> + <nl> + @ override <nl> + public observable < string > call ( observable < integer > o ) { <nl> + return o . flatmap ( new func1 < integer , observable < string > > ( ) { <nl> + <nl> + @ override <nl> + public observable < string > call ( integer t ) { <nl> + return observable . from ( string . valueof ( t ) ) . delay ( 100 , timeunit . milliseconds ) ; <nl> + } <nl> + <nl> + } ) ; <nl> + } <nl> + } ) . toblockingobservable ( ) . foreach ( new action1 < string > ( ) { <nl>  <nl> @ override <nl> - public void call ( integer [ ] v ) { <nl> + public void call ( string v ) { <nl> count . incrementandget ( ) ; <nl> - system . out . println ( " v : " + v [ 0 ] + " r : " + v [ 1 ] + " thread : " + thread . currentthread ( ) ) ; <nl> } <nl>  <nl> } ) ;
public class observable < t > { <nl> * @ see < a href = " https : / / github . com / netflix / rxjava / wiki / observable - utility - operators # wiki - parallel " > rxjava wiki : parallel ( ) < / a > <nl> * / <nl> public final < r > observable < r > parallel ( func1 < observable < t > , observable < r > > f ) { <nl> - return lift ( new operatorparallel < t , r > ( f , schedulers . computation ( ) ) ) ; <nl> + <nl> + return lift ( new operatorparallel < t , r > ( f , schedulers . newthread ( ) ) ) ; <nl> } <nl>  <nl> / * *
<nl> ( reify <nl> ; if they want func1 , give them onsubscribe as well so observable / create can be <nl> ; used seemlessly with rx / fn . <nl> + ; <nl> ~ @ ( if ( and ( = prefix " rx . util . functions . func " ) <nl> ( some # { 1 } arities ) ) <nl> ` ( rx . observable $ onsubscribefunc <nl> ( ~ ' onsubscribe [ ~ ' this observer # ] <nl> ( ~ f - name observer # ) ) ) ) <nl>  <nl> + ; onsubscribe is just an action1 , so add it to the list of implemented interfaces <nl> + ; so an action cab be used with observable / create <nl> + ~ @ ( if ( and ( = prefix " rx . util . functions . action " ) <nl> + ( some # { 1 } arities ) ) <nl> + ` ( rx . observable $ onsubscribe ) ) <nl> + <nl> ~ @ ( mapcat ( clojure . core / fn [ n ] <nl> ( let [ ifc - sym ( symbol ( str prefix n ) ) <nl> arg - syms ( map # ( symbol ( str " v " % ) ) ( range n ) ) ] <nl>
subprojects { <nl> module { <nl> / / include ' provided ' dependencies on the classpath <nl> scopes . provided . plus + = configurations . provided <nl> + <nl> } <nl> } <nl> }
<nl> + package rx ; <nl> + <nl> + import rx . subscriptions . compositesubscription ; <nl> + <nl> + public abstract class operator < t > implements observer < t > , subscription { <nl> + <nl> + private final compositesubscription cs ; <nl> + <nl> + <nl> + protected operator ( operator < ? > op ) { <nl> + this . cs = op . cs ; <nl> + } <nl> + <nl> + protected operator ( compositesubscription cs ) { <nl> + this . cs = cs ; <nl> + } <nl> + <nl> + public static < t > operator < t > create ( final observer < ? super t > o , compositesubscription cs ) { <nl> + if ( o = = null ) { <nl> + throw new illegalargumentexception ( " observer can not be null " ) ; <nl> + } <nl> + if ( cs = = null ) { <nl> + throw new illegalargumentexception ( " compositesubscription can not be null " ) ; <nl> + } <nl> + return new operator < t > ( cs ) { <nl> + <nl> + @ override <nl> + public void oncompleted ( ) { <nl> + o . oncompleted ( ) ; <nl> + } <nl> + <nl> + @ override <nl> + public void onerror ( throwable e ) { <nl> + o . onerror ( e ) ; <nl> + } <nl> + <nl> + @ override <nl> + public void onnext ( t v ) { <nl> + o . onnext ( v ) ; <nl> + } <nl> + <nl> + } ; <nl> + } <nl> + <nl> + public static < t > operator < t > create ( final observer < ? super t > o , subscription s ) { <nl> + if ( s = = null ) { <nl> + throw new illegalargumentexception ( " subscription can not be null " ) ; <nl> + } <nl> + compositesubscription cs = new compositesubscription ( ) ; <nl> + cs . add ( s ) ; <nl> + <nl> + return create ( o , cs ) ; <nl> + } <nl> + <nl> + / * * <nl> + * used to register an unsubscribe callback . <nl> + * / <nl> + public final void add ( subscription s ) { <nl> + cs . add ( s ) ; <nl> + } <nl> + <nl> + @ override <nl> + public final void unsubscribe ( ) { <nl> + cs . unsubscribe ( ) ; <nl> + } <nl> + <nl> + public final boolean isunsubscribed ( ) { <nl> + return cs . isunsubscribed ( ) ; <nl> + } <nl> + } <nl> \ no newline at end of file
object observable { <nl> } <nl> ` ` ` <nl>  <nl> - the major changes in ` observable ` are wrt to the factory methods * can ' t write this when i don ' t have samuel ' s changes * . <nl> + the major changes in ` observable ` are wrt to the factory methods * <nl>  <nl> subject <nl> - - - - - - -
trait scheduler { <nl>  <nl> } <nl>  <nl> + <nl> private [ scala ] object scheduler { <nl> def apply ( scheduler : rx . scheduler ) : scheduler = { <nl> new scheduler ( ) { <nl> mmm a / language - adaptors / rxjava - scala / src / main / scala / rx / lang / scala / subscriptions / booleansubscription . scala <nl> ppp b / language - adaptors / rxjava - scala / src / main / scala / rx / lang / scala / subscriptions / booleansubscription . scala <nl>
<nl> + package rx ; <nl> + <nl> + import static org . junit . assert . * ; <nl> + <nl> + import java . util . arraylist ; <nl> + import java . util . list ; <nl> + import java . util . concurrent . timeunit ; <nl> + <nl> + import org . junit . test ; <nl> + <nl> + import rx . concurrency . testscheduler ; <nl> + import rx . util . functions . action1 ; <nl> + <nl> + public class refcounttest { <nl> + <nl> + @ test <nl> + public void testrefcount ( ) { <nl> + testscheduler s = new testscheduler ( ) ; <nl> + observable < long > interval = observable . interval ( 100 , timeunit . milliseconds , s ) . publish ( ) . refcount ( ) ; <nl> + <nl> + / / subscribe list1 <nl> + final list < long > list1 = new arraylist < long > ( ) ; <nl> + subscription s1 = interval . subscribe ( new action1 < long > ( ) { <nl> + <nl> + @ override <nl> + public void call ( long t1 ) { <nl> + list1 . add ( t1 ) ; <nl> + } <nl> + <nl> + } ) ; <nl> + s . advancetimeby ( 200 , timeunit . milliseconds ) ; <nl> + <nl> + assertequals ( 2 , list1 . size ( ) ) ; <nl> + assertequals ( 0l , list1 . get ( 0 ) . longvalue ( ) ) ; <nl> + assertequals ( 1l , list1 . get ( 1 ) . longvalue ( ) ) ; <nl> + <nl> + / / subscribe list2 <nl> + final list < long > list2 = new arraylist < long > ( ) ; <nl> + subscription s2 = interval . subscribe ( new action1 < long > ( ) { <nl> + <nl> + @ override <nl> + public void call ( long t1 ) { <nl> + list2 . add ( t1 ) ; <nl> + } <nl> + <nl> + } ) ; <nl> + s . advancetimeby ( 300 , timeunit . milliseconds ) ; <nl> + <nl> + / / list num should have num items <nl> + assertequals ( 5 , list1 . size ( ) ) ; <nl> + assertequals ( 2l , list1 . get ( 2 ) . longvalue ( ) ) ; <nl> + assertequals ( 3l , list1 . get ( 3 ) . longvalue ( ) ) ; <nl> + assertequals ( 4l , list1 . get ( 4 ) . longvalue ( ) ) ; <nl> + <nl> + / / list num should only have num items <nl> + assertequals ( 3 , list2 . size ( ) ) ; <nl> + assertequals ( 2l , list2 . get ( 0 ) . longvalue ( ) ) ; <nl> + assertequals ( 3l , list2 . get ( 1 ) . longvalue ( ) ) ; <nl> + assertequals ( 4l , list2 . get ( 2 ) . longvalue ( ) ) ; <nl> + <nl> + / / unsubscribe list1 <nl> + s1 . unsubscribe ( ) ; <nl> + <nl> + / / advance further <nl> + s . advancetimeby ( 300 , timeunit . milliseconds ) ; <nl> + <nl> + / / list num should still have num items <nl> + assertequals ( 5 , list1 . size ( ) ) ; <nl> + <nl> + / / list num should have num items <nl> + assertequals ( 6 , list2 . size ( ) ) ; <nl> + assertequals ( 5l , list2 . get ( 3 ) . longvalue ( ) ) ; <nl> + assertequals ( 6l , list2 . get ( 4 ) . longvalue ( ) ) ; <nl> + assertequals ( 7l , list2 . get ( 5 ) . longvalue ( ) ) ; <nl> + <nl> + / / unsubscribe list2 <nl> + s2 . unsubscribe ( ) ; <nl> + <nl> + / / advance further <nl> + s . advancetimeby ( 1000 , timeunit . milliseconds ) ; <nl> + <nl> + <nl> + <nl> + <nl> + / / / / subscribing a new one should start over because the source should have been unsubscribed <nl> + / / / / subscribe list1 <nl> + / / final list < long > list3 = new arraylist < long > ( ) ; <nl> + / / subscription s3 = interval . subscribe ( new action1 < long > ( ) { <nl> + / / <nl> + / / @ override <nl> + / / public void call ( long t1 ) { <nl> + / / list3 . add ( t1 ) ; <nl> + / / } <nl> + / / <nl> + / / } ) ; <nl> + / / s . advancetimeby ( 200 , timeunit . milliseconds ) ; <nl> + / / <nl> + / / assertequals ( 2 , list3 . size ( ) ) ; <nl> + / / assertequals ( 0l , list3 . get ( 0 ) . longvalue ( ) ) ; <nl> + / / assertequals ( 1l , list3 . get ( 1 ) . longvalue ( ) ) ; <nl> + <nl> + } <nl> + }
class completenesstest extends junitsuite { <nl> " you can use ` fold ` instead to accumulate ` sum ` and ` numberofelements ` and divide at the end . ] " <nl>  <nl> val commentforfirstwithpredicate = " [ use ` . filter ( condition ) . first ` ] " <nl> + <nl> + val fromfuture = " [ <nl> + " common base interface for future and observable ? and should futures also have an unsubscribe method ? ] " <nl>  <nl> val correspondence = defaultmethodcorrespondence + + map ( <nl> / / manually added entries for java instance methods <nl> " aggregate ( func2 [ t , t , t ] ) " - > " reduce ( ( u , u ) = > u ) " , <nl> - " aggregate ( r , func2 [ r , _ > : t , r ] ) " - > " fold ( r ) ( ( r , t ) = > r ) " , <nl> + " aggregate ( r , func2 [ r , _ > : t , r ] ) " - > " foldleft ( r ) ( ( r , t ) = > r ) " , <nl> " all ( func1 [ _ > : t , boolean ] ) " - > " forall ( t = > boolean ) " , <nl> " buffer ( long , long , timeunit ) " - > " buffer ( duration , duration ) " , <nl> " buffer ( long , long , timeunit , scheduler ) " - > " buffer ( duration , duration , scheduler ) " , <nl>
<nl> + package rx . lang . scala . concurrency <nl> + <nl> + import scala . concurrent . duration . duration <nl> + import rx . lang . scala . subscription <nl> + import rx . lang . scala . scheduler <nl> + import rx . lang . scala . implicitfunctionconversions . _ <nl> + import rx . util . functions . func2 <nl> + import java . util . concurrent . timeunit <nl> + <nl> + <nl> + <nl> + class testscheduler extends scheduler { <nl> + <nl> + private val asjava = new rx . concurrency . testscheduler <nl> + <nl> + override def now : long = asjava . now <nl> + <nl> + def advancetimeby ( time : duration ) { <nl> + asjava . advancetimeby ( time . length , time . unit ) <nl> + } <nl> + <nl> + def advancetimeto ( time : duration ) { <nl> + asjava . advancetimeto ( time . length , time . unit ) <nl> + } <nl> + <nl> + def triggeractions ( ) { <nl> + asjava . triggeractions ( ) <nl> + } <nl> + <nl> + def schedule [ t ] ( state : t , action : ( scheduler , t ) = > subscription ) : subscription = { <nl> + asjava . schedule ( state , action ) <nl> + } <nl> + <nl> + def schedule [ t ] ( state : t , action : ( scheduler , t ) = > subscription , delay : duration ) : subscription = { <nl> + asjava . schedule ( state , action , delay . length , delay . unit ) <nl> + } <nl> + <nl> + override def schedule [ t ] ( state : t , action : func2 [ _ > : scheduler , _ > : t , _ < : subscription ] ) : subscription = { <nl> + asjava . schedule ( state , action ) <nl> + } <nl> + <nl> + override def schedule [ t ] ( state : t , action : func2 [ _ > : scheduler , _ > : t , _ < : subscription ] , delaytime : long , unit : timeunit ) : subscription = { <nl> + asjava . schedule ( state , action , delaytime , unit ) <nl> + } <nl> + <nl> + }
package object util { <nl>  <nl> class timestamped [ + t ] ( val asjava : rx . util . timestamped [ _ < : t ] ) { } <nl>  <nl> - object timestamped { <nl> + <nl> + object timestampedobject { <nl> def apply [ t ] ( timestampmillis : long , value : t ) : timestamped [ t ] = { <nl> new timestamped ( new rx . util . timestamped ( timestampmillis , value ) ) <nl> }
object olympics { <nl> val neveruseddummymedal = medal ( 3333 , " ? " , " ? " , " ? " , " ? " , " ? " ) <nl>  <nl> def fouryearsempty : observable [ medal ] = { <nl> - observable . interval ( fouryears ) . take ( 1 ) . map ( i = > neveruseddummymedal ) . filter ( m = > false ) <nl> + <nl> + / / so we don ' t use this : <nl> + / / observable . interval ( fouryears ) . take ( 1 ) . map ( i = > neveruseddummymedal ) . filter ( m = > false ) <nl> + / / but we just return empty , which completes immediately <nl> + observable ( ) <nl> } <nl>  <nl> } <nl> \ no newline at end of file <nl> mmm a / language - adaptors / rxjava - scala / src / main / scala / rx / lang / scala / examples / rxscalademo . scala <nl> ppp b / language - adaptors / rxjava - scala / src / main / scala / rx / lang / scala / examples / rxscalademo . scala <nl>
class observable [ + t ] ( val asjava : rx . observable [ _ < : t ] ) extends anyval { <nl> * <nl> * @ return an observable that emits timestamped items from the source observable <nl> * / <nl> + <nl> + / * <nl> def timestamp : observable [ timestamped [ t ] ] = { <nl> new observable ( asjava . timestamp ( ) ) <nl> } <nl> - <nl> * / <nl>  <nl> + <nl> } <nl>  <nl> object observable { <nl>
public class observable < t > { <nl> this . onsubscribe = onsubscribe ; <nl> } <nl>  <nl> + protected observable ( ) { <nl> + this ( null ) ; <nl> + <nl> + } <nl> + <nl> / * * <nl> * an { @ link observer } must call an observable ' s < code > subscribe < / code > method in order to register itself <nl> * to receive push - based notifications from the observable . a typical implementation of the
public final class operationconcat { <nl>  <nl> } <nl>  <nl> + <nl> + <nl> + @ test <nl> + public void testconcatunsubscribenotblockingobservables ( ) { <nl> + <nl> + final countdownlatch oktocontinuew1 = new countdownlatch ( 1 ) ; <nl> + final countdownlatch oktocontinuew2 = new countdownlatch ( 1 ) ; <nl> + <nl> + final testobservable < string > w1 = new testobservable < string > ( null , oktocontinuew1 , " one " , " two " , " three " ) ; <nl> + final testobservable < string > w2 = new testobservable < string > ( null , oktocontinuew2 , " four " , " five " , " six " ) ; <nl> + <nl> + @ suppresswarnings ( " unchecked " ) <nl> + observer < string > aobserver = mock ( observer . class ) ; <nl> + observable < observable < string > > observableofobservables = observable . create ( new func1 < observer < observable < string > > , subscription > ( ) { <nl> + <nl> + @ override <nl> + public subscription call ( observer < observable < string > > observer ) { <nl> + / / simulate what would happen in an observable <nl> + observer . onnext ( w1 ) ; <nl> + observer . onnext ( w2 ) ; <nl> + observer . oncompleted ( ) ; <nl> + <nl> + return new subscription ( ) { <nl> + <nl> + @ override <nl> + public void unsubscribe ( ) { <nl> + } <nl> + <nl> + } ; <nl> + } <nl> + <nl> + } ) ; <nl> + observable < string > concat = observable . create ( concat ( observableofobservables ) ) ; <nl> + <nl> + concat . subscribe ( aobserver ) ; <nl> + <nl> + verify ( aobserver , times ( 0 ) ) . oncompleted ( ) ; <nl> + <nl> + <nl> + / / wait for the thread to start up . <nl> + try { <nl> + thread . sleep ( 25 ) ; <nl> + w1 . t . join ( ) ; <nl> + w2 . t . join ( ) ; <nl> + oktocontinuew1 . countdown ( ) ; <nl> + oktocontinuew2 . countdown ( ) ; <nl> + } catch ( interruptedexception e ) { <nl> + <nl> + e . printstacktrace ( ) ; <nl> + } <nl> + <nl> + inorder inorder = inorder ( aobserver ) ; <nl> + inorder . verify ( aobserver , times ( 1 ) ) . onnext ( " one " ) ; <nl> + inorder . verify ( aobserver , times ( 1 ) ) . onnext ( " two " ) ; <nl> + inorder . verify ( aobserver , times ( 1 ) ) . onnext ( " three " ) ; <nl> + inorder . verify ( aobserver , times ( 1 ) ) . onnext ( " four " ) ; <nl> + inorder . verify ( aobserver , times ( 1 ) ) . onnext ( " five " ) ; <nl> + inorder . verify ( aobserver , times ( 1 ) ) . onnext ( " six " ) ; <nl> + verify ( aobserver , times ( 1 ) ) . oncompleted ( ) ; <nl> + <nl> + <nl> + } <nl> + <nl>  <nl> / * * <nl> * test unsubscribing the concatenated observable in a single thread . <nl>
public final class operationconcat { <nl>  <nl> } <nl>  <nl> + @ test <nl> + public void testconcatconcurrentwithinfinityfirstsequence ( ) { <nl> + final testobservable < string > w1 = new testobservable < string > ( " one " , " two " , " three " ) ; <nl> + / / this observable will send " hello " max_value time . <nl> + final testobservable < string > w2 = new testobservable < string > ( " hello " , integer . max_value ) ; <nl> + <nl> + @ suppresswarnings ( " unchecked " ) <nl> + observer < string > aobserver = mock ( observer . class ) ; <nl> + @ suppresswarnings ( " unchecked " ) <nl> + testobservable < observable < string > > observableofobservables = new testobservable < observable < string > > ( w2 , w1 ) ; <nl> + func1 < observer < string > , subscription > concatf = concat ( observableofobservables ) ; <nl> + <nl> + observable < string > concat = observable . create ( concatf ) ; <nl> + <nl> + concat . take ( 50 ) . subscribe ( aobserver ) ; <nl> + <nl> + / / wait for the thread to start up . <nl> + try { <nl> + thread . sleep ( 25 ) ; <nl> + w2 . t . join ( ) ; <nl> + } catch ( interruptedexception e ) { <nl> + <nl> + e . printstacktrace ( ) ; <nl> + } <nl> + <nl> + inorder inorder = inorder ( aobserver ) ; <nl> + inorder . verify ( aobserver , times ( 50 ) ) . onnext ( " hello " ) ; <nl> + verify ( aobserver , times ( 1 ) ) . oncompleted ( ) ; <nl> + verify ( aobserver , never ( ) ) . onerror ( any ( exception . class ) ) ; <nl> + <nl> + } <nl> + <nl>  <nl> / * * <nl> * test unsubscribing the concatenated observable in a single thread .
<nl> + package rx . concurrency ; <nl> + <nl> + import rx . subscription ; <nl> + import rx . util . functions . func0 ; <nl> + <nl> + import java . util . concurrent . scheduledexecutorservice ; <nl> + import java . util . concurrent . timeunit ; <nl> + <nl> + <nl> + public class scheduledexecutorservicescheduler extends abstractscheduler { <nl> + private final scheduledexecutorservice executorservice ; <nl> + <nl> + public scheduledexecutorservicescheduler ( scheduledexecutorservice executorservice ) { <nl> + this . executorservice = executorservice ; <nl> + } <nl> + <nl> + @ override <nl> + public subscription schedule ( func0 < subscription > action ) { <nl> + return schedule ( action , num , timeunit . milliseconds ) ; <nl> + } <nl> + <nl> + @ override <nl> + public subscription schedule ( func0 < subscription > action , long timespan , timeunit unit ) { <nl> + final discardableaction discardableaction = new discardableaction ( action ) ; <nl> + executorservice . schedule ( new runnable ( ) { <nl> + @ override <nl> + public void run ( ) { <nl> + discardableaction . call ( ) ; <nl> + } <nl> + } , timespan , unit ) ; <nl> + return discardableaction ; <nl> + } <nl> + <nl> + }
<nl> < artifactid > rocketmq - spring - boot - starter < / artifactid > <nl> < version > $ { rocketmq . starter . version } < / version > <nl> < / dependency > <nl> + <nl> + < ! - - <nl> + <nl> + check it every times , whern spring - boot - starter - webflux : 2 . 2 . 4 . release or spring - cloud - gateway - core : 2 . 2 . 2 . release has bean upgrade <nl> + due to spring - cloud - build : 2 . 2 . 2 . release has not support spring - cloud - gateway - dependencies : 2 . 2 . 2 . release very well <nl> + it cource some compatibility problem between reactornettywebsocketclient and gatewayautoconfiguration <nl> + - - > <nl> + < dependency > <nl> + < groupid > org . springframework < / groupid > <nl> + < artifactid > spring - web < / artifactid > <nl> + < version > 5 . 2 . 4 . release < / version > <nl> + < / dependency > <nl> + < dependency > <nl> + < groupid > org . springframework < / groupid > <nl> + < artifactid > spring - webflux < / artifactid > <nl> + < version > 5 . 2 . 4 . release < / version > <nl> + < scope > compile < / scope > <nl> + < / dependency > <nl> < / dependencies > <nl> < / dependencymanagement >
public class systemmetricdataserviceimpl implements systemmetricdataservice { <nl> metricdatatype metricdatatype = systemmetricdatatypeservice . getmetricdatatype ( metricdataname ) ; <nl> list < metrictag > metrictaglist = systemmetrichostinfoservice . gettag ( metricdatasearchkey , field ) ; <nl>  <nl> + <nl> + metricdatatype = metricdatatype . double ; <nl> for ( metrictag metrictag : metrictaglist ) { <nl> switch ( metricdatatype ) { <nl> case long :
export class periodselectorcontainercomponent implements oninit , ondestroy { <nl> } else { <nl> this . analyticsservice . trackevent ( tracked_event_list . select_period , selectedperiod ) ; <nl>  <nl> - const tree = this . router . parseurl ( this . router . url ) ; <nl> - const g = tree . root . children [ primary_outlet ] ; <nl> - const s = g . segments ; <nl> + <nl> + / / const g = tree . root . children [ primary_outlet ] ; <nl> + / / const s = g . segments ; <nl>  <nl> this . urlroutemanagerservice . move ( { <nl> url : [ <nl> this . newurlstatenotificationservice . getstartpath ( ) , <nl> - / / this . newurlstatenotificationservice . getpathvalue ( urlpathid . application ) . geturlstr ( ) , <nl> + this . newurlstatenotificationservice . getpathvalue ( urlpathid . application ) . geturlstr ( ) , <nl> / / this . router . url [ 1 ] , <nl> - s [ 1 ] . path , <nl> + / / s [ 1 ] . path , <nl> selectedperiod <nl> ] , <nl> needservertimerequest : true , <nl> - / / nexturl : this . newurlstatenotificationservice . hasvalue ( urlpathid . agent_id ) ? [ this . newurlstatenotificationservice . getpathvalue ( urlpathid . agent_id ) ] : [ ] <nl> - nexturl : s [ 4 ] ? [ s [ 4 ] . path ] : [ ] <nl> + nexturl : this . newurlstatenotificationservice . hasvalue ( urlpathid . agent_id ) ? [ this . newurlstatenotificationservice . getpathvalue ( urlpathid . agent_id ) ] : [ ] <nl> + / / nexturl : s [ 4 ] ? [ s [ 4 ] . path ] : [ ] <nl> } ) ; <nl> } <nl> } <nl> mmm a / web / src / main / angular / src / proxy . conf . js <nl> ppp b / web / src / main / angular / src / proxy . conf . js <nl>
public class mariadb_2_4_x_it extends mariadb_it_base { <nl> method executequery = jdbcapi . getpreparedstatement ( ) . getexecutequery ( ) ; <nl> verifier . verifytrace ( event ( db_execute_query , executequery , null , url , database_name , sql ( callable_statement_query , null , callable_statement_input_param ) ) ) ; <nl>  <nl> - / / mariadbconnection # preparestatement ( string ) <nl> - method preparestatement = jdbcapi . getconnection ( ) . getpreparestatement ( ) ; <nl> - verifier . verifytrace ( event ( db_type , preparestatement , null , url , database_name , sql ( callable_query_meta_infos_query , null ) ) ) ; <nl> + <nl> + if ( tracecount = = num ) { <nl> + / / getint ( ) - > metadata query <nl> + / / mariadb num . 4 . 0 ~ num . 7 . 2 <nl> + / / mariadbconnection # preparestatement ( string ) <nl> + method preparestatement = jdbcapi . getconnection ( ) . getpreparestatement ( ) ; <nl> + verifier . verifytrace ( event ( db_type , preparestatement , null , url , database_name , sql ( callable_query_meta_infos_query , null ) ) ) ; <nl> + <nl> + / / clientsidepreparedstatement # executequery <nl> + method executequeryclient = clientjdbcapi . getpreparedstatement ( ) . getexecutequery ( ) ; <nl> + verifier . verifytrace ( event ( db_execute_query , executequeryclient , null , url , database_name , sql ( callable_query_meta_infos_query , null , getpreparecallbindvariable ( ) ) ) ) ; <nl> + } else if ( tracecount = = num ) { <nl> + / / mariadb num . 7 . 3 ~ <nl> + / / mariadbconnection . getinternalparametermetadata ( ) <nl> + / / clientsidepreparedstatement creation is different . <nl> + method executequerymethod = getmethod ( " org . mariadb . jdbc . clientsidepreparedstatement " , " executequery " ) ; <nl> + verifier . verifytrace ( event ( " unknown_db_execute_query " , executequerymethod , null , " unknown " , " unknown " ) ) ; <nl> + } <nl> + } <nl>  <nl> - / / clientsidepreparedstatement # executequery <nl> - method executequeryclient = clientjdbcapi . getpreparedstatement ( ) . getexecutequery ( ) ; <nl> - verifier . verifytrace ( event ( db_execute_query , executequeryclient , null , url , database_name , sql ( callable_query_meta_infos_query , null , getpreparecallbindvariable ( ) ) ) ) ; <nl> + private method getmethod ( string classname , string methodname , class < ? > . . . parametertypes ) { <nl> + classloader cl = thread . currentthread ( ) . getcontextclassloader ( ) ; <nl> + try { <nl> + class < ? > clazz = cl . loadclass ( classname ) ; <nl> + return clazz . getmethod ( methodname , parametertypes ) ; <nl> + } catch ( exception e ) { <nl> + throw new runtimeexception ( " reflect error " , e ) ; <nl> + } <nl> } <nl>  <nl> public string getpreparecallbindvariable ( ) {
public class setendpointinterceptor implements aroundinterceptor { <nl> } else if ( argzero instanceof jedisshardinfo ) { <nl> final jedisshardinfo info = ( jedisshardinfo ) argzero ; <nl> return hostandport . tohostandportstring ( info . gethost ( ) , info . getport ( ) ) ; <nl> - } else if ( argzero instanceof jedissocketfactory ) { <nl> - final jedissocketfactory factory = ( jedissocketfactory ) argzero ; <nl> - return hostandport . tohostandportstring ( factory . gethost ( ) , factory . getport ( ) ) ; <nl> + <nl> + / / final jedissocketfactory factory = ( jedissocketfactory ) argzero ; <nl> + / / return hostandport . tohostandportstring ( factory . gethost ( ) , factory . getport ( ) ) ; <nl> } <nl> return " unknown " ; <nl> }
public class keepaliveservice { <nl>  <nl> final header header = pingsession . getheader ( ) ; <nl> if ( header = = null ) { <nl> + <nl> logger . warn ( " not found request header " ) ; <nl> return ; <nl> } <nl>
public class keepaliveservice { <nl>  <nl> final long socketid = header . getsocketid ( ) ; <nl> if ( socketid = = - 1 ) { <nl> - logger . info ( " socketid not exist : { } " , header ) ; <nl> + <nl> + logger . warn ( " socketid not exist . header : { } " , header ) ; <nl> / / skip <nl> return ; <nl> }
export class scatterchartcontainercomponent implements oninit , ondestroy { <nl> this . unsubscribe . complete ( ) ; <nl> } <nl>  <nl> + private addeventlistener ( ) : void { <nl> + const visibility $ = fromevent ( document , ' visibilitychange ' ) . pipe ( <nl> + takeuntil ( this . unsubscribe ) , <nl> + filter ( ( ) = > this . scatterchartmode = = = scatterchart . mode . realtime ) <nl> + ) ; <nl> + <nl> + / / visible <nl> + visibility $ . pipe ( <nl> + filter ( ( ) = > ! document . hidden ) , <nl> + ) . subscribe ( ( ) = > { <nl> + <nl> + this . getscatterdata ( ) ; <nl> + } ) ; <nl> + <nl> + / / hidden <nl> + visibility $ . pipe ( <nl> + filter ( ( ) = > document . hidden ) , <nl> + delay ( 10000 ) , <nl> + filter ( ( ) = > document . hidden ) , <nl> + ) . subscribe ( ( ) = > { <nl> + this . scatterchartdataservice . stopload ( ) ; <nl> + } ) ; <nl> + } <nl> + <nl> private setscattery ( ) { <nl> const { min , max } = this . webappsettingdataservice . getscattery ( this . instancekey ) ; <nl>  <nl> mmm a / web / src / main / angular / src / app / core / components / scatter - chart / scatter - chart - data . service . ts <nl> ppp b / web / src / main / angular / src / app / core / components / scatter - chart / scatter - chart - data . service . ts <nl>
public class spanencodertest { <nl> decodingcontext . setcollectoracceptedtime ( spanbo . getcollectoraccepttime ( ) ) ; <nl>  <nl> spanbo decode = ( spanbo ) spandecoder . decode ( qualifier , column , decodingcontext ) ; <nl> - <nl> - logger . debug ( " span dump \noriginal spanbo : { } \ndecode spanbo : { } " , spanbo , decode ) ; <nl> + <nl>  <nl> list < string > notserializedfield = lists . newarraylist ( " parentapplicationid " , " parentapplicationservicetype " ) ; <nl> list < string > excludefield = lists . newarraylist ( " annotationbolist " , " spaneventbolist " ) ; <nl>
public class spanencodertest { <nl> decodingcontext . setcollectoracceptedtime ( spanchunkbo . getcollectoraccepttime ( ) ) ; <nl>  <nl> spanchunkbo decode = ( spanchunkbo ) spandecoder . decode ( qualifier , column , decodingcontext ) ; <nl> - <nl> - logger . debug ( " spanchunk dump \noriginal spanchunkbo : { } \ndecode spanchunkbo : { } " , spanchunkbo , decode ) ; <nl> + <nl>  <nl> list < string > notserializedfield = lists . newarraylist ( " endpoint " , " servicetype " , " applicationservicetype " ) ; <nl> list < string > excludefield = lists . newarraylist ( " spaneventbolist " ) ; <nl> mmm a / profiler - optional / profiler - optional - jdk7 / src / test / java / bug_regression_jdk7 / javassist / javassistverifyerrortest . java <nl> ppp b / profiler - optional / profiler - optional - jdk7 / src / test / java / bug_regression_jdk7 / javassist / javassistverifyerrortest . java <nl>
public class calltreeiteratortest { <nl>  <nl> index + + ; <nl> } <nl> - logger . debug ( buffer . tostring ( ) ) ; <nl> + <nl> } <nl>  <nl> private queue < integer > parseexpected ( string expectedvalues ) {
public class connectorsexecuteroothandlerinterceptor implements aroundintercepto <nl> try { <nl> final httpserverexchange request = ( httpserverexchange ) args [ 1 ] ; <nl> final int statuscode = getstatuscode ( request ) ; <nl> - final throwable t = getexception ( request ) ; <nl> - this . servletrequestlistenerinterceptorhelper . destroyed ( request , t , statuscode ) ; <nl> + <nl> + this . servletrequestlistenerinterceptorhelper . destroyed ( request , throwable , statuscode ) ; <nl> } catch ( throwable t ) { <nl> if ( isinfo ) { <nl> logger . info ( " failed to servlet request event handle . " , t ) ; <nl>
public class wrappedspaneventrecorder extends abstractrecorder implements spanev <nl> final asyncstate asyncstate = this . asyncstate ; <nl> if ( asyncstatesupport & & asyncstate ! = null ) { <nl> asyncstate . setup ( ) ; <nl> - return asynccontextfactory . newasynccontext ( traceroot , asyncstate ) ; <nl> + final asynccontext asynccontext = asynccontextfactory . newasynccontext ( traceroot , asyncstate ) ; <nl> + setnextasyncid ( spanevent , asynccontext . getasyncid ( ) ) ; <nl> + return asynccontext ; <nl> } <nl>  <nl> - return asynccontextfactory . newasynccontext ( traceroot ) ; <nl> + final asynccontext asynccontext = asynccontextfactory . newasynccontext ( traceroot ) ; <nl> + setnextasyncid ( spanevent , asynccontext . getasyncid ( ) ) ; <nl> + return asynccontext ; <nl> + } <nl> + <nl> + private void setnextasyncid ( spanevent spanevent , int asyncid ) { <nl> + <nl> + spanevent . setnextasyncid ( asyncid ) ; <nl> } <nl>  <nl> @ deprecated
public final class apiutils { <nl> final string methoddesc = apidescriptor . substring ( methoddescbegin + num , methoddescend ) ; <nl> final string [ ] parametertypes = methoddesc . split ( " , " ) ; <nl> for ( int i = num ; i < parametertypes . length ; i + + ) { <nl> - final int end = parametertypes [ i ] . indexof ( " " ) ; <nl> - if ( end ! = - 1 ) { <nl> - parametertypes [ i ] = parametertypes [ i ] . substring ( 0 , end ) ; <nl> - } <nl> + final string parametertype = parametertypes [ i ] ; <nl> + parametertypes [ i ] = extractparameterclass ( parametertype ) ; <nl> } <nl> - <nl> return tomethoddescriptor ( classname , methodname , parametertypes ) ; <nl> } <nl> + <nl> + private static string extractparameterclass ( string parametertype ) { <nl> + parametertype = safetrim ( parametertype ) ; <nl> + final int classendindex = parametertype . indexof ( ' ' ) ; <nl> + if ( classendindex ! = - 1 ) { <nl> + return parametertype . substring ( 0 , classendindex ) ; <nl> + } <nl> + / / else { <nl> + / / <nl> + / / } <nl> + return parametertype ; <nl> + } <nl> + <nl> + private static string safetrim ( string parametertype ) { <nl> + if ( parametertype = = null | | parametertype . isempty ( ) ) { <nl> + return parametertype ; <nl> + } <nl> + return parametertype . trim ( ) ; <nl> + } <nl> } <nl> \ no newline at end of file <nl> mmm a / profiler / src / test / java / com / navercorp / pinpoint / profiler / util / apiutilstest . java <nl> ppp b / profiler / src / test / java / com / navercorp / pinpoint / profiler / util / apiutilstest . java <nl>
public class spanencoder { <nl> final int asyncid2 = o2 . getasyncid ( ) ; <nl> final int asyncidcompare = integer . compare ( asyncid1 , asyncid2 ) ; <nl> if ( asyncidcompare ! = num ) { <nl> - if ( asyncid1 = = - 1 ) { <nl> - return - 1 ; <nl> - } <nl> - if ( asyncid2 = = - 1 ) { <nl> - return - 1 ; <nl> - } <nl> + / / bug comparison method violates its general contract ! <nl> + <nl> + / / return - 1 ; <nl> + / / } <nl> + / / if ( asyncid2 = = - 1 ) { <nl> + / / return - 1 ; <nl> + / / } <nl> return asyncidcompare ; <nl> } <nl> return integer . compare ( o1 . getasyncsequence ( ) , o2 . getasyncsequence ( ) ) ;
public class mockagent extends defaultagent { <nl>  <nl> } <nl>  <nl> + / * * <nl> + * <nl> + * @ param plugin <nl> + * @ param context <nl> + * / <nl> + private void prepareplugin ( profilerplugin plugin , profilerpluginsetupcontext context ) { <nl> + <nl> + if ( plugin instanceof transformtemplateaware ) { <nl> + transformtemplate transformtemplate = new defaulttransformtemplate ( context ) ; <nl> + ( ( transformtemplateaware ) plugin ) . settransformtemplate ( transformtemplate ) ; <nl> + } <nl> + } <nl> + <nl> + <nl> public static string tostring ( span span ) { <nl> stringbuilder builder = new stringbuilder ( ) ; <nl> builder . append ( ' ( ' ) ;
public class javassistclass implements instrumentclass { <nl> if ( constructor = = null ) { <nl> throw new notfoundinstrumentexception ( " cannot find constructor with parameter types : " + arrays . tostring ( c . value ( ) ) ) ; <nl> } <nl> - <nl> - return constructor . addgroupedinterceptor ( interceptorclassname , constructorargs , group , executionpolicy ) ; <nl> + <nl> + return ( ( javassistmethod ) constructor ) . addinterceptorinternal ( interceptorclassname , constructorargs , group , executionpolicy ) ; <nl> } <nl>  <nl> private int addinterceptor0 ( targetmethod m , string interceptorclassname , object [ ] constructorargs , interceptorgroup group , executionpolicy executionpolicy ) throws instrumentexception { <nl>
public class javassistclass implements instrumentclass { <nl> if ( method = = null ) { <nl> throw new notfoundinstrumentexception ( " cannot find method " + m . name ( ) + " with parameter types : " + arrays . tostring ( m . paramtypes ( ) ) ) ; <nl> } <nl> - <nl> - return method . addgroupedinterceptor ( interceptorclassname , constructorargs , group , executionpolicy ) ; <nl> + <nl> + return ( ( javassistmethod ) method ) . addinterceptorinternal ( interceptorclassname , constructorargs , group , executionpolicy ) ; <nl> } <nl>  <nl> private int addinterceptor0 ( targetfilter annotation , string interceptorclassname , interceptorgroup group , executionpolicy executionpolicy , object [ ] constructorargs ) throws instrumentexception {
public class spanaligner2 { <nl> if ( spanbo ! = null ) { <nl> populate ( spanbo , childdepth , container ) ; <nl> } else { <nl> + <nl> logger . debug ( " nextspanid not found . { } " , nextspanid ) ; <nl> } <nl> }
public abstract class abstractpinpointplugintestsuite extends suite { <nl> try { <nl> for ( int ver : jvmversions ) { <nl> string javaexe = getjavaexecutable ( ver ) ; <nl> + <nl> + <nl> + if ( javaexe = = null ) { <nl> + system . out . println ( " cannot find java version " + ver + " . skip test with java " + ver ) ; <nl> + continue ; <nl> + } <nl> + <nl> pinpointplugintestcontext context = new pinpointplugintestcontext ( agentjar , configfile , requiredlibraries , gettestclass ( ) . getjavaclass ( ) , testclasslocation , jvmarguments , debug , ver , javaexe ) ; <nl>  <nl> list < pinpointplugintestinstance > cases = createtestcases ( context ) ;
public class serverinstancelistserializertest { <nl>  <nl> @ test <nl> public void testserialize ( ) throws exception { <nl> - genericxmlapplicationcontext applicationcontext = new genericxmlapplicationcontext ( " / applicationcontext - web . xml " ) ; <nl> - objectmapper mapper = applicationcontext . getbean ( objectmapper . class ) ; <nl> + <nl> + pinpointobjectmapper mapper = new pinpointobjectmapper ( ) ; <nl> + mapper . afterpropertiesset ( ) ; <nl> + <nl>  <nl> agentinfobo . builder agentinfobuilder = new agentinfobo . builder ( ) ; <nl> agentinfobuilder . setagentid ( " agentid " ) ; <nl> + <nl> agentinfobuilder . setservicetypecode ( servicetype . test_stand_alone . getcode ( ) ) ; <nl> + <nl> + agentinfobuilder . setservicetype ( servicetype . test_stand_alone ) ; <nl> + <nl> agentinfobuilder . sethostname ( " testcomputer " ) ; <nl>  <nl> agentinfobo agentinfobo = agentinfobuilder . build ( ) ;
public class javaassistbytecodeinstrumentor implements bytecodeinstrumentor { <nl>  <nl> @ override <nl> public instrumentclass getclass ( classloader classloader , string javassistclassname , byte [ ] classfilebuffer ) throws instrumentexception { <nl> - checklibrary ( classloader , javassistclassname ) ; <nl> - return getclass ( javassistclassname ) ; <nl> + final namedclasspool classpool = findclasspool ( classloader ) ; <nl> + checklibrary ( classloader , classpool , javassistclassname ) ; <nl> + try { <nl> + ctclass cc = classpool . get ( javassistclassname ) ; <nl> + return new javaassistclass ( this , cc ) ; <nl> + } catch ( notfoundexception e ) { <nl> + throw new instrumentexception ( javassistclassname + " class not found . cause : " + e . getmessage ( ) , e ) ; <nl> + } <nl> + } <nl> + <nl> + private namedclasspool findclasspool ( classloader classloader ) { <nl> + <nl> + return childclasspool ; <nl> } <nl>  <nl> @ override
public class tomcatprofiler implements classfiletransformer { <nl> string [ ] paths = gettomcatlibpath ( ) ; <nl> this . bytecodeinstrumentor = new javaassistbytecodeinstrumentor ( paths ) ; <nl> this . modifierrepository = createmodifierregistry ( bytecodeinstrumentor ) ; <nl> - <nl> } <nl>  <nl> - private string [ ] gettomcatlibpath ( ) { <nl> - string catalinahome = system . getproperty ( " catalina . home " ) ; <nl> - if ( catalinahome = = null ) { <nl> - return null ; <nl> - } <nl> - if ( logger . isloggable ( level . info ) ) { <nl> - logger . info ( " catalina_home = " + catalinahome ) ; <nl> - } <nl> - return new string [ ] { catalinahome + " / lib / servlet - api . jar " , catalinahome + " / lib / catalina . jar " } ; <nl> - } <nl> + private string [ ] gettomcatlibpath ( ) { <nl> + string catalinahome = system . getproperty ( " catalina . home " ) ; <nl> + <nl> + if ( catalinahome = = null ) { <nl> + return null ; <nl> + } <nl> + <nl> + if ( logger . isloggable ( level . info ) ) { <nl> + logger . info ( " catalina_home = " + catalinahome ) ; <nl> + } <nl> + <nl> + <nl> + string type = system . getproperty ( " hippo . servertype " , " tomcat " ) ; <nl> + <nl> + if ( type . equals ( " bloc " ) ) { <nl> + return new string [ ] { catalinahome + " / server / lib / catalina . jar " , catalinahome + " / common / lib / servlet - api . jar " } ; <nl> + } else { <nl> + return new string [ ] { catalinahome + " / lib / servlet - api . jar " , catalinahome + " / lib / catalina . jar " } ; <nl> + } <nl> + } <nl>  <nl> private modifierregistry createmodifierregistry ( bytecodeinstrumentor bytecodeinstrumentor ) { <nl> defaultmodifierregistry modifierrepository = new defaultmodifierregistry ( bytecodeinstrumentor , profilerconfig ) ;
public class span { <nl> span . setendpoint ( endpoint ) ; <nl> span . setterminal ( isterminal ) ; <nl>  <nl> + <nl> + <nl> list < com . profiler . common . dto . thrift . annotation > annotationlist = new arraylist < com . profiler . common . dto . thrift . annotation > ( annotations . size ( ) ) ; <nl> for ( hippoannotation a : annotations ) { <nl> annotationlist . add ( a . tothrift ( ) ) ;
public final class trace { <nl> return id ; <nl> } <nl>  <nl> - public static boolean removetraceid ( ) { <nl> - / / traceid traceid = traceidlocal . get ( ) ; <nl> + public static boolean removecurrenttraceidfromstack ( ) { <nl> traceidstack stack = traceidlocal . get ( ) ; <nl> traceid traceid = null ; <nl> - if ( stack ! = null ) <nl> + <nl> + if ( stack ! = null ) { <nl> traceid = stack . gettraceid ( ) ; <nl> + } else { <nl> + <nl> + system . out . println ( " # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # " ) ; <nl> + system . out . println ( " # something ' s going wrong . stack is not exists . # " ) ; <nl> + system . out . println ( " # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # " ) ; <nl> + <nl> + stack = new traceidstack ( ) ; <nl> + traceidlocal . set ( stack ) ; <nl> + } <nl>  <nl> if ( traceid ! = null ) { <nl> - / / traceidlocal . remove ( ) ; <nl> - <nl> - if ( stack = = null ) { <nl> - traceidlocal . set ( new traceidstack ( ) ) ; <nl> - } <nl> - <nl> - traceidlocal . get ( ) . clear ( ) ; <nl> - <nl> + stack . clear ( ) ; <nl> spanmap . remove ( traceid ) ; <nl> return true ; <nl> } <nl>
public class invokemethodinterceptor implements staticaroundinterceptor { <nl> trace . record ( annotation . serversend , stopwatch . stopandgetelapsed ( " invokemethodinterceptor - starttime " ) ) ; <nl> requesttracer . endtransaction ( ) ; <nl>  <nl> - trace . removetraceid ( ) ; <nl> + <nl> } <nl>  <nl> / * * <nl> mmm a / src / test / java / com / profiler / modifier / db / mysql / mysqlconnectionimplmodifiertest . java <nl> ppp b / src / test / java / com / profiler / modifier / db / mysql / mysqlconnectionimplmodifiertest . java <nl>
public final class trace { <nl> public static void settraceid ( traceid traceid ) { <nl> if ( getcurrenttraceid ( ) ! = null ) { <nl> logger . log ( level . warning , " traceid is already exists . but overwritten . " ) ; <nl> + <nl> + <nl> + system . out . println ( " # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # " ) ; <nl> + system . out . println ( " # [ debug msg ] traceid is overwritten . " ) ; <nl> + system . out . println ( " # before : " + getcurrenttraceid ( ) ) ; <nl> + system . out . println ( " # after : " + traceid ) ; <nl> + system . out . println ( " # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # " ) ; <nl> + try { <nl> + throw new runtimeexception ( " traceid overwritten . " ) ; <nl> + } catch ( exception e ) { <nl> + e . printstacktrace ( ) ; <nl> + } <nl> } <nl> trace . traceidlocal . set ( traceid ) ; <nl> } <nl>
public class invokemethodinterceptor implements staticaroundinterceptor { <nl>  <nl> / / record <nl> if ( traceid ! = null ) { <nl> - trace . settraceid ( new traceid ( traceid , parentspanid , spanid , sampled , flags ) ) ; <nl> + traceid id = new traceid ( traceid , parentspanid , spanid , sampled , flags ) ; <nl> + <nl> + <nl> + system . out . println ( " \n\n\ngot a traceid . traceid = " + id + " \n\n\n " ) ; <nl> + <nl> + trace . settraceid ( id ) ; <nl> } else { <nl> trace . settraceid ( traceid . newtraceid ( ) ) ; <nl> }
import org . junit . runner . runwith ; <nl> / * * checks transcoding quality . * / <nl> @ runwith ( androidjunit4 . class ) <nl> public final class transcodequalitytest { <nl> + <nl> @ test <nl> - public void singletranscode_ssimisgreaterthan90percent ( ) throws exception { <nl> + public void transformwithdecodeencode_ssimisgreaterthan90percent ( ) throws exception { <nl> context context = applicationprovider . getapplicationcontext ( ) ; <nl> transformer transformer = <nl> new transformer . builder ( context ) <nl> . settransformationrequest ( <nl> - new transformationrequest . builder ( ) . setvideomimetype ( mimetypes . video_h265 ) . build ( ) ) <nl> + new transformationrequest . builder ( ) . setvideomimetype ( mimetypes . video_h264 ) . build ( ) ) <nl> + . setencoderfactory ( androidtestutil . force_encode_encoder_factory ) <nl> . setremoveaudio ( true ) <nl> . build ( ) ;
import org . junit . runner . runwith ; <nl> / * * checks transcoding quality . * / <nl> @ runwith ( androidjunit4 . class ) <nl> public final class transcodequalitytest { <nl> + <nl> @ test <nl> - public void singletranscode_ssimisgreaterthan90percent ( ) throws exception { <nl> + public void transformwithdecodeencode_ssimisgreaterthan90percent ( ) throws exception { <nl> context context = applicationprovider . getapplicationcontext ( ) ; <nl> transformer transformer = <nl> new transformer . builder ( context ) <nl> . settransformationrequest ( <nl> - new transformationrequest . builder ( ) . setvideomimetype ( mimetypes . video_h265 ) . build ( ) ) <nl> + new transformationrequest . builder ( ) . setvideomimetype ( mimetypes . video_h264 ) . build ( ) ) <nl> + . setencoderfactory ( androidtestutil . force_encode_encoder_factory ) <nl> . setremoveaudio ( true ) <nl> . build ( ) ;
public class transformationtest { <nl>  <nl> context context = applicationprovider . getapplicationcontext ( ) ; <nl> transformer transformer = new transformer . builder ( context ) . build ( ) ; <nl> + <nl> new transformerandroidtestrunner . builder ( context , transformer ) <nl> - . setcalculatessim ( true ) <nl> . build ( ) <nl> . run ( testid , mp4_asset_with_increasing_timestamps_uri_string ) ; <nl> } <nl>
public class transformationtest { <nl> } <nl> } ) <nl> . build ( ) ; <nl> + <nl> new transformerandroidtestrunner . builder ( context , transformer ) <nl> - . setcalculatessim ( true ) <nl> . build ( ) <nl> . run ( testid , mp4_asset_with_increasing_timestamps_uri_string ) ; <nl> } <nl>
public class transformationtest { <nl> public void transform4k60 ( ) throws exception { <nl> final string testid = tag + " _transform4k60 " ; <nl>  <nl> + <nl> context context = applicationprovider . getapplicationcontext ( ) ; <nl> transformer transformer = new transformer . builder ( context ) . build ( ) ; <nl> new transformerandroidtestrunner . builder ( context , transformer ) <nl> - . setcalculatessim ( true ) <nl> . build ( ) <nl> . run ( testid , mp4_remote_4k60_portrait_uri_string ) ; <nl> } <nl>
public class transformationtest { <nl> public void transformnoaudio ( ) throws exception { <nl> final string testid = tag + " _transformnoaudio " ; <nl>  <nl> + <nl> context context = applicationprovider . getapplicationcontext ( ) ; <nl> transformer transformer = new transformer . builder ( context ) . setremoveaudio ( true ) . build ( ) ; <nl> new transformerandroidtestrunner . builder ( context , transformer ) <nl> - . setcalculatessim ( true ) <nl> . build ( ) <nl> . run ( testid , mp4_asset_with_increasing_timestamps_uri_string ) ; <nl> } <nl>
public class transformationtest { <nl> . settransformationrequest ( <nl> new transformationrequest . builder ( ) . setflattenforslowmotion ( true ) . build ( ) ) <nl> . build ( ) ; <nl> + <nl> new transformerandroidtestrunner . builder ( context , transformer ) <nl> - . setcalculatessim ( true ) <nl> . build ( ) <nl> . run ( testid , mp4_asset_sef_uri_string ) ; <nl> }
public class transformationtest { <nl>  <nl> context context = applicationprovider . getapplicationcontext ( ) ; <nl> transformer transformer = new transformer . builder ( context ) . build ( ) ; <nl> + <nl> new transformerandroidtestrunner . builder ( context , transformer ) <nl> - . setcalculatessim ( true ) <nl> . build ( ) <nl> . run ( testid , mp4_asset_with_increasing_timestamps_uri_string ) ; <nl> } <nl>
public class transformationtest { <nl> } <nl> } ) <nl> . build ( ) ; <nl> + <nl> new transformerandroidtestrunner . builder ( context , transformer ) <nl> - . setcalculatessim ( true ) <nl> . build ( ) <nl> . run ( testid , mp4_asset_with_increasing_timestamps_uri_string ) ; <nl> } <nl>
public class transformationtest { <nl> public void transform4k60 ( ) throws exception { <nl> final string testid = tag + " _transform4k60 " ; <nl>  <nl> + <nl> context context = applicationprovider . getapplicationcontext ( ) ; <nl> transformer transformer = new transformer . builder ( context ) . build ( ) ; <nl> new transformerandroidtestrunner . builder ( context , transformer ) <nl> - . setcalculatessim ( true ) <nl> . build ( ) <nl> . run ( testid , mp4_remote_4k60_portrait_uri_string ) ; <nl> } <nl>
public class transformationtest { <nl> public void transformnoaudio ( ) throws exception { <nl> final string testid = tag + " _transformnoaudio " ; <nl>  <nl> + <nl> context context = applicationprovider . getapplicationcontext ( ) ; <nl> transformer transformer = new transformer . builder ( context ) . setremoveaudio ( true ) . build ( ) ; <nl> new transformerandroidtestrunner . builder ( context , transformer ) <nl> - . setcalculatessim ( true ) <nl> . build ( ) <nl> . run ( testid , mp4_asset_with_increasing_timestamps_uri_string ) ; <nl> } <nl>
public class transformationtest { <nl> . settransformationrequest ( <nl> new transformationrequest . builder ( ) . setflattenforslowmotion ( true ) . build ( ) ) <nl> . build ( ) ; <nl> + <nl> new transformerandroidtestrunner . builder ( context , transformer ) <nl> - . setcalculatessim ( true ) <nl> . build ( ) <nl> . run ( testid , mp4_asset_sef_uri_string ) ; <nl> }
public final class frameworkmediadrm implements exomediadrm { <nl>  <nl> @ override <nl> public void setplayeridforsession ( byte [ ] sessionid , playerid playerid ) { <nl> - if ( util . sdk_int > = num ) { <nl> - api31 . setlogsessionidonmediadrmsession ( mediadrm , sessionid , playerid ) ; <nl> - } <nl> + <nl> } <nl>  <nl> / / return values of mediadrm . keyrequest . getrequesttype are equal to keyrequest . requesttype . <nl>
public final class frameworkmediadrm implements exomediadrm { <nl>  <nl> @ override <nl> public void setplayeridforsession ( byte [ ] sessionid , playerid playerid ) { <nl> - if ( util . sdk_int > = num ) { <nl> - api31 . setlogsessionidonmediadrmsession ( mediadrm , sessionid , playerid ) ; <nl> - } <nl> + <nl> } <nl>  <nl> / / return values of mediadrm . keyrequest . getrequesttype are equal to keyrequest . requesttype . <nl>
import org . checkerframework . dataflow . qual . pure ; <nl> return false ; <nl> } <nl>  <nl> - if ( sdk_int > = num ) { <nl> + if ( sdk_int > = num <nl> + & & ! ( ( " samsung " . equals ( util . manufacturer ) | | " oneplus " . equals ( util . manufacturer ) ) <nl> + & & sdk_int < num ) ) { <nl> + <nl> return processdatav29 ( ) ; <nl> } else { <nl> return processdatadefault ( ) ;
import org . checkerframework . dataflow . qual . pure ; <nl> return false ; <nl> } <nl>  <nl> - if ( sdk_int > = num ) { <nl> + if ( sdk_int > = num <nl> + & & ! ( ( " samsung " . equals ( util . manufacturer ) | | " oneplus " . equals ( util . manufacturer ) ) <nl> + & & sdk_int < num ) ) { <nl> + <nl> return processdatav29 ( ) ; <nl> } else { <nl> return processdatadefault ( ) ;
import android . content . context ; <nl> import androidx . test . core . app . applicationprovider ; <nl> import androidx . test . ext . junit . runners . androidjunit4 ; <nl> import com . google . android . exoplayer2 . transformer . transformer ; <nl> + import com . google . android . exoplayer2 . util . log ; <nl> + import com . google . android . exoplayer2 . util . util ; <nl> import org . junit . test ; <nl> import org . junit . runner . runwith ; <nl>  <nl> / * * { @ link transformer } instrumentation test for removing audio . * / <nl> @ runwith ( androidjunit4 . class ) <nl> public class removeaudiotransformationtest { <nl> + <nl> + private static final string tag = " removeaudiotransformationtest " ; <nl> + <nl> @ test <nl> public void removeaudiotransform ( ) throws exception { <nl> + if ( util . sdk_int < num ) { <nl> + <nl> + log . i ( tag , " skipping on this api version due to lack of muxing support " ) ; <nl> + return ; <nl> + } <nl> + <nl> context context = applicationprovider . getapplicationcontext ( ) ; <nl> transformer transformer = new transformer . builder ( context ) . setremoveaudio ( true ) . build ( ) ; <nl> runtransformer ( <nl> mmm a / library / transformer / src / androidtest / java / com / google / android / exoplayer2 / transformer / mh / seftransformationtest . java <nl> ppp b / library / transformer / src / androidtest / java / com / google / android / exoplayer2 / transformer / mh / seftransformationtest . java <nl>
import androidx . test . core . app . applicationprovider ; <nl> import androidx . test . ext . junit . runners . androidjunit4 ; <nl> import com . google . android . exoplayer2 . transformer . transformationrequest ; <nl> import com . google . android . exoplayer2 . transformer . transformer ; <nl> + import com . google . android . exoplayer2 . util . log ; <nl> + import com . google . android . exoplayer2 . util . util ; <nl> import org . junit . test ; <nl> import org . junit . runner . runwith ; <nl>  <nl> / * * { @ link transformer } instrumentation test for sef . * / <nl> @ runwith ( androidjunit4 . class ) <nl> public class seftransformationtest { <nl> + <nl> + private static final string tag = " seftransformationtest " ; <nl> + <nl> @ test <nl> public void seftransform ( ) throws exception { <nl> + if ( util . sdk_int < num ) { <nl> + <nl> + log . i ( tag , " skipping on this api version due to lack of muxing support " ) ; <nl> + return ; <nl> + } <nl> + <nl> context context = applicationprovider . getapplicationcontext ( ) ; <nl> transformer transformer = <nl> new transformer . builder ( context ) <nl> mmm a / library / transformer / src / androidtest / java / com / google / android / exoplayer2 / transformer / mh / transformationtest . java <nl> ppp b / library / transformer / src / androidtest / java / com / google / android / exoplayer2 / transformer / mh / transformationtest . java <nl>
import android . content . context ; <nl> import androidx . test . core . app . applicationprovider ; <nl> import androidx . test . ext . junit . runners . androidjunit4 ; <nl> import com . google . android . exoplayer2 . transformer . transformer ; <nl> + import com . google . android . exoplayer2 . util . log ; <nl> + import com . google . android . exoplayer2 . util . util ; <nl> import org . junit . test ; <nl> import org . junit . runner . runwith ; <nl>  <nl> / * * { @ link transformer } instrumentation test . * / <nl> @ runwith ( androidjunit4 . class ) <nl> public class transformationtest { <nl> + <nl> + private static final string tag = " transformationtest " ; <nl> + <nl> @ test <nl> public void transform ( ) throws exception { <nl> + if ( util . sdk_int < num ) { <nl> + <nl> + log . i ( tag , " skipping on this api version due to lack of muxing support " ) ; <nl> + return ; <nl> + } <nl> + <nl> context context = applicationprovider . getapplicationcontext ( ) ; <nl> transformer transformer = new transformer . builder ( context ) . build ( ) ; <nl> runtransformer (
import org . checkerframework . checker . nullness . qual . requiresnonnull ; <nl> return false ; <nl> } <nl> if ( ! transformationrequest . transformationmatrix . isidentity ( ) ) { <nl> + <nl> + / / adjustments result in identity matrices . <nl> return false ; <nl> } <nl> return true ;
import org . junit . runner . runwith ; <nl> / * * { @ link transformer } instrumentation test for removing audio . * / <nl> @ runwith ( androidjunit4 . class ) <nl> public class removeaudiotransformationtest { <nl> + <nl> + private static final string tag = " removeaudiotransformationtest " ; <nl> + <nl> @ test <nl> public void removeaudiotransform ( ) throws exception { <nl> + if ( util . sdk_int < num ) { <nl> + <nl> + log . i ( tag , " skipping on this api version due to lack of muxing support " ) ; <nl> + return ; <nl> + } <nl> + <nl> context context = applicationprovider . getapplicationcontext ( ) ; <nl> transformer transformer = new transformer . builder ( context ) . setremoveaudio ( true ) . build ( ) ; <nl> runtransformer ( <nl> mmm a / libraries / transformer / src / androidtest / java / androidx / media3 / transformer / mh / seftransformationtest . java <nl> ppp b / libraries / transformer / src / androidtest / java / androidx / media3 / transformer / mh / seftransformationtest . java <nl>
import org . junit . runner . runwith ; <nl> / * * { @ link transformer } instrumentation test for sef . * / <nl> @ runwith ( androidjunit4 . class ) <nl> public class seftransformationtest { <nl> + <nl> + private static final string tag = " seftransformationtest " ; <nl> + <nl> @ test <nl> public void seftransform ( ) throws exception { <nl> + if ( util . sdk_int < num ) { <nl> + <nl> + log . i ( tag , " skipping on this api version due to lack of muxing support " ) ; <nl> + return ; <nl> + } <nl> + <nl> context context = applicationprovider . getapplicationcontext ( ) ; <nl> transformer transformer = <nl> new transformer . builder ( context ) <nl> mmm a / libraries / transformer / src / androidtest / java / androidx / media3 / transformer / mh / transformationtest . java <nl> ppp b / libraries / transformer / src / androidtest / java / androidx / media3 / transformer / mh / transformationtest . java <nl>
import org . junit . runner . runwith ; <nl> / * * { @ link transformer } instrumentation test . * / <nl> @ runwith ( androidjunit4 . class ) <nl> public class transformationtest { <nl> + <nl> + private static final string tag = " transformationtest " ; <nl> + <nl> @ test <nl> public void transform ( ) throws exception { <nl> + if ( util . sdk_int < num ) { <nl> + <nl> + log . i ( tag , " skipping on this api version due to lack of muxing support " ) ; <nl> + return ; <nl> + } <nl> + <nl> context context = applicationprovider . getapplicationcontext ( ) ; <nl> transformer transformer = new transformer . builder ( context ) . build ( ) ; <nl> runtransformer (
import org . checkerframework . checker . nullness . qual . requiresnonnull ; <nl> return false ; <nl> } <nl> if ( ! transformationrequest . transformationmatrix . isidentity ( ) ) { <nl> + <nl> + / / adjustments result in identity matrices . <nl> return false ; <nl> } <nl> return true ;
import org . checkerframework . checker . nullness . qual . requiresnonnull ; <nl> * / <nl> @ requiresnonnull ( " trackoutput " ) <nl> private void processaggregationpacket ( parsablebytearray data ) throws parserexception { <nl> + <nl> throw parserexception . createformalformedmanifest ( <nl> " need to implement processaggregationpacket " , <nl> / * cause = * / null ) ;
import org . checkerframework . checker . nullness . qual . requiresnonnull ; <nl> } <nl> } <nl>  <nl> + <nl> + if ( mimetype . equals ( mimetypes . video_h264 ) ) { <nl> + / / applying suggested profile / level settings from <nl> + / / https : / / developer . android . com / guide / topics / media / sharing - video # b - frames_and_encoding_profiles <nl> + if ( util . sdk_int > = num ) { <nl> + / / use the highest supported profile and use b - frames . <nl> + mediaformat . setinteger ( <nl> + mediaformat . key_profile , mediacodecinfo . codecprofilelevel . avcprofilehigh ) ; <nl> + mediaformat . setinteger ( mediaformat . key_max_b_frames , num ) ; <nl> + } else if ( util . sdk_int > = num ) { <nl> + / / use the highest - supported profile , but disable the generation of b - frames . this <nl> + / / accommodates some limitations in the mediamuxer in these system versions . <nl> + mediaformat . setinteger ( <nl> + mediaformat . key_profile , mediacodecinfo . codecprofilelevel . avcprofilehigh ) ; <nl> + mediaformat . setinteger ( mediaformat . key_latency , num ) ; <nl> + } else { <nl> + / / use the baseline profile for safest results . <nl> + mediaformat . setinteger ( <nl> + mediaformat . key_profile , mediacodecinfo . codecprofilelevel . avcprofilebaseline ) ; <nl> + } <nl> + } <nl> + <nl> mediaformat . setinteger ( mediaformat . key_color_format , default_color_format ) ; <nl> mediaformat . setinteger ( mediaformat . key_i_frame_interval , default_i_frame_interval_secs ) ;
import org . checkerframework . checker . nullness . qual . requiresnonnull ; <nl> } <nl> } <nl>  <nl> + <nl> + if ( mimetype . equals ( mimetypes . video_h264 ) ) { <nl> + / / applying suggested profile / level settings from <nl> + / / https : / / developer . android . com / guide / topics / media / sharing - video # b - frames_and_encoding_profiles <nl> + if ( util . sdk_int > = num ) { <nl> + / / use the highest supported profile and use b - frames . <nl> + mediaformat . setinteger ( <nl> + mediaformat . key_profile , mediacodecinfo . codecprofilelevel . avcprofilehigh ) ; <nl> + mediaformat . setinteger ( mediaformat . key_max_b_frames , num ) ; <nl> + } else if ( util . sdk_int > = num ) { <nl> + / / use the highest - supported profile , but disable the generation of b - frames . this <nl> + / / accommodates some limitations in the mediamuxer in these system versions . <nl> + mediaformat . setinteger ( <nl> + mediaformat . key_profile , mediacodecinfo . codecprofilelevel . avcprofilehigh ) ; <nl> + mediaformat . setinteger ( mediaformat . key_latency , num ) ; <nl> + } else { <nl> + / / use the baseline profile for safest results . <nl> + mediaformat . setinteger ( <nl> + mediaformat . key_profile , mediacodecinfo . codecprofilelevel . avcprofilebaseline ) ; <nl> + } <nl> + } <nl> + <nl> mediaformat . setinteger ( mediaformat . key_color_format , default_color_format ) ; <nl> mediaformat . setinteger ( mediaformat . key_i_frame_interval , default_i_frame_interval_secs ) ;
public class mediacodecaudiorenderer extends mediacodecrenderer implements media <nl> = = audiosink . sink_format_supported_directly ) { <nl> mediaformat . setinteger ( mediaformat . key_pcm_encoding , audioformat . encoding_pcm_float ) ; <nl> } <nl> + <nl> + if ( util . sdk_int > = num ) { <nl> + / / disable down - mixing in the decoder ( for decoders that read the max - output - channel - count <nl> + / / key ) . <nl> + <nl> + mediaformat . setinteger ( " max - output - channel - count " , num ) ; <nl> + } <nl> return mediaformat ; <nl> }
public class mediacodecaudiorenderer extends mediacodecrenderer implements media <nl> = = audiosink . sink_format_supported_directly ) { <nl> mediaformat . setinteger ( mediaformat . key_pcm_encoding , audioformat . encoding_pcm_float ) ; <nl> } <nl> + <nl> + if ( util . sdk_int > = num ) { <nl> + / / disable down - mixing in the decoder ( for decoders that read the max - output - channel - count <nl> + / / key ) . <nl> + <nl> + mediaformat . setinteger ( " max - output - channel - count " , num ) ; <nl> + } <nl> return mediaformat ; <nl> }
public final class glutil { <nl> checkglerror ( ) ; <nl> } <nl>  <nl> - / * * uses the program . * / <nl> + / * * <nl> + * uses the program . <nl> + * <nl> + * < p > call this in the rendering loop to switch between different programs . <nl> + * / <nl> public void use ( ) { <nl> + <nl> gles20 . gluseprogram ( programid ) ; <nl> checkglerror ( ) ; <nl> } <nl> mmm a / libraries / exoplayer / src / main / java / androidx / media3 / exoplayer / video / videodecoderglsurfaceview . java <nl> ppp b / libraries / exoplayer / src / main / java / androidx / media3 / exoplayer / video / videodecoderglsurfaceview . java <nl>
public final class glutil { <nl> checkglerror ( ) ; <nl> } <nl>  <nl> - / * * uses the program . * / <nl> + / * * <nl> + * uses the program . <nl> + * <nl> + * < p > call this in the rendering loop to switch between different programs . <nl> + * / <nl> public void use ( ) { <nl> + <nl> gles20 . gluseprogram ( programid ) ; <nl> checkglerror ( ) ; <nl> } <nl> mmm a / library / core / src / main / java / com / google / android / exoplayer2 / video / videodecoderglsurfaceview . java <nl> ppp b / library / core / src / main / java / com / google / android / exoplayer2 / video / videodecoderglsurfaceview . java <nl>
public final class udpdatasource extends basedatasource { <nl> } else { <nl> socket = new datagramsocket ( socketaddress ) ; <nl> } <nl> + } catch ( securityexception e ) { <nl> + throw new udpdatasourceexception ( e , playbackexception . error_code_io_no_permission ) ; <nl> + } catch ( unknownhostexception e ) { <nl> + <nl> + throw new udpdatasourceexception ( e , playbackexception . error_code_io_dns_failed ) ; <nl> + } catch ( bindexception e ) { <nl> + throw new udpdatasourceexception ( e , playbackexception . error_code_io_network_unavailable ) ; <nl> } catch ( ioexception e ) { <nl> throw new udpdatasourceexception ( <nl> e , playbackexception . error_code_io_network_connection_failed ) ; <nl>
public final class c { <nl> throw new illegalstateexception ( ) ; <nl> } <nl> } <nl> + <nl> + / / copy of relevant error codes defined in mediadrm . errorcodes from api num . <nl> + <nl> + private static final int error_key_expired = num ; <nl> + private static final int error_insufficient_output_protection = num ; <nl> + private static final int error_insufficient_security = num ; <nl> + private static final int error_frame_too_large = num ; <nl> + private static final int error_certificate_malformed = num ; <nl> + private static final int error_init_data = num ; <nl> + private static final int error_key_not_loaded = num ; <nl> + private static final int error_license_parse = num ; <nl> + private static final int error_license_policy = num ; <nl> + private static final int error_license_release = num ; <nl> + private static final int error_license_request_rejected = num ; <nl> + private static final int error_license_restore = num ; <nl> + private static final int error_license_state = num ; <nl> + private static final int error_provisioning_certificate = num ; <nl> + private static final int error_provisioning_config = num ; <nl> + private static final int error_provisioning_parse = num ; <nl> + private static final int error_provisioning_request_rejected = num ; <nl> + private static final int error_provisioning_retry = num ; <nl> + <nl> + @ playbackexception . errorcode <nl> + public static int geterrorcodecorrespondingtoplatformdrmerrorcode ( int mediadrmerrorcode ) { <nl> + switch ( mediadrmerrorcode ) { <nl> + case error_provisioning_config : <nl> + case error_provisioning_parse : <nl> + case error_provisioning_request_rejected : <nl> + case error_provisioning_certificate : <nl> + case error_provisioning_retry : <nl> + return playbackexception . error_code_drm_provisioning_failed ; <nl> + case error_license_parse : <nl> + case error_license_release : <nl> + case error_license_request_rejected : <nl> + case error_license_restore : <nl> + case error_license_state : <nl> + case error_certificate_malformed : <nl> + return playbackexception . error_code_drm_license_acquisition_failed ; <nl> + case error_license_policy : <nl> + case error_insufficient_output_protection : <nl> + case error_insufficient_security : <nl> + case error_key_expired : <nl> + case error_key_not_loaded : <nl> + return playbackexception . error_code_drm_disallowed_operation ; <nl> + case error_init_data : <nl> + case error_frame_too_large : <nl> + return playbackexception . error_code_drm_content_error ; <nl> + default : <nl> + return playbackexception . error_code_drm_system_error ; <nl> + } <nl> + } <nl> }
public final class util { <nl>  <nl> / * * <nl> * attempts to parse an error code from a diagnostic string found in framework media exceptions . <nl> - * for example : android . media . mediacodec . error_1 or android . media . mediadrm . error_neg_2 . <nl> + * <nl> + * < p > for example : android . media . mediacodec . error_1 or android . media . mediadrm . error_neg_2 . <nl> + * <nl> + * @ param diagnosticsinfo a string from which to parse the error code . <nl> + * @ return the parser error code , or num if an error code could not be parsed . <nl> * / <nl> public static int geterrorcodefromplatformdiagnosticsinfo ( @ nullable string diagnosticsinfo ) { <nl> + <nl> if ( diagnosticsinfo = = null ) { <nl> return num ; <nl> } <nl> - matcher matcher = diagnostic_info_code_pattern . matcher ( diagnosticsinfo ) ; <nl> - if ( ! matcher . matches ( ) ) { <nl> + string [ ] strings = split ( diagnosticsinfo , " _ " ) ; <nl> + int length = strings . length ; <nl> + if ( length < num ) { <nl> return num ; <nl> } <nl> + string digitssection = strings [ length - num ] ; <nl> + boolean isnegative = length > = num & & " neg " . equals ( strings [ length - num ] ) ; <nl> try { <nl> - int errorcode = integer . parseint ( assertions . checknotnull ( matcher . group ( 2 ) ) ) ; <nl> - return assertions . checknotnull ( matcher . group ( 1 ) ) . isempty ( ) ? errorcode : - errorcode ; <nl> + int errorcode = integer . parseint ( assertions . checknotnull ( digitssection ) ) ; <nl> + return isnegative ? - errorcode : errorcode ; <nl> } catch ( numberformatexception e ) { <nl> return num ; <nl> }
public class utiltest { <nl> . isequalto ( " - 00 : 35 " ) ; <nl> } <nl>  <nl> + @ test <nl> + public void geterrorcodefromplatformdiagnosticsinfo_withvalidinput_returnsexpectedvalue ( ) { <nl> + assertthat ( util . geterrorcodefromplatformdiagnosticsinfo ( " android . media . mediadrm . error_1 " ) ) <nl> + . isequalto ( 1 ) ; <nl> + assertthat ( util . geterrorcodefromplatformdiagnosticsinfo ( " android . media . mediadrm . error_neg_1 " ) ) <nl> + . isequalto ( - 1 ) ; <nl> + assertthat ( util . geterrorcodefromplatformdiagnosticsinfo ( " android . media . mediacodec2 . error_3 " ) ) <nl> + . isequalto ( 3 ) ; <nl> + assertthat ( <nl> + util . geterrorcodefromplatformdiagnosticsinfo ( <nl> + " android . media . mediacodec . weird_error_neg_10000 " ) ) <nl> + . isequalto ( - 10000 ) ; <nl> + assertthat ( <nl> + util . geterrorcodefromplatformdiagnosticsinfo ( <nl> + " android . media . mediacodec . weird_error_negx_10000 " ) ) <nl> + . isequalto ( 10000 ) ; <nl> + assertthat ( <nl> + util . geterrorcodefromplatformdiagnosticsinfo ( <nl> + " android . media . mediacodec . weird_error_xneg_10000 " ) ) <nl> + . isequalto ( 10000 ) ; <nl> + } <nl> + <nl> + @ test <nl> + public void geterrorcodefromplatformdiagnosticsinfo_withinvalidinput_returnszero ( ) { <nl> + <nl> + assertthat ( util . geterrorcodefromplatformdiagnosticsinfo ( " " ) ) . isequalto ( 0 ) ; <nl> + assertthat ( util . geterrorcodefromplatformdiagnosticsinfo ( " android . media . mediadrm . empty " ) ) <nl> + . isequalto ( 0 ) ; <nl> + assertthat ( util . geterrorcodefromplatformdiagnosticsinfo ( " android . media . mediadrm . error_neg_1a " ) ) <nl> + . isequalto ( 0 ) ; <nl> + assertthat ( util . geterrorcodefromplatformdiagnosticsinfo ( " android . media . mediadrm . error_a1 " ) ) <nl> + . isequalto ( 0 ) ; <nl> + } <nl> + <nl> private static void assertescapeunescapefilename ( string filename , string escapedfilename ) { <nl> assertthat ( escapefilename ( filename ) ) . isequalto ( escapedfilename ) ; <nl> assertthat ( unescapefilename ( escapedfilename ) ) . isequalto ( filename ) ;
public final class leanbackplayeradapter extends playeradapter implements runnab <nl> pair < integer , string > errormessage = errormessageprovider . geterrormessage ( exception ) ; <nl> callback . onerror ( leanbackplayeradapter . this , errormessage . first , errormessage . second ) ; <nl> } else { <nl> + <nl> + int rendererindex = exception . rendererindex ; <nl> callback . onerror ( <nl> leanbackplayeradapter . this , <nl> - exception . type , <nl> - context . getstring ( <nl> - r . string . lb_media_player_error , exception . type , exception . rendererindex ) ) ; <nl> + exception . errorcode , <nl> + context . getstring ( r . string . lb_media_player_error , exception . errorcode , rendererindex ) ) ; <nl> } <nl> }
public abstract class timeline implements bundleable { <nl> return bundle ; <nl> } <nl>  <nl> + / * * <nl> + * { @ inheritdoc } <nl> + * <nl> + * < p > it omits the { @ link # uid } and { @ link # manifest } fields . the { @ link # uid } of an instance <nl> + * restored by { @ link # creator } will be a fake { @ link object } and the { @ link # manifest } of the <nl> + * instance will be { @ code null } . <nl> + * / <nl> + <nl> + @ override <nl> + public bundle tobundle ( ) { <nl> + return tobundle ( / * excludemediaitem = * / false ) ; <nl> + } <nl> + <nl> / * * <nl> * object that can restore { @ link period } from a { @ link bundle } . <nl> * <nl>
public final class rtspmediasource extends basemediasource { <nl> return this ; <nl> } <nl>  <nl> - / * * @ deprecated not supported . * / <nl> + / * * <nl> + * does nothing . { @ link rtspmediasource } does not support drm . <nl> + * <nl> + * @ deprecated { @ link rtspmediasource } does not support drm . <nl> + * / <nl> @ deprecated <nl> @ override <nl> public factory setdrmuseragent ( @ nullable string useragent ) { <nl> return this ; <nl> } <nl>  <nl> - / * * @ deprecated not supported . * / <nl> - @ deprecated <nl> + / * * does nothing . { @ link rtspmediasource } does not support error handling policies . * / <nl> @ override <nl> public factory setloaderrorhandlingpolicy ( <nl> @ nullable loaderrorhandlingpolicy loaderrorhandlingpolicy ) { <nl> + <nl> return this ; <nl> }
<nl> + / * <nl> + * copyright num the android open source project <nl> + * <nl> + * licensed under the apache license , version num . 0 ( the " license " ) ; <nl> + * you may not use this file except in compliance with the license . <nl> + * you may obtain a copy of the license at <nl> + * <nl> + * http : / / www . apache . org / licenses / license - 2 . 0 <nl> + * <nl> + * unless required by applicable law or agreed to in writing , software <nl> + * distributed under the license is distributed on an " as is " basis , <nl> + * without warranties or conditions of any kind , either express or implied . <nl> + * see the license for the specific language governing permissions and <nl> + * limitations under the license . <nl> + * / <nl> + package com . google . android . exoplayer2 ; <nl> + <nl> + import static com . google . common . truth . truth . assertthat ; <nl> + <nl> + import androidx . test . ext . junit . runners . androidjunit4 ; <nl> + import java . io . ioexception ; <nl> + import org . junit . test ; <nl> + import org . junit . runner . runwith ; <nl> + <nl> + / * * unit tests for { @ link playbackexception } . * / <nl> + @ runwith ( androidjunit4 . class ) <nl> + public class playbackexceptiontest { <nl> + <nl> + @ test <nl> + public void roundtripviabundle_yieldsequalinstance ( ) { <nl> + playbackexception before = <nl> + new playbackexception ( <nl> + / * message = * / " test " , <nl> + / * cause = * / new ioexception ( / * message = * / " io " ) , <nl> + playbackexception . error_code_io_file_not_found ) ; <nl> + playbackexception after = playbackexception . creator . frombundle ( before . tobundle ( ) ) ; <nl> + assertplaybackexceptionsareequal ( before , after ) ; <nl> + } <nl> + <nl> + <nl> + <nl> + private static void assertplaybackexceptionsareequal ( playbackexception a , playbackexception b ) { <nl> + assertthat ( a . getmessage ( ) ) . isequalto ( b . getmessage ( ) ) ; <nl> + assertthat ( a . errorcode ) . isequalto ( b . errorcode ) ; <nl> + assertthat ( a . timestampms ) . isequalto ( b . timestampms ) ; <nl> + assertthat ( a . getcause ( ) . getclass ( ) ) . issameinstanceas ( b . getcause ( ) . getclass ( ) ) ; <nl> + assertthat ( a . getcause ( ) . getmessage ( ) ) . isequalto ( b . getcause ( ) . getmessage ( ) ) ; <nl> + } <nl> + }
public final class rtspmediasource extends basemediasource { <nl> return this ; <nl> } <nl>  <nl> - / * * @ deprecated not supported . * / <nl> + / * * <nl> + * does nothing . { @ link rtspmediasource } does not support drm . <nl> + * <nl> + * @ deprecated { @ link rtspmediasource } does not support drm . <nl> + * / <nl> @ deprecated <nl> @ override <nl> public factory setdrmuseragent ( @ nullable string useragent ) { <nl> return this ; <nl> } <nl>  <nl> - / * * @ deprecated not supported . * / <nl> - @ deprecated <nl> + / * * does nothing . { @ link rtspmediasource } does not support error handling policies . * / <nl> @ override <nl> public factory setloaderrorhandlingpolicy ( <nl> @ nullable loaderrorhandlingpolicy loaderrorhandlingpolicy ) { <nl> + <nl> return this ; <nl> }
public final class adsmediasource extends compositemediasource < mediaperiodid > { <nl> & & adindexinadgroup < adplaybackstate . adgroups [ adgroupindex ] . uris . length ) { <nl> @ nullable uri aduri = adplaybackstate . adgroups [ adgroupindex ] . uris [ adindexinadgroup ] ; <nl> if ( aduri ! = null ) { <nl> - mediasource admediasource = <nl> - admediasourcefactory . createmediasource ( mediaitem . fromuri ( aduri ) ) ; <nl> + mediaitem . builder admediaitem = new mediaitem . builder ( ) . seturi ( aduri ) ; <nl> + / / propagate the content ' s drm config into the ad media source . <nl> + @ nullable <nl> + mediaitem . playbackproperties contentplaybackproperties = <nl> + contentmediasource . getmediaitem ( ) . playbackproperties ; <nl> + if ( contentplaybackproperties ! = null <nl> + & & contentplaybackproperties . drmconfiguration ! = null ) { <nl> + mediaitem . drmconfiguration drmconfiguration = <nl> + contentplaybackproperties . drmconfiguration ; <nl> + <nl> + admediaitem . setdrmuuid ( drmconfiguration . uuid ) ; <nl> + admediaitem . setdrmkeysetid ( drmconfiguration . getkeysetid ( ) ) ; <nl> + admediaitem . setdrmlicenseuri ( drmconfiguration . licenseuri ) ; <nl> + admediaitem . setdrmforcedefaultlicenseuri ( drmconfiguration . forcedefaultlicenseuri ) ; <nl> + admediaitem . setdrmlicenserequestheaders ( drmconfiguration . requestheaders ) ; <nl> + admediaitem . setdrmmultisession ( drmconfiguration . multisession ) ; <nl> + admediaitem . setdrmplayclearcontentwithoutkey ( <nl> + drmconfiguration . playclearcontentwithoutkey ) ; <nl> + admediaitem . setdrmsessionforcleartypes ( drmconfiguration . sessionforcleartypes ) ; <nl> + } <nl> + mediasource admediasource = admediasourcefactory . createmediasource ( admediaitem . build ( ) ) ; <nl> admediasourceholder . initializewithmediasource ( admediasource , aduri ) ; <nl> } <nl> }
public final class adsmediasource extends compositemediasource < mediaperiodid > { <nl> & & adindexinadgroup < adplaybackstate . adgroups [ adgroupindex ] . uris . length ) { <nl> @ nullable uri aduri = adplaybackstate . adgroups [ adgroupindex ] . uris [ adindexinadgroup ] ; <nl> if ( aduri ! = null ) { <nl> - mediasource admediasource = <nl> - admediasourcefactory . createmediasource ( mediaitem . fromuri ( aduri ) ) ; <nl> + mediaitem . builder admediaitem = new mediaitem . builder ( ) . seturi ( aduri ) ; <nl> + / / propagate the content ' s drm config into the ad media source . <nl> + @ nullable <nl> + mediaitem . playbackproperties contentplaybackproperties = <nl> + contentmediasource . getmediaitem ( ) . playbackproperties ; <nl> + if ( contentplaybackproperties ! = null <nl> + & & contentplaybackproperties . drmconfiguration ! = null ) { <nl> + mediaitem . drmconfiguration drmconfiguration = <nl> + contentplaybackproperties . drmconfiguration ; <nl> + <nl> + admediaitem . setdrmuuid ( drmconfiguration . uuid ) ; <nl> + admediaitem . setdrmkeysetid ( drmconfiguration . getkeysetid ( ) ) ; <nl> + admediaitem . setdrmlicenseuri ( drmconfiguration . licenseuri ) ; <nl> + admediaitem . setdrmforcedefaultlicenseuri ( drmconfiguration . forcedefaultlicenseuri ) ; <nl> + admediaitem . setdrmlicenserequestheaders ( drmconfiguration . requestheaders ) ; <nl> + admediaitem . setdrmmultisession ( drmconfiguration . multisession ) ; <nl> + admediaitem . setdrmplayclearcontentwithoutkey ( <nl> + drmconfiguration . playclearcontentwithoutkey ) ; <nl> + admediaitem . setdrmsessionforcleartypes ( drmconfiguration . sessionforcleartypes ) ; <nl> + } <nl> + mediasource admediasource = admediasourcefactory . createmediasource ( admediaitem . build ( ) ) ; <nl> admediasourceholder . initializewithmediasource ( admediasource , aduri ) ; <nl> } <nl> }
public final class mediacodecutil { <nl> if ( levelstring = = null ) { <nl> return null ; <nl> } <nl> + <nl> switch ( levelstring ) { <nl> case " 01 " : <nl> return codecprofilelevel . dolbyvisionlevelhd24 ; <nl>
public final class mediacodecutil { <nl> if ( levelstring = = null ) { <nl> return null ; <nl> } <nl> + <nl> switch ( levelstring ) { <nl> case " 01 " : <nl> return codecprofilelevel . dolbyvisionlevelhd24 ; <nl>
public final class defaultaudiosink implements audiosink { <nl> if ( ! supportedencoding ) { <nl> return null ; <nl> } <nl> - <nl> - / / e - ac3 joc is object based , so any channel count specified in the format is arbitrary . use num , <nl> - / / since the e - ac3 compatible part of the stream is num . 1 . <nl> - int channelcount = encoding = = c . encoding_e_ac3_joc ? num : format . channelcount ; <nl> - if ( channelcount > audiocapabilities . getmaxchannelcount ( ) ) { <nl> + if ( encoding = = c . encoding_e_ac3_joc <nl> + & & ! audiocapabilities . supportsencoding ( c . encoding_e_ac3_joc ) ) { <nl> + / / e - ac3 receivers support e - ac3 joc streams ( but decode only the base layer ) . <nl> + encoding = c . encoding_e_ac3 ; <nl> + } <nl> + if ( ! audiocapabilities . supportsencoding ( encoding ) ) { <nl> return null ; <nl> } <nl>  <nl> + int channelcount ; <nl> + if ( encoding = = c . encoding_e_ac3_joc ) { <nl> + / / e - ac3 joc is object based so the format channel count is arbitrary . from api num we can get <nl> + / / the channel count for this encoding , but before then there is no way to query it so we <nl> + / / assume num channel audio is supported . <nl> + if ( util . sdk_int > = num ) { <nl> + channelcount = <nl> + getmaxsupportedchannelcountforpassthroughv29 ( c . encoding_e_ac3_joc , format . samplerate ) ; <nl> + if ( channelcount = = num ) { <nl> + log . w ( tag , " e - ac3 joc encoding supported but no channel count supported " ) ; <nl> + return null ; <nl> + } <nl> + } else { <nl> + channelcount = num ; <nl> + } <nl> + } else { <nl> + channelcount = format . channelcount ; <nl> + if ( channelcount > audiocapabilities . getmaxchannelcount ( ) ) { <nl> + return null ; <nl> + } <nl> + } <nl> int channelconfig = getchannelconfigforpassthrough ( channelcount ) ; <nl> if ( channelconfig = = audioformat . channel_invalid ) { <nl> return null ; <nl> } <nl>  <nl> - if ( audiocapabilities . supportsencoding ( encoding ) ) { <nl> - return pair . create ( encoding , channelconfig ) ; <nl> - } else if ( encoding = = c . encoding_e_ac3_joc <nl> - & & audiocapabilities . supportsencoding ( c . encoding_e_ac3 ) ) { <nl> - / / e - ac3 receivers support e - ac3 joc streams ( but decode in num - d rather than num - d ) . <nl> - return pair . create ( c . encoding_e_ac3 , channelconfig ) ; <nl> - } <nl> + return pair . create ( encoding , channelconfig ) ; <nl> + } <nl>  <nl> - return null ; <nl> + / * * <nl> + * returns the maximum number of channels supported for passthrough playback of audio in the given <nl> + * format , or num if the format is unsupported . <nl> + * / <nl> + @ requiresapi ( 29 ) <nl> + private static int getmaxsupportedchannelcountforpassthroughv29 ( <nl> + @ c . encoding int encoding , int samplerate ) { <nl> + android . media . audioattributes audioattributes = <nl> + new android . media . audioattributes . builder ( ) <nl> + . setusage ( android . media . audioattributes . usage_media ) <nl> + . setcontenttype ( android . media . audioattributes . content_type_movie ) <nl> + . build ( ) ; <nl> + <nl> + for ( int channelcount = num ; channelcount > num ; channelcount - - ) { <nl> + audioformat audioformat = <nl> + new audioformat . builder ( ) <nl> + . setencoding ( encoding ) <nl> + . setsamplerate ( samplerate ) <nl> + . setchannelmask ( util . getaudiotrackchannelconfig ( channelcount ) ) <nl> + . build ( ) ; <nl> + if ( audiotrack . isdirectplaybacksupported ( audioformat , audioattributes ) ) { <nl> + return channelcount ; <nl> + } <nl> + } <nl> + return num ; <nl> } <nl>  <nl> private static int getchannelconfigforpassthrough ( int channelcount ) {
public class gvraudioprocessor implements audioprocessor { <nl>  <nl> @ override <nl> public void queueendofstream ( ) { <nl> + <nl> if ( gvraudiosurround ! = null ) { <nl> gvraudiosurround . triggerprocessing ( ) ; <nl> } <nl> mmm a / library / core / src / main / java / com / google / android / exoplayer2 / audio / defaultaudiosink . java <nl> ppp b / library / core / src / main / java / com / google / android / exoplayer2 / audio / defaultaudiosink . java <nl>
public final class sonicaudioprocessor implements audioprocessor { <nl>  <nl> @ override <nl> public void queueinput ( bytebuffer inputbuffer ) { <nl> - sonic sonic = checknotnull ( this . sonic ) ; <nl> - if ( inputbuffer . hasremaining ( ) ) { <nl> - shortbuffer shortbuffer = inputbuffer . asshortbuffer ( ) ; <nl> - int inputsize = inputbuffer . remaining ( ) ; <nl> - inputbytes + = inputsize ; <nl> - sonic . queueinput ( shortbuffer ) ; <nl> - inputbuffer . position ( inputbuffer . position ( ) + inputsize ) ; <nl> - } <nl> - int outputsize = sonic . getoutputsize ( ) ; <nl> - if ( outputsize > num ) { <nl> - if ( buffer . capacity ( ) < outputsize ) { <nl> - buffer = bytebuffer . allocatedirect ( outputsize ) . order ( byteorder . nativeorder ( ) ) ; <nl> - shortbuffer = buffer . asshortbuffer ( ) ; <nl> - } else { <nl> - buffer . clear ( ) ; <nl> - shortbuffer . clear ( ) ; <nl> - } <nl> - sonic . getoutput ( shortbuffer ) ; <nl> - outputbytes + = outputsize ; <nl> - buffer . limit ( outputsize ) ; <nl> - outputbuffer = buffer ; <nl> + if ( ! inputbuffer . hasremaining ( ) ) { <nl> + return ; <nl> } <nl> + sonic sonic = checknotnull ( this . sonic ) ; <nl> + shortbuffer shortbuffer = inputbuffer . asshortbuffer ( ) ; <nl> + int inputsize = inputbuffer . remaining ( ) ; <nl> + inputbytes + = inputsize ; <nl> + sonic . queueinput ( shortbuffer ) ; <nl> + inputbuffer . position ( inputbuffer . position ( ) + inputsize ) ; <nl> } <nl>  <nl> @ override <nl> public void queueendofstream ( ) { <nl> + <nl> if ( sonic ! = null ) { <nl> sonic . queueendofstream ( ) ; <nl> } <nl>
import org . junit . runner . runwith ; <nl>  <nl> / * * tests widevine encrypted dash playbacks using offline keys . * / <nl> @ runwith ( androidjunit4 . class ) <nl> - @ ignore ( " need to be reconfigured / rewritten with an offline - compatible licence ( b / 176960595 ) . " ) <nl> + <nl> + @ ignore ( <nl> + " need to be reconfigured / rewritten with an offline - compatible licence [ internal b / 176960595 ] . " ) <nl> public final class dashwidevineofflinetest { <nl>  <nl> private static final string tag = " dashwidevineofflinetest " ;
public class mediacodecvideorenderer extends mediacodecrenderer { <nl>  <nl> @ override <nl> public void handlemessage ( int messagetype , @ nullable object message ) throws exoplaybackexception { <nl> - if ( messagetype = = msg_set_surface ) { <nl> - setsurface ( ( surface ) message ) ; <nl> - } else if ( messagetype = = msg_set_scaling_mode ) { <nl> - scalingmode = ( integer ) message ; <nl> - @ nullable mediacodecadapter codec = getcodec ( ) ; <nl> - if ( codec ! = null ) { <nl> - codec . setvideoscalingmode ( scalingmode ) ; <nl> - } <nl> - } else if ( messagetype = = msg_set_video_frame_metadata_listener ) { <nl> - framemetadatalistener = ( videoframemetadatalistener ) message ; <nl> - } else { <nl> - super . handlemessage ( messagetype , message ) ; <nl> + switch ( messagetype ) { <nl> + case msg_set_surface : <nl> + setsurface ( ( surface ) message ) ; <nl> + break ; <nl> + case msg_set_scaling_mode : <nl> + scalingmode = ( integer ) message ; <nl> + @ nullable mediacodecadapter codec = getcodec ( ) ; <nl> + if ( codec ! = null ) { <nl> + codec . setvideoscalingmode ( scalingmode ) ; <nl> + } <nl> + break ; <nl> + case msg_set_video_frame_metadata_listener : <nl> + framemetadatalistener = ( videoframemetadatalistener ) message ; <nl> + break ; <nl> + case msg_set_audio_session_id : <nl> + <nl> + break ; <nl> + default : <nl> + super . handlemessage ( messagetype , message ) ; <nl> } <nl> }
<nl> + / * <nl> + * copyright ( c ) num the android open source project <nl> + * <nl> + * licensed under the apache license , version num . 0 ( the " license " ) ; <nl> + * you may not use this file except in compliance with the license . <nl> + * you may obtain a copy of the license at <nl> + * <nl> + * http : / / www . apache . org / licenses / license - 2 . 0 <nl> + * <nl> + * unless required by applicable law or agreed to in writing , software <nl> + * distributed under the license is distributed on an " as is " basis , <nl> + * without warranties or conditions of any kind , either express or implied . <nl> + * see the license for the specific language governing permissions and <nl> + * limitations under the license . <nl> + * / <nl> + package com . google . android . exoplayer2 . e2etest ; <nl> + <nl> + import android . content . context ; <nl> + import androidx . test . core . app . applicationprovider ; <nl> + import androidx . test . ext . junit . runners . androidjunit4 ; <nl> + import com . google . android . exoplayer2 . player ; <nl> + import com . google . android . exoplayer2 . simpleexoplayer ; <nl> + import com . google . android . exoplayer2 . robolectric . playbackoutput ; <nl> + import com . google . android . exoplayer2 . robolectric . testplayerrunhelper ; <nl> + import com . google . android . exoplayer2 . source . silencemediasource ; <nl> + import com . google . android . exoplayer2 . testutil . autoadvancingfakeclock ; <nl> + import com . google . android . exoplayer2 . testutil . capturingrenderersfactory ; <nl> + import com . google . android . exoplayer2 . testutil . dumpfileasserts ; <nl> + import org . junit . test ; <nl> + import org . junit . runner . runwith ; <nl> + import org . robolectric . annotation . config ; <nl> + <nl> + / * * end - to - end tests using { @ link silencemediasource } . * / <nl> + <nl> + @ config ( sdk = num ) <nl> + @ runwith ( androidjunit4 . class ) <nl> + public final class silenceplaybacktest { <nl> + <nl> + @ test <nl> + public void test_500ms ( ) throws exception { <nl> + context applicationcontext = applicationprovider . getapplicationcontext ( ) ; <nl> + capturingrenderersfactory capturingrenderersfactory = <nl> + new capturingrenderersfactory ( applicationcontext ) ; <nl> + simpleexoplayer player = <nl> + new simpleexoplayer . builder ( applicationcontext , capturingrenderersfactory ) <nl> + . setclock ( new autoadvancingfakeclock ( ) ) <nl> + . build ( ) ; <nl> + playbackoutput playbackoutput = playbackoutput . register ( player , capturingrenderersfactory ) ; <nl> + <nl> + player . setmediasource ( new silencemediasource ( / * durationus = * / num _000 ) ) ; <nl> + player . prepare ( ) ; <nl> + player . play ( ) ; <nl> + testplayerrunhelper . rununtilplaybackstate ( player , player . state_ended ) ; <nl> + player . release ( ) ; <nl> + <nl> + dumpfileasserts . assertoutput ( <nl> + applicationcontext , playbackoutput , " playbackdumps / silence / 500ms . dump " ) ; <nl> + } <nl> + }
public class sessionplayerconnectortest { <nl> assertthat ( onplaylistchangedlatch . getcount ( ) ) . isequalto ( 1 ) ; <nl> } <nl>  <nl> + <nl> + @ ignore <nl> @ test <nl> @ largetest <nl> @ sdksuppress ( minsdkversion = build . version_codes . kitkat )
public final class defaulthlsplaylisttracker <nl> } <nl> } <nl> if ( playlistsnapshot . servercontrol . skipuntilus ! = c . time_unset ) { <nl> - uribuilder . appendqueryparameter ( <nl> - skip_param , playlistsnapshot . servercontrol . canskipdateranges ? " v2 " : " yes " ) ; <nl> + <nl> + / / skip_param , playlistsnapshot . servercontrol . canskipdateranges ? " v2 " : " yes " ) ; <nl> } <nl> return uribuilder . build ( ) ; <nl> } <nl> mmm a / library / hls / src / test / java / com / google / android / exoplayer2 / source / hls / playlist / defaulthlsplaylisttrackertest . java <nl> ppp b / library / hls / src / test / java / com / google / android / exoplayer2 / source / hls / playlist / defaulthlsplaylisttrackertest . java <nl>
<nl> * / <nl> package com . google . android . exoplayer2 . trackselection ; <nl>  <nl> - import com . google . android . exoplayer2 . player ; <nl> - <nl> + <nl> / * * <nl> - * the component of a { @ link player } responsible for selecting tracks to be played . <nl> + * the component of a { @ code player } responsible for selecting tracks to be played . <nl> * <nl> * < p > no player agnostic track selection is currently supported . clients should downcast to the <nl> * implementation ' s track selection .
<nl> apply from : " $ gradle . ext . exoplayersettingsdir / constants . gradle " <nl> apply plugin : ' com . android . library ' <nl>  <nl> + repositories { <nl> + <nl> + maven { url " https : / / oss . sonatype . org / content / repositories / snapshots " } <nl> + } <nl> + <nl> android { <nl> compilesdkversion project . ext . compilesdkversion
<nl> + / * <nl> + * copyright ( c ) num the android open source project <nl> + * <nl> + * licensed under the apache license , version num . 0 ( the " license " ) ; <nl> + * you may not use this file except in compliance with the license . <nl> + * you may obtain a copy of the license at <nl> + * <nl> + * http : / / www . apache . org / licenses / license - 2 . 0 <nl> + * <nl> + * unless required by applicable law or agreed to in writing , software <nl> + * distributed under the license is distributed on an " as is " basis , <nl> + * without warranties or conditions of any kind , either express or implied . <nl> + * see the license for the specific language governing permissions and <nl> + * limitations under the license . <nl> + * / <nl> + package com . google . android . exoplayer2 . trackselection ; <nl> + <nl> + import com . google . android . exoplayer2 . player ; <nl> + <nl> + / * * <nl> + * the component of a { @ link player } responsible for selecting tracks to be played . <nl> + * <nl> + * < p > no player agnostic track selection is currently supported . clients should downcast to the <nl> + * implementation ' s track selection . <nl> + * / <nl> + <nl> + public interface trackselectorinterface { }
public final class playbackoutput implements dumper . dumpable { <nl> / / player . getcurrentposition ( ) inside onmetadata / cues will likely be non - deterministic <nl> / / because renderer - thread ! = playback - thread . <nl> player . addmetadataoutput ( metadatas : : add ) ; <nl> - player . addtextoutput ( subtitles : : add ) ; <nl> + <nl> } <nl>  <nl> / * * <nl> mmm a / testdata / src / test / assets / playbackdumps / dash / webvtt - in - mp4 . dump <nl> ppp b / testdata / src / test / assets / playbackdumps / dash / webvtt - in - mp4 . dump <nl>
public class gvraudioprocessor implements audioprocessor { <nl>  <nl> @ override <nl> public void queueendofstream ( ) { <nl> + <nl> if ( gvraudiosurround ! = null ) { <nl> gvraudiosurround . triggerprocessing ( ) ; <nl> } <nl> mmm a / library / core / src / main / java / com / google / android / exoplayer2 / audio / defaultaudiosink . java <nl> ppp b / library / core / src / main / java / com / google / android / exoplayer2 / audio / defaultaudiosink . java <nl>
public final class sonicaudioprocessor implements audioprocessor { <nl>  <nl> @ override <nl> public void queueinput ( bytebuffer inputbuffer ) { <nl> - sonic sonic = checknotnull ( this . sonic ) ; <nl> - if ( inputbuffer . hasremaining ( ) ) { <nl> - shortbuffer shortbuffer = inputbuffer . asshortbuffer ( ) ; <nl> - int inputsize = inputbuffer . remaining ( ) ; <nl> - inputbytes + = inputsize ; <nl> - sonic . queueinput ( shortbuffer ) ; <nl> - inputbuffer . position ( inputbuffer . position ( ) + inputsize ) ; <nl> - } <nl> - int outputsize = sonic . getoutputsize ( ) ; <nl> - if ( outputsize > num ) { <nl> - if ( buffer . capacity ( ) < outputsize ) { <nl> - buffer = bytebuffer . allocatedirect ( outputsize ) . order ( byteorder . nativeorder ( ) ) ; <nl> - shortbuffer = buffer . asshortbuffer ( ) ; <nl> - } else { <nl> - buffer . clear ( ) ; <nl> - shortbuffer . clear ( ) ; <nl> - } <nl> - sonic . getoutput ( shortbuffer ) ; <nl> - outputbytes + = outputsize ; <nl> - buffer . limit ( outputsize ) ; <nl> - outputbuffer = buffer ; <nl> + if ( ! inputbuffer . hasremaining ( ) ) { <nl> + return ; <nl> } <nl> + sonic sonic = checknotnull ( this . sonic ) ; <nl> + shortbuffer shortbuffer = inputbuffer . asshortbuffer ( ) ; <nl> + int inputsize = inputbuffer . remaining ( ) ; <nl> + inputbytes + = inputsize ; <nl> + sonic . queueinput ( shortbuffer ) ; <nl> + inputbuffer . position ( inputbuffer . position ( ) + inputsize ) ; <nl> } <nl>  <nl> @ override <nl> public void queueendofstream ( ) { <nl> + <nl> if ( sonic ! = null ) { <nl> sonic . queueendofstream ( ) ; <nl> } <nl>
public final class imaadsloader <nl> return imasdkfactory . getinstance ( ) <nl> . createadsloader ( context , imasdksettings , addisplaycontainer ) ; <nl> } <nl> + <nl> + / * * <nl> + * returns a language code that ' s suitable for passing to { @ link imasdksettings # setlanguage } and <nl> + * corresponds to the device ' s { @ link locale # getdefault ( ) default locale } . <nl> + * / <nl> + <nl> + / / ima will fall back to its default language code ( " en " ) if the value returned is unsupported . <nl> + private static string getimalanguagecodefordefaultlocale ( ) { <nl> + return util . splitatfirst ( util . getsystemlanguagecodes ( ) [ 0 ] , " - " ) [ 0 ] ; <nl> + } <nl> } <nl> }
public final class imaadsloader implements player . eventlistener , adsloader { <nl> return imasdkfactory . getinstance ( ) <nl> . createadsloader ( context , imasdksettings , addisplaycontainer ) ; <nl> } <nl> + <nl> + / * * <nl> + * returns a language code that ' s suitable for passing to { @ link imasdksettings # setlanguage } and <nl> + * corresponds to the device ' s { @ link locale # getdefault ( ) default locale } . <nl> + * / <nl> + <nl> + / / ima will fall back to its default language code ( " en " ) if the value returned is unsupported . <nl> + private static string getimalanguagecodefordefaultlocale ( ) { <nl> + return util . splitatfirst ( util . getsystemlanguagecodes ( ) [ 0 ] , " - " ) [ 0 ] ; <nl> + } <nl> } <nl> }
import com . google . android . gms . cast . mediatrack ; <nl> * / <nl> / * package * / final class castutils { <nl>  <nl> + / * * the duration returned by { @ link mediainfo # getstreamduration ( ) } for live streams . * / <nl> + <nl> + private static final long live_stream_duration = - 1000 ; <nl> + <nl> / * * <nl> * returns the duration in microseconds advertised by a media info , or { @ link c # time_unset } if <nl> * unknown or not applicable . <nl>
import com . google . android . gms . cast . mediatrack ; <nl> * / <nl> / * package * / final class castutils { <nl>  <nl> + / * * the duration returned by { @ link mediainfo # getstreamduration ( ) } for live streams . * / <nl> + <nl> + private static final long live_stream_duration = - 1000 ; <nl> + <nl> / * * <nl> * returns the duration in microseconds advertised by a media info , or { @ link c # time_unset } if <nl> * unknown or not applicable . <nl>
public class metadataretrievertest { <nl> listenablefuture < trackgrouparray > trackgroupsfuture ) <nl> throws interruptedexception , executionexception { <nl> while ( ! trackgroupsfuture . isdone ( ) ) { <nl> - / / simulate advancing systemclock so that delayed messages sent to handlers are received . <nl> + <nl> + / / looper are received . <nl> systemclock . setcurrenttimemillis ( systemclock . uptimemillis ( ) + num ) ; <nl> thread . sleep ( / * millis = * / num ) ; <nl> }
import org . junit . rules . externalresource ; <nl>  <nl> @ override <nl> protected void before ( ) { <nl> + / / workaround limitation in androidx . media2 . session : 1 . 0 . 3 which session can only be instantiated <nl> + / / on thread with prepared looper . <nl> + <nl> + if ( looper . mylooper ( ) = = null ) { <nl> + looper . prepare ( ) ; <nl> + } <nl> + <nl> context = applicationprovider . getapplicationcontext ( ) ; <nl> executor = executors . newfixedthreadpool ( 1 ) ; <nl>  <nl> instrumentationregistry . getinstrumentation ( ) <nl> . runonmainsync ( <nl> ( ) - > { <nl> - / / initialize audiomanager on the main thread to workaround b / 78617702 that <nl> + / / initialize audiomanager on the main thread to workaround that <nl> / / audio focus listener is called on the thread where the audiomanager was <nl> - / / originally initialized . <nl> + / / originally initialized . [ internal : b / 78617702 ] <nl> / / without posting this , audio focus listeners wouldn ' t be called because the <nl> / / listeners would be posted to the test thread ( here ) where it waits until the <nl> / / tests are finished .
public class utiltest { <nl>  <nl> assertthat ( result ) . isinstanceof ( spannablestring . class ) ; <nl> assertthat ( result . tostring ( ) ) . isequalto ( " a short " ) ; <nl> - spannedsubject . assertthat ( ( spanned ) result ) <nl> - . hasunderlinespanbetween ( 0 , num ) <nl> - . withflags ( spanned . span_exclusive_exclusive ) ; <nl> - spannedsubject . assertthat ( ( spanned ) result ) <nl> - . hasstrikethroughspanbetween ( 4 , num ) <nl> - . withflags ( spanned . span_inclusive_exclusive ) ; <nl> + <nl> + spanned spannedresult = ( spanned ) result ; <nl> + object [ ] spans = spannedresult . getspans ( 0 , result . length ( ) , object . class ) ; <nl> + assertthat ( spans ) . haslength ( 2 ) ; <nl> + assertthat ( spans [ 0 ] ) . isinstanceof ( underlinespan . class ) ; <nl> + assertthat ( spannedresult . getspanstart ( spans [ 0 ] ) ) . isequalto ( 0 ) ; <nl> + assertthat ( spannedresult . getspanend ( spans [ 0 ] ) ) . isequalto ( 7 ) ; <nl> + assertthat ( spannedresult . getspanflags ( spans [ 0 ] ) ) . isequalto ( spanned . span_exclusive_exclusive ) ; <nl> + assertthat ( spans [ 1 ] ) . isinstanceof ( strikethroughspan . class ) ; <nl> + assertthat ( spannedresult . getspanstart ( spans [ 1 ] ) ) . isequalto ( 4 ) ; <nl> + assertthat ( spannedresult . getspanend ( spans [ 1 ] ) ) . isequalto ( 7 ) ; <nl> + assertthat ( spannedresult . getspanflags ( spans [ 1 ] ) ) . isequalto ( spanned . span_inclusive_exclusive ) ; <nl> } <nl>  <nl> @ test
class asynchronousmediacodecbufferenqueuer implements mediacodecinputbufferenque <nl> } <nl>  <nl> / * * performs a deep copy of { @ code cryptoinfo } to { @ code frameworkcryptoinfo } . * / <nl> + <nl> + @ suppresswarnings ( " nullness : argument . type . incompatible " ) <nl> private static void copy ( <nl> cryptoinfo cryptoinfo , android . media . mediacodec . cryptoinfo frameworkcryptoinfo ) { <nl> / / update frameworkcryptoinfo fields directly because cryptoinfo . set performs an unnecessary
<nl> + / * <nl> + * copyright num the android open source project <nl> + * <nl> + * licensed under the apache license , version num . 0 ( the " license " ) ; <nl> + * you may not use this file except in compliance with the license . <nl> + * you may obtain a copy of the license at <nl> + * <nl> + * http : / / www . apache . org / licenses / license - 2 . 0 <nl> + * <nl> + * unless required by applicable law or agreed to in writing , software <nl> + * distributed under the license is distributed on an " as is " basis , <nl> + * without warranties or conditions of any kind , either express or implied . <nl> + * see the license for the specific language governing permissions and <nl> + * limitations under the license . <nl> + * / <nl> + package com . google . android . exoplayer2 ; <nl> + <nl> + import static com . google . common . truth . truth . assertthat ; <nl> + <nl> + import androidx . test . core . app . applicationprovider ; <nl> + import androidx . test . ext . junit . runners . androidjunit4 ; <nl> + import java . util . concurrent . atomic . atomicreference ; <nl> + import org . junit . test ; <nl> + import org . junit . runner . runwith ; <nl> + import org . robolectric . annotation . config ; <nl> + <nl> + / * * unit test for { @ link simpleexoplayer } . * / <nl> + @ runwith ( androidjunit4 . class ) <nl> + public class simpleexoplayertest { <nl> + <nl> + <nl> + @ test <nl> + @ config ( minsdk = config . oldest_sdk , maxsdk = config . target_sdk ) <nl> + public void builder_inbackgroundthread_doesnotthrow ( ) throws exception { <nl> + thread builderthread = <nl> + new thread ( <nl> + ( ) - > new simpleexoplayer . builder ( applicationprovider . getapplicationcontext ( ) ) . build ( ) ) ; <nl> + atomicreference < throwable > builderthrow = new atomicreference < > ( ) ; <nl> + builderthread . setuncaughtexceptionhandler ( ( thread , throwable ) - > builderthrow . set ( throwable ) ) ; <nl> + <nl> + builderthread . start ( ) ; <nl> + builderthread . join ( ) ; <nl> + <nl> + assertthat ( builderthrow . get ( ) ) . isnull ( ) ; <nl> + } <nl> + }
public final class exoplayertest { <nl> assertthat ( initialmediaitems ) . containsexactlyelementsin ( currentmediaitems ) ; <nl> } <nl>  <nl> + <nl> + @ test <nl> + @ config ( minsdk = config . oldest_sdk , maxsdk = config . target_sdk ) <nl> + public void buildsimpleexoplayerinbackgroundthread_doesnotthrow ( ) throws exception { <nl> + thread builderthread = new thread ( ( ) - > new simpleexoplayer . builder ( context ) . build ( ) ) ; <nl> + atomicreference < throwable > builderthrow = new atomicreference < > ( ) ; <nl> + builderthread . setuncaughtexceptionhandler ( ( thread , throwable ) - > builderthrow . set ( throwable ) ) ; <nl> + <nl> + builderthread . start ( ) ; <nl> + builderthread . join ( ) ; <nl> + <nl> + assertthat ( builderthrow . get ( ) ) . isnull ( ) ; <nl> + } <nl> + <nl> / / internal methods . <nl>  <nl> private static actionschedule . builder addsurfaceswitch ( actionschedule . builder builder ) {
public abstract class mediacodecrenderer extends baserenderer { <nl> formatqueue . add ( presentationtimeus , inputformat ) ; <nl> waitingforfirstsampleinformat = false ; <nl> } <nl> - largestqueuedpresentationtimeus = math . max ( largestqueuedpresentationtimeus , presentationtimeus ) ; <nl>  <nl> + <nl> + if ( c2mp3timestamptracker ! = null ) { <nl> + largestqueuedpresentationtimeus = math . max ( largestqueuedpresentationtimeus , buffer . timeus ) ; <nl> + } else { <nl> + largestqueuedpresentationtimeus = <nl> + math . max ( largestqueuedpresentationtimeus , presentationtimeus ) ; <nl> + } <nl> buffer . flip ( ) ; <nl> if ( buffer . hassupplementaldata ( ) ) { <nl> handleinputbuffersupplementaldata ( buffer ) ;
public final class concatenatingmediasource extends compositemediasource < mediaso <nl>  <nl> / / compositemediasource implementation . <nl>  <nl> - @ override <nl> - @ nullable <nl> - public object gettag ( ) { <nl> - return null ; <nl> + <nl> + public mediaitem getmediaitem ( ) { <nl> + / / this method is actually never called because getinitialtimeline is implemented and hence the <nl> + / / maskingmediasource does not need to create a dummy timeline for this media source . <nl> + return dummy_media_item ; <nl> } <nl>  <nl> @ override <nl>
public final class concatenatingmediasource extends compositemediasource < mediaso <nl> / / do nothing . <nl> } <nl>  <nl> - @ override <nl> - @ nullable <nl> - public object gettag ( ) { <nl> - return null ; <nl> + <nl> + public mediaitem getmediaitem ( ) { <nl> + return dummy_media_item ; <nl> } <nl>  <nl> @ override
public final class parsablebytearray { <nl> public byte [ ] data ; <nl>  <nl> private int position ; <nl> + <nl> + <nl> private int limit ; <nl>  <nl> / * * creates a new instance that initially has no backing data . * /
import org . checkerframework . checker . nullness . qual . requiresnonnull ; <nl> * / <nl> private static final class hlssamplequeue extends samplequeue { <nl>  <nl> - / * * <nl> - * the fraction of the chunk duration from which timestamps of samples loaded from within a <nl> - * chunk are allowed to deviate from the expected range . <nl> - * / <nl> - private static final double max_timestamp_deviation_fraction = num . 5 ; <nl> - <nl> - / * * <nl> - * a minimum tolerance for sample timestamps in microseconds . timestamps of samples loaded from <nl> - * within a chunk are always allowed to deviate up to this amount from the expected range . <nl> - * / <nl> - private static final long min_timestamp_deviation_tolerance_us = num _000_000 ; <nl> - <nl> - @ nullable private hlsmediachunk sourcechunk ; <nl> - private long sourcechunklastsampletimeus ; <nl> - private long minallowedsampletimeus ; <nl> - private long maxallowedsampletimeus ; <nl> + <nl> + / / / * * <nl> + / / * the fraction of the chunk duration from which timestamps of samples loaded from within a <nl> + / / * chunk are allowed to deviate from the expected range . <nl> + / / * / <nl> + / / private static final double max_timestamp_deviation_fraction = num . 5 ; <nl> + / / <nl> + / / / * * <nl> + / / * a minimum tolerance for sample timestamps in microseconds . timestamps of samples loaded <nl> + / / * from within a chunk are always allowed to deviate up to this amount from the expected <nl> + / / * range . <nl> + / / * / <nl> + / / private static final long min_timestamp_deviation_tolerance_us = num _000_000 ; <nl> + / / <nl> + / / @ nullable private hlsmediachunk sourcechunk ; <nl> + / / private long sourcechunklastsampletimeus ; <nl> + / / private long minallowedsampletimeus ; <nl> + / / private long maxallowedsampletimeus ; <nl>  <nl> private final map < string , drminitdata > overridingdrminitdata ; <nl> @ nullable private drminitdata drminitdata ; <nl>
import org . checkerframework . checker . nullness . qual . requiresnonnull ; <nl> } <nl>  <nl> public void setsourcechunk ( hlsmediachunk chunk ) { <nl> - sourcechunk = chunk ; <nl> - sourcechunklastsampletimeus = c . time_unset ; <nl> sourceid ( chunk . uid ) ; <nl>  <nl> - long alloweddeviationus = <nl> - math . max ( <nl> - ( long ) ( ( chunk . endtimeus - chunk . starttimeus ) * max_timestamp_deviation_fraction ) , <nl> - min_timestamp_deviation_tolerance_us ) ; <nl> - minallowedsampletimeus = chunk . starttimeus - alloweddeviationus ; <nl> - maxallowedsampletimeus = chunk . endtimeus + alloweddeviationus ; <nl> + <nl> + / / sourcechunk = chunk ; <nl> + / / sourcechunklastsampletimeus = c . time_unset ; <nl> + / / long alloweddeviationus = <nl> + / / math . max ( <nl> + / / ( long ) ( ( chunk . endtimeus - chunk . starttimeus ) * max_timestamp_deviation_fraction ) , <nl> + / / min_timestamp_deviation_tolerance_us ) ; <nl> + / / minallowedsampletimeus = chunk . starttimeus - alloweddeviationus ; <nl> + / / maxallowedsampletimeus = chunk . endtimeus + alloweddeviationus ; <nl> } <nl>  <nl> public void setdrminitdata ( @ nullable drminitdata drminitdata ) { <nl>
public class mediacodecaudiorenderer extends mediacodecrenderer implements media <nl> } <nl> int channelcount = mediaformat . getinteger ( mediaformat . key_channel_count ) ; <nl> int samplerate = mediaformat . getinteger ( mediaformat . key_sample_rate ) ; <nl> - int [ ] channelmap ; <nl> + @ nullable int [ ] channelmap = null ; <nl> if ( codecneedsdiscardchannelsworkaround & & channelcount = = num & & inputformat . channelcount < num ) { <nl> channelmap = new int [ inputformat . channelcount ] ; <nl> for ( int i = num ; i < inputformat . channelcount ; i + + ) { <nl> channelmap [ i ] = i ; <nl> } <nl> - } else { <nl> - channelmap = null ; <nl> } <nl> - configureaudiosink ( encoding , channelcount , samplerate , channelmap ) ; <nl> + try { <nl> + audiosink . configure ( <nl> + encoding , <nl> + channelcount , <nl> + samplerate , <nl> + / * specifiedbuffersize = * / num , <nl> + channelmap , <nl> + inputformat . encoderdelay , <nl> + inputformat . encoderpadding ) ; <nl> + } catch ( audiosink . configurationexception e ) { <nl> + <nl> + throw createrendererexception ( e , inputformat ) ; <nl> + } <nl> } <nl>  <nl> @ override <nl> protected void onoutputpassthroughformatchanged ( format outputformat ) throws exoplaybackexception { <nl> @ c . encoding <nl> int encoding = getpassthroughencoding ( outputformat . channelcount , outputformat . samplemimetype ) ; <nl> - configureaudiosink ( <nl> - encoding , outputformat . channelcount , outputformat . samplerate , / * channelmap = * / null ) ; <nl> + try { <nl> + audiosink . configure ( <nl> + encoding , <nl> + outputformat . channelcount , <nl> + outputformat . samplerate , <nl> + / * specifiedbuffersize = * / num , <nl> + / * outputchannels = * / null , <nl> + outputformat . encoderdelay , <nl> + outputformat . encoderpadding ) ; <nl> + } catch ( audiosink . configurationexception e ) { <nl> + throw createrendererexception ( e , outputformat ) ; <nl> + } <nl> } <nl>  <nl> / * * <nl>
public final class hlsplaylistparser implements parsingloadable . parser < hlsplayli <nl> segmentencryptioniv = long . tohexstring ( segmentmediasequence ) ; <nl> } <nl>  <nl> + string segmentresourseuri = replacevariablereferences ( line , variabledefinitions ) ; <nl> + <nl> segmentmediasequence + + ; <nl> if ( segmentbyterangelength = = c . length_unset ) { <nl> segmentbyterangeoffset = num ; <nl> + } else if ( isiframeonly ) { <nl> + / / if the i - frame segment is byte - ranged then check if there is an initialization segment , if not , <nl> + / / per the spec ( https : / / tools . ietf . org / html / draft - pantos - hls - rfc8216bis - 04 # section - 4 . 4 . 3 . 6 ) <nl> + / / it is assumed to be " located between the start of the resource and the offset of the <nl> + / / first i - frame segment " <nl> + <nl> + / / wipe previous implict init segment if base resource uri changes <nl> + if ( isexplicitinitsegment & & initializationsegment ! = null ) { <nl> + if ( ! segmentresourseuri . equals ( initializationsegment . url ) ) { <nl> + initializationsegment = null ; <nl> + } <nl> + } <nl> + <nl> + if ( initializationsegment = = null ) { <nl> + isexplicitinitsegment = true ; <nl> + initializationsegment = new segment ( <nl> + segmentresourseuri , <nl> + num , <nl> + segmentbyterangeoffset - num , <nl> + null , <nl> + null <nl> + ) ; <nl> + } <nl> } <nl>  <nl> if ( cacheddrminitdata = = null & & ! currentschemedatas . isempty ( ) ) { <nl>
public class samplequeue implements trackoutput { <nl> boolean loadingfinished , <nl> long decodeonlyuntilus , <nl> sampleextrasholder extrasholder ) { <nl> - if ( ! hasnextsample ( ) ) { <nl> + <nl> + / / this is a temporary fix for https : / / github . com / google / exoplayer / issues / 6155 . <nl> + <nl> + boolean hasnextsample ; <nl> + int relativereadindex = c . index_unset ; <nl> + while ( ( hasnextsample = hasnextsample ( ) ) ) { <nl> + relativereadindex = getrelativeindex ( readposition ) ; <nl> + long timeus = timesus [ relativereadindex ] ; <nl> + if ( timeus < decodeonlyuntilus <nl> + & & mimetypes . allsamplesaresyncsamples ( formats [ relativereadindex ] . samplemimetype ) ) { <nl> + readposition + + ; <nl> + } else { <nl> + break ; <nl> + } <nl> + } <nl> + <nl> + if ( ! hasnextsample ) { <nl> if ( loadingfinished | | islastsamplequeued ) { <nl> buffer . setflags ( c . buffer_flag_end_of_stream ) ; <nl> return c . result_buffer_read ; <nl>
public final class mimetypes { <nl> return base_type_application . equals ( gettopleveltype ( mimetype ) ) ; <nl> } <nl>  <nl> + / * * <nl> + * returns true if it is known that all samples in a stream of the given sample mime type are <nl> + * guaranteed to be sync samples ( i . e . , { @ link c # buffer_flag_key_frame } is guaranteed to be set on <nl> + * every sample ) . <nl> + * <nl> + * @ param mimetype the sample mime type . <nl> + * @ return true if it is known that all samples in a stream of the given sample mime type are <nl> + * guaranteed to be sync samples . false otherwise , including if { @ code null } is passed . <nl> + * / <nl> + public static boolean allsamplesaresyncsamples ( @ nullable string mimetype ) { <nl> + if ( mimetype = = null ) { <nl> + return false ; <nl> + } <nl> + <nl> + switch ( mimetype ) { <nl> + case audio_aac : <nl> + case audio_mpeg : <nl> + case audio_mpeg_l1 : <nl> + case audio_mpeg_l2 : <nl> + return true ; <nl> + default : <nl> + return false ; <nl> + } <nl> + } <nl> + <nl> / * * <nl> * derives a video sample mimetype from a codecs attribute . <nl> *
public final class flacextractor implements extractor { <nl> } <nl>  <nl> if ( foundendofinput ) { <nl> - / / reached the end of the file . assume it ' s the end of the frame . <nl> + / / verify whether there is a frame of size < max_frame_header_size at the end of the stream by <nl> + / / checking at every position at a distance between max_frame_header_size and minframesize <nl> + / / from the buffer limit if it corresponds to a valid frame header . <nl> + / / at every offset , the different possibilities are : <nl> + / / num . the current offset indicates the start of a valid frame header . in this case , consider <nl> + / / that a frame has been found and stop searching . <nl> + / / num . a frame starting at the current offset would be invalid . in this case , keep looking for <nl> + / / a valid frame header . <nl> + / / num . the current offset could be the start of a valid frame header , but there is not enough <nl> + / / bytes remaining to complete the header . as the end of the file has been reached , this <nl> + / / means that the current offset does not correspond to a new frame and that the last bytes <nl> + / / of the last frame happen to be a valid partial frame header . this case can occur in two <nl> + / / ways : <nl> + / / num . 1 . an attempt to read past the buffer is made when reading the potential frame header . <nl> + / / num . 2 . reading the potential frame header does not exceed the buffer size , but exceeds the <nl> + / / buffer limit . <nl> + / / note that the third case is very unlikely . it never happens if the end of the input has not <nl> + / / been reached as it is always made sure that the buffer has at least max_frame_header_size <nl> + / / bytes available when reading a potential frame header . <nl> + while ( frameoffset < = data . limit ( ) - minframesize ) { <nl> + data . setposition ( frameoffset ) ; <nl> + boolean framefound ; <nl> + try { <nl> + framefound = <nl> + flacframereader . checkandreadframeheader ( <nl> + data , flacstreammetadata , framestartmarker , samplenumberholder ) ; <nl> + } catch ( indexoutofboundsexception e ) { <nl> + / / case num . 1 . <nl> + framefound = false ; <nl> + } <nl> + if ( data . getposition ( ) > data . limit ( ) ) { <nl> + <nl> + framefound = false ; <nl> + } <nl> + if ( framefound ) { <nl> + / / case num . <nl> + data . setposition ( frameoffset ) ; <nl> + return samplenumberholder . samplenumber ; <nl> + } <nl> + frameoffset + + ; <nl> + } <nl> + / / the end of the frame is the end of the file . <nl> data . setposition ( data . limit ( ) ) ; <nl> } else { <nl> data . setposition ( frameoffset ) ;
public class samplequeue implements trackoutput { <nl> boolean loadingfinished , <nl> long decodeonlyuntilus , <nl> sampleextrasholder extrasholder ) { <nl> - if ( ! hasnextsample ( ) ) { <nl> + <nl> + / / this is a temporary fix for https : / / github . com / google / exoplayer / issues / 6155 . <nl> + <nl> + boolean hasnextsample ; <nl> + int relativereadindex = c . index_unset ; <nl> + while ( ( hasnextsample = hasnextsample ( ) ) ) { <nl> + relativereadindex = getrelativeindex ( readposition ) ; <nl> + long timeus = timesus [ relativereadindex ] ; <nl> + if ( timeus < decodeonlyuntilus <nl> + & & mimetypes . allsamplesaresyncsamples ( formats [ relativereadindex ] . samplemimetype ) ) { <nl> + readposition + + ; <nl> + } else { <nl> + break ; <nl> + } <nl> + } <nl> + <nl> + if ( ! hasnextsample ) { <nl> if ( loadingfinished | | islastsamplequeued ) { <nl> buffer . setflags ( c . buffer_flag_end_of_stream ) ; <nl> return c . result_buffer_read ; <nl>
public final class mimetypes { <nl> return base_type_application . equals ( gettopleveltype ( mimetype ) ) ; <nl> } <nl>  <nl> + / * * <nl> + * returns true if it is known that all samples in a stream of the given sample mime type are <nl> + * guaranteed to be sync samples ( i . e . , { @ link c # buffer_flag_key_frame } is guaranteed to be set on <nl> + * every sample ) . <nl> + * <nl> + * @ param mimetype the sample mime type . <nl> + * @ return true if it is known that all samples in a stream of the given sample mime type are <nl> + * guaranteed to be sync samples . false otherwise , including if { @ code null } is passed . <nl> + * / <nl> + public static boolean allsamplesaresyncsamples ( @ nullable string mimetype ) { <nl> + if ( mimetype = = null ) { <nl> + return false ; <nl> + } <nl> + <nl> + switch ( mimetype ) { <nl> + case audio_aac : <nl> + case audio_mpeg : <nl> + case audio_mpeg_l1 : <nl> + case audio_mpeg_l2 : <nl> + return true ; <nl> + default : <nl> + return false ; <nl> + } <nl> + } <nl> + <nl> / * * <nl> * derives a video sample mimetype from a codecs attribute . <nl> *
public final class flacextractor implements extractor { <nl> } <nl>  <nl> if ( foundendofinput ) { <nl> - / / reached the end of the file . assume it ' s the end of the frame . <nl> + / / verify whether there is a frame of size < max_frame_header_size at the end of the stream by <nl> + / / checking at every position at a distance between max_frame_header_size and minframesize <nl> + / / from the buffer limit if it corresponds to a valid frame header . <nl> + / / at every offset , the different possibilities are : <nl> + / / num . the current offset indicates the start of a valid frame header . in this case , consider <nl> + / / that a frame has been found and stop searching . <nl> + / / num . a frame starting at the current offset would be invalid . in this case , keep looking for <nl> + / / a valid frame header . <nl> + / / num . the current offset could be the start of a valid frame header , but there is not enough <nl> + / / bytes remaining to complete the header . as the end of the file has been reached , this <nl> + / / means that the current offset does not correspond to a new frame and that the last bytes <nl> + / / of the last frame happen to be a valid partial frame header . this case can occur in two <nl> + / / ways : <nl> + / / num . 1 . an attempt to read past the buffer is made when reading the potential frame header . <nl> + / / num . 2 . reading the potential frame header does not exceed the buffer size , but exceeds the <nl> + / / buffer limit . <nl> + / / note that the third case is very unlikely . it never happens if the end of the input has not <nl> + / / been reached as it is always made sure that the buffer has at least max_frame_header_size <nl> + / / bytes available when reading a potential frame header . <nl> + while ( frameoffset < = data . limit ( ) - minframesize ) { <nl> + data . setposition ( frameoffset ) ; <nl> + boolean framefound ; <nl> + try { <nl> + framefound = <nl> + flacframereader . checkandreadframeheader ( <nl> + data , flacstreammetadata , framestartmarker , samplenumberholder ) ; <nl> + } catch ( indexoutofboundsexception e ) { <nl> + / / case num . 1 . <nl> + framefound = false ; <nl> + } <nl> + if ( data . getposition ( ) > data . limit ( ) ) { <nl> + <nl> + framefound = false ; <nl> + } <nl> + if ( framefound ) { <nl> + / / case num . <nl> + data . setposition ( frameoffset ) ; <nl> + return samplenumberholder . samplenumber ; <nl> + } <nl> + frameoffset + + ; <nl> + } <nl> + / / the end of the frame is the end of the file . <nl> data . setposition ( data . limit ( ) ) ; <nl> } else { <nl> data . setposition ( frameoffset ) ;
<nl> + / * <nl> + * copyright ( c ) num the android open source project <nl> + * <nl> + * licensed under the apache license , version num . 0 ( the " license " ) ; <nl> + * you may not use this file except in compliance with the license . <nl> + * you may obtain a copy of the license at <nl> + * <nl> + * http : / / www . apache . org / licenses / license - 2 . 0 <nl> + * <nl> + * unless required by applicable law or agreed to in writing , software <nl> + * distributed under the license is distributed on an " as is " basis , <nl> + * without warranties or conditions of any kind , either express or implied . <nl> + * see the license for the specific language governing permissions and <nl> + * limitations under the license . <nl> + * <nl> + * / <nl> + package com . google . android . exoplayer2 . text . span ; <nl> + <nl> + import static java . lang . annotation . retentionpolicy . source ; <nl> + <nl> + import androidx . annotation . intdef ; <nl> + import java . lang . annotation . documented ; <nl> + import java . lang . annotation . retention ; <nl> + <nl> + / * * <nl> + * a styling span for ruby text . <nl> + * <nl> + * < p > the text covered by this span is known as the " base text " , and the ruby text is stored in <nl> + * { @ link # rubytext } . <nl> + * <nl> + * < p > more information on < a href = " https : / / en . wikipedia . org / wiki / ruby_character " > ruby characters < / a > <nl> + * and < a href = " https : / / developer . android . com / guide / topics / text / spans " > span styling < / a > . <nl> + * / <nl> + / / note : there ' s no android layout support for rubies , so this span currently doesn ' t extend any <nl> + / / styling superclasses ( e . g . metricaffectingspan ) . the only way to render these rubies is to <nl> + / / extract the spans and do the layout manually . <nl> + <nl> + public final class rubyspan { <nl> + <nl> + / * * the ruby position is unknown . * / <nl> + public static final int position_unknown = - 1 ; <nl> + <nl> + / * * <nl> + * the ruby text should be positioned above the base text . <nl> + * <nl> + * < p > for vertical text it should be positioned to the right , same as css ' s < a <nl> + * href = " https : / / developer . mozilla . org / en - us / docs / web / css / ruby - position " > ruby - position < / a > . <nl> + * / <nl> + public static final int position_over = num ; <nl> + <nl> + / * * <nl> + * the ruby text should be positioned below the base text . <nl> + * <nl> + * < p > for vertical text it should be positioned to the left , same as css ' s < a <nl> + * href = " https : / / developer . mozilla . org / en - us / docs / web / css / ruby - position " > ruby - position < / a > . <nl> + * / <nl> + public static final int position_under = num ; <nl> + <nl> + / * * <nl> + * the possible positions of the ruby text relative to the base text . <nl> + * <nl> + * < p > one of : <nl> + * <nl> + * < ul > <nl> + * < li > { @ link # position_unknown } <nl> + * < li > { @ link # position_over } <nl> + * < li > { @ link # position_under } <nl> + * < / ul > <nl> + * / <nl> + @ documented <nl> + @ retention ( source ) <nl> + @ intdef ( { position_unknown , position_over , position_under } ) <nl> + public @ interface position { } <nl> + <nl> + / * * the ruby text , i . e . the smaller explanatory characters . * / <nl> + public final string rubytext ; <nl> + <nl> + / * * the position of the ruby text relative to the base text . * / <nl> + @ position public final int position ; <nl> + <nl> + public rubyspan ( string rubytext , @ position int position ) { <nl> + this . rubytext = rubytext ; <nl> + this . position = position ; <nl> + } <nl> + }
public final class hlsplaylistparser implements parsingloadable . parser < hlsplayli <nl> } else if ( line . startswith ( tag_stream_inf ) ) { <nl> noclosedcaptions | = line . contains ( attr_closed_captions_none ) ; <nl> int bitrate = parseintattr ( line , regex_bandwidth ) ; <nl> - string averagebandwidthstring = <nl> - parseoptionalstringattr ( line , regex_average_bandwidth , variabledefinitions ) ; <nl> - if ( averagebandwidthstring ! = null ) { <nl> - / / if available , the average bandwidth attribute is used as the variant ' s bitrate . <nl> - bitrate = integer . parseint ( averagebandwidthstring ) ; <nl> - } <nl> + <nl> + int averagebitrate = parseoptionalintattr ( line , regex_average_bandwidth , - 1 ) ; <nl> string codecs = parseoptionalstringattr ( line , regex_codecs , variabledefinitions ) ; <nl> string resolutionstring = <nl> parseoptionalstringattr ( line , regex_resolution , variabledefinitions ) ; <nl>
project . ext { <nl> releaseversion = ' 2 . 11 . 0 ' <nl> releaseversioncode = num <nl> minsdkversion = num <nl> - targetsdkversion = num <nl> + apptargetsdkversion = num <nl> + targetsdkversion = num <nl> compilesdkversion = num <nl> dexmakerversion = ' 2 . 21 . 0 ' <nl> mockitoversion = ' 2 . 25 . 0 ' <nl> mmm a / demos / cast / build . gradle <nl> ppp b / demos / cast / build . gradle <nl>
public final class hlsplaylistparser implements parsingloadable . parser < hlsplayli <nl> } else if ( line . startswith ( tag_stream_inf ) ) { <nl> noclosedcaptions | = line . contains ( attr_closed_captions_none ) ; <nl> int bitrate = parseintattr ( line , regex_bandwidth ) ; <nl> - string averagebandwidthstring = <nl> - parseoptionalstringattr ( line , regex_average_bandwidth , variabledefinitions ) ; <nl> - if ( averagebandwidthstring ! = null ) { <nl> - / / if available , the average bandwidth attribute is used as the variant ' s bitrate . <nl> - bitrate = integer . parseint ( averagebandwidthstring ) ; <nl> - } <nl> + <nl> + int averagebitrate = parseoptionalintattr ( line , regex_average_bandwidth , - 1 ) ; <nl> string codecs = parseoptionalstringattr ( line , regex_codecs , variabledefinitions ) ; <nl> string resolutionstring = <nl> parseoptionalstringattr ( line , regex_resolution , variabledefinitions ) ; <nl>
project . ext { <nl> releaseversion = ' 2 . 11 . 0 ' <nl> releaseversioncode = num <nl> minsdkversion = num <nl> - targetsdkversion = num <nl> + apptargetsdkversion = num <nl> + targetsdkversion = num <nl> compilesdkversion = num <nl> dexmakerversion = ' 2 . 21 . 0 ' <nl> mockitoversion = ' 2 . 25 . 0 ' <nl> mmm a / demos / cast / build . gradle <nl> ppp b / demos / cast / build . gradle <nl>
import java . io . ioexception ; <nl> } <nl> } <nl>  <nl> + / * * <nl> + * returns whether it ' s possible to read the next sample . <nl> + * <nl> + * @ param relativereadindex the relative read <nl> + * @ return whether it ' s possible to read the next sample . <nl> + * / <nl> + private boolean mayreadsample ( int relativereadindex ) { <nl> + if ( drmsessionmanager = = drmsessionmanager . dummy ) { <nl> + <nl> + / / the renderers . we assume that the renderers will be able to acquire a drmsession if needed . <nl> + return true ; <nl> + } <nl> + return currentdrmsession = = null <nl> + | | currentdrmsession . getstate ( ) = = drmsession . state_opened_with_keys <nl> + | | ( ( flags [ relativereadindex ] & c . buffer_flag_encrypted ) = = num <nl> + & & currentdrmsession . playclearsampleswithoutkeys ( ) ) ; <nl> + } <nl> + <nl> / * * <nl> * finds the sample in the specified range that ' s before or at the specified time . if { @ code <nl> * keyframe } is { @ code true } then the sample is additionally required to be a keyframe .
import java . io . ioexception ; <nl> } <nl> } <nl>  <nl> + / * * <nl> + * returns whether it ' s possible to read the next sample . <nl> + * <nl> + * @ param relativereadindex the relative read <nl> + * @ return whether it ' s possible to read the next sample . <nl> + * / <nl> + private boolean mayreadsample ( int relativereadindex ) { <nl> + if ( drmsessionmanager = = drmsessionmanager . dummy ) { <nl> + <nl> + / / the renderers . we assume that the renderers will be able to acquire a drmsession if needed . <nl> + return true ; <nl> + } <nl> + return currentdrmsession = = null <nl> + | | currentdrmsession . getstate ( ) = = drmsession . state_opened_with_keys <nl> + | | ( ( flags [ relativereadindex ] & c . buffer_flag_encrypted ) = = num <nl> + & & currentdrmsession . playclearsampleswithoutkeys ( ) ) ; <nl> + } <nl> + <nl> / * * <nl> * finds the sample in the specified range that ' s before or at the specified time . if { @ code <nl> * keyframe } is { @ code true } then the sample is additionally required to be a keyframe .
public final class frameworkmediadrm implements exomediadrm < frameworkmediacrypto <nl> return mediadrm . querykeystatus ( sessionid ) ; <nl> } <nl>  <nl> + @ override <nl> + public void acquire ( ) { <nl> + <nl> + } <nl> + <nl> @ override <nl> public void release ( ) { <nl> mediadrm . release ( ) ;
public class defaultdrmsession < t extends exomediacrypto > implements drmsession < t <nl> postresponsehandler . obtainmessage ( msg . what , pair . create ( request , response ) ) . sendtotarget ( ) ; <nl> } <nl>  <nl> - private boolean mayberetryrequest ( message originalmsg ) { <nl> + private boolean mayberetryrequest ( message originalmsg , exception e ) { <nl> boolean allowretry = originalmsg . arg1 = = num ; <nl> if ( ! allowretry ) { <nl> return false ; <nl> } <nl> int errorcount = originalmsg . arg2 + num ; <nl> - if ( errorcount > initialdrmrequestretrycount ) { <nl> + if ( errorcount > loaderrorhandlingpolicy . getminimumloadableretrycount ( c . data_type_drm ) ) { <nl> return false ; <nl> } <nl> message retrymsg = message . obtain ( originalmsg ) ; <nl> retrymsg . arg2 = errorcount ; <nl> - sendmessagedelayed ( retrymsg , getretrydelaymillis ( errorcount ) ) ; <nl> - return true ; <nl> - } <nl>  <nl> - private long getretrydelaymillis ( int errorcount ) { <nl> - return math . min ( ( errorcount - num ) * num , num ) ; <nl> + ioexception ioexception = <nl> + e instanceof ioexception ? ( ioexception ) e : new unexpecteddrmsessionexception ( e ) ; <nl> + <nl> + long retrydelayms = <nl> + loaderrorhandlingpolicy . getretrydelaymsfor ( <nl> + c . data_type_drm , / * loaddurationms = * / c . time_unset , ioexception , errorcount ) ; <nl> + sendmessagedelayed ( retrymsg , retrydelayms ) ; <nl> + return true ; <nl> } <nl> } <nl> }
import kotlin . annotations . jvm . undermigration ; <nl> * / <nl> @ nonnull <nl> @ typequalifierdefault ( elementtype . type_use ) <nl> - @ undermigration ( status = migrationstatus . strict ) <nl> + <nl> + / / @ undermigration ( status = migrationstatus . strict ) <nl> @ retention ( retentionpolicy . class ) <nl> public @ interface nonnullapi { }
public final class decryptablesamplequeuereader { <nl> * updates the current format and manages any necessary drm resources . <nl> * <nl> * @ param format the format read from upstream . <nl> + * @ param outputformatholder the output { @ link formatholder } . <nl> * / <nl> - private void onformat ( format format ) { <nl> - drminitdata olddrminitdata = currentformat ! = null ? currentformat . drminitdata : null ; <nl> + private void onformat ( format format , formatholder outputformatholder ) { <nl> + outputformatholder . format = format ; <nl> currentformat = format ; <nl> + if ( sessionmanager = = drmsessionmanager . dummy ) { <nl> + / / avoid attempting to acquire a session using the dummy drm session manager . it ' s likely that <nl> + / / the media source creation has not yet been migrated and the renderer can acquire the <nl> + / / session for the read drm init data . <nl> + <nl> + return ; <nl> + } <nl> + outputformatholder . includesdrmsession = true ; <nl> + outputformatholder . drmsession = currentsession ; <nl> + drminitdata olddrminitdata = currentformat ! = null ? currentformat . drminitdata : null ; <nl> if ( util . areequal ( olddrminitdata , format . drminitdata ) ) { <nl> / / nothing to do . <nl> return ; <nl>
public final class playbackstatslistener <nl> * <nl> * @ param isfinal whether this is the final build and no further events are expected . <nl> * / <nl> + <nl> + @ suppresswarnings ( " nullness : conditional . type . incompatible " ) <nl> public playbackstats build ( boolean isfinal ) { <nl> long [ ] playbackstatedurationsms = this . playbackstatedurationsms ; <nl> list < long [ ] > mediatimehistory = this . mediatimehistory ;
<nl> package com . google . android . exoplayer2 ; <nl>  <nl> import androidx . annotation . nullable ; <nl> + import com . google . android . exoplayer2 . drm . decryptionresource ; <nl>  <nl> / * * <nl> * holds a { @ link format } . <nl> * / <nl> public final class formatholder { <nl>  <nl> + / * * <nl> + * whether the object expected to populate { @ link # format } is also expected to populate { @ link <nl> + * # decryptionresource } . <nl> + * / <nl> + <nl> + public boolean decryptionresourceisprovided ; <nl> + <nl> + / * * an accompanying context for decrypting samples in the format . * / <nl> + @ nullable public decryptionresource < ? > decryptionresource ; <nl> + <nl> / * * the held { @ link format } . * / <nl> - public @ nullable format format ; <nl> + @ nullable public format format ; <nl> }
<nl> + / * <nl> + * copyright ( c ) num the android open source project <nl> + * <nl> + * licensed under the apache license , version num . 0 ( the " license " ) ; <nl> + * you may not use this file except in compliance with the license . <nl> + * you may obtain a copy of the license at <nl> + * <nl> + * http : / / www . apache . org / licenses / license - 2 . 0 <nl> + * <nl> + * unless required by applicable law or agreed to in writing , software <nl> + * distributed under the license is distributed on an " as is " basis , <nl> + * without warranties or conditions of any kind , either express or implied . <nl> + * see the license for the specific language governing permissions and <nl> + * limitations under the license . <nl> + * / <nl> + package com . google . android . exoplayer2 . drm ; <nl> + <nl> + / * * <nl> + * a reference - counted resource used in the decryption of media samples . <nl> + * <nl> + * @ param < t > the reference type with which to make { @ link owner # onlastreferencereleased } calls . <nl> + * / <nl> + public abstract class cryptoresource < t extends cryptoresource < t > > { <nl> + <nl> + / * * <nl> + * implemented by the class in charge of managing a { @ link cryptoresource resource ' s } lifecycle . <nl> + * / <nl> + public interface owner < t extends cryptoresource < t > > { <nl> + <nl> + / * * <nl> + * called when the last reference to a { @ link cryptoresource } is { @ link # releasereference ( ) <nl> + * released } . <nl> + * / <nl> + void onlastreferencereleased ( cryptoresource < t > resource ) ; <nl> + } <nl> + <nl> + <nl> + private final cryptoresource . owner < t > owner ; <nl> + private int referencecount ; <nl> + <nl> + / * * <nl> + * creates a new instance with no incoming references . <nl> + * <nl> + * @ param owner the owner of this instance . <nl> + * / <nl> + public cryptoresource ( owner < t > owner ) { <nl> + this . owner = owner ; <nl> + referencecount = num ; <nl> + } <nl> + <nl> + / * * increases by one the incoming reference count for this resource . * / <nl> + public void acquirereference ( ) { <nl> + referencecount + + ; <nl> + } <nl> + <nl> + / * * <nl> + * decreases by one the incoming reference count for this resource , and notifies the owner if said <nl> + * count reached zero as a result of this operation . <nl> + * <nl> + * < p > must only be called as releasing counter - part of { @ link # acquirereference ( ) } . <nl> + * / <nl> + @ suppresswarnings ( " unchecked " ) <nl> + public synchronized void releasereference ( ) { <nl> + if ( - - referencecount = = num ) { <nl> + owner . onlastreferencereleased ( this ) ; <nl> + } else if ( referencecount < num ) { <nl> + throw new illegalstateexception ( " illegal release of resource . " ) ; <nl> + } <nl> + } <nl> + }
public final class simplecache implements cache { <nl> try { <nl> uid = createuid ( cachedir ) ; <nl> } catch ( ioexception e ) { <nl> - initializationexception = new cacheexception ( " failed to create cache uid : " + cachedir ) ; <nl> - return ; <nl> + string message = " failed to create cache uid : " + cachedir ; <nl> + log . e ( tag , message , e ) ; <nl> + <nl> + / / return ; <nl> } <nl> } <nl>  <nl>
public abstract class mediacodecrenderer extends baserenderer { <nl> reinitializecodec ( ) ; <nl> return ; <nl> } <nl> + if ( c . playready_uuid . equals ( sessionmediacrypto . uuid ) ) { <nl> + / / the playready cdm does not implement setmediadrmsession . <nl> + <nl> + reinitializecodec ( ) ; <nl> + return ; <nl> + } <nl>  <nl> if ( flushorreinitializecodec ( ) ) { <nl> / / the codec was reinitialized . the new codec will be using the new drm session , so there ' s
public final class exodatabaseprovider extends sqliteopenhelper implements datab <nl> } <nl> } <nl> } <nl> + <nl> + <nl> + / / to instantiate an exodatabaseprovider . <nl> + / * * <nl> + * a { @ link context } that only implements { @ link # getdatabasepath ( string ) } . this is the only <nl> + * method used by { @ link sqliteopenhelper } . <nl> + * / <nl> + private static class databasefileprovidingcontext extends contextwrapper { <nl> + <nl> + private final file file ; <nl> + <nl> + public databasefileprovidingcontext ( file file ) { <nl> + super ( / * base = * / null ) ; <nl> + this . file = file ; <nl> + } <nl> + <nl> + @ override <nl> + public file getdatabasepath ( string name ) { <nl> + return file ; <nl> + } <nl> + } <nl> }
<nl>  <nl> # # # dev - v2 ( not yet released ) # # # <nl>  <nl> + * support for playing spherical videos on daydream . <nl> + * improve decoder re - use between playbacks . <nl> + here ( [ # 2826 ] ( https : / / github . com / google / exoplayer / issues / 2826 ) ) . <nl> + * add options for controlling audio track selections to ` defaulttrackselector ` <nl> + ( [ # 3314 ] ( https : / / github . com / google / exoplayer / issues / 3314 ) ) . <nl> + * do not retry failed loads whose error is ` filenotfoundexception ` . <nl> + <nl> + # # # num . 9 . 2 # # # <nl> + <nl> * hls : <nl> * fix issue causing unnecessary media playlist requests when playing live <nl> streams ( [ # 5059 ] ( https : / / github . com / google / exoplayer / issues / 5059 ) ) . <nl>
public abstract class mediacodecrenderer extends baserenderer { <nl> @ override <nl> protected void ondisabled ( ) { <nl> inputformat = null ; <nl> + if ( drmsession ! = null | | pendingdrmsession ! = null ) { <nl> + <nl> + onreset ( ) ; <nl> + } else { <nl> + flushorreleasecodec ( ) ; <nl> + } <nl> + } <nl> + <nl> + @ override <nl> + protected void onreset ( ) { <nl> try { <nl> releasecodec ( ) ; <nl> } finally { <nl>
public abstract class mediacodecrenderer extends baserenderer { <nl> @ override <nl> protected void ondisabled ( ) { <nl> inputformat = null ; <nl> + if ( drmsession ! = null | | pendingdrmsession ! = null ) { <nl> + <nl> + onreset ( ) ; <nl> + } else { <nl> + flushorreleasecodec ( ) ; <nl> + } <nl> + } <nl> + <nl> + @ override <nl> + protected void onreset ( ) { <nl> try { <nl> releasecodec ( ) ; <nl> } finally { <nl>
public abstract class mediacodecrenderer extends baserenderer { <nl>  <nl> @ override <nl> protected void ondisabled ( ) { <nl> + if ( drmsession ! = null | | pendingdrmsession ! = null ) { <nl> + <nl> + onreset ( ) ; <nl> + } else { <nl> + flushorreleasecodec ( ) ; <nl> + } <nl> + } <nl> + <nl> + @ override <nl> + protected void onreset ( ) { <nl> format = null ; <nl> availablecodecinfos = null ; <nl> try {
public class defaultdrmsessionmanager < t extends exomediacrypto > implements drmse <nl> mode = mode_playback ; <nl> sessions = new arraylist < > ( ) ; <nl> provisioningsessions = new arraylist < > ( ) ; <nl> - if ( multisession ) { <nl> + if ( multisession & & c . widevine_uuid . equals ( uuid ) & & util . sdk_int > = num ) { <nl> + <nl> + / / implemented . or if custom renderers are being used that allow playback to proceed before <nl> + / / keys , which seems unlikely to be true in practice . <nl> mediadrm . setpropertystring ( " sessionsharing " , " enable " ) ; <nl> } <nl> mediadrm . setoneventlistener ( new mediadrmeventlistener ( ) ) ;
public class defaultdrmsessionmanager < t extends exomediacrypto > implements drmse <nl> mode = mode_playback ; <nl> sessions = new arraylist < > ( ) ; <nl> provisioningsessions = new arraylist < > ( ) ; <nl> - if ( multisession ) { <nl> + if ( multisession & & c . widevine_uuid . equals ( uuid ) & & util . sdk_int > = num ) { <nl> + <nl> + / / implemented . or if custom renderers are being used that allow playback to proceed before <nl> + / / keys , which seems unlikely to be true in practice . <nl> mediadrm . setpropertystring ( " sessionsharing " , " enable " ) ; <nl> } <nl> mediadrm . setoneventlistener ( new mediadrmeventlistener ( ) ) ;
public final class imaadsloader <nl> } <nl> } <nl>  <nl> - @ override <nl> + <nl> public int getvolume ( ) { <nl> if ( player = = null ) { <nl> return lastvolumepercentage ;
public class mediacodecaudiorenderer extends mediacodecrenderer implements media <nl> @ override <nl> protected @ keepcodecresult int cankeepcodec ( <nl> mediacodec codec , mediacodecinfo codecinfo , format oldformat , format newformat ) { <nl> - return getcodecmaxinputsize ( codecinfo , newformat ) < = codecmaxinputsize <nl> - & & areadaptationcompatible ( oldformat , newformat ) <nl> - ? keep_codec_result_yes_without_reconfiguration <nl> - : keep_codec_result_no ; <nl> + return keep_codec_result_no ; <nl> + <nl> + / / return getcodecmaxinputsize ( codecinfo , newformat ) < = codecmaxinputsize <nl> + / / & & areadaptationcompatible ( oldformat , newformat ) <nl> + / / ? keep_codec_result_yes_without_reconfiguration <nl> + / / : keep_codec_result_no ; <nl> } <nl>  <nl> @ override <nl>
public class mediacodecaudiorenderer extends mediacodecrenderer implements media <nl> @ override <nl> protected @ keepcodecresult int cankeepcodec ( <nl> mediacodec codec , mediacodecinfo codecinfo , format oldformat , format newformat ) { <nl> - return getcodecmaxinputsize ( codecinfo , newformat ) < = codecmaxinputsize <nl> - & & areadaptationcompatible ( oldformat , newformat ) <nl> - ? keep_codec_result_yes_without_reconfiguration <nl> - : keep_codec_result_no ; <nl> + return keep_codec_result_no ; <nl> + <nl> + / / return getcodecmaxinputsize ( codecinfo , newformat ) < = codecmaxinputsize <nl> + / / & & areadaptationcompatible ( oldformat , newformat ) <nl> + / / ? keep_codec_result_yes_without_reconfiguration <nl> + / / : keep_codec_result_no ; <nl> } <nl>  <nl> @ override <nl>
public final class clippingmediasource extends compositemediasource < void > { <nl> / * relativetodefaultposition = * / false ) ; <nl> } <nl>  <nl> + / * * <nl> + * creates a new clipping source that wraps the specified source and provides samples between the <nl> + * specified start and end position . <nl> + * <nl> + * @ param mediasource the single - period source to wrap . <nl> + * @ param startpositionus the start position within { @ code mediasource } ' s window at which to start <nl> + * providing samples , in microseconds . <nl> + * @ param endpositionus the end position within { @ code mediasource } ' s window at which to stop <nl> + * providing samples , in microseconds . specify { @ link c # time_end_of_source } to provide samples <nl> + * from the specified start point up to the end of the source . specifying a position that <nl> + * exceeds the { @ code mediasource } ' s duration will also result in the end of the source not <nl> + * being clipped . <nl> + * @ param enableinitialdiscontinuity whether the initial discontinuity should be enabled . <nl> + * / <nl> + <nl> + @ deprecated <nl> + public clippingmediasource ( <nl> + mediasource mediasource , <nl> + long startpositionus , <nl> + long endpositionus , <nl> + boolean enableinitialdiscontinuity ) { <nl> + this ( <nl> + mediasource , <nl> + startpositionus , <nl> + endpositionus , <nl> + enableinitialdiscontinuity , <nl> + / * allowdynamicclippingupdates = * / false , <nl> + / * relativetodefaultposition = * / false ) ; <nl> + } <nl> + <nl> / * * <nl> * creates a new clipping source that wraps the specified source and provides samples from the <nl> * default position for the specified duration .
decoder_func ( jlong , vpxinit , jboolean disableloopfilter ) { <nl> return num ; <nl> } <nl> if ( disableloopfilter ) { <nl> - vpx_codec_control_ ( context , vp9_set_skip_loop_filter , true ) ; <nl> + <nl> + err = vpx_codec_control_ ( context , vp9_set_skip_loop_filter , true ) ; <nl> + if ( err ) { <nl> + loge ( " error : failed to shut off libvpx loop filter , error = % d . " , err ) ; <nl> + } <nl> } <nl>  <nl> / / populate jni references .
public class mediacodecaudiorenderer extends mediacodecrenderer implements media <nl> return audiosink . getplaybackparameters ( ) ; <nl> } <nl>  <nl> + @ override <nl> + protected void onqueueinputbuffer ( decoderinputbuffer buffer ) { <nl> + if ( allowfirstbufferpositiondiscontinuity & & ! buffer . isdecodeonly ( ) ) { <nl> + <nl> + / / differs significantly from what was expected . <nl> + if ( math . abs ( buffer . timeus - currentpositionus ) > num ) { <nl> + currentpositionus = buffer . timeus ; <nl> + } <nl> + allowfirstbufferpositiondiscontinuity = false ; <nl> + } <nl> + } <nl> + <nl> @ override <nl> protected boolean processoutputbuffer ( long positionus , long elapsedrealtimeus , mediacodec codec , <nl> bytebuffer buffer , int bufferindex , int bufferflags , long bufferpresentationtimeus , <nl> mmm a / library / core / src / main / java / com / google / android / exoplayer2 / audio / simpledecoderaudiorenderer . java <nl> ppp b / library / core / src / main / java / com / google / android / exoplayer2 / audio / simpledecoderaudiorenderer . java <nl>
public abstract class simpledecoderaudiorenderer extends baserenderer implements <nl> eventdispatcher . inputformatchanged ( newformat ) ; <nl> } <nl>  <nl> + private void onqueueinputbuffer ( decoderinputbuffer buffer ) { <nl> + if ( allowfirstbufferpositiondiscontinuity & & ! buffer . isdecodeonly ( ) ) { <nl> + <nl> + / / differs significantly from what was expected . <nl> + if ( math . abs ( buffer . timeus - currentpositionus ) > num ) { <nl> + currentpositionus = buffer . timeus ; <nl> + } <nl> + allowfirstbufferpositiondiscontinuity = false ; <nl> + } <nl> + } <nl> + <nl> private void updatecurrentposition ( ) { <nl> long newcurrentpositionus = audiosink . getcurrentpositionus ( isended ( ) ) ; <nl> if ( newcurrentpositionus ! = audiosink . current_position_not_set ) {
public class mediacodecaudiorenderer extends mediacodecrenderer implements media <nl> return audiosink . getplaybackparameters ( ) ; <nl> } <nl>  <nl> + @ override <nl> + protected void onqueueinputbuffer ( decoderinputbuffer buffer ) { <nl> + if ( allowfirstbufferpositiondiscontinuity & & ! buffer . isdecodeonly ( ) ) { <nl> + <nl> + / / differs significantly from what was expected . <nl> + if ( math . abs ( buffer . timeus - currentpositionus ) > num ) { <nl> + currentpositionus = buffer . timeus ; <nl> + } <nl> + allowfirstbufferpositiondiscontinuity = false ; <nl> + } <nl> + } <nl> + <nl> @ override <nl> protected boolean processoutputbuffer ( long positionus , long elapsedrealtimeus , mediacodec codec , <nl> bytebuffer buffer , int bufferindex , int bufferflags , long bufferpresentationtimeus , <nl> mmm a / library / core / src / main / java / com / google / android / exoplayer2 / audio / simpledecoderaudiorenderer . java <nl> ppp b / library / core / src / main / java / com / google / android / exoplayer2 / audio / simpledecoderaudiorenderer . java <nl>
public abstract class simpledecoderaudiorenderer extends baserenderer implements <nl> eventdispatcher . inputformatchanged ( newformat ) ; <nl> } <nl>  <nl> + private void onqueueinputbuffer ( decoderinputbuffer buffer ) { <nl> + if ( allowfirstbufferpositiondiscontinuity & & ! buffer . isdecodeonly ( ) ) { <nl> + <nl> + / / differs significantly from what was expected . <nl> + if ( math . abs ( buffer . timeus - currentpositionus ) > num ) { <nl> + currentpositionus = buffer . timeus ; <nl> + } <nl> + allowfirstbufferpositiondiscontinuity = false ; <nl> + } <nl> + } <nl> + <nl> private void updatecurrentposition ( ) { <nl> long newcurrentpositionus = audiosink . getcurrentpositionus ( isended ( ) ) ; <nl> if ( newcurrentpositionus ! = audiosink . current_position_not_set ) {
public final class imaadsloader extends player . defaulteventlistener implements a <nl> return adgrouptimesus ; <nl> } <nl>  <nl> + private static boolean isadgrouploaderror ( aderror aderror ) { <nl> + <nl> + return aderror . geterrorcode ( ) = = aderrorcode . vast_linear_asset_mismatch ; <nl> + } <nl> }
public final class imaadsloader extends player . defaulteventlistener implements a <nl> return adgrouptimesus ; <nl> } <nl>  <nl> + private static boolean isadgrouploaderror ( aderror aderror ) { <nl> + <nl> + return aderror . geterrorcode ( ) = = aderrorcode . vast_linear_asset_mismatch ; <nl> + } <nl> }
public final class requirements { <nl> : util . sdk_int > = num ? ! powermanager . isinteractive ( ) : ! powermanager . isscreenon ( ) ; <nl> } <nl>  <nl> + private static boolean checkinternetconnectivity ( connectivitymanager connectivitymanager ) { <nl> + if ( util . sdk_int < num ) { <nl> + <nl> + return true ; <nl> + } <nl> + network activenetwork = connectivitymanager . getactivenetwork ( ) ; <nl> + if ( activenetwork = = null ) { <nl> + logd ( " no active network . " ) ; <nl> + return false ; <nl> + } <nl> + networkcapabilities networkcapabilities = <nl> + connectivitymanager . getnetworkcapabilities ( activenetwork ) ; <nl> + boolean validated = <nl> + networkcapabilities = = null <nl> + | | ! networkcapabilities . hascapability ( networkcapabilities . net_capability_validated ) ; <nl> + logd ( " network capability validated : " + validated ) ; <nl> + return ! validated ; <nl> + } <nl> + <nl> + private static boolean isactivenetworkmetered ( <nl> + connectivitymanager connectivitymanager , networkinfo networkinfo ) { <nl> + if ( util . sdk_int > = num ) { <nl> + return connectivitymanager . isactivenetworkmetered ( ) ; <nl> + } <nl> + int type = networkinfo . gettype ( ) ; <nl> + return type ! = connectivitymanager . type_wifi <nl> + & & type ! = connectivitymanager . type_bluetooth <nl> + & & type ! = connectivitymanager . type_ethernet ; <nl> + } <nl> + <nl> private static void logd ( string message ) { <nl> if ( scheduler . debug ) { <nl> log . d ( tag , message ) ;
public final class extractormediasource implements mediasource , extractormediape <nl> private void notifysourceinforefreshed ( long durationus , boolean isseekable ) { <nl> timelinedurationus = durationus ; <nl> timelineisseekable = isseekable ; <nl> - / / if the duration is currently unset , we expect to be able to update the window when its <nl> - / / duration eventually becomes known . <nl> - boolean isdynamic = timelinedurationus = = c . time_unset ; <nl> + <nl> sourcelistener . onsourceinforefreshed ( this , <nl> - new singleperiodtimeline ( timelinedurationus , timelineisseekable , isdynamic ) , null ) ; <nl> + new singleperiodtimeline ( timelinedurationus , timelineisseekable , false ) , null ) ; <nl> } <nl>  <nl> }
import java . util . concurrent . copyonwritearrayset ; <nl> if ( windowindex < num | | ( ! timeline . isempty ( ) & & windowindex > = timeline . getwindowcount ( ) ) ) { <nl> throw new illegalseekpositionexception ( timeline , windowindex , positionms ) ; <nl> } <nl> + if ( isplayingad ( ) ) { <nl> + <nl> + / / content position can be played , if a different ad is playing at the moment . <nl> + log . w ( tag , " seekto ignored because an ad is playing " ) ; <nl> + if ( pendingseekacks = = num ) { <nl> + for ( player . eventlistener listener : listeners ) { <nl> + listener . onseekprocessed ( ) ; <nl> + } <nl> + } <nl> + return ; <nl> + } <nl> pendingseekacks + + ; <nl> maskingwindowindex = windowindex ; <nl> if ( timeline . isempty ( ) ) {
public class cronetdatasource extends urlrequest . callback implements httpdatasou <nl> } <nl> requestbuilder . addheader ( " range " , rangevalue . tostring ( ) ) ; <nl> } <nl> + <nl> + / / force identity encoding unless gzip is allowed . <nl> + / / if ( ! dataspec . isflagset ( dataspec . flag_allow_gzip ) ) { <nl> + / / requestbuilder . addheader ( " accept - encoding " , " identity " ) ; <nl> + / / } <nl> / / set the method and ( if non - empty ) the body . <nl> if ( dataspec . postbody ! = null ) { <nl> requestbuilder . sethttpmethod ( " post " ) ;
public final class ttmldecodertest extends instrumentationtestcase { <nl> assertequals ( 1 , output . size ( ) ) ; <nl> ttmlcue = output . get ( 0 ) ; <nl> assertequals ( " dolor " , ttmlcue . text . tostring ( ) ) ; <nl> - assertequals ( 10f / num f , ttmlcue . position ) ; <nl> - assertequals ( 80f / num f , ttmlcue . line ) ; <nl> - assertequals ( 1f , ttmlcue . size ) ; <nl> + assertequals ( cue . dimen_unset , ttmlcue . position ) ; <nl> + assertequals ( cue . dimen_unset , ttmlcue . line ) ; <nl> + assertequals ( cue . dimen_unset , ttmlcue . size ) ; <nl> + <nl> + / / assertequals ( 80f / num f , ttmlcue . line ) ; <nl> + / / assertequals ( 1f , ttmlcue . size ) ; <nl>  <nl> output = subtitle . getcues ( 21000000 ) ; <nl> assertequals ( 1 , output . size ( ) ) ; <nl> mmm a / library / core / src / main / java / com / google / android / exoplayer2 / text / ttml / ttmldecoder . java <nl> ppp b / library / core / src / main / java / com / google / android / exoplayer2 / text / ttml / ttmldecoder . java <nl>
public final class ttmldecoder extends simplesubtitledecoder { <nl> return null ; <nl> } <nl> } else { <nl> + log . w ( tag , " ignoring region without an origin " ) ; <nl> + return null ; <nl> + <nl> / / origin is omitted . default to top left . <nl> - position = num ; <nl> - line = num ; <nl> + / / position = num ; <nl> + / / line = num ; <nl> } <nl>  <nl> float width ; <nl>
public final class ttmldecoder extends simplesubtitledecoder { <nl> return null ; <nl> } <nl> } else { <nl> + log . w ( tag , " ignoring region without an extent " ) ; <nl> + return null ; <nl> + <nl> / / extent is omitted . default to extent of parent . <nl> - width = num ; <nl> - height = num ; <nl> + / / width = num ; <nl> + / / height = num ; <nl> } <nl>  <nl> @ cue . anchortype int lineanchor = cue . anchor_type_start ;
import java . util . list ; <nl> drminitdata = drminitdata . copywithschemetype ( schemetype ) ; <nl> } <nl> parent . setposition ( childposition ) ; <nl> - } else { <nl> - drminitdata = null ; <nl> } <nl> + <nl> + / / drminitdata = null ; <nl> + / / } <nl>  <nl> list < byte [ ] > initializationdata = null ; <nl> string mimetype = null ; <nl>
import java . util . list ; <nl> drminitdata = drminitdata . copywithschemetype ( schemetype ) ; <nl> } <nl> parent . setposition ( childposition ) ; <nl> - } else { <nl> - drminitdata = null ; <nl> } <nl> + <nl> + / / drminitdata = null ; <nl> + / / } <nl>  <nl> / / if the atom type determines a mime type , set it immediately . <nl> string mimetype = null ;
public final class ttmldecodertest extends instrumentationtestcase { <nl> assertequals ( 1 , output . size ( ) ) ; <nl> ttmlcue = output . get ( 0 ) ; <nl> assertequals ( " dolor " , ttmlcue . text . tostring ( ) ) ; <nl> - assertequals ( 10f / num f , ttmlcue . position ) ; <nl> - assertequals ( 80f / num f , ttmlcue . line ) ; <nl> - assertequals ( 1f , ttmlcue . size ) ; <nl> + assertequals ( cue . dimen_unset , ttmlcue . position ) ; <nl> + assertequals ( cue . dimen_unset , ttmlcue . line ) ; <nl> + assertequals ( cue . dimen_unset , ttmlcue . size ) ; <nl> + <nl> + / / assertequals ( 80f / num f , ttmlcue . line ) ; <nl> + / / assertequals ( 1f , ttmlcue . size ) ; <nl>  <nl> output = subtitle . getcues ( 21000000 ) ; <nl> assertequals ( 1 , output . size ( ) ) ; <nl> mmm a / library / core / src / main / java / com / google / android / exoplayer2 / text / ttml / ttmldecoder . java <nl> ppp b / library / core / src / main / java / com / google / android / exoplayer2 / text / ttml / ttmldecoder . java <nl>
public final class ttmldecoder extends simplesubtitledecoder { <nl> return null ; <nl> } <nl> } else { <nl> + log . w ( tag , " ignoring region without an origin " ) ; <nl> + return null ; <nl> + <nl> / / origin is omitted . default to top left . <nl> - position = num ; <nl> - line = num ; <nl> + / / position = num ; <nl> + / / line = num ; <nl> } <nl>  <nl> float width ; <nl>
public final class ttmldecoder extends simplesubtitledecoder { <nl> return null ; <nl> } <nl> } else { <nl> + log . w ( tag , " ignoring region without an extent " ) ; <nl> + return null ; <nl> + <nl> / / extent is omitted . default to extent of parent . <nl> - width = num ; <nl> - height = num ; <nl> + / / width = num ; <nl> + / / height = num ; <nl> } <nl>  <nl> @ cue . anchortype int lineanchor = cue . anchor_type_start ;
package com . google . android . exoplayer2 . source ; <nl>  <nl> import com . google . android . exoplayer2 . c ; <nl>  <nl> + <nl> / * * <nl> * a loader that can proceed in approximate synchronization with other loaders . <nl> * /
public final class dashhostedtest extends exohostedtest { <nl> private static final float max_dropped_video_frame_fraction = num . 01f ; <nl>  <nl> private static final string manifest_url_prefix = " https : / / storage . googleapis . com / exoplayer - test - " <nl> - + " media - 1 / gen - 3 / screens / dash - vod - single - segment / " ; <nl> + + " media - 1 / gen - 4 / screens / dash - vod - single - segment / " ; <nl>  <nl> - private static final string widevine_l1_suffix = " - hw . mpd " ; <nl> - private static final string widevine_l3_suffix = " - sw . mpd " ; <nl> + <nl> + private static final string widevine_l1_suffix = " . mpd " ; <nl> + private static final string widevine_l3_suffix = " . mpd " ; <nl>  <nl> private static final string widevine_license_url = <nl> " https : / / proxy . uat . widevine . com / proxy ? provider = widevine_test & video_id = " ; <nl> mmm a / playbacktests / src / androidtest / java / com / google / android / exoplayer2 / playbacktests / gts / dashtestdata . java <nl> ppp b / playbacktests / src / androidtest / java / com / google / android / exoplayer2 / playbacktests / gts / dashtestdata . java <nl>
public final class fragmentedmp4extractor implements extractor { <nl> output . sampledata ( nalstartcode , num ) ; <nl> / / write the nal unit type byte . <nl> output . sampledata ( nalprefix , num ) ; <nl> + <nl> processseinalunitpayload = cea608trackoutput ! = null <nl> & & nalunitutil . isnalunitsei ( track . format . samplemimetype , nalprefixdata [ 4 ] ) ; <nl> samplebyteswritten + = num ; <nl> mmm a / library / src / main / java / com / google / android / exoplayer2 / text / cea / ceautil . java <nl> ppp b / library / src / main / java / com / google / android / exoplayer2 / text / cea / ceautil . java <nl>
public final class matroskaextractor implements extractor { <nl> nalunitlengthfieldlength = hevcconfig . nalunitlengthfieldlength ; <nl> break ; <nl> case codec_id_fourcc : <nl> - mimetype = mimetypes . video_vc1 ; <nl> initializationdata = parsefourccvc1private ( new parsablebytearray ( codecprivate ) ) ; <nl> + mimetype = initializationdata = = null ? mimetypes . video_unknown : mimetypes . video_vc1 ; <nl> + break ; <nl> + case codec_id_theora : <nl> + <nl> + mimetype = mimetypes . video_unknown ; <nl> break ; <nl> case codec_id_vorbis : <nl> mimetype = mimetypes . audio_vorbis ; <nl>
import java . util . arraylist ; <nl> allrenderersreadyorended = allrenderersreadyorended & & rendererreadyorended ; <nl> } <nl>  <nl> - boolean timelineisready = timeline . isready ( ) ; <nl> + <nl> + / / position update . we could probably return [ ended | ready | buffering ] and get rid of isended too . <nl> if ( allrenderersended & & ( playbackinfo . durationus = = c . unset_time_us <nl> - | | playbackinfo . durationus < = playbackinfo . positionus ) ) { <nl> + | | playbackinfo . durationus < = playbackinfo . positionus ) & & timeline . isended ( ) ) { <nl> setstate ( exoplayer . state_ended ) ; <nl> stoprenderers ( ) ; <nl> - } else if ( state = = exoplayer . state_buffering & & allrenderersreadyorended <nl> - & & havesufficientbuffer ( ) & & timelineisready ) { <nl> - setstate ( exoplayer . state_ready ) ; <nl> - if ( playwhenready ) { <nl> - startrenderers ( ) ; <nl> - } <nl> - } else if ( state = = exoplayer . state_ready & & ( ! allrenderersreadyorended | | ! timelineisready ) ) { <nl> - rebuffering = playwhenready ; <nl> - setstate ( exoplayer . state_buffering ) ; <nl> - stoprenderers ( ) ; <nl> + } else if ( state = = exoplayer . state_buffering ) { <nl> + if ( ( enabledrenderers . length > num ? allrenderersreadyorended : timeline . isready ( ) ) <nl> + & & havesufficientbuffer ( ) ) { <nl> + setstate ( exoplayer . state_ready ) ; <nl> + if ( playwhenready ) { <nl> + startrenderers ( ) ; <nl> + } <nl> + } <nl> + } else if ( state = = exoplayer . state_ready ) { <nl> + if ( enabledrenderers . length > num ? ! allrenderersreadyorended : ! timeline . isready ( ) ) { <nl> + rebuffering = playwhenready ; <nl> + setstate ( exoplayer . state_buffering ) ; <nl> + stoprenderers ( ) ; <nl> + } <nl> } <nl>  <nl> handler . removemessages ( msg_do_some_work ) ; <nl>
public final class exoplayerlibraryinfo { <nl> * three digits are used for each component of { @ link # version } . for example " 1 . 2 . 3 " has the <nl> * corresponding integer version num . <nl> * / <nl> + <nl> public static final int version_int = num ; <nl>  <nl> / * *
public final class hlssamplesource implements samplesource , loader . callback { <nl> lastseekpositionus = positionus ; <nl> downstreampositionus = positionus ; <nl> arrays . fill ( pendingresets , true ) ; <nl> - chunksource . seek ( ) ; <nl> - restartfrom ( positionus ) ; <nl> + boolean seekinsidebuffer = ! ispendingreset ( ) ; <nl> + <nl> + / / before for such tracks . for id3 we probably explicitly don ' t want the keyframe before , even <nl> + / / if we do have it , since it might be quite a long way behind the seek position . we probably <nl> + / / only want to output id3 buffers whose timestamps are greater than or equal to positionus . <nl> + for ( int i = num ; seekinsidebuffer & & i < samplequeues . length ; i + + ) { <nl> + if ( groupenabledstates [ i ] ) { <nl> + seekinsidebuffer = samplequeues [ i ] . skiptokeyframebefore ( positionus ) ; <nl> + } <nl> + } <nl> + if ( seekinsidebuffer ) { <nl> + while ( mediachunks . size ( ) > num & & mediachunks . get ( 1 ) . starttimeus < = positionus ) { <nl> + mediachunks . removefirst ( ) ; <nl> + } <nl> + } else { <nl> + / / if we failed to seek within the sample queues , we need to restart . <nl> + chunksource . seek ( ) ; <nl> + restartfrom ( positionus ) ; <nl> + } <nl> } <nl>  <nl> private void discardsamplesfordisabledtracks ( ) {
public final class tsextractor implements extractor { <nl> streamtype = ts_stream_type_h265 ; <nl> } <nl> break ; <nl> + } else if ( descriptortag = = num x6a ) { <nl> + streamtype = ts_stream_type_ac3 ; <nl> + } else if ( descriptortag = = num x7a ) { <nl> + streamtype = ts_stream_type_e_ac3 ; <nl> + } else if ( descriptortag = = num x7b ) { <nl> + <nl> } <nl> + <nl> data . skipbytes ( descriptorlength ) ; <nl> } <nl> data . setposition ( descriptorsendposition ) ;
public final class c { <nl> public static final int encoding_dts = num ; <nl> public static final int encoding_dts_hd = num ; <nl>  <nl> + <nl> + / * * <nl> + * @ see audioformat # channel_out_7point1_surround <nl> + * / <nl> + @ suppresswarnings ( { " inlinedapi " , " deprecation " } ) <nl> + public static final int channel_out_7point1_surround = util . sdk_int < num <nl> + ? audioformat . channel_out_7point1 : num ; <nl> + <nl> / * * <nl> * @ see mediaextractor # sample_flag_sync <nl> * / <nl> mmm a / library / src / main / java / com / google / android / exoplayer / audio / audiotrack . java <nl> ppp b / library / src / main / java / com / google / android / exoplayer / audio / audiotrack . java <nl>
public final class hlssamplesource implements samplesource , samplesourcereader , <nl> downstreammediaformats [ track ] = null ; <nl> pendingdiscontinuities [ track ] = false ; <nl> downstreamformat = null ; <nl> + boolean wasloadcontrolregistered = loadcontrolregistered ; <nl> if ( ! loadcontrolregistered ) { <nl> loadcontrol . register ( this , buffersizecontribution ) ; <nl> loadcontrolregistered = true ; <nl> } <nl> if ( enabledtrackcount = = num ) { <nl> - downstreampositionus = positionus ; <nl> lastseekpositionus = positionus ; <nl> - restartfrom ( positionus ) ; <nl> + if ( wasloadcontrolregistered & & downstreampositionus = = positionus ) { <nl> + <nl> + / / was passed to prepare . in this case we can avoid restarting , which would reload the same <nl> + / / chunks as were loaded during preparation . <nl> + maybestartloading ( ) ; <nl> + } else { <nl> + downstreampositionus = positionus ; <nl> + restartfrom ( positionus ) ; <nl> + } <nl> } <nl> }
public class hlschunksource { <nl> chunkmediasequence = switchingvariantspliced <nl> ? previoustschunk . chunkindex : previoustschunk . chunkindex + num ; <nl> if ( chunkmediasequence < mediaplaylist . mediasequence ) { <nl> + <nl> / / if the chunk is no longer in the playlist . skip ahead and start again . <nl> chunkmediasequence = getlivestartchunkmediasequence ( nextvariantindex ) ; <nl> livediscontinuity = true ; <nl> + / / } else { <nl> + / / fatalerror = new behindlivewindowexception ( ) ; <nl> + / / return null ; <nl> + / / } <nl> } <nl> } <nl> } else { <nl>
public class metadatatrackrenderer < t > extends trackrenderer implements callback <nl> try { <nl> source . continuebuffering ( trackindex , positionus ) ; <nl> } catch ( ioexception e ) { <nl> - throw new exoplaybackexception ( e ) ; <nl> + <nl> + / / throw new exoplaybackexception ( e ) ; <nl> } <nl>  <nl> if ( ! inputstreamended & & pendingmetadata = = null ) { <nl> mmm a / library / src / main / java / com / google / android / exoplayer / text / eia608 / eia608trackrenderer . java <nl> ppp b / library / src / main / java / com / google / android / exoplayer / text / eia608 / eia608trackrenderer . java <nl>
public class eia608trackrenderer extends trackrenderer implements callback { <nl> try { <nl> source . continuebuffering ( trackindex , positionus ) ; <nl> } catch ( ioexception e ) { <nl> - throw new exoplaybackexception ( e ) ; <nl> + <nl> + / / throw new exoplaybackexception ( e ) ; <nl> } <nl>  <nl> if ( issamplepending ( ) ) {
public class metadatatrackrenderer < t > extends trackrenderer implements callback <nl> inputstreamended = true ; <nl> } <nl> } catch ( ioexception e ) { <nl> - throw new exoplaybackexception ( e ) ; <nl> + <nl> + / / throw new exoplaybackexception ( e ) ; <nl> } <nl> } <nl>  <nl> mmm a / library / src / main / java / com / google / android / exoplayer / text / eia608 / eia608trackrenderer . java <nl> ppp b / library / src / main / java / com / google / android / exoplayer / text / eia608 / eia608trackrenderer . java <nl>
public class eia608trackrenderer extends trackrenderer implements callback { <nl> inputstreamended = true ; <nl> } <nl> } catch ( ioexception e ) { <nl> - throw new exoplaybackexception ( e ) ; <nl> + <nl> + / / throw new exoplaybackexception ( e ) ; <nl> } <nl> }
import java . util . collections ; <nl>  <nl> mpascratch . setposition ( 0 ) ; <nl>  <nl> - parsablebytearray header = new parsablebytearray ( mpascratch . getdata ( ) , headerlength ) ; <nl> + parsablebytearray header = new parsablebytearray ( mpascratch . data , headerlength ) ; <nl> output . sampledata ( header , headerlength ) ; <nl> } <nl> + <nl> + / * ( non - javadoc ) <nl> + * @ see com . google . android . exoplayer . extractor . ts . elementarystreamreader # seek ( ) <nl> + * / <nl> + @ override <nl> + public void seek ( ) { <nl> + <nl> + <nl> + } <nl> }
public final class tsextractor implements extractor , seekmap { <nl> continue ; <nl> } <nl>  <nl> + <nl> elementarystreamreader pespayloadreader = null ; <nl> switch ( streamtype ) { <nl> case ts_stream_type_aac : <nl> pespayloadreader = new adtsreader ( output . track ( ts_stream_type_aac ) ) ; <nl> break ; <nl> case ts_stream_type_atsc_ac3 : <nl> - case ts_stream_type_dvb_ac3 : <nl> pespayloadreader = new ac3reader ( output . track ( streamtype ) ) ; <nl> break ; <nl> case ts_stream_type_h264 :
public class hlssamplesource implements samplesource , loader . callback { <nl> assertions . checkstate ( prepared ) ; <nl> assertions . checkstate ( enabledtrackcount > num ) ; <nl> lastseekpositionus = positionus ; <nl> - if ( pendingresetpositionus = = positionus | | downstreampositionus = = positionus ) { <nl> - downstreampositionus = positionus ; <nl> + if ( ( ispendingreset ( ) ? pendingresetpositionus : downstreampositionus ) = = positionus ) { <nl> return ; <nl> } <nl> + <nl> + <nl> downstreampositionus = positionus ; <nl> for ( int i = num ; i < pendingdiscontinuities . length ; i + + ) { <nl> pendingdiscontinuities [ i ] = true ; <nl>
public class httpdatasource implements datasource { <nl> } <nl> } <nl>  <nl> + / * <nl> + * <nl> + * the size of the compressed response , where - as it should be returning the decompressed size or <nl> + * - 1 . see : developer . android . com / reference / java / net / httpurlconnection . html <nl> + * <nl> + * to fix this we should : <nl> + * <nl> + * num . explicitly require no compression for media requests ( since media should be compressed <nl> + * already ) by setting the accept - encoding header to " identity " <nl> + * num . in other cases , for example when requesting manifests , we don ' t want to disable compression . <nl> + * for these cases we should ensure that we return - 1 here ( and avoid performing any sanity <nl> + * checks on the content length ) . <nl> + * / <nl> @ override <nl> public long open ( dataspec dataspec ) throws httpdatasourceexception { <nl> this . dataspec = dataspec ; <nl>
public class dashchunksource implements chunksource { <nl> return ; <nl> } <nl>  <nl> - int lastsegmentnum = segmentindex . getlastsegmentnum ( ) ; <nl> - boolean indexunbounded = lastsegmentnum = = dashsegmentindex . index_unbounded ; <nl> + <nl> + long nowus = system . currenttimemillis ( ) * num ; <nl> + <nl> + int firstavailablesegmentnum = segmentindex . getfirstsegmentnum ( ) ; <nl> + int lastavailablesegmentnum = segmentindex . getlastsegmentnum ( ) ; <nl> + boolean indexunbounded = lastavailablesegmentnum = = dashsegmentindex . index_unbounded ; <nl> + if ( indexunbounded ) { <nl> + / / the <nl> + / / available segments . <nl> + long liveedgetimestampus = nowus - currentmanifest . availabilitystarttime * num ; <nl> + if ( currentmanifest . timeshiftbufferdepth ! = - 1 ) { <nl> + long bufferdepthus = currentmanifest . timeshiftbufferdepth * num ; <nl> + firstavailablesegmentnum = math . max ( firstavailablesegmentnum , <nl> + segmentindex . getsegmentnum ( liveedgetimestampus - bufferdepthus ) ) ; <nl> + } <nl> + / / getsegmentnum ( liveedgetimestampus ) will not be completed yet , so subtract one to get the <nl> + / / <nl> + lastavailablesegmentnum = segmentindex . getsegmentnum ( liveedgetimestampus ) - num ; <nl> + } <nl>  <nl> int segmentnum ; <nl> if ( queue . isempty ( ) ) { <nl> if ( currentmanifest . dynamic ) { <nl> - seekpositionus = getliveseekposition ( indexunbounded ) ; <nl> + seekpositionus = getliveseekposition ( nowus , indexunbounded ) ; <nl> } <nl> segmentnum = segmentindex . getsegmentnum ( seekpositionus ) ; <nl> } else { <nl>
public final class tschunk extends hlschunk { <nl>  <nl> @ override <nl> public void load ( ) throws ioexception , interruptedexception { <nl> - dataspec loaddataspec ; <nl> - if ( loadposition = = num ) { <nl> - loaddataspec = dataspec ; <nl> - } else { <nl> - long remaininglength = dataspec . length ! = c . length_unbounded <nl> - ? dataspec . length - loadposition : c . length_unbounded ; <nl> - loaddataspec = new dataspec ( dataspec . uri , dataspec . position + loadposition , <nl> - remaininglength , dataspec . key ) ; <nl> - } <nl> try { <nl> - datasource . open ( loaddataspec ) ; <nl> + datasource . open ( dataspec ) ; <nl> int bytesread = num ; <nl> + int bytesskipped = num ; <nl> + / / if we previously fed part of this chunk to the extractor , skip it this time . <nl> + <nl> + / / do this is straightforward for non - encrypted content , but more complicated for content <nl> + / / encrypted with aes , for which we ' ll need to modify the way that decryption is performed . <nl> + while ( bytesread ! = - 1 & & ! loadcanceled & & bytesskipped < loadposition ) { <nl> + int skiplength = math . min ( loadposition - bytesskipped , scratch_space . length ) ; <nl> + bytesread = datasource . read ( scratch_space , num , skiplength ) ; <nl> + if ( bytesread ! = - 1 ) { <nl> + bytesskipped + = bytesread ; <nl> + } <nl> + } <nl> + / / feed the remaining data into the extractor . <nl> while ( bytesread ! = - 1 & & ! loadcanceled ) { <nl> bytesread = extractor . read ( datasource ) ; <nl> + if ( bytesread ! = - 1 ) { <nl> + loadposition + = bytesread ; <nl> + } <nl> } <nl> loadfinished = ! loadcanceled ; <nl> } finally {
public class mediacodecutil { <nl> / * * <nl> * returns the best decoder and its capabilities for the given mimetype . if there ' s no decoder <nl> * returns null . <nl> + * <nl> + * <nl> * / <nl> + @ suppresswarnings ( " deprecation " ) <nl> private static synchronized pair < mediacodecinfo , codeccapabilities > getmediacodecinfo ( <nl> string mimetype ) { <nl> pair < mediacodecinfo , codeccapabilities > result = codecs . get ( mimetype ) ;
public class redissonsemaphoretest extends baseconcurrenttest { <nl> assertthat ( lockedcounter . get ( ) ) . isequalto ( iterations ) ; <nl> } <nl>  <nl> + @ test <nl> + public void testconcurrencyloopmax_multiinstance ( ) throws interruptedexception { <nl> + final int iterations = num ; <nl> + final atomicinteger lockedcounter = new atomicinteger ( ) ; <nl> + <nl> + rsemaphore s = redisson . getsemaphore ( " test " ) ; <nl> + s . trysetpermits ( integer . max_value ) ; <nl> + <nl> + testmultiinstanceconcurrency ( 4 , r - > { <nl> + for ( int i = num ; i < iterations ; i + + ) { <nl> + int v = integer . max_value ; <nl> + if ( threadlocalrandom . current ( ) . nextboolean ( ) ) { <nl> + v = num ; <nl> + } <nl> + try { <nl> + r . getsemaphore ( " test " ) . acquire ( v ) ; <nl> + } catch ( interruptedexception e1 ) { <nl> + <nl> + e1 . printstacktrace ( ) ; <nl> + } <nl> + try { <nl> + thread . sleep ( 10 ) ; <nl> + } catch ( interruptedexception e ) { <nl> + e . printstacktrace ( ) ; <nl> + } <nl> + lockedcounter . incrementandget ( ) ; <nl> + r . getsemaphore ( " test " ) . release ( v ) ; <nl> + } <nl> + } ) ; <nl> + <nl> + assertthat ( lockedcounter . get ( ) ) . isequalto ( 4 * iterations ) ; <nl> + } <nl> + <nl> @ test <nl> public void testconcurrencyloop_multiinstance ( ) throws interruptedexception { <nl> final int iterations = num ;
public class redissontest { <nl> assertthat ( success ) . isgreaterthan ( 5000 ) ; <nl> } <nl>  <nl> - <nl> + @ test <nl> + public void testfailoverinclusterslave ( ) throws exception { <nl> + redisrunner master1 = new redisrunner ( ) . port ( 6890 ) . randomdir ( ) . nosave ( ) ; <nl> + redisrunner master2 = new redisrunner ( ) . port ( 6891 ) . randomdir ( ) . nosave ( ) ; <nl> + redisrunner master3 = new redisrunner ( ) . port ( 6892 ) . randomdir ( ) . nosave ( ) ; <nl> + redisrunner slave1 = new redisrunner ( ) . port ( 6900 ) . randomdir ( ) . nosave ( ) ; <nl> + redisrunner slave2 = new redisrunner ( ) . port ( 6901 ) . randomdir ( ) . nosave ( ) ; <nl> + redisrunner slave3 = new redisrunner ( ) . port ( 6902 ) . randomdir ( ) . nosave ( ) ; <nl> + <nl> + clusterrunner clusterrunner = new clusterrunner ( ) <nl> + . addnode ( master1 , slave1 ) <nl> + . addnode ( master2 , slave2 ) <nl> + . addnode ( master3 , slave3 ) ; <nl> + clusterprocesses process = clusterrunner . run ( ) ; <nl> + <nl> + thread . sleep ( 5000 ) ; <nl> + <nl> + config config = new config ( ) ; <nl> + config . useclusterservers ( ) <nl> + . setloadbalancer ( new randomloadbalancer ( ) ) <nl> + . addnodeaddress ( process . getnodes ( ) . stream ( ) . findany ( ) . get ( ) . getredisserveraddressandport ( ) ) ; <nl> + redissonclient redisson = redisson . create ( config ) ; <nl> + <nl> + redisprocess slave = process . getnodes ( ) . stream ( ) . filter ( x - > x . getredisserverport ( ) = = slave1 . getport ( ) ) . findfirst ( ) . get ( ) ; <nl> + <nl> + list < rfuture < ? > > futures = new arraylist < rfuture < ? > > ( ) ; <nl> + countdownlatch latch = new countdownlatch ( 1 ) ; <nl> + thread t = new thread ( ) { <nl> + public void run ( ) { <nl> + for ( int i = num ; i < num ; i + + ) { <nl> + rfuture < ? > f1 = redisson . getbucket ( " i " + i ) . getasync ( ) ; <nl> + futures . add ( f1 ) ; <nl> + try { <nl> + thread . sleep ( 100 ) ; <nl> + } catch ( interruptedexception e ) { <nl> + <nl> + e . printstacktrace ( ) ; <nl> + } <nl> + if ( i % num = = num ) { <nl> + system . out . println ( " step : " + i ) ; <nl> + } <nl> + } <nl> + latch . countdown ( ) ; <nl> + } ; <nl> + } ; <nl> + t . start ( ) ; <nl> + t . join ( 1000 ) ; <nl> + <nl> + slave . stop ( ) ; <nl> + system . out . println ( " slave " + slave . getredisserveraddressandport ( ) + " has been stopped ! " ) ; <nl> + <nl> + assertthat ( latch . await ( 30 , timeunit . seconds ) ) . istrue ( ) ; <nl> + <nl> + int errors = num ; <nl> + int success = num ; <nl> + int readonlyerrors = num ; <nl> + <nl> + for ( rfuture < ? > rfuture : futures ) { <nl> + rfuture . awaituninterruptibly ( ) ; <nl> + if ( ! rfuture . issuccess ( ) ) { <nl> + errors + + ; <nl> + } else { <nl> + success + + ; <nl> + } <nl> + } <nl> + <nl> + redisson . shutdown ( ) ; <nl> + process . shutdown ( ) ; <nl> + <nl> + assertthat ( readonlyerrors ) . iszero ( ) ; <nl> + assertthat ( errors ) . islessthan ( 50 ) ; <nl> + assertthat ( success ) . isgreaterthan ( 150 ) ; <nl> + } <nl> + <nl> + <nl> @ test <nl> public void testreconnection ( ) throws ioexception , interruptedexception , timeoutexception { <nl> redisprocess runner = new redisrunner ( )
import reactor . fn . supplier ; <nl> * @ author nikita koksharov <nl> * <nl> * / <nl> + <nl> + / / methodtype . methodtype ( method . getreturntype ( ) , method . getparametertypes ( ) ) ) ; <nl> public class reactiveproxybuilder { <nl>  <nl> private static class cachekey { <nl> mmm a / redisson / src / main / java / org / redisson / rx / rxproxybuilder . java <nl> ppp b / redisson / src / main / java / org / redisson / rx / rxproxybuilder . java <nl>
import org . redisson . api . rfuture ; <nl> * @ author nikita koksharov <nl> * <nl> * / <nl> + <nl> + / / methodtype . methodtype ( method . getreturntype ( ) , method . getparametertypes ( ) ) ) ; <nl> public class rxproxybuilder { <nl>  <nl> private static class cachekey {
public class redischannelinitializer extends channelinitializer < channel > { <nl>  <nl> sslparameters sslparams = new sslparameters ( ) ; <nl> if ( config . issslenableendpointidentification ( ) ) { <nl> - sslparams . setendpointidentificationalgorithm ( " https " ) ; <nl> + <nl> + try { <nl> + method method = sslparams . getclass ( ) . getdeclaredmethod ( " setendpointidentificationalgorithm " , string . class ) ; <nl> + method . invoke ( sslparams , " https " ) ; <nl> + } catch ( exception e ) { <nl> + throw new sslexception ( e ) ; <nl> + } <nl> } else { <nl> if ( config . getssltruststore ( ) = = null ) { <nl> sslcontextbuilder . trustmanager ( insecuretrustmanagerfactory . instance ) ; <nl> mmm a / redisson / src / main / java / org / redisson / client / protocol / decoder / pendingresultdecoder . java <nl> ppp b / redisson / src / main / java / org / redisson / client / protocol / decoder / pendingresultdecoder . java <nl>
public abstract class basetest { <nl> if ( ! redissonruntimeenvironment . istravis ) { <nl> redisrunner . startdefaultredisserverinstance ( ) ; <nl> defaultredisson = createinstance ( ) ; <nl> - } <nl> - } <nl> - <nl> - @ afterclass <nl> - public static void afterclass ( ) throws ioexception , interruptedexception { <nl> - if ( ! redissonruntimeenvironment . istravis ) { <nl> - defaultredisson . shutdown ( ) ; <nl> - redisrunner . shutdowndefaultredisserverinstance ( ) ; <nl> + runtime . getruntime ( ) . addshutdownhook ( new thread ( ) { <nl> + @ override <nl> + public void run ( ) { <nl> + defaultredisson . shutdown ( ) ; <nl> + try { <nl> + redisrunner . shutdowndefaultredisserverinstance ( ) ; <nl> + } catch ( interruptedexception e ) { <nl> + <nl> + e . printstacktrace ( ) ; <nl> + } <nl> + } <nl> + } ) ; <nl> } <nl> }
public class redissonsortedset < v > extends redissonobject implements rsortedset < v <nl> return res ; <nl> } <nl>  <nl> + <nl> public binarysearchresult < v > binarysearch ( v value , codec codec ) { <nl> int size = list . size ( ) ; <nl> int upperindex = size - num ;
public class redissonlocktest extends baseconcurrenttest { <nl> @ test <nl> public void testautoexpire ( ) throws interruptedexception { <nl> final countdownlatch latch = new countdownlatch ( 1 ) ; <nl> - testsingleinstanceconcurrency ( 1 , r - > { <nl> - rlock lock = r . getlock ( " lock " ) ; <nl> - lock . lock ( ) ; <nl> - latch . countdown ( ) ; <nl> - } ) ; <nl> + <nl> + redissonclient r = createinstance ( ) ; <nl> + <nl> + thread t = new thread ( ) { <nl> + @ override <nl> + public void run ( ) { <nl> + rlock lock = r . getlock ( " lock " ) ; <nl> + lock . lock ( ) ; <nl> + latch . countdown ( ) ; <nl> + try { <nl> + thread . sleep ( 15000 ) ; <nl> + } catch ( interruptedexception e ) { <nl> + <nl> + e . printstacktrace ( ) ; <nl> + } <nl> + } <nl> + } ; <nl> + <nl> + t . start ( ) ; <nl>  <nl> assert . asserttrue ( latch . await ( 1 , timeunit . seconds ) ) ; <nl> rlock lock = redisson . getlock ( " lock " ) ; <nl> - thread . sleep ( timeunit . seconds . tomillis ( redissonlock . lock_expiration_interval_seconds + num ) ) ; <nl> + t . join ( ) ; <nl> + r . shutdown ( ) ; <nl> + thread . sleep ( timeunit . seconds . tomillis ( redissonlock . lock_expiration_interval_seconds ) ) ; <nl> assert . assertfalse ( " transient lock has not expired automatically " , lock . islocked ( ) ) ; <nl> }
public class redissonblockingqueuetest extends basetest { <nl> config . usesingleserver ( ) . setaddress ( " 127 . 0 . 0 . 1 : 6319 " ) ; <nl> redissonclient redisson = redisson . create ( config ) ; <nl>  <nl> + final atomicboolean executed = new atomicboolean ( ) ; <nl> + <nl> + thread t = new thread ( ) { <nl> + public void run ( ) { <nl> + try { <nl> + rblockingqueue < integer > queue1 = redisson . getblockingqueue ( " queue : pollany " ) ; <nl> + long start = system . currenttimemillis ( ) ; <nl> + integer res = queue1 . poll ( 10 , timeunit . seconds ) ; <nl> + assertthat ( system . currenttimemillis ( ) - start ) . isgreaterthan ( 2000 ) ; <nl> + assertthat ( res ) . isequalto ( 123 ) ; <nl> + executed . set ( true ) ; <nl> + } catch ( interruptedexception e ) { <nl> + <nl> + e . printstacktrace ( ) ; <nl> + } <nl> + } ; <nl> + } ; <nl> + <nl> + t . start ( ) ; <nl> + t . join ( 1000 ) ; <nl> + runner . stop ( ) ; <nl> + <nl> + runner = new redisrunner ( ) <nl> + . port ( 6319 ) <nl> + . nosave ( ) <nl> + . randomdir ( ) <nl> + . run ( ) ; <nl> + <nl> + thread . sleep ( 1000 ) ; <nl> + <nl> + rblockingqueue < integer > queue1 = redisson . getblockingqueue ( " queue : pollany " ) ; <nl> + queue1 . put ( 123 ) ; <nl> + <nl> + t . join ( ) ; <nl> + <nl> + await ( ) . atmost ( 5 , timeunit . seconds ) . until ( ( ) - > assertthat ( executed . get ( ) ) . istrue ( ) ) ; <nl> + <nl> + runner . stop ( ) ; <nl> + } <nl> + <nl> + @ test <nl> + public void testpollasyncreattach ( ) throws interruptedexception , ioexception , executionexception , timeoutexception { <nl> + redisprocess runner = new redisrunner ( ) <nl> + . port ( 6319 ) <nl> + . nosave ( ) <nl> + . randomdir ( ) <nl> + . run ( ) ; <nl> + <nl> + config config = new config ( ) ; <nl> + config . usesingleserver ( ) . setaddress ( " 127 . 0 . 0 . 1 : 6319 " ) ; <nl> + redissonclient redisson = redisson . create ( config ) ; <nl> + <nl> rblockingqueue < integer > queue1 = redisson . getblockingqueue ( " queue : pollany " ) ; <nl> future < integer > f = queue1 . pollasync ( 10 , timeunit . seconds ) ; <nl> f . await ( 1 , timeunit . seconds ) ;
public class redisconnection implements rediscommands { <nl> } <nl>  <nl> public < r > r await ( future < r > cmd ) { <nl> + <nl> if ( ! cmd . awaituninterruptibly ( redisclient . gettimeout ( ) , timeunit . milliseconds ) ) { <nl> promise < r > promise = ( promise < r > ) cmd ; <nl> redistimeoutexception ex = new redistimeoutexception ( " command execution timeout for " + redisclient . getaddr ( ) ) ; <nl> mmm a / src / main / java / org / redisson / connection / masterslaveconnectionmanager . java <nl> ppp b / src / main / java / org / redisson / connection / masterslaveconnectionmanager . java <nl>
public class redissonblockingqueuetest extends basetest { <nl>  <nl> @ test <nl> public void testpolllastandofferfirstto ( ) throws interruptedexception { <nl> - rblockingqueue < integer > queue1 = redisson . getblockingqueue ( " { queue } 1 " ) ; <nl> - queue1 . put ( 1 ) ; <nl> - queue1 . put ( 2 ) ; <nl> - queue1 . put ( 3 ) ; <nl> + final rblockingqueue < integer > queue1 = redisson . getblockingqueue ( " { queue } 1 " ) ; <nl> + executors . newsinglethreadscheduledexecutor ( ) . schedule ( new runnable ( ) { <nl> + @ override <nl> + public void run ( ) { <nl> + try { <nl> + queue1 . put ( 3 ) ; <nl> + } catch ( interruptedexception e ) { <nl> + <nl> + e . printstacktrace ( ) ; <nl> + } <nl> + } <nl> + } , num , timeunit . seconds ) ; <nl>  <nl> rblockingqueue < integer > queue2 = redisson . getblockingqueue ( " { queue } 2 " ) ; <nl> queue2 . put ( 4 ) ;
public class redissonlocktest extends baseconcurrenttest { <nl> public void run ( ) { <nl> rlock lock = redisson . getlock ( " lock " ) ; <nl> lock . lock ( ) ; <nl> + <nl> + try { <nl> + thread . sleep ( 1000 ) ; <nl> + } catch ( interruptedexception e ) { <nl> + <nl> + e . printstacktrace ( ) ; <nl> + } <nl> + <nl> + lock . unlock ( ) ; <nl> } ; <nl> } ; <nl>  <nl> t . start ( ) ; <nl> - t . join ( ) ; <nl> - <nl> - lock . unlock ( ) ; <nl> + t . join ( 400 ) ; <nl> + <nl> + try { <nl> + lock . unlock ( ) ; <nl> + } catch ( illegalmonitorstateexception e ) { <nl> + t . join ( ) ; <nl> + throw e ; <nl> + } <nl> }
import org . hamcrest . * ; <nl> import org . junit . * ; <nl> import org . redisson . core . * ; <nl>  <nl> + import io . netty . util . concurrent . future ; <nl> + <nl> public class redissonblockingqueuetest extends basetest { <nl>  <nl> + @ test <nl> + public void testpollfromany ( ) throws interruptedexception { <nl> + final rblockingqueue < integer > queue1 = redisson . getblockingqueue ( " queue : pollany " ) ; <nl> + executors . newsinglethreadscheduledexecutor ( ) . schedule ( new runnable ( ) { <nl> + @ override <nl> + public void run ( ) { <nl> + rblockingqueue < integer > queue2 = redisson . getblockingqueue ( " queue : pollany1 " ) ; <nl> + rblockingqueue < integer > queue3 = redisson . getblockingqueue ( " queue : pollany2 " ) ; <nl> + try { <nl> + queue1 . put ( 1 ) ; <nl> + queue3 . put ( 2 ) ; <nl> + queue2 . put ( 3 ) ; <nl> + } catch ( interruptedexception e ) { <nl> + <nl> + e . printstacktrace ( ) ; <nl> + } <nl> + } <nl> + } , num , timeunit . seconds ) ; <nl> + <nl> + long s = system . currenttimemillis ( ) ; <nl> + int l = queue1 . pollfromany ( 4 , timeunit . seconds , " queue : pollany1 " , " queue : pollany2 " ) ; <nl> + <nl> + assert . assertequals ( 2 , l ) ; <nl> + assert . asserttrue ( system . currenttimemillis ( ) - s > num ) ; <nl> + } <nl> + <nl> @ test <nl> public void testtake ( ) throws interruptedexception { <nl> rblockingqueue < integer > queue1 = redisson . getblockingqueue ( " queue : take " ) ;
import org . redisson . core . * ; <nl>  <nl> public class redissonblockingqueuetest extends basetest { <nl>  <nl> + @ test <nl> + public void testtake ( ) throws interruptedexception { <nl> + rblockingqueue < integer > queue1 = redisson . getblockingqueue ( " queue : take " ) ; <nl> + executors . newsinglethreadscheduledexecutor ( ) . schedule ( new runnable ( ) { <nl> + @ override <nl> + public void run ( ) { <nl> + rblockingqueue < integer > queue = redisson . getblockingqueue ( " queue : take " ) ; <nl> + try { <nl> + queue . put ( 3 ) ; <nl> + } catch ( interruptedexception e ) { <nl> + <nl> + e . printstacktrace ( ) ; <nl> + } <nl> + } <nl> + } , num , timeunit . seconds ) ; <nl> + <nl> + long s = system . currenttimemillis ( ) ; <nl> + int l = queue1 . take ( ) ; <nl> + <nl> + assert . assertequals ( 3 , l ) ; <nl> + assert . asserttrue ( system . currenttimemillis ( ) - s > num ) ; <nl> + <nl> + <nl> + } <nl> + <nl> @ test <nl> public void testpoll ( ) throws interruptedexception { <nl> rblockingqueue < integer > queue1 = redisson . getblockingqueue ( " queue1 " ) ;
public class redissonatomiclong extends redissonexpirable implements ratomiclong <nl>  <nl> @ override <nl> public long get ( ) { <nl> - number res = connectionmanager . read ( new resultoperation < number , number > ( ) { <nl> - @ override <nl> - protected future < number > execute ( redisasyncconnection < object , number > async ) { <nl> - return async . get ( getname ( ) ) ; <nl> - } <nl> - } ) ; <nl> - return res . longvalue ( ) ; <nl> + return addandget ( 0 ) ; <nl> } <nl>  <nl> @ override <nl> public long getandadd ( long delta ) { <nl> while ( true ) { <nl> + <nl> long current = get ( ) ; <nl> long next = current + delta ; <nl> if ( compareandset ( current , next ) ) <nl>
public class redissontopic < m > extends redissonobject implements rtopic < m > { <nl>  <nl> @ override <nl> public long publish ( m message ) { <nl> + <nl> redisconnection < string , object > conn = connectionmanager . connectionwriteop ( ) ; <nl> try { <nl> return conn . publish ( getname ( ) , message ) ; <nl>
import com . lambdaworks . redis . pubsub . redispubsublistener ; <nl> * @ author nikita koksharov <nl> * <nl> * / <nl> + <nl> public class connectionmanager { <nl>  <nl> public static class pubsubentry { <nl>
public class connectionwatchdog extends channelinboundhandleradapter implements <nl> * / <nl> @ override <nl> public void run ( timeout timeout ) throws exception { <nl> - bootstrap . connect ( ) ; <nl> + channelpipeline old = channel . pipeline ( ) ; <nl> + final commandhandler < ? , ? > handler = old . get ( commandhandler . class ) ; <nl> + final redisasyncconnection < ? , ? > connection = old . get ( redisasyncconnection . class ) ; <nl> + <nl> + channelfuture connect = null ; <nl> + <nl> + synchronized ( bootstrap ) { <nl> + connect = bootstrap . handler ( new channelinitializer < channel > ( ) { <nl> + @ override <nl> + protected void initchannel ( channel ch ) throws exception { <nl> + ch . pipeline ( ) . addlast ( this , handler , connection ) ; <nl> + } <nl> + } ) . connect ( ) ; <nl> + } <nl> + connect . sync ( ) ; <nl> } <nl> }
public class redissonlock implements rlock { <nl>  <nl> @ override <nl> public condition newcondition ( ) { <nl> + <nl> throw new unsupportedoperationexception ( ) ; <nl> }
public class redissonset < v > implements set < v > { <nl>  <nl> @ override <nl> public iterator < v > iterator ( ) { <nl> + <nl> return ( iterator < v > ) connection . smembers ( name ) . iterator ( ) ; <nl> } <nl>  <nl> mmm / dev / null <nl> ppp b / src / test / java / org / redisson / baseredissontest . java <nl>
public class redisclient { <nl> private < k , v , t extends redisasyncconnection < k , v > > t connect ( final commandhandler < k , v > handler , final t connection ) { <nl> try { <nl> final connectionwatchdog watchdog = new connectionwatchdog ( bootstrap , channels , timer ) ; <nl> - bootstrap . handler ( new channelinitializer < channel > ( ) { <nl> - @ override <nl> - protected void initchannel ( channel ch ) throws exception { <nl> - ch . pipeline ( ) . addlast ( watchdog , handler , connection ) ; <nl> - } <nl> - } ) ; <nl> - <nl> - bootstrap . connect ( ) . sync ( ) ; <nl> + <nl> + channelfuture connect = null ; <nl> + <nl> + synchronized ( bootstrap ) { <nl> + connect = bootstrap . handler ( new channelinitializer < channel > ( ) { <nl> + @ override <nl> + protected void initchannel ( channel ch ) throws exception { <nl> + ch . pipeline ( ) . addlast ( watchdog , handler , connection ) ; <nl> + } <nl> + } ) . connect ( ) ; <nl> + } <nl> + connect . sync ( ) ; <nl>  <nl> watchdog . setreconnect ( true ) ;
<nl> + package org . redisson ; <nl> + <nl> + import java . util . collection ; <nl> + import java . util . hashmap ; <nl> + import java . util . hashset ; <nl> + import java . util . map ; <nl> + import java . util . set ; <nl> + <nl> + import com . lambdaworks . redis . redisconnection ; <nl> + <nl> + public class redissonmap < k , v > implements map < k , v > { <nl> + <nl> + private final redisconnection < object , object > connection ; <nl> + private final string name ; <nl> + <nl> + redissonmap ( redisconnection < object , object > connection , string name ) { <nl> + this . connection = connection ; <nl> + this . name = name ; <nl> + } <nl> + <nl> + @ override <nl> + public int size ( ) { <nl> + return connection . hlen ( name ) . intvalue ( ) ; <nl> + } <nl> + <nl> + @ override <nl> + public boolean isempty ( ) { <nl> + return size ( ) = = num ; <nl> + } <nl> + <nl> + @ override <nl> + public boolean containskey ( object key ) { <nl> + return connection . hexists ( name , key ) ; <nl> + } <nl> + <nl> + @ override <nl> + public boolean containsvalue ( object value ) { <nl> + return connection . hvals ( name ) . contains ( value ) ; <nl> + } <nl> + <nl> + @ override <nl> + public v get ( object key ) { <nl> + return ( v ) connection . hget ( name , key ) ; <nl> + } <nl> + <nl> + @ override <nl> + public v put ( k key , v value ) { <nl> + v prev = get ( key ) ; <nl> + connection . hset ( name , key , value ) ; <nl> + return prev ; <nl> + } <nl> + <nl> + @ override <nl> + public v remove ( object key ) { <nl> + v prev = get ( key ) ; <nl> + connection . hdel ( name , key ) ; <nl> + return prev ; <nl> + } <nl> + <nl> + @ override <nl> + public void putall ( map < ? extends k , ? extends v > map ) { <nl> + connection . hmset ( name , ( map < object , object > ) map ) ; <nl> + } <nl> + <nl> + @ override <nl> + public void clear ( ) { <nl> + object [ ] fields = connection . hkeys ( name ) . toarray ( ) ; <nl> + connection . hdel ( name , fields ) ; <nl> + } <nl> + <nl> + @ override <nl> + public set < k > keyset ( ) { <nl> + <nl> + return new hashset < k > ( ( collection < ? extends k > ) connection . hkeys ( name ) ) ; <nl> + } <nl> + <nl> + @ override <nl> + public collection < v > values ( ) { <nl> + return ( collection < v > ) connection . hvals ( name ) ; <nl> + } <nl> + <nl> + @ override <nl> + public set < java . util . map . entry < k , v > > entryset ( ) { <nl> + map < object , object > map = connection . hgetall ( name ) ; <nl> + map < k , v > result = new hashmap < k , v > ( ) ; <nl> + for ( java . util . map . entry < object , object > entry : map . entryset ( ) ) { <nl> + result . put ( ( k ) entry . getkey ( ) , ( v ) entry . getvalue ( ) ) ; <nl> + } <nl> + return result . entryset ( ) ; <nl> + } <nl> + <nl> + }
public class consumerservice extends baseservice { <nl>  <nl> protected popmessagerequestheader buildpopmessagerequestheader ( context ctx , receivemessagerequest request ) { <nl> checksubscriptiondata ( request . getmessagequeue ( ) . gettopic ( ) , request . getfilterexpression ( ) ) ; <nl> - boolean fifo = grpcclientmanager . getclientsettings ( ctx ) . getsubscription ( ) . getfifo ( ) ; <nl> + <nl> + boolean fifo = false ; <nl> return grpcconverter . buildpopmessagerequestheader ( request , grpcconverter . buildpolltimefromcontext ( ctx ) , fifo ) ; <nl> }
public class dledgercommitlog extends commitlog { <nl> } <nl> / / indicate that , it is the first time to load mixed commitlog , need to recover the old commitlog <nl> isinrecoveringoldcommitlog = true ; <nl> + <nl> if ( lastok ) { <nl> super . recovernormally ( maxphyoffsetofconsumequeue ) ; <nl> } else { <nl>
public class dledgercommitlog extends commitlog { <nl> bytebuffer . putint ( mappedfile . getfilesize ( ) - mappedfile . getwroteposition ( ) ) ; <nl> bytebuffer . putint ( blank_magic_code ) ; <nl> mappedfile . flush ( 0 ) ; <nl> + <nl> mappedfile . setwroteposition ( mappedfile . getfilesize ( ) ) ; <nl> mappedfile . setcommittedposition ( mappedfile . getfilesize ( ) ) ; <nl> mappedfile . setflushedposition ( mappedfile . getfilesize ( ) ) ;
<nl> + image : <nl> + file : . gitpod . dockerfile <nl> + <nl> + tasks : <nl> + - init : ' echo " <nl> + command : ( e . g . ' npm start ' , ' yarn watch ' . . . ) <nl> mmm a / readme . md <nl> ppp b / readme . md <nl>
<nl> + package ciphers ; <nl> + <nl> + import java . util . * ; <nl> + <nl> + / * * <nl> + * <nl> + * the simple substitution cipher is a cipher that has been in use for many hundreds of years <nl> + * ( an excellent history is given in simon singhs ' the code book ' ) . <nl> + * it basically consists of substituting every plaintext character for a different ciphertext character . <nl> + * it differs from the caesar cipher in that the cipher alphabet is not simply the alphabet shifted , <nl> + * it is completely jumbled . <nl> + * <nl> + * @ author hassan elseoudy <nl> + * / <nl> + <nl> + public class simplesubstitutioncipher { <nl> + <nl> + / * * <nl> + * encrypt text by replacing each element with its opposite character . <nl> + * <nl> + * @ param message <nl> + * @ param ciphersmall <nl> + * @ return encrypted message <nl> + * / <nl> + public static string encode ( string message , string ciphersmall ) { <nl> + string encoded = " " ; <nl> + <nl> + / / this map is used to encode <nl> + map < character , character > ciphermap = new hashmap < character , character > ( ) ; <nl> + <nl> + char beginsmallletter = ' a ' ; <nl> + char begincapitalletter = ' a ' ; <nl> + <nl> + ciphersmall = ciphersmall . tolowercase ( ) ; <nl> + string ciphercapital = ciphersmall . touppercase ( ) ; <nl> + <nl> + / / to handle small and capital letters <nl> + for ( int i = num ; i < ciphersmall . length ( ) ; i + + ) { <nl> + ciphermap . put ( beginsmallletter + + , ciphersmall . charat ( i ) ) ; <nl> + ciphermap . put ( begincapitalletter + + , ciphercapital . charat ( i ) ) ; <nl> + } <nl> + <nl> + for ( int i = num ; i < message . length ( ) ; i + + ) { <nl> + if ( character . isalphabetic ( message . charat ( i ) ) ) <nl> + encoded + = ciphermap . get ( message . charat ( i ) ) ; <nl> + else <nl> + encoded + = message . charat ( i ) ; <nl> + } <nl> + <nl> + return encoded ; <nl> + } <nl> + <nl> + / * * <nl> + * decrypt message by replacing each element with its opposite character in cipher . <nl> + * <nl> + * @ param encryptedmessage <nl> + * @ param ciphersmall <nl> + * @ return message <nl> + * / <nl> + public static string decode ( string encryptedmessage , string ciphersmall ) { <nl> + string decoded = " " ; <nl> + <nl> + <nl> + map < character , character > ciphermap = new hashmap < character , character > ( ) ; <nl> + <nl> + char beginsmallletter = ' a ' ; <nl> + char begincapitalletter = ' a ' ; <nl> + <nl> + ciphersmall = ciphersmall . tolowercase ( ) ; <nl> + string ciphercapital = ciphersmall . touppercase ( ) ; <nl> + <nl> + for ( int i = num ; i < ciphersmall . length ( ) ; i + + ) { <nl> + ciphermap . put ( ciphersmall . charat ( i ) , beginsmallletter + + ) ; <nl> + ciphermap . put ( ciphercapital . charat ( i ) , begincapitalletter + + ) ; <nl> + } <nl> + <nl> + for ( int i = num ; i < encryptedmessage . length ( ) ; i + + ) { <nl> + if ( character . isalphabetic ( encryptedmessage . charat ( i ) ) ) <nl> + decoded + = ciphermap . get ( encryptedmessage . charat ( i ) ) ; <nl> + else <nl> + decoded + = encryptedmessage . charat ( i ) ; <nl> + } <nl> + <nl> + return decoded ; <nl> + } <nl> + <nl> + / * * <nl> + * <nl> + * <nl> + * / <nl> + public static void main ( string [ ] args ) { <nl> + string a = encode ( " defend the east wall of the castle " , " phqgiumeaylnofdxjkrcvstzwb " ) ; <nl> + string b = decode ( a , " phqgiumeaylnofdxjkrcvstzwb " ) ; <nl> + system . out . println ( b ) ; <nl> + } <nl> + <nl> + } <nl> \ no newline at end of file
class matrix { <nl> } <nl>  <nl> / * * <nl> - * matrix fast power <nl> - * <nl> - * @ param k : power of matrix <nl> - * @ return product <nl> - * / <nl> - public matrix matrixfastpower ( int k ) throws runtimeexception { <nl> - <nl> - if ( this . getcolumns ( ) ! = this . getrows ( ) ) <nl> - throw new runtimeexception ( " matrix is not square matrix . " ) ; <nl> - <nl> - int [ ] [ ] newdata = new int [ this . getcolumns ( ) ] [ this . getrows ( ) ] ; <nl> - <nl> - for ( int i = num ; i < this . getcolumns ( ) ; i + + ) <nl> - newdata [ i ] [ i ] = num ; <nl> - <nl> - matrix newmatrix = new matrix ( newdata ) , <nl> - comatrix = new matrix ( this . data ) ; <nl> - <nl> - while ( k ! = num ) { <nl> - <nl> - if ( ( k & num ) ! = num ) <nl> - newmatrix = newmatrix . multiply ( comatrix ) ; <nl> - <nl> - k > > = num ; <nl> - comatrix = comatrix . multiply ( comatrix ) ; <nl> + * returns the matrix as a string in the following format <nl> + * <nl> + * [ a b c ] . . . <nl> + * [ x y z ] . . . <nl> + * [ i j k ] . . . <nl> + * . . . <nl> + * <nl> + * @ return matrix as string <nl> + * <nl> + * / <nl> + public string tostring ( ) { <nl> + string str = " " ; <nl> + <nl> + for ( int i = num ; i < this . data . length ; i + + ) { <nl> + str + = " [ " ; <nl> + <nl> + for ( int j = num ; j < this . data [ 0 ] . length ; j + + ) { <nl> + str + = data [ i ] [ j ] ; <nl> + str + = " " ; <nl> + } <nl>  <nl> + str + = " ] " ; <nl> + str + = " \n " ; <nl> } <nl>  <nl> - return newmatrix ; <nl> + return str ; <nl> } <nl> + <nl> }
<nl> - / * <nl> + package data_structures . stacks ; <nl>  <nl> - the nested brackets problem is a problem that determines if a sequence of <nl> - brackets are properly nested . a sequence of brackets s is considered properly nested <nl> - if any of the following conditions are true : <nl> - - s is empty <nl> - - s has the form ( u ) or [ u ] or { u } where u is a properly nested string <nl> - - s has the form vw where v and w are properly nested strings <nl> - for example , the string " ( ) ( ) [ ( ) ] " is properly nested but " [ ( ( ) ] " is not . <nl> - the function called is_balanced takes as input a string s which is a sequence of brackets and <nl> - returns true if s is nested and false otherwise . <nl> - <nl> - author : akshay sharma <nl> - date : num - 10 - 17 <nl> - * / <nl> import java . util . scanner ; <nl> import java . util . stack ; <nl> - import java . util . arraylist ; <nl>  <nl> + / * * <nl> + * <nl> + * the nested brackets problem is a problem that determines if a sequence of <nl> + * brackets are properly nested . a sequence of brackets s is considered properly <nl> + * nested if any of the following conditions are true : - s is empty - s has the <nl> + * form ( u ) or [ u ] or { u } where u is a properly nested string - s has the form <nl> + * vw where v and w are properly nested strings for example , the string <nl> + * " ( ) ( ) [ ( ) ] " is properly nested but " [ ( ( ) ] " is not . the function called <nl> + * is_balanced takes as input a string s which is a sequence of brackets and <nl> + * returns true if s is nested and false otherwise . <nl> + * <nl> + * @ author akshay sharma <nl> + * @ date : num - 10 - 17 <nl> + * @ author < a href = " https : / / github . com / khalil2535 " > khalil2535 < a > <nl> + * <nl> + * / <nl> class balancedbrackets { <nl>  <nl> - static boolean is_balanced ( char [ ] s ) { <nl> - stack < character > stack = new stack < > ( ) ; <nl> - string pair = " " ; <nl> - for ( int i = num ; i < s . length ; + + i ) { <nl> - if ( s [ i ] = = ' ( ' | | s [ i ] = = ' { ' | | s [ i ] = = ' [ ' ) { <nl> - stack . push ( s [ i ] ) ; <nl> - } else if ( stack . size ( ) > num ) { <nl> - if ( ! pair . equals ( " [ ] " ) & & ! pair . equals ( " ( ) " ) & & ! pair . equals ( " { } " ) ) { <nl> - return false ; <nl> - } <nl> - } else { <nl> - return false ; <nl> + / * * <nl> + * <nl> + * @ param s <nl> + * @ return <nl> + * / <nl> + static boolean is_balanced ( string s ) { <nl> + stack < character > bracketsstack = new stack < > ( ) ; <nl> + char [ ] text = s . tochararray ( ) ; <nl> + for ( char x : text ) { <nl> + switch ( x ) { <nl> + case ' { ' : <nl> + case ' < ' : <nl> + case ' ( ' : <nl> + case ' [ ' : <nl> + bracketsstack . push ( x ) ; <nl> + break ; <nl> + case ' } ' : <nl> + if ( bracketsstack . peek ( ) = = ' { ' ) { <nl> + bracketsstack . pop ( ) ; <nl> + break ; <nl> + } else { <nl> + return false ; <nl> + } <nl> + case ' > ' : <nl> + if ( bracketsstack . peek ( ) = = ' < ' ) { <nl> + bracketsstack . pop ( ) ; <nl> + break ; <nl> + } else { <nl> + return false ; <nl> + } <nl> + case ' ) ' : <nl> + if ( bracketsstack . peek ( ) = = ' ( ' ) { <nl> + bracketsstack . pop ( ) ; <nl> + break ; <nl> + } else { <nl> + return false ; <nl> + } <nl> + case ' ] ' : <nl> + if ( bracketsstack . peek ( ) = = ' [ ' ) { <nl> + bracketsstack . pop ( ) ; <nl> + break ; <nl> + } else { <nl> + return false ; <nl> + } <nl> } <nl> } <nl> - <nl> - return stack . isempty ( ) ; <nl> - } <nl> - <nl> - static void print ( object a ) { <nl> - system . out . println ( a ) ; <nl> + return bracketsstack . empty ( ) ; <nl> } <nl>  <nl> + / * * <nl> + * <nl> + * @ param args <nl> + * @ <nl> + * / <nl> public static void main ( string args [ ] ) { <nl> - try { <nl> - scanner in = new scanner ( system . in ) ; <nl> - print ( " enter sequence of brackets : " ) ; <nl> - string s = in . nextline ( ) ; <nl> - if ( is_balanced ( s . tochararray ( ) ) ) { <nl> - print ( s + " is balanced " ) ; <nl> + try ( scanner in = new scanner ( system . in ) ) { <nl> + system . out . println ( " enter sequence of brackets : " ) ; <nl> + string s = in . nextline ( ) ; <nl> + if ( is_balanced ( s ) ) { <nl> + system . out . println ( s + " is balanced " ) ; <nl> } else { <nl> - print ( s + " ain ' t balanced " ) ; <nl> + system . out . println ( s + " ain ' t balanced " ) ; <nl> } <nl> - in . close ( ) ; <nl> - } catch ( exception e ) { <nl> - e . tostring ( ) ; <nl> } <nl> } <nl> }
<nl> + import java . util . * ; <nl> + <nl> + / * * <nl> + * program to perform saddleback search <nl> + * given a sorted num d array ( elements are sorted across every row and column , assuming ascending order ) <nl> + * of size n * m we can search a given element in o ( n + m ) <nl> + * <nl> + * we start from bottom left corner <nl> + * if the current element is greater than the given element then we move up <nl> + * else we move right <nl> + * sample input : <nl> + * num num - > dimensions <nl> + * - 10 - 5 - 3 num num <nl> + * - 6 - 2 num num num <nl> + * - 4 - 1 num num num <nl> + * num num num num num <nl> + * num num num num num <nl> + * num - > element to be searched <nl> + * output : num num / / first value is row , second one is column <nl> + * <nl> + * @ author nishita aggarwal <nl> + * <nl> + * / <nl> + <nl> + public class saddlebacksearch { <nl> + <nl> + / * * <nl> + * this method performs saddleback search <nl> + * <nl> + * @ param arr the * * sorted * * array in which we will search the element . <nl> + * @ param crow the current row . <nl> + * @ param ccol the current column . <nl> + * @ param ele the element that we want to search for . <nl> + * <nl> + * @ return the index ( row and column ) of the element if found . <nl> + * else returns - 1 - 1 . <nl> + * / <nl> + static int [ ] search ( int arr [ ] [ ] , int crow , int ccol , int ele ) { <nl> + <nl> + / / array to store the answer row and column <nl> + int ans [ ] = { - 1 , - 1 } ; <nl> + if ( crow < 0 | | ccol > = arr [ crow ] . length ) { <nl> + return ans ; <nl> + } <nl> + if ( arr [ crow ] [ ccol ] = = ele ) <nl> + { <nl> + ans [ 0 ] = crow ; <nl> + ans [ 1 ] = ccol ; <nl> + return ans ; <nl> + } <nl> + / / if the current element is greater than the given element then we move up <nl> + else if ( arr [ crow ] [ ccol ] > ele ) <nl> + { <nl> + return search ( arr , crow - 1 , ccol , ele ) ; <nl> + } <nl> + / / else we move right <nl> + return search ( arr , crow , ccol + 1 , ele ) ; <nl> + } <nl> + <nl> + / * * <nl> + * main method <nl> + * <nl> + * @ param args command line arguments <nl> + * / <nl> + public static void main ( string [ ] args ) { <nl> + <nl> + scanner sc = new scanner ( system . in ) ; <nl> + int arr [ ] [ ] ; <nl> + int i , j , rows = sc . nextint ( ) , col = sc . nextint ( ) ; <nl> + arr = new int [ rows ] [ col ] ; <nl> + for ( i = 0 ; i < rows ; i + + ) <nl> + { <nl> + for ( j = 0 ; j < col ; j + + ) { <nl> + arr [ i ] [ j ] = sc . nextint ( ) ; <nl> + } <nl> + } <nl> + int ele = sc . nextint ( ) ; <nl> + / / we start from bottom left corner <nl> + int ans [ ] = search ( arr , rows - 1 , 0 , ele ) ; <nl> + system . out . println ( ans [ 0 ] + " " + ans [ 1 ] ) ; <nl> + sc . close ( ) ; <nl> + } <nl> + <nl> + }
public class res9patchstreamdecoder implements resstreamdecoder { <nl> drawvline ( im2 , num , ydivs [ i ] + num , ydivs [ i + num ] ) ; <nl> } <nl>  <nl> + try { <nl> + opticalinset oi = getopticalinset ( data ) ; <nl> + <nl> + / / as far as i know , only the length of the red lines are interesting <nl> + / / not their positions <nl> + / / so set them up in the corners <nl> + <nl> + for ( int i = num ; i < oi . layoutboundsleft ; i + + ) { <nl> + int x = num + i ; <nl> + im2 . setrgb ( x , h + num , oi_color ) ; <nl> + } <nl> + <nl> + for ( int i = num ; i < oi . layoutboundsright ; i + + ) { <nl> + int x = w - i ; <nl> + im2 . setrgb ( x , h + num , oi_color ) ; <nl> + } <nl> + <nl> + for ( int i = num ; i < oi . layoutboundstop ; i + + ) { <nl> + int y = num + i ; <nl> + im2 . setrgb ( w + num , y , oi_color ) ; <nl> + } <nl> + <nl> + for ( int i = num ; i < oi . layoutboundsbottom ; i + + ) { <nl> + int y = h - i ; <nl> + im2 . setrgb ( w + num , y , oi_color ) ; <nl> + } <nl> + } catch ( cantfind9patchchunk t ) { <nl> + / / this chunk might not exist <nl> + } <nl> + <nl> imageio . write ( im2 , " png " , out ) ; <nl> } catch ( ioexception ex ) { <nl> throw new androlibexception ( ex ) ; <nl>
public class res9patchstreamdecoder implements resstreamdecoder { <nl> int w = im . getwidth ( ) , h = im . getheight ( ) ; <nl>  <nl> bufferedimage im2 = new bufferedimage ( w + 2 , h + 2 , bufferedimage . type_int_argb ) ; <nl> - im2 . creategraphics ( ) . drawimage ( im , num , num , w , h , null ) ; <nl> + if ( im . gettype ( ) = = bufferedimage . type_custom ) { <nl> + <nl> + raster srcraster = im . getraster ( ) ; <nl> + writableraster dstraster = im2 . getraster ( ) ; <nl> + int [ ] gray = null , alpha = null ; <nl> + for ( int y = num ; y < im . getheight ( ) ; y + + ) { <nl> + gray = srcraster . getsamples ( 0 , y , w , num , num , gray ) ; <nl> + alpha = srcraster . getsamples ( 0 , y , w , num , num , alpha ) ; <nl> + <nl> + dstraster . setsamples ( 1 , y + 1 , w , num , num , gray ) ; <nl> + dstraster . setsamples ( 1 , y + 1 , w , num , num , gray ) ; <nl> + dstraster . setsamples ( 1 , y + 1 , w , num , num , gray ) ; <nl> + dstraster . setsamples ( 1 , y + 1 , w , num , num , alpha ) ; <nl> + } <nl> + } else { <nl> + im2 . creategraphics ( ) . drawimage ( im , num , num , w , h , null ) ; <nl> + } <nl>  <nl> ninepatch np = getninepatch ( data ) ; <nl> drawhline ( im2 , h + num , np . padleft + num , w - np . padright ) ;
public class methodanalyzer { <nl>  <nl> / / methodclass is now the first accessible class found . now . we need to make sure that the method is <nl> / / actually valid for this class <nl> - resolvedmethod = classpath . getclass ( methodclass . gettype ( ) ) . getmethodbyvtableindex ( methodindex ) ; <nl> - if ( resolvedmethod = = null ) { <nl> + methodreference newresolvedmethod = <nl> + classpath . getclass ( methodclass . gettype ( ) ) . getmethodbyvtableindex ( methodindex ) ; <nl> + if ( newresolvedmethod = = null ) { <nl> + <nl> throw new exceptionwithcontext ( " couldn ' t find accessible class while resolving method % s " , <nl> referenceutil . getmethoddescriptor ( resolvedmethod , true ) ) ; <nl> } <nl> + resolvedmethod = newresolvedmethod ; <nl> resolvedmethod = new immutablemethodreference ( methodclass . gettype ( ) , resolvedmethod . getname ( ) , <nl> resolvedmethod . getparametertypes ( ) , resolvedmethod . getreturntype ( ) ) ; <nl> }
public class axmlresourceparser implements xmlresourceparser { <nl> if ( namespace = = - 1 ) { <nl> return " " ; <nl> } <nl> - return m_strings . getstring ( namespace ) ; <nl> + <nl> + / / hacky : if the attribute names are proguarded , then so are the namespace <nl> + / / i don ' t know where these are located yet in the file , but it is always <nl> + / / this . android_ns in testing , so we will default to that for now . <nl> + <nl> + string value = m_strings . getstring ( namespace ) ; <nl> + <nl> + if ( value . length ( ) = = num ) { <nl> + int offsetname = getattributeoffset ( index ) ; <nl> + int name = m_attributes [ offsetname + attribute_ix_name ] ; <nl> + if ( m_strings . getstring ( name ) . length ( ) = = num ) { <nl> + value = android_ns ; <nl> + } <nl> + } <nl> + <nl> + return value ; <nl> } <nl>  <nl> @ override <nl>
public class androlib { <nl> } <nl> } <nl>  <nl> + private boolean isapkfilenames ( string file ) { <nl> + for ( string apkfile : apk_standard_all_filenames ) { <nl> + if ( apkfile . equals ( file ) | | file . startswith ( apkfile ) ) { <nl> + return true ; <nl> + } <nl> + } <nl> + return false ; <nl> + } <nl> + <nl> + public void decodeunknownfiles ( extfile apkfile , file outdir ) <nl> + throws androlibexception { <nl> + logger . info ( " copying unknown files / dir . . . " ) ; <nl> + file unknownout = new file ( outdir , unk_dirname ) ; <nl> + <nl> + / / have to use container of zipfile to help identify compression type <nl> + / / with regular looping of apkfile for easy copy <nl> + try { <nl> + directory unk = apkfile . getdirectory ( ) ; <nl> + zipfile apkzipfile = new zipfile ( apkfile . getabsolutepath ( ) ) ; <nl> + <nl> + / / loop all items in container , ignoring any that are pre - defined by aapt <nl> + set < string > files = unk . getfiles ( ) ; <nl> + for ( string file : files ) { <nl> + if ( ! isapkfilenames ( file ) ) { <nl> + unk . copytodir ( unknownout , file ) ; <nl> + system . out . println ( apkzipfile . getentry ( file ) . getmethod ( ) ) ; <nl> + } <nl> + } <nl> + / / for folders now . <nl> + map < string , directory > dirs = unk . getdirs ( ) ; <nl> + for ( string dir : dirs . keyset ( ) ) { <nl> + if ( ! isapkfilenames ( dir ) ) { <nl> + unk . copytodir ( unknownout , dir ) ; <nl> + system . out . println ( apkzipfile . getentry ( dir ) . getmethod ( ) ) ; <nl> + } <nl> + <nl> + } <nl> + } <nl> + catch ( directoryexception ex ) { <nl> + throw new androlibexception ( ex ) ; <nl> + } <nl> + catch ( ioexception ex ) { <nl> + throw new androlibexception ( ex ) ; <nl> + } <nl> + <nl> + <nl> + } <nl> + <nl> public void writeoriginalfiles ( extfile apkfile , file outdir ) <nl> throws androlibexception { <nl> logger . info ( " copying original files . . . " ) ; <nl>
final public class androlibresources { <nl>  <nl> cmd . add ( " aapt " ) ; <nl> cmd . add ( " p " ) ; <nl> + cmd . add ( " - v " ) ; <nl> if ( update ) { <nl> cmd . add ( " - u " ) ; <nl> }
public class resconfigflags { <nl> return hash ; <nl> } <nl>  <nl> + <nl> + <nl> + private static int serrcounter = num ; <nl> + <nl> + <nl> public final static byte orientation_any = num ; <nl> public final static byte orientation_port = num ; <nl> public final static byte orientation_land = num ;
<nl> + / * <nl> + * copyright num android4me <nl> + * <nl> + * licensed under the apache license , version num . 0 ( the " license " ) ; <nl> + * you may not use this file except in compliance with the license . <nl> + * you may obtain a copy of the license at <nl> + * <nl> + * http : / / www . apache . org / licenses / license - 2 . 0 <nl> + * <nl> + * unless required by applicable law or agreed to in writing , software <nl> + * distributed under the license is distributed on an " as is " basis , <nl> + * without warranties or conditions of any kind , either express or implied . <nl> + * see the license for the specific language governing permissions and <nl> + * limitations under the license . <nl> + * / <nl> + package android . util ; <nl> + <nl> + / * * <nl> + * @ author dmitry skiba <nl> + * <nl> + * / <nl> + public interface attributeset { <nl> + int getattributecount ( ) ; <nl> + string getattributename ( int index ) ; <nl> + string getattributevalue ( int index ) ; <nl> + string getpositiondescription ( ) ; <nl> + int getattributenameresource ( int index ) ; <nl> + int getattributelistvalue ( int index , string options [ ] , int defaultvalue ) ; <nl> + boolean getattributebooleanvalue ( int index , boolean defaultvalue ) ; <nl> + int getattributeresourcevalue ( int index , int defaultvalue ) ; <nl> + int getattributeintvalue ( int index , int defaultvalue ) ; <nl> + int getattributeunsignedintvalue ( int index , int defaultvalue ) ; <nl> + float getattributefloatvalue ( int index , float defaultvalue ) ; <nl> + string getidattribute ( ) ; <nl> + string getclassattribute ( ) ; <nl> + int getidattributeresourcevalue ( int index ) ; <nl> + int getstyleattribute ( ) ; <nl> + string getattributevalue ( string namespace , string attribute ) ; <nl> + int getattributelistvalue ( string namespace , string attribute , string options [ ] , int defaultvalue ) ; <nl> + boolean getattributebooleanvalue ( string namespace , string attribute , boolean defaultvalue ) ; <nl> + int getattributeresourcevalue ( string namespace , string attribute , int defaultvalue ) ; <nl> + int getattributeintvalue ( string namespace , string attribute , int defaultvalue ) ; <nl> + int getattributeunsignedintvalue ( string namespace , string attribute , int defaultvalue ) ; <nl> + float getattributefloatvalue ( string namespace , string attribute , float defaultvalue ) ; <nl> + <nl> + <nl> + int getattributevaluetype ( int index ) ; <nl> + int getattributevaluedata ( int index ) ; <nl> + }
public class nodeprovisionertest { <nl> / / no build on the built - in node , to make sure we get everything from the cloud <nl> r . jenkins . setnumexecutors ( 0 ) ; <nl> r . jenkins . setnodes ( collections . emptylist ( ) ) ; <nl> + <nl> + <nl> + handler handler = new consolehandler ( ) ; <nl> + handler . setformatter ( new supportlogformatter ( ) ) ; <nl> + handler . setlevel ( level . finer ) ; <nl> + logger logger = logger . getlogger ( nodeprovisioner . class . getname ( ) ) ; <nl> + logger . setlevel ( level . finer ) ; <nl> + logger . addhandler ( handler ) ; <nl> + <nl> return cloud ; <nl> }
public class jetty10provider implements provider { <nl>  <nl> @ override <nl> public void sendping ( bytebuffer applicationdata ) throws ioexception { <nl> - session ( ) . getremote ( ) . sendping ( applicationdata ) ; <nl> + completablefuture < void > f = new completablefuture < > ( ) ; <nl> + session ( ) . getremote ( ) . sendping ( applicationdata , new writecallbackimpl ( f ) ) ; <nl> + <nl> } <nl>  <nl> @ override
public class initmilestonetest { <nl>  <nl> list < initmilestone > attained = r . jenkins . getextensionlist ( initializers . class ) . get ( 0 ) . getattained ( ) ; <nl>  <nl> - assertequals ( attained , list . of ( <nl> + <nl> + assertthat ( attained , containsinanyorder ( <nl> initmilestone . extensions_augmented , <nl> initmilestone . system_config_loaded , <nl> initmilestone . system_config_adapted ,
public class nodeprovisionertest { <nl> @ issue ( " jenkins - 67635 " ) <nl> @ test <nl> public void testjobwithcloudlabelexpressionprovisionsonlyoneagent ( ) throws exception { <nl> + assumefalse ( " <nl> dummycloudimpl3 cloud1 = new dummycloudimpl3 ( r ) ; <nl> dummycloudimpl3 cloud2 = new dummycloudimpl3 ( r ) ;
public class iconsettest { <nl>  <nl> assertthat ( symbol , not ( containsstring ( " tooltip " ) ) ) ; <nl> } <nl> + <nl> + / * * <nl> + * culprit : https : / / github . com / jenkinsci / jenkins / blob / <commit_id> / core / src / main / java / org / jenkins / ui / icon / iconset . java # l97 = <nl> + * if the tooltip contains an ampersand symbol ( & amp ; ) , it won ' t be removed . <nl> + * / <nl> + @ disabled ( " <nl> + @ test <nl> + void getsymbol_notsettingtooltipdoesntaddtooltipattribute_evenwithampersand ( ) { <nl> + string symbol = iconset . getsymbol ( " download " , " title " , " with & ampersand " , " class1 class2 " , " " , " id " ) ; <nl> + <nl> + assertthat ( symbol , not ( containsstring ( " tooltip " ) ) ) ; <nl> + } <nl> }
public class doublelaunchchecker { <nl> } <nl> / / we noticed that someone else have updated this file . <nl> / / switch gui to display this error . <nl> + <nl> jenkins . get ( ) . servletcontext . setattribute ( " app " , this ) ; <nl> logger . severe ( " collision detected . timestamp = " + t + " , expected = " + lastwritetime ) ; <nl> / / we need to continue updating this file , so that the other hudson would notice the problem , too . <nl>
public class doublelaunchchecker { <nl> * / <nl> public void schedule ( ) { <nl> / / randomize the scheduling so that multiple hudson instances will write at the file at different time <nl> - long minute = num * num ; <nl> + long minute = num * num ; <nl>  <nl> timer . get ( ) <nl> . schedule ( new safetimertask ( ) { <nl>
public class doublelaunchchecker { <nl>  <nl> @ initializer ( after = job_config_adapted ) <nl> public static void init ( ) { <nl> + <nl> new doublelaunchchecker ( ) . schedule ( ) ; <nl> }
the software . <nl> < junit . jupiter . version > 5 . 8 . 2 < / junit . jupiter . version > <nl> < mockito . version > 4 . 5 . 1 < / mockito . version > <nl> < spotless . version > 2 . 22 . 5 < / spotless . version > <nl> + <nl> + < ! - - <nl> + < maven - surefire - plugin . version > 2 . 22 . 2 < / maven - surefire - plugin . version > <nl> + < maven - surefire - report - plugin . version > 2 . 22 . 2 < / maven - surefire - report - plugin . version > <nl> < / properties > <nl>  <nl> < dependencymanagement >
for ( i = num ; i < buildtypes . size ( ) ; i + + ) { <nl> if ( buildtype = = ' windows ' & & jdk = = num ) { <nl> continue / / unnecessary use of hardware <nl> } <nl> + if ( buildtype = = ' windows ' & & jdk = = num ) { <nl> + continue <nl> + } <nl> builds [ " $ { buildtype } - jdk $ { jdk } " ] = { <nl> / / see https : / / github . com / jenkins - infra / documentation / blob / master / ci . adoc # node - labels for information on what node types are available <nl> def agentcontainerlabel = jdk = = num ? ' maven ' : ' maven - ' + jdk <nl> mmm a / core / pom . xml <nl> ppp b / core / pom . xml <nl>
n / a <nl> - [ ] changelog entries and upgrade guidelines are appropriate for the audience affected by the change ( users or developer , depending on the change ) . [ examples ] ( https : / / github . com / jenkins - infra / jenkins . io / blob / master / content / _data / changelogs / weekly . yml ) <nl> * fill - in the ` proposed changelog entries ` section only if there are breaking changes or other changes which may require extra steps from users during the upgrade <nl> - [ ] appropriate autotests or explanation to why this change has no tests <nl> + - [ ] new public classes , fields , and methods are annotated with ` @ restricted ` or have ` @ since <nl> - [ ] for dependency updates : links to external changelogs and , if possible , full diffs <nl>  <nl> < ! - - for new api and extension points : link to the reference implementation in open - source ( or example in javadoc ) - - >
public class jenkinslocationconfiguration extends globalconfiguration implements <nl> } <nl>  <nl> public formvalidation docheckadminaddress ( @ queryparameter string value ) { <nl> - try { <nl> - new internetaddress ( value ) ; <nl> + <nl> + if ( util . fixnull ( value ) . contains ( " @ " ) ) { <nl> return formvalidation . ok ( ) ; <nl> - } catch ( addressexception e ) { <nl> - return formvalidation . error ( e . getmessage ( ) ) ; <nl> + } else { <nl> + return formvalidation . error ( messages . jenkinslocationconfiguration_does_not_look_like_an_email_address ( ) ) ; <nl> } <nl> } <nl>  <nl> mmm a / core / src / main / resources / jenkins / model / messages . properties <nl> ppp b / core / src / main / resources / jenkins / model / messages . properties <nl>
<nl> + package jenkins . model ; <nl> + <nl> + import static org . hamcrest . matcherassert . assertthat ; <nl> + import static org . hamcrest . matchers . containsinrelativeorder ; <nl> + import static org . hamcrest . matchers . empty ; <nl> + import static org . hamcrest . matchers . hasitem ; <nl> + import static org . hamcrest . matchers . not ; <nl> + <nl> + import hudson . util . versionnumber ; <nl> + import java . lang . ref . weakreference ; <nl> + import java . util . list ; <nl> + import java . util . logging . level ; <nl> + import java . util . logging . logrecord ; <nl> + import java . util . logging . logger ; <nl> + import java . util . stream . collectors ; <nl> + import org . junit . rule ; <nl> + import org . junit . test ; <nl> + import org . jvnet . hudson . test . jenkinsrule ; <nl> + import org . jvnet . hudson . test . memoryassert ; <nl> + import org . jvnet . hudson . test . realjenkinsrule ; <nl> + <nl> + public class jenkinslogrecordstest { <nl> + <nl> + @ rule <nl> + public realjenkinsrule rr = new realjenkinsrule ( ) ; <nl> + <nl> + @ test <nl> + public void logrecordsarepresentoncontroller ( ) throws throwable { <nl> + rr . then ( jenkinslogrecordstest : : _logrecordsarepresentoncontroller ) ; <nl> + } <nl> + private static void _logrecordsarepresentoncontroller ( jenkinsrule r ) throws throwable { <nl> + list < logrecord > logrecords = jenkins . logrecords ; <nl> + assertthat ( logrecords , not ( empty ( ) ) ) ; <nl> + assertthat ( " records are displayed in reverse order " , <nl> + logrecords . stream ( ) . map ( logrecord : : getmessage ) . collect ( collectors . tolist ( ) ) , <nl> + containsinrelativeorder ( " completed initialization " , " started initialization " ) ) ; <nl> + if ( new versionnumber ( system . getproperty ( " java . specification . version " ) ) . isolderthan ( new versionnumber ( " 9 " ) ) ) { <nl> + logrecord lr = new logrecord ( level . info , " collect me " ) ; <nl> + logger . getlogger ( jenkins . class . getname ( ) ) . log ( lr ) ; <nl> + weakreference < logrecord > ref = new weakreference < > ( lr ) ; <nl> + lr = null ; <nl> + memoryassert . assertgc ( ref , true ) ; <nl> + assertthat ( " records collected " , <nl> + logrecords . stream ( ) . map ( logrecord : : getmessage ) . collect ( collectors . tolist ( ) ) , <nl> + hasitem ( " < discarded > " ) ) ; <nl> + } <nl> + } <nl> + <nl> + }
public class loadstatisticstest { <nl>  <nl> @ test <nl> public void graph ( ) throws ioexception { <nl> + assumefalse ( " <nl> loadstatistics ls = new loadstatistics ( 0 , num ) { <nl> @ override <nl> public int computeidleexecutors ( ) { <nl> mmm a / test / src / test / java / hudson / pluginmanagertest . java <nl> ppp b / test / src / test / java / hudson / pluginmanagertest . java <nl>
public class pluginmanagertest { <nl> @ issue ( " jenkins - 59136 " ) <nl> @ withplugin ( { " credentials . hpi " , " htmlpublisher . jpi " , " icon - shim . hpi " , " token - macro . hpi " , " variant . hpi " } ) <nl> public void testdeprecationnotices ( ) throws exception { <nl> + assumefalse ( " <nl> persistedlist < updatesite > sites = r . jenkins . getupdatecenter ( ) . getsites ( ) ; <nl> sites . clear ( ) ; <nl> url url = pluginmanagertest . class . getresource ( " / plugins / deprecations - update - center . json " ) ; <nl>
public class pluginmanagertest { <nl>  <nl> @ test @ issue ( " jenkins - 64840 " ) <nl> public void searchmultipleupdatesites ( ) throws exception { <nl> + assumefalse ( " <nl> persistedlist < updatesite > sites = r . jenkins . getupdatecenter ( ) . getsites ( ) ; <nl> sites . clear ( ) ; <nl> url url = pluginmanagertest . class . getresource ( " / plugins / search - test - update - center1 . json " ) ; <nl> mmm a / test / src / test / java / jenkins / security / resourcedomaintest . java <nl> ppp b / test / src / test / java / jenkins / security / resourcedomaintest . java <nl>
public class resourcedomaintest { <nl> @ test <nl> @ issue ( " jenkins - 59849 " ) <nl> public void testmoreurlencoding ( ) throws exception { <nl> + assumefalse ( " <nl> jenkinsrule . webclient webclient = j . createwebclient ( ) ; <nl> webclient . setthrowexceptiononfailingstatuscode ( false ) ; <nl> webclient . setredirectenabled ( true ) ; <nl> mmm a / test / src / test / java / jenkins / security / stapler / jenkinssupportannotationstest . java <nl> ppp b / test / src / test / java / jenkins / security / stapler / jenkinssupportannotationstest . java <nl>
public class jenkinssupportannotationstest { <nl> @ test <nl> @ withplugin ( " annotations - test . hpi " ) <nl> public void testpluginwithannotations ( ) throws exception { <nl> + assumefalse ( " <nl> / / test fails if typedfilter ignores @ staplerdispatchable <nl> j . createwebclient ( ) . goto ( " annotationstest / whatever " , " " ) ;
public class masterkillswitchconfiguration extends globalconfiguration { <nl> } <nl>  <nl> / * * <nl> - * returns true if the configuration of this subsystem becomes relevant . <nl> - * unless this option is relevant , we don ' t let users choose this . <nl> + * returns true if the configuration of this subsystem is relevant . <nl> + * <nl> + * < p > historically , this was only shown when " security " ( authn / authz ) was enabled . <nl> + * that missed the use case of trusted local networks and jenkins building public ( untrusted ) pull requests . <nl> + * to be sure we ' re not missing another case where this option is useful , just show it always . < / p > <nl> * / <nl> public boolean isrelevant ( ) { <nl> - return jenkins . haspermission ( jenkins . administer ) & & jenkins . isusesecurity ( ) ; <nl> + / * <nl> + * <nl> + * return ! jenkins . clouds . isempty ( ) | | ! jenkins . getnodes ( ) . isempty ( ) ; <nl> + * / <nl> + return true ; <nl> } <nl> }
the software . <nl> < staplerfork > true < / staplerfork > <nl> < hamcrest . version > 2 . 2 < / hamcrest . version > <nl> < xmlunit . version > 2 . 8 . 2 < / xmlunit . version > <nl> + < ! - - <nl> + < spotbugs . threshold > high < / spotbugs . threshold > <nl> < / properties > <nl>  <nl> < dependencymanagement > <nl>
public class queue extends resourcecontroller implements saveable { <nl> * / <nl> @ nonnull subtask getparent ( ) ; <nl>  <nl> + / * * <nl> + * an umbrella executable ( such as a { @ link run } ) of which this is one part . <nl> + * if { @ link # getparent } has a distinct { @ link subtask # getownertask } , <nl> + * then it should be the case that { @ code getparentexecutable ( ) . getparent ( ) = = getparent ( ) . getownertask ( ) } . <nl> + * @ return a < em > distinct < / em > executable ( never { @ code this } , unlike the default of { @ link subtask # getownertask } ! ) ; or null if this executable was already at top level <nl> + * @ since <nl> + * / <nl> + default @ checkfornull executable getparentexecutable ( ) { <nl> + return null ; <nl> + } <nl> + <nl> / * * <nl> * called by { @ link executor } to perform the task . <nl> * @ throws asynchronousexecution if you would like to continue without consuming a thread
import static org . objectweb . asm . opcodes . return ; <nl> * / <nl> @ deprecated <nl> @ restricted ( donotuse . class ) <nl> + @ restrictedsince ( " <nl> public class subclassgenerator extends classloader { <nl> public subclassgenerator ( classloader parent ) { <nl> super ( parent ) ;
<nl> < ! - - we don ' t care about this behavior . - - > <nl> < bug pattern = " crlf_injection_logs " / > <nl> < / match > <nl> + < match > <nl> + < ! - - <nl> + this is a false positive in spotbugs num . 2 . 3 . <nl> + when the fix for spotbugs / spotbugs # 1539 is widely adopted . <nl> + - - > <nl> + < bug pattern = " dmi_random_used_only_once " / > <nl> + < / match > <nl> < match > <nl> < ! - - jenkins handles this issue differently or doesn ' t care about it . - - > <nl> < bug pattern = " information_exposure_through_an_error_message " / >
the software . <nl> < groupid > com . github . jnr < / groupid > <nl> < artifactid > jnr - posix < / artifactid > <nl> < / dependency > <nl> + < dependency > <nl> + < groupid > org . ow2 . asm < / groupid > <nl> + < artifactid > asm < / artifactid > <nl> + < / dependency > <nl> + < ! - - <nl> + for compatibility only ; not included into the bom for the same reason . <nl> + https : / / github . com / jenkinsci / scm - api - plugin / pull / 88 is widely adopted , this <nl> + dependency can be dropped . <nl> + - - > <nl> + < dependency > <nl> + < groupid > org . kohsuke < / groupid > <nl> + < artifactid > asm5 < / artifactid > <nl> + < version > 5 . 0 . 1 < / version > <nl> + < / dependency > <nl> < dependency > <nl> < groupid > org . kohsuke . stapler < / groupid > <nl> < artifactid > stapler < / artifactid > <nl> mmm a / core / src / main / java / hudson / util / subclassgenerator . java <nl> ppp b / core / src / main / java / hudson / util / subclassgenerator . java <nl>
public class fileparametervalue extends parametervalue { <nl> } <nl> filepath locationfilepath = ws . child ( location ) ; <nl> locationfilepath . getparent ( ) . mkdirs ( ) ; <nl> + <nl> + <nl> + if ( locationfilepath . exists ( ) & & ! locationfilepath . isdirectory ( ) ) { <nl> + locationfilepath . delete ( ) ; <nl> + } <nl> + <nl> locationfilepath . copyfrom ( file ) ; <nl> locationfilepath . copyto ( new filepath ( getlocationunderbuild ( build ) ) ) ; <nl> }
the software . <nl> < properties > <nl> < guavaversion > 11 . 0 . 1 < / guavaversion > <nl> < slf4jversion > 1 . 7 . 30 < / slf4jversion > <nl> - < stapler . version > 1 . 263 - rc1493 . 8d975ba0042b < / stapler . version > <nl> + < stapler . version > 1 . 263 - rc1501 . 514659f9d703 < / stapler . version > < ! - - <nl> < groovy . version > 2 . 4 . 12 < / groovy . version > <nl> < / properties >
the software . <nl> < dependency > <nl> < groupid > org . jenkins - ci . plugins < / groupid > <nl> < artifactid > antisamy - markup - formatter < / artifactid > <nl> - < version > 1 . 0 < / version > <nl> + < version > 2 . 1 < / version > <nl> < scope > test < / scope > <nl> + < exclusions > <nl> + < exclusion > < ! - - <nl> + < groupid > com . google . guava < / groupid > <nl> + < artifactid > guava < / artifactid > <nl> + < / exclusion > <nl> + < / exclusions > <nl> < / dependency > <nl> < dependency > <nl> < groupid > org . jenkins - ci . plugins < / groupid >
function registervalidator ( e ) { <nl> formchecker . sendrequest ( this . targeturl ( ) , { <nl> method : method , <nl> oncomplete : function ( x ) { <nl> - target . innerhtml = x . responsetext ; <nl> + if ( x . status = = num ) { <nl> + / / all formvalidation responses are num <nl> + target . innerhtml = x . responsetext ; <nl> + } else { <nl> + / / content is taken from formvalidation # _errorwithmarkup <nl> + <nl> + target . innerhtml = " < div class = ' error ' > an internal error occurred during form field validation ( http " + x . status + " ) . please reload the page and if the problem persists , ask the administrator for help . < / div > " ; <nl> + } <nl> behaviour . applysubtree ( target ) ; <nl> } <nl> } ) ;
public abstract class pluginmanager extends abstractmodelobject implements onmas <nl> file t = file . createtempfile ( " uploaded " , " . jpi " ) ; <nl> t . deleteonexit ( ) ; <nl> try { <nl> + <nl> + t . delete ( ) ; <nl> + <nl> fileitem . write ( t ) ; <nl> } catch ( exception e ) { <nl> / / exception thrown is too generic so at least limit the scope where it can occur
public class virtualfiletest { <nl> } <nl>  <nl> @ test <nl> + @ ignore ( " <nl> public void testcanread_false_filevf ( ) throws exception { <nl> file ws = tmp . newfolder ( " ws " ) ; <nl> string childstring = " child " ; <nl>
public class virtualfiletest { <nl> } <nl>  <nl> @ test <nl> + @ ignore ( " <nl> public void testcanread_false_filepathvf ( ) throws exception { <nl> / / this test checks the method ' s behavior in the abstract base class , <nl> / / which generally does nothing .
public class updatecenter2test { <nl> assertequals ( messages . updatecenter_n_a ( ) , j . jenkins . getupdatecenter ( ) . getlastupdatedstring ( ) ) ; <nl> } <nl>  <nl> + @ ignore ( " <nl> @ issue ( " security - 234 " ) <nl> @ test public void installinvalidchecksum ( ) throws exception { <nl> updatesite . neverupdate = false ;
public class functionstest { <nl> s . println ( " some custom exception " ) ; <nl> } <nl> } , " some custom exception\n " , " some custom exception\n " ) ; <nl> + / * <nl> / / circular references : <nl> stack stack1 = new stack ( " p . exc1 " , " p . c . method1 : 17 " ) ; <nl> stack stack2 = new stack ( " p . exc2 " , " p . c . method2 : 27 " ) ; <nl>
public class functionstest { <nl> s . println ( " some custom exception " ) ; <nl> } <nl> } , " some custom exception\n " , " some custom exception\n " ) ; <nl> + / * <nl> / / circular references : <nl> stack stack1 = new stack ( " p . exc1 " , " p . c . method1 : 17 " ) ; <nl> stack stack2 = new stack ( " p . exc2 " , " p . c . method2 : 27 " ) ; <nl>
public class security637test { <nl> return handler . getclass ( ) . getname ( ) ; <nl> } <nl> } <nl> - <nl> + <nl> + @ ignore ( " <nl> @ test <nl> @ issue ( " security - 637 " ) <nl> public void urldnsequivalence ( ) { <nl>
public class security637test { <nl> } ) ; <nl> } <nl>  <nl> + @ ignore ( " <nl> @ test <nl> @ issue ( " security - 637 " ) <nl> public void urlsafedeserialization_urlbuiltinagent_insamejvmremotingcontext ( ) { <nl>
public class security637test { <nl> } <nl> } <nl>  <nl> + @ ignore ( " <nl> @ test <nl> @ issue ( " security - 637 " ) <nl> public void urlsafedeserialization_urlbuiltinmaster_insamejvmremotingcontext ( ) {
public class clienvvartest { <nl>  <nl> @ test <nl> public void testwithoutsoptionandwithoutjenkins_url ( ) throws exception { <nl> + assume . assumethat ( system . getenv ( " jenkins_url " ) , is ( nullvalue ( ) ) ) ; <nl> assertnotequals ( 0 , launch ( " java " , <nl> " - duser . home = " + home , <nl> " - jar " , jar . getabsolutepath ( ) ,
<nl> + package hudson . model ; <nl> + <nl> + import org . junit . assert ; <nl> + import org . junit . rule ; <nl> + import org . junit . test ; <nl> + import org . jvnet . hudson . test . issue ; <nl> + import org . jvnet . hudson . test . jenkinsrule ; <nl> + import org . jvnet . hudson . test . recipes . localdata ; <nl> + import org . xml . sax . saxexception ; <nl> + <nl> + import java . io . ioexception ; <nl> + <nl> + <nl> + public class causesecurity1960test { <nl> + @ rule <nl> + public jenkinsrule j = new jenkinsrule ( ) ; <nl> + <nl> + @ test <nl> + @ issue ( " security - 1960 " ) <nl> + @ localdata <nl> + public void xssinremotecause ( ) throws ioexception , saxexception { <nl> + final item item = j . jenkins . getitembyfullname ( " fs " ) ; <nl> + assert . asserttrue ( item instanceof freestyleproject ) ; <nl> + freestyleproject fs = ( freestyleproject ) item ; <nl> + final freestylebuild build = fs . getbuildbynumber ( 1 ) ; <nl> + <nl> + final jenkinsrule . webclient wc = j . createwebclient ( ) ; <nl> + final string content = wc . getpage ( build ) . getwebresponse ( ) . getcontentasstring ( ) ; <nl> + assert . assertfalse ( content . contains ( " started by remote host < img " ) ) ; <nl> + assert . asserttrue ( content . contains ( " started by remote host & lt ; img " ) ) ; <nl> + } <nl> + } <nl> mmm / dev / null <nl> ppp b / test / src / test / resources / hudson / model / causesecurity1960test / jobs / fs / builds / 1 / build . xml <nl>
public class isoverriddentest { <nl> } <nl> public class derived extends intermediate { } <nl>  <nl> + @ ignore ( " <nl> + @ issue ( " jenkins - 62723 " ) <nl> + @ test <nl> + public void finaloverrides ( ) { <nl> + errors . checkthat ( " x1 overrides x . m1 " , util . isoverridden ( x . class , x1 . class , " m1 " ) , is ( true ) ) ; <nl> + errors . checkthat ( " x1 does not override x . m2 " , util . isoverridden ( x . class , x1 . class , " m2 " ) , is ( false ) ) ; <nl> + errors . checkthat ( " x2 overrides x . m1 " , util . isoverridden ( x . class , x2 . class , " m1 " ) , is ( true ) ) ; <nl> + errors . checkthat ( " x2 does not override x . m2 " , util . isoverridden ( x . class , x2 . class , " m2 " ) , is ( false ) ) ; <nl> + errors . checkthat ( " x3 overrides x . m1 " , util . isoverridden ( x . class , x3 . class , " m1 " ) , is ( true ) ) ; <nl> + errors . checkthat ( " x3 overrides x . m2 " , util . isoverridden ( x . class , x3 . class , " m2 " ) , is ( true ) ) ; <nl> + errors . checkthat ( " x4 overrides x . m1 " , util . isoverridden ( x . class , x4 . class , " m1 " ) , is ( true ) ) ; <nl> + errors . checkthat ( " x4 overrides x . m2 " , util . isoverridden ( x . class , x4 . class , " m2 " ) , is ( true ) ) ; <nl> + } <nl> + public static interface x { <nl> + void m1 ( ) ; <nl> + default void m2 ( ) { } <nl> + } <nl> + public static class x1 implements x { <nl> + public void m1 ( ) { } <nl> + } <nl> + public static class x2 implements x { <nl> + public final void m1 ( ) { } <nl> + } <nl> + public static class x3 implements x { <nl> + public void m1 ( ) { } <nl> + @ override <nl> + public void m2 ( ) { } <nl> + } <nl> + public static class x4 implements x { <nl> + public void m1 ( ) { } <nl> + @ override <nl> + public final void m2 ( ) { } <nl> + } <nl> + <nl> }
<nl> + / * <nl> + * the mit license <nl> + * <nl> + * copyright ( c ) num - 2009 , sun microsystems , inc . , kohsuke kawaguchi <nl> + * copyright ( c ) num christopher simons <nl> + * <nl> + * permission is hereby granted , free of charge , to any person obtaining a copy <nl> + * of this software and associated documentation files ( the " software " ) , to deal <nl> + * in the software without restriction , including without limitation the rights <nl> + * to use , copy , modify , merge , publish , distribute , sublicense , and / or sell <nl> + * copies of the software , and to permit persons to whom the software is <nl> + * furnished to do so , subject to the following conditions : <nl> + * <nl> + * the above copyright notice and this permission notice shall be included in <nl> + * all copies or substantial portions of the software . <nl> + * <nl> + * the software is provided " as is " , without warranty of any kind , express or <nl> + * implied , including but not limited to the warranties of merchantability , <nl> + * fitness for a particular purpose and noninfringement . in no event shall the <nl> + * authors or copyright holders be liable for any claim , damages or other <nl> + * liability , whether in an action of contract , tort or otherwise , arising from , <nl> + * out of or in connection with the software or the use or other dealings in <nl> + * the software . <nl> + * / <nl> + package hudson . model ; <nl> + <nl> + import hudson . slaves . retentionstrategy ; <nl> + import org . junit . rule ; <nl> + import org . junit . test ; <nl> + import org . jvnet . hudson . test . issue ; <nl> + import org . jvnet . hudson . test . jenkinsrule ; <nl> + <nl> + import java . util . arraylist ; <nl> + import java . util . concurrent . atomic . atomicreference ; <nl> + <nl> + import static org . junit . assert . assertequals ; <nl> + <nl> + / * * <nl> + * @ author kohsuke kawaguchi <nl> + * / <nl> + <nl> + public class jobsec1868test { <nl> + <nl> + @ rule public jenkinsrule j = new jenkinsrule ( ) ; <nl> + <nl> + @ issue ( " security - 1868 " ) <nl> + @ test public void noxsspossible ( ) throws exception { <nl> + string desirednodename = " agent is a better name2 < script > alert ( 123 ) < / script > " ; <nl> + string initialnodename = " agent is a better name " ; <nl> + <nl> + namechangingnode node = new namechangingnode ( j , initialnodename ) ; <nl> + j . jenkins . addnode ( node ) ; <nl> + <nl> + j . waitonline ( node ) ; <nl> + <nl> + j . jenkins . setnumexecutors ( 0 ) ; <nl> + <nl> + freestyleproject p = j . createfreestyleproject ( ) ; <nl> + j . assertbuildstatussuccess ( p . schedulebuild2 ( 0 ) ) ; <nl> + <nl> + node . setvirtualname ( desirednodename ) ; <nl> + <nl> + jenkinsrule . webclient wc = j . createwebclient ( ) ; <nl> + atomicreference < string > alertcontent = new atomicreference < > ( " " ) ; <nl> + <nl> + wc . setalerthandler ( ( page , s1 ) - > <nl> + alertcontent . set ( s1 ) <nl> + ) ; <nl> + <nl> + wc . withthrowexceptiononfailingstatuscode ( false ) ; <nl> + wc . getpage ( p , " buildtimetrend " ) ; <nl> + <nl> + assertequals ( " " , alertcontent . get ( ) ) ; <nl> + } <nl> + <nl> + / * * <nl> + * this special class was created just to avoid running the test on unix only <nl> + * as the only limitation is the file path , if we change only the name , the xss is possible also under windows <nl> + * / <nl> + static class namechangingnode extends slave { <nl> + private string virtualname ; <nl> + <nl> + public namechangingnode ( jenkinsrule j , string name ) throws exception { <nl> + super ( name , " dummy " , j . createtmpdir ( ) . getpath ( ) , " 1 " , node . mode . normal , " " , j . createcomputerlauncher ( null ) , retentionstrategy . noop , new arraylist < > ( ) ) ; <nl> + } <nl> + <nl> + public void setvirtualname ( string virtualname ) { <nl> + this . virtualname = virtualname ; <nl> + } <nl> + <nl> + @ override <nl> + public string getnodename ( ) { <nl> + if ( virtualname ! = null ) { <nl> + return virtualname ; <nl> + } else { <nl> + return super . getnodename ( ) ; <nl> + } <nl> + } <nl> + } <nl> + }
public class logtasklistener extends abstracttasklistener implements tasklistene <nl> return delegate . getlogger ( ) ; <nl> } <nl>  <nl> - @ override <nl> - @ suppresswarnings ( " rawtypes " ) <nl> - public void annotate ( consolenote ann ) { <nl> - / / no annotation support <nl> - } <nl> - <nl> @ override <nl> public void close ( ) { <nl> delegate . getlogger ( ) . close ( ) ; <nl> } <nl>  <nl> + <nl> private static class logoutputstream extends outputstream { <nl>  <nl> private final logger logger ; <nl> mmm / dev / null <nl> ppp b / test / src / test / java / hudson / util / logtasklistenertest . java <nl>
the software . <nl> - - > <nl> < groupid > org . jenkins - ci < / groupid > <nl> < artifactid > winstone < / artifactid > <nl> - < version > 5 . 6 < / version > <nl> + < version > 5 . 8 - rc518 . e237e80782ab < / version > < ! - - <nl> < scope > test < / scope > <nl> < / dependency > <nl> < dependency >
jobs : <nl> uses : jenkinsci / jenkins - core - changelog - generator @ master <nl> env : <nl> github_auth : github - actions : $ { { secrets . github_token } } <nl> - # upload yaml to the release draft assets <nl> - - name : upload changelog . yaml to the release draft <nl> - id : upload - changelog - yaml <nl> - uses : actions / upload - release - asset @ v1 . 0 . 1 <nl> - env : <nl> - github_token : $ { { secrets . github_token } } <nl> + - name : upload changelog yaml <nl> + uses : actions / upload - artifact @ v1 <nl> with : <nl> - upload_url : $ { { steps . release - drafter . outputs . upload_url } } <nl> - asset_path : . / changelog . yaml <nl> - asset_name : changelog . yaml <nl> - asset_content_type : text / yaml <nl> + name : changelog . yaml <nl> + path : changelog . yaml <nl> + # <nl> + # upload yaml to the release draft assets <nl> + # - name : upload changelog . yaml to the release draft <nl> + # id : upload - changelog - yaml <nl> + # uses : actions / upload - release - asset @ v1 . 0 . 1 <nl> + # env : <nl> + # github_token : $ { { secrets . github_token } } <nl> + # with : <nl> + # upload_url : $ { { steps . release - drafter . outputs . upload_url } } <nl> + # asset_path : . / changelog . yaml <nl> + # asset_name : changelog . yaml <nl> + # asset_content_type : text / yaml
jobs : <nl> uses : jenkinsci / jenkins - core - changelog - generator @ master <nl> env : <nl> github_auth : github - actions : $ { { secrets . github_token } } <nl> + # <nl> + # https : / / github . com / jenkinsci / jenkins / releases / tag / untagged - e3a154d27f5bd99802eb <nl> + - name : upload changelog yaml to the release draft ( untagged - e3a154d27f5bd99802eb ) <nl> + uses : svenstaro / upload - release - action @ v1 - release <nl> + with : <nl> + repo_token : $ { { secrets . github_token } } <nl> + file : changelog . yaml <nl> + asset_name : changelog . yaml <nl> + tag : untagged - e3a154d27f5bd99802eb <nl> + overwrite : true
import pluginselectlist from ' . / templates / pluginselectlist . hbs ' ; <nl>  <nl> handlebars . registerpartial ( ' pluginselectlist ' , pluginselectlist ) ; <nl>  <nl> - window . zq = $ <nl> + <nl> + <nl> + window . zq = $ ; <nl>  <nl> / / setup the dialog , exported <nl> var createpluginsetupwizard = function ( appendtarget ) { <nl>
public class plugintest { <nl> ( ( testpluginmanager ) r . jenkins . pluginmanager ) . installdetachedplugin ( " matrix - auth " ) ; <nl> r . createwebclient ( ) . goto ( " plugin / matrix - auth / images / user - disabled . png " , " image / png " ) ; <nl> r . createwebclient ( ) . goto ( " plugin / matrix - auth / images / . . / images / user - disabled . png " , " image / png " ) ; / / collapsed somewhere before it winds up in restofpath <nl> + / * <nl> r . createwebclient ( ) . assertfails ( " plugin / matrix - auth / images / % 2e % 2e / images / user - disabled . png " , httpservletresponse . sc_internal_server_error ) ; / / iae from tokenlist . < init > <nl> r . createwebclient ( ) . assertfails ( " plugin / matrix - auth / images / % 252e % 252e / images / user - disabled . png " , httpservletresponse . sc_bad_request ) ; / / security - 131 <nl> r . createwebclient ( ) . assertfails ( " plugin / matrix - auth / images / % 25252e % 25252e / images / user - disabled . png " , httpservletresponse . sc_bad_request ) ; / / just checking <nl> + * / <nl> / / security - 705 : <nl> r . createwebclient ( ) . assertfails ( " plugin / matrix - auth / images / . . % 2fweb - inf / licenses . xml " , httpservletresponse . sc_bad_request ) ; <nl> r . createwebclient ( ) . assertfails ( " plugin / matrix - auth / . / matrix - auth . jpi " , / * path collapsed to simply ` credentials . jpi ` before entering * / httpservletresponse . sc_not_found ) ; <nl> mmm a / test / src / test / java / hudson / diagnosis / hudsonhomediskusagemonitortest . java <nl> ppp b / test / src / test / java / hudson / diagnosis / hudsonhomediskusagemonitortest . java <nl>
public class security637test { <nl> return handler . getclass ( ) . getname ( ) ; <nl> } <nl> } <nl> - <nl> + <nl> + @ ignore ( " <nl> @ test <nl> @ issue ( " security - 637 " ) <nl> public void urldnsequivalence ( ) { <nl>
public class security637test { <nl> } ) ; <nl> } <nl>  <nl> + @ ignore ( " <nl> @ test <nl> @ issue ( " security - 637 " ) <nl> public void urlsafedeserialization_urlbuiltinagent_insamejvmremotingcontext ( ) { <nl>
public class security637test { <nl> } <nl> } <nl>  <nl> + @ ignore ( " <nl> @ test <nl> @ issue ( " security - 637 " ) <nl> public void urlsafedeserialization_urlbuiltinmaster_insamejvmremotingcontext ( ) {
public class peepholepermalinktest { <nl>  <nl> string lsb = " lastsuccessfulbuild " ; <nl> string lfb = " lastfailedbuild " ; <nl> + string lcb = " lastcompletedbuild " ; <nl>  <nl> assertstorage ( lsb , p , b1 ) ; <nl> + / * <nl> + assertstorage ( lfb , p , null ) ; <nl> + * / <nl> + assertstorage ( lcb , p , b1 ) ; <nl>  <nl> / / now another build that fails <nl> p . getbuilderslist ( ) . add ( new failurebuilder ( ) ) ; <nl>
def failfast = false <nl>  <nl> properties ( [ builddiscarder ( logrotator ( numtokeepstr : ' 50 ' , artifactnumtokeepstr : ' 3 ' ) ) , durabilityhint ( ' performance_optimized ' ) ] ) <nl>  <nl> - def buildtypes = [ ' linux ' , ' windows ' ] <nl> + <nl> + def buildtypes = [ ' linux ' ] <nl> def jdks = [ 8 , num ] <nl>  <nl> def builds = [ : ] <nl>
public class peepholepermalinktest { <nl>  <nl> string lsb = " lastsuccessfulbuild " ; <nl> string lfb = " lastfailedbuild " ; <nl> + string lcb = " lastcompletedbuild " ; <nl>  <nl> assertstorage ( lsb , p , b1 ) ; <nl> + / * <nl> + assertstorage ( lfb , p , null ) ; <nl> + * / <nl> + assertstorage ( lcb , p , b1 ) ; <nl>  <nl> / / now another build that fails <nl> p . getbuilderslist ( ) . add ( new failurebuilder ( ) ) ; <nl>
<nl> + package lib . form ; <nl> + <nl> + import com . gargoylesoftware . htmlunit . html . htmlelement ; <nl> + import com . gargoylesoftware . htmlunit . html . htmlelementutil ; <nl> + import com . gargoylesoftware . htmlunit . html . htmlpage ; <nl> + import hudson . model . freestyleproject ; <nl> + import hudson . model . job ; <nl> + import hudson . util . comboboxmodel ; <nl> + import jenkins . model . optionaljobproperty ; <nl> + import org . jvnet . hudson . test . hudsontestcase ; <nl> + import org . jvnet . hudson . test . issue ; <nl> + import org . jvnet . hudson . test . testextension ; <nl> + <nl> + <nl> + public class comboboxsec1525test extends hudsontestcase { <nl> + public static class xssproperty extends optionaljobproperty < job < ? , ? > > { <nl> + @ testextension ( " testensurexssnotpossible " ) <nl> + public static class descriptorimpl extends optionaljobproperty . optionaljobpropertydescriptor { <nl> + <nl> + @ override <nl> + public string getdisplayname ( ) { <nl> + return " xss property " ; <nl> + } <nl> + <nl> + public comboboxmodel dofillxssitems ( ) { <nl> + return new comboboxmodel ( " < h1 > hack < / h1 > " ) ; <nl> + } <nl> + } <nl> + } <nl> + <nl> + @ issue ( " security - 1525 " ) <nl> + public void testensurexssnotpossible ( ) throws exception { <nl> + xssproperty xssproperty = new xssproperty ( ) ; <nl> + freestyleproject p = createfreestyleproject ( ) ; <nl> + p . addproperty ( xssproperty ) ; <nl> + <nl> + webclient wc = new webclient ( ) ; <nl> + <nl> + htmlpage configurepage = wc . getpage ( p , " configure " ) ; <nl> + int numberofh1before = configurepage . getelementsbytagname ( " h1 " ) . size ( ) ; <nl> + <nl> + htmlelement combobox = configurepage . getelementbyname ( " _ . xss " ) ; <nl> + htmlelementutil . click ( combobox ) ; <nl> + <nl> + / / no additional h1 , meaning the " payload " is not interpreted <nl> + int numberofh1after = configurepage . getelementsbytagname ( " h1 " ) . size ( ) ; <nl> + <nl> + assertequals ( numberofh1before , numberofh1after ) ; <nl> + } <nl> + } <nl> mmm / dev / null <nl> ppp b / test / src / test / resources / lib / form / comboboxsec1525test / xssproperty / config . jelly <nl>
<nl> + package lib . form ; <nl> + <nl> + import com . gargoylesoftware . htmlunit . html . htmlelementutil ; <nl> + import com . gargoylesoftware . htmlunit . html . htmlinput ; <nl> + import com . gargoylesoftware . htmlunit . html . htmlpage ; <nl> + import hudson . model . freestyleproject ; <nl> + import hudson . model . job ; <nl> + import jenkins . model . optionaljobproperty ; <nl> + import org . junit . rule ; <nl> + import org . junit . test ; <nl> + import org . jvnet . hudson . test . jenkinsrule ; <nl> + import org . jvnet . hudson . test . testextension ; <nl> + <nl> + import static org . junit . assert . assertequals ; <nl> + <nl> + <nl> + public class expandabletextboxsec1498test { <nl> + @ rule <nl> + public jenkinsrule j = new jenkinsrule ( ) ; <nl> + <nl> + @ test <nl> + public void noxssusinginputvalue ( ) throws exception { <nl> + xssproperty xssproperty = new xssproperty ( " < / textarea > < h1 > hack < / h1 > " ) ; <nl> + freestyleproject p = j . createfreestyleproject ( ) ; <nl> + p . addproperty ( xssproperty ) ; <nl> + <nl> + jenkinsrule . webclient wc = j . createwebclient ( ) ; <nl> + htmlpage configurepage = wc . getpage ( p , " configure " ) ; <nl> + <nl> + int numberofh1before = configurepage . getelementsbytagname ( " h1 " ) . size ( ) ; <nl> + <nl> + htmlinput xssinput = configurepage . getelementbyname ( " _ . xss " ) ; <nl> + htmlinput expandbutton = ( htmlinput ) xssinput . getparentnode ( ) . getnextsibling ( ) . getfirstchild ( ) ; <nl> + htmlelementutil . click ( expandbutton ) ; <nl> + <nl> + / / no additional h1 , meaning the " payload " is not interpreted <nl> + int numberofh1after = configurepage . getelementsbytagname ( " h1 " ) . size ( ) ; <nl> + <nl> + assertequals ( numberofh1before , numberofh1after ) ; <nl> + } <nl> + <nl> + public static final class xssproperty extends optionaljobproperty < job < ? , ? > > { <nl> + <nl> + private string xss ; <nl> + <nl> + public xssproperty ( string xss ) { <nl> + this . xss = xss ; <nl> + } <nl> + <nl> + public string getxss ( ) { <nl> + return xss ; <nl> + } <nl> + <nl> + @ testextension ( " noxssusinginputvalue " ) <nl> + public static class descriptorimpl extends optionaljobproperty . optionaljobpropertydescriptor { <nl> + } <nl> + } <nl> + } <nl> mmm / dev / null <nl> ppp b / test / src / test / resources / lib / form / expandabletextboxsec1498test / xssproperty / config - details . jelly <nl>
public class rsstest { <nl> @ rule <nl> public jenkinsrule j = new jenkinsrule ( ) ; <nl>  <nl> + <nl> @ test <nl> + @ ignore ( " xml parser too picky on ci " ) <nl> @ issue ( " jenkins - 59167 " ) <nl> public void absoluteurlspresentinrss_evenwithoutrooturlsetup ( ) throws exception { <nl> xmlpage page = getrsspage ( ) ; <nl>
public class rsstest { <nl> } <nl> } <nl>  <nl> + <nl> @ test <nl> + @ ignore ( " xml parser too picky on ci " ) <nl> @ issue ( " jenkins - 59167 " ) <nl> public void absoluteurlspresentinatom_evenwithoutrooturlsetup ( ) throws exception { <nl> xmlpage page = getatompage ( ) ;
the software . <nl> < findbugs . threshold > high < / findbugs . threshold > <nl> < findbugs . excludefilterfile > $ { project . basedir } / . . / src / findbugs / findbugs - excludes . xml < / findbugs . excludefilterfile > <nl>  <nl> - < ! - - xxx keep these in sync - - > <nl> + < ! - - <nl> < access - modifier - annotation . version > 1 . 14 < / access - modifier - annotation . version > <nl> < access - modifier - checker . version > 1 . 14 < / access - modifier - checker . version > <nl> < / properties > <nl>
template : | <nl> ` ` ` yaml <nl> $ changes <nl> ` ` ` <nl> + <nl> + # categories will be commented out , because we use yaml <nl> + # now we use categories only for sorting <nl> + categories : <nl> + - title : major bugs and regressions <nl> + labels : <nl> + - major - bug <nl> + - regression - fix <nl> + - title : major rfe <nl> + label : major - rfe <nl> + - title : rfes <nl> + label : enhancement <nl> + - title : bug fixes <nl> + label : bug <nl> + - title : localization <nl> + label : localization <nl> + # <nl> + - title : internal / developer changes <nl> + label : internal <nl> + <nl> replacers : <nl> - search : ' / \ [ * jenkins - ( \ d + ) \ ] * \ s * - * \ s * / g ' <nl> replace : | - <nl>
def failfast = false <nl>  <nl> properties ( [ builddiscarder ( logrotator ( numtokeepstr : ' 50 ' , artifactnumtokeepstr : ' 3 ' ) ) , durabilityhint ( ' performance_optimized ' ) ] ) <nl>  <nl> - def buildtypes = [ ' linux ' , ' windows ' ] <nl> + <nl> + def buildtypes = [ ' linux ' ] <nl> def jdks = [ 8 , num ] <nl>  <nl> def builds = [ : ] <nl>
import java . io . serializable ; <nl> import org . apache . commons . io . ioutils ; <nl> import org . kohsuke . args4j . argument ; <nl>  <nl> + <nl> + <nl> + @ suppressfbwarnings ( value = " se_no_serialversionid " , justification = " the serializable should be removed . " ) <nl> @ extension <nl> public class setbuilddescriptioncommand extends clicommand implements serializable { <nl>  <nl> - private static final long serialversionuid = num l ; <nl> - <nl> @ override <nl> public string getshortdescription ( ) { <nl> return messages . setbuilddescriptioncommand_shortdescription ( ) ;
public class loaddetachedpluginstest { <nl> assertequals ( expectedplugin , pw . getshortname ( ) ) ; <nl> } <nl>  <nl> + @ issue ( " jenkins - 55582 " ) <nl> + @ localdata <nl> + @ test <nl> + public void nonstandardfilenames ( ) { <nl> + logging . record ( pluginmanager . class , level . fine ) . record ( classicpluginstrategy . class , level . fine ) ; <nl> + rr . then ( r - > { <nl> + asserttrue ( r . jenkins . pluginmanager . getplugin ( " build - token - root " ) . isactive ( ) ) ; <nl> + assertequals ( " 1 . 2 " , r . jenkins . pluginmanager . getplugin ( " jdk - tool " ) . getversion ( ) ) ; <nl> + / * <nl> + assertequals ( " 1 . 3 " , r . jenkins . pluginmanager . getplugin ( " command - launcher " ) . getversion ( ) ) ; <nl> + * / <nl> + } ) ; <nl> + } <nl> + <nl> private list < pluginwrapper > getinstalleddetachedplugins ( jenkinsrule r , list < detachedplugin > detachedplugins ) { <nl> pluginmanager pluginmanager = r . jenkins . getpluginmanager ( ) ; <nl> list < pluginwrapper > installedplugins = new arraylist < > ( ) ; <nl> binary files / dev / null and b / test / src / test / resources / jenkins / install / loaddetachedpluginstest / nonstandardfilenames / plugins / build - token - root . jpi differ <nl> binary files / dev / null and b / test / src / test / resources / jenkins / install / loaddetachedpluginstest / nonstandardfilenames / plugins / command - launcher - 1 . 3 . hpi differ <nl> binary files / dev / null and b / test / src / test / resources / jenkins / install / loaddetachedpluginstest / nonstandardfilenames / plugins / jdk - tool . hpi differ
public class functions { <nl> / * * <nl> * converts the hudson build status to cruisecontrol build status , <nl> * which is either success , failure , exception , or unknown . <nl> + * <nl> + * @ deprecated this functionality has been moved to ccxml plugin . <nl> * / <nl> + @ deprecated <nl> + @ restricted ( donotuse . class ) <nl> + @ restrictedsince ( " since <nl> public static string toccstatus ( item i ) { <nl> - if ( i instanceof job ) { <nl> - job j = ( job ) i ; <nl> - switch ( j . geticoncolor ( ) ) { <nl> - case aborted : <nl> - case aborted_anime : <nl> - case red : <nl> - case red_anime : <nl> - case yellow : <nl> - case yellow_anime : <nl> - return " failure " ; <nl> - case blue : <nl> - case blue_anime : <nl> - return " success " ; <nl> - case disabled : <nl> - case disabled_anime : <nl> - case grey : <nl> - case grey_anime : <nl> - case notbuilt : <nl> - case notbuilt_anime : <nl> - return " unknown " ; <nl> - } <nl> - } <nl> return " unknown " ; <nl> } <nl>  <nl> mmm a / core / src / main / resources / hudson / model / view / builds . jelly <nl> ppp b / core / src / main / resources / hudson / model / view / builds . jelly <nl>
public class argumentlistbuilder2test { <nl> args . add ( " java " ) ; <nl> args . addmasked ( " - version " ) ; <nl>  <nl> - slave s = j . createslave ( ) ; <nl> - s . tocomputer ( ) . connect ( false ) . get ( ) ; <nl> + slave s = j . createonlineslave ( ) ; <nl> + / * <nl> + j . showslavelogs ( s , logging ) ; <nl> + * / <nl>  <nl> stringwriter out = new stringwriter ( ) ; <nl> assertequals ( 0 , s . createlauncher ( new streamtasklistener ( out ) ) . launch ( ) . cmds ( args ) . join ( ) ) ;
public class plugintest { <nl> r . createwebclient ( ) . assertfails ( " plugin / credentials / meta - inf / manifest . mf " , httpservletresponse . sc_bad_request ) ; <nl> } <nl>  <nl> + @ ignore ( " <nl> + @ test <nl> + @ issue ( " security - 925 " ) <nl> + public void preventtimestamp2_tobeserved ( ) throws exception { <nl> + / / impossible to use installdetachedplugin ( " credentials " ) since we want to have it exploded like with war <nl> + jenkins . getinstance ( ) . getupdatecenter ( ) . getsites ( ) . get ( 0 ) . updatedirectlynow ( false ) ; <nl> + list < future < updatecenter . updatecenterjob > > plugininstalled = r . jenkins . pluginmanager . install ( arrays . aslist ( " credentials " ) , true ) ; <nl> + <nl> + for ( future < updatecenter . updatecenterjob > job : plugininstalled ) { <nl> + job . get ( ) ; <nl> + } <nl> + r . createwebclient ( ) . assertfails ( " plugin / credentials / . timestamp2 " , httpservletresponse . sc_bad_request ) ; <nl> + } <nl> }
the software . <nl> < version > 2 . 2 < / version > <nl> < / dependency > <nl> < dependency > <nl> - < ! - - sshcliauthenticator no longer used , but userpropertyimpl used by sshd : - - > <nl> < groupid > org . jenkins - ci . modules < / groupid > <nl> < artifactid > ssh - cli - auth < / artifactid > <nl> - < version > 1 . 4 < / version > <nl> + < version > 1 . 5 - 20190205 . 173740 - 1 < / version > < ! - - <nl> < / dependency > <nl> < dependency > <nl> < groupid > org . jenkins - ci . modules < / groupid >
public class apitest { <nl> j . createfreestyleproject ( ) ; <nl> j . createwebclient ( ) . assertfails ( " api / xml ? xpath = / hudson / job / name " , httpurlconnection . http_internal_error ) ; <nl> } <nl> + <nl> + @ issue ( " jenkins - 22566 " ) <nl> + @ test <nl> + public void parameter ( ) throws exception { <nl> + freestyleproject p = j . createfreestyleproject ( " p " ) ; <nl> + p . addproperty ( new parametersdefinitionproperty ( new stringparameterdefinition ( " foo " , " " ) ) ) ; <nl> + j . assertbuildstatussuccess ( p . schedulebuild2 ( 0 , new parametersaction ( new stringparametervalue ( " foo " , " bar " ) ) ) ) ; <nl> + <nl> + page page = j . createwebclient ( ) . goto ( <nl> + p . geturl ( ) + " api / xml ? tree = builds [ actions [ parameters [ name , value ] ] ] & xpath = freestyleproject / build / action / parameter " , <nl> + " application / xml " ) ; <nl> + assertequals ( <nl> + " < parameter _class = \ " hudson . model . stringparametervalue \ " > < name > foo < / name > < value > bar < / value > < / parameter > " , <nl> + page . getwebresponse ( ) . getcontentasstring ( ) ) ; <nl> + } <nl> + <nl> + @ issue ( " jenkins - 22566 " ) <nl> + @ ignore ( " <nl> + @ test <nl> + public void escapedparameter ( ) throws exception { <nl> + freestyleproject p = j . createfreestyleproject ( " p " ) ; <nl> + p . addproperty ( new parametersdefinitionproperty ( new stringparameterdefinition ( " foo " , " " ) ) ) ; <nl> + j . assertbuildstatussuccess ( p . schedulebuild2 ( 0 , new parametersaction ( new stringparametervalue ( " foo " , " bar \ u001b " ) ) ) ) ; <nl> + <nl> + page page = j . createwebclient ( ) . goto ( <nl> + p . geturl ( ) + " api / xml ? tree = builds [ actions [ parameters [ name , value ] ] ] & xpath = freestyleproject / build / action / parameter " , <nl> + " application / xml " ) ; <nl> + assertequals ( <nl> + " < parameter _class = \ " hudson . model . stringparametervalue \ " > < name > foo < / name > < value > bar & # x1b ; < / value > < / parameter > " , <nl> + page . getwebresponse ( ) . getcontentasstring ( ) ) ; <nl> + } <nl> }
public class hudsonprivatesecurityrealm extends abstractpasswordbasedsecurityrea <nl> public string username , password1 , password2 , fullname , email , captcha ; <nl>  <nl> / * * <nl> - * to display an error message , set it here . <nl> + * to display a general error message , set it here . <nl> + * <nl> * / <nl> public string errormessage ; <nl>  <nl> + / * * <nl> + * add field - specific error messages here . <nl> + * keys are field names ( e . g . { @ code password2 } ) , values are the messages . <nl> + * / <nl> + <nl> public hashmap < string , string > errors = new hashmap < string , string > ( ) ; <nl>  <nl> public signupinfo ( ) { <nl> mmm a / core / src / main / resources / hudson / security / hudsonprivatesecurityrealm / _entryform . jelly <nl> ppp b / core / src / main / resources / hudson / security / hudsonprivatesecurityrealm / _entryform . jelly <nl>
public class javautils { <nl> * @ return { @ code true } if it is java num or above <nl> * / <nl> public static boolean isrunningwithpostjava8 ( ) { <nl> - string javaversion = system . getproperty ( " java . specification . version " ) ; <nl> + string javaversion = getcurrentruntimejavaversion ( ) ; <nl> return ! javaversion . startswith ( " 1 . " ) ; <nl> } <nl>  <nl> + / * * <nl> + * returns the jvm ' s current version as a { @ link versionnumber } instance . <nl> + * / <nl> + public static versionnumber getcurrentjavaruntimeversionnumber ( ) { <nl> + return new versionnumber ( getcurrentruntimejavaversion ( ) ) ; <nl> + } <nl> + <nl> + / * * <nl> + * returns the jvm ' s current version as a { @ link string } . <nl> + * @ see system # getproperty ( string ) <nl> + * / <nl> + public static string getcurrentruntimejavaversion ( ) { <nl> + <nl> + return system . getproperty ( " java . specification . version " ) ; <nl> + } <nl> }
public abstract class securitylistener implements extensionpoint { <nl> } <nl> } <nl>  <nl> + / * * @ since <nl> + public static void fireusercreated ( @ nonnull string username ) { <nl> + logger . log ( level . fine , " new user created : { 0 } " , username ) ; <nl> + for ( securitylistener l : all ( ) ) { <nl> + l . usercreated ( username ) ; <nl> + } <nl> + } <nl> + <nl> / * * @ since num . 569 * / <nl> public static void firefailedtoauthenticate ( @ nonnull string username ) { <nl> logger . log ( level . fine , " failed to authenticate : { 0 } " , username ) ; <nl> mmm a / test / src / test / java / hudson / security / hudsonprivatesecurityrealmtest . java <nl> ppp b / test / src / test / java / hudson / security / hudsonprivatesecurityrealmtest . java <nl>
public class disableplugincommandtest { <nl> / * * <nl> * can disable a plugin without dependents plugins and jenkins restart after it if - restart argument is passed . <nl> * / <nl> + @ ignore ( " <nl> @ test <nl> @ issue ( " jenkins - 27177 " ) <nl> @ withplugin ( " dependee - 0 . 0 . 2 . hpi " ) <nl>
public class disableplugincommandtest { <nl> / * * <nl> * if some plugins are disabled , jenkins will restart even though the status code isn ' t num ( is num ) . <nl> * / <nl> + @ ignore ( " <nl> @ test <nl> @ issue ( " jenkins - 27177 " ) <nl> @ withplugin ( { " variant . hpi " , " depender - 0 . 0 . 2 . hpi " , " mandatory - depender - 0 . 0 . 2 . hpi " , " plugin - first . hpi " , " dependee - 0 . 0 . 2 . hpi " , } ) <nl> mmm a / test / src / test / java / hudson / cli / enableplugincommandtest . java <nl> ppp b / test / src / test / java / hudson / cli / enableplugincommandtest . java <nl>
public class enableplugincommandtest { <nl> assertjenkinsnotinquietmode ( ) ; <nl> } <nl>  <nl> + @ ignore ( " <nl> @ test <nl> @ issue ( " jenkins - 52950 " ) <nl> public void enablepluginwithrestart ( ) throws ioexception {
public class jenkinsbuildsandworkspacesdirectoriestest { <nl> ) ; <nl> } <nl>  <nl> + @ ignore ( " <nl> @ issue ( " jenkins - 50164 " ) <nl> @ localdata <nl> @ test <nl>
public class queuetest { <nl> fail ( " expected an cancellationexception to be thrown " ) ; <nl> } catch ( cancellationexception e ) { } <nl> } <nl> - <nl> + <nl> + @ ignore ( " <nl> @ issue ( " jenkins - 27871 " ) <nl> @ test public void testblockbuildwhenupstreambuildinglock ( ) throws exception { <nl> final string prefix = " jenkins - 27871 " ;
import static hudson . cli . disableplugincommand . return_code_no_such_plugin ; <nl> import static org . hamcrest . matchers . is ; <nl> import static org . hamcrest . matchers . notnullvalue ; <nl> import static org . junit . assert . * ; <nl> + import org . junit . ignore ; <nl>  <nl> + @ ignore ( " <nl> public class disableplugincommandtest { <nl>  <nl> @ rule
public class utiltest { <nl> assertfalse ( " f1 exists " , f1 . exists ( ) ) ; <nl> } <nl>  <nl> + @ ignore ( " <nl> @ test <nl> public void testdeletecontentsrecursive_onwindows ( ) throws exception { <nl> assume . assumetrue ( functions . iswindows ( ) ) ; <nl> mmm a / test / src / test / java / hudson / pluginsec925test . java <nl> ppp b / test / src / test / java / hudson / pluginsec925test . java <nl>
public class pluginsec925test { <nl> @ rule <nl> public jenkinsrule r = new jenkinsrule ( ) ; <nl>  <nl> + @ ignore ( " <nl> @ test <nl> @ issue ( " security - 925 " ) <nl> public void preventtimestamp2_tobeserved ( ) throws exception { <nl> mmm a / test / src / test / java / hudson / cli / clitest . java <nl> ppp b / test / src / test / java / hudson / cli / clitest . java <nl>
public class clitest { <nl> } <nl> } <nl>  <nl> + @ ignore ( " <nl> @ test <nl> @ issue ( " jenkins - 54310 " ) <nl> public void readinputatonce ( ) throws exception { <nl> mmm a / test / src / test / java / hudson / util / atomicfilewriterperftest . java <nl> ppp b / test / src / test / java / hudson / util / atomicfilewriterperftest . java <nl>
public class atomicfilewriterperftest { <nl> * so using slightly more than the worse value obtained above should avoid making this flaky and still catch <nl> * < strong > really < / strong > bad performance regressions . <nl> * / <nl> + @ ignore ( " <nl> @ issue ( " jenkins - 34855 " ) <nl> @ test ( timeout = num * num l ) <nl> public void poormanperformancetestbed ( ) throws exception {
public class hudsonprivatesecurityrealm extends abstractpasswordbasedsecurityrea <nl> public string username , password1 , password2 , fullname , email , captcha ; <nl>  <nl> / * * <nl> - * to display an error message , set it here . <nl> + * to display a general error message , set it here . <nl> + * <nl> * / <nl> public string errormessage ; <nl>  <nl> + / * * <nl> + * add field - specific error messages here . <nl> + * keys are field names ( e . g . { @ code password2 } ) , values are the messages . <nl> + * / <nl> + <nl> public hashmap < string , string > errors = new hashmap < string , string > ( ) ; <nl>  <nl> public signupinfo ( ) { <nl> mmm a / core / src / main / resources / hudson / security / hudsonprivatesecurityrealm / _entryform . jelly <nl> ppp b / core / src / main / resources / hudson / security / hudsonprivatesecurityrealm / _entryform . jelly <nl>
public class updatecenter extends abstractmodelobject implements saveable , onmas <nl>  <nl> private boolean requiresrestart ; <nl>  <nl> + static { <nl> + logger logger = logger . getlogger ( updatecenter . class . getname ( ) ) ; <nl> + logger = logger ; <nl> + string ucoverride = systemproperties . getstring ( updatecenter . class . getname ( ) + " . updatecenterurl " ) ; <nl> + if ( ucoverride ! = null ) { <nl> + logger . log ( level . info , " using a custom update center defined by the system property : { 0 } " , ucoverride ) ; <nl> + update_center_url = ucoverride ; <nl> + } else if ( javautils . isrunningwithjava8orbelow ( ) ) { <nl> + update_center_url = " https : / / updates . jenkins . io / " ; <nl> + } else { <nl> + <nl> + string experimentaljava11uc = " https : / / updates . jenkins . io / temporary - experimental - java11 " ; <nl> + logger . log ( level . warning , " running jenkins with java { 0 } which is available in the preview mode only . " + <nl> + " a custom experimental update center will be used : { 1 } " , <nl> + new object [ ] { system . getproperty ( " java . specification . version " ) , experimentaljava11uc } ) ; <nl> + update_center_url = experimentaljava11uc ; <nl> + } <nl> + } <nl> + <nl> / * * <nl> * simple connection status enum . <nl> * / <nl>
the software . <nl> < failifnotests > false < / failifnotests > <nl> < / properties > <nl> < / profile > <nl> + < profile > <nl> + < id > jdk11 < / id > <nl> + < properties > <nl> + < ! - - <nl> + < doclint > none < / doclint > <nl> + < maven . javadoc . skip > true < / maven . javadoc . skip > <nl> + < / properties > <nl> + < activation > <nl> + < jdk > 11 < / jdk > <nl> + < / activation > <nl> + < / profile > <nl> < / profiles > <nl> < / project > <nl> mmm a / src / findbugs / findbugs - excludes . xml <nl> ppp b / src / findbugs / findbugs - excludes . xml <nl>
for ( i = num ; i < buildtypes . size ( ) ; i + + ) { <nl> } <nl> } <nl> } <nl> - } <nl> + } } <nl>  <nl> + <nl> builds . ath = { <nl> node ( " docker & & highmem " ) { <nl> / / just to be safe <nl>
public abstract class pluginmanager extends abstractmodelobject implements onmas <nl> if ( toinstall . isfornewerhudson ( ) ) { <nl> logger . log ( warning , " { 0 } @ { 1 } was built for a newer jenkins " , new object [ ] { toinstall . name , toinstall . version } ) ; <nl> } <nl> + <nl> jobs . add ( toinstall . deploy ( true ) ) ; <nl> } else if ( pw . isolderthan ( requestedplugin . getvalue ( ) ) ) { / / upgrade <nl> updatesite . plugin toinstall = uc . getplugin ( requestedplugin . getkey ( ) ) ; <nl>
public abstract class pluginmanager extends abstractmodelobject implements onmas <nl> if ( toinstall . isfornewerhudson ( ) ) { <nl> logger . log ( warning , " { 0 } @ { 1 } was built for a newer jenkins " , new object [ ] { toinstall . name , toinstall . version } ) ; <nl> } <nl> + <nl> if ( ! toinstall . iscompatiblewithinstalledversion ( ) ) { <nl> logger . log ( warning , " { 0 } @ { 1 } is incompatible with the installed @ { 2 } " , new object [ ] { toinstall . name , toinstall . version , pw . getversion ( ) } ) ; <nl> } <nl> mmm a / core / src / main / java / hudson / model / updatesite . java <nl> ppp b / core / src / main / java / hudson / model / updatesite . java <nl>
public class apitokenstore { <nl> this . init ( ) ; <nl> } <nl>  <nl> + <nl> + @ suppressfbwarnings ( " se_read_resolve_must_return_object " ) <nl> private apitokenstore readresolve ( ) { <nl> this . init ( ) ; <nl> return this ; <nl>
public class apitokenstore { <nl> this . init ( ) ; <nl> } <nl>  <nl> + <nl> + @ suppressfbwarnings ( " se_read_resolve_must_return_object " ) <nl> private hashedtoken readresolve ( ) { <nl> this . init ( ) ; <nl> return this ;
the software . <nl> < parent > <nl> < groupid > org . jenkins - ci < / groupid > <nl> < artifactid > jenkins < / artifactid > <nl> - < version > 1 . 46 < / version > <nl> + < version > 1 . 48 - 20180730 . 183534 - 1 < / version > < ! - - <nl> < relativepath / > <nl> < / parent >
<nl> + package hudson ; <nl> + <nl> + import hudson . model . updatecenter ; <nl> + import jenkins . model . jenkins ; <nl> + import org . junit . rule ; <nl> + import org . junit . test ; <nl> + import org . jvnet . hudson . test . issue ; <nl> + import org . jvnet . hudson . test . jenkinsrule ; <nl> + <nl> + import javax . servlet . http . httpservletresponse ; <nl> + import java . util . arrays ; <nl> + import java . util . list ; <nl> + import java . util . concurrent . future ; <nl> + <nl> + <nl> + public class plugintest_sec925 { <nl> + <nl> + @ rule <nl> + public jenkinsrule r = new jenkinsrule ( ) ; <nl> + <nl> + @ test <nl> + @ issue ( " security - 925 " ) <nl> + public void preventtimestamp2_tobeserved ( ) throws exception { <nl> + / / impossible to use installdetachedplugin ( " credentials " ) since we want to have it exploded like with war <nl> + jenkins . getinstance ( ) . getupdatecenter ( ) . getsites ( ) . get ( 0 ) . updatedirectlynow ( false ) ; <nl> + list < future < updatecenter . updatecenterjob > > plugininstalled = r . jenkins . pluginmanager . install ( arrays . aslist ( " credentials " ) , true ) ; <nl> + <nl> + for ( future < updatecenter . updatecenterjob > job : plugininstalled ) { <nl> + job . get ( ) ; <nl> + } <nl> + r . createwebclient ( ) . assertfails ( " plugin / credentials / . timestamp2 " , httpservletresponse . sc_bad_request ) ; <nl> + } <nl> + }
<nl> + package hudson . model ; <nl> + <nl> + import com . gargoylesoftware . htmlunit . httpmethod ; <nl> + import com . gargoylesoftware . htmlunit . page ; <nl> + import com . gargoylesoftware . htmlunit . webrequest ; <nl> + import hudson . model . cause . useridcause ; <nl> + import hudson . slaves . nodeprovisionerrule ; <nl> + import jenkins . model . jenkins ; <nl> + import org . junit . rule ; <nl> + import org . junit . test ; <nl> + import org . jvnet . hudson . test . jenkinsrule ; <nl> + import org . jvnet . hudson . test . mockauthorizationstrategy ; <nl> + <nl> + import java . net . url ; <nl> + import java . util . function . function ; <nl> + <nl> + import static org . hamcrest . matchers . equalto ; <nl> + import static org . hamcrest . matchers . lessthan ; <nl> + import static org . junit . assert . assertfalse ; <nl> + import static org . junit . assert . assertthat ; <nl> + import static org . junit . assert . asserttrue ; <nl> + <nl> + <nl> + public class queuetest_sec891 { <nl> + <nl> + @ rule <nl> + public jenkinsrule r = new nodeprovisionerrule ( - 1 , num , num ) ; <nl> + <nl> + @ test public void docancelitem_permissionischecked ( ) throws exception { <nl> + checkcanceloperationusingurl ( item - > " queue / cancelitem ? id = " + item . getid ( ) ) ; <nl> + } <nl> + <nl> + @ test public void docancelqueue_permissionischecked ( ) throws exception { <nl> + checkcanceloperationusingurl ( item - > " queue / item / " + item . getid ( ) + " / cancelqueue " ) ; <nl> + } <nl> + <nl> + private void checkcanceloperationusingurl ( function < queue . item , string > urlprovider ) throws exception { <nl> + queue q = r . jenkins . getqueue ( ) ; <nl> + <nl> + r . jenkins . setcrumbissuer ( null ) ; <nl> + r . jenkins . setsecurityrealm ( r . createdummysecurityrealm ( ) ) ; <nl> + r . jenkins . setauthorizationstrategy ( new mockauthorizationstrategy ( ) <nl> + . grant ( jenkins . read , item . cancel ) . everywhere ( ) . to ( " admin " ) <nl> + . grant ( jenkins . read ) . everywhere ( ) . to ( " user " ) <nl> + ) ; <nl> + <nl> + / / prevent execution to push stuff into the queue <nl> + r . jenkins . setnumexecutors ( 0 ) ; <nl> + assertthat ( q . getitems ( ) . length , equalto ( 0 ) ) ; <nl> + <nl> + freestyleproject testproject = r . createfreestyleproject ( " test " ) ; <nl> + testproject . schedulebuild ( new useridcause ( ) ) ; <nl> + <nl> + queue . item [ ] items = q . getitems ( ) ; <nl> + assertthat ( items . length , equalto ( 1 ) ) ; <nl> + queue . item currentone = items [ 0 ] ; <nl> + assertfalse ( currentone . getfuture ( ) . iscancelled ( ) ) ; <nl> + <nl> + webrequest request = new webrequest ( new url ( r . geturl ( ) + urlprovider . apply ( currentone ) ) , httpmethod . post ) ; <nl> + <nl> + { / / user without right cannot cancel <nl> + jenkinsrule . webclient wc = r . createwebclient ( ) ; <nl> + wc . getoptions ( ) . setthrowexceptiononfailingstatuscode ( false ) ; <nl> + wc . getoptions ( ) . setredirectenabled ( false ) ; <nl> + wc . login ( " user " ) ; <nl> + page p = wc . getpage ( request ) ; <nl> + / / currently the endpoint return a redirection to the previously visited page , none in our case <nl> + / / ( so force no redirect to avoid false positive error ) <nl> + assertthat ( p . getwebresponse ( ) . getstatuscode ( ) , lessthan ( 400 ) ) ; <nl> + <nl> + assertfalse ( currentone . getfuture ( ) . iscancelled ( ) ) ; <nl> + } <nl> + { / / user with right can <nl> + jenkinsrule . webclient wc = r . createwebclient ( ) ; <nl> + wc . getoptions ( ) . setthrowexceptiononfailingstatuscode ( false ) ; <nl> + wc . getoptions ( ) . setredirectenabled ( false ) ; <nl> + wc . login ( " admin " ) ; <nl> + page p = wc . getpage ( request ) ; <nl> + assertthat ( p . getwebresponse ( ) . getstatuscode ( ) , lessthan ( 400 ) ) ; <nl> + <nl> + asserttrue ( currentone . getfuture ( ) . iscancelled ( ) ) ; <nl> + } <nl> + } <nl> + }
public class workspacecleanupthread extends asyncperiodicwork { <nl> } <nl> } <nl>  <nl> + <nl> + if ( item instanceof job < ? , ? > ) { <nl> + job < ? , ? > j = ( job < ? , ? > ) item ; <nl> + if ( j . isbuilding ( ) ) { <nl> + logger . log ( level . fine , " job { 0 } is building , so not deleting " , item . getfulldisplayname ( ) ) ; <nl> + return false ; <nl> + } <nl> + } <nl> + <nl> logger . log ( level . finer , " going to delete directory { 0 } " , dir ) ; <nl> return true ; <nl> }
public class classfilterimpl extends classfilter { <nl> for ( customclassfilter f : extensionlist . lookup ( customclassfilter . class ) ) { <nl> boolean r = f . permits ( name ) ; <nl> if ( r ! = null ) { <nl> - logger . log ( level . finer , " { 0 } specifies a policy for { 1 } : { 2 } " , new object [ ] { f , name , r } ) ; <nl> + if ( r ) { <nl> + logger . log ( level . finer , " { 0 } specifies a policy for { 1 } : { 2 } " , new object [ ] { f , name , r } ) ; <nl> + } else { <nl> + notifyrejected ( null , name , <nl> + string . format ( " % s specifies a policy for % s : % s " , f , name , r ) ) ; <nl> + } <nl> + <nl> return ! r ; <nl> } <nl> } <nl> / / could apply a cache if the pattern search turns out to be slow <nl> if ( classfilter . standard . isblacklisted ( name ) ) { <nl> if ( suppress_all ) { <nl> - logger . log ( level . warning , " would normally reject { 0 } according to standard blacklist ; see https : / / jenkins . io / redirect / class - filter / " , name ) ; <nl> + notifyrejected ( null , name , <nl> + string . format ( " would normally reject % s according to standard blacklist ; see https : / / jenkins . io / redirect / class - filter / " , name ) ) ; <nl> return false ; <nl> } <nl> - logger . log ( level . warning , " rejecting { 0 } according to standard blacklist ; see https : / / jenkins . io / redirect / class - filter / " , name ) ; <nl> + notifyrejected ( null , name , <nl> + string . format ( " rejecting % s according to standard blacklist ; see https : / / jenkins . io / redirect / class - filter / " , name ) ) ; <nl> return true ; <nl> } else { <nl> return false ; <nl> } <nl> } <nl>  <nl> + private void notifyrejected ( @ checkfornull class < ? > clazz , @ checkfornull string clazzname , string message ) { <nl> + throwable cause = null ; <nl> + if ( logger . isloggable ( level . fine ) ) { <nl> + cause = new securityexception ( " class rejected by the class filter : " + <nl> + ( clazz ! = null ? clazz . getname ( ) : clazzname ) ) ; <nl> + } <nl> + logger . log ( level . warning , message , cause ) ; <nl> + <nl> + <nl> + } <nl> }
public class classfilterimpl extends classfilter { <nl> for ( customclassfilter f : extensionlist . lookup ( customclassfilter . class ) ) { <nl> boolean r = f . permits ( name ) ; <nl> if ( r ! = null ) { <nl> - logger . log ( level . finer , " { 0 } specifies a policy for { 1 } : { 2 } " , new object [ ] { f , name , r } ) ; <nl> + if ( r ) { <nl> + logger . log ( level . finer , " { 0 } specifies a policy for { 1 } : { 2 } " , new object [ ] { f , name , r } ) ; <nl> + } else { <nl> + notifyrejected ( null , name , <nl> + string . format ( " % s specifies a policy for % s : % s " , f , name , r ) ) ; <nl> + } <nl> + <nl> return ! r ; <nl> } <nl> } <nl> / / could apply a cache if the pattern search turns out to be slow <nl> if ( classfilter . standard . isblacklisted ( name ) ) { <nl> if ( suppress_all ) { <nl> - logger . log ( level . warning , " would normally reject { 0 } according to standard blacklist ; see https : / / jenkins . io / redirect / class - filter / " , name ) ; <nl> + notifyrejected ( null , name , <nl> + string . format ( " would normally reject % s according to standard blacklist ; see https : / / jenkins . io / redirect / class - filter / " , name ) ) ; <nl> return false ; <nl> } <nl> - logger . log ( level . warning , " rejecting { 0 } according to standard blacklist ; see https : / / jenkins . io / redirect / class - filter / " , name ) ; <nl> + notifyrejected ( null , name , <nl> + string . format ( " rejecting % s according to standard blacklist ; see https : / / jenkins . io / redirect / class - filter / " , name ) ) ; <nl> return true ; <nl> } else { <nl> return false ; <nl> } <nl> } <nl>  <nl> + private void notifyrejected ( @ checkfornull class < ? > clazz , @ checkfornull string clazzname , string message ) { <nl> + throwable cause = null ; <nl> + if ( logger . isloggable ( level . fine ) ) { <nl> + cause = new securityexception ( " class rejected by the class filter : " + <nl> + ( clazz ! = null ? clazz . getname ( ) : clazzname ) ) ; <nl> + } <nl> + logger . log ( level . warning , message , cause ) ; <nl> + <nl> + <nl> + } <nl> }
public class workspacecleanupthread extends asyncperiodicwork { <nl> } <nl> } <nl>  <nl> + <nl> + if ( item instanceof job < ? , ? > ) { <nl> + job < ? , ? > j = ( job < ? , ? > ) item ; <nl> + if ( j . isbuilding ( ) ) { <nl> + logger . log ( level . fine , " job { 0 } is building , so not deleting " , item . getfulldisplayname ( ) ) ; <nl> + return false ; <nl> + } <nl> + } <nl> + <nl> logger . log ( level . finer , " going to delete directory { 0 } " , dir ) ; <nl> return true ; <nl> }
the software . <nl> < parent > <nl> < groupid > org . jenkins - ci < / groupid > <nl> < artifactid > jenkins < / artifactid > <nl> - < version > 1 . 44 < / version > <nl> + < version > 1 . 46 - 20180514 . 183442 - 1 < / version > < ! - - <nl> < relativepath / > <nl> < / parent >
the software . <nl> < parent > <nl> < groupid > org . jenkins - ci < / groupid > <nl> < artifactid > jenkins < / artifactid > <nl> - < version > 1 . 44 < / version > <nl> + < version > 1 . 45 - 20180509 . 203006 - 1 < / version > < ! - - <nl> < relativepath / > <nl> < / parent > <nl>  <nl>
the software . <nl> < matrix - project . version > 1 . 4 . 1 < / matrix - project . version > <nl> < sorcerer . version > 0 . 11 < / sorcerer . version > <nl> < animal . sniffer . skip > $ { skiptests } < / animal . sniffer . skip > <nl> - < access - modifier . version > 1 . 13 < / access - modifier . version > <nl> - < access - modifier - annotation . version > $ { access - modifier . version } < / access - modifier - annotation . version > < ! - - differing only where needed for timestamped snapshots - - > <nl> - < access - modifier - checker . version > $ { access - modifier . version } < / access - modifier - checker . version > <nl> + < access - modifier . version > 1 . 14 - snapshot < / access - modifier . version > < ! - - <nl> + < ! - - after release , would just be $ { access - modifier . version } : - - > <nl> + < access - modifier - annotation . version > 1 . 14 - 20180326 . 221427 - 2 < / access - modifier - annotation . version > <nl> + < access - modifier - checker . version > 1 . 14 - 20180326 . 221430 - 2 < / access - modifier - checker . version > <nl>  <nl> < java . level > 8 < / java . level >
the software . <nl> < remoting . version > 3 . 17 < / remoting . version > <nl> < remoting . minimum . supported . version > 2 . 60 < / remoting . minimum . supported . version > <nl>  <nl> + < ! - - <nl> < findbugs . effort > max < / findbugs . effort > <nl> < findbugs . threshold > high < / findbugs . threshold > <nl> < findbugs . excludefilterfile > . . / src / findbugs / findbugs - excludes . xml < / findbugs . excludefilterfile >
<nl> < name > jenkins cli < / name > <nl> < description > command line interface for jenkins < / description > <nl>  <nl> + < properties > <nl> + < ! - - <nl> + < findbugs . threshold > medium < / findbugs . threshold > <nl> + < / properties > <nl> + <nl> < dependencies > <nl> < dependency > <nl> < groupid > org . powermock < / groupid > <nl>
org . jruby . java . proxies . concretejavaproxy <nl> org . jvnet . hudson . memoryusage <nl> org . jvnet . localizer . localizable <nl> org . jvnet . localizer . resourcebundleholder <nl> + <nl> + # <nl> + org . owasp . dependencycheck . dependency . reference <nl> + org . owasp . dependencycheck . dependency . vulnerability <nl> + org . owasp . dependencycheck . dependency . vulnerablesoftware <nl> + <nl> sun . security . rsa . rsapublickeyimpl <nl> sun . security . x509 . x509key
public class xstream2 extends xstream { <nl> throw new conversionexception ( " refusing to unmarshal " + reader . getnodename ( ) + " for security reasons ; see https : / / jenkins . io / redirect / class - filter / " ) ; <nl> } <nl>  <nl> + / * * <nl> + private static final pattern jruby_proxy = pattern . compile ( " org [ . ] jruby [ . ] proxy [ . ] . + [ $ ] proxy \ \ d + " ) ; <nl> + <nl> @ override <nl> public boolean canconvert ( class type ) { <nl> if ( type = = null ) { <nl> return false ; <nl> } <nl> + string name = type . getname ( ) ; <nl> + if ( jruby_proxy . matcher ( name ) . matches ( ) ) { <nl> + return false ; <nl> + } <nl> / / claim we can convert all the scary stuff so we can throw exceptions when attempting to do so <nl> - return classfilter . default . isblacklisted ( type . getname ( ) ) | | classfilter . default . isblacklisted ( type ) ; <nl> + return classfilter . default . isblacklisted ( name ) | | classfilter . default . isblacklisted ( type ) ; <nl> } <nl> } <nl> } <nl> mmm a / core / src / main / java / jenkins / security / customclassfilter . java <nl> ppp b / core / src / main / java / jenkins / security / customclassfilter . java <nl>
org . jboss . marshalling . traceinformation $ objectinfo <nl> org . jenkinsci . lib . xtrigger . xtriggercause <nl> org . jenkinsci . lib . xtrigger . xtriggercauseaction <nl>  <nl> + # <nl> + org . jruby . rubyarray <nl> + org . jruby . rubybignum <nl> + org . jruby . rubyboolean <nl> + org . jruby . rubyfixnum <nl> + org . jruby . rubyhash <nl> + org . jruby . rubyobject <nl> + org . jruby . rubystring <nl> + org . jruby . rubysymbol <nl> + org . jruby . java . proxies . concretejavaproxy <nl> + <nl> org . jvnet . hudson . memoryusage <nl> org . jvnet . localizer . localizable <nl> org . jvnet . localizer . resourcebundleholder
org . eclipse . jgit . transport . uriish <nl> org . jboss . marshalling . traceinformation $ fieldinfo <nl> org . jboss . marshalling . traceinformation $ objectinfo <nl>  <nl> + # <nl> + org . jenkinsci . lib . xtrigger . xtriggercause <nl> + org . jenkinsci . lib . xtrigger . xtriggercauseaction <nl> + <nl> org . jvnet . hudson . memoryusage <nl> org . jvnet . localizer . localizable <nl> org . jvnet . localizer . resourcebundleholder
public abstract class pluginmanager extends abstractmodelobject implements onmas <nl> ( ( uberclassloader ) uberclassloader ) . loaded . clear ( ) ; <nl> } <nl>  <nl> + <nl> + customclassfilter . contributed . load ( ) ; <nl> + <nl> try { <nl> p . resolveplugindependencies ( ) ; <nl> strategy . load ( p ) ; <nl> mmm a / core / src / main / java / jenkins / security / customclassfilter . java <nl> ppp b / core / src / main / java / jenkins / security / customclassfilter . java <nl>
public class setupwizardtest { <nl> wc . assertfails ( " setupwizard / createadminuser " , num ) ; <nl> wc . assertfails ( " setupwizard / completeinstall " , num ) ; <nl> } <nl> - <nl> + <nl> + <nl> @ test <nl> @ issue ( " jenkins - 45841 " ) <nl> + @ ignore <nl> public void shoulddisableunencryptedprotocolsbydefault ( ) throws exception { <nl> agentprotocoltest . assertprotocols ( j . jenkins , true , <nl> " encrypted jnlp4 - protocols protocol should be enabled " , " jnlp4 - connect " ) ; <nl> agentprotocoltest . assertprotocols ( j . jenkins , false , <nl> " non - encrypted jnlp protocols should be disabled by default " , <nl> " jnlp - connect " , " jnlp2 - connect " , " cli - connect " ) ; <nl> - agentprotocoltest . assertmonitornotactive ( ) ; <nl> + / / the ci test fails here , presumably due to the cli protocols . <nl> + agentprotocoltest . assertmonitornotactive ( j ) ; <nl> } <nl>  <nl> private string jsonrequest ( jenkinsrule . webclient wc , string path ) throws exception {
import java . util . logging . level ; <nl> import java . util . logging . logrecord ; <nl> import java . util . logging . logger ; <nl>  <nl> + <nl> + <nl> / * * <nl> * { @ link tasklistener } which sends messages to a { @ link logger } . <nl> * / <nl> - public class logtasklistener implements tasklistener , closeable { <nl> + public class logtasklistener extends abstracttasklistener implements tasklistener , closeable { <nl>  <nl> / / would be simpler to delegate to the logoutputstream but this would incompatibly change the serial form <nl> private final tasklistener delegate ; <nl> mmm a / core / src / main / java / hudson / util / streamtasklistener . java <nl> ppp b / core / src / main / java / hudson / util / streamtasklistener . java <nl>
import java . util . logging . level ; <nl> import java . util . logging . logger ; <nl> import org . kohsuke . stapler . framework . io . writeroutputstream ; <nl>  <nl> + <nl> + <nl> / * * <nl> * { @ link tasklistener } that generates output into a single stream . <nl> * <nl>
the software . <nl> < dependency > <nl> < groupid > $ { project . groupid } < / groupid > <nl> < artifactid > jenkins - test - harness < / artifactid > <nl> - < version > 2 . 28 < / version > <nl> + < version > 2 . 31 - 20171011 . 213336 - 1 < / version > < ! - - <nl> < scope > test < / scope > <nl> < exclusions > <nl> < exclusion > <nl>
public class queuetest { <nl> assertequals ( " aws - linux - dummy " , matrixproject . getbuilds ( ) . getlastbuild ( ) . getbuilton ( ) . getlabelstring ( ) ) ; <nl> } <nl>  <nl> + @ ignore ( " <nl> + @ issue ( " jenkins - 30084 " ) <nl> @ test <nl> public void shouldbeabletoblockflyweighttaskatthelastminute ( ) throws exception { <nl> matrixproject matrixproject = r . jenkins . createproject ( matrixproject . class , " downstream " ) ; <nl>
public class agentprotocoltest { <nl>  <nl> @ rule <nl> public jenkinsrule j = new jenkinsrule ( ) ; <nl> - <nl> + <nl> + <nl> / * * <nl> * checks that jenkins does not disable agent protocols by default after the upgrade . <nl> * <nl>
<nl> + / * <nl> + * the mit license <nl> + * <nl> + * copyright num cloudbees , inc . <nl> + * <nl> + * permission is hereby granted , free of charge , to any person obtaining a copy <nl> + * of this software and associated documentation files ( the " software " ) , to deal <nl> + * in the software without restriction , including without limitation the rights <nl> + * to use , copy , modify , merge , publish , distribute , sublicense , and / or sell <nl> + * copies of the software , and to permit persons to whom the software is <nl> + * furnished to do so , subject to the following conditions : <nl> + * <nl> + * the above copyright notice and this permission notice shall be included in <nl> + * all copies or substantial portions of the software . <nl> + * <nl> + * the software is provided " as is " , without warranty of any kind , express or <nl> + * implied , including but not limited to the warranties of merchantability , <nl> + * fitness for a particular purpose and noninfringement . in no event shall the <nl> + * authors or copyright holders be liable for any claim , damages or other <nl> + * liability , whether in an action of contract , tort or otherwise , arising from , <nl> + * out of or in connection with the software or the use or other dealings in <nl> + * the software . <nl> + * / <nl> + <nl> + package jenkins ; <nl> + <nl> + import com . google . common . collect . iterators ; <nl> + import java . io . file ; <nl> + import java . util . arraylist ; <nl> + import java . util . list ; <nl> + import java . util . map ; <nl> + import java . util . treemap ; <nl> + import java . util . jar . jarfile ; <nl> + import org . junit . ignore ; <nl> + import org . junit . rule ; <nl> + import org . junit . test ; <nl> + import org . junit . rules . errorcollector ; <nl> + import org . jvnet . hudson . test . issue ; <nl> + import org . jvnet . hudson . test . warexploder ; <nl> + <nl> + public class classpathtest { <nl> + <nl> + @ rule <nl> + public errorcollector errors = new errorcollector ( ) ; <nl> + <nl> + @ ignore ( " <nl> + @ issue ( " jenkins - 46754 " ) <nl> + @ test <nl> + public void uniqueness ( ) throws exception { <nl> + map < string , list < string > > entries = new treemap < > ( ) ; <nl> + for ( file jar : new file ( warexploder . getexplodeddir ( ) , " web - inf / lib " ) . listfiles ( ( dir , name ) - > name . endswith ( " . jar " ) ) ) { <nl> + string jarname = jar . getname ( ) ; <nl> + try ( jarfile jf = new jarfile ( jar ) ) { <nl> + iterators . forenumeration ( jf . entries ( ) ) . foreachremaining ( e - > { <nl> + string name = e . getname ( ) ; <nl> + if ( name . startswith ( " meta - inf / " ) | | name . endswith ( " / " ) | | ! name . contains ( " / " ) ) { <nl> + return ; <nl> + } <nl> + entries . computeifabsent ( name , k - > new arraylist < > ( ) ) . add ( jarname ) ; <nl> + } ) ; <nl> + } <nl> + } <nl> + entries . foreach ( ( name , jarnames ) - > { <nl> + if ( jarnames . size ( ) > num ) { / / matchers . hassize unfortunately does not display the collection <nl> + errors . adderror ( new assertionerror ( name + " duplicated in " + jarnames ) ) ; <nl> + } <nl> + } ) ; <nl> + } <nl> + <nl> + }
<nl> + / * <nl> + * the mit license <nl> + * <nl> + * copyright num cloudbees , inc . <nl> + * <nl> + * permission is hereby granted , free of charge , to any person obtaining a copy <nl> + * of this software and associated documentation files ( the " software " ) , to deal <nl> + * in the software without restriction , including without limitation the rights <nl> + * to use , copy , modify , merge , publish , distribute , sublicense , and / or sell <nl> + * copies of the software , and to permit persons to whom the software is <nl> + * furnished to do so , subject to the following conditions : <nl> + * <nl> + * the above copyright notice and this permission notice shall be included in <nl> + * all copies or substantial portions of the software . <nl> + * <nl> + * the software is provided " as is " , without warranty of any kind , express or <nl> + * implied , including but not limited to the warranties of merchantability , <nl> + * fitness for a particular purpose and noninfringement . in no event shall the <nl> + * authors or copyright holders be liable for any claim , damages or other <nl> + * liability , whether in an action of contract , tort or otherwise , arising from , <nl> + * out of or in connection with the software or the use or other dealings in <nl> + * the software . <nl> + * / <nl> + <nl> + package jenkins ; <nl> + <nl> + import com . google . common . collect . iterators ; <nl> + import java . io . file ; <nl> + import java . util . arraylist ; <nl> + import java . util . list ; <nl> + import java . util . map ; <nl> + import java . util . treemap ; <nl> + import java . util . jar . jarfile ; <nl> + import org . junit . ignore ; <nl> + import org . junit . rule ; <nl> + import org . junit . test ; <nl> + import org . junit . rules . errorcollector ; <nl> + import org . jvnet . hudson . test . issue ; <nl> + import org . jvnet . hudson . test . warexploder ; <nl> + <nl> + public class classpathtest { <nl> + <nl> + @ rule <nl> + public errorcollector errors = new errorcollector ( ) ; <nl> + <nl> + @ ignore ( " <nl> + @ issue ( " jenkins - 46754 " ) <nl> + @ test <nl> + public void uniqueness ( ) throws exception { <nl> + map < string , list < string > > entries = new treemap < > ( ) ; <nl> + for ( file jar : new file ( warexploder . getexplodeddir ( ) , " web - inf / lib " ) . listfiles ( ( dir , name ) - > name . endswith ( " . jar " ) ) ) { <nl> + string jarname = jar . getname ( ) ; <nl> + try ( jarfile jf = new jarfile ( jar ) ) { <nl> + iterators . forenumeration ( jf . entries ( ) ) . foreachremaining ( e - > { <nl> + string name = e . getname ( ) ; <nl> + if ( name . startswith ( " meta - inf / " ) | | name . endswith ( " / " ) | | ! name . contains ( " / " ) ) { <nl> + return ; <nl> + } <nl> + entries . computeifabsent ( name , k - > new arraylist < > ( ) ) . add ( jarname ) ; <nl> + } ) ; <nl> + } <nl> + } <nl> + entries . foreach ( ( name , jarnames ) - > { <nl> + if ( jarnames . size ( ) > num ) { / / matchers . hassize unfortunately does not display the collection <nl> + errors . adderror ( new assertionerror ( name + " duplicated in " + jarnames ) ) ; <nl> + } <nl> + } ) ; <nl> + } <nl> + <nl> + }
the software . <nl> < dependency > <nl> < groupid > $ { project . groupid } < / groupid > <nl> < artifactid > jenkins - test - harness < / artifactid > <nl> - < version > 2 . 24 < / version > <nl> + < version > 2 . 26 - 20170913 . 084530 - 2 < / version > < ! - - <nl> < scope > test < / scope > <nl> < exclusions > <nl> < exclusion >
public class cliactiontest { <nl> / / - ssh mode does not pass client locale or encoding <nl> } <nl>  <nl> + @ ignore ( " <nl> @ issue ( " jenkins - 41745 " ) <nl> @ test <nl> public void interleavedstdio ( ) throws exception {
the software . <nl> < dependency > <nl> < groupid > $ { project . groupid } < / groupid > <nl> < artifactid > jenkins - test - harness < / artifactid > <nl> - < version > 2 . 20 < / version > <nl> + < version > 2 . 24 - 20170801 . 213935 - 3 < / version > < ! - - <nl> < scope > test < / scope > <nl> < exclusions > <nl> < exclusion > <nl> mmm a / test / src / test / java / hudson / model / userrestarttest . java <nl> ppp b / test / src / test / java / hudson / model / userrestarttest . java <nl>
public abstract class slave extends node implements serializable { <nl> * if there is no computer it will return a { @ link hudson . launcher . dummylauncher } , otherwise it <nl> * will return a { @ link hudson . launcher . remotelauncher } instead . <nl> * / <nl> + @ nonnull <nl> public launcher createlauncher ( tasklistener listener ) { <nl> slavecomputer c = getcomputer ( ) ; <nl> if ( c = = null ) { <nl> - listener . error ( " issue with creating launcher for agent " + name + " . " ) ; <nl> + listener . error ( " issue with creating launcher for agent " + name + " . computer has been disconnected " ) ; <nl> return new launcher . dummylauncher ( listener ) ; <nl> } else { <nl> - return new remotelauncher ( listener , c . getchannel ( ) , c . isunix ( ) ) . decoratefor ( this ) ; <nl> + <nl> + <nl> + / / ensure that the computer instance still points to this node <nl> + / / otherwise we may end up running the command on a wrong ( reconnected ) node instance . <nl> + slave node = c . getnode ( ) ; <nl> + if ( node ! = this ) { <nl> + string message = " issue with creating launcher for agent " + name + " . computer has been reconnected " ; <nl> + if ( logger . isloggable ( level . warning ) ) { <nl> + logger . log ( level . warning , message , new illegalstateexception ( " computer has been reconnected , this node instance cannot be used anymore " ) ) ; <nl> + } <nl> + return new launcher . dummylauncher ( listener ) ; <nl> + } <nl> + <nl> + / / remotelauncher requires an active channel instance to operate correctly <nl> + final channel channel = c . getchannel ( ) ; <nl> + if ( channel = = null ) { <nl> + reportlauncercreateerror ( " the agent has not been fully initialized yet " , <nl> + " no remoting channel to the agent or it has not been fully initialized yet " , listener ) ; <nl> + return new launcher . dummylauncher ( listener ) ; <nl> + } <nl> + if ( channel . isclosingorclosed ( ) ) { <nl> + reportlauncercreateerror ( " the agent is being disconnected " , <nl> + " remoting channel is either in the process of closing down or has closed down " , listener ) ; <nl> + return new launcher . dummylauncher ( listener ) ; <nl> + } <nl> + final boolean isunix = c . isunix ( ) ; <nl> + if ( isunix = = null ) { <nl> + / / isunix is always set when the channel is not null , so it should never happen <nl> + reportlauncercreateerror ( " the agent has not been fully initialized yet " , <nl> + " cannot determing if the agent is a unix one , the system status request has not completed yet . " + <nl> + " it is an invalid channel state , please report a bug to jenkins if you see it . " , <nl> + listener ) ; <nl> + return new launcher . dummylauncher ( listener ) ; <nl> + } <nl> + <nl> + return new remotelauncher ( listener , channel , isunix ) . decoratefor ( this ) ; <nl> + } <nl> + } <nl> + <nl> + private void reportlauncercreateerror ( @ nonnull string humanreadablemsg , @ checkfornull string exceptiondetails , @ nonnull tasklistener listener ) { <nl> + string message = " issue with creating launcher for agent " + name + " . " + humanreadablemsg ; <nl> + listener . error ( message ) ; <nl> + if ( logger . isloggable ( level . warning ) ) { <nl> + / / send stacktrace to the log as well in order to diagnose the root cause of issues like jenkins - 38527 <nl> + logger . log ( level . warning , message <nl> + + " probably there is a race condition with agent reconnection or disconnection , check other log entries " , <nl> + new illegalstateexception ( exceptiondetails ! = null ? exceptiondetails : humanreadablemsg ) ) ; <nl> } <nl> }
public abstract class slave extends node implements serializable { <nl> * if there is no computer it will return a { @ link hudson . launcher . dummylauncher } , otherwise it <nl> * will return a { @ link hudson . launcher . remotelauncher } instead . <nl> * / <nl> + @ nonnull <nl> public launcher createlauncher ( tasklistener listener ) { <nl> slavecomputer c = getcomputer ( ) ; <nl> if ( c = = null ) { <nl> - listener . error ( " issue with creating launcher for agent " + name + " . " ) ; <nl> + listener . error ( " issue with creating launcher for agent " + name + " . computer has been disconnected " ) ; <nl> return new launcher . dummylauncher ( listener ) ; <nl> } else { <nl> - return new remotelauncher ( listener , c . getchannel ( ) , c . isunix ( ) ) . decoratefor ( this ) ; <nl> + <nl> + <nl> + / / ensure that the computer instance still points to this node <nl> + / / otherwise we may end up running the command on a wrong ( reconnected ) node instance . <nl> + slave node = c . getnode ( ) ; <nl> + if ( node ! = this ) { <nl> + string message = " issue with creating launcher for agent " + name + " . computer has been reconnected " ; <nl> + if ( logger . isloggable ( level . warning ) ) { <nl> + logger . log ( level . warning , message , new illegalstateexception ( " computer has been reconnected , this node instance cannot be used anymore " ) ) ; <nl> + } <nl> + return new launcher . dummylauncher ( listener ) ; <nl> + } <nl> + <nl> + / / remotelauncher requires an active channel instance to operate correctly <nl> + final channel channel = c . getchannel ( ) ; <nl> + if ( channel = = null ) { <nl> + reportlauncercreateerror ( " the agent has not been fully initialized yet " , <nl> + " no remoting channel to the agent or it has not been fully initialized yet " , listener ) ; <nl> + return new launcher . dummylauncher ( listener ) ; <nl> + } <nl> + if ( channel . isclosingorclosed ( ) ) { <nl> + reportlauncercreateerror ( " the agent is being disconnected " , <nl> + " remoting channel is either in the process of closing down or has closed down " , listener ) ; <nl> + return new launcher . dummylauncher ( listener ) ; <nl> + } <nl> + final boolean isunix = c . isunix ( ) ; <nl> + if ( isunix = = null ) { <nl> + / / isunix is always set when the channel is not null , so it should never happen <nl> + reportlauncercreateerror ( " the agent has not been fully initialized yet " , <nl> + " cannot determing if the agent is a unix one , the system status request has not completed yet . " + <nl> + " it is an invalid channel state , please report a bug to jenkins if you see it . " , <nl> + listener ) ; <nl> + return new launcher . dummylauncher ( listener ) ; <nl> + } <nl> + <nl> + return new remotelauncher ( listener , channel , isunix ) . decoratefor ( this ) ; <nl> + } <nl> + } <nl> + <nl> + private void reportlauncercreateerror ( @ nonnull string humanreadablemsg , @ checkfornull string exceptiondetails , @ nonnull tasklistener listener ) { <nl> + string message = " issue with creating launcher for agent " + name + " . " + humanreadablemsg ; <nl> + listener . error ( message ) ; <nl> + if ( logger . isloggable ( level . warning ) ) { <nl> + / / send stacktrace to the log as well in order to diagnose the root cause of issues like jenkins - 38527 <nl> + logger . log ( level . warning , message <nl> + + " probably there is a race condition with agent reconnection or disconnection , check other log entries " , <nl> + new illegalstateexception ( exceptiondetails ! = null ? exceptiondetails : humanreadablemsg ) ) ; <nl> } <nl> }
public class jenkins extends abstractcibase implements directlymodifiabletopleve <nl>  <nl>  <nl> if ( kill_after_load ) <nl> + <nl> system . exit ( 0 ) ; <nl>  <nl> setupwizard = new setupwizard ( ) ; <nl>
the software . <nl> < plugin > <nl> < groupid > org . jenkins - ci . tools < / groupid > <nl> < artifactid > maven - hpi - plugin < / artifactid > <nl> - < version > 1 . 122 < / version > <nl> + < version > 2 . 0 - 20170524 . 211828 - 1 < / version > < ! - - <nl> < / plugin > <nl> < plugin > <nl> < groupid > org . apache . maven . plugins < / groupid > <nl> mmm a / test / pom . xml <nl> ppp b / test / pom . xml <nl>
import java . util . concurrent . timeunit ; <nl> * had better conversion until java num went out . ) <nl> * / <nl> @ deprecated <nl> + @ restrictedsince ( " <nl> @ restricted ( donotuse . class ) <nl> public enum timeunit2 { <nl> nanoseconds { <nl> mmm a / pom . xml <nl> ppp b / pom . xml <nl>
import java . util . concurrent . future ; <nl> * the resource ( such as shutting down a virtual machine . ) { @ link computer } needs to own this handle information <nl> * because by the time this happens , a { @ link slave } object is already long gone . <nl> * <nl> + * < h3 > views < / h3 > <nl> + * <nl> + * since version <nl> + * to be presented at the top of the page or at the bottom respectively . in the middle , actions have their < tt > summary < / tt > <nl> + * views displayed . actions further contribute to < tt > sidepanel < / tt > with < tt > box < / tt > views . all mentioned views are <nl> + * optional to preserve backward compatibility . <nl> * <nl> * @ author kohsuke kawaguchi <nl> * @ see nodeprovisioner <nl>
public abstract class pluginmanager extends abstractmodelobject implements onmas <nl> installutil . savelastexecversion ( ) ; <nl> } else { <nl> final set < classicpluginstrategy . detachedplugin > forceupgrade = new hashset < > ( ) ; <nl> + <nl> for ( classicpluginstrategy . detachedplugin p : classicpluginstrategy . getdetachedplugins ( ) ) { <nl> versionnumber installedversion = getpluginversion ( rootdir , p . getshortname ( ) ) ; <nl> versionnumber requiredversion = p . getrequiredversion ( ) ; <nl> mmm a / test / src / test / groovy / hudson / model / abstractprojecttest . groovy <nl> ppp b / test / src / test / groovy / hudson / model / abstractprojecttest . groovy <nl>
public class myviewtest { <nl> itemtype . click ( ) ; <nl> rule . submit ( form ) ; <nl> item item = rule . jenkins . getitem ( " job " ) ; <nl> + assumethat ( " <nl> assertthat ( view . getitems ( ) , contains ( equalto ( item ) ) ) ; <nl> }
public class executables { <nl> try { <nl> return e . getestimatedduration ( ) ; <nl> } catch ( abstractmethoderror error ) { <nl> + <nl> return e . getparent ( ) . getestimatedduration ( ) ; <nl> } <nl> } <nl> mmm a / core / src / main / java / hudson / model / queue / workunit . java <nl> ppp b / core / src / main / java / hudson / model / queue / workunit . java <nl>
public class jenkins extends abstractcibase implements directlymodifiabletopleve <nl> / * * <nl> * do a finger - print check . <nl> * / <nl> + @ requirepost <nl> public void dodofingerprintcheck ( staplerrequest req , staplerresponse rsp ) throws ioexception , servletexception { <nl> / / parse the request <nl> multipartformdataparser p = new multipartformdataparser ( req ) ; <nl> if ( isusecrumbs ( ) & & ! getcrumbissuer ( ) . validatecrumb ( req , p ) ) { <nl> + <nl> rsp . senderror ( httpservletresponse . sc_forbidden , " no crumb found " ) ; <nl> } <nl> try {
public class apitokenpropertytest { <nl>  <nl> / / make sure that admin can reset a token of another user <nl> webclient wc = createclientforuser ( " bar " ) ; <nl> - htmlpage res = wc . goto ( foo . geturl ( ) + " / " + descriptor . getdescriptorurl ( ) + " / changetoken " ) ; <nl> + wc . getoptions ( ) . setthrowexceptiononfailingstatuscode ( false ) ; <nl> + htmlpage requirepost = wc . goto ( foo . geturl ( ) + " / " + descriptor . getdescriptorurl ( ) + " / changetoken " ) ; <nl> + assertequals ( " method should not be allowed " , num , requirepost . getwebresponse ( ) . getstatuscode ( ) ) ; <nl> + <nl> + wc . getoptions ( ) . setthrowexceptiononfailingstatuscode ( true ) ; <nl> + webrequest request = new webrequest ( new url ( j . geturl ( ) . tostring ( ) + foo . geturl ( ) + " / " + descriptor . getdescriptorurl ( ) + " / changetoken " ) , httpmethod . post ) ; <nl> + wc . addcrumb ( request ) ; <nl> + htmlpage res = wc . getpage ( request ) ; <nl> + <nl> + <nl> assertequals ( " update token response is incorrect " , <nl> messages . apitokenproperty_changetoken_successhidden ( ) , " < div > " + res . getbody ( ) . astext ( ) + " < / div > " ) ; <nl> }
public class jenkins extends abstractcibase implements directlymodifiabletopleve <nl>  <nl> adjuncts = new adjunctmanager ( servletcontext , pluginmanager . uberclassloader , " adjuncts / " + session_hash , timeunit2 . days . tomillis ( 365 ) ) ; <nl>  <nl> + classfilter . appenddefaultfilter ( pattern . compile ( " java [ . ] security [ . ] signedobject " ) ) ; <nl> + <nl> / / initialization consists of . . . <nl> executereactor ( is , <nl> pluginmanager . inittasks ( is ) , / / loading and preparing plugins <nl> mmm a / pom . xml <nl> ppp b / pom . xml <nl>
the software . <nl> < dependency > <nl> < groupid > org . jenkins - ci . main < / groupid > <nl> < artifactid > remoting < / artifactid > <nl> - < version > 2 . 53 . 5 < / version > <nl> + < version > 2 . 53 . 6 - 20170306 . 191805 - 1 < / version > < ! - - <nl> < / dependency > <nl>  <nl> < dependency > <nl> mmm a / test / src / test / java / jenkins / security / security218clitest . java <nl> ppp b / test / src / test / java / jenkins / security / security218clitest . java <nl>
public abstract class abstractproject < p extends abstractproject < p , r > , r extends a <nl> return collections . unmodifiablelist ( actions ) ; <nl> } <nl>  <nl> + <nl> + <nl> / * * <nl> * gets the { @ link node } where this project was last built on . <nl> * <nl> mmm a / core / src / main / java / hudson / model / computer . java <nl> ppp b / core / src / main / java / hudson / model / computer . java <nl>
public / * transient * / abstract class computer extends actionable implements acces <nl> return collections . unmodifiablelist ( result ) ; <nl> } <nl>  <nl> + @ suppresswarnings ( { " constantconditions " , " deprecation " } ) <nl> + @ suppressfbwarnings ( " rcn_redundant_nullcheck_of_nonnull_value " ) <nl> + @ override <nl> + public void addaction ( @ nonnull action a ) { <nl> + if ( a = = null ) { <nl> + throw new illegalargumentexception ( " action must be non - null " ) ; <nl> + } <nl> + super . getactions ( ) . add ( a ) ; <nl> + } <nl> + <nl> + <nl> + <nl> / * * <nl> * this is where the log from the remote agent goes . <nl> * the method also creates a log directory if required . <nl> mmm a / core / src / main / java / hudson / model / labels / labelatom . java <nl> ppp b / core / src / main / java / hudson / model / labels / labelatom . java <nl>
public class labelatom extends label implements saveable { <nl> return collections . unmodifiablelist ( actions ) ; <nl> } <nl>  <nl> + <nl> + <nl> protected void updatetransientactions ( ) { <nl> vector < action > ta = new vector < action > ( ) ; <nl>  <nl> mmm a / test / src / test / java / hudson / model / computertest . java <nl> ppp b / test / src / test / java / hudson / model / computertest . java <nl>
class plaincliprotocol { <nl> } <nl> } catch ( ioexception x ) { <nl> logger . log ( level . warning , null , flightrecorder . analyzecrash ( x , " broken stream " ) ) ; <nl> - } catch ( readpendingexception x ) { / / as above <nl> + } catch ( readpendingexception x ) { <nl> logger . log ( level . fine , null , x ) ; <nl> + <nl> handleclose ( ) ; <nl> } <nl> }
public class clitest { <nl> assertthat ( baos . tostring ( ) , containsstring ( " authenticated as : admin " ) ) ; <nl> } <nl>  <nl> + @ issue ( " jenkins - 41745 " ) <nl> + @ test <nl> + public void interrupt ( ) throws exception { <nl> + r . jenkins . setsecurityrealm ( r . createdummysecurityrealm ( ) ) ; <nl> + r . jenkins . setauthorizationstrategy ( new mockauthorizationstrategy ( ) . grant ( jenkins . administer ) . everywhere ( ) . to ( " admin " ) ) ; <nl> + sshd . get ( ) . setport ( 0 ) ; <nl> + file jar = tmp . newfile ( " jenkins - cli . jar " ) ; <nl> + fileutils . copyurltofile ( r . jenkins . getjnlpjars ( " jenkins - cli . jar " ) . geturl ( ) , jar ) ; <nl> + file privkey = tmp . newfile ( " id_rsa " ) ; <nl> + fileutils . copyurltofile ( clitest . class . getresource ( " id_rsa " ) , privkey ) ; <nl> + user . get ( " admin " ) . addproperty ( new userpropertyimpl ( ioutils . tostring ( clitest . class . getresource ( " id_rsa . pub " ) ) ) ) ; <nl> + freestyleproject p = r . createfreestyleproject ( " p " ) ; <nl> + p . getbuilderslist ( ) . add ( new sleepbuilder ( timeunit . minutes . tomillis ( 5 ) ) ) ; <nl> + dointerrupt ( jar , p , " - remoting " , " - i " , privkey . getabsolutepath ( ) ) ; <nl> + dointerrupt ( jar , p , " - ssh " , " - user " , " admin " , " - i " , privkey . getabsolutepath ( ) ) ; <nl> + / * <nl> + dointerrupt ( jar , p , " - http " , " - auth " , " admin : admin " ) ; <nl> + * / <nl> + } <nl> + private void dointerrupt ( file jar , freestyleproject p , string . . . modeargs ) throws exception { <nl> + bytearrayoutputstream baos = new bytearrayoutputstream ( ) ; <nl> + list < string > args = lists . newarraylist ( " java " , " - jar " , jar . getabsolutepath ( ) , " - s " , r . geturl ( ) . tostring ( ) ) ; <nl> + args . addall ( arrays . aslist ( modeargs ) ) ; <nl> + args . addall ( arrays . aslist ( " build " , " - s " , " - v " , " p " ) ) ; <nl> + proc proc = new launcher . locallauncher ( streamtasklistener . fromstderr ( ) ) . launch ( ) . cmds ( args ) . stdout ( new teeoutputstream ( baos , system . out ) ) . stderr ( system . err ) . start ( ) ; <nl> + while ( ! baos . tostring ( ) . contains ( " sleeping " ) ) { <nl> + thread . sleep ( 100 ) ; <nl> + } <nl> + system . err . println ( " killing client " ) ; <nl> + proc . kill ( ) ; <nl> + r . waitforcompletion ( p . getlastbuild ( ) ) ; <nl> + } <nl> + <nl> }
public abstract class abstractproject < p extends abstractproject < p , r > , r extends a <nl> return collections . unmodifiablelist ( actions ) ; <nl> } <nl>  <nl> + <nl> + <nl> / * * <nl> * gets the { @ link node } where this project was last built on . <nl> * <nl> mmm a / core / src / main / java / hudson / model / computer . java <nl> ppp b / core / src / main / java / hudson / model / computer . java <nl>
public / * transient * / abstract class computer extends actionable implements acces <nl> return collections . unmodifiablelist ( result ) ; <nl> } <nl>  <nl> + @ suppresswarnings ( { " constantconditions " , " deprecation " } ) <nl> + @ suppressfbwarnings ( " rcn_redundant_nullcheck_of_nonnull_value " ) <nl> + @ override <nl> + public void addaction ( @ nonnull action a ) { <nl> + if ( a = = null ) { <nl> + throw new illegalargumentexception ( " action must be non - null " ) ; <nl> + } <nl> + super . getactions ( ) . add ( a ) ; <nl> + } <nl> + <nl> + <nl> + <nl> / * * <nl> * this is where the log from the remote agent goes . <nl> * the method also creates a log directory if required . <nl> mmm a / core / src / main / java / hudson / model / labels / labelatom . java <nl> ppp b / core / src / main / java / hudson / model / labels / labelatom . java <nl>
public class labelatom extends label implements saveable { <nl> return collections . unmodifiablelist ( actions ) ; <nl> } <nl>  <nl> + <nl> + <nl> protected void updatetransientactions ( ) { <nl> vector < action > ta = new vector < action > ( ) ; <nl>  <nl> mmm a / test / src / test / java / hudson / model / computertest . java <nl> ppp b / test / src / test / java / hudson / model / computertest . java <nl>
public class cliactiontest { <nl> assertequals ( code , new launcher . locallauncher ( streamtasklistener . fromstderr ( ) ) . launch ( ) . cmds ( commands ) . stdout ( system . out ) . stderr ( system . err ) . join ( ) ) ; <nl> } <nl>  <nl> + @ issue ( " jenkins - 41745 " ) <nl> + @ test <nl> + public void encodingandlocale ( ) throws exception { <nl> + file jar = tmp . newfile ( " jenkins - cli . jar " ) ; <nl> + fileutils . copyurltofile ( j . jenkins . getjnlpjars ( " jenkins - cli . jar " ) . geturl ( ) , jar ) ; <nl> + bytearrayoutputstream baos = new bytearrayoutputstream ( ) ; <nl> + assertequals ( 0 , new launcher . locallauncher ( streamtasklistener . fromstderr ( ) ) . launch ( ) . cmds ( <nl> + " java " , " - dfile . encoding = iso - 8859 - 2 " , " - duser . language = cs " , " - duser . country = cz " , " - jar " , jar . getabsolutepath ( ) , " - s " , j . geturl ( ) . tostring ( ) , " - nokeyauth " , " test - diagnostic " ) . <nl> + stdout ( baos ) . stderr ( system . err ) . join ( ) ) ; <nl> + assertequals ( " encoding = iso - 8859 - 2 locale = cs_cz " , baos . tostring ( ) . trim ( ) ) ; <nl> + <nl> + } <nl> + <nl> + @ testextension ( " encodingandlocale " ) <nl> + public static class testdiagnosticcommand extends clicommand { <nl> + <nl> + @ override <nl> + public string getshortdescription ( ) { <nl> + return " print information about the command environment . " ; <nl> + } <nl> + <nl> + @ override <nl> + protected int run ( ) throws exception { <nl> + stdout . println ( " encoding = " + getclientcharset ( ) + " locale = " + locale ) ; <nl> + return num ; <nl> + } <nl> + <nl> + } <nl> + <nl> }
public class setupwizard extends pagedecorator { <nl> jenkins . getinjector ( ) . getinstance ( adminwhitelistrule . class ) <nl> . setmasterkillswitch ( false ) ; <nl>  <nl> - jenkins . save ( ) ; / / ! ! <nl> + jenkins . save ( ) ; <nl> bc . commit ( ) ; <nl> } <nl> }
public class consolecommand extends clicommand { <nl> do { <nl> logtext = run . getlogtext ( ) ; <nl> pos = logtext . writelogto ( pos , w ) ; <nl> + <nl> } while ( ! logtext . iscomplete ( ) ) ; <nl> } else { <nl> try ( inputstream loginputstream = run . getloginputstream ( ) ) {
the software . <nl> < dependency > <nl> < groupid > org . jenkins - ci . modules < / groupid > <nl> < artifactid > sshd < / artifactid > <nl> - < version > 1 . 9 < / version > <nl> + < version > 1 . 11 - 20170315 . 153852 - 1 < / version > < ! - - <nl> < / dependency > <nl> < dependency > <nl> < groupid > org . jenkins - ci . ui < / groupid >
public class reloadconfigurationcommandtest { <nl> @ rule public final jenkinsrule j = new jenkinsrule ( ) ; <nl>  <nl> @ before public void setup ( ) { <nl> - command = new clicommandinvoker ( j , " reload - configuration " ) ; <nl> + j . jenkins . setsecurityrealm ( j . createdummysecurityrealm ( ) ) ; <nl> + reloadconfigurationcommand cmd = new reloadconfigurationcommand ( ) ; <nl> + cmd . settransportauth ( user . get ( " user " ) . impersonate ( ) ) ; <nl> + command = new clicommandinvoker ( j , cmd ) ; <nl> + j . jenkins . setauthorizationstrategy ( new mockauthorizationstrategy ( ) . grant ( jenkins . administer ) . everywhere ( ) . toauthenticated ( ) ) ; <nl> } <nl>  <nl> @ test <nl> public void reloadconfigurationshouldfailwithoutadministerpermission ( ) throws exception { <nl> - final clicommandinvoker . result result = command <nl> - . authorizedto ( jenkins . read ) . invoke ( ) ; <nl> + j . jenkins . setauthorizationstrategy ( new mockauthorizationstrategy ( ) . grant ( jenkins . read ) . everywhere ( ) . toauthenticated ( ) ) ; <nl> + final clicommandinvoker . result result = command . invoke ( ) ; <nl>  <nl> assertthat ( result , failedwith ( 6 ) ) ; <nl> assertthat ( result , hasnostandardoutput ( ) ) ; <nl>
the software . <nl> < artifactid > jcifs < / artifactid > <nl> < version > 1 . 3 . 17 - kohsuke - 1 < / version > <nl> < / dependency > <nl> + < dependency > <nl> + < groupid > org . apache . sshd < / groupid > <nl> + < artifactid > sshd - core < / artifactid > <nl> + < version > 1 . 2 . 0 < / version > < ! - - <nl> + < / dependency > <nl> < / dependencies > <nl> < / dependencymanagement > <nl>  <nl> mmm a / test / pom . xml <nl> ppp b / test / pom . xml <nl>
public class cli implements autocloseable { <nl> public void run ( ) { <nl> try { <nl> int c ; <nl> - while ( ( c = system . in . read ( ) ) ! = - 1 ) { <nl> + while ( ( c = system . in . read ( ) ) ! = - 1 ) { <nl> stdin . write ( c ) ; <nl> } <nl> connection . sendendstdin ( ) ; <nl> mmm a / cli / src / test / java / hudson / cli / privatekeyprovidertest . java <nl> ppp b / cli / src / test / java / hudson / cli / privatekeyprovidertest . java <nl>
the software . <nl> ( the permission will be checked against the " it " object . ) <nl> < / st : attribute > <nl> < st : attribute name = " type " use = " optional " > <nl> - available values : two - column ( by default ) , one - column ( full - width size ) or full - screen . <nl> + available values : two - column ( by default ) , one - column ( full - width size ) or full - screen ( since <nl> < / st : attribute > <nl> < / st : documentation > <nl> < st : setheader name = " expires " value = " 0 " / >
properties ( [ [ $ class : ' jenkins . model . builddiscarderproperty ' , strategy : [ $ class : <nl> artifactnumtokeepstr : ' 20 ' ] ] ] ) <nl>  <nl> / / see https : / / github . com / jenkins - infra / documentation / blob / master / ci . adoc for information on what node types are available <nl> - def buildtypes = [ ' linux ' , ' windows ' ] <nl> + def buildtypes = [ ' linux ' ] <nl>  <nl> def builds = [ : ] <nl> for ( i = num ; i < buildtypes . size ( ) ; i + + ) {
public class historypagefiltertest { <nl> } <nl>  <nl> @ test <nl> + public void test_search_should_be_case_sensitive_for_anonymous_user ( ) throws ioexception { <nl> + / / given <nl> + historypagefilter < modelobject > historypagefilter = newpage ( 5 , null , null ) ; <nl> + / / and <nl> + historypagefilter . setsearchstring ( " failure " ) ; <nl> + / / and <nl> + list < modelobject > runs = lists . < modelobject > newarraylist ( new mockrun ( 2 , result . failure ) , new mockrun ( 1 , result . success ) ) ; <nl> + list < queue . item > queueitems = newqueueitems ( 3 , num ) ; <nl> + <nl> + / / when <nl> + historypagefilter . add ( runs , queueitems ) ; <nl> + <nl> + / / then <nl> + assert . assertequals ( 0 , historypagefilter . runs . size ( ) ) ; <nl> + } <nl> + <nl> + @ test <nl> + @ ignore / / user with insensitivesearch enabled needs to be injected <nl> public void test_search_runs_by_build_result ( ) throws ioexception { <nl> / / given <nl> + <nl> historypagefilter < modelobject > historypagefilter = newpage ( 5 , null , null ) ; <nl> / / and <nl> historypagefilter . setsearchstring ( " failure " ) ; <nl>
public class historypagefiltertest { <nl> } <nl>  <nl> @ test <nl> + @ ignore / / user with insensitivesearch enabled needs to be injected <nl> public void test_case_insensitivity_in_search_runs ( ) throws ioexception { <nl> / / given <nl> + <nl> historypagefilter < modelobject > historypagefilter = newpage ( 5 , null , null ) ; <nl> list < modelobject > runs = lists . < modelobject > newarraylist ( new mockrun ( 2 , result . failure ) , new mockrun ( 1 , result . success ) ) ; <nl> list < queue . item > queueitems = newqueueitems ( 3 , num ) ;
public abstract class consolenote < t > implements serializable , describable < consol <nl> dataoutputstream dos = new dataoutputstream ( new base64outputstream ( buf2 , true , - 1 , null ) ) ; <nl> try { <nl> buf2 . write ( preamble ) ; <nl> - byte [ ] mac = mac . mac ( buf . tobytearray ( ) ) ; <nl> - dos . writeint ( - mac . length ) ; / / negative to differentiate from older form <nl> - dos . write ( mac ) ; <nl> + if ( jenkins . getinstance ( ) ! = null ) { <nl> + byte [ ] mac = mac . mac ( buf . tobytearray ( ) ) ; <nl> + dos . writeint ( - mac . length ) ; / / negative to differentiate from older form <nl> + dos . write ( mac ) ; <nl> + } <nl> dos . writeint ( buf . size ( ) ) ; <nl> buf . writeto ( dos ) ; <nl> } finally {
public class user extends abstractmodelobject implements accesscontrolled , descr <nl> * <nl> * security - 406 . <nl> * / <nl> + <nl> @ restricted ( noexternaluse . class ) <nl> public static boolean allow_user_creation_via_url = boolean . getboolean ( user . class . getname ( ) + " . allowusercreationviaurl " ) ; <nl> } <nl> mmm a / core / src / main / java / jenkins / model / jenkins . java <nl> ppp b / core / src / main / java / jenkins / model / jenkins . java <nl>
public class user extends abstractmodelobject implements accesscontrolled , descr <nl> * jenkins - 22346 . <nl> * / <nl> public static boolean allow_non_existent_user_to_login = boolean . getboolean ( user . class . getname ( ) + " . allownonexistentusertologin " ) ; <nl> + <nl> + <nl> + / * * <nl> + * jenkins historically created a ( usually ) ephemeral user record when an user with overall / administer permission <nl> + * accesses a / user / arbitraryname url . <nl> + * < p > <nl> + * unfortunately this constitutes a csrf vulnerability , as malicious users can make admins create arbitrary numbers <nl> + * of ephemeral user records , so the behavior was changed in jenkins num . <nl> + * < p > <nl> + * as some users may be relying on the previous behavior , setting this to true restores the previous behavior . this <nl> + * is not recommended . <nl> + * <nl> + * security - 406 . <nl> + * / <nl> + @ restricted ( noexternaluse . class ) <nl> + public static boolean allow_user_creation_via_url = boolean . getboolean ( user . class . getname ( ) + " . allowusercreationviaurl " ) ; <nl> } <nl>  <nl> mmm a / core / src / main / java / jenkins / model / jenkins . java <nl> ppp b / core / src / main / java / jenkins / model / jenkins . java <nl>
import jenkins . security . hmacconfidentialkey ; <nl> public abstract class consolenote < t > implements serializable , describable < consolenote < ? > > , extensionpoint { <nl>  <nl> private static final hmacconfidentialkey mac = new hmacconfidentialkey ( consolenote . class , " mac " ) ; <nl> + / * * <nl> + * allows historical build records with unsigned console notes to be displayed , at the expense of any security . <nl> + * disables checking of { @ link # mac } so do not set this flag unless you completely trust all users capable of affecting build output , <nl> + * which in practice means that all scm committers as well as all jenkins users with any non - read - only access are consider administrators . <nl> + * / <nl> + static / * nonfinal for tests & script console * / boolean lenient_mac = boolean . getboolean ( consolenote . class . getname ( ) + " . lenient_mac " ) ; <nl>  <nl> / * * <nl> * when the line of a console output that this annotation is attached is read by someone , <nl>
import org . jenkinsci . remoting . protocol . cert . publickeymatchingx509extendedtrustma <nl> * <nl> * < p > @ see { @ link org . jenkinsci . remoting . engine . jnlpprotocol4handler } for more details . <nl> * <nl> - * @ since num . 27 <nl> + * @ since num . 27 available as the experimental protocol <nl> + * @ since <nl> * / <nl> @ extension <nl> public class jnlpslaveagentprotocol4 extends agentprotocol { <nl>
public class parameterstest { <nl> final htmlform form = page . getformbyname ( " parameters " ) ; <nl> htmlformutil . submit ( form , htmlformutil . getbuttonbycaption ( form , " build " ) ) ; <nl> } <nl> + <nl> + @ ignore ( " <nl> + @ issue ( " security - 353 " ) <nl> + @ test <nl> + public void xss ( ) throws exception { <nl> + freestyleproject p = j . createfreestyleproject ( " p " ) ; <nl> + p . addproperty ( new parametersdefinitionproperty ( new stringparameterdefinition ( " < param name > " , " < param default > " , " < param description > " ) ) ) ; <nl> + webclient wc = j . createwebclient ( ) ; <nl> + wc . getoptions ( ) . setthrowexceptiononfailingstatuscode ( false ) ; <nl> + htmlpage page = wc . getpage ( p , " build ? delay = 0sec " ) ; <nl> + collector . checkthat ( page . getwebresponse ( ) . getstatuscode ( ) , is ( httpstatus . sc_method_not_allowed ) ) ; / / num to dissuade scripts from thinking this triggered the build <nl> + string text = page . getwebresponse ( ) . getcontentasstring ( ) ; <nl> + collector . checkthat ( text , containsstring ( " & lt ; param name & gt ; " ) ) ; <nl> + collector . checkthat ( text , not ( containsstring ( " < param name > " ) ) ) ; <nl> + collector . checkthat ( text , containsstring ( " & lt ; param default & gt ; " ) ) ; <nl> + collector . checkthat ( text , not ( containsstring ( " < param default > " ) ) ) ; <nl> + collector . checkthat ( text , containsstring ( " & lt ; param description & gt ; " ) ) ; <nl> + collector . checkthat ( text , not ( containsstring ( " < param description > " ) ) ) ; <nl> + htmlform form = page . getformbyname ( " parameters " ) ; <nl> + htmltextinput value = form . getinputbyvalue ( " < param default > " ) ; <nl> + value . settext ( " < param value > " ) ; <nl> + j . submit ( form ) ; <nl> + j . waituntilnoactivity ( ) ; <nl> + freestylebuild b = p . getbuildbynumber ( 1 ) ; <nl> + page = j . createwebclient ( ) . getpage ( b , " parameters / " ) ; <nl> + text = page . getwebresponse ( ) . getcontentasstring ( ) ; <nl> + collector . checkthat ( text , containsstring ( " & lt ; param name & gt ; " ) ) ; <nl> + collector . checkthat ( text , not ( containsstring ( " < param name > " ) ) ) ; <nl> + collector . checkthat ( text , containsstring ( " & lt ; param value & gt ; " ) ) ; <nl> + collector . checkthat ( text , not ( containsstring ( " < param value > " ) ) ) ; <nl> + collector . checkthat ( text , containsstring ( " & lt ; param description & gt ; " ) ) ; <nl> + collector . checkthat ( text , not ( containsstring ( " < param description > " ) ) ) ; <nl> + } <nl> + <nl> }
public class queue extends resourcecontroller implements saveable { <nl> p . task . getfulldisplayname ( ) ) ; <nl> p . ispending = false ; <nl> pendings . remove ( p ) ; <nl> - makebuildable ( p ) ; <nl> + makebuildable ( p ) ; <nl> } <nl> }
public class user extends abstractmodelobject implements accesscontrolled , descr <nl> public contextmenu docontextmenu ( staplerrequest request , staplerresponse response ) throws exception { <nl> return new contextmenu ( ) . from ( this , request , response ) ; <nl> } <nl> + <nl> + / * * <nl> + * gets list of illegal usernames , for which users should not be created . <nl> + * always includes users from { @ link # illegal_persisted_usernames } <nl> + * @ return list of usernames <nl> + * / <nl> + @ restricted ( noexternaluse . class ) <nl> + / * package * / static set < string > getillegalpersistedusernames ( ) { <nl> + <nl> + final set < string > res = new hashset < > ( ) ; <nl> + res . addall ( arrays . aslist ( illegal_persisted_usernames ) ) ; <nl> + return res ; <nl> + } <nl>  <nl> public static abstract class canonicalidresolver extends abstractdescribableimpl < canonicalidresolver > implements extensionpoint , comparable < canonicalidresolver > { <nl>  <nl> mmm a / core / src / test / java / hudson / model / usertest . java <nl> ppp b / core / src / test / java / hudson / model / usertest . java <nl>
the software . <nl> < stapler . version > 1 . 243 < / stapler . version > <nl> < spring . version > 2 . 5 . 6 . sec03 < / spring . version > <nl> < groovy . version > 2 . 4 . 7 < / groovy . version > <nl> - < ! - - currently there is a huge number of errors = > we cannot fix all of them immediately - - > <nl> - < findbugs . failonerror > false < / findbugs . failonerror > <nl> + < ! - - <nl> + < findbugs . failonerror > true < / findbugs . failonerror > <nl> < / properties > <nl>  <nl> < dependencies >
public abstract class tooldescriptor < t extends toolinstallation > extends descrip <nl> class t = types . erasure ( pt . getactualtypearguments ( ) [ 0 ] ) ; <nl> return ( t [ ] ) array . newinstance ( t , 0 ) ; <nl> } else { <nl> - / / can ' t infer the type . fallacbk <nl> - return ( t [ ] ) new object [ 0 ] ; <nl> + / / can ' t infer the type . fallback <nl> + return emptyarray_unsafecast ( ) ; <nl> } <nl> } <nl> + <nl> + <nl> + @ suppresswarnings ( " unchecked " ) <nl> + @ suppressfbwarnings ( value = " bc_impossible_downcast " , <nl> + justification = " such casting is generally unsafe , but we use it as a last resort . " ) <nl> + private t [ ] emptyarray_unsafecast ( ) { <nl> + return ( t [ ] ) new object [ 0 ] ; <nl> + } <nl>  <nl> / * * <nl> * overwrites { @ link toolinstallation } s .
public class climanagerimpl implements clientrypoint , serializable { <nl>  <nl> private authentication transportauth ; <nl>  <nl> + <nl> / * * <nl> * runs callable from this cli client with the transport authentication credential . <nl> * / <nl> - private final callablefilter authenticationfilter = new callablefilter ( ) { <nl> + private transient final callablefilter authenticationfilter = new callablefilter ( ) { <nl> public < v > v call ( callable < v > callable ) throws exception { <nl> securitycontext context = securitycontextholder . getcontext ( ) ; <nl> authentication old = context . getauthentication ( ) ;
<nl> + package jenkins . model . identity ; <nl> + <nl> + import com . gargoylesoftware . htmlunit . html . htmlpage ; <nl> + import hudson . extensionlist ; <nl> + import hudson . model . unprotectedrootaction ; <nl> + import java . security . keypair ; <nl> + import java . security . keypairgenerator ; <nl> + import java . security . nosuchalgorithmexception ; <nl> + import java . security . cert . x509certificate ; <nl> + import java . security . interfaces . rsaprivatekey ; <nl> + import java . security . interfaces . rsapublickey ; <nl> + import java . security . spec . invalidkeyspecexception ; <nl> + import javax . annotation . nullable ; <nl> + import org . junit . rule ; <nl> + import org . junit . test ; <nl> + import org . jvnet . hudson . test . jenkinsrule ; <nl> + import org . jvnet . hudson . test . testextension ; <nl> + <nl> + import static org . hamcrest . matchers . containsstring ; <nl> + import static org . junit . assert . assertthat ; <nl> + <nl> + public class identityrootactiontest { <nl> + <nl> + @ rule <nl> + public jenkinsrule r = new jenkinsrule ( ) ; <nl> + <nl> + @ test <nl> + public void ui ( ) throws exception { <nl> + htmlpage p = r . createwebclient ( ) . goto ( " instance - identity " ) ; <nl> + assertthat ( p . getelementbyid ( " fingerprint " ) . gettextcontent ( ) , <nl> + containsstring ( extensionlist . lookup ( unprotectedrootaction . class ) . get ( identityrootaction . class ) . getfingerprint ( ) ) ) ; <nl> + } <nl> + <nl> + @ testextension <nl> + public static class providerimpl extends instanceidentityprovider < rsapublickey , rsaprivatekey > { <nl> + <nl> + private final keypair keypair ; <nl> + <nl> + public providerimpl ( ) throws nosuchalgorithmexception , invalidkeyspecexception { <nl> + keypairgenerator generator = keypairgenerator . getinstance ( " rsa " ) ; <nl> + generator . initialize ( 1024 ) ; <nl> + this . keypair = generator . generatekeypair ( ) ; <nl> + } <nl> + <nl> + @ nullable <nl> + @ override <nl> + public keypair getkeypair ( ) { <nl> + return keypair ; <nl> + } <nl> + <nl> + @ nullable <nl> + @ override <nl> + public x509certificate getcertificate ( ) { <nl> + return null ; <nl> + } <nl> + } <nl> + }
<nl> + package hudson ; <nl> + <nl> + import com . gargoylesoftware . htmlunit . failinghttpstatuscodeexception ; <nl> + import com . gargoylesoftware . htmlunit . page ; <nl> + import com . gargoylesoftware . htmlunit . html . htmlpage ; <nl> + import hudson . remoting . base64 ; <nl> + import java . security . keyfactory ; <nl> + import java . security . keypair ; <nl> + import java . security . keypairgenerator ; <nl> + import java . security . nosuchalgorithmexception ; <nl> + import java . security . cert . x509certificate ; <nl> + import java . security . interfaces . rsaprivatekey ; <nl> + import java . security . interfaces . rsapublickey ; <nl> + import java . security . spec . invalidkeyspecexception ; <nl> + import java . security . spec . pkcs8encodedkeyspec ; <nl> + import javax . annotation . nullable ; <nl> + import jenkins . model . identity . instanceidentityprovider ; <nl> + import org . junit . rule ; <nl> + import org . junit . test ; <nl> + import org . jvnet . hudson . test . jenkinsrule ; <nl> + import org . jvnet . hudson . test . testextension ; <nl> + <nl> + import static org . hamcrest . matchers . is ; <nl> + import static org . hamcrest . matchers . notnullvalue ; <nl> + import static org . junit . assert . assertthat ; <nl> + import static org . junit . assert . fail ; <nl> + <nl> + public class tcpslaveagentlistenertest { <nl> + <nl> + @ rule <nl> + public jenkinsrule r = new jenkinsrule ( ) ; <nl> + <nl> + @ test <nl> + public void headers ( ) throws exception { <nl> + r . getinstance ( ) . setslaveagentport ( - 1 ) ; <nl> + try { <nl> + r . createwebclient ( ) . goto ( " tcpslaveagentlistener " ) ; <nl> + fail ( " should get num " ) ; <nl> + } catch ( failinghttpstatuscodeexception e ) { <nl> + assertthat ( e . getstatuscode ( ) , is ( 404 ) ) ; <nl> + } <nl> + r . getinstance ( ) . setslaveagentport ( 0 ) ; <nl> + page p = r . createwebclient ( ) . goto ( " tcpslaveagentlistener " , " text / plain " ) ; <nl> + assertthat ( p . getwebresponse ( ) . getresponseheadervalue ( " x - instance - identity " ) , notnullvalue ( ) ) ; <nl> + } <nl> + <nl> + @ testextension <nl> + public static class providerimpl extends instanceidentityprovider < rsapublickey , rsaprivatekey > { <nl> + <nl> + private final keypair keypair ; <nl> + <nl> + public providerimpl ( ) throws nosuchalgorithmexception , invalidkeyspecexception { <nl> + keypairgenerator generator = keypairgenerator . getinstance ( " rsa " ) ; <nl> + generator . initialize ( 1024 ) ; <nl> + this . keypair = generator . generatekeypair ( ) ; <nl> + } <nl> + <nl> + @ nullable <nl> + @ override <nl> + public keypair getkeypair ( ) { <nl> + return keypair ; <nl> + } <nl> + <nl> + @ nullable <nl> + @ override <nl> + public x509certificate getcertificate ( ) { <nl> + return null ; <nl> + } <nl> + } <nl> + }
the software . <nl> < enabled > true < / enabled > <nl> < / releases > <nl> < snapshots > <nl> - < enabled > false < / enabled > <nl> + < enabled > true < / enabled > < ! - - <nl> < / snapshots > <nl> < / repository > <nl> < / repositories >
public class classicpluginstrategy implements pluginstrategy { <nl> new detachedplugin ( " windows - slaves " , " 1 . 547 . * " , " 1 . 0 " ) , <nl> new detachedplugin ( " antisamy - markup - formatter " , " 1 . 553 . * " , " 1 . 0 " ) , <nl> new detachedplugin ( " matrix - project " , " 1 . 561 . * " , " 1 . 0 " ) , <nl> - new detachedplugin ( " junit " , " 1 . 577 . * " , " 1 . 0 " ) <nl> + new detachedplugin ( " junit " , " 1 . 577 . * " , " 1 . 0 " ) , <nl> + new detachedplugin ( " bouncycastle - api " , " 2 . 16 . * " , " 2 . 16 . 0 - snapshot " ) <nl> ) ) ; <nl>  <nl> / * * implicit dependencies that are known to be unnecessary and which must be cut out to prevent a dependency cycle among bundled plugins . * / <nl> mmm a / war / pom . xml <nl> ppp b / war / pom . xml <nl>
the software . <nl> < version > 1 . 2 - beta - 4 < / version > <nl> < type > hpi < / type > <nl> < / artifactitem > <nl> + < artifactitem > <nl> + < groupid > org . jenkins - ci . plugins < / groupid > <nl> + < artifactid > bouncycastle - api < / artifactid > <nl> + < version > 2 . 16 . 0 - snapshot < / version > < ! - - <nl> + < type > hpi < / type > <nl> + < / artifactitem > <nl> < / artifactitems > <nl> < outputdirectory > $ { project . build . directory } / $ { project . build . finalname } / web - inf / detached - plugins < / outputdirectory > <nl> < stripversion > true < / stripversion >
the software . <nl> < dependency > <nl> < groupid > org . jenkins - ci . modules < / groupid > <nl> < artifactid > instance - identity < / artifactid > <nl> - < version > 1 . 5 . 1 < / version > <nl> + < version > 2 . 0 < / version > <nl> + < / dependency > <nl> + < dependency > <nl> + < ! - - <nl> + < groupid > org . bouncycastle < / groupid > <nl> + < artifactid > bcpkix - jdk15on < / artifactid > <nl> + < version > 1 . 54 < / version > <nl> < / dependency > <nl> < dependency > <nl> < groupid > org . jenkins - ci . modules < / groupid >
public class chartutil { <nl> @ deprecated <nl> public static boolean awtproblem = false ; <nl>  <nl> + <nl> / * * <nl> * see issue num . detect an error in x11 and handle it gracefully . <nl> * / <nl> + @ suppressfbwarnings ( value = " ms_should_be_refactored_to_be_final " , <nl> + justification = " it ' s actually being widely used by plugins . " <nl> + + " obsolete approach , should be ideally replaced by getter " ) <nl> public static throwable awtproblemcause = null ; <nl>  <nl> / * *
public abstract class pluginmanager extends abstractmodelobject implements onmas <nl> return loadpluginsfromwar ( frompath , null ) ; <nl> } <nl>  <nl> + <nl> + @ suppressfbwarnings ( value = " dmi_collection_of_urls " , justification = " plugin loading happens only once on jenkins startup " ) <nl> protected @ nonnull set < string > loadpluginsfromwar ( @ nonnull string frompath , @ checkfornull filenamefilter filter ) { <nl> set < string > names = new hashset ( ) ; <nl>  <nl>
public abstract class pluginmanager extends abstractmodelobject implements onmas <nl> return names ; <nl> } <nl>  <nl> + <nl> + @ suppressfbwarnings ( value = " dmi_collection_of_urls " , justification = " plugin loading happens only once on jenkins startup " ) <nl> protected static void adddependencies ( url hpiresurl , string frompath , set < url > dependencyset ) throws urisyntaxexception , malformedurlexception { <nl> if ( dependencyset . contains ( hpiresurl ) ) { <nl> return ;
public class user extends abstractmodelobject implements accesscontrolled , descr <nl> * prevent anyone from logging in as these users . therefore , we prevent <nl> * saving a user with one of these ids . <nl> * <nl> - * @ return true if the username or fullname is valid <nl> + * @ param id id to be checked <nl> + * @ return { @ code true } if the username or fullname is valid . <nl> + * for { @ code null } or blank ids returns { @ code false } . <nl> * @ since num . 600 <nl> * / <nl> - public static boolean isidorfullnameallowed ( string id ) { <nl> + public static boolean isidorfullnameallowed ( @ checkfornull string id ) { <nl> + <nl> + if ( id = = null | | stringutils . isblank ( id ) ) { <nl> + return false ; <nl> + } <nl> for ( string invalidid : illegal_persisted_usernames ) { <nl> if ( id . equalsignorecase ( invalidid ) ) <nl> return false ; <nl> mmm / dev / null <nl> ppp b / core / src / test / java / hudson / model / usertest . java <nl>
upcoming changes < / a > <nl> < ! - - record your changes in the trunk here . - - > <nl> < div id = " trunk " style = " display : none " > < ! - - = trunk - begin = - - > <nl> < ul class = image > <nl> - < li class = > <nl> + < li class = " major rfe " > <nl> + adapt the setup wizard gui to provide a similar user experience when upgrading jenkins . <nl> + ( < a href = " https : / / issues . jenkins - ci . org / browse / jenkins - 33663 " > issue num < / a > ) <nl> + < ! - - <nl> + < li class = " rfe " > <nl> + improve extensibility of the setup wizard gui : <nl> + < code > installstate < / code > and < code > installstatefilter < / code > extension points . <nl> + ( < a href = " https : / / github . com / jenkinsci / jenkins / pull / 2281 " > pr num < / a > as supplimentary change for <nl> + < a href = " https : / / issues . jenkins - ci . org / browse / jenkins - 33663 " > issue num < / a > ) <nl> + < li class = " rfe " > <nl> + improve user experience in the new item form . submit button is always visible . <nl> + ( < a href = " https : / / issues . jenkins - ci . org / browse / jenkins - 34244 " > issue num < / a > ) <nl> + < li class = " rfe " > <nl> + allow passing a list of safe job parameters in < code > parametersaction < / code > . <nl> + it simplifies fixing of < a href = " https : / / wiki . jenkins - ci . org / display / jenkins / plugins + affected + by + fix + for + security - 170 " > plugins affected by security - 170 fix < / a > . <nl> + ( < a href = " https : / / github . com / jenkinsci / jenkins / pull / 2353 " > pr num < / a > ) <nl> + < li class = " rfe " > <nl> + added symbol annotations for <nl> + < code > parametersdefinition < / code > and < code > builddiscarder / code > properties . <nl> + ( < a href = " https : / / github . com / jenkinsci / jenkins / pull / 2358 " > pr num < / a > ) <nl> + < li class = " rfe " > <nl> + extended the < code > online - node < / code > cli command for accepting multiple agents . <nl> + ( < a href = " https : / / issues . jenkins - ci . org / browse / jenkins - 34531 " > issue num < / a > ) <nl> + < li class = " bug " > <nl> + listed parameters should reflect what was used when the build ran ( filtering of unsafe parameters ) . <nl> + ( < a href = " https : / / issues . jenkins - ci . org / browse / jenkins - 34858 " > issue num < / a > ) <nl> + < li class = " bug " > <nl> + scalability : fix performance issues in the xml unmarshalling code . <nl> + ( < a href = " https : / / issues . jenkins - ci . org / browse / jenkins - 34888 " > issue num < / a > ) <nl> + < li class = " bug " > <nl> + support the legacy icon size specification approach in the status ball visualization . <nl> + ( < a href = " https : / / issues . jenkins - ci . org / browse / jenkins - 25220 " > issue num < / a > , regression in num . 586 ) <nl> + < li class = " bug " > <nl> + migrate the leftover system properties to the new engine introduced in num . 4 . <nl> + ( < a href = " https : / / issues . jenkins - ci . org / browse / jenkins - 34854 " > issue num < / a > ) <nl> + < li class = " bug " > <nl> + do not show warnings abot a missing tool installer if it is present in at least one update site . <nl> + ( < a href = " https : / / issues . jenkins - ci . org / browse / jenkins - 34880 " > issue num < / a > ) <nl> + < li class = " rfe " > <nl> + internal : cli command < code > connect - node < / code > was extracted from the core to cli . <nl> + ( < a href = " https : / / issues . jenkins - ci . org / browse / jenkins - 31417 " > issue num < / a > ) <nl> < / ul > <nl> < / div > < ! - - = trunk - end = - - > <nl> < h3 > < a name = v2 . 5 > what ' s new in num . 5 < / a > ( 2016 / 05 / 16 ) < / h3 >
public class updatecenter extends abstractmodelobject implements saveable , onmas <nl>  <nl> / * * <nl> * { @ linkplain updatesite # getid ( ) id } of the default update site . <nl> - * @ since num . 483 <nl> + * @ since num . 483 - public property <nl> + * @ since <nl> * / <nl> - public static final string id_default = " default " ; <nl> + public static final string id_default = system . getproperty ( updatecenter . class . getname ( ) + " . defaultupdatesiteid " , " default " ) ; <nl>  <nl> @ restricted ( noexternaluse . class ) <nl> public static final string id_upload = " _upload " ; <nl> mmm a / war / src / main / js / pluginsetupwizardgui . js <nl> ppp b / war / src / main / js / pluginsetupwizardgui . js <nl>
public class util { <nl> * the same algorithm can be seen in { @ link uri } , but <nl> * implementing this by ourselves allow it to be more lenient about <nl> * escaping of uri . <nl> + * <nl> + * @ deprecated use { @ code isabsoluteorschemerelativeuri } instead if your goal is to prevent open redirects <nl> * / <nl> + @ deprecated <nl> + @ restrictedsince ( " 1 . 651 . 2 / num . <nl> + @ restricted ( noexternaluse . class ) <nl> public static boolean isabsoluteuri ( @ nonnull string uri ) { <nl> int idx = uri . indexof ( ' : ' ) ; <nl> if ( idx < 0 ) return false ; / / no ' : ' . can ' t be absolute <nl>
import org . kohsuke . accmod . restrictions . noexternaluse ; <nl> @ extension ( ordinal = - 100 ) <nl> public class nestedprojectscategory extends itemcategory { <nl>  <nl> - public static final string id = " nestedprojects " ; <nl> + / * * <nl> + * <nl> + * / <nl> + private static final string id = " nestedprojects " ; <nl>  <nl> @ override <nl> public string getid ( ) {
<nl> < div > <nl> - this controls the disk consumption of jenkins by managing how long you ' d like to keep <nl> - records of the builds ( such as console output , build artifacts , and so on . ) <nl> - jenkins offers two criteria : <nl> - <nl> + this determines when , if ever , build records for this project should be <nl> + discarded . build records include the console output , archived artifacts , and <nl> + any other metadata related to a particular build . <nl> + < p > <nl> + keeping fewer builds means less disk space will be used in the < i > build record <nl> + root directory < / i > , which is specified on the < i > configure system < / i > screen . <nl> + < p > <nl> + < ! - - <nl> + ` builddiscarder ` implementations that are currently loaded - - > <nl> + jenkins offers two options for determining when builds should be discarded : <nl> < ol > <nl> < li > <nl> - driven by age . you can have jenkins delete a record if it reaches a certain age <nl> - ( for example , num days old . ) <nl> + build age : discard builds if they reach a certain age ; for example , seven <nl> + days old . <nl> < li > <nl> - driven by number . you can have jenkins make sure that it only maintains up to <nl> - n build records . if a new build is started , the oldest record will <nl> - be simply removed . <nl> + build count : discard the oldest build if a certain number of builds <nl> + already exist . <nl> < / ol > <nl> + these two options can be active at the same time , so you can keep builds for <nl> + num days , but only up to a limit of num builds , for example . if either limit is <nl> + exceeded , then any builds beyond that limit will be discarded . <nl> + < p > <nl> + you can also ensure that important builds are kept forever , regardless of the <nl> + setting here & mdash ; click the < i > keep this build forever < / i > button on the <nl> + build page . <nl> + < br > <nl> + the last stable and last successful build are also excluded from these rules . <nl> + <nl> + < hr > <nl> + <nl> + in the < i > advanced < / i > section , the same options can be specified , but <nl> + specifically for build < b > artifacts < / b > . if enabled , build artifacts will be <nl> + discarded for any builds which exceed the defined limits . the builds <nl> + themselves will still be kept ; only the associated artifacts , if any , will be <nl> + deleted . <nl> + < p > <nl> + for example , if a project builds some software and produces a large installer , <nl> + which is archived , you may wish to always keep the console log and information <nl> + about which source control commit was built . while for disk space reasons , <nl> + you may want to keep only the last three installers that were built . <nl> + < br > <nl> + this can make sense for projects where you can easily recreate the same <nl> + artifacts later by building the same source control commit again . <nl> + <nl> + < hr > <nl>  <nl> - jenkins also allows you to mark an individual build as ' keep this log forever ' , to <nl> - exclude certain important builds from being discarded automatically . <nl> - the last stable and last successful build are always kept as well . <nl> - < / div > <nl> \ no newline at end of file <nl> + for time - based limits , note that jenkins does not discard items as soon as <nl> + the configured time is exceeded ; these rules are evaluated the next time that <nl> + a build of this project starts . <nl> + < / div > <nl> mmm a / core / src / main / resources / jenkins / model / messages . properties <nl> ppp b / core / src / main / resources / jenkins / model / messages . properties <nl>
public abstract class scmlistener implements extensionpoint { <nl> @ suppresswarnings ( " deprecation " ) <nl> public static collection < ? extends scmlistener > all ( ) { <nl> jenkins j = jenkins . getinstanceornull ( ) ; <nl> - if ( j = = null ) { <nl> + if ( j = = null ) { <nl> return collections . emptyset ( ) ; <nl> } <nl> list < scmlistener > r = new arraylist < scmlistener > ( j . getextensionlist ( scmlistener . class ) ) ; <nl>
public abstract class runlistener < r extends run > implements extensionpoint { <nl> * fires the { @ link # onfinalized ( run ) } event . <nl> * / <nl> public static void firefinalized ( run r ) { <nl> - if ( jenkins . getinstanceornull ( ) = = null ) { <nl> + if ( jenkins . getinstanceornull ( ) = = null ) { <nl> return ; <nl> } <nl> for ( runlistener l : all ( ) ) {
public class usagestatistics extends pagedecorator { <nl> * returns true if it ' s time for us to check for new version . <nl> * / <nl> public boolean isdue ( ) { <nl> - final jenkins j = jenkins . getinstanceornull ( ) ; <nl> + final jenkins j = jenkins . getinstanceornull ( ) ; <nl> / / user opted out or jenkins not fully initialized . no data collection . <nl> if ( j = = null | | j . isusagestatisticscollected ( ) | | disabled | | completed . compareto ( j . getinitlevel ( ) ) > num ) { <nl> return false ;
public class queue extends resourcecontroller implements saveable { <nl> * / <nl> public static void withlock ( runnable runnable ) { <nl> final jenkins jenkins = jenkins . getinstanceornull ( ) ; <nl> + <nl> final queue queue = jenkins = = null ? null : jenkins . getqueue ( ) ; <nl> if ( queue = = null ) { <nl> runnable . run ( ) ; <nl>
public class queue extends resourcecontroller implements saveable { <nl> * / <nl> public static < v , t extends throwable > v withlock ( hudson . remoting . callable < v , t > callable ) throws t { <nl> final jenkins jenkins = jenkins . getinstanceornull ( ) ; <nl> + <nl> final queue queue = jenkins = = null ? null : jenkins . getqueue ( ) ; <nl> if ( queue = = null ) { <nl> return callable . call ( ) ; <nl>
public class queue extends resourcecontroller implements saveable { <nl> * / <nl> public static < v > v withlock ( java . util . concurrent . callable < v > callable ) throws exception { <nl> final jenkins jenkins = jenkins . getinstanceornull ( ) ; <nl> + <nl> final queue queue = jenkins = = null ? null : jenkins . getqueue ( ) ; <nl> if ( queue = = null ) { <nl> return callable . call ( ) ; <nl>
public class queue extends resourcecontroller implements saveable { <nl> * / <nl> public static boolean trywithlock ( runnable runnable ) { <nl> final jenkins jenkins = jenkins . getinstanceornull ( ) ; <nl> + <nl> final queue queue = jenkins = = null ? null : jenkins . getqueue ( ) ; <nl> if ( queue = = null ) { <nl> runnable . run ( ) ; <nl>
public class queue extends resourcecontroller implements saveable { <nl> * / <nl> public static runnable wrapwithlock ( runnable runnable ) { <nl> final jenkins jenkins = jenkins . getinstanceornull ( ) ; <nl> + <nl> final queue queue = jenkins = = null ? null : jenkins . getqueue ( ) ; <nl> return queue = = null ? runnable : new lockedrunnable ( runnable ) ; <nl> } <nl>
public class queue extends resourcecontroller implements saveable { <nl> * / <nl> public static < v , t extends throwable > hudson . remoting . callable < v , t > wrapwithlock ( hudson . remoting . callable < v , t > callable ) { <nl> final jenkins jenkins = jenkins . getinstanceornull ( ) ; <nl> + <nl> final queue queue = jenkins = = null ? null : jenkins . getqueue ( ) ; <nl> return queue = = null ? callable : new lockedhrcallable < > ( callable ) ; <nl> } <nl>
public class queue extends resourcecontroller implements saveable { <nl> * / <nl> public static < v > java . util . concurrent . callable < v > wrapwithlock ( java . util . concurrent . callable < v > callable ) { <nl> final jenkins jenkins = jenkins . getinstanceornull ( ) ; <nl> + <nl> final queue queue = jenkins = = null ? null : jenkins . getqueue ( ) ; <nl> return queue = = null ? callable : new lockedjuccallable < v > ( callable ) ; <nl> }
public class executor extends thread implements modelobject { <nl> * / <nl> @ checkfornull <nl> public static executor of ( executable executable ) { <nl> - jenkins jenkins = jenkins . getinstanceornull ( ) ; <nl> + jenkins jenkins = jenkins . getinstanceornull ( ) ; <nl> if ( jenkins = = null ) { <nl> return null ; <nl> }
public / * transient * / abstract class computer extends actionable implements acces <nl> * / <nl> @ checkfornull <nl> public node getnode ( ) { <nl> - jenkins j = jenkins . getinstanceornull ( ) ; <nl> + jenkins j = jenkins . getinstanceornull ( ) ; <nl> if ( j = = null ) { <nl> return null ; <nl> } <nl>
public / * transient * / abstract class computer extends actionable implements acces <nl> addnewexecutorifnecessary ( ) ; <nl> if ( ! isalive ( ) ) { <nl> abstractcibase cibase = jenkins . getinstanceornull ( ) ; <nl> - if ( cibase ! = null ) { <nl> + if ( cibase ! = null ) { <nl> cibase . removecomputer ( computer . this ) ; <nl> } <nl> }
public class solarissmflifecycle extends lifecycle { <nl> * / <nl> @ override <nl> public void restart ( ) throws ioexception , interruptedexception { <nl> - jenkins h = jenkins . getinstanceornull ( ) ; <nl> + jenkins h = jenkins . getinstanceornull ( ) ; <nl> if ( h ! = null ) <nl> h . cleanup ( ) ; <nl> system . exit ( 0 ) ; <nl> mmm a / core / src / main / java / hudson / lifecycle / unixlifecycle . java <nl> ppp b / core / src / main / java / hudson / lifecycle / unixlifecycle . java <nl>
public class unixlifecycle extends lifecycle { <nl>  <nl> @ override <nl> public void restart ( ) throws ioexception , interruptedexception { <nl> - jenkins h = jenkins . getinstanceornull ( ) ; <nl> + jenkins h = jenkins . getinstanceornull ( ) ; <nl> if ( h ! = null ) <nl> h . cleanup ( ) ;
public class olddatamonitor extends administrativemonitor { <nl> } <nl> if ( buf . length ( ) = = num ) return ; <nl> jenkins j = jenkins . getinstanceornull ( ) ; <nl> - if ( j = = null ) { <nl> + if ( j = = null ) { <nl> / / startup failed , something is very broken , so report what we can . <nl> for ( throwable t : errors ) { <nl> logger . log ( level . warning , " could not read " + obj + " ( and jenkins did not start up ) " , t ) ;
public class nodes implements saveable { <nl> jenkins . trimlabels ( ) ; <nl> } <nl> } ) ; <nl> + <nl> persistnode ( node ) ; <nl> } <nl> } <nl>
public class nodes implements saveable { <nl> exists = false ; <nl> } <nl> if ( exists ) { <nl> + <nl> persistnode ( node ) ; <nl> return true ; <nl> }
class cliactiontest { <nl> } <nl> } <nl>  <nl> + <nl> @ test <nl> @ presetdata ( dataset . no_anonymous_readaccess ) <nl> public void servecliactiontoanonymoususerwithoutpermissions ( ) throws exception { <nl> mmm a / test / src / test / java / hudson / cli / cliactiontest2 . java <nl> ppp b / test / src / test / java / hudson / cli / cliactiontest2 . java <nl>
public class jenkins extends abstractcibase implements directlymodifiabletopleve <nl> return nodes . getnodes ( ) ; <nl> } <nl>  <nl> + / * * <nl> + * get the { @ code nodes } object that handles maintaining { @ code node } s . <nl> + * @ return the nodes object . <nl> + * / <nl> + @ restricted ( noexternaluse . class ) <nl> + public nodes getnodesobject ( ) { <nl> + <nl> + return nodes ; <nl> + } <nl> + <nl> / * * <nl> * adds one more { @ link node } to jenkins . <nl> * /
<nl> + / * <nl> + * the mit license <nl> + * <nl> + * copyright ( c ) num cloudbees , inc . <nl> + * <nl> + * permission is hereby granted , free of charge , to any person obtaining a copy <nl> + * of this software and associated documentation files ( the " software " ) , to deal <nl> + * in the software without restriction , including without limitation the rights <nl> + * to use , copy , modify , merge , publish , distribute , sublicense , and / or sell <nl> + * copies of the software , and to permit persons to whom the software is <nl> + * furnished to do so , subject to the following conditions : <nl> + * <nl> + * the above copyright notice and this permission notice shall be included in <nl> + * all copies or substantial portions of the software . <nl> + * <nl> + * the software is provided " as is " , without warranty of any kind , express or <nl> + * implied , including but not limited to the warranties of merchantability , <nl> + * fitness for a particular purpose and noninfringement . in no event shall the <nl> + * authors or copyright holders be liable for any claim , damages or other <nl> + * liability , whether in an action of contract , tort or otherwise , arising from , <nl> + * out of or in connection with the software or the use or other dealings in <nl> + * the software . <nl> + * / <nl> + package hudson . model ; <nl> + <nl> + import java . net . malformedurlexception ; <nl> + import org . junit . rule ; <nl> + import org . junit . test ; <nl> + import org . jvnet . hudson . test . jenkinsrule ; <nl> + <nl> + import static org . junit . assert . * ; <nl> + import org . jvnet . hudson . test . bug ; <nl> + <nl> + / * * <nl> + * tests for the { @ link slave } class . <nl> + * there is also a groovy implementation of such test file , hence the class name <nl> + * has an index . <nl> + * @ author oleg nenashev <nl> + * / <nl> + public class slavetest2 { <nl> + <nl> + @ rule <nl> + public jenkinsrule rule = new jenkinsrule ( ) ; <nl> + <nl> + @ test <nl> + <nl> + public void shouldnotescapejnlpslavesresources ( ) throws exception { <nl> + slave slave = rule . createslave ( ) ; <nl> + <nl> + / / raw access to api <nl> + slave . jnlpjar jnlpjar = slave . getcomputer ( ) . getjnlpjars ( " . . / " ) ; <nl> + try { <nl> + jnlpjar . geturl ( ) ; <nl> + } catch ( malformedurlexception ex ) { <nl> + / / we expect the exception here <nl> + ex . printstacktrace ( ) ; <nl> + return ; <nl> + } <nl> + fail ( " expected the malformedurlexception " ) ; <nl> + <nl> + / / access from a web client <nl> + jenkinsrule . webclient client = rule . createwebclient ( ) ; <nl> + client . assertfails ( " jnlpjars / . . % f " , num ) ; <nl> + } <nl> + }
public class apitokenpropertytest { <nl> assertsame ( t , u . getproperty ( apitokenproperty . class ) ) ; <nl>  <nl> webclient wc = j . createwebclient ( ) ; <nl> - wc . setcredentialsprovider ( new credentialsprovider ( ) { <nl> - public credentials getcredentials ( authscheme scheme , string host , int port , boolean proxy ) throws credentialsnotavailableexception { <nl> - return new usernamepasswordcredentials ( " foo " , token ) ; <nl> - } <nl> - } ) ; <nl> - wc . setwebconnection ( new httpwebconnection ( wc ) { <nl> - @ override <nl> - protected httpclient gethttpclient ( ) { <nl> - httpclient c = super . gethttpclient ( ) ; <nl> - c . getparams ( ) . setauthenticationpreemptive ( true ) ; <nl> - c . getstate ( ) . setcredentials ( new authscope ( " localhost " , authscope . any_port , authscope . any_realm ) , new usernamepasswordcredentials ( " foo " , token ) ) ; <nl> - return c ; <nl> - } <nl> - } ) ; <nl> + wc . getcredentialsprovider ( ) . setcredentials ( <nl> + new authscope ( " localhost " , authscope . any_port ) , <nl> + new usernamepasswordcredentials ( " foo " , token ) <nl> + ) ; <nl> + <nl> + / / see http : / / stackoverflow . com / questions / 2014700 / preemptive - basic - authentication - with - apache - httpclient - 4 etc <nl> + / / wc . setwebconnection ( new httpwebconnection ( wc ) { <nl> + / / @ override <nl> + / / protected httpclient gethttpclient ( ) { <nl> + / / httpclient c = super . gethttpclient ( ) ; <nl> + / / c . getparams ( ) . setauthenticationpreemptive ( true ) ; <nl> + / / c . getstate ( ) . setcredentials ( new authscope ( " localhost " , authscope . any_port , authscope . any_realm ) , new usernamepasswordcredentials ( " foo " , token ) ) ; <nl> + / / return c ; <nl> + / / } <nl> + / / } ) ; <nl>  <nl> / / test the authentication <nl> assertequals ( u , wc . executeonserver ( new callable < user > ( ) {
public class jenkins extends abstractcibase implements directlymodifiabletopleve <nl> return nodes . getnodes ( ) ; <nl> } <nl>  <nl> + / * * <nl> + * get the { @ code nodes } object that handles maintaining { @ code node } s . <nl> + * @ return the nodes object . <nl> + * / <nl> + @ restricted ( noexternaluse . class ) <nl> + public nodes getnodesobject ( ) { <nl> + <nl> + return nodes ; <nl> + } <nl> + <nl> / * * <nl> * adds one more { @ link node } to jenkins . <nl> * /
public class commandlaunchertest { <nl>  <nl> public dumbslave createslave ( string command ) throws exception { <nl> dumbslave slave ; <nl> - synchronized ( j . jenkins ) { <nl> + synchronized ( j . jenkins ) { <nl> slave = new dumbslave ( <nl> " dummy " , <nl> " dummy " , <nl>
public class pluginautomatictestbuilder { <nl> * testoutputdirectory ( string ) : target / test - classes . <nl> * / <nl> public static testsuite build ( map < string , ? > params ) throws exception { <nl> - testsuite suite = new testsuite ( ) ; <nl> - <nl> / / automatic jelly tests <nl> if ( params . containskey ( " outputdirectory " ) / / shouldn ' t happen , but be defensive <nl> - | | notskiptests ( " jellytest " ) ) { <nl> + | | notskiptests ( " jellytest " ) ) { <nl> file outputdirectory = new file ( ( string ) params . get ( " outputdirectory " ) ) ; <nl> - suite . addtest ( jellytestsuitebuilder . build ( outputdirectory , toboolean ( params . get ( " requirepi " ) ) ) ) ; <nl> + testsuite suite = jellytestsuitebuilder . build ( outputdirectory , toboolean ( params . get ( " requirepi " ) ) ) ; <nl> + suite . addtest ( new othertests ( " testclisanity " ) ) ; <nl> + return suite ; <nl> + } else { <nl> + return new testsuite ( ) ; <nl> } <nl> - <nl> - suite . addtestsuite ( clisanitytest . class ) ; <nl> - <nl> - return suite ; <nl> } <nl>  <nl> private static boolean toboolean ( object requirepi ) { <nl>
public final class computerset extends abstractmodelobject implements describabl <nl>  <nl> jsonobject formdata = req . getsubmittedform ( ) ; <nl> formdata . put ( " name " , fixedname ) ; <nl> - <nl> + <nl> + <nl> node result = nodedescriptor . all ( ) . find ( type ) . newinstance ( req , formdata ) ; <nl> app . addnode ( result ) ; <nl>  <nl> mmm a / core / src / main / java / hudson / model / items . java <nl> ppp b / core / src / main / java / hudson / model / items . java <nl>
public class toollocationnodeproperty extends nodeproperty < node > { <nl> return home ; <nl> } <nl>  <nl> + @ suppresswarnings ( " deprecation " ) <nl> public tooldescriptor gettype ( ) { <nl> if ( descriptor = = null ) { <nl> descriptor = ( tooldescriptor ) descriptor . find ( type ) ; <nl> mmm a / core / src / main / java / hudson / util / descriptorlist . java <nl> ppp b / core / src / main / java / hudson / util / descriptorlist . java <nl>
public class descriptortest { <nl> } <nl> } <nl>  <nl> + @ ignore ( " <nl> + @ issue ( " jenkins - 26781 " ) <nl> + @ test public void overriddenid ( ) throws exception { <nl> + freestyleproject p = rule . createfreestyleproject ( ) ; <nl> + p . getbuilderslist ( ) . add ( new builderimpl ( " builder - a " ) ) ; <nl> + rule . configroundtrip ( p ) ; <nl> + list < builder > builders = p . getbuilderslist ( ) ; <nl> + assertequals ( 1 , builders . size ( ) ) ; <nl> + assertequals ( builderimpl . class , builders . get ( 0 ) . getclass ( ) ) ; <nl> + assertequals ( " builder - a " , ( ( builderimpl ) builders . get ( 0 ) ) . id ) ; <nl> + rule . assertlogcontains ( " running builder - a " , rule . buildandassertsuccess ( p ) ) ; <nl> + p . getbuilderslist ( ) . replace ( new builderimpl ( " builder - b " ) ) ; <nl> + rule . configroundtrip ( p ) ; <nl> + builders = p . getbuilderslist ( ) ; <nl> + assertequals ( 1 , builders . size ( ) ) ; <nl> + assertequals ( builderimpl . class , builders . get ( 0 ) . getclass ( ) ) ; <nl> + assertequals ( " builder - b " , ( ( builderimpl ) builders . get ( 0 ) ) . id ) ; <nl> + rule . assertlogcontains ( " running builder - b " , rule . buildandassertsuccess ( p ) ) ; <nl> + } <nl> + private static final class builderimpl extends builder { <nl> + private final string id ; <nl> + builderimpl ( string id ) { <nl> + this . id = id ; <nl> + } <nl> + @ override public boolean perform ( abstractbuild < ? , ? > build , launcher launcher , buildlistener listener ) throws interruptedexception , ioexception { <nl> + listener . getlogger ( ) . println ( " running " + getdescriptor ( ) . getid ( ) ) ; <nl> + return true ; <nl> + } <nl> + @ override public descriptor < builder > getdescriptor ( ) { <nl> + return ( descriptor < builder > ) jenkins . getinstance ( ) . getdescriptorbyname ( id ) ; <nl> + } <nl> + } <nl> + private static final class descriptorimpl extends buildstepdescriptor < builder > { <nl> + private final string id ; <nl> + descriptorimpl ( string id ) { <nl> + super ( builderimpl . class ) ; <nl> + this . id = id ; <nl> + } <nl> + @ override public string getid ( ) { <nl> + return id ; <nl> + } <nl> + @ override public builder newinstance ( staplerrequest req , jsonobject formdata ) throws descriptor . formexception { <nl> + return new builderimpl ( id ) ; <nl> + } <nl> + @ override public string getdisplayname ( ) { <nl> + return id ; <nl> + } <nl> + @ override public boolean isapplicable ( class < ? extends abstractproject > jobtype ) { <nl> + return true ; <nl> + } <nl> + } <nl> + @ testextension ( " overriddenid " ) public static final buildstepdescriptor < builder > buildera = new descriptorimpl ( " builder - a " ) ; <nl> + @ testextension ( " overriddenid " ) public static final buildstepdescriptor < builder > builderb = new descriptorimpl ( " builder - b " ) ; <nl> + <nl> }
the software . <nl> < artifactid > maven - compiler - plugin < / artifactid > <nl> < configuration > <nl> < source > 1 . $ { java . level } < / source > <nl> - < target > 1 . $ { java . level } < / target > <nl> + < target > 1 . 7 < / target > < ! - - <nl> < ! - - default reusecreated is more performant <nl> feel free to uncomment if you have any issues on your platform <nl> < compilerreusestrategy > alwaysnew < / compilerreusestrategy > <nl>
the software . <nl> < configuration > <nl> < rules > <nl> < requirejavaversion > <nl> - < version > 1 . 6 . 0 - 18 < / version > <nl> + < version > 1 . 7 . 0 < / version > <nl> < / requirejavaversion > <nl> < requiremavenversion > <nl> < version > 3 . 0 < / version > <nl> < / requiremavenversion > <nl> < enforcebytecodeversion > <nl> - < maxjdkversion > 1 . $ { java . level } < / maxjdkversion > <nl> + < maxjdkversion > 1 . 7 < / maxjdkversion > < ! - - <nl> < ignoreclasses > <nl> < ignoreclass > org . eclipse . jetty . spdy . * < / ignoreclass > <nl> < / ignoreclasses > <nl> mmm a / war / pom . xml <nl> ppp b / war / pom . xml <nl>
public final class computerset extends abstractmodelobject implements describabl <nl>  <nl> jsonobject formdata = req . getsubmittedform ( ) ; <nl> formdata . put ( " name " , fixedname ) ; <nl> - <nl> + <nl> + <nl> node result = nodedescriptor . all ( ) . find ( type ) . newinstance ( req , formdata ) ; <nl> app . addnode ( result ) ; <nl>  <nl> mmm a / core / src / main / java / hudson / model / items . java <nl> ppp b / core / src / main / java / hudson / model / items . java <nl>
public class toollocationnodeproperty extends nodeproperty < node > { <nl> return home ; <nl> } <nl>  <nl> + @ suppresswarnings ( " deprecation " ) <nl> public tooldescriptor gettype ( ) { <nl> if ( descriptor = = null ) { <nl> descriptor = ( tooldescriptor ) descriptor . find ( type ) ; <nl> mmm a / core / src / main / java / hudson / util / descriptorlist . java <nl> ppp b / core / src / main / java / hudson / util / descriptorlist . java <nl>
public class descriptortest { <nl> } <nl> } <nl>  <nl> + @ ignore ( " <nl> + @ issue ( " jenkins - 26781 " ) <nl> + @ test public void overriddenid ( ) throws exception { <nl> + freestyleproject p = rule . createfreestyleproject ( ) ; <nl> + p . getbuilderslist ( ) . add ( new builderimpl ( " builder - a " ) ) ; <nl> + rule . configroundtrip ( p ) ; <nl> + list < builder > builders = p . getbuilderslist ( ) ; <nl> + assertequals ( 1 , builders . size ( ) ) ; <nl> + assertequals ( builderimpl . class , builders . get ( 0 ) . getclass ( ) ) ; <nl> + assertequals ( " builder - a " , ( ( builderimpl ) builders . get ( 0 ) ) . id ) ; <nl> + rule . assertlogcontains ( " running builder - a " , rule . buildandassertsuccess ( p ) ) ; <nl> + p . getbuilderslist ( ) . replace ( new builderimpl ( " builder - b " ) ) ; <nl> + rule . configroundtrip ( p ) ; <nl> + builders = p . getbuilderslist ( ) ; <nl> + assertequals ( 1 , builders . size ( ) ) ; <nl> + assertequals ( builderimpl . class , builders . get ( 0 ) . getclass ( ) ) ; <nl> + assertequals ( " builder - b " , ( ( builderimpl ) builders . get ( 0 ) ) . id ) ; <nl> + rule . assertlogcontains ( " running builder - b " , rule . buildandassertsuccess ( p ) ) ; <nl> + } <nl> + private static final class builderimpl extends builder { <nl> + private final string id ; <nl> + builderimpl ( string id ) { <nl> + this . id = id ; <nl> + } <nl> + @ override public boolean perform ( abstractbuild < ? , ? > build , launcher launcher , buildlistener listener ) throws interruptedexception , ioexception { <nl> + listener . getlogger ( ) . println ( " running " + getdescriptor ( ) . getid ( ) ) ; <nl> + return true ; <nl> + } <nl> + @ override public descriptor < builder > getdescriptor ( ) { <nl> + return ( descriptor < builder > ) jenkins . getinstance ( ) . getdescriptorbyname ( id ) ; <nl> + } <nl> + } <nl> + private static final class descriptorimpl extends buildstepdescriptor < builder > { <nl> + private final string id ; <nl> + descriptorimpl ( string id ) { <nl> + super ( builderimpl . class ) ; <nl> + this . id = id ; <nl> + } <nl> + @ override public string getid ( ) { <nl> + return id ; <nl> + } <nl> + @ override public builder newinstance ( staplerrequest req , jsonobject formdata ) throws descriptor . formexception { <nl> + return new builderimpl ( id ) ; <nl> + } <nl> + @ override public string getdisplayname ( ) { <nl> + return id ; <nl> + } <nl> + @ override public boolean isapplicable ( class < ? extends abstractproject > jobtype ) { <nl> + return true ; <nl> + } <nl> + } <nl> + @ testextension ( " overriddenid " ) public static final buildstepdescriptor < builder > buildera = new descriptorimpl ( " builder - a " ) ; <nl> + @ testextension ( " overriddenid " ) public static final buildstepdescriptor < builder > builderb = new descriptorimpl ( " builder - b " ) ; <nl> + <nl> }
the software . <nl> < ? jelly escape - by - default = ' true ' ? > <nl> < j : jelly xmlns : j = " jelly : core " xmlns : st = " jelly : stapler " xmlns : d = " jelly : define " xmlns : l = " / lib / layout " xmlns : t = " / lib / hudson " xmlns : f = " / lib / form " xmlns : i = " jelly : fmt " > <nl> < td style = " $ { indenter . getcss ( job ) } " > <nl> + < ! - - <nl> < a href = " $ { jobbaseurl } $ { job . shorturl } " class = ' model - link inside ' > < l : breakable value = " $ { h . getrelativedisplaynamefrom ( job , itemgroup ) } " / > < / a > <nl> < / td > <nl> < / j : jelly >
public class apitest { <nl> j . createwebclient ( ) . goto ( " api / xml ? xpath = / * [ 1 ] " , " application / xml " ) ; <nl> } <nl>  <nl> + @ ignore ( " <nl> + @ issue ( " jenkins - 27607 " ) <nl> + @ test public void json ( ) throws exception { <nl> + freestyleproject p = j . createfreestyleproject ( " p " ) ; <nl> + jenkinsrule . webclient wc = j . createwebclient ( ) ; <nl> + assertequals ( " { \ " name \ " : \ " p \ " } " , wc . goto ( p . geturl ( ) + " api / json ? tree = name " , " application / json " ) . getwebresponse ( ) . getcontentasstring ( ) ) ; <nl> + assertequals ( " wrap ( { \ " name \ " : \ " p \ " } ) " , wc . goto ( p . geturl ( ) + " api / json ? tree = name & jsonp = wrap " , " application / javascript " ) . getwebresponse ( ) . getcontentasstring ( ) ) ; <nl> + } <nl> + <nl> @ test <nl> @ issue ( " jenkins - 3267 " ) <nl> public void wrappedzeroitems ( ) throws exception {
public class nodeprovisioner { <nl> / * * <nl> * periodically invoked to keep track of the load . <nl> * launches additional nodes if necessary . <nl> + * <nl> + * note : this method will obtain a lock on { @ link # provisioninglock } first ( to ensure that one and only one <nl> + * instance of this provisioner is running at a time ) and then a lock on { @ link queue # lock } <nl> * / <nl> private void update ( ) { <nl> provisioninglock . lock ( ) ; <nl> try { <nl> lastsuggestedreview = system . currenttimemillis ( ) ; <nl> + <nl> + / / we need to get the lock on queue for two reasons : <nl> + / / num . we will potentially adding a lot of nodes and we don ' t want to fight with queue # maintain to acquire <nl> + / / the queue # lock in order to add each node . much better is to hold the queue # lock until all nodes <nl> + / / that were provisioned since last we checked have been added . <nl> + / / num . we want to know the idle executors count , which can only be measured if you hold the queue # lock <nl> + / / strictly speaking we don ' t need an accurate measure for this , but as we had to get the queue # lock <nl> + / / anyway , we might as well get an accurate measure . <nl> + / / <nl> + / / we do not need the queue # lock to get the count of items in the queue as that is a lock - free call <nl> + / / since adding a node should not ( in principle ) confuse queue # maintain ( it is only removal of nodes <nl> + / / that causes issues in queue # maintain ) we should be able to remove the need for queue # lock <nl> + / / <nl> + <nl> queue . withlock ( new runnable ( ) { <nl> @ override <nl> public void run ( ) { <nl>
the software . <nl> progress bar for a build in progress . <nl>  <nl> < st : attribute name = " build " use = " required " type = " hudson . model . queue . executable " > <nl> - build in progress . <nl> + build in progress . must have a url property . <nl> < / st : attribute > <nl> < st : attribute name = " executor " > <nl> executor that ' s carrying out the build . if null , defaults to " build . executor " <nl> < / st : attribute > <nl> < / st : documentation > <nl> - < j : set var = " executor " value = " $ { executor ? : build . executor } " / > <nl> + < j : set var = " executor " value = " $ { executor ? : build . executor } " / > < ! - - <nl> < t : progressbar tooltip = " $ { % text ( executor . timestampstring , executor . estimatedremainingtime ) } " <nl> red = " $ { executor . islikelystuck ( ) } " <nl> pos = " $ { executor . progress } " href = " $ { rooturl } / $ { build . url } console " / >
public class artifactarchivertest { <nl> assertequals ( " lodge " , kids [ 0 ] . getname ( ) ) ; <nl> / / do not check that it . exists ( ) since its target has not been archived <nl> } <nl> + <nl> + @ ignore ( " <nl> + @ test public void outsidesymlinks ( ) throws exception { <nl> + final freestyleproject p = j . createfreestyleproject ( ) ; <nl> + p . getbuilderslist ( ) . add ( new testbuilder ( ) { <nl> + @ override public boolean perform ( abstractbuild < ? , ? > build , launcher launcher , buildlistener listener ) throws interruptedexception , ioexception { <nl> + filepath ws = build . getworkspace ( ) ; <nl> + if ( ws = = null ) { <nl> + return false ; <nl> + } <nl> + ws . child ( " hack " ) . symlinkto ( p . getconfigfile ( ) . getfile ( ) . getabsolutepath ( ) , listener ) ; <nl> + return true ; <nl> + } <nl> + } ) ; <nl> + p . getpublisherslist ( ) . add ( new artifactarchiver ( " hack " , " " , false , true ) ) ; <nl> + freestylebuild b = j . assertbuildstatussuccess ( p . schedulebuild2 ( 0 ) ) ; <nl> + list < freestylebuild . artifact > artifacts = b . getartifacts ( ) ; <nl> + assertequals ( 1 , artifacts . size ( ) ) ; <nl> + freestylebuild . artifact artifact = artifacts . get ( 0 ) ; <nl> + assertequals ( " hack " , artifact . relativepath ) ; <nl> + virtualfile [ ] kids = b . getartifactmanager ( ) . root ( ) . list ( ) ; <nl> + assertequals ( 1 , kids . length ) ; <nl> + assertequals ( " hack " , kids [ 0 ] . getname ( ) ) ; <nl> + assertfalse ( kids [ 0 ] . isdirectory ( ) ) ; <nl> + assertfalse ( kids [ 0 ] . isfile ( ) ) ; <nl> + assertfalse ( kids [ 0 ] . exists ( ) ) ; <nl> + } <nl>  <nl> private void runnewbuildandstartunitliscreated ( abstractproject project ) throws interruptedexception { <nl> int buildnumber = project . getnextbuildnumber ( ) ;
public class fingerprinter extends recorder implements serializable , dependencyd <nl> } <nl>  <nl> abstractproject p = key ; <nl> - if ( key instanceof matrixconfiguration ) { <nl> + <nl> + if ( key . getclass ( ) . getname ( ) . equals ( " hudson . matrix . matrixconfiguration " ) ) { <nl> p = key . getrootproject ( ) ; <nl> }
the software . <nl> < st : include page = " sidepanel . jelly " / > <nl> < l : main - panel > <nl> < h1 class = " job - index - headline page - headline " > $ { it . pronoun } < l : breakable value = " $ { it . displayname } " / > < / h1 > <nl> - < j : if test = " $ { ( it . name ! = it . displayname ) and ( it . class . name ! = ' hudson . matrix . matrixconfiguration ' ) } " > <nl> + < j : if test = " $ { ( it . name ! = it . displayname ) and ( it . class . name ! = ' hudson . matrix . matrixconfiguration ' ) } " > < ! - - <nl> $ { % project name } : $ { it . fullname } <nl> < / j : if > <nl> < t : editabledescription permission = " $ { it . configure } " / >
public final class runidmigrator { <nl> } <nl> } <nl>  <nl> + / * * <nl> + * tries to move / rename a file from one path to another . <nl> + * uses { @ link java . nio . file . files # move } when available . <nl> + * does not use { @ link java . nio . file . standardcopyoption # replace_existing } or any other options . <nl> + * <nl> + * / <nl> + static void move ( file src , file dest ) throws ioexception { <nl> + class < ? > pathc ; <nl> + try { <nl> + pathc = class . forname ( " java . nio . file . path " ) ; <nl> + } catch ( classnotfoundexception x ) { <nl> + / / java num , do our best <nl> + if ( dest . exists ( ) ) { <nl> + throw new ioexception ( dest + " already exists " ) ; <nl> + } <nl> + if ( src . renameto ( dest ) ) { <nl> + return ; <nl> + } <nl> + throw new ioexception ( " could not move " + src + " to " + dest ) ; <nl> + } <nl> + try { <nl> + method topath = file . class . getmethod ( " topath " ) ; <nl> + class < ? > copyoptionac = class . forname ( " [ ljava . nio . file . copyoption ; " ) ; <nl> + class . forname ( " java . nio . file . files " ) . getmethod ( " move " , pathc , pathc , copyoptionac ) . invoke ( null , topath . invoke ( src ) , topath . invoke ( dest ) , array . newinstance ( copyoptionac . getcomponenttype ( ) , num ) ) ; <nl> + } catch ( invocationtargetexception x ) { <nl> + throwable cause = x . getcause ( ) ; <nl> + if ( cause instanceof ioexception ) { <nl> + throw ( ioexception ) cause ; <nl> + } else { <nl> + throw new ioexception ( cause ) ; <nl> + } <nl> + } catch ( exception x ) { <nl> + throw new ioexception ( x ) ; <nl> + } <nl> + } <nl> + <nl> / * * <nl> * look up a historical run by id . <nl> * @ param id a nonnumeric id which may be a valid { @ link run # getid } <nl> mmm a / core / src / test / java / jenkins / model / runidmigratortest . java <nl> ppp b / core / src / test / java / jenkins / model / runidmigratortest . java <nl>
public class simplebuildwrappertest { <nl> } <nl> } <nl>  <nl> + @ test public void envoverrideexpand ( ) throws exception { <nl> + assume . assumefalse ( functions . iswindows ( ) ) ; <nl> + freestyleproject p = r . createfreestyleproject ( ) ; <nl> + p . getbuildwrapperslist ( ) . add ( new wrapperwithenvoverrideexpand ( ) ) ; <nl> + specialenvslave slave = new specialenvslave ( tmp . getroot ( ) , r . createcomputerlauncher ( null ) ) ; <nl> + r . jenkins . addnode ( slave ) ; <nl> + p . setassignednode ( slave ) ; <nl> + jdk jdk = new jdk ( " test " , " / opt / jdk " ) ; <nl> + r . jenkins . getjdks ( ) . add ( jdk ) ; <nl> + p . setjdk ( jdk ) ; <nl> + captureenvironmentbuilder captureenvironment = new captureenvironmentbuilder ( ) ; <nl> + p . getbuilderslist ( ) . add ( captureenvironment ) ; <nl> + p . getbuilderslist ( ) . add ( new shell ( " echo effective path = $ path " ) ) ; <nl> + freestylebuild b = r . buildandassertsuccess ( p ) ; <nl> + string expected = " / home / jenkins / bin : / opt / jdk / bin : / usr / bin : / bin " ; <nl> + assertequals ( expected , captureenvironment . getenvvars ( ) . get ( " path " ) ) ; <nl> + <nl> + r . assertlogcontains ( " effective path = / opt / jdk / bin : " + expected , b ) ; <nl> + } <nl> + public static class wrapperwithenvoverrideexpand extends simplebuildwrapper { <nl> + @ override public void setup ( context context , run < ? , ? > build , filepath workspace , launcher launcher , tasklistener listener , envvars initialenvironment ) throws ioexception , interruptedexception { <nl> + assertequals ( " / opt / jdk / bin : / usr / bin : / bin " , initialenvironment . get ( " path " ) ) ; <nl> + assertequals ( " / home / jenkins " , initialenvironment . get ( " home " ) ) ; <nl> + context . env ( " path + stuff " , " $ { home } / bin " ) ; <nl> + } <nl> + @ testextension ( " envoverrideexpand " ) public static class descriptorimpl extends buildwrapperdescriptor { <nl> + @ override public string getdisplayname ( ) { <nl> + return " wrapperwithenvoverrideexpand " ; <nl> + } <nl> + @ override public boolean isapplicable ( abstractproject < ? , ? > item ) { <nl> + return true ; <nl> + } <nl> + } <nl> + } <nl> + private static class specialenvslave extends slave { <nl> + specialenvslave ( file remotefs , commandlauncher launcher ) throws descriptor . formexception , ioexception { <nl> + super ( " special " , " specialenvslave " , remotefs . getabsolutepath ( ) , num , mode . normal , " " , launcher , retentionstrategy . noop , collections . < nodeproperty < ? > > emptylist ( ) ) ; <nl> + } <nl> + @ override public computer createcomputer ( ) { <nl> + return new specialenvcomputer ( this ) ; <nl> + } <nl> + } <nl> + private static class specialenvcomputer extends slavecomputer { <nl> + specialenvcomputer ( specialenvslave slave ) { <nl> + super ( slave ) ; <nl> + } <nl> + @ override public envvars getenvironment ( ) throws ioexception , interruptedexception { <nl> + envvars env = super . getenvironment ( ) ; <nl> + env . put ( " path " , " / usr / bin : / bin " ) ; <nl> + env . put ( " home " , " / home / jenkins " ) ; <nl> + return env ; <nl> + } <nl> + } <nl> + <nl> @ test public void disposer ( ) throws exception { <nl> freestyleproject p = r . createfreestyleproject ( ) ; <nl> p . getbuildwrapperslist ( ) . add ( new wrapperwithdisposer ( ) ) ;
public final class runidmigrator { <nl> } <nl> } <nl>  <nl> + / * * <nl> + * tries to move / rename a file from one path to another . <nl> + * uses { @ link java . nio . file . files # move } when available . <nl> + * does not use { @ link java . nio . file . standardcopyoption # replace_existing } or any other options . <nl> + * <nl> + * / <nl> + static void move ( file src , file dest ) throws ioexception { <nl> + class < ? > pathc ; <nl> + try { <nl> + pathc = class . forname ( " java . nio . file . path " ) ; <nl> + } catch ( classnotfoundexception x ) { <nl> + / / java num , do our best <nl> + if ( dest . exists ( ) ) { <nl> + throw new ioexception ( dest + " already exists " ) ; <nl> + } <nl> + if ( src . renameto ( dest ) ) { <nl> + return ; <nl> + } <nl> + throw new ioexception ( " could not move " + src + " to " + dest ) ; <nl> + } <nl> + try { <nl> + method topath = file . class . getmethod ( " topath " ) ; <nl> + class < ? > copyoptionac = class . forname ( " [ ljava . nio . file . copyoption ; " ) ; <nl> + class . forname ( " java . nio . file . files " ) . getmethod ( " move " , pathc , pathc , copyoptionac ) . invoke ( null , topath . invoke ( src ) , topath . invoke ( dest ) , array . newinstance ( copyoptionac . getcomponenttype ( ) , num ) ) ; <nl> + } catch ( invocationtargetexception x ) { <nl> + throwable cause = x . getcause ( ) ; <nl> + if ( cause instanceof ioexception ) { <nl> + throw ( ioexception ) cause ; <nl> + } else { <nl> + throw new ioexception ( cause ) ; <nl> + } <nl> + } catch ( exception x ) { <nl> + throw new ioexception ( x ) ; <nl> + } <nl> + } <nl> + <nl> / * * <nl> * look up a historical run by id . <nl> * @ param id a nonnumeric id which may be a valid { @ link run # getid } <nl> mmm a / core / src / test / java / jenkins / model / runidmigratortest . java <nl> ppp b / core / src / test / java / jenkins / model / runidmigratortest . java <nl>
public final class filepath implements serializable { <nl> act ( new securefilecallable < void > ( ) { <nl> private static final long serialversionuid = num l ; <nl> public void invoke ( file f , virtualchannel channel ) throws ioexception { <nl> + <nl> _chmod ( writing ( f ) , mask ) ; <nl>  <nl> return null ; <nl>
public final class filepath implements serializable { <nl> * run chmod via jnr - posix <nl> * / <nl> private static void _chmod ( file f , int mask ) throws ioexception { <nl> - if ( functions . iswindows ( ) ) return ; / / noop <nl> + <nl> + if ( file . pathseparatorchar = = ' ; ' ) return ; / / noop <nl>  <nl> posixapi . jnr ( ) . chmod ( f . getabsolutepath ( ) , mask ) ; <nl> }
public final class filepath implements serializable { <nl> act ( new securefilecallable < void > ( ) { <nl> private static final long serialversionuid = num l ; <nl> public void invoke ( file f , virtualchannel channel ) throws ioexception { <nl> + <nl> _chmod ( writing ( f ) , mask ) ; <nl>  <nl> return null ; <nl>
public final class filepath implements serializable { <nl> * run chmod via jnr - posix <nl> * / <nl> private static void _chmod ( file f , int mask ) throws ioexception { <nl> - if ( functions . iswindows ( ) ) return ; / / noop <nl> + <nl> + if ( file . pathseparatorchar = = ' ; ' ) return ; / / noop <nl>  <nl> posixapi . jnr ( ) . chmod ( f . getabsolutepath ( ) , mask ) ; <nl> }
import org . kohsuke . stapler . staplerrequest ; <nl> return jenkins . getinstance ( ) . getinjector ( ) . getinstance ( downloadsettings . class ) ; <nl> } <nl>  <nl> - private boolean usebrowser = true ; / / historical default , not necessarily recommended <nl> + private boolean usebrowser = false ; <nl>  <nl> public downloadsettings ( ) { <nl> load ( ) ; <nl> mmm / dev / null <nl> ppp b / test / src / test / java / hudson / model / downloadservice2test . java <nl>
public class tokenbasedremembermeservices2 extends tokenbasedremembermeservices <nl> logger . debug ( " did not send remember - me cookie because ' remember me ' is disabled in " + <nl> " security configuration ( principal did set parameter ' " + getparameter ( ) + " ' ) " ) ; <nl> } <nl> - / / xxx log warning when receiving remember - me request despite the feature being disabled ? <nl> + <nl> return ; <nl> } <nl>  <nl> mmm a / core / src / main / java / hudson / tools / abstractcommandinstaller . java <nl> ppp b / core / src / main / java / hudson / tools / abstractcommandinstaller . java <nl>
public abstract class abstractcommandinstaller extends toolinstaller { <nl> @ override <nl> public filepath performinstallation ( toolinstallation tool , node node , tasklistener log ) throws ioexception , interruptedexception { <nl> filepath dir = preferredlocation ( tool , node ) ; <nl> - / / xxx support windows batch scripts , unix scripts with interpreter line , etc . ( see commandinterpreter subclasses ) <nl> + <nl> filepath script = dir . createtexttempfile ( " hudson " , getcommandfileextension ( ) , command ) ; <nl> try { <nl> string cmd [ ] = getcommandcall ( script ) ; <nl> mmm a / core / src / main / java / jenkins / util / antclassloader . java <nl> ppp b / core / src / main / java / jenkins / util / antclassloader . java <nl>
public class antclassloader extends classloader implements subbuildlistener { <nl> / / designated to use a specific loader first <nl> / / ( this one or the parent one ) <nl>  <nl> - / / xxx - shouldn ' t this always return false in isolated mode ? <nl> + <nl>  <nl> boolean useparentfirst = parentfirst ; <nl>  <nl>
public class jenkins extends abstractcibase implements directlymodifiabletopleve <nl> * do not use in the production code as the signature may change . <nl> * / <nl> public interface jenkinsholder { <nl> - jenkins getinstance ( ) ; <nl> + @ checkfornull jenkins getinstance ( ) ; <nl> } <nl>  <nl> static jenkinsholder holder = new jenkinsholder ( ) { <nl> - public jenkins getinstance ( ) { <nl> + public @ checkfornull jenkins getinstance ( ) { <nl> return theinstance ; <nl> } <nl> } ; <nl>  <nl> / * * <nl> - * gets the jenkins singleton . <nl> - * @ return the instance , or null if jenkins has not been started , or was already shut down <nl> + * gets the { @ link jenkins } singleton . <nl> + * { @ link # getinstance ( ) } provides the unchecked versions of the method . <nl> + * @ return { @ link jenkins } instance <nl> + * @ throws illegalstateexception { @ link jenkins } has not been started , or was already shut down <nl> + * @ since <nl> + * / <nl> + public static @ nonnull jenkins getactiveinstance ( ) throws illegalstateexception { <nl> + jenkins instance = holder . getinstance ( ) ; <nl> + if ( instance = = null ) { <nl> + throw new illegalstateexception ( " jenkins has not been started , or was already shut down " ) ; <nl> + } <nl> + return instance ; <nl> + } <nl> + <nl> + / * * <nl> + * gets the { @ link jenkins } singleton . <nl> + * { @ link # getactiveinstance ( ) } provides the checked versions of the method . <nl> + * @ return the instance . null if the { @ link jenkins } instance has not been started , <nl> + * or was already shut down <nl> * / <nl> @ cliresolver <nl> @ checkfornull
public class fileparametervalue extends parametervalue { <nl> if ( getclass ( ) ! = obj . getclass ( ) ) <nl> return false ; <nl> fileparametervalue other = ( fileparametervalue ) obj ; <nl> - if ( location = = null ) { <nl> - if ( other . location ! = null ) <nl> - return false ; <nl> - } else if ( ! location . equals ( other . location ) ) <nl> - return false ; <nl> - return true ; <nl> + <nl> + if ( location = = null & & other . location = = null ) <nl> + return true ; / / consider null parameters as equal <nl> + <nl> + <nl> + return false ; <nl> } <nl>  <nl> @ override
public final class directorybrowsersupport implements httpresponse { <nl> } else { <nl> relativepath = n ; <nl> } <nl> - zipentry e = new zipentry ( relativepath ) ; <nl> + / / in zip archives " all slashes must be forward slashes " ( http : / / pkware . com / documents / casestudies / appnote . txt ) <nl> + <nl> + / / but not the file separator char of the ( maybe remote ) " dir " . <nl> + zipentry e = new zipentry ( relativepath . replace ( ' \ \ ' , ' / ' ) ) ; <nl> virtualfile f = dir . child ( n ) ; <nl> e . settime ( f . lastmodified ( ) ) ; <nl> zos . putnextentry ( e ) ;
public abstract class extensionfinder implements extensionpoint { <nl> logger . log ( level . severe , " failed to create guice container from all the plugins " , e ) ; <nl> / / failing to load all bindings are disastrous , so recover by creating minimum that works <nl> / / by just including the core <nl> + <nl> container = guice . createinjector ( new sezpozmodule ( loadsezpozindices ( jenkins . class . getclassloader ( ) ) ) ) ; <nl> } <nl>  <nl>
<nl> # generated file . do not modify . <nl> # <nl> - # this file is for the jenkins core developers to place what we think is the best filtering rules <nl> - # that balance the unnecessary exposure of data to slaves vs backward compatibility with plugins <nl> + # this file is for jenkins core developers to list what we think are the best filtering rules <nl> + # for apparently harmless accesses to files on the jenkins master from slaves . <nl> # <nl> # to override these rules , place * . conf files by other names into this folder . files are sorted <nl> # before parsed , so using a lower number allows you to override what we have here . this file <nl> # gets overwritten every time jenkins starts . <nl> # <nl> - # see http : / / jenkins - ci . org / security - 144 for more details <nl> + # see http : / / jenkins - ci . org / security - 144 for more details . <nl>  <nl> # this directory contains credentials , master encryption keys , and other sensitive information <nl> - # that slave have absolutely no business with . <nl> + # that slaves have absolutely no business with . <nl> # unless there are rules in other files allowing access to other portions of $ jenkins_home , <nl> # this rule as it stands here has no effect , because anything left unspecified is rejected . <nl> deny all < jenkins_home > / secrets / . * <nl>  <nl> - # user content is publicly readable , so quite safe for slaves to read , too <nl> - # xunit plugin is known to read from here <nl> + # user content is publicly readable , so quite safe for slaves to read , too . <nl> + # ( the xunit plugin is known to read from here . ) <nl> # https : / / wiki . jenkins - ci . org / display / jenkins / user + content <nl> allow read , stat < jenkins_home > / usercontent / . * <nl>  <nl> - # in next rule we grant lots of access under builds directory , so first protect ones that we <nl> - # think are somewhat more sensitive . we found no plugins that hit those rules either <nl> + # in the next rule we grant general access under build directories , so first we protect <nl> + # the actual build record that jenkins core reads , which nothing should be touching . <nl> deny all < builddir > / build . xml <nl>  <nl> - # various plugins read / write under builds , so allow them all <nl> - # - git num . x and subversion plugin writes changelog <nl> - # - analysis - core and its families write reports <nl> - # - cobertura plugin and violation plugin writes reports from slaves <nl> + # various plugins read / write files under build directories , so allow them all . <nl> + # - git num . x writes changelog . xml from the slave ( 2 . x writes from the master so need not be listed ) <nl> + # - analysis - core and plugins based on it write reports to workspace - files / <nl> + # - cobertura writes coverage . xml <nl> + # - violations writes violations . xml and other content under violations / <nl> + # - dependency - check writes archive / artifacts . txt <nl> allow all < builddir > / . + <nl>  <nl> + # <nl> + <nl> # all the other accesses that aren ' t specified here will be left upto other rules in this directory . <nl> - # if no rules in those other files matches , then the access will be rejected . <nl> \ no newline at end of file <nl> + # if no rules in those other files matches , then the access will be rejected .
public final class filepath implements serializable { <nl> * @ see # unzipfrom ( inputstream ) <nl> * / <nl> public void unzip ( final filepath target ) throws ioexception , interruptedexception { <nl> + <nl> if ( this . channel ! = target . channel ) { / / local - > remote or remote - > local <nl> final remoteinputstream in = new remoteinputstream ( read ( ) , flag . greedy ) ; <nl> target . act ( new securefilecallable < void > ( ) { <nl>
public final class filepath implements serializable { <nl> * @ see # untarfrom ( inputstream , tarcompression ) <nl> * / <nl> public void untar ( final filepath target , final tarcompression compression ) throws ioexception , interruptedexception { <nl> - target . act ( new securefilecallable < void > ( ) { <nl> - public void invoke ( file dir , virtualchannel channel ) throws ioexception , interruptedexception { <nl> - readfromtar ( filepath . this . getname ( ) , dir , compression . extract ( filepath . this . read ( ) ) ) ; <nl> - return null ; <nl> - } <nl> - private static final long serialversionuid = num l ; <nl> - } ) ; <nl> + <nl> + if ( this . channel ! = target . channel ) { / / local - > remote or remote - > local <nl> + final remoteinputstream in = new remoteinputstream ( read ( ) , flag . greedy ) ; <nl> + target . act ( new securefilecallable < void > ( ) { <nl> + public void invoke ( file dir , virtualchannel channel ) throws ioexception , interruptedexception { <nl> + readfromtar ( filepath . this . getname ( ) , dir , compression . extract ( in ) ) ; <nl> + return null ; <nl> + } <nl> + <nl> + private static final long serialversionuid = num l ; <nl> + } ) ; <nl> + } else { / / local - > local or remote - > remote <nl> + target . act ( new securefilecallable < void > ( ) { <nl> + public void invoke ( file dir , virtualchannel channel ) throws ioexception , interruptedexception { <nl> + readfromtar ( filepath . this . getname ( ) , dir , compression . extract ( filepath . this . read ( ) ) ) ; <nl> + return null ; <nl> + } <nl> + private static final long serialversionuid = num l ; <nl> + } ) ; <nl> + } <nl> } <nl>  <nl> / * *
public class fileparametervalue extends parametervalue { <nl> if ( getclass ( ) ! = obj . getclass ( ) ) <nl> return false ; <nl> fileparametervalue other = ( fileparametervalue ) obj ; <nl> - if ( location = = null ) { <nl> - if ( other . location ! = null ) <nl> - return false ; <nl> - } else if ( ! location . equals ( other . location ) ) <nl> - return false ; <nl> - return true ; <nl> + <nl> + if ( location = = null & & other . location = = null ) <nl> + return true ; / / consider null parameters as equal <nl> + <nl> + <nl> + return false ; <nl> } <nl>  <nl> @ override
the software . <nl> < patch . tracker . serverid > jenkins - jira < / patch . tracker . serverid > <nl>  <nl> < slf4jversion > 1 . 7 . 4 < / slf4jversion > < ! - - < num . 6 . x version didn ' t specify the license ( mit ) - - > <nl> - < maven - plugin . version > 2 . 0 < / maven - plugin . version > <nl> + < maven - plugin . version > 2 . 0 . 5 - snapshot < / maven - plugin . version > < ! - - <nl> < animal . sniffer . skip > $ { skiptests } < / animal . sniffer . skip > <nl>  <nl> < java . level > 6 < / java . level >
public class callabledirectionchecker extends rolechecker { <nl>  <nl> / * * <nl> * test feature that is meant to replace all logging , and log what would have been violations . <nl> + * <nl> * / <nl> - public static printwriter bypass_log ; <nl> + private static final printwriter bypass_log ; <nl>  <nl> static { <nl> string log = system . getproperty ( callabledirectionchecker . class . getname ( ) + " . log " ) ; <nl> mmm a / core / src / main / java / jenkins / security / defaultfilepathfilter . java <nl> ppp b / core / src / main / java / jenkins / security / defaultfilepathfilter . java <nl>
import org . kohsuke . accmod . restrictions . donotuse ; <nl> * escape hatch to disable this check completely . <nl> * / <nl> public static boolean bypass = boolean . getboolean ( defaultfilepathfilter . class . getname ( ) + " . allow " ) ; <nl> - private static final printwriter bypass_log ; <nl> + private static final printwriter bypass_log ; <nl> static { <nl> string log = system . getproperty ( " jenkins . security . defaultfilepathfilter . log " ) ; <nl> if ( log = = null ) {
import java . util . logging . logger ; <nl> * if a slave is idle for num mins , this retention strategy will remove the slave . this can be used as - is for <nl> * a { @ link node } provisioned by cloud to implement the auto - scaling semantics , it can be subtyped to tweak <nl> * the behavior , or it can be used as an example . <nl> - * <nl> + * < p > <nl> * @ author kohsuke kawaguchi <nl> * @ since num . 510 <nl> * /
public class updatesitetest { <nl> @ test public void updatedirectlywithjson ( ) throws exception { <nl> updatesite us = new updatesite ( " default " , new url ( baseurl , " update - center . json " ) . toexternalform ( ) ) ; <nl> assertnull ( us . getplugin ( " adaptiveplugin " ) ) ; <nl> - assertequals ( formvalidation . ok ( ) , us . updatedirectly ( true ) . get ( ) ) ; <nl> + assertequals ( formvalidation . ok ( ) , us . updatedirectly ( / * <nl> assertnotnull ( us . getplugin ( " adaptiveplugin " ) ) ; <nl> } <nl>  <nl> @ test public void updatedirectlywithhtml ( ) throws exception { <nl> updatesite us = new updatesite ( " default " , new url ( baseurl , " update - center . json . html " ) . toexternalform ( ) ) ; <nl> assertnull ( us . getplugin ( " adaptiveplugin " ) ) ; <nl> - assertequals ( formvalidation . ok ( ) , us . updatedirectly ( true ) . get ( ) ) ; <nl> + assertequals ( formvalidation . ok ( ) , us . updatedirectly ( false ) . get ( ) ) ; <nl> assertnotnull ( us . getplugin ( " adaptiveplugin " ) ) ; <nl> } <nl> }
public class abstractprojecttest extends hudsontestcase { <nl> assertsymlinkforbuild ( laststable , num ) ; <nl> } <nl>  <nl> + / * <nl> @ bug ( 15156 ) <nl> public void testgetbuildaftergc ( ) { <nl> freestyleproject job = createfreestyleproject ( ) ; <nl>
public class callabledirectionchecker extends callabledecorator { <nl> public < v , t extends throwable > callable < v , t > userrequest ( callable < v , t > op , callable < v , t > stem ) { <nl> class c = op . getclass ( ) ; <nl>  <nl> - if ( c . getname ( ) . startswith ( " hudson . remoting " ) ) <nl> + if ( c . getname ( ) . startswith ( " hudson . remoting " ) ) <nl> return stem ; / / lower level services provided by remoting , such iosyncer , rpcrequest , ping , etc . that we allow <nl>  <nl> boolean m2s = c . isannotationpresent ( mastertoslave . class ) ;
public abstract class acl { <nl> * safer variant of { @ link # impersonate ( authentication ) } that does not require a finally - block . <nl> * @ param auth authentication , such as { @ link # system } <nl> * @ param body an action to run with this alternate authentication in effect <nl> - * @ since num . 581 <nl> * / <nl> + <nl> + @ restricted ( noexternaluse . class ) <nl> public static < v , t extends exception > v impersonate ( authentication auth , callable < v , t > body ) throws t { <nl> securitycontext old = impersonate ( auth ) ; <nl> try {
import org . apache . commons . io . ioutils ; <nl> * <nl> * @ author kohsuke kawaguchi <nl> * / <nl> - @ extension ( optional = true ) <nl> + @ extension ( optional = true ) <nl> public class hserrpidlist extends administrativemonitor { <nl> / * * <nl> * hs_err_pid files that we think belong to us . <nl>
public class plugintest { <nl>  <nl> @ rule public jenkinsrule r = new jenkinsrule ( ) ; <nl>  <nl> - @ issue ( " security - 131 " ) <nl> + @ issue ( " security - 131 " ) <nl> @ test public void dodynamic ( ) throws exception { <nl> r . createwebclient ( ) . goto ( " plugin / credentials / images / 24x24 / credentials . png " , " image / png " ) ; <nl> / * collapsed somewhere before it winds up in restofpath :
import org . kohsuke . stapler . interceptor . requirepost ; <nl> * / <nl> @ exportedbean <nl> public class queue extends resourcecontroller implements saveable { <nl> + <nl> + / * * <nl> + * defines the refresh period for of the internal cache ( { @ link # itemsview } ) . <nl> + * data should be defined in milliseconds , default value - num ; <nl> + * @ since <nl> + * / <nl> + private static int cache_refresh_period = integer . getinteger ( queue . class . getname ( ) + " . cacherefreshperiod " , num ) ; <nl> + <nl> / * * <nl> * items that are waiting for its quiet period to pass . <nl> * <nl>
public class junitresultarchiver extends recorder implements simplebuildstep { <nl> return keeplongstdio ; <nl> } <nl>  <nl> + / * * @ since <nl> + @ databoundsetter public final void setkeeplongstdio ( boolean keeplongstdio ) { <nl> + this . keeplongstdio = keeplongstdio ; <nl> + } <nl> + <nl> private static final long serialversionuid = num l ; <nl>  <nl> @ extension
public final class directorybrowsersupport implements httpresponse { <nl>  <nl> private static void zip ( outputstream outputstream , virtualfile dir , string glob ) throws ioexception { <nl> zipoutputstream zos = new zipoutputstream ( outputstream ) ; <nl> + zos . setencoding ( system . getproperty ( " file . encoding " ) ) ; <nl> for ( string n : dir . list ( glob . length ( ) = = num ? " * * " : glob ) ) { <nl> string relativepath ; <nl> if ( glob . length ( ) = = num ) {
import static java . lang . annotation . retentionpolicy . runtime ; <nl>  <nl> / * * <nl> * { @ link optionhandler } s that should be auto - discovered . <nl> - * <nl> + * <nl> * @ author kohsuke kawaguchi <nl> * / <nl> @ indexed
public class jenkinsrule implements testrule , methodrule , rootaction { <nl> } <nl>  <nl> private boolean ignore ( cssparseexception e ) { <nl> - return e . geturi ( ) . contains ( " / yui / " ) ; <nl> + string uri = e . geturi ( ) ; <nl> + return uri . contains ( " / yui / " ) <nl> + <nl> + | | uri . contains ( " / css / style . css " ) | | uri . contains ( " / css / responsive - grid . css " ) ; <nl> } <nl> } ) ;
<nl> + / * <nl> + * the mit license <nl> + * <nl> + * copyright num oleg nenashev < nenashev @ synopsys . com > , synopsys inc . <nl> + * <nl> + * permission is hereby granted , free of charge , to any person obtaining a copy <nl> + * of this software and associated documentation files ( the " software " ) , to deal <nl> + * in the software without restriction , including without limitation the rights <nl> + * to use , copy , modify , merge , publish , distribute , sublicense , and / or sell <nl> + * copies of the software , and to permit persons to whom the software is <nl> + * furnished to do so , subject to the following conditions : <nl> + * <nl> + * the above copyright notice and this permission notice shall be included in <nl> + * all copies or substantial portions of the software . <nl> + * <nl> + * the software is provided " as is " , without warranty of any kind , express or <nl> + * implied , including but not limited to the warranties of merchantability , <nl> + * fitness for a particular purpose and noninfringement . in no event shall the <nl> + * authors or copyright holders be liable for any claim , damages or other <nl> + * liability , whether in an action of contract , tort or otherwise , arising from , <nl> + * out of or in connection with the software or the use or other dealings in <nl> + * the software . <nl> + * / <nl> + package hudson ; <nl> + <nl> + import hudson . model . abstractbuild ; <nl> + import hudson . model . abstractproject ; <nl> + import hudson . model . buildlistener ; <nl> + import hudson . model . freestyleproject ; <nl> + import hudson . model . run ; <nl> + import hudson . tasks . buildwrapper ; <nl> + import hudson . tasks . buildwrapperdescriptor ; <nl> + import java . io . ioexception ; <nl> + import org . jvnet . hudson . test . bug ; <nl> + import hudson . launcher . decoratedlauncher ; <nl> + import org . junit . rule ; <nl> + import org . junit . test ; <nl> + import org . jvnet . hudson . test . jenkinsrule ; <nl> + <nl> + / * * <nl> + * contains tests for { @ link procstarter } class . <nl> + * @ author oleg nenashev < nenashev @ synopsys . com > , synopsys inc . <nl> + * @ since <nl> + * / <nl> + public class procstartertest { <nl> + <nl> + @ rule <nl> + public jenkinsrule rule = new jenkinsrule ( ) ; <nl> + <nl> + @ test <nl> + @ bug ( 20559 ) <nl> + public void testnoninitializedenvsnpe ( ) throws exception { <nl> + / / create nodes and other test stuff <nl> + rule . hudson . setnumexecutors ( 0 ) ; <nl> + rule . createslave ( ) ; <nl> + <nl> + / / create a job with test build wrappers <nl> + freestyleproject project = rule . createfreestyleproject ( ) ; <nl> + project . getbuildwrapperslist ( ) . add ( new decoratedwrapper ( ) ) ; <nl> + project . getbuildwrapperslist ( ) . add ( new echowrapper ( ) ) ; <nl> + <nl> + / / run the build . if npe occurs , the test will fail <nl> + rule . buildandassertsuccess ( project ) ; <nl> + } <nl> + <nl> + / * * <nl> + * a stub descriptor for { @ link buildwrapper } s . <nl> + * / <nl> + public abstract static class testwrapperdescriptor extends buildwrapperdescriptor { <nl> + <nl> + @ override <nl> + public boolean isapplicable ( abstractproject < ? , ? > ap ) { <nl> + return true ; <nl> + } <nl> + <nl> + @ override <nl> + public string getdisplayname ( ) { <nl> + return " teststub " ; <nl> + } <nl> + } <nl> + <nl> + / * * <nl> + * a wrapper , which contains a nested launch . <nl> + * / <nl> + public static class echowrapper extends buildwrapper { <nl> + <nl> + @ override <nl> + public environment setup ( abstractbuild build , launcher launcher , buildlistener listener ) throws ioexception , interruptedexception { <nl> + launcher . procstarter starter = launcher . launch ( ) . cmds ( " echo " , " hello " ) ; <nl> + starter . start ( ) ; <nl> + starter . join ( ) ; <nl> + return new environment ( ) { <nl> + } ; <nl> + } <nl> + <nl> + @ extension <nl> + public static class descriptorimpl extends testwrapperdescriptor { <nl> + } <nl> + } ; <nl> + <nl> + / * * <nl> + * a wrapper , which decorates launchers . <nl> + * / <nl> + public static class decoratedwrapper extends buildwrapper { <nl> + <nl> + @ override <nl> + public launcher decoratelauncher ( abstractbuild build , launcher launcher , buildlistener listener ) throws ioexception , interruptedexception , run . runnerabortedexception { <nl> + final buildlistener l = listener ; <nl> + return new decoratedlauncher ( launcher ) { <nl> + @ override <nl> + public proc launch ( launcher . procstarter starter ) throws ioexception { <nl> + string [ ] envs = starter . envs ( ) ; / / finally , call envs ( ) <nl> + l . getlogger ( ) . println ( " [ decoratedwrapper ] : number of environment variables is " + envs . length ) ; / / fail on null <nl> + return super . launch ( starter ) ; <nl> + } <nl> + } ; <nl> + } <nl> + <nl> + @ override <nl> + public environment setup ( abstractbuild build , launcher launcher , buildlistener listener ) throws ioexception , interruptedexception { <nl> + return new environment ( ) { <nl> + } ; <nl> + } <nl> + <nl> + @ extension <nl> + public static class descriptorimpl extends testwrapperdescriptor { <nl> + } <nl> + } ; <nl> + }
public abstract class launcher { <nl> } <nl> } <nl> } <nl> + <nl> + / * * <nl> + * a launcher which delegates to a provided inner launcher . <nl> + * allows subclasses to only implement methods they want to override . <nl> + * originally , this launcher has been implemented in <nl> + * < a href = " https : / / wiki . jenkins - ci . org / display / jenkins / custom + tools + plugin " > <nl> + * custom tools plugin < / a > . <nl> + * <nl> + * @ author rcampbell <nl> + * @ author oleg nenashev , synopsys inc . <nl> + * @ since <nl> + * / <nl> + public static class decoratedlauncher extends launcher { <nl> + <nl> + private launcher inner = null ; <nl> + <nl> + public decoratedlauncher ( launcher inner ) { <nl> + super ( inner ) ; <nl> + this . inner = inner ; <nl> + } <nl> + <nl> + @ override <nl> + public proc launch ( procstarter starter ) throws ioexception { <nl> + return inner . launch ( starter ) ; <nl> + } <nl> + <nl> + @ override <nl> + public channel launchchannel ( string [ ] cmd , outputstream out , <nl> + filepath workdir , map < string , string > envvars ) throws ioexception , <nl> + interruptedexception { <nl> + return inner . launchchannel ( cmd , out , workdir , envvars ) ; <nl> + } <nl> + <nl> + @ override <nl> + public void kill ( map < string , string > modelenvvars ) throws ioexception , <nl> + interruptedexception { <nl> + inner . kill ( modelenvvars ) ; <nl> + } <nl> + <nl> + @ override <nl> + public boolean isunix ( ) { <nl> + return inner . isunix ( ) ; <nl> + } <nl> + <nl> + @ override <nl> + public proc launch ( string [ ] cmd , boolean [ ] mask , string [ ] env , inputstream in , outputstream out , filepath workdir ) throws ioexception { <nl> + return inner . launch ( cmd , mask , env , in , out , workdir ) ; <nl> + } <nl> + <nl> + @ override <nl> + public computer getcomputer ( ) { <nl> + return inner . getcomputer ( ) ; <nl> + } <nl> + <nl> + @ override <nl> + public tasklistener getlistener ( ) { <nl> + return inner . getlistener ( ) ; <nl> + } <nl> + <nl> + @ override <nl> + public string tostring ( ) { <nl> + return super . tostring ( ) + " ; decorates " + inner . tostring ( ) ; <nl> + } <nl> + <nl> + @ override <nl> + public virtualchannel getchannel ( ) { <nl> + return inner . getchannel ( ) ; <nl> + } <nl> + <nl> + @ override <nl> + public proc launch ( string [ ] cmd , string [ ] env , inputstream in , outputstream out , filepath workdir ) throws ioexception { <nl> + return inner . launch ( cmd , env , in , out , workdir ) ; <nl> + } <nl> + <nl> + / * * <nl> + * gets nested launcher . <nl> + * @ return inner launcher <nl> + * / <nl> + public launcher getinner ( ) { <nl> + return inner ; <nl> + } <nl> + } <nl>  <nl> public static class iotriplet implements serializable { <nl> inputstream stdout , stderr ;
package hudson . tasks . shell ; <nl> f = namespace ( lib . formtaglib ) <nl>  <nl> f . entry ( title : _ ( " command " ) , description : _ ( " description " , rooturl ) ) { <nl> - f . textarea ( name : " command " , value : instance ? . command , class : " fixed - width " , ' codemirror - mode ' : ' shell ' ) <nl> + <nl> + f . textarea ( name : " command " , value : instance ? . command , class : " fixed - width " ) <nl> }
public abstract class run < jobt extends job < jobt , runt > , runt extends run < jobt , run <nl> * / <nl> public void reload ( ) throws ioexception { <nl> this . state = state . completed ; <nl> + <nl> this . result = result . failure ; / / defensive measure . value should be overwritten by unmarshal , but just in case the saved data is inconsistent <nl> getdatafile ( ) . unmarshal ( this ) ; / / load the rest of the data <nl>  <nl> + if ( state = = state . completed ) { <nl> + logger . log ( fine , " reload { 0 } @ { 1 } " , new object [ ] { this , hashcode ( ) } ) ; <nl> + } else { <nl> + logger . log ( warning , " reload { 0 } @ { 1 } with anomalous state { 2 } " , new object [ ] { this , hashcode ( ) , state } ) ; <nl> + } <nl> + <nl> / / not calling onload upon reload . partly because we don ' t want to call that from run constructor , <nl> / / and partly because some existing use of onload isn ' t assuming that it can be invoked multiple times . <nl> } <nl>
public class fingerprinter extends recorder implements serializable , dependencyd <nl> } <nl>  <nl> abstractproject p = key ; <nl> - if ( key instanceof matrixconfiguration ) { <nl> + <nl> + if ( key . getclass ( ) . getname ( ) . equals ( " hudson . matrix . matrixconfiguration " ) ) { <nl> p = key . getrootproject ( ) ; <nl> }
the software . <nl> < st : include page = " sidepanel . jelly " / > <nl> < l : main - panel > <nl> < h1 class = " job - index - headline page - headline " > $ { it . pronoun } < l : breakable value = " $ { it . displayname } " / > < / h1 > <nl> - < j : if test = " $ { ( it . name ! = it . displayname ) and ( it . class . name ! = ' hudson . matrix . matrixconfiguration ' ) } " > <nl> + < j : if test = " $ { ( it . name ! = it . displayname ) and ( it . class . name ! = ' hudson . matrix . matrixconfiguration ' ) } " > < ! - - <nl> $ { % project name } : $ { it . fullname } <nl> < / j : if > <nl> < t : editabledescription permission = " $ { it . configure } " / >
public abstract class cause { <nl> @ override <nl> public void print ( tasklistener listener ) { <nl> listener . getlogger ( ) . println ( messages . cause_useridcause_shortdescription ( <nl> + <nl> modelhyperlinknote . encodeto ( " / user / " + getuserid ( ) , getusername ( ) ) ) ) ; <nl> } <nl>  <nl> mmm a / core / src / main / java / hudson / model / run . java <nl> ppp b / core / src / main / java / hudson / model / run . java <nl>
public abstract class buildsteplistener implements extensionpoint { <nl> * returns all the registered { @ link buildsteplistener } s . <nl> * / <nl> public static extensionlist < buildsteplistener > all ( ) { <nl> + <nl> return jenkins . getinstance ( ) . getextensionlist ( buildsteplistener . class ) ; <nl> } <nl> } <nl> mmm a / core / src / main / java / hudson / model / job . java <nl> ppp b / core / src / main / java / hudson / model / job . java <nl>
public abstract class view extends abstractmodelobject implements accesscontroll <nl> return true ; <nl> } <nl>  <nl> + / * * <nl> + * enables or disables automatic refreshes of the view . <nl> + * by default , automatic refreshes are enabled . <nl> + * @ since <nl> + * / <nl> + public boolean isautomaticrefreshenabled ( ) { <nl> + return true ; <nl> + } <nl> + <nl> / * * <nl> * if true , only show relevant executors <nl> * / <nl> mmm a / core / src / main / resources / hudson / model / view / index . jelly <nl> ppp b / core / src / main / resources / hudson / model / view / index . jelly <nl>
public abstract class abstractitem extends actionable implements item , httpdelet <nl> } <nl> } <nl>  <nl> + / * * <nl> + * reloads this job from the disk . <nl> + * <nl> + * exposed through cli as well . <nl> + * <nl> + * <nl> + * <nl> + * @ since num . 556 <nl> + * / <nl> + @ climethod ( name = " reload - job " ) <nl> + @ requirepost <nl> + public void doreload ( ) throws ioexception { <nl> + checkpermission ( configure ) ; <nl> + <nl> + / / try to reflect the changes by reloading <nl> + getconfigfile ( ) . unmarshal ( this ) ; <nl> + items . whileupdatingbyxml ( new callable < void , ioexception > ( ) { <nl> + @ override <nl> + public void call ( ) throws ioexception { <nl> + onload ( getparent ( ) , getrootdir ( ) . getname ( ) ) ; <nl> + return null ; <nl> + } <nl> + } ) ; <nl> + jenkins . getinstance ( ) . rebuilddependencygraphasync ( ) ; <nl> + <nl> + saveablelistener . fireonchange ( this , getconfigfile ( ) ) ; <nl> + } <nl> + <nl>  <nl> / * ( non - javadoc ) <nl> * @ see hudson . model . abstractmodelobject # getsearchname ( ) <nl> mmm a / core / src / main / resources / hudson / model / messages . properties <nl> ppp b / core / src / main / resources / hudson / model / messages . properties <nl>
the software . <nl> < artifactid > upstart - slave - installer < / artifactid > <nl> < version > 1 . 1 < / version > <nl> < / dependency > <nl> + < ! - - <nl> + warning : org . jenkinsci . modules . systemd_slave_installer . slaveinstallerfactoryimpl @ 614899d4 has failed on hudson . slaves . slavecomputer @ 163dc443 <nl> + java . io . ioexception : cannot run program " systemctl " : error = 2 , no such file or directory <nl> + at java . lang . processbuilder . start ( processbuilder . java : 1041 ) <nl> + at org . jenkinsci . modules . systemd_slave_installer . slaveinstallerfactoryimpl $ hassystemd . call ( slaveinstallerfactoryimpl . java : 46 ) <nl> + at org . jenkinsci . modules . systemd_slave_installer . slaveinstallerfactoryimpl $ hassystemd . call ( slaveinstallerfactoryimpl . java : 39 ) <nl> < dependency > <nl> < groupid > org . jenkins - ci . modules < / groupid > <nl> < artifactid > systemd - slave - installer < / artifactid > <nl> < version > 1 . 0 < / version > <nl> < / dependency > <nl> + - - > <nl> < dependency > <nl> < groupid > org . jenkins - ci . modules < / groupid > <nl> < artifactid > sshd < / artifactid >
public class itemlistener implements extensionpoint { <nl> for ( itemlistener l : all ( ) ) <nl> l . onupdated ( item ) ; <nl> } <nl> + <nl> + / * * @ since <nl> + public static void fireondeleted ( item item ) { <nl> + for ( itemlistener l : all ( ) ) { <nl> + l . ondeleted ( item ) ; <nl> + } <nl> + } <nl> + <nl> } <nl> mmm a / core / src / main / java / jenkins / model / jenkins . java <nl> ppp b / core / src / main / java / jenkins / model / jenkins . java <nl>
public class abstractprojecttest extends hudsontestcase { <nl> assertsymlinkforbuild ( laststable , num ) ; <nl> } <nl>  <nl> + / * <nl> @ bug ( 15156 ) <nl> public void testgetbuildaftergc ( ) { <nl> freestyleproject job = createfreestyleproject ( ) ; <nl>
public class user extends abstractmodelobject implements accesscontrolled , descr <nl>  <nl> public void dorsslatest ( staplerrequest req , staplerresponse rsp ) throws ioexception , servletexception { <nl> final list < run > lastbuilds = new arraylist < run > ( ) ; <nl> - for ( final toplevelitem item : jenkins . getinstance ( ) . getitems ( ) ) { <nl> - if ( ! ( item instanceof job ) ) continue ; <nl> - for ( run r = ( ( job ) item ) . getlastbuild ( ) ; r ! = null ; r = r . getpreviousbuild ( ) ) { <nl> - if ( ! ( r instanceof abstractbuild ) ) continue ; <nl> - final abstractbuild b = ( abstractbuild ) r ; <nl> - if ( b . hasparticipant ( this ) ) { <nl> + for ( abstractproject < ? , ? > p : jenkins . getinstance ( ) . getallitems ( abstractproject . class ) ) { <nl> + for ( abstractbuild < ? , ? > b = p . getlastbuild ( ) ; b ! = null ; b = b . getpreviousbuild ( ) ) { <nl> + if ( b . hasparticipant ( this ) ) { <nl> lastbuilds . add ( b ) ; <nl> break ; <nl> }
public final class workunitcontext { <nl> * to create its { @ link workunit } . <nl> * / <nl> public workunit createworkunit ( subtask execunit ) { <nl> - future . addexecutor ( executor . currentexecutor ( ) ) ; <nl> + executor executor = executor . currentexecutor ( ) ; <nl> + if ( executor ! = null ) { <nl> + future . addexecutor ( executor ) ; <nl> + } <nl> workunit wu = new workunit ( this , execunit ) ; <nl> workunits . add ( wu ) ; <nl> return wu ;
public class asynchpeopletest { <nl> htmlpage page = wc . goto ( " asynchpeople " ) ; <nl> assertequals ( 0 , wc . waitforbackgroundjavascript ( 120000 ) ) ; <nl> assertequals ( " display : none ; " , page . getelementbyid ( " status " ) . getattribute ( " style " ) ) ; <nl> + / * <nl> assertnotnull ( page . getelementbyid ( " person - bob " ) ) ; <nl> + * / <nl> } <nl>  <nl> }
public class jenkins extends abstractcibase implements modifiabletoplevelitemgro <nl> if ( dnsmulticast ! = null ) <nl> dnsmulticast . close ( ) ; <nl> interruptreloadthread ( ) ; <nl> + <nl> + java . util . timer timer = trigger . timer ; <nl> + if ( timer ! = null ) { <nl> + timer . cancel ( ) ; <nl> + } <nl> + <nl> + trigger . timer = null ; <nl> + <nl> timer . shutdown ( ) ; <nl>  <nl> if ( tcpslaveagentlistener ! = null )
the software . <nl>  <nl> < ? jelly escape - by - default = ' true ' ? > <nl> < j : jelly xmlns : j = " jelly : core " xmlns : st = " jelly : stapler " xmlns : d = " jelly : define " xmlns : l = " / lib / layout " xmlns : t = " / lib / hudson " xmlns : f = " / lib / form " xmlns : i = " jelly : fmt " > <nl> - < h2 > fetch / update config . xml < / h2 > <nl> + <nl> + < st : include page = " / hudson / model / abstractitem / _api . jelly " / > <nl> + <nl> + < h2 > fetch / update job description < / h2 > <nl> < p > <nl> - to programmatically obtain < tt > config . xml < / tt > , hit < a href = " . . / config . xml " > this url < / a > . <nl> - you can also post an updated < tt > config . xml < / tt > to the same url to programmatically <nl> - update the configuration of a job . similarly , < a href = " . . / description " > this url < / a > <nl> + < a href = " . . / description " > this url < / a > <nl> can be used to get and set just the job description . post form data with a <nl> " description " parameter to set the description . <nl> + < ! - - <nl> < / p > <nl>  <nl> < h2 > perform a build < / h2 > <nl>
final class warexploder { <nl> if ( ! timestamp . exists ( ) | | ( timestamp . lastmodified ( ) ! = war . lastmodified ( ) ) ) { <nl> system . out . println ( " exploding jenkins . war at " + war ) ; <nl> new filepath ( explodedir ) . deleterecursive ( ) ; <nl> + <nl> new filepath ( war ) . unzip ( new filepath ( explodedir ) ) ; <nl> if ( ! explodedir . exists ( ) ) / / this is supposed to be impossible , but i ' m investigating hudson - 2605 <nl> throw new ioexception ( " failed to explode " + war ) ;
the software . <nl> < groupid > com . google . guava < / groupid > <nl> < artifactid > guava < / artifactid > <nl> < / dependency > <nl> + < ! - - <nl> + < dependency > <nl> + < groupid > com . jcraft < / groupid > <nl> + < artifactid > jzlib < / artifactid > <nl> + < version > 1 . 1 . 3 < / version > <nl> + < / dependency > <nl> < / dependencies > <nl>  <nl> < build > <nl> mmm a / core / src / main / java / hudson / filepath . java <nl> ppp b / core / src / main / java / hudson / filepath . java <nl>
the software . <nl> < artifactid > jnr - posix < / artifactid > <nl> < version > 3 . 0 . 0 < / version > <nl> < / dependency > <nl> + < ! - - <nl> + < dependency > <nl> + < groupid > com . github . jnr < / groupid > <nl> + < artifactid > jnr - ffi < / artifactid > <nl> + < version > 1 . 0 . 6 < / version > <nl> + < / dependency > <nl> + - - > <nl> < dependency > <nl> < groupid > org . kohsuke < / groupid > <nl> < artifactid > trilead - putty - extension < / artifactid >
public final class filepath implements serializable { <nl> } <nl> } <nl> public outputstream compress ( outputstream out ) throws ioexception { <nl> - return new gzipoutputstream ( new bufferedoutputstream ( out ) ) ; <nl> + return new gzipoutputstream ( new bufferedoutputstream ( out ) , <nl> + <nl> + new com . jcraft . jzlib . deflater ( 6 , num + 16 , num ) , / / use num for memlevel <nl> + num , <nl> + true <nl> + ) ; <nl> } <nl> } ;
the software . <nl>  <nl> < ? jelly escape - by - default = ' true ' ? > <nl> < j : jelly xmlns : j = " jelly : core " xmlns : f = " / lib / form " > <nl> - < j : foreach var = " choice " items = " $ { descriptor . choices } " > <nl> - < f : radioblock name = " choice " value = " $ { choice } " title = " $ { choice } " checked = " $ { instance . choice = = choice } " / > <nl> - < / j : foreach > <nl> + < f : entry field = " choice " title = " choice " > <nl> + < f : select / > <nl> + < / f : entry > <nl> + < ! - - <nl> < / j : jelly >
public class filepathtest extends channeltestcase { <nl> } <nl> } <nl>  <nl> + @ bug ( 9540 ) <nl> + public void testerrormessageinremotecopyrecursive ( ) throws exception { <nl> + file tmp = util . createtempdir ( ) ; <nl> + try { <nl> + file src = new file ( tmp , " src " ) ; <nl> + file dst = new file ( tmp , " dst " ) ; <nl> + filepath from = new filepath ( src ) ; <nl> + filepath to = new filepath ( british , dst . getabsolutepath ( ) ) ; <nl> + for ( int i = num ; i < num ; i + + ) { <nl> + <nl> + outputstream os = from . child ( " content " + i ) . write ( ) ; <nl> + try { <nl> + for ( int j = num ; j < num ; j + + ) { <nl> + os . write ( ' . ' ) ; <nl> + } <nl> + } finally { <nl> + os . close ( ) ; <nl> + } <nl> + } <nl> + filepath tof = to . child ( " content0 " ) ; <nl> + tof . write ( ) . close ( ) ; <nl> + tof . chmod ( 0400 ) ; <nl> + try { <nl> + from . copyrecursiveto ( to ) ; <nl> + / / on windows this may just succeed ; ok , test did not prove anything then <nl> + } catch ( ioexception x ) { <nl> + if ( functions . printthrowable ( x ) . contains ( " content0 " ) ) { <nl> + / / fine , error message talks about permission denied . <nl> + } else { <nl> + throw x ; <nl> + } <nl> + } finally { <nl> + tof . chmod ( 700 ) ; <nl> + } <nl> + } finally { <nl> + util . deleterecursive ( tmp ) ; <nl> + } <nl> + } <nl> + <nl> public void testarchivebug4039 ( ) throws exception { <nl> file tmp = util . createtempdir ( ) ; <nl> try {
the software . <nl> < label class = " attach - previous " > $ { attrs [ ' true ' ] ? : ' % yes ' } < / label > <nl> < f : radio name = " _ . $ { attrs . field } " value = " false " checked = " $ { ! instance [ field ] } " / > <nl> < label class = " attach - previous " > $ { attrs [ ' false ' ] ? : ' % no ' } < / label > <nl> - < / j : jelly > <nl> \ no newline at end of file <nl> + < ! - - <nl> + < / j : jelly > <nl> mmm a / core / src / main / resources / lib / form / combobox . jelly <nl> ppp b / core / src / main / resources / lib / form / combobox . jelly <nl>
the software . <nl> autocomplete = " off " class = " combobox2 settings - input $ { attrs . clazz } $ { attrs . checkurl ! = null ? ' validated ' : ' ' } " <nl> name = " $ { attrs . name ? : ' _ . ' + attrs . field } " <nl> value = " $ { attrs . value ? : instance [ attrs . field ] } " / > <nl> + < ! - - <nl> < / j : jelly > <nl> mmm a / core / src / main / resources / lib / form / editablecombobox . jelly <nl> ppp b / core / src / main / resources / lib / form / editablecombobox . jelly <nl>
the software . <nl> < / j : if > <nl> < d : invokebody / > <nl> < / div > <nl> + < ! - - <nl> < / j : jelly > <nl> mmm a / core / src / main / resources / lib / form / enum . jelly <nl> ppp b / core / src / main / resources / lib / form / enum . jelly <nl>
the software . <nl> < / f : option > <nl> < / j : foreach > <nl> < / select > <nl> - < / j : jelly > <nl> \ no newline at end of file <nl> + < ! - - <nl> + < / j : jelly > <nl> mmm a / core / src / main / resources / lib / form / hetero - radio . jelly <nl> ppp b / core / src / main / resources / lib / form / hetero - radio . jelly <nl>
the software . <nl> < / f : radioblock > <nl> < / j : foreach > <nl> < / table > <nl> + < ! - - <nl> < / j : jelly > <nl> mmm a / core / src / main / resources / lib / form / number . jelly <nl> ppp b / core / src / main / resources / lib / form / number . jelly <nl>
the software . <nl> value = " $ { attrs . value ? : instance [ attrs . field ] ? : attrs . default } " <nl> type = " number " <nl> attributes = " $ { attrs } " except = " field clazz " / > <nl> + < ! - - <nl> < / j : jelly > <nl> mmm a / core / src / main / resources / lib / form / password . jelly <nl> ppp b / core / src / main / resources / lib / form / password . jelly <nl>
the software . <nl> value = " $ { h . getpasswordvalue ( attrs . value ? : instance [ attrs . field ] ) } " <nl> type = " password " <nl> attributes = " $ { attrs } " except = " field clazz " / > <nl> + < ! - - <nl> < / j : jelly > <nl> mmm a / core / src / main / resources / lib / form / select . jelly <nl> ppp b / core / src / main / resources / lib / form / select . jelly <nl>
the software . <nl> < option value = " $ { value } " > $ { value } < / option > <nl> < / j : if > <nl> < / m : select > <nl> + < ! - - <nl> < / j : jelly >
public class xstream2 extends xstream { <nl> } <nl> } ) ; <nl> annotationmapper a = new annotationmapper ( m , getconverterregistry ( ) , getconverterlookup ( ) , getclassloader ( ) , getreflectionprovider ( ) , getjvm ( ) ) ; <nl> + <nl> a . autodetectannotations ( true ) ; <nl>  <nl> mapperinjectionpoint = new mapperinjectionpoint ( a ) ;
public class maven31processfactory extends maven3processfactory <nl> string path = ( ismaster ? which . jarfile ( maven31main . class ) . getabsolutepath ( ) : slaveroot . child ( " maven31 - agent . jar " ) . getremote ( ) ) + <nl> ( getlauncher ( ) . isunix ( ) ? " : " : " ; " ) + classworldsjar ; <nl>  <nl> + <nl> + path + = ( getlauncher ( ) . isunix ( ) ? " : " : " ; " ) + mvn . gethomedir ( ) . getpath ( ) + " / conf / logging " ; <nl> + <nl> return path ; <nl> }
the software . <nl> < plugin > <nl> < groupid > org . jenkins - ci . tools < / groupid > <nl> < artifactid > maven - hpi - plugin < / artifactid > <nl> - < version > 1 . 93 < / version > <nl> + < version > 1 . 96 < / version > < ! - - <nl> < / plugin > <nl> < plugin > <nl> < groupid > org . apache . maven . plugins < / groupid >
public class projecttest { <nl> j . submit ( form ) ; <nl> assertequals ( " scm retry count was set . " , num , p . getscmcheckoutretrycount ( ) ) ; <nl> } <nl> - <nl> + <nl> + @ ignore ( " <nl> @ test <nl> public void isbuildable ( ) throws ioexception { <nl> freestyleproject p = j . createfreestyleproject ( " project " ) ; <nl>
public class projecttest { <nl> asserttrue ( " project should have participant . " , project . hasparticipant ( user ) ) ; <nl> } <nl>  <nl> + @ ignore ( " <nl> @ test <nl> public void testgetrelationship ( ) throws exception { <nl> freestyleproject project = j . createfreestyleproject ( " project " ) ;
public class rekeysecretadminmonitortest extends hudsontestcase { <nl> fileutils . readfiletostring ( xml ) . trim ( ) ) ; <nl> } <nl>  <nl> - public void testbasicworkflow ( ) throws exception { <nl> - if ( " https : / / jenkins . ci . cloudbees . com / job / core / job / jenkins_main_trunk / " . equals ( system . getenv ( " job_url " ) ) ) { <nl> - / / junit num : assume . assumefalse <nl> - / / " invalid request submission : { json = [ ljava . lang . string ; @ 2c46358e , . crumb = [ ljava . lang . string ; @ 35661457 } " <nl> - return ; <nl> - } <nl> + <nl> + public void _testbasicworkflow ( ) throws exception { <nl> putsomeolddata ( jenkins . getrootdir ( ) ) ; <nl>  <nl> webclient wc = createwebclient ( ) ;
final class warexploder { <nl> throw new assertionerror ( " jenkins . war is not in the classpath . if you are running this from the core workspace , run ' mvn install ' to create the war image in war / target / jenkins " ) ; <nl> file war = which . jarfile ( class . forname ( " executable . executable " ) ) ; <nl>  <nl> + <nl> file explodedir = new file ( " . / target / jenkins - for - test " ) . getabsolutefile ( ) ; <nl> file timestamp = new file ( explodedir , " . timestamp " ) ;
public class mavenmodulesetbuild extends abstractmavenbuild < mavenmoduleset , maven <nl>  <nl> computer computer = computer . currentcomputer ( ) ; <nl> if ( computer ! = null ) { / / just in case were not in a build <nl> - node node = computer . getnode ( ) ; <nl> + node node = computer . getnode ( ) ; <nl> if ( node ! = null ) { <nl> mvn = mvn . fornode ( node , log ) ; <nl> mvn . buildenvvars ( envs ) ;
public class jenkins extends abstractcibase implements modifiabletoplevelitemgro <nl> getprimaryview ( ) . dosubmitdescription ( req , rsp ) ; <nl> } <nl>  <nl> - @ requirepost <nl> + @ requirepost <nl> public synchronized httpredirect doquietdown ( ) throws ioexception { <nl> try { <nl> return doquietdown ( false , 0 ) ; <nl>
public class jenkins extends abstractcibase implements modifiabletoplevelitemgro <nl> } <nl>  <nl> @ climethod ( name = " cancel - quiet - down " ) <nl> - @ requirepost <nl> + @ requirepost <nl> public synchronized httpredirect docancelquietdown ( ) { <nl> checkpermission ( administer ) ; <nl> isquietingdown = false ;
table . progress - bar . red td . progress - bar - done { <nl> padding : num . 5em ; <nl> } <nl>  <nl> + / * = = = = = = = = = = = = = = = = = = = = = = = = = logrecords . jelly = = = = = = = = = = = = = = = = = = * / <nl> + <nl> + . logrecord - metadata { <nl> + <nl> + } <nl> + <nl> + . logrecord - metadata - new { <nl> + color : # 8a8 ; <nl> + } <nl> + <nl> + . logrecord - metadata - old { <nl> + color : # aaa ; <nl> + } <nl> + <nl> / * = = = = = = = = = = = = = = = = = = = = = = = = = matrix configuration table = = = = = = = = = = = = = = = = = = * / <nl> table # configuration - matrix { <nl> border : num px # bbbbbb solid ;
public abstract class slave extends node implements serializable { <nl> if ( value . startswith ( " \ \ \ \ " ) | | value . startswith ( " / net / " ) ) <nl> return formvalidation . warning ( messages . slave_network_mounted_file_system_warning ( ) ) ; <nl>  <nl> - if ( ! value . startswith ( " \ \ " ) & & ! value . startswith ( " / " ) ) { <nl> + if ( ! value . contains ( " \ \ " ) & & ! value . startswith ( " / " ) ) { <nl> + / / unix - looking path that doesn ' t start with ' / ' <nl> + <nl> return formvalidation . error ( messages . slave_the_remote_root_must_be_an_absolute_path ( ) ) ; <nl> } <nl>  <nl> mmm a / test / src / test / groovy / hudson / model / slavetest . groovy <nl> ppp b / test / src / test / groovy / hudson / model / slavetest . groovy <nl>
import hudson . model . view ; <nl> * & lt ; l : pane width = " 2 " title = " . . . " > . . . body . . . & lt ; / l : pane > structure . <nl> * in this view , " it " points to the { @ link widget } and " view " points to { @ link view } <nl> * that ' s rendering the widget . <nl> + * < / ul > <nl> + * <nl> + * <nl> + * - make widget describable & provide the ui to let admin configure widgets ? <nl> + * - backward compatibility implications ? <nl> + * <nl> * <nl> * @ author kohsuke kawaguchi <nl> * @ since num . 146
public class maven3builder extends abstractmavenbuilder implements delegatingcal <nl>  <nl> private executioneventlogger eventlogger ; <nl>  <nl> - public mavenexecutionlistener ( maven3builder maven3builder ) { <nl> + public mavenexecutionlistener ( abstractmavenbuilder maven3builder ) { <nl> this . maven3builder = maven3builder ; <nl> this . proxies = new concurrenthashmap < modulename , filterimpl > ( maven3builder . proxies ) ; <nl> for ( modulename name : this . proxies . keyset ( ) ) { <nl> executedmojospermodule . put ( name , new copyonwritearraylist < executedmojo > ( ) ) ; <nl> } <nl> this . reporters = new concurrenthashmap < modulename , list < mavenreporter > > ( maven3builder . reporters ) ; <nl> - this . eventlogger = new executioneventlogger ( new printstreamlogger ( maven3builder . listener . getlogger ( ) ) ) ; <nl> + <nl> + <nl> + printstreamlogger logger = new printstreamlogger ( maven3builder . listener . getlogger ( ) ) ; <nl> + if ( maven3builder . isdebug ( ) ) { <nl> + logger . setthreshold ( printstreamlogger . level_debug ) ; <nl> + } else if ( maven3builder . isquiet ( ) ) { <nl> + logger . setthreshold ( printstreamlogger . level_error ) ; <nl> + } <nl> + <nl> + this . eventlogger = new executioneventlogger ( logger ) ; <nl> } <nl>  <nl> / * *
public class matrixconfiguration extends project < matrixconfiguration , matrixrun > <nl> / / directory name is not a name for us mmm it ' s taken from the combination name <nl> super . onload ( parent , combination . tostring ( ) ) ; <nl> } <nl> - <nl> + <nl> + @ override <nl> + public envvars getenvironment ( node node , tasklistener listener ) throws ioexception , interruptedexception { <nl> + envvars env = super . getenvironment ( node , listener ) ; <nl> + <nl> + axislist axes = getparent ( ) . getaxes ( ) ; <nl> + for ( map . entry < string , string > e : getcombination ( ) . entryset ( ) ) { <nl> + axis a = axes . find ( e . getkey ( ) ) ; <nl> + if ( a ! = null ) <nl> + a . addbuildvariable ( e . getvalue ( ) , env ) ; <nl> + else <nl> + env . put ( e . getkey ( ) , e . getvalue ( ) ) ; <nl> + } <nl> + <nl> + return env ; <nl> + } <nl> + <nl> @ override <nl> protected void updatetransientactions ( ) { <nl> / / this method is exactly the same as in { @ link # abstractproject } .
public class surefirearchiver extends testfailuredetector { <nl>  <nl> if ( result = = null ) result = new testresult ( ) ; <nl>  <nl> - iterable < file > reportfilesfiltered = getfilesbetween ( reportsdir , reportfiles , mojo . getstarttime ( ) , system . currenttimemillis ( ) ) ; <nl> - result . parse ( reportfilesfiltered ) ; <nl> + result . parse ( system . currenttimemillis ( ) - build . getmillisecssincebuildstart ( ) , reportsdir , reportfiles ) ; <nl> + <nl> + <nl> + / / iterable < file > reportfilesfiltered = getfilesbetween ( reportsdir , reportfiles , mojo . getstarttime ( ) , system . currenttimemillis ( ) ) ; <nl> + / / result . parse ( reportfilesfiltered ) ; <nl>  <nl> / / final reference in order to serialize it : <nl> final testresult r = result ; <nl>
public class mavenmodulesetbuild extends abstractmavenbuild < mavenmoduleset , maven <nl> return r ; <nl> } <nl>  <nl> + / / # # # # # # # # # # # # # # # # # # # # # # # <nl> + <nl> string settingsconfigid = project . getsettingconfigid ( ) ; <nl> if ( stringutils . isnotblank ( settingsconfigid ) ) { <nl> settingconfig settingsconfig = settingsproviderutils . findsettings ( settingsconfigid ) ; <nl>
public class filepathsettingsprovider extends settingsprovider { <nl> * check that the provided file is a relative path . and check that it exists , just in case . <nl> * / <nl> public formvalidation docheck ( @ ancestorinpath abstractproject job , @ queryparameter string value ) throws ioexception , servletexception { <nl> - string v = fixempty ( value ) ; <nl> - if ( ( v = = null ) | | ( v . length ( ) = = num ) ) { <nl> - / / null values are allowed . <nl> - return formvalidation . ok ( ) ; <nl> - } <nl> - if ( ( v . startswith ( " / " ) ) | | ( v . startswith ( " \ \ " ) ) | | ( v . matches ( " ^ \ \ w \ \ : \ \ \ \ . * " ) ) ) { <nl> - return formvalidation . error ( messages . mavenmoduleset_alternatesettingsrelativepath ( ) ) ; <nl> - } <nl> - <nl> - run lb = job . getlastbuild ( ) ; <nl> - if ( lb ! = null ) { <nl> - filepath ws = lb . getworkspace ( ) ; <nl> - if ( ws ! = null ) <nl> - return ws . validaterelativepath ( value , true , true ) ; <nl> - } <nl> + <nl> + <nl> + <nl> + / / string v = fixempty ( value ) ; <nl> + / / if ( ( v = = null ) | | ( v . length ( ) = = num ) ) { <nl> + / / / / null values are allowed . <nl> + / / return formvalidation . ok ( ) ; <nl> + / / } <nl> + / / if ( ( v . startswith ( " / " ) ) | | ( v . startswith ( " \ \ " ) ) | | ( v . matches ( " ^ \ \ w \ \ : \ \ \ \ . * " ) ) ) { <nl> + / / return formvalidation . error ( messages . mavenmoduleset_alternatesettingsrelativepath ( ) ) ; <nl> + / / } <nl> + / / <nl> + / / run lb = job . getlastbuild ( ) ; <nl> + / / if ( lb ! = null ) { <nl> + / / filepath ws = lb . getworkspace ( ) ; <nl> + / / if ( ws ! = null ) <nl> + / / return ws . validaterelativepath ( value , true , true ) ; <nl> + / / } <nl> return formvalidation . ok ( ) ; <nl> }
import java . util . set ; <nl> @ supportedsourceversion ( sourceversion . release_6 ) <nl> @ supportedannotationtypes ( " * " ) <nl> @ metainfservices ( processor . class ) <nl> + <nl> @ ignorejrerequirement <nl> @ suppresswarnings ( { " since15 " } ) <nl> public class pluginsubtypemarker extends abstractprocessor {
public abstract class abstractlazyloadrunmap < r > extends abstractmap < integer , r > i <nl> * smallest build number - 1 to be in the returned set ( - 1 because this is exclusive ) <nl> * / <nl> public sortedmap < integer , r > submap ( integer fromkey , integer tokey ) { <nl> + <nl> + / / to look up keys in sortedmap , various places of jenkins rely on <nl> + / / submap + firstkey / lastkey combo . <nl> + <nl> r start = search ( fromkey , desc ) ; <nl> if ( start = = null ) return empty_sorted_map ;
<nl> - <nl> - - perhaps better to create two independent implementations , <nl> - one that relies on symlinks ( thus mapping from n - > r ) , the other <nl> - that uses id - > r mapping . <nl> - <nl> - it ' s not clear how we can mix two <nl> \ no newline at end of file <nl> + <nl> + - remove java6 dependency ( or do we really ? ) <nl> + - ship it ! <nl> \ no newline at end of file
public class downloadservicetest extends hudsontestcase { <nl>  <nl> @ bug ( 5536 ) <nl> public void testpost ( ) throws exception { <nl> + / / initially it should fail because the data doesn ' t have a signature <nl> assertnull ( job . getdata ( ) ) ; <nl> createwebclient ( ) . goto ( " / self / testpost " ) ; <nl> - jsonobject d = job . getdata ( ) ; <nl> - assertequals ( hashcode ( ) , d . getint ( " hello " ) ) ; <nl> + assertnull ( job . getdata ( ) ) ; <nl> + <nl> + / / and now it should work <nl> + downloadservice . signaturecheck = false ; <nl> + try { <nl> + createwebclient ( ) . goto ( " / self / testpost " ) ; <nl> + jsonobject d = job . getdata ( ) ; <nl> + assertequals ( hashcode ( ) , d . getint ( " hello " ) ) ; <nl> + } finally { <nl> + downloadservice . signaturecheck = true ; <nl> + } <nl> + <nl> + <nl> } <nl>  <nl> / * *
public class updatecenter extends abstractmodelobject implements saveable , onmas <nl> } <nl>  <nl> public list < plugin > getavailables ( ) { <nl> - list < plugin > plugins = new arraylist < plugin > ( ) ; <nl> - <nl> - for ( updatesite s : sites ) { <nl> - plugins . addall ( s . getavailables ( ) ) ; <nl> + map < string , plugin > pluginmap = new linkedhashmap < string , plugin > ( ) ; <nl> + for ( updatesite site : sites ) { <nl> + for ( plugin plugin : site . getavailables ( ) ) { <nl> + final plugin existing = pluginmap . get ( plugin . name ) ; <nl> + if ( existing = = null ) { <nl> + pluginmap . put ( plugin . name , plugin ) ; <nl> + } else if ( ! existing . version . equals ( plugin . version ) ) { <nl> + / / allow secondary update centers to publish different versions <nl> + <nl> + final string altkey = plugin . name + " : " + plugin . version ; <nl> + if ( ! pluginmap . containskey ( altkey ) ) { <nl> + pluginmap . put ( altkey , plugin ) ; <nl> + } <nl> + } <nl> + } <nl> } <nl>  <nl> - return plugins ; <nl> + return new arraylist < plugin > ( pluginmap . values ( ) ) ; <nl> } <nl>  <nl> / * * <nl>
public class updatecenter extends abstractmodelobject implements saveable , onmas <nl> } <nl>  <nl> public list < plugin > getupdates ( ) { <nl> - list < plugin > plugins = new arraylist < plugin > ( ) ; <nl> - <nl> - for ( updatesite s : sites ) { <nl> - plugins . addall ( s . getupdates ( ) ) ; <nl> + map < string , plugin > pluginmap = new linkedhashmap < string , plugin > ( ) ; <nl> + for ( updatesite site : sites ) { <nl> + for ( plugin plugin : site . getupdates ( ) ) { <nl> + final plugin existing = pluginmap . get ( plugin . name ) ; <nl> + if ( existing = = null ) { <nl> + pluginmap . put ( plugin . name , plugin ) ; <nl> + } else if ( ! existing . version . equals ( plugin . version ) ) { <nl> + / / allow secondary update centers to publish different versions <nl> + <nl> + final string altkey = plugin . name + " : " + plugin . version ; <nl> + if ( ! pluginmap . containskey ( altkey ) ) { <nl> + pluginmap . put ( altkey , plugin ) ; <nl> + } <nl> + } <nl> + } <nl> } <nl>  <nl> - return plugins ; <nl> + return new arraylist < plugin > ( pluginmap . values ( ) ) ; <nl> }
<nl> + package hudson . node_monitors ; <nl> + <nl> + import hudson . extension ; <nl> + import hudson . model . computer ; <nl> + import hudson . model . tasklistener ; <nl> + import hudson . slaves . computerlistener ; <nl> + import hudson . util . daemonthreadfactory ; <nl> + import jenkins . model . jenkins ; <nl> + <nl> + import java . io . ioexception ; <nl> + import java . util . concurrent . scheduledexecutorservice ; <nl> + import java . util . concurrent . scheduledthreadpoolexecutor ; <nl> + import java . util . concurrent . timeunit ; <nl> + <nl> + / * * <nl> + * when a slave is connected , redo the node monitoring . <nl> + * <nl> + * @ author kohsuke kawaguchi <nl> + * / <nl> + @ extension <nl> + public class nodemonitorupdater extends computerlistener { <nl> + <nl> + private final scheduledexecutorservice timer = new scheduledthreadpoolexecutor ( 1 , new daemonthreadfactory ( ) ) ; <nl> + <nl> + private volatile long timestamp ; <nl> + <nl> + / * * <nl> + * triggers the update with num seconds quiet period , to avoid triggering data check too often <nl> + * when multiple slaves become online at about the same time . <nl> + * / <nl> + @ override <nl> + public void ononline ( computer c , tasklistener listener ) throws ioexception , interruptedexception { <nl> + timestamp = system . currenttimemillis ( ) ; <nl> + timer . schedule ( new runnable ( ) { <nl> + public void run ( ) { <nl> + if ( system . currenttimemillis ( ) - timestamp < 4000 ) <nl> + return ; <nl> + <nl> + for ( nodemonitor nm : jenkins . getinstance ( ) . getcomputer ( ) . getmonitors ( ) ) { <nl> + nm . triggerupdate ( ) ; <nl> + } <nl> + } <nl> + } , num , timeunit . seconds ) ; <nl> + } <nl> + }
<nl> + event . observe ( window , " load " , function ( ) { <nl> + / * * @ type section . sectionnode * / <nl> + var outline = section . buildtree ( ) ; <nl> + var menu = new breadcrumbs . contextmenu ( ) ; <nl> + $ a ( outline . children ) . each ( function ( e ) { <nl> + var id = " section " + ( iota + + ) ; <nl> + var caption = e . gethtml ( ) ; <nl> + var cur = $ ( e . section ) . down ( " a . section - anchor " ) ; <nl> + if ( cur ! = null ) { <nl> + id = cur . id ; <nl> + caption = caption . substring ( caption . indexof ( " & lt ; / a > " ) + num ) ; <nl> + } else <nl> + $ ( e . section ) . insert ( { top : " & lt ; a id = " + id + " class = ' section - anchor ' > # & lt ; / a > " } ) ; <nl> + menu . add ( ' # ' + id , null , caption ) ; <nl> + } ) ; <nl> + breadcrumbs . attachmenu ( ' inpage - nav ' , menu ) ; <nl> + } ) ;
var radioblocksupport = { <nl> } <nl> } ; <nl>  <nl> - behaviour . register ( { <nl> + behaviour . list . unshift ( { <nl> + / / this needs to happen before tr . row - set - end rule kicks in . <nl> + / / but this is a hack . <nl> + <nl> " input . radio - block - control " : function ( r ) { <nl> r . id = " radio - block - " + ( iota + + ) ;
public class javascriptdebugger implements debugger { <nl> * call stack as a list . the list grows at the end , so the first element in the list <nl> * is the oldest stack frame . <nl> * / <nl> - public final list < callstackframe > callstack = new arraylist < callstackframe > ( ) ; <nl> + private final list < callstackframe > callstack = new arraylist < callstackframe > ( ) ; <nl> + <nl> + synchronized void addcallstackframe ( callstackframe frame ) { <nl> + this . callstack . add ( frame ) ; <nl> + } <nl> + <nl> + synchronized void removecallstackframe ( callstackframe frame ) { <nl> + / / can ' t simply call removefirst , because due to tail call elimination , <nl> + / / intermediate frames can be dropped at any time <nl> + <nl> + this . callstack . remove ( frame ) ; <nl> + } <nl>  <nl> public void handlecompilationdone ( context cx , debuggablescript fnorscript , string source ) { <nl> } <nl>
public class buildcommand extends clicommand { <nl> future < ? extends abstractbuild > f = job . schedulebuild2 ( 0 , new clicause ( jenkins . getauthentication ( ) . getname ( ) ) , a ) ; <nl> if ( ! sync ) return num ; <nl>  <nl> + <nl> abstractbuild b = f . get ( ) ; / / wait for the completion <nl> stdout . println ( " completed " + b . getfulldisplayname ( ) + " : " + b . getresult ( ) ) ; <nl> return b . getresult ( ) . ordinal ;
<nl> + < ! - - <nl> + the mit license <nl> + <nl> + copyright ( c ) num - cloudbees , inc . <nl> + <nl> + permission is hereby granted , free of charge , to any person obtaining a copy <nl> + of this software and associated documentation files ( the " software " ) , to deal <nl> + in the software without restriction , including without limitation the rights <nl> + to use , copy , modify , merge , publish , distribute , sublicense , and / or sell <nl> + copies of the software , and to permit persons to whom the software is <nl> + furnished to do so , subject to the following conditions : <nl> + <nl> + the above copyright notice and this permission notice shall be included in <nl> + all copies or substantial portions of the software . <nl> + <nl> + the software is provided " as is " , without warranty of any kind , express or <nl> + implied , including but not limited to the warranties of merchantability , <nl> + fitness for a particular purpose and noninfringement . in no event shall the <nl> + authors or copyright holders be liable for any claim , damages or other <nl> + liability , whether in an action of contract , tort or otherwise , arising from , <nl> + out of or in connection with the software or the use or other dealings in <nl> + the software . <nl> + - - > <nl> + < ? jelly escape - by - default = ' true ' ? > <nl> + < j : jelly xmlns : j = " jelly : core " xmlns : st = " jelly : stapler " xmlns : d = " jelly : define " xmlns : l = " / lib / layout " xmlns : i = " jelly : fmt " xmlns : x = " jelly : xml " > <nl> + < st : documentation > <nl> + adds one more in - page breadcrumb that jumps to sections in the page . <nl> + put this tag right before & lt ; l : main - panel > <nl> + < / st : documentation > <nl> + <nl> + < l : breadcrumb title = " $ { % configuration } " id = " inpage - nav " / > <nl> + < style > <nl> + # breadcrumbs # inpage - nav a { background : none ; } <nl> + < / style > <nl> + < ! - - <nl> + <nl> + - - > <nl> + < script > <nl> + window . addeventlistener ( " load " , function ( ) { <nl> + / * * @ type section . sectionnode * / <nl> + var outline = section . buildtree ( ) ; <nl> + var menu = new breadcrumbs . contextmenu ( ) ; <nl> + $ a ( outline . children ) . each ( function ( e ) { <nl> + if ( ! e . section . id ) <nl> + e . section . setattribute ( " id " , " section " + ( iota + + ) ) ; <nl> + menu . add ( ' # ' + e . section . id , null , e . gethtml ( ) ) ; <nl> + } ) ; <nl> + breadcrumbs . attachmenu ( ' inpage - nav ' , menu ) ; <nl> + } ) ; <nl> + < / script > <nl> + < / j : jelly > <nl> \ no newline at end of file
public class jenkins extends abstractcibase implements modifiableitemgroup < tople <nl> for ( extensionlist el : descriptorlists . values ( ) ) { <nl> el . refresh ( delta ) ; <nl> } <nl> + <nl> + <nl> + for ( extensioncomponent < rootaction > ea : delta . find ( rootaction . class ) ) { <nl> + action a = ea . getinstance ( ) ; <nl> + if ( ! actions . contains ( a ) ) actions . add ( a ) ; <nl> + } <nl> } <nl>  <nl> / * *
public class jenkins extends abstractcibase implements modifiableitemgroup < tople <nl> return descriptorlists . get ( type ) ; <nl> } <nl>  <nl> + / * * <nl> + * <nl> + * / <nl> + public void refreshextensions ( ) throws extensionrefreshexception { <nl> + extensionlist < extensionfinder > finders = getextensionlist ( extensionfinder . class ) ; <nl> + for ( extensionfinder ef : finders ) { <nl> + if ( ! ef . isrefreshable ( ) ) <nl> + throw new extensionrefreshexception ( ef + " doesn ' t support refresh " ) ; <nl> + } <nl> + <nl> + list < extensioncomponentset > fragments = lists . newarraylist ( ) ; <nl> + for ( extensionfinder ef : finders ) { <nl> + fragments . add ( ef . refresh ( ) ) ; <nl> + } <nl> + extensioncomponentset delta = extensioncomponentset . union ( fragments ) ; <nl> + <nl> + for ( extensionlist el : extensionlists . values ( ) ) { <nl> + el . refresh ( delta ) ; <nl> + } <nl> + for ( extensionlist el : descriptorlists . values ( ) ) { <nl> + el . refresh ( delta ) ; <nl> + } <nl> + } <nl> + <nl> / * * <nl> * returns the root { @ link acl } . <nl> *
public class mavenfingerprinter extends mavenreporter { <nl> } <nl> } <nl>  <nl> - private artifactrepository getlocalrepository ( string mavenversion , mavenproject parent ) { <nl> + private artifact getartifact ( mavenproject parent ) { <nl> + artifact art = parent . getartifact ( ) ; <nl> + if ( art = = null ) { <nl> + / / happens for maven num . x <nl> + <nl> + / / parent . getversion ( ) , " compile " , " pom " , null , null ) ; <nl> + } <nl> + return art ; <nl> + } <nl> + <nl> + private artifactrepository getlocalrepository ( string mavenversion , mavenproject parent , mavenproject pom ) { <nl> / / maven num . 0 has no corresponding mechanism <nl> - / / maven num . 1 , 2 . 2 has a projectbuildconfiguration , however it is null , need to further look into this <nl> - if ( mavenversion . startswith ( " 2 . " ) ) return null ; <nl> - <nl> - / / maven num <nl> - return parent . getprojectbuildingrequest ( ) <nl> + if ( mavenversion . startswith ( " 2 . 0 " ) ) { <nl> + return null ; <nl> + } else if ( mavenversion . startswith ( " 2 . 1 " ) | | mavenversion . startswith ( " 2 . 2 " ) ) { <nl> + / / return getartifactrepositorymaven21 ( pom ) ; <nl> + / / still fails , because of missing artifact later <nl> + return null ; <nl> + } else if ( mavenversion . startswith ( " 3 . " ) | | mavenversion . startswith ( " 4 . " ) / * who knows ? ; ) * / ) { <nl> + / / maven num + <nl> + return parent . getprojectbuildingrequest ( ) <nl> . getlocalrepository ( ) ; <nl> + } else { <nl> + logger . warning ( " unknown maven version : " + mavenversion ) ; <nl> + return null ; <nl> + } <nl> } <nl>  <nl> - private void record ( collection < artifact > artifacts , map < string , string > record ) throws ioexception , interruptedexception { <nl> + @ suppresswarnings ( " deprecation " ) <nl> + private artifactrepository getartifactrepositorymaven21 ( mavenproject pom ) { <nl> + / / maven num . 1 , 2 . 2 has a projectbuildconfiguration in the original project ( not parent itself ) , but no direct accessor <nl> + try { <nl> + field field = mavenproject . class . getdeclaredfield ( " projectbuilderconfiguration " ) ; <nl> + field . setaccessible ( true ) ; <nl> + projectbuilderconfiguration projbuilderconfig = ( projectbuilderconfiguration ) field . get ( pom ) ; <nl> + return projbuilderconfig ! = null ? projbuilderconfig . getlocalrepository ( ) : null ; <nl> + } catch ( exception e ) { <nl> + logger . warning ( e . tostring ( ) ) ; <nl> + return null ; <nl> + } <nl> + } <nl> + <nl> + private void record ( collection < artifact > artifacts , map < string , string > record ) throws ioexception , interruptedexception { <nl> for ( artifact a : artifacts ) <nl> record ( a , record ) ; <nl> } <nl>
public class mavenfingerprinter extends mavenreporter { <nl> * mojos perform different dependency resolution , so we need to check this for each mojo . <nl> * / <nl> public boolean postexecute ( mavenbuildproxy build , mavenproject pom , mojoinfo mojo , buildlistener listener , throwable error ) throws interruptedexception , ioexception { <nl> - record ( pom . getartifacts ( ) , used ) ; <nl> + <nl> + record ( pom . getartifacts ( ) , used ) ; <nl> record ( pom . getartifact ( ) , produced ) ; <nl> record ( pom . getattachedartifacts ( ) , produced ) ; <nl> - record ( pom . getgroupid ( ) , pom . getfile ( ) , produced ) ; <nl> + record ( pom . getgroupid ( ) + " : " + pom . getartifactid ( ) , pom . getfile ( ) , produced ) ; <nl>  <nl> return true ; <nl> } <nl>
public class mavenfingerprinter extends mavenreporter { <nl> * mojos perform different dependency resolution , so we need to check this for each mojo . <nl> * / <nl> public boolean postexecute ( mavenbuildproxy build , mavenproject pom , mojoinfo mojo , buildlistener listener , throwable error ) throws interruptedexception , ioexception { <nl> - recordparents ( pom ) ; <nl> + <nl> record ( pom . getartifacts ( ) , used ) ; <nl> record ( pom . getartifact ( ) , produced ) ; <nl> record ( pom . getattachedartifacts ( ) , produced ) ; <nl>
public class mojoinfo { <nl> private final converterlookup converterlookup = new defaultconverterlookup ( ) ; <nl>  <nl> public mojoinfo ( mojoexecution mojoexecution , mojo mojo , plexusconfiguration configuration , expressionevaluator expressionevaluator ) { <nl> + if ( mojo = = null ) throw new illegalargumentexception ( ) ; <nl> + <nl> this . mojo = mojo ; <nl> this . mojoexecution = mojoexecution ; <nl> this . configuration = configuration ; <nl>
<nl> + package jenkins . plugins . ui_samples ; <nl> + <nl> + import hudson . extension ; <nl> + <nl> + import java . util . arrays ; <nl> + import java . util . list ; <nl> + <nl> + / * * <nl> + * @ author kohsuke kawaguchi <nl> + * / <nl> + @ extension <nl> + public class progressbar extends uisample { <nl> + @ override <nl> + public string getdescription ( ) { <nl> + return " shows you how to use the progress bar widget that ' s used in the executor view and other places " ; <nl> + } <nl> + <nl> + public list < sourcefile > getsourcefiles ( ) { <nl> + <nl> + return arrays . aslist ( <nl> + / / new sourcefile ( getclass ( ) . getsimplename ( ) + " . java " ) , / / nothing interesting in the java source file <nl> + new sourcefile ( " index . groovy " ) ) ; <nl> + } <nl> + <nl> + @ extension <nl> + public static final class descriptorimpl extends uisampledescriptor { <nl> + } <nl> + } <nl> + <nl> mmm / dev / null <nl> ppp b / ui - samples - plugin / src / main / resources / jenkins / plugins / ui_samples / progressbar / index . groovy <nl>
<nl> + package jenkins . plugins . ui_samples ; <nl> + <nl> + import hudson . extension ; <nl> + <nl> + import java . util . arrays ; <nl> + import java . util . list ; <nl> + <nl> + / * * <nl> + * define portions of view fragments in separate methods / classes to improve reuse . <nl> + * <nl> + * @ author kohsuke kawaguchi <nl> + * / <nl> + @ extension <nl> + public class modularizeviewscript extends uisample { <nl> + @ override <nl> + public string getdescription ( ) { <nl> + return " define portions of view fragments in separate methods / classes to improve reuse " ; <nl> + } <nl> + <nl> + public list < sourcefile > getsourcefiles ( ) { <nl> + <nl> + return arrays . aslist ( new sourcefile ( " index . groovy " ) ) ; <nl> + } <nl> + <nl> + @ extension <nl> + public static final class descriptorimpl extends uisampledescriptor { <nl> + } <nl> + } <nl> mmm / dev / null <nl> ppp b / ui - samples - plugin / src / main / resources / jenkins / plugins / ui_samples / modularizeviewscript / index . groovy <nl>
<nl> + package jenkins . plugins . ui_samples ; <nl> + <nl> + import hudson . extension ; <nl> + <nl> + import java . util . arrays ; <nl> + import java . util . list ; <nl> + <nl> + / * * <nl> + * syntax - highlighted text area ( powered by codemirror ) . <nl> + * <nl> + * @ author kohsuke kawaguchi <nl> + * / <nl> + @ extension <nl> + public class syntaxhighlightedtextarea extends uisample { <nl> + @ override <nl> + public string getdescription ( ) { <nl> + return " syntax - highlighted text area powered by codemirror " ; <nl> + } <nl> + <nl> + public list < sourcefile > getsourcefiles ( ) { <nl> + <nl> + return arrays . aslist ( new sourcefile ( getclass ( ) . getsimplename ( ) + " . java " ) , <nl> + new sourcefile ( " index . groovy " ) ) ; <nl> + } <nl> + <nl> + @ extension <nl> + public static final class descriptorimpl extends uisampledescriptor { <nl> + } <nl> + } <nl> mmm / dev / null <nl> ppp b / ui - samples - plugin / src / main / resources / jenkins / plugins / ui_samples / syntaxhighlightedtextarea / index . groovy <nl>
public class mavenartifactarchiver extends mavenreporter { <nl> repositoryid ) ; <nl> build . addaction ( mar ) ; <nl>  <nl> + <nl> mar . recordfingerprints ( ) ; <nl>  <nl> return null ;
public final class xmlfile { <nl> * if the xml representation is completely new . <nl> * / <nl> public object unmarshal ( object o ) throws ioexception { <nl> - reader r = new bufferedreader ( new inputstreamreader ( new fileinputstream ( file ) , " utf - 8 " ) ) ; <nl> + inputstream in = new bufferedinputstream ( new fileinputstream ( file ) ) ; <nl> try { <nl> - return xs . unmarshal ( new xppreader ( r ) , o ) ; <nl> + <nl> + return xs . unmarshal ( default_driver . createreader ( in ) , o ) ; <nl> } catch ( streamexception e ) { <nl> throw new ioexception2 ( " unable to read " + file , e ) ; <nl> } catch ( conversionexception e ) { <nl>
<nl> + import hudson . taglibs . layouttaglib <nl> + <nl> + l = namespace ( layouttaglib ) <nl> + t = namespace ( " / lib / hudson " ) <nl> + st = namespace ( " jelly : stapler " ) <nl> + <nl> + def feature ( string icon , string href , string title , closure body = null ) { <nl> + t . summary ( icon : icon , href : href , icononly : true ) { <nl> + div ( class : " link " ) { <nl> + a ( href : href , title ) <nl> + } <nl> + div ( style : " color : gray ; text - decoration : none ; " , body ) <nl> + } <nl> + } <nl> + <nl> + l . layout ( title : i18n ( " manage jenkins " ) , permission : app . administer ) { <nl> + <nl> + st . include ( page : " sidepanel . jelly " ) <nl> + l . main_panel { <nl> + h1 ( i18n ( " manage jenkins " ) ) <nl> + <nl> + if ( my . ischeckuriencodingenabled ( ) ) { <nl> + script " " " <nl> + var url = ' checkuriencoding ' ; <nl> + var params = ' value = \ u57f7 \ u4e8b ' ; <nl> + var checkajax = new ajax . updater ( <nl> + ' message ' , url , <nl> + { <nl> + method : ' get ' , parameters : params <nl> + } <nl> + ) ; <nl> + " " " <nl> + span ( id : " message " ) <nl> + } <nl> + <nl> + app . administrativemonitors . each { am - > <nl> + if ( am . isactivated ( ) & & am . isenabled ( ) ) <nl> + st . include ( it : am , page : " message . jelly " ) <nl> + } <nl> + <nl> + st . include ( page : " downgrade . jelly " ) <nl> + <nl> + table ( style : " padding - left : num em ; " , id : " management - links " ) { <nl> + feature ( " setting . gif " , " configure " , i18n ( " configure system " ) ) { <nl> + raw ( i18n ( " configure global settings and paths . " ) ) <nl> + } <nl> + <nl> + <nl> + app . managementlinks . each { m - > <nl> + if ( m . iconfilename = = null ) return ; <nl> + feature ( m . iconfilename , m . urlname , m . displayname ) { <nl> + raw ( m . description ) <nl> + } <nl> + } <nl> + <nl> + if ( app . quietingdown ) { <nl> + feature ( " system - log - out . gif " , " cancelquietdown " , i18n ( " cancel shutdown " ) ) <nl> + } else { <nl> + feature ( " system - log - out . gif " , " quietdown " , i18n ( " prepare for shutdown " ) ) { <nl> + raw ( i18n ( " stops executing new builds , so that the system can be eventually shut down safely . " ) ) <nl> + } <nl> + } <nl> + } <nl> + } <nl> + } <nl> \ no newline at end of file
public final class mavenmodule extends abstractmavenproject < mavenmodule , mavenbui <nl> graph . putcomputationaldata ( mavendependencycomputationdata . class , data ) ; <nl> } <nl>  <nl> - / / in case two modules with the same name are defined , modules in the same mavenmoduleset <nl> + / / in case two modules with the same name are defined , modules in the same mavenmoduleset <nl> / / take precedence . <nl> - map < moduledependency , mavenmodule > myparentsmodules = data . modulesperparent . get ( getparent ( ) ) ; <nl>  <nl> - if ( myparentsmodules = = null ) { <nl> - myparentsmodules = new hashmap < moduledependency , mavenmodule > ( ) ; <nl> + / / can lead to oome , if remembered in the computational data and there are lot big multi - module projects <nl> + <nl> + map < moduledependency , mavenmodule > myparentsmodules ; / / = data . modulesperparent . get ( getparent ( ) ) ; <nl> + <nl> + / / if ( myparentsmodules = = null ) { <nl> + myparentsmodules = new hashmap < moduledependency , mavenmodule > ( ) ; <nl>  <nl> for ( mavenmodule m : getparent ( ) . getmodules ( ) ) { <nl> if ( m . isdisabled ( ) ) continue ; <nl>
we record noteworthy changes in this file , which then become http : / / jenkins - ci . o <nl>  <nl> some tips : <nl>  <nl> - - record your changes between " trunk - begin " and " trunk - end " . <nl> - ( unless you are making changes in the rc branch , in which case it goes <nl> - to the rc section . <nl> + - record your changes between " trunk - begin " and " trunk - end " . <nl> + ( except in rare cases when you are making changes in the rc branch , <nl> + in which case it goes to the rc section ) <nl>  <nl> - - there are four css classes to denote the kind of changes . " rfe " for enhancement and " bug " for bug fixes , <nl> - plus ' major ' to indicate major rfe / bugfix . <nl> + - there are four css classes to denote the kind of changes . <nl> + " rfe " for enhancement and " bug " for bug fixes , <nl> + plus " major " to indicate major rfe / bugfix . <nl>  <nl> - - link to bugs in the issue tracker , e - mail thread in the archive , and so on if you can . <nl> + - link to bugs in the issue tracker , e - mail thread in the archive , and so on if you can . <nl>  <nl> - - > <nl> < head > <nl> < meta http - equiv = " content - type " content = " text / html ; charset = utf - 8 " > <nl> < title > changelog < / title > <nl> - < link rel = " alternate " title = " hudson announcements " href = " https : / / hudson . dev . java . net / servlets / projectnewsrss " type = " application / rss + xml " > <nl> + < ! - - <nl> + link rel = " alternate " title = " hudson announcements " href = " https : / / hudson . dev . java . net / servlets / projectnewsrss " type = " application / rss + xml " - - > <nl> < link rel = " stylesheet " type = " text / css " href = " changelog . css " > <nl> < ! - - [ if ie ] > <nl> < style type = " text / css " > div . rate - offset { bottom : num . 2em ! important ; left : num em ! important ; } < / style > <nl>
some tips : <nl> < img src = " images / bug2 . gif " alt = " major bug " > major bug fix < img src = " images / bug . gif " alt = " bug " > bug fix <nl> < / span > < span style = " visibility : hidden " > xxxxx < / span > <nl> < / div > <nl> - < div align = right > <nl> + < ! - - <nl> < a href = " https : / / hudson . dev . java . net / servlets / projectnewsrss " > < img src = atom . gif border = 0 alt = " atom " > subscribe to rss feed < / a > <nl> - < / div > <nl> + < / div - - > <nl>  <nl> < div id = " ratings " style = " display : none ; font - size : 120 % ; <nl> border : 1px solid black ; background - color : # eee ; padding : 0 . 5em ; margin - bottom : 1em " > <nl> - help other hudson users by letting the community know which releases you ' ve used , <nl> + help other jenkins users by letting the community know which releases you ' ve used , <nl> and whether they had any significant issues . < br > <nl> legend : < br > <nl> < img src = " http : / / ci . jenkins - ci . org / images / 16x16 / health - 80plus . gif " width = " 16 " height = " 16 "
import java . io . writer ; <nl> * < p > <nl> * this extension point must have a valid < tt > config . jelly < / tt > that feeds the constructor . <nl> * <nl> + * <nl> + * <nl> * @ author kohsuke kawaguchi <nl> * @ since num . 391 <nl> * @ see hudson # getmarkupformatter ( ) <nl>
public class surefirearchiver extends mavenreporter { <nl> if ( failcount > 0 & & error instanceof mojofailureexception ) { <nl> mavenbuilder . markassuccess = true ; <nl> } <nl> + <nl> + if ( failcount > 0 ) { <nl> + maven3builder . markassuccess = true ; <nl> + } <nl> } <nl>  <nl> return true ;
public class maven3builder extends abstractmavenbuilder implements delegatingcal <nl> if ( mavenreporters ! = null ) { <nl> for ( mavenreporter mavenreporter : mavenreporters ) { <nl> try { <nl> - / / fixme get exception during mojo execution ? <nl> + <nl> + / / catch nosuchmethoderror if folks not using num . 0 . 2 + <nl> mavenreporter . postexecute ( mavenbuildproxy2 , mavenproject , mojoinfo , maven3builder . listener , null ) ; <nl> } catch ( interruptedexception e ) { <nl> e . printstacktrace ( ) ;
public class pipetest extends rmitestbase { <nl> f . close ( ) ; <nl> } <nl>  <nl> + / * * <nl> + * writer end closes even before the remote computation kicks in . <nl> + * / <nl> + public void testquickburstwrite ( ) throws exception { <nl> + final pipe p = pipe . createlocaltoremote ( ) ; <nl> + future < integer > f = channel . callasync ( new callable < integer , ioexception > ( ) { <nl> + public integer call ( ) throws ioexception { <nl> + bytearrayoutputstream baos = new bytearrayoutputstream ( ) ; <nl> + ioutils . copy ( p . getin ( ) , baos ) ; <nl> + return baos . size ( ) ; <nl> + } <nl> + } ) ; <nl> + outputstream os = p . getout ( ) ; <nl> + os . write ( 1 ) ; <nl> + os . close ( ) ; <nl> + <nl> + / / at this point the async executable kicks in . <nl> + <nl> + <nl> + assertequals ( 1 , ( int ) f . get ( ) ) ; <nl> + } <nl> + <nl> private static class devnullsink implements callable < outputstream , ioexception > { <nl> public outputstream call ( ) throws ioexception { <nl> return new remoteoutputstream ( new nulloutputstream ( ) ) ; <nl>
public abstract class descriptor < t extends describable < t > > implements saveable { <nl> } <nl> } <nl>  <nl> + / * * <nl> + * look out for a typical error a plugin developer makes . <nl> + * see http : / / hudson . 361315 . n4 . nabble . com / help - hint - needed - post - build - action - doesn - t - stay - activated - td2308833 . html <nl> + * / <nl> + private t verifynewinstance ( t t ) { <nl> + if ( t ! = null & & t . getdescriptor ( ) ! = this ) { <nl> + <nl> + logger . warning ( " father of " + t + " and its getdescriptor ( ) points to two different instances . probably malplaced @ extension . see http : / / hudson . 361315 . n4 . nabble . com / help - hint - needed - post - build - action - doesn - t - stay - activated - td2308833 . html " ) ; <nl> + } <nl> + return t ; <nl> + } <nl> + <nl> / * * <nl> * returns the resource path to the help screen html , if any . <nl> *
public final class executedmojo implements serializable { <nl> this . digest = digest ; <nl> } <nl>  <nl> + / * * <nl> + * copy constructor used for interning . <nl> + * / <nl> + private executedmojo ( string groupid , string artifactid , string version , string goal , string executionid , long duration , string digest ) { <nl> + this . groupid = groupid ; <nl> + this . artifactid = artifactid ; <nl> + this . version = version ; <nl> + this . goal = goal ; <nl> + this . executionid = executionid ; <nl> + this . duration = duration ; <nl> + this . digest = digest ; <nl> + } <nl> + <nl> + / * * <nl> + * lots of { @ link executedmojo } s tend to have the same groupid , artifactid , etc . , so interning them help <nl> + * with memory consumption . <nl> + * <nl> + * <nl> + * / <nl> + executedmojo readresolve ( ) { <nl> + return new executedmojo ( intern ( groupid ) , intern ( artifactid ) , intern ( version ) , intern ( goal ) , intern ( executionid ) , duration , intern ( digest ) ) ; <nl> + } <nl> + <nl> / * * <nl> * returns duration in a human readable text . <nl> * / <nl> mmm a / maven - plugin / src / main / java / hudson / maven / moduledependency . java <nl> ppp b / maven - plugin / src / main / java / hudson / maven / moduledependency . java <nl>
<nl> + / * <nl> + * the mit license <nl> + * <nl> + * copyright ( c ) num , infradna , inc . <nl> + * <nl> + * permission is hereby granted , free of charge , to any person obtaining a copy <nl> + * of this software and associated documentation files ( the " software " ) , to deal <nl> + * in the software without restriction , including without limitation the rights <nl> + * to use , copy , modify , merge , publish , distribute , sublicense , and / or sell <nl> + * copies of the software , and to permit persons to whom the software is <nl> + * furnished to do so , subject to the following conditions : <nl> + * <nl> + * the above copyright notice and this permission notice shall be included in <nl> + * all copies or substantial portions of the software . <nl> + * <nl> + * the software is provided " as is " , without warranty of any kind , express or <nl> + * implied , including but not limited to the warranties of merchantability , <nl> + * fitness for a particular purpose and noninfringement . in no event shall the <nl> + * authors or copyright holders be liable for any claim , damages or other <nl> + * liability , whether in an action of contract , tort or otherwise , arising from , <nl> + * out of or in connection with the software or the use or other dealings in <nl> + * the software . <nl> + * / <nl> + <nl> + package hudson . util ; <nl> + <nl> + import hudson . filepath ; <nl> + import hudson . launcher ; <nl> + import hudson . launcher . procstarter ; <nl> + <nl> + import java . io . file ; <nl> + import java . io . serializable ; <nl> + import java . util . map ; <nl> + import java . util . treemap ; <nl> + <nl> + / * * <nl> + * used to build up launch parameters for a java virtual machine . <nl> + * <nl> + * @ author kohsuke kawaguchi <nl> + * @ since num . 361 <nl> + * / <nl> + public class jvmbuilder implements serializable { <nl> + private final classpathbuilder classpath = new classpathbuilder ( ) ; <nl> + private final map < string , string > systemproperties = new treemap < string , string > ( ) ; <nl> + private final argumentlistbuilder args = new argumentlistbuilder ( ) ; <nl> + private filepath pwd ; <nl> + <nl> + private string mainclass ; <nl> + <nl> + / * * <nl> + * returns a builder object for creating classpath arguments . <nl> + * / <nl> + public classpathbuilder classpath ( ) { <nl> + return classpath ; <nl> + } <nl> + <nl> + public jvmbuilder systemproperty ( string key , string value ) { <nl> + this . systemproperties . put ( key , value ) ; <nl> + return this ; <nl> + } <nl> + <nl> + public map < string , string > systemproperties ( ) { <nl> + return this . systemproperties ; <nl> + } <nl> + <nl> + public jvmbuilder systemproperties ( map < string , string > props ) { <nl> + if ( props ! = null ) this . systemproperties . putall ( props ) ; <nl> + return this ; <nl> + } <nl> + <nl> + / * * <nl> + * arguments to the main class . <nl> + * / <nl> + public argumentlistbuilder args ( ) { <nl> + return args ; <nl> + } <nl> + <nl> + / * * <nl> + * sets the current directory for the new jvm . <nl> + * / <nl> + public jvmbuilder pwd ( filepath pwd ) { <nl> + this . pwd = pwd ; <nl> + return this ; <nl> + } <nl> + <nl> + / * * <nl> + * sets the current directory for the new jvm . <nl> + * this overloaded version only makes sense when you are launching jvm locally . <nl> + * / <nl> + public jvmbuilder pwd ( file pwd ) { <nl> + return pwd ( new filepath ( pwd ) ) ; <nl> + } <nl> + <nl> + public jvmbuilder mainclass ( string fullyqualifiedclassname ) { <nl> + this . mainclass = fullyqualifiedclassname ; <nl> + return this ; <nl> + } <nl> + <nl> + public jvmbuilder mainclass ( class mainclass ) { <nl> + return mainclass ( mainclass . getname ( ) ) ; <nl> + } <nl> + <nl> + public argumentlistbuilder tofullarguments ( ) { <nl> + argumentlistbuilder args = new argumentlistbuilder ( ) ; <nl> + args . add ( new file ( system . getproperty ( " java . home " ) , " bin / java " ) ) ; <nl> + args . addkeyvaluepairs ( " - d " , systemproperties ) ; <nl> + args . add ( " - cp " ) . add ( classpath . tostring ( ) ) ; <nl> + args . add ( mainclass ) ; <nl> + args . add ( this . args . tocommandarray ( ) ) ; <nl> + return args ; <nl> + } <nl> + <nl> + / * * <nl> + * fills a { @ link procstarter } with all the parameters configured by this builder . <nl> + * / <nl> + public procstarter launch ( launcher launcher ) { <nl> + return launcher . launch ( ) . cmds ( args ) . pwd ( pwd ) ; <nl> + } <nl> + <nl> + <nl> + private static final long serialversionuid = num l ; <nl> + }
public class hudsonhomediskusagemonitortest extends hudsontestcase { <nl> asserttrue ( mon . isenabled ( ) ) ; <nl>  <nl> / / now dismiss <nl> - submit ( getform ( mon ) , " no " ) ; <nl> + <nl> + mon . doact ( " no " ) ; <nl> assertfalse ( mon . isenabled ( ) ) ; <nl>  <nl> / / and make sure it ' s gone
public final class pluginmanager extends abstractmodelobject { <nl> url url = context . getresource ( path ) ; <nl> long lastmodified = url . openconnection ( ) . getlastmodified ( ) ; <nl> file file = new file ( rootdir , filename ) ; <nl> + <nl> if ( ! file . exists ( ) | | file . lastmodified ( ) ! = lastmodified ) { <nl> fileutils . copyurltofile ( url , file ) ; <nl> file . setlastmodified ( url . openconnection ( ) . getlastmodified ( ) ) ;
public class matrixproject extends abstractproject < matrixproject , matrixbuild > im <nl> return rsp ; <nl> } <nl>  <nl> + / * * <nl> + * makes sure that the given name is good as a axis name . <nl> + * / <nl> + public formvalidation docheckaxisname ( @ queryparameter string value ) { <nl> + checkpermission ( configure ) ; <nl> + <nl> + if ( util . fixempty ( value ) = = null ) <nl> + return formvalidation . ok ( ) ; <nl> + <nl> + try { <nl> + checkaxisname ( value ) ; <nl> + return formvalidation . ok ( ) ; <nl> + } catch ( parseexception e ) { <nl> + return formvalidation . error ( e . getmessage ( ) ) ; <nl> + } <nl> + } <nl> + <nl> + / * * <nl> + * makes sure that the given name is good as a axis name . <nl> + * <nl> + * / <nl> + private static void checkaxisname ( string name ) throws parseexception { <nl> + hudson . checkgoodname ( name ) ; <nl> + } <nl> + <nl> public descriptorimpl getdescriptor ( ) { <nl> return descriptor ; <nl> } <nl> mmm a / core / src / main / resources / hudson / matrix / matrixproject / configure - entries . jelly <nl> ppp b / core / src / main / resources / hudson / matrix / matrixproject / configure - entries . jelly <nl>
import org . kohsuke . stapler . staplerresponse ; <nl>  <nl> / * * <nl> * a view that delegates to another . <nl> + * <nl> + * <nl> + * <nl> * @ author tom huybrechts <nl> * <nl> * / <nl> mmm a / core / src / main / java / hudson / model / view . java <nl> ppp b / core / src / main / java / hudson / model / view . java <nl>
<nl> + < ! - - <nl> + the mit license <nl> + <nl> + copyright ( c ) num - 2009 , sun microsystems , inc . , kohsuke kawaguchi , seiji sogabe <nl> + <nl> + permission is hereby granted , free of charge , to any person obtaining a copy <nl> + of this software and associated documentation files ( the " software " ) , to deal <nl> + in the software without restriction , including without limitation the rights <nl> + to use , copy , modify , merge , publish , distribute , sublicense , and / or sell <nl> + copies of the software , and to permit persons to whom the software is <nl> + furnished to do so , subject to the following conditions : <nl> + <nl> + the above copyright notice and this permission notice shall be included in <nl> + all copies or substantial portions of the software . <nl> + <nl> + the software is provided " as is " , without warranty of any kind , express or <nl> + implied , including but not limited to the warranties of merchantability , <nl> + fitness for a particular purpose and noninfringement . in no event shall the <nl> + authors or copyright holders be liable for any claim , damages or other <nl> + liability , whether in an action of contract , tort or otherwise , arising from , <nl> + out of or in connection with the software or the use or other dealings in <nl> + the software . <nl> + - - > <nl> + <nl> + < ! - - <nl> + thread dump <nl> + <nl> + <nl> + - - > <nl> + < j : jelly xmlns : j = " jelly : core " xmlns : st = " jelly : stapler " xmlns : d = " jelly : define " xmlns : l = " / lib / layout " xmlns : t = " / lib / hudson " xmlns : f = " / lib / form " > <nl> + < l : layout title = " $ { % title ( it . displayname ) } " > <nl> + < st : include page = " sidepanel . jelly " / > <nl> + <nl> + < l : main - panel > <nl> + < l : isadmin > <nl> + < h1 > $ { % thread dump } < / h1 > <nl> + < j : foreach var = " t " items = " $ { it . getthreaddump ( ) . entryset ( ) } " > <nl> + < h2 > $ { t . key } < / h2 > <nl> + < pre > $ { t . value } < / pre > <nl> + < / j : foreach > <nl> + < / l : isadmin > <nl> + < / l : main - panel > <nl> + < / l : layout > <nl> + < / j : jelly > <nl> \ no newline at end of file <nl> mmm / dev / null <nl> ppp b / core / src / main / resources / hudson / slaves / slavecomputer / threaddump . properties <nl>
public class pluginmanagertest extends hudsontestcase { <nl> public void testwithrecipe ( ) throws exception { <nl> assertnotnull ( hudson . getplugin ( " tasks " ) ) ; <nl> } <nl> + <nl> + / * * <nl> + * makes sure that plugins can see maven2 plugin that ' s refactored out in num . 296 . <nl> + * / <nl> + @ withplugin ( " tasks . hpi " ) <nl> + public void testoptionalmavendependency ( ) throws exception { <nl> + pluginwrapper . dependency m2 = null ; <nl> + pluginwrapper tasks = hudson . getpluginmanager ( ) . getplugin ( " tasks " ) ; <nl> + for ( pluginwrapper . dependency d : tasks . getoptionaldependencies ( ) ) { <nl> + if ( d . shortname . equals ( " maven - plugin " ) ) { <nl> + assertnull ( m2 ) ; <nl> + m2 = d ; <nl> + } <nl> + } <nl> + assertnotnull ( m2 ) ; <nl> + <nl> + / / this actually doesn ' t really test what we need , though , because <nl> + / / i thought test harness is loading the maven classes by itself . <nl> + <nl> + tasks . classloader . loadclass ( hudson . maven . agent . abortexception . class . getname ( ) ) ; <nl> + } <nl> }
public class maven extends builder { <nl> * @ deprecated as of num . 286 <nl> * use { @ link hudson # getdescriptorbytype ( class ) } to obtain the current instance . <nl> * for compatibility , this field retains the last created { @ link descriptorimpl } . <nl> + * <nl> * / <nl> public static descriptorimpl descriptor ;
public abstract class filesystemprovisioner implements extensionpoint , describab <nl>  <nl> public abstract filesystemprovisionerdescriptor getdescriptor ( ) ; <nl>  <nl> + / * * <nl> + * <nl> + * per node , but as of now kept here to avoid interfering with the production code . <nl> + * / <nl> + public static filesystemprovisioner get ( node node ) { <nl> + return default ; <nl> + } <nl> + <nl> + <nl> / * * <nl> * a list of available file system provider types . <nl> * /
th . pane { <nl> background - repeat : no - repeat ; <nl> } <nl>  <nl> + . info { <nl> + color : black ; <nl> + font - weight : bold ; <nl> + padding - left : num px ; <nl> + min - height : num px ; <nl> + background - image : url ( " . . / images / 16x16 / go - next . gif " ) ; / * <nl> + background - position : left center ; <nl> + background - repeat : no - repeat ; <nl> + } <nl> / * = = = = = = = = = = = = = = = = = = = = = = help = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = * / <nl>  <nl> . help {
<nl> package org . jvnet . hudson . test ; <nl>  <nl> / * * <nl> + * <nl> + * we can then pin down the current hudsontestcase to the thread for easier access . <nl> + * <nl> * @ author kohsuke kawaguchi <nl> * / <nl> public class testenvironment {
<nl> # out of or in connection with the software or the use or other dealings in <nl> # the software . <nl>  <nl> + # <nl> newversionavailable = une nouvelle version de hudson ( { 0 } ) est < a href = " { 1 } " > disponible < / a > . <nl> or \ upgrade \ automatically = ou mettre ? jour automatiquement <nl> mmm a / core / src / main / resources / hudson / model / updatecenter / coreupdatemonitor / message_ja . properties <nl> ppp b / core / src / main / resources / hudson / model / updatecenter / coreupdatemonitor / message_ja . properties <nl>
<nl> # out of or in connection with the software or the use or other dealings in <nl> # the software . <nl>  <nl> + # <nl> newversionavailable = hudson \ u306e \ u65b0 \ u3057 \ u3044 \ u30d0 \ u30fc \ u30b8 \ u30e7 \ u30f3 ( { 0 } ) \ u3092 < a href = " { 1 } " > \ u30c0 \ u30a6 \ u30f3 \ u30ed \ u30fc \ u30c9 < / a > \ u3067 \ u304d \ u307e \ u3059 \ u3002 <nl> or \ upgrade \ automatically = \ u3082 \ u3057 \ u304f \ u306f \ u3001 \ u81ea \ u52d5 \ u66f4 \ u65b0 \ u3057 \ u307e \ u3059 \ u304b ? <nl> \ no newline at end of file
<nl> + package hudson . model ; <nl> + <nl> + import hudson . tasks . shell ; <nl> + import org . jvnet . hudson . test . email ; <nl> + import org . jvnet . hudson . test . hudsontestcase ; <nl> + <nl> + / * * <nl> + * @ author kohsuke kawaguchi <nl> + * / <nl> + public class directorybrowsersupporttest extends hudsontestcase { <nl> + @ email ( " http : / / www . nabble . com / status - code - 400 - viewing - or - downloading - artifact - whose - filename - contains - two - consecutive - periods - tt21407604 . html " ) <nl> + public void testdoubledots ( ) throws exception { <nl> + / / create a problematic file name in the workspace <nl> + freestyleproject p = createfreestyleproject ( ) ; <nl> + p . getbuilderslist ( ) . add ( new shell ( " touch abc . . def " ) ) ; <nl> + p . schedulebuild2 ( 0 ) . get ( ) ; <nl> + <nl> + / / can we see it ? <nl> + new webclient ( ) . goto ( " job / " + p . getname ( ) + " / ws / abc . . def " , " application / octet - stream " ) ; <nl> + <nl> + <nl> + / / / / but this should fail <nl> + / / try { <nl> + / / new webclient ( ) . goto ( " job / " + p . getname ( ) + " / ws / abc / . . / " , " application / octet - stream " ) ; <nl> + / / } catch ( failinghttpstatuscodeexception e ) { <nl> + / / assertequals ( 400 , e . getstatuscode ( ) ) ; <nl> + / / } <nl> + } <nl> + }
public abstract class hudsontestcase extends testcase { <nl> server . stop ( ) ; <nl> for ( lenientrunnable r : teardowns ) <nl> r . run ( ) ; <nl> + <nl> + <nl> + / / without this , plugins loaded in the tests will be left and interferes with the later tests . <nl> + cleanupdescriptors ( descriptor . all ) ; <nl> + cleanupdescriptors ( buildstep . publishers ) ; <nl> + cleanupdescriptors ( mavenreporters . list ) ; <nl> + <nl> hudson . cleanup ( ) ; <nl> env . dispose ( ) ; <nl> } <nl>  <nl> + private void cleanupdescriptors ( iterable < ? extends descriptor > cont ) { <nl> + classloader base = getclass ( ) . getclassloader ( ) ; <nl> + for ( iterator < ? extends descriptor > itr = cont . iterator ( ) ; itr . hasnext ( ) ; ) { <nl> + descriptor d = itr . next ( ) ; <nl> + classloader cl = d . getclass ( ) . getclassloader ( ) ; <nl> + if ( cl = = base ) continue ; <nl> + <nl> + while ( cl ! = null ) { <nl> + cl = cl . getparent ( ) ; <nl> + if ( cl = = base ) { <nl> + itr . remove ( ) ; <nl> + break ; <nl> + } <nl> + } <nl> + } <nl> + } <nl> + <nl> protected void runtest ( ) throws throwable { <nl> new javascriptengine ( null ) ; / / ensure that contextfactory is initialized <nl> context cx = contextfactory . getglobal ( ) . entercontext ( ) ;
<nl> + package org . jvnet . hudson . test . recipes ; <nl> + <nl> + import org . jvnet . hudson . test . hudsontestcase ; <nl> + import org . apache . commons . io . fileutils ; <nl> + <nl> + import java . io . file ; <nl> + import java . lang . annotation . documented ; <nl> + import static java . lang . annotation . elementtype . method ; <nl> + import java . lang . annotation . retention ; <nl> + import static java . lang . annotation . retentionpolicy . runtime ; <nl> + import java . lang . annotation . target ; <nl> + import java . net . url ; <nl> + <nl> + / * * <nl> + * installs the specified plugin before launching hudson . <nl> + * <nl> + * @ author kohsuke kawaguchi <nl> + * / <nl> + @ documented <nl> + @ recipe ( withplugin . runnerimpl . class ) <nl> + @ target ( method ) <nl> + @ retention ( runtime ) <nl> + public @ interface withplugin { <nl> + / * * <nl> + * name of the plugin . <nl> + * <nl> + * for now , this has to be one of the plugins statically available in resources <nl> + * " / plugins / name " . <nl> + * / <nl> + string value ( ) ; <nl> + <nl> + public class runnerimpl extends recipe . runner < withplugin > { <nl> + private withplugin a ; <nl> + <nl> + @ override <nl> + public void setup ( hudsontestcase testcase , withplugin recipe ) throws exception { <nl> + a = recipe ; <nl> + } <nl> + <nl> + @ override <nl> + public void decoratehome ( hudsontestcase testcase , file home ) throws exception { <nl> + url res = getclass ( ) . getclassloader ( ) . getresource ( " plugins / " + a . value ( ) ) ; <nl> + fileutils . copyurltofile ( res , new file ( home , " plugins / " + a . value ( ) ) ) ; <nl> + } <nl> + } <nl> + } <nl> mmm a / test / src / test / java / hudson / pluginmanagertest . java <nl> ppp b / test / src / test / java / hudson / pluginmanagertest . java <nl>
<nl> + package hudson . model ; <nl> + <nl> + import hudson . triggers . safetimertask ; <nl> + <nl> + import java . lang . management . memorypoolmxbean ; <nl> + import java . lang . management . memorytype ; <nl> + import java . lang . management . memoryusage ; <nl> + import java . lang . management . managementfactory ; <nl> + import java . util . list ; <nl> + import java . util . arraylist ; <nl> + <nl> + / * * <nl> + * <nl> + * @ author kohsuke kawaguchi <nl> + * / <nl> + public class memoryusagemonitor extends safetimertask { <nl> + class memorygroup { <nl> + private final list < memorypoolmxbean > pools = new arraylist < memorypoolmxbean > ( ) ; <nl> + <nl> + memorygroup ( list < memorypoolmxbean > pools , memorytype type ) { <nl> + for ( memorypoolmxbean pool : pools ) { <nl> + if ( pool . gettype ( ) = = type ) <nl> + this . pools . add ( pool ) ; <nl> + } <nl> + } <nl> + <nl> + public string metrics ( ) { <nl> + long used = num ; <nl> + long max = num ; <nl> + long cur = num ; <nl> + for ( memorypoolmxbean pool : pools ) { <nl> + memoryusage usage = pool . getcollectionusage ( ) ; <nl> + if ( usage = = null ) continue ; / / not available <nl> + used + = usage . getused ( ) ; <nl> + max + = usage . getmax ( ) ; <nl> + <nl> + usage = pool . getusage ( ) ; <nl> + if ( usage = = null ) continue ; / / not available <nl> + cur + = usage . getused ( ) ; <nl> + } <nl> + <nl> + / / b - > kb <nl> + used / = num ; <nl> + max / = num ; <nl> + cur / = num ; <nl> + <nl> + return string . format ( " % d / % d / % d ( % d % % ) " , used , cur , max , used * 100 / max ) ; <nl> + } <nl> + } <nl> + <nl> + private final memorygroup heap ; <nl> + private final memorygroup nonheap ; <nl> + <nl> + public memoryusagemonitor ( ) { <nl> + list < memorypoolmxbean > pools = managementfactory . getmemorypoolmxbeans ( ) ; <nl> + heap = new memorygroup ( pools , memorytype . heap ) ; <nl> + nonheap = new memorygroup ( pools , memorytype . non_heap ) ; <nl> + } <nl> + <nl> + protected void dorun ( ) { <nl> + system . out . printf ( " % s \ t % s\n " , heap . metrics ( ) , nonheap . metrics ( ) ) ; <nl> + } <nl> + }
public class queuetest extends hudsontestcase { <nl> q . load ( ) ; <nl> assertequals ( 0 , q . getitems ( ) . length ) ; <nl> } <nl> + <nl> + public static final class fileitempersistencetestservlet extends httpservlet { <nl> + protected void doget ( httpservletrequest req , httpservletresponse resp ) throws servletexception , ioexception { <nl> + resp . setcontenttype ( " text / html " ) ; <nl> + resp . getwriter ( ) . println ( <nl> + " < html > < body > < form action = ' / ' method = post name = main enctype = ' multipart / form - data ' > " + <nl> + " < input type = file name = test > < input type = submit > " + <nl> + " < / form > < / body > < / html > " <nl> + ) ; <nl> + } <nl> + <nl> + protected void dopost ( httpservletrequest req , httpservletresponse resp ) throws servletexception , ioexception { <nl> + try { <nl> + servletfileupload f = new servletfileupload ( new diskfileitemfactory ( ) ) ; <nl> + list v = f . parserequest ( req ) ; <nl> + assertequals ( 1 , v . size ( ) ) ; <nl> + xstream2 xs = new xstream2 ( ) ; <nl> + system . out . println ( xs . toxml ( v . get ( 0 ) ) ) ; <nl> + } catch ( fileuploadexception e ) { <nl> + throw new servletexception ( e ) ; <nl> + } <nl> + } <nl> + } <nl> + <nl> + public void testfileitempersistence ( ) throws exception { <nl> + <nl> + byte [ ] testdata = new byte [ 1024 ] ; <nl> + for ( int i = 0 ; i < testdata . length ; i + + ) testdata [ i ] = ( byte ) i ; <nl> + <nl> + <nl> + server server = new server ( ) ; <nl> + socketconnector connector = new socketconnector ( ) ; <nl> + server . addconnector ( connector ) ; <nl> + <nl> + servlethandler handler = new servlethandler ( ) ; <nl> + handler . addservletwithmapping ( new servletholder ( new fileitempersistencetestservlet ( ) ) , " / " ) ; <nl> + server . addhandler ( handler ) ; <nl> + <nl> + server . start ( ) ; <nl> + <nl> + localport = connector . getlocalport ( ) ; <nl> + <nl> + try { <nl> + webclient wc = new webclient ( ) ; <nl> + htmlpage p = ( htmlpage ) wc . getpage ( " http : / / localhost : " + localport + ' / ' ) ; <nl> + htmlform f = p . getformbyname ( " main " ) ; <nl> + htmlfileinput input = ( htmlfileinput ) f . getinputbyname ( " test " ) ; <nl> + input . setdata ( testdata ) ; <nl> + f . submit ( ) ; <nl> + } finally { <nl> + server . stop ( ) ; <nl> + } <nl> + } <nl> + <nl> }
<nl> + package hudson . remoting ; <nl> + <nl> + import org . objectweb . asm . classreader ; <nl> + import org . objectweb . asm . attrs . stackmapattribute ; <nl> + <nl> + import java . io . ioexception ; <nl> + <nl> + / * * <nl> + * @ author kohsuke kawaguchi <nl> + * / <nl> + public class prefetchtest extends rmitestbase { <nl> + public void testprefetch ( ) throws exception { <nl> + verifytask vt = new verifytask ( ) ; <nl> + asserttrue ( channel . preloadjar ( vt , classreader . class ) ) ; <nl> + assertfalse ( channel . preloadjar ( vt , classreader . class ) ) ; <nl> + <nl> + system . out . println ( channel . call ( vt ) ) ; <nl> + } <nl> + <nl> + private static class verifytask implements callable < string , ioexception > { <nl> + public string call ( ) throws ioexception { <nl> + stackmapattribute sma = new stackmapattribute ( ) ; <nl> + return which . jarfile ( sma . getclass ( ) ) . getpath ( ) ; <nl> + } <nl> + } <nl> + }
<nl> + < ! - - <nl> + just for reference , until a solution is found - - > <nl> + <nl> < j : jelly xmlns : j = " jelly : core " > <nl> < j : new var = " h " classname = " hudson . functions " / > < ! - - instead of jsp functions - - > <nl> < div > <nl> mmm / dev / null <nl> ppp b / war / resources / help / _cvs / cvspass_de . html <nl>
import java . util . set ; <nl> * <nl> * @ author kohsuke kawaguchi <nl> * / <nl> + <nl> public class globalmatrixauthorizationstrategy extends authorizationstrategy { <nl> private transient acl acl = new aclimpl ( ) ; <nl>  <nl>
<nl> < bug pattern = " dm_gc " / > <nl> < / match > <nl>  <nl> + < match > <nl> + < ! - - <nl> + < class name = " hudson . tasks . buildstep " / > <nl> + < bug pattern = " ic_superclass_uses_subclass_during_initialization " / > <nl> + < / match > <nl> + <nl> < / findbugsfilter > <nl> \ no newline at end of file
<nl> + package hudson ; <nl> + <nl> + import hudson . model . action ; <nl> + <nl> + / * * <nl> + * represents a workspace snapshot created by { @ link filesystemprovisioner } . <nl> + * <nl> + * < p > <nl> + * this class encapsulates a logic to use the snapshot elsewhere . <nl> + * <nl> + * < p > <nl> + * <nl> + * perhaps when a new build is started ? <nl> + * <nl> + * @ author kohsuke kawaguchi <nl> + * / <nl> + public abstract class workspacesnapshot implements action { <nl> + public abstract void restoreto ( filepath dst ) ; <nl> + }
public final class hudson extends view implements itemgroup < toplevelitem > , node , <nl> } . process ( ) ; <nl> } <nl>  <nl> + / * * <nl> + * performs syntactical check on the remote fs for slaves . <nl> + * <nl> + * <nl> + * / <nl> + public void doremotefscheck ( staplerrequest req , staplerresponse rsp , @ queryparameter ( " value " ) final string value ) throws ioexception , servletexception { <nl> + new formfieldvalidator ( req , rsp , false ) { <nl> + protected void check ( ) throws ioexception , servletexception { <nl> + if ( util . fixemptyandtrim ( value ) = = null ) { <nl> + error ( " remote directory is mandatory " ) ; <nl> + return ; <nl> + } <nl> + <nl> + if ( value . startswith ( " \ \ \ \ " ) | | value . startswith ( " / net / " ) ) { <nl> + warning ( " are you sure you want to use network mounted file system for fs root ? " + <nl> + " note that this directory needs not be visible to the master . " ) ; <nl> + return ; <nl> + } <nl> + <nl> + ok ( ) ; <nl> + } <nl> + } . process ( ) ; <nl> + } <nl> + <nl> / * * <nl> * serves static resources placed along with jelly view files . <nl> * < p > <nl> mmm a / core / src / main / resources / hudson / model / hudson / configureexecutors . jelly <nl> ppp b / core / src / main / resources / hudson / model / hudson / configureexecutors . jelly <nl>
public final class computerset implements modelobject { <nl> rsp . sendredirect ( " . " ) ; <nl> } <nl>  <nl> + / * * <nl> + * triggers the schedule update now . <nl> + * <nl> + * <nl> + * / <nl> + public void doupdatenow ( staplerrequest req , staplerresponse rsp ) throws ioexception , servletexception { <nl> + hudson . getinstance ( ) . checkpermission ( hudson . administer ) ; <nl> + <nl> + for ( nodemonitor nodemonitor : nodemonitor . getall ( ) ) { <nl> + thread t = nodemonitor . triggerupdate ( ) ; <nl> + t . setname ( nodemonitor . getcolumncaption ( ) ) ; <nl> + } <nl> + rsp . forwardtopreviouspage ( req ) ; <nl> + } <nl> + <nl> public api getapi ( ) { <nl> return new api ( this ) ; <nl> } <nl> mmm a / core / src / main / java / hudson / node_monitors / nodemonitor . java <nl> ppp b / core / src / main / java / hudson / node_monitors / nodemonitor . java <nl>
public class diskspacemonitor extends nodemonitor { <nl> filepath p = c . getnode ( ) . getrootpath ( ) ; <nl> if ( p = = null ) return null ; <nl>  <nl> - return p . act ( new getusablespace ( ) ) ; <nl> + long size = p . act ( new getusablespace ( ) ) ; <nl> + if ( size ! = null & & size ! = 0 & & size / ( 1024 * 1024 * 1024 ) = = 0 ) { <nl> + <nl> + if ( ! c . istemporarilyoffline ( ) ) { <nl> + logger . warning ( " making " + c . getname ( ) + " offline temporarily due to the lack of disk space " ) ; <nl> + c . settemporarilyoffline ( true ) ; <nl> + } <nl> + } <nl> + return size ; <nl> } <nl>  <nl> public string getdisplayname ( ) { <nl>
<nl> + # definition of the ips package . <nl> + # see http : / / wiki . updatecenter . java . net / wiki . jsp ? page = uc20 . docs . packaging for more about this <nl> + <nl> + mode755 = { " mode " : " 0755 " } <nl> + <nl> + pkg = { <nl> + " name " : " hudson " , <nl> + " version " : " 1 . 227 , 0 - 0 " , <nl> + " attributes " : { <nl> + " pkg . summary " : " hudson " , <nl> + " pkg . description " : " extensible continuous integration system " , <nl> + } , <nl> + " dirs " : { } , <nl> + " files " : { } <nl> + } <nl> + <nl> + <nl> + # add directories recursively , kind of like " mkdir - p " <nl> + def mkdirs ( path ) : <nl> + head = " " <nl> + for i in path . split ( ' / ' ) : <nl> + if len ( i ) = = 0 : <nl> + continue <nl> + if len ( head ) > num : <nl> + head + = ' / ' <nl> + head + = i <nl> + if head not in pkg [ " dirs " ] : <nl> + print ' adding % s ' % head <nl> + pkg [ " dirs " ] [ head ] = mode755 <nl> + <nl> + # add a file , and create parent directories if necessary <nl> + def addfile ( fullpath , properties = { } ) : <nl> + components = fullpath . rpartition ( ' / ' ) <nl> + mkdirs ( components [ 0 ] ) <nl> + <nl> + mkdirs ( " / var / run / hudson " ) <nl> + mkdirs ( " / var / log / hudson " ) <nl> + addfile ( " / usr / local / bin / hudson . war " ) <nl> + addfile ( " / var / svc / manifest / local / hudson . xml " ) <nl> + # <nl> + # see http : / / www . pauloswald . com / article / 29 / hudson - solaris - smf - manifest <nl> mmm / dev / null <nl> ppp b / ips / readme . txt <nl>
<nl> < ! - - <nl> config page <nl> + <nl> + <nl> - - > <nl> < j : jelly xmlns : j = " jelly : core " xmlns : st = " jelly : stapler " xmlns : d = " jelly : define " xmlns : l = " / lib / layout " xmlns : t = " / lib / hudson " xmlns : s = " / lib / form " > <nl> < l : layout permission = " $ { app . administer } " norefresh = " true " >
import groovy . lang . script ; <nl> * <nl> * @ author kohsuke kawaguchi <nl> * / <nl> + <nl> public abstract class closurescript extends script { <nl> private groovyobject delegate ; <nl>  <nl> mmm a / debian / changelog <nl> ppp b / debian / changelog <nl>
public class functions { <nl> return stapler . getcurrentrequest ( ) . getcontextpath ( ) + ' / ' + iturl + urlname ; <nl> } <nl>  <nl> + / * * <nl> + * escapes the character unsafe for e - mail address . <nl> + * see http : / / en . wikipedia . org / wiki / e - mail_address for the details , <nl> + * but here the vocabulary is even more restricted . <nl> + * / <nl> + public static string toemailsafestring ( string projectname ) { <nl> + <nl> + stringbuilder buf = new stringbuilder ( projectname . length ( ) ) ; <nl> + for ( int i = 0 ; i < projectname . length ( ) ; i + + ) { <nl> + char ch = projectname . charat ( i ) ; <nl> + if ( ( ' a ' < = ch & & ch < = ' z ' ) <nl> + | | ( ' z ' < = ch & & ch < = ' z ' ) <nl> + | | ( ' 0 ' < = ch & & ch < = ' 9 ' ) <nl> + | | " - _ . " . indexof ( ch ) > = 0 ) <nl> + buf . append ( ch ) ; <nl> + else <nl> + buf . append ( ' _ ' ) ; / / escape <nl> + } <nl> + return projectname ; <nl> + } <nl> + <nl> private static final pattern scheme = pattern . compile ( " [ a - z ] + : / / . + " ) ; <nl> } <nl> mmm a / core / src / main / java / hudson / model / hudson . java <nl> ppp b / core / src / main / java / hudson / model / hudson . java <nl>
public class subversionscm extends scm implements serializable { <nl> * <nl> * this code is fairly ugly because of the way svnkit handles credentials . <nl> * / <nl> + <nl> public void dopostcredential ( staplerrequest req , staplerresponse rsp ) throws ioexception , servletexception { <nl> hudson . getinstance ( ) . checkpermission ( hudson . administer ) ; <nl>  <nl>
public final class slavecomputer extends computer { <nl> * if still connected , disconnect . <nl> * / <nl> private void closechannel ( ) { <nl> - synchronized ( channellock ) { <nl> - channel c = channel ; <nl> - channel = null ; <nl> - isunix = null ; <nl> - if ( c ! = null ) { <nl> - try { <nl> - c . close ( ) ; <nl> - } catch ( ioexception e ) { <nl> - logger . log ( level . severe , " failed to terminate channel to " + getdisplayname ( ) , e ) ; <nl> - } <nl> + <nl> + channel c = channel ; <nl> + channel = null ; <nl> + isunix = null ; <nl> + if ( c ! = null ) { <nl> + try { <nl> + c . close ( ) ; <nl> + } catch ( ioexception e ) { <nl> + logger . log ( level . severe , " failed to terminate channel to " + getdisplayname ( ) , e ) ; <nl> } <nl> } <nl> } <nl>
public final class slavecomputer extends computer { <nl> launcher = ( ( slave ) node ) . getlauncher ( ) ; <nl>  <nl> / / maybe the configuration was changed to relaunch the slave , so try to re - launch now . <nl> - launch ( ) ; <nl> + / / launch ( ) ; this can cause a partially constructed object to leak out of the constructor <nl> + <nl> } <nl>  <nl> private static final logger logger = logger . getlogger ( slavecomputer . class . getname ( ) ) ;
import hudson . triggers . safetimertask ; <nl> * / <nl> public class slavereconnectionwork extends safetimertask { <nl> protected void dorun ( ) { <nl> - for ( slave s : hudson . getinstance ( ) . getslaves ( ) ) { <nl> - computerimpl c = s . getcomputer ( ) ; <nl> - if ( c = = null ) / / shouldn ' t happen , but let ' s be defensive <nl> - continue ; <nl> - if ( c . isoffline ( ) & & c . isstartsupported ( ) ) <nl> - c . tryreconnect ( ) ; <nl> + / / use a weak hashmap <nl> + map < slave , long > nextcheck = new weakhashmap < slave , long > ( ) ; <nl> + for ( slave s : hudson . getinstance ( ) . getslaves ( ) ) { <nl> + if ( ! nextcheck . containskey ( s ) | | system . currenttimemillis ( ) > nextcheck . get ( s ) ) { <nl> + final queue queue = hudson . getinstance ( ) . getqueue ( ) ; <nl> + boolean hasjob = false ; <nl> + for ( executor exec : s . getcomputer ( ) . getexecutors ( ) ) { <nl> + if ( ! exec . isidle ( ) ) { <nl> + hasjob = true ; <nl> + break ; <nl> + } <nl> + } <nl> + <nl> + state state = new state ( queue . getitems ( ) . length > num , hasjob ) ; <nl> + / / at the moment i don ' t trust strategies to wait more than num minutes <nl> + / / strategies need to wait at least one minute <nl> + final long waitinmins = math . min ( 1 , math . max ( 60 , s . getavailabilitystrategy ( ) . check ( s , state ) ) ) ; <nl> + nextcheck . put ( s , system . currenttimemillis ( ) + num * num * waitinmins ) ; <nl> + } <nl> } <nl> } <nl> }
public class subversionscm extends scm implements serializable { <nl> } else { <nl> item = parser . getfileitem ( kind . equals ( " publickey " ) ? " privatekey " : " certificate " ) ; <nl> keyfile = file . createtempfile ( " hudson " , " key " ) ; <nl> - if ( item ! = null ) <nl> + if ( item ! = null ) { <nl> try { <nl> item . write ( keyfile ) ; <nl> } catch ( exception e ) { <nl> throw new ioexception2 ( e ) ; <nl> } <nl> + if ( puttykey . isputtykeyfile ( keyfile ) ) { <nl> + <nl> + logger . info ( " converting " + keyfile + " from putty format to openssh format " ) ; <nl> + new puttykey ( keyfile , null ) . toopenssh ( keyfile ) ; <nl> + } <nl> + } <nl> } <nl>  <nl> svnrepository repository = null ;
public abstract class abstractbuild < p extends abstractproject < p , r > , r extends abs <nl> public string getwhykeeplog ( ) { <nl> / / if any of the downstream project is configured with ' keep dependency component ' , <nl> / / we need to keep this log <nl> + outer : <nl> for ( abstractproject < ? , ? > p : getparent ( ) . getdownstreamprojects ( ) ) { <nl> if ( ! p . iskeepdependencies ( ) ) continue ; <nl>  <nl> + abstractbuild < ? , ? > fb = p . getfirstbuild ( ) ; <nl> + if ( fb = = null ) continue ; / / no active record <nl> + <nl> + / / is there any active build that depends on us ? <nl> for ( int i : getdownstreamrelationship ( p ) . listnumbersreverse ( ) ) { <nl> + <nl> + <nl> + if ( i < fb . getnumber ( ) ) <nl> + continue outer ; / / all the other records are younger than the first record , so pointless to search . <nl> + <nl> abstractbuild < ? , ? > b = p . getbuildbynumber ( i ) ; <nl> - if ( b ! = null & & b . iskeeplog ( ) ) <nl> + if ( b ! = null ) <nl> return messages . abstractbuild_keptbecause ( b ) ; <nl> } <nl> }
public final class mavenmodulesetbuild extends abstractbuild < mavenmoduleset , mave <nl>  <nl> performallbuildstep ( listener , project . getpublishers ( ) , true ) ; <nl> performallbuildstep ( listener , project . getproperties ( ) , true ) ; <nl> + <nl> + / / aggregate all module fingerprints to us , <nl> + / / so that dependencies between module builds can be understood as <nl> + / / dependencies between module set builds . <nl> + <nl> + / / show up in the persisted record . <nl> + mavenfingerprinter . aggregate ( mavenmodulesetbuild . this ) ; <nl> } <nl>  <nl> @ override <nl> mmm a / core / src / main / java / hudson / maven / reporters / mavenfingerprinter . java <nl> ppp b / core / src / main / java / hudson / maven / reporters / mavenfingerprinter . java <nl>
<nl> + < j : jelly xmlns : j = " jelly : core " xmlns : st = " jelly : stapler " xmlns : d = " jelly : define " xmlns : l = " / lib / layout " xmlns : t = " / lib / hudson " xmlns : f = " / lib / form " xmlns : i = " jelly : fmt " > <nl> + < l : layout title = " $ { it . displayname } " > <nl> + < st : include page = " sidepanel . jelly " / > <nl> + < l : main - panel > <nl> + < h1 > tweak launch parameters < / h1 > <nl> + < p > <nl> + this page allows you to tweak the jvm parameters when launching jnlp slave agents . <nl> + < ! - - <nl> + < / p > <nl> + < / l : main - panel > <nl> + < / l : layout > <nl> + < / j : jelly > <nl> mmm a / core / src / main / resources / hudson / model / computer / index . jelly <nl> ppp b / core / src / main / resources / hudson / model / computer / index . jelly <nl>
<nl> < / td > <nl> < / j : if > <nl> < / tr > <nl> + < ! - - <nl> < j : if test = " $ { help ! = null } " > <nl> < f : helparea / > <nl> < / j : if >
public final class computerset implements modelobject { <nl> public api getapi ( ) { <nl> return new api ( this ) ; <nl> } <nl> + <nl> + / * * <nl> + * just to force the execution of the static initializer . <nl> + * / <nl> + public static void initialize ( ) { } <nl> + <nl> + static { <nl> + / / create all instances <nl> + arraylist < nodemonitor > r = new arraylist < nodemonitor > ( ) ; <nl> + for ( descriptor < nodemonitor > d : nodemonitor . list ) <nl> + try { <nl> + r . add ( d . newinstance ( null , null ) ) ; <nl> + } catch ( formexception e ) { <nl> + <nl> + } <nl> + monitors = r ; <nl> + } <nl> } <nl> mmm a / core / src / main / java / hudson / triggers / trigger . java <nl> ppp b / core / src / main / java / hudson / triggers / trigger . java <nl>
<nl> $ { % check the health of slaves and controls them . } <nl> < / local : feature > <nl> < / j : if > <nl> + < ! - - <nl> + < j : foreach var = " m " items = " $ { it . managementlinks } " > <nl> + < local : feature icon = " $ { m . iconfilename } " href = " $ { m . urlname } " title = " $ { m . displayname } " > <nl> + $ { m . description } <nl> + < / local : feature > <nl> + < / j : foreach > <nl> + <nl> < j : choose > <nl> < j : when test = " $ { it . quietingdown } " > <nl> < local : feature icon = " system - log - out . gif " href = " cancelquietdown " title = " $ { % cancel shutdown } " / >
public abstract class mavenabstractartifactrecord < t extends abstractbuild < ? , ? > > <nl> else <nl> return result . color ; <nl> } <nl> + <nl> + <nl> + public final void doindex ( staplerrequest req , staplerresponse rsp ) throws ioexception { <nl> + rsp . setcontenttype ( " text / plain ; charset = utf - 8 " ) ; <nl> + getlog ( ) . writelogto ( 0 , rsp . getwriter ( ) ) ; <nl> + } <nl> } <nl>  <nl> / * * <nl>
<nl> < th > $ { % status } < / th > <nl> < th > < st : nbsp / > < / th > <nl> < / tr > <nl> - < j : foreach var = " b " items = " $ { attrs . builds } " > <nl> + < ! - - <nl> + < j : foreach var = " b " items = " $ { h . sublist ( attrs . builds , 50 ) } " > <nl> < tr > <nl> < td data = " $ { b . iconcolor . ordinal ( ) } " > <nl> < a href = " $ { rooturl } / $ { b . url } " >
public abstract class project < p extends project < p , b > , b extends build < p , b > > <nl> return null ; <nl> } <nl>  <nl> + <nl> private void _builddependencygraph ( collection < ? > possibledependecydeclarers , dependencygraph graph ) { <nl> for ( object o : possibledependecydeclarers ) { <nl> if ( o instanceof dependecydeclarer ) {
<nl> config page <nl> - - > <nl> < j : jelly xmlns : j = " jelly : core " xmlns : st = " jelly : stapler " xmlns : d = " jelly : define " xmlns : l = " / lib / layout " xmlns : t = " / lib / hudson " xmlns : f = " / lib / form " xmlns : i = " jelly : fmt " > <nl> - < l : layout norefresh = " true " > <nl> + < ! - - <nl> + < l : layout norefresh = " true " permission = " $ { app . administer } " > <nl> < st : include page = " sidepanel . jelly " / > <nl> < l : main - panel > <nl> < f : form method = " post " action = " configsubmit " >
import java . util . list ; <nl> * @ author kohsuke kawaguchi <nl> * / <nl> public final class computerset implements modelobject { <nl> + private static volatile list < nodemonitor > monitors = collections . emptylist ( ) ; <nl> + <nl> + public computerset ( ) { <nl> + if ( monitors . isempty ( ) ) { <nl> + / / create all instances when requested for the first time . <nl> + arraylist < nodemonitor > r = new arraylist < nodemonitor > ( ) ; <nl> + for ( descriptor < nodemonitor > d : nodemonitor . list ) <nl> + try { <nl> + r . add ( d . newinstance ( null ) ) ; <nl> + } catch ( formexception e ) { <nl> + <nl> + } <nl> + monitors = r ; <nl> + } <nl> + } <nl> + <nl> public string getdisplayname ( ) { <nl> return " nodes " ; <nl> } <nl>  <nl> public list < nodemonitor > get_monitors ( ) { <nl> - return null ; <nl> + return monitors ; <nl> } <nl>  <nl> public computer [ ] get_all ( ) { <nl> mmm / dev / null <nl> ppp b / core / src / main / java / hudson / node_monitors / diskspacemonitor . java <nl>
public class queue { <nl> / * * <nl> * unique name of this task . <nl> * @ see hudson . model . item # getname ( ) <nl> + * <nl> + * <nl> * / <nl> string getname ( ) ;
abstract class abstractcvsfamilyscm extends scm { <nl> map < string , string > env = new hashmap < string , string > ( ) ; <nl> if ( ! overrideonly ) <nl> env . putall ( envvars . masterenvvars ) ; <nl> - buildenvvars ( env ) ; <nl> + buildenvvars ( null / * <nl> return env ; <nl> } <nl> } <nl> mmm a / core / src / main / java / hudson / scm / cvsscm . java <nl> ppp b / core / src / main / java / hudson / scm / cvsscm . java <nl>
public final class build extends abstractbuild < project , build > { <nl> } <nl>  <nl> public api getapi ( final staplerrequest req ) { <nl> + <nl> class build { <nl> public int number = getnumber ( ) ; <nl> public calendar timestamp = gettimestamp ( ) ;
<nl> + package hudson ; <nl> + <nl> + import junit . framework . testcase ; <nl> + <nl> + / * * <nl> + * @ author kohsuke kawaguchi <nl> + * / <nl> + public class filepathtest extends / * rmitestbase * / testcase { <nl> + public void testdummy ( ) { <nl> + <nl> + / / test code is not . <nl> + } <nl> + <nl> + / / / * * <nl> + / / * copy zero files . <nl> + / / * / <nl> + / / public void testemptycopy ( ) throws exception { <nl> + / / file src = util . createtempdir ( ) ; <nl> + / / file dst = util . createtempdir ( ) ; <nl> + / / src . deleteonexit ( ) ; <nl> + / / dst . deleteonexit ( ) ; <nl> + / / <nl> + / / new filepath ( src ) . copyrecursiveto ( " * * / * " , new filepath ( channel , dst . getpath ( ) ) ) ; <nl> + / / } <nl> + } <nl> mmm a / remoting / src / main / java / hudson / remoting / proxyoutputstream . java <nl> ppp b / remoting / src / main / java / hudson / remoting / proxyoutputstream . java <nl>
public class mavenbuild extends abstractbuild < mavenmodule , mavenbuild > { <nl> / / m2_home <nl> args . add ( mvn . getmavenhome ( ) ) ; <nl>  <nl> - / / remoting . jar <nl> - args . add ( which . jarfile ( launcher . class ) . getpath ( ) ) ; <nl> + / / remoting . jar <nl> + args . add ( launcher . getchannel ( ) . call ( new getremotingjar ( ) ) ) ; <nl> / / interceptor . jar <nl> args . add ( ismaster ? <nl> which . jarfile ( hudson . maven . agent . pluginmanagerinterceptor . class ) . getabsolutepath ( ) :
public final class slave implements node , serializable { <nl> private static final long serialversionuid = num l ; <nl> } <nl>  <nl> - private static class remotechannellaunchcallable implements callable < integer , ioexception > { <nl> + private static class remotechannellaunchcallable implements callable < outputstream , ioexception > { <nl> private final string [ ] cmd ; <nl> - private final pipe in ; <nl> private final pipe out ; <nl> private final string workdir ; <nl> + private final outputstream err ; <nl>  <nl> - public remotechannellaunchcallable ( string [ ] cmd , pipe in , pipe out , string workdir ) { <nl> + public remotechannellaunchcallable ( string [ ] cmd , pipe out , outputstream err , string workdir ) { <nl> this . cmd = cmd ; <nl> - this . in = in ; <nl> this . out = out ; <nl> + this . err = new remoteoutputstream ( err ) ; <nl> this . workdir = workdir ; <nl> } <nl>  <nl> - public integer call ( ) throws ioexception { <nl> - proc p = new locallauncher ( tasklistener . null ) . launch ( cmd , null , in . getin ( ) , out . getout ( ) , <nl> - workdir = = null ? null : new filepath ( new file ( workdir ) ) ) ; <nl> - return p . join ( ) ; <nl> + public outputstream call ( ) throws ioexception { <nl> + process p = runtime . getruntime ( ) . exec ( cmd , null , workdir = = null ? null : new file ( workdir ) ) ; <nl> + <nl> + new streamcopythread ( " stdin copier for remote agent on " + cmd , <nl> + p . getinputstream ( ) , out . getout ( ) ) . start ( ) ; <nl> + new streamcopythread ( " stderr copier for remote agent on " + cmd , <nl> + p . geterrorstream ( ) , err ) . start ( ) ; <nl> + <nl> + <nl> + <nl> + return new remoteoutputstream ( p . getoutputstream ( ) ) ; <nl> } <nl>  <nl> private static final long serialversionuid = num l ;
public final class pluginwrapper { <nl> return name . endswith ( " . jar " ) ; <nl> } <nl> } ; <nl> + <nl> + / * * <nl> + * used to load classes from dependency plugins . <nl> + * / <nl> + final class dependencyclassloader extends classloader { <nl> + public dependencyclassloader ( classloader parent ) { <nl> + super ( parent ) ; <nl> + } <nl> + <nl> + protected class < ? > findclass ( string name ) throws classnotfoundexception { <nl> + pluginmanager m = hudson . getinstance ( ) . getpluginmanager ( ) ; <nl> + for ( dependency dep : dependencies ) { <nl> + pluginwrapper p = m . getplugin ( dep . shortname ) ; <nl> + if ( p ! = null ) <nl> + try { <nl> + p . classloader . loadclass ( name ) ; <nl> + } catch ( classnotfoundexception _ ) { <nl> + / / try next <nl> + } <nl> + } <nl> + <nl> + throw new classnotfoundexception ( name ) ; <nl> + } <nl> + <nl> + <nl> + } <nl> }
public final class slave implements node , serializable { <nl> } <nl> } ) ; <nl> channel . addlistener ( listener ) ; <nl> + <nl> + { / / send jars that we need for our operations <nl> + <nl> + printwriter log = new printwriter ( launchlog , true ) ; <nl> + filepath dst = new filepath ( channel , getnode ( ) . getremotefs ( ) ) ; <nl> + log . println ( " copying maven - agent . jar " ) ; <nl> + new filepath ( which . jarfile ( main . class ) ) . copyto ( dst . child ( " maven - agent . jar " ) ) ; <nl> + log . println ( " copying maven - interceptor . jar " ) ; <nl> + new filepath ( which . jarfile ( pluginmanagerinterceptor . class ) ) . copyto ( dst . child ( " maven - interceptor . jar " ) ) ; <nl> + } <nl> + <nl> + / / prevent others from seeing a channel that ' s not properly initialized yet <nl> + this . channel = channel ; <nl> } <nl> hudson . getinstance ( ) . getqueue ( ) . schedulemaintenance ( ) ; <nl> }
<nl> + < ! - - <nl> + textbox that can be expanded into text area <nl> + <nl> + < input class = " setting - input $ { h . ifthenelse ( attrs . checkurl ! = null , ' validated ' , ' ' ) } " name = " $ { attrs . name } " <nl> + type = " text " value = " $ { attrs . value } " checkurl = " $ { attrs . checkurl } " / > <nl> + <nl> + <nl> + - - > <nl> + < j : jelly xmlns : j = " jelly : core " xmlns : d = " jelly : define " > <nl> + < table border = " 0 " style = " width : 100 % " cellspacing = " 0 " cellpadding = " 0 " > <nl> + < j : choose > <nl> + < j : when test = " $ { h . ismultiline ( attrs . value ) } " > <nl> + < ! - - multiline text area to begin with - - > <nl> + < textarea rows = " 8 " class = ' setting - input ' name = ' $ { attrs . name } ' > $ { attrs . value } < / textarea > <nl> + < / j : when > <nl> + < j : otherwise > <nl> + < ! - - single line textbox with expand button - - > <nl> + < tr > <nl> + < td width = " * " > <nl> + < input class = " setting - input " name = " $ { attrs . name } " id = " textarea . $ { attrs . name } " <nl> + type = " text " value = " $ { attrs . value } " / > <nl> + < / td > < td width = " 1 " > <nl> + < input type = " button " value = " & # x25bc ; " onclick = " expandtextarea ( this , ' textarea . $ { attrs . name } ' ) " / > <nl> + < / td > <nl> + < / tr > <nl> + < / j : otherwise > <nl> + < / j : choose > <nl> + < / table > <nl> + < / j : jelly > <nl> \ no newline at end of file <nl> mmm a / war / resources / scripts / hudson - behavior . js <nl> ppp b / war / resources / scripts / hudson - behavior . js <nl>
public class mavenbuild extends abstractbuild < mavenjob , mavenbuild > { <nl> this . listener = listener ; <nl> } <nl>  <nl> - public result invoke ( file ws , virtualchannel channel ) throws ioexception { <nl> + public result invoke ( file moduleroot , virtualchannel channel ) throws ioexception { <nl> try { <nl> mavenembedder embedder = mavenutil . createembedder ( listener ) ; <nl> - file pom = new file ( ws , " pom . xml " ) . getabsolutefile ( ) ; / / mavenembedder only works if it ' s absolute <nl> + file pom = new file ( moduleroot , " pom . xml " ) . getabsolutefile ( ) ; / / mavenembedder only works if it ' s absolute <nl> if ( ! pom . exists ( ) ) { <nl> listener . error ( " no pom : " + pom ) ; <nl> return result . failure ; <nl> } <nl>  <nl> + / / event monitor is mostly useless . it only provides a few strings <nl> + eventmonitor eventmonitor = new defaulteventmonitor ( new plexusloggeradapter ( new embedderloggerimpl ( listener ) ) ) ; <nl> + <nl> mavenproject p = embedder . readproject ( pom ) ; <nl> - embedder . execute ( p , arrays . aslist ( " install " ) , null , null , null , null ) ; <nl> + embedder . execute ( p , arrays . aslist ( " install " ) , <nl> + eventmonitor , <nl> + new transferlistenerimpl ( listener ) , <nl> + null , <nl> + pom . getparentfile ( ) ) ; <nl>  <nl> return null ; <nl> } catch ( mavenembedderexception e ) { <nl>
public abstract class job < jobt extends job < jobt , runt > , runt extends run < jobt , run <nl> } <nl>  <nl> public color getcolor ( ) { <nl> + <nl> result r = run . getresult ( ) ; <nl> if ( r = = result . failure | | r = = result . aborted ) <nl> return colorpalette . red ;
<nl> < j : foreach var = " log " items = " $ { h . logrecords } " > <nl> < pre > $ { h . printlogrecord ( log ) } < / pre > <nl> < / j : foreach > <nl> + <nl> + < ! - - <nl> + < div align = " right " style = " margin : 1em " > <nl> + < img src = " $ { rooturl } / images / atom . gif " border = " 0 " / > <nl> + < st : nbsp / > < st : nbsp / > < st : nbsp / > < st : nbsp / > <nl> + < a href = " logrss " > all < / a > <nl> + < st : nbsp / > < st : nbsp / > < st : nbsp / > < st : nbsp / > <nl> + < a href = " logrss ? level = severe " > & gt ; severe < / a > <nl> + < st : nbsp / > < st : nbsp / > < st : nbsp / > < st : nbsp / > <nl> + < a href = " logrss ? level = warning " > & gt ; warning < / a > <nl> + < / div > <nl> < / l : main - panel > <nl> < / l : layout > <nl> < / j : jelly >
public final class hudson extends jobcollection implements node { <nl> / * * <nl> * called once the user logs in . just forward to the top page . <nl> * / <nl> - public synchronized void dologinentry ( staplerrequest req , staplerresponse rsp ) throws ioexception { <nl> + public void dologinentry ( staplerrequest req , staplerresponse rsp ) throws ioexception { <nl> rsp . sendredirect2 ( req . getcontextpath ( ) + " / " ) ; <nl> } <nl>  <nl> / * * <nl> * called once the user logs in . just forward to the top page . <nl> * / <nl> - public synchronized void dologout ( staplerrequest req , staplerresponse rsp ) throws ioexception { <nl> + public void dologout ( staplerrequest req , staplerresponse rsp ) throws ioexception { <nl> httpsession session = req . getsession ( false ) ; <nl> if ( session ! = null ) <nl> session . invalidate ( ) ; <nl> rsp . sendredirect2 ( req . getcontextpath ( ) + " / " ) ; <nl> } <nl>  <nl> + / * * <nl> + * rss feed for log entries . <nl> + * / <nl> + public void dologrss ( staplerrequest req , staplerresponse rsp ) throws ioexception , servletexception { <nl> + list < logrecord > logs = logrecords ; <nl> + <nl> + / / filter log records based on the log level <nl> + string level = req . getparameter ( " level " ) ; <nl> + if ( level ! = null ) { <nl> + level threshold = level . parse ( level ) ; <nl> + list < logrecord > filtered = new arraylist < logrecord > ( ) ; <nl> + for ( logrecord r : logs ) { <nl> + if ( r . getlevel ( ) . intvalue ( ) > = threshold . intvalue ( ) ) <nl> + filtered . add ( r ) ; <nl> + } <nl> + logs = filtered ; <nl> + } <nl> + <nl> + rss . forwardtorss ( " hudson log " , " " , logs , new feedadapter < logrecord > ( ) { <nl> + public string getentrytitle ( logrecord entry ) { <nl> + return entry . getmessage ( ) ; <nl> + } <nl> + <nl> + public string getentryurl ( logrecord entry ) { <nl> + return " log " ; <nl> + } <nl> + <nl> + public string getentryid ( logrecord entry ) { <nl> + return string . valueof ( entry . getsequencenumber ( ) ) ; <nl> + } <nl> + <nl> + public calendar getentrytimestamp ( logrecord entry ) { <nl> + gregoriancalendar cal = new gregoriancalendar ( ) ; <nl> + cal . settimeinmillis ( entry . getmillis ( ) ) ; <nl> + return cal ; <nl> + } <nl> + } , req , rsp ) ; <nl> + } <nl> + <nl> / * * <nl> * reloads the configuration . <nl> * /
public class subversionscm extends abstractcvsfamilyscm { <nl> continue ; <nl> } <nl>  <nl> + <nl> string cmd = descriptor . getsvnexe ( ) + " log - v - - xml - - non - interactive - r " + ( prevrev + 1 ) + " : base " + module ; <nl> outputstream os = new bufferedoutputstream ( new fileoutputstream ( changelogfile ) ) ; <nl> + changelogfilecreated = true ; <nl> try { <nl> int r = launcher . launch ( cmd , env , os , build . getproject ( ) . getworkspace ( ) ) . join ( ) ; <nl> if ( r ! = 0 ) { <nl>
public class recoveredclasshelper { <nl> / / the operator delete or if there is no vftable ref , the call is before <nl> / / the operator delete call <nl> function calledfunction = addresstofunctioncallmap . get ( callingaddress ) ; <nl> - if ( calledfunction . isthunk ( ) ) { <nl> - calledfunction . getthunkedfunction ( true ) ; <nl> + if ( calledfunction ! = null ) { <nl> + if ( calledfunction . isthunk ( ) ) { <nl> + <nl> + calledfunction . getthunkedfunction ( true ) ; <nl> + } <nl> + possiblecalleddestructorset . add ( calledfunction ) ; <nl> } <nl> - possiblecalleddestructorset . add ( calledfunction ) ; <nl> } <nl> list < function > possiblecalleddestructors = <nl> new arraylist < function > ( possiblecalleddestructorset ) ;
<nl> * / <nl> package ghidra . app . plugin . core . debug . gui . memory ; <nl>  <nl> - import static ghidra . lifecycle . unfinished . * ; <nl> + import static ghidra . lifecycle . unfinished . <nl> import static org . junit . assert . * ; <nl>  <nl> import java . awt . * ;
public class debuggertracemanagerserviceplugin extends plugin <nl> return trace ; <nl> } <nl> catch ( versionexception e ) { <nl> + <nl> + e = new versionexception ( e . getversionindicator ( ) , false ) . combine ( e ) ; <nl> versionexceptionhandler . showversionerror ( null , file . getname ( ) , file . getcontenttype ( ) , <nl> - " open trace " , e ) ; <nl> + " open " , e ) ; <nl> return null ; <nl> } <nl> catch ( ioexception e ) { <nl> mmm a / ghidra / debug / framework - tracemodeling / src / main / java / ghidra / trace / database / dbtracecontenthandler . java <nl> ppp b / ghidra / debug / framework - tracemodeling / src / main / java / ghidra / trace / database / dbtracecontenthandler . java <nl>
public class debuggerwatchesprovidertest extends abstractghidraheadeddebuggergui <nl> tracememoryoperations mem = tb . trace . getmemorymanager ( ) ; <nl> bytebuffer buf = bytebuffer . allocate ( 8 ) ; <nl>  <nl> + <nl> + waitforpass ( ( ) - > assertequals ( tb . addr ( 0x00400000 ) , row . getaddress ( ) ) ) ; <nl> row . setrawvaluestring ( " 0x1234 " ) ; <nl> waitforpass ( ( ) - > { <nl> long viewsnap = tracemanager . getcurrent ( ) . getviewsnap ( ) ; <nl>
public class debuggerwatchesprovidertest extends abstractghidraheadeddebuggergui <nl> assertequals ( 0x1234 , buf . getlong ( ) ) ; <nl> } ) ; <nl>  <nl> + <nl> + waitforpass ( ( ) - > assertequals ( tb . addr ( 0x00400000 ) , row . getaddress ( ) ) ) ; <nl> row . setrawvaluestring ( " { num num num num num a bc de f0 } " ) ; <nl> waitforpass ( ( ) - > { <nl> long viewsnap = tracemanager . getcurrent ( ) . getviewsnap ( ) ; <nl> mmm a / ghidra / debug / debugger / src / test / java / ghidra / debug / flatapi / flatdebuggerapitest . java <nl> ppp b / ghidra / debug / debugger / src / test / java / ghidra / debug / flatapi / flatdebuggerapitest . java <nl>
public class elfarmrelocationfixuphandler extends relocationfixuphandler { <nl> address newimagebase ) throws memoryaccessexception , codeunitinsertionexception { <nl>  <nl> switch ( relocation . gettype ( ) ) { <nl> + <nl> case arm_elfrelocationconstants . r_arm_none : <nl> case arm_elfrelocationconstants . r_arm_abs32 : <nl> case arm_elfrelocationconstants . r_arm_rel32 : <nl> case arm_elfrelocationconstants . r_arm_glob_dat : <nl> / / case arm_elfrelocationconstants . r_arm_jump_slot : <nl> case arm_elfrelocationconstants . r_arm_relative : <nl> - case arm_elfrelocationconstants . r_arm_got_plt32 : <nl> + case arm_elfrelocationconstants . r_arm_plt32 : <nl> case arm_elfrelocationconstants . r_arm_call : <nl> case arm_elfrelocationconstants . r_arm_jump24 : <nl> case arm_elfrelocationconstants . r_arm_thm_jump24 :
public class decompilerdatatypereferencefinder implements datatypereferencefinde <nl> else { <nl> debugwriter = new nullprintwriter ( ) ; <nl> } <nl> + <nl> + <nl> + debugwriter = new nullprintwriter ( ) ; <nl> } <nl>  <nl> list < datatypereference > findusage ( ) { <nl>
public class demangledfunction extends demangledobject { <nl> / / account for register context . this class may trigger disassembly , so we need to make <nl> / / sure that the context is correctly set before that happens . also , be sure to apply <nl> / / the function to the correct address . <nl> - address = pseudodisassembler . settargecontextfordisassembly ( program , address ) ; <nl> + <nl> + <nl> + if ( ! address . isexternaladdress ( ) ) { <nl> + address = pseudodisassembler . settargecontextfordisassembly ( program , address ) ; <nl> + } <nl>  <nl> if ( ! passespreconditions ( program , address ) ) { <nl> return true ; / / eventually will not return anything
class datadb extends codeunitdb implements data { <nl> } <nl> } <nl>  <nl> - bytes = null ; <nl> - <nl> / / if this is not a component where the size could change and <nl> / / the length restricted by the following instruction / data item , assume <nl> / / the createdata method stopped fixed code units that won ' t fit from being added <nl> - if ( ! ( basedatatype instanceof composite | | basedatatype instanceof arraydatatype ) ) { <nl> - return ; <nl> - } <nl> + / / <nl> + <nl> + / / if the data organization changing could be detected , this could be done . <nl> + / / <nl> + / / if ( ! ( basedatatype instanceof composite | | basedatatype instanceof arraydatatype ) ) { <nl> + / / return ; <nl> + / / } <nl>  <nl> / / this is potentially expensive ! so only do if necessary <nl> / / see if the datatype length is restricted by a following codeunit <nl>
public abstract class debuggerreadsmemorytrait { <nl> } <nl> } <nl>  <nl> - protected class forcaptureenabledtracelistener extends tracedomainobjectlistener { <nl> - public forcaptureenabledtracelistener ( ) { <nl> + protected class forcapturetracelistener extends tracedomainobjectlistener { <nl> + public forcapturetracelistener ( ) { <nl> listenfor ( tracesnapshotchangetype . added , this : : snapshotadded ) ; <nl> + listenfor ( tracememorystatechangetype . changed , this : : memstatechanged ) ; <nl> } <nl>  <nl> private void snapshotadded ( tracesnapshot snapshot ) { <nl> actioncaptureselected . updateenabled ( null ) ; <nl> } <nl> + <nl> + private void memstatechanged ( traceaddresssnaprange range , tracememorystate oldisnull , <nl> + tracememorystate newstate ) { <nl> + if ( current . getview ( ) = = null ) { <nl> + return ; <nl> + } <nl> + if ( ! range . getlifespan ( ) . contains ( current . getsnap ( ) ) ) { <nl> + return ; <nl> + } <nl> + <nl> + repaintpanel ( ) ; <nl> + <nl> + if ( newstate = = tracememorystate . unknown ) { <nl> + doautoread ( ) ; <nl> + } <nl> + } <nl> } <nl>  <nl> protected class foraccessrecorderlistener implements tracerecorderlistener { <nl>
public class debuggermemorybytesprovidertest extends abstractghidraheadeddebugge <nl> } <nl>  <nl> @ test <nl> + @ ignore ( " <nl> public void testeditlivebyteswritestarget ( ) throws exception { <nl> createtestmodel ( ) ; <nl> mb . createtestprocessesandthreads ( ) ; <nl>
public class debuggermemorybytesprovidertest extends abstractghidraheadeddebugge <nl> } <nl>  <nl> @ test <nl> - @ ignore <nl> + @ ignore ( " <nl> public void testeditpastbyteswritesnottarget ( ) throws exception { <nl> createtestmodel ( ) ; <nl> mb . createtestprocessesandthreads ( ) ; <nl>
public class debuggermemorybytesprovidertest extends abstractghidraheadeddebugge <nl> } <nl>  <nl> @ test <nl> - @ ignore <nl> + @ ignore ( " <nl> public void testpastelivebyteswritestarget ( ) throws exception { <nl> createtestmodel ( ) ; <nl> mb . createtestprocessesandthreads ( ) ;
<nl> + / * # # # <nl> + * ip : ghidra <nl> + * <nl> + * licensed under the apache license , version num . 0 ( the " license " ) ; <nl> + * you may not use this file except in compliance with the license . <nl> + * you may obtain a copy of the license at <nl> + * <nl> + * http : / / www . apache . org / licenses / license - 2 . 0 <nl> + * <nl> + * unless required by applicable law or agreed to in writing , software <nl> + * distributed under the license is distributed on an " as is " basis , <nl> + * without warranties or conditions of any kind , either express or implied . <nl> + * see the license for the specific language governing permissions and <nl> + * limitations under the license . <nl> + * / <nl> + package agent . dbgeng . manager . cmd ; <nl> + <nl> + import java . util . arraylist ; <nl> + import java . util . list ; <nl> + <nl> + import agent . dbgeng . dbgeng . debugexceptionfilterinformation ; <nl> + import agent . dbgeng . jna . dbgeng . dbgengnative . debug_exception_filter_parameters ; <nl> + import agent . dbgeng . manager . impl . dbgmanagerimpl ; <nl> + <nl> + public class dbglistexceptionfilterscommand <nl> + extends abstractdbgcommand < list < debug_exception_filter_parameters > > { <nl> + private list < debug_exception_filter_parameters > result ; <nl> + <nl> + public dbglistexceptionfilterscommand ( dbgmanagerimpl manager ) { <nl> + super ( manager ) ; <nl> + } <nl> + <nl> + @ override <nl> + public list < debug_exception_filter_parameters > complete ( dbgpendingcommand < ? > pending ) { <nl> + return result ; <nl> + } <nl> + <nl> + @ override <nl> + public void invoke ( ) { <nl> + result = new arraylist < > ( ) ; <nl> + <nl> + int [ ] codes = new int [ 0 ] ; <nl> + debugexceptionfilterinformation filterinfo = <nl> + manager . getcontrol ( ) . getexceptionfilterparameters ( 0 , codes , num ) ; <nl> + for ( int i = num ; i < filterinfo . getnumberofparameters ( ) ; i + + ) { <nl> + debug_exception_filter_parameters fi = filterinfo . getparameter ( i ) ; <nl> + result . add ( fi ) ; <nl> + } <nl> + } <nl> + } <nl> mmm / dev / null <nl> ppp b / ghidra / debug / debugger - agent - dbgeng / src / main / java / agent / dbgeng / manager / cmd / dbglistspecificfilterscommand . java <nl>
<nl> + / * # # # <nl> + * ip : ghidra <nl> + * <nl> + * licensed under the apache license , version num . 0 ( the " license " ) ; <nl> + * you may not use this file except in compliance with the license . <nl> + * you may obtain a copy of the license at <nl> + * <nl> + * http : / / www . apache . org / licenses / license - 2 . 0 <nl> + * <nl> + * unless required by applicable law or agreed to in writing , software <nl> + * distributed under the license is distributed on an " as is " basis , <nl> + * without warranties or conditions of any kind , either express or implied . <nl> + * see the license for the specific language governing permissions and <nl> + * limitations under the license . <nl> + * / <nl> + package agent . dbgeng . manager . cmd ; <nl> + <nl> + import java . util . arraylist ; <nl> + import java . util . list ; <nl> + <nl> + import agent . dbgeng . dbgeng . debugspecificfilterinformation ; <nl> + import agent . dbgeng . jna . dbgeng . dbgengnative . debug_specific_filter_parameters ; <nl> + import agent . dbgeng . manager . impl . dbgmanagerimpl ; <nl> + <nl> + public class dbglistspecificfilterscommand <nl> + extends abstractdbgcommand < list < debug_specific_filter_parameters > > { <nl> + private list < debug_specific_filter_parameters > result ; <nl> + <nl> + public dbglistspecificfilterscommand ( dbgmanagerimpl manager ) { <nl> + super ( manager ) ; <nl> + } <nl> + <nl> + @ override <nl> + public list < debug_specific_filter_parameters > complete ( dbgpendingcommand < ? > pending ) { <nl> + return result ; <nl> + } <nl> + <nl> + @ override <nl> + public void invoke ( ) { <nl> + result = new arraylist < > ( ) ; <nl> + <nl> + debugspecificfilterinformation filterinfo = <nl> + manager . getcontrol ( ) . getspecificfilterparameters ( 0 , num ) ; <nl> + for ( int i = num ; i < filterinfo . getnumberofparameters ( ) ; i + + ) { <nl> + debug_specific_filter_parameters fi = filterinfo . getparameter ( i ) ; <nl> + result . add ( fi ) ; <nl> + } <nl> + } <nl> + }
public class analysisoptionstest extends abstractghidraheadedintegrationtest { <nl> private analysisoptionsdialog invokeanalysisdialog ( ) { <nl> dockingactionif action = getaction ( tool , " auto analyze " ) ; <nl> performaction ( action , false ) ; <nl> - return waitfordialogcomponent ( analysisoptionsdialog . class ) ; <nl> - } <nl>  <nl> - private void apply ( ) { <nl> - pressbuttonbytext ( optionsdialog , " analyze " ) ; <nl> + <nl> + try { <nl> + return waitfordialogcomponent ( analysisoptionsdialog . class ) ; <nl> + } <nl> + catch ( throwable t ) { <nl> + <nl> + printopenwindows ( ) ; <nl> + <nl> + failwithexception ( " unable to find analysis dialog " , t ) ; <nl> + return null ; / / can ' t get here <nl> + } <nl> } <nl>  <nl> private boolean isanalyzerenabledinprogramoptions ( string analyzername ) { <nl>
ghidra_bin = . . / . . / . . / . . / . . / . . / . . / ghidra . bin <nl> os = $ ( shell uname - s ) <nl> cpu = $ ( shell uname - m ) <nl>  <nl> + # <nl> + <nl> ifeq ( $ ( os ) , linux ) <nl> # allow arch to be specified externally so we can build for num - bit from a num - bit linux <nl> ifndef arch <nl>
<nl> + package ghidra . app . plugin . core . debug . platform . gdb ; <nl> + <nl> + import static org . junit . assert . assertfalse ; <nl> + import static org . junit . assert . asserttrue ; <nl> + <nl> + import java . util . * ; <nl> + import java . util . stream . collectors ; <nl> + <nl> + import org . junit . test ; <nl> + <nl> + import ghidra . app . plugin . core . debug . mapping . debuggermappingoffer ; <nl> + import ghidra . app . plugin . core . debug . mapping . debuggermappingopinion ; <nl> + import ghidra . app . plugin . core . debug . platform . gdb . defaultgdbdebuggermappingopinion . gdbdefaultoffer ; <nl> + import ghidra . dbg . model . testdebuggerobjectmodel ; <nl> + import ghidra . dbg . model . testtargetprocess ; <nl> + import ghidra . program . model . lang . languageid ; <nl> + import ghidra . test . abstractghidraheadlessintegrationtest ; <nl> + <nl> + public class defaultgdbdebuggermappingopiniontest extends abstractghidraheadlessintegrationtest { <nl> + @ test <nl> + public void testqueryopinionsincludesldefsbased ( ) { <nl> + testdebuggerobjectmodel model = new testdebuggerobjectmodel ( ) ; <nl> + <nl> + <nl> + model . session . environment . changeattributes ( list . of ( ) , map . ofentries ( <nl> + map . entry ( " _debugger " , " gdb " ) , <nl> + map . entry ( " _arch " , " armv5t " ) , <nl> + map . entry ( " _endian " , " little " ) ) , <nl> + " testing " ) ; <nl> + <nl> + testtargetprocess process = model . addprocess ( 1234 ) ; <nl> + <nl> + list < debuggermappingoffer > offers = debuggermappingopinion . queryopinions ( process ) ; <nl> + assertfalse ( offers . isempty ( ) ) ; <nl> + set < debuggermappingoffer > ldefsones = offers . stream ( ) <nl> + . filter ( o - > o . getclass ( ) . equals ( gdbdefaultoffer . class ) ) <nl> + . collect ( collectors . toset ( ) ) ; <nl> + assertfalse ( ldefsones . isempty ( ) ) ; <nl> + set < languageid > ids = <nl> + ldefsones . stream ( ) . map ( o - > o . gettracelanguageid ( ) ) . collect ( collectors . toset ( ) ) ; <nl> + asserttrue ( ids . contains ( new languageid ( " arm : le : 32 : v5t " ) ) ) ; <nl> + } <nl> + } <nl> mmm a / ghidra / debug / framework - debugging / src / test / resources / ghidra / dbg / model / test_schema . xml <nl> ppp b / ghidra / debug / framework - debugging / src / test / resources / ghidra / dbg / model / test_schema . xml <nl>
task nodepjar ( type : jar ) { <nl> } <nl>  <nl> from ( ziptree ( jar . archivepath ) ) <nl> + <nl> + / / i probably must include duplicate license files , so that all are included <nl> + / / idk why the duplicate osgi framework classes , but i probably don ' t care . <nl> + duplicatesstrategy = ' include ' <nl> } <nl>  <nl> test { <nl> mmm a / ghidra / debug / debugger - agent - dbgmodel / build . gradle <nl> ppp b / ghidra / debug / debugger - agent - dbgmodel / build . gradle <nl>
task nodepjar ( type : jar ) { <nl> } <nl>  <nl> from ( ziptree ( jar . archivepath ) ) <nl> + <nl> + / / i probably must include duplicate license files , so that all are included <nl> + / / idk why the duplicate osgi framework classes , but i probably don ' t care . <nl> + duplicatesstrategy = ' include ' <nl> } <nl>  <nl> test { <nl> mmm a / ghidra / debug / debugger - agent - gdb / build . gradle <nl> ppp b / ghidra / debug / debugger - agent - gdb / build . gradle <nl>
task nodepjar ( type : jar ) { <nl> } <nl>  <nl> from ( ziptree ( jar . archivepath ) ) <nl> + <nl> + / / i probably must include duplicate license files , so that all are included <nl> + / / idk why the duplicate osgi framework classes , but i probably don ' t care . <nl> + duplicatesstrategy = ' include ' <nl> } <nl>  <nl> task executablejar {
def inittestjvm ( task task , string rootdirname ) { <nl> / / - xnoagent <nl> / / - djava . compiler = none <nl> / / - xrunjdwp : transport = dt_socket , server = y , suspend = n , address = 8000 <nl> + <nl> + / / <nl> + <nl> + / / command - line test execution , ci test execution of a branch upon request , and full <nl> + / / ci test execution ( this is slow and may need to run overnight ) . we do not currently <nl> + / / support well running tests via the command - line . see discussion at github num . <nl> + / / for better command - line usage we will need to update tests such that they can <nl> + / / share a vm , enabling us to elimnate the use of ' forever num ' in this file . <nl> + / / <nl> } <nl> } <nl> / * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * <nl> mmm a / gradle / root / test . gradle <nl> ppp b / gradle / root / test . gradle <nl>
def inittestjvm ( task task , string rootdirname ) { <nl> mkdir testoutputdir <nl> } <nl> / / if false , testing will halt when an error is found . <nl> - task . ignorefailures true <nl> + <nl> + / / if test report not generated that task could be changed to always <nl> + / / run even on failure ( e . g . , options . failonerror ( false ) ) <nl> + / / task . ignorefailures true <nl> + task . failfast false <nl>  <nl> / / if false , then tests are re - run every time , even if no code has changed . <nl> task . outputs . uptodatewhen { false }
public class graphactiontest extends abstractghidraheadedintegrationtest { <nl>  <nl> } <nl>  <nl> - @ test <nl> + <nl> public void testselectnodethatisdoublegrouped ( ) { <nl> select ( a , b , c ) ; <nl> collapse ( ) ; <nl>
public class graphactiontest extends abstractghidraheadedintegrationtest { <nl> asserttrue ( vertex instanceof groupvertex ) ; <nl> } <nl>  <nl> - @ test <nl> + <nl> public void testfocusnodethatisdoublegrouped ( ) { <nl> select ( a , b , c ) ; <nl> collapse ( ) ; <nl>
public class graphactiontest extends abstractghidraheadedintegrationtest { <nl> asserttrue ( graphspy . isfocused ( a ) ) ; <nl> } <nl>  <nl> - @ test <nl> + <nl> public void testlistenernotificatinwhendoublegroupednodefocused ( ) { <nl> select ( a , b , c ) ; <nl> collapse ( ) ; <nl>
public class graphactiontest extends abstractghidraheadedintegrationtest { <nl> asserttrue ( graphspy . isselected ( a , b , c ) ) ; <nl> } <nl>  <nl> - @ test <nl> + <nl> public void testselectnotificatinwhendoublegroupednodefocused ( ) { <nl> select ( a , b , c ) ; <nl> collapse ( ) ;
public class datatypemerge3test extends abstractdatatypemergetest { <nl>  <nl> } <nl>  <nl> - @ test <nl> - @ ignore <nl> + <nl> public void testeditstructurewithreplacementandremoval ( ) throws exception { <nl>  <nl> - / / see gp - 585 for design issue preventing this test from passing <nl> - <nl> mtf . initialize ( " notepad " , new originalprogrammodifierlistener ( ) { <nl>  <nl> @ override
public class dockingcheckboxmenuitem extends jcheckboxmenuitem { <nl>  <nl> @ override <nl> protected boolean processkeybinding ( keystroke ks , keyevent e , int condition , boolean pressed ) { <nl> - return true ; / / we will take care of the action ourselves <nl> + <nl> + / / dockingmenuitem . <nl> + / / return true ; / / we will take care of the action ourselves <nl> + <nl> + / / our keybindingoverridekeyeventdispatcher processes actions for us , so there is no <nl> + / / need to have the menu item do it <nl> + return false ; <nl> } <nl> } <nl> mmm a / ghidra / framework / docking / src / main / java / docking / dockingmenuitem . java <nl> ppp b / ghidra / framework / docking / src / main / java / docking / dockingmenuitem . java <nl>
public class fdetable { <nl>  <nl> / / this is an indirect reference to code from the table , <nl> / / so tag reference as an indirect code flow <nl> + <nl> prog . getreferencemanager ( ) . addmemoryreference ( loccomponentaddr , locaddr , <nl> reftype . indirection , <nl> sourcetype . analysis , num ) ; <nl> mmm a / ghidra / features / base / src / main / java / ghidra / util / undefinedfunction . java <nl> ppp b / ghidra / features / base / src / main / java / ghidra / util / undefinedfunction . java <nl>
public class symbolpathparser { <nl> return naiveparse ( name ) ; <nl> } <nl>  <nl> + private static boolean skipparsing ( string name ) { <nl> + <nl> + / / if ( name . indexof ( namespace . delimiter ) = = - 1 ) { <nl> + <nl> + / / seen in " rust . " <nl> + if ( name . startswith ( " ( " ) ) { <nl> + / / anonymous namespace is a gnu c + + construct . we do not have any way of modeling <nl> + / / this yet , but still wish not to lose this information , so we do not strip it out of <nl> + / / the name when parsing gnu demangled symbols . <nl> + return ! name . startswith ( anonymous_namespace ) ; <nl> + } <nl> + <nl> + return ! name . contains ( namespace . delimiter ) ; <nl> + } <nl> + <nl> / * * <nl> * naive parsing that assumes evenly matched angle brackets ( templates ) with no operator <nl> * overloading that contains these and no other rule breakers .
define register offset = 0x80 size = 1 [ <nl> # to act as the high bits where the x , y , or z registers are used , or in direct <nl> # addressing instructions . <nl> # <nl> + # <nl> + # elpm , and lds instructions use rampz and rampd <nl> + # <nl> # these io registers need to be accessible to sleigh instruction pcode <nl> # so they are defined here . the bulk of the io registers are defined <nl> # as labels in the appropriate . pspec file . <nl>  <nl> + <nl> + <nl> define mem offset = $ ( io_start ) size = num [ <nl> # io_start + num x00 <nl> _ _ _ _ _ _ _ _ <nl> mmm a / ghidra / processors / atmel / data / languages / avr8xmega . pspec <nl> ppp b / ghidra / processors / atmel / data / languages / avr8xmega . pspec <nl>
public class calltreeprovider extends componentprovideradapter implements domain <nl> } <nl>  <nl> private boolean updaterootnodes ( function function ) { <nl> - callnode callnode = ( callnode ) incomingtree . getmodelroot ( ) ; <nl> - function nodefunction = callnode . getcontainingfunction ( ) ; <nl> - if ( nodefunction . equals ( function ) ) { <nl> - reloadupdatemanager . update ( ) ; <nl> - return true ; <nl> + gtreenode root = incomingtree . getmodelroot ( ) ; <nl> + / / root might be a " pendingrootnode " <nl> + <nl> + if ( root instanceof callnode ) { <nl> + callnode callnode = ( callnode ) root ; <nl> + function nodefunction = callnode . getcontainingfunction ( ) ; <nl> + if ( nodefunction . equals ( function ) ) { <nl> + reloadupdatemanager . update ( ) ; <nl> + return true ; <nl> + } <nl> } <nl>  <nl> return false ;
public abstract class datatypeconflicthandler { <nl>  <nl> @ override <nl> public boolean shouldupdate ( datatype sourcedatatype , datatype localdatatype ) { <nl> - return true ; <nl> + return true ; <nl> } <nl>  <nl> @ override <nl>
public class gnudemanglerparsertest extends abstractgenerictest { <nl> assertnull ( res ) ; <nl> } <nl>  <nl> - @ test <nl> + <nl> public void testfunctionwithlambda_wrappinganotherfunctioncall ( ) throws exception { <nl>  <nl> / /
class stackeditormodel extends compositeeditormodel { <nl> newlength = compdt . getlength ( ) ; <nl> } <nl> int offset = comp . getoffset ( ) ; <nl> - if ( ( ( stackframedatatype ) viewcomposite ) . growsnegative ( ) ) { <nl> - if ( offset > = num & & offset < getparameteroffset ( ) ) { <nl> - return false ; <nl> - } <nl> - } <nl> - else { <nl> - if ( offset < num & & offset > getparameteroffset ( ) ) { <nl> - return false ; <nl> - } <nl> - <nl> - } <nl> + <nl> + / / if ( ( ( stackframedatatype ) viewcomposite ) . growsnegative ( ) ) { <nl> + / / if ( offset > = num & & offset < getparameteroffset ( ) ) { <nl> + / / return false ; <nl> + / / } <nl> + / / } <nl> + / / else { <nl> + / / if ( offset < num & & offset > getparameteroffset ( ) ) { <nl> + / / return false ; <nl> + / / } <nl> + / / } <nl> int maxbytes = ( ( stackframedatatype ) viewcomposite ) . getmaxlength ( offset ) ; <nl> if ( newlength > maxbytes ) { <nl> return false ; <nl> mmm a / ghidra / features / base / src / test . slow / java / ghidra / app / plugin / core / stackeditor / stackeditoractions4test . java <nl> ppp b / ghidra / features / base / src / test . slow / java / ghidra / app / plugin / core / stackeditor / stackeditoractions4test . java <nl>
public class datamanagertest extends abstractghidraheadedintegrationtest { <nl> / / program . saveas ( programfile , " testdb " , null ) ; <nl> / / <nl> / / <nl> - / / } <nl> + / / } <nl> + <nl> + <nl> + / / @ test <nl> + / / public void testreplacebuiltindatatype ( ) throws exception { <nl> + / / / / byte based types <nl> + / / typedef btd = <nl> + / / ( typedef ) datamgr . resolve ( new typedefdatatype ( " bytetypedef " , bytedatatype . datatype ) , <nl> + / / null ) ; <nl> + / / array barray = <nl> + / / ( array ) datamgr . resolve ( new arraydatatype ( bytedatatype . datatype , num , btd . getlength ( ) ) , <nl> + / / null ) ; <nl> + / / array barray2 = <nl> + / / ( array ) datamgr . resolve ( new arraydatatype ( barray , num , barray . getlength ( ) ) , null ) ; <nl> + / / typedef btd1 = ( typedef ) datamgr . resolve ( new typedefdatatype ( " bytetypedef1 " , barray ) , null ) ; <nl> + / / pointer bp = ( pointer ) datamgr . resolve ( new pointerdatatype ( btd ) , null ) ; <nl> + / / pointer bp2 = ( pointer ) datamgr . resolve ( new pointerdatatype ( bp ) , null ) ; <nl> + / / typedef btd2 = ( typedef ) datamgr . resolve ( new typedefdatatype ( " bytetypedef2 " , bp2 ) , null ) ; <nl> + / / <nl> + / / / / int based types <nl> + / / typedef itd = <nl> + / / ( typedef ) datamgr . resolve ( new typedefdatatype ( " bytetypedef " , integerdatatype . datatype ) , <nl> + / / null ) ; <nl> + / / array iarray = <nl> + / / ( array ) datamgr . resolve ( new arraydatatype ( bytedatatype . datatype , num , itd . getlength ( ) ) , <nl> + / / null ) ; <nl> + / / array iarray2 = <nl> + / / ( array ) datamgr . resolve ( new arraydatatype ( iarray , num , iarray . getlength ( ) ) , null ) ; <nl> + / / typedef itd1 = ( typedef ) datamgr . resolve ( new typedefdatatype ( " bytetypedef1 " , iarray ) , null ) ; <nl> + / / pointer ip = ( pointer ) datamgr . resolve ( new pointerdatatype ( itd ) , null ) ; <nl> + / / pointer ip2 = ( pointer ) datamgr . resolve ( new pointerdatatype ( ip ) , null ) ; <nl> + / / typedef itd2 = ( typedef ) datamgr . resolve ( new typedefdatatype ( " bytetypedef2 " , ip2 ) , null ) ; <nl> + / / <nl> + / / datamgr . replacedatatype ( btd . getbasedatatype ( ) , integerdatatype . datatype , false ) ; <nl> + / / <nl> + / / asserttrue ( btd . getbasedatatype ( ) . isequivalent ( integerdatatype . datatype ) ) ; <nl> + / / <nl> + / / if ( ! barray . isdeleted ( ) ) { <nl> + / / msg . debug ( this , " barray : " + barray . getdisplayname ( ) ) ; <nl> + / / fail ( " expected barray to be replaced by iarray " ) ; <nl> + / / } <nl> + / / <nl> + / / if ( ! barray2 . isdeleted ( ) ) { <nl> + / / msg . debug ( this , " barray2 : " + barray . getdisplayname ( ) ) ; <nl> + / / fail ( " expected barray2 to be replaced by iarray2 " ) ; <nl> + / / } <nl> + / / <nl> + / / if ( ! bp . isdeleted ( ) ) { <nl> + / / msg . debug ( this , " bp : " + bp . getdisplayname ( ) ) ; <nl> + / / fail ( " expected barray to be replaced by bp " ) ; <nl> + / / } <nl> + / / <nl> + / / if ( ! bp2 . isdeleted ( ) ) { <nl> + / / msg . debug ( this , " bp2 : " + bp . getdisplayname ( ) ) ; <nl> + / / fail ( " expected barray to be replaced by bp2 " ) ; <nl> + / / } <nl> + / / <nl> + / / asserttrue ( itd . getbasedatatype ( ) = = btd . getbasedatatype ( ) ) ; <nl> + / / asserttrue ( itd2 . getbasedatatype ( ) = = btd2 . getbasedatatype ( ) ) ; <nl> + / / } <nl>  <nl> @ test <nl> public void testcreatestructure ( ) {
public class pcodedatatypemanager { <nl> resbuf . append ( " > \n " ) ; <nl> datatypecomponent [ ] comps = ( ( structure ) type ) . getdefinedcomponents ( ) ; <nl> for ( datatypecomponent comp : comps ) { <nl> + if ( comp . isbitfieldcomponent ( ) ) { <nl> + <nl> + continue ; <nl> + } <nl> resbuf . append ( " < field " ) ; <nl> string field_name = comp . getfieldname ( ) ; <nl> if ( field_name = = null ) { <nl>
public class pcodedatatypemanager { <nl> resbuf . append ( buildtyperef ( fieldtype , comp . getlength ( ) ) ) ; <nl> resbuf . append ( " < / field > \n " ) ; <nl> } <nl> + <nl> } <nl> else if ( type instanceof enum ) { <nl> enum enumdt = ( enum ) type ;
import java . util . zip . zipoutputstream ; <nl> * / <nl> public final class ziputils { <nl>  <nl> + <nl> / * * <nl> * unzip files to path . <nl> * <nl>
<nl> < objenesis . version > 3 . 2 < / objenesis . version > <nl> < paged - data . version > 0 . 2 . 0 < / paged - data . version > <nl> < procyon . version > 0 . 5 . 36 < / procyon . version > <nl> + < ! - - <nl> + < procyon - snapshot . version > 10b32a4 < / procyon - snapshot . version > <nl> < rsyntaxtextarea . version > 3 . 1 . 5 < / rsyntaxtextarea . version > <nl> < semantic - version . version > 2 . 1 . 1 < / semantic - version . version > <nl> < slf4j . version > 1 . 7 . 32 < / slf4j . version > <nl>
<nl> < artifactid > paged_data < / artifactid > <nl> < version > $ { paged - data . version } < / version > <nl> < / dependency > <nl> + < ! - - <nl> < dependency > <nl> < groupid > org . bitbucket . mstrobel < / groupid > <nl> < artifactid > procyon - core < / artifactid > <nl>
public class contextmenu <nl> static <nl> { <nl> / / resource list <nl> - addcontext ( new delete ( ) ) ; <nl> + addcontext ( new delete ( ) ) ; <nl> addcontext ( new new ( ) ) ; <nl> addcontext ( new open ( ) ) ; <nl> addcontext ( new quickopen ( ) ) ;
import java . util . arraylist ; <nl>  <nl> public class resourcelisticonrenderer extends defaulttreecellrenderer <nl> { <nl> + <nl> + public static hashmap < resourcetreenode , imageicon > iconcache = new hashmap < > ( ) ; <nl> + <nl> / / called every time there is a pane update <nl> @ override <nl> public component gettreecellrenderercomponent ( <nl>
public class securityman extends securitymanager <nl> throw new securityexception ( e ) ; <nl> } <nl>  <nl> - throw new securityexception ( " bcv is awesome , blocking write ( " + file + " ) ; " ) ; <nl> + <nl> + / / throw new securityexception ( " bcv is awesome , blocking write ( " + file + " ) ; " ) ; <nl> } <nl> }
public class searchboxpane extends translatedvisiblecomponent <nl>  <nl> getcontentpane ( ) . add ( optionpanel , borderlayout . north ) ; <nl> getcontentpane ( ) . add ( new jscrollpane ( tree ) , borderlayout . center ) ; <nl> - <nl> - this . tree . addtreeselectionlistener ( selectionevent - > <nl> + <nl> + tree . addmouselistener ( new mouseadapter ( ) <nl> { <nl> - try <nl> + @ override <nl> + public void mousereleased ( mouseevent e ) <nl> { <nl> - if ( selectionevent . getpath ( ) . getpathcomponent ( 0 ) . equals ( translatedstrings . results ) ) <nl> - return ; <nl> + <nl> + if ( e . ismetadown ( ) ) <nl> + { <nl> + } <nl> + else if ( e . getbutton ( ) = = mouseevent . button1 ) <nl> + { <nl> + if ( ! ( tree . getlastselectedpathcomponent ( ) instanceof ldcsearchtreenoderesult ) ) <nl> + return ; <nl> + <nl> + ldcsearchtreenoderesult result = ( ldcsearchtreenoderesult ) tree . getlastselectedpathcomponent ( ) ; <nl>  <nl> - ldcsearchtreenoderesult result = ( ldcsearchtreenoderesult ) tree . getlastselectedpathcomponent ( ) ; <nl> + final string name = result . resourceworkingname ; <nl>  <nl> - final string name = result . resourceworkingname ; <nl> - <nl> - bytecodeviewer . viewer . workpane . addclassresource ( result . container , name ) ; <nl> - } <nl> - catch ( exception e ) <nl> - { <nl> - e . printstacktrace ( ) ; <nl> + bytecodeviewer . viewer . workpane . addclassresource ( result . container , name ) ; <nl> + } <nl> } <nl> } ) ;
public class ldcsearch implements searchtypedetails <nl> desc2 = method . desc ; <nl> } catch ( arrayindexoutofboundsexception ignored ) { } <nl>  <nl> - if ( ( exact & & ldcstring . equals ( srchtext ) ) | | ( ! exact & & ldcstring . contains ( srchtext ) ) ) <nl> + <nl> + boolean exact = false ; <nl> + final boolean exactmatch = exact & & ldcstring . equals ( srchtext ) ; <nl> + final boolean caseinsensitivematch = ! exact & & casesensitive & & ldcstring . contains ( srchtext ) ; <nl> + final boolean casesensitivematch = ! exact & & ! casesensitive & & ldcstring . tolowercase ( ) . contains ( srchtextlowercase ) ; <nl> + final boolean anymatch = exactmatch | | caseinsensitivematch | | casesensitivematch ; <nl> + <nl> + if ( anymatch ) <nl> { <nl> srn . notifyofresult ( container . name + " > " + node . name + " . " + method . name <nl> + desc2
public class bcv <nl> * / <nl> public static class < ? > loadclassintoclassloader ( classnode cn ) <nl> { <nl> + if ( cn = = null ) <nl> + return null ; <nl> + <nl> getclassnodeloader ( ) . addclass ( cn ) ; <nl>  <nl> - try { <nl> + try <nl> + { <nl> + <nl> + if ( cl = = null ) <nl> + loadclassesintoclassloader ( ) ; <nl> + <nl> return cl . loadclass ( cn . name ) ; <nl> } catch ( exception classloadexception ) { <nl> the . bytecode . club . bytecodeviewer . bytecodeviewer . handleexception ( classloadexception ) ;
<nl> < artifactid > webp - imageio < / artifactid > <nl> < version > 0 . 2 . 1 < / version > <nl> < / dependency > <nl> - < dependency > <nl> + <nl> + < ! - - <nl> + < ! - - < dependency > <nl> < groupid > org . graalvm . js < / groupid > <nl> < artifactid > js < / artifactid > <nl> < version > 21 . 2 . 0 < / version > <nl>
public class jhexeditorhex extends jcomponent implements mouselistener , keyliste <nl> { <nl> debug ( " paint ( " + g + " ) " ) ; <nl> debug ( " cursor = " + he . cursor + " buff . length = " + he . buff . length ) ; <nl> - dimension d = getminimumsize ( ) ; <nl> - g . setcolor ( color . white ) ; <nl> - g . fillrect ( 0 , num , d . width , d . height ) ; <nl> - g . setcolor ( color . black ) ; <nl> + <nl> + if ( ! configuration . laftheme . isdark ( ) ) <nl> + { <nl> + <nl> + / / g . fillrect ( 0 , num , getwidth ( ) , getheight ( ) ) ; <nl> + g . setcolor ( color . black ) ; <nl> + } <nl> + else <nl> + { <nl> + g . setcolor ( color . white ) ; <nl> + } <nl>  <nl> g . setfont ( jhexeditor . font ) ; <nl>  <nl>
public class mainviewergui extends jframe <nl> settingsmainmenu . add ( setoptionallibrary ) ; <nl> settingsmainmenu . add ( setjavac ) ; <nl> settingsmainmenu . add ( new jseparator ( ) ) ; <nl> - settingsmainmenu . add ( usenewsettingsdialogue ? apkconversionsettings : apkconversionmenu ) ; <nl> + <nl> + <nl> + settingsmainmenu . add ( apkconversionsecondarymenu ) ; <nl> + / / settingsmainmenu . add ( usenewsettingsdialogue ? apkconversionsettings : apkconversionmenu ) ; <nl> + <nl> settingsmainmenu . add ( new jseparator ( ) ) ; <nl>  <nl> fontspinner . setpreferredsize ( new dimension ( 60 , num ) ) ; <nl>
<nl> < / properties > <nl>  <nl> < repositories > <nl> - < repository > <nl> - < id > jitpack . io < / id > <nl> - < url > https : / / jitpack . io < / url > <nl> - < / repository > <nl> < repository > <nl> < id > local - maven - repo < / id > <nl> < url > file : / / / $ { project . basedir } / libs < / url > <nl> < / repository > <nl> + < repository > <nl> + < id > sonatype - snapshots < / id > <nl> + < url > https : / / oss . sonatype . org / content / repositories / snapshots < / url > <nl> + < / repository > < ! - - <nl> + < repository > <nl> + < id > jitpack . io < / id > <nl> + < url > https : / / jitpack . io < / url > <nl> + < / repository > <nl> < / repositories > <nl>  <nl> < dependencies > <nl>
<nl> < dependency > <nl> < groupid > com . github . weisj < / groupid > <nl> < artifactid > darklaf - core < / artifactid > <nl> - < version > 2 . 5 . 5 < / version > <nl> + < version > 2 . 6 . 2 - snapshot < / version > < ! - - <nl> < / dependency > <nl> < dependency > <nl> < groupid > com . github . weisj < / groupid >
public class resourcelistpane extends translatedvisiblecomponent implements file <nl> { <nl> try <nl> { <nl> + <nl> + <nl> treeroot . removeallchildren ( ) ; <nl> for ( resourcecontainer container : bytecodeviewer . resourcecontainers ) <nl> { <nl>
public class resourcelistpane extends translatedvisiblecomponent implements file <nl> } <nl> else if ( container . resourcefiles . containskey ( name ) ) <nl> { <nl> - bytecodeviewer . viewer . workpane . addfileresource ( container , name ) ; <nl> + final string fn = name . tolowercase ( ) ; <nl> + final string extension = fn . contains ( " : " ) ? null : filenameutils . getextension ( fn ) ; <nl> + <nl> + import imp = import . extensionmap . get ( extension ) ; <nl> + if ( imp = = null ) / / show images , text files , or hex view <nl> + bytecodeviewer . viewer . workpane . addfileresource ( container , name ) ; <nl> + else / / attempt to import known resources <nl> + { <nl> + int hash = ( container . name + name ) . hashcode ( ) ; <nl> + <nl> + <nl> + file tempfile = new file ( tempdirectory + fs + hash + fs + name + " . " + extension ) ; <nl> + if ( ! tempfile . exists ( ) ) <nl> + { <nl> + diskwriter . replacefilebytes ( tempfile . getabsolutepath ( ) , container . resourcefiles . get ( name ) , false ) ; <nl> + <nl> + try <nl> + { <nl> + imp . getimporter ( ) . open ( tempfile ) ; <nl> + try { <nl> + updatetree ( ) ; <nl> + } catch ( nullpointerexception ignored ) { } <nl> + } <nl> + catch ( exception e ) <nl> + { <nl> + e . printstacktrace ( ) ; <nl> + <nl> + / / failsafe <nl> + bytecodeviewer . viewer . workpane . addfileresource ( container , name ) ; <nl> + } <nl> + } <nl> + else <nl> + { <nl> + / / alert the user <nl> + } <nl> + } <nl> } <nl> }
public enum import <nl> { <nl> directory ( new directoryresourceimporter ( ) ) , <nl> file ( new fileresourceimporter ( ) ) , <nl> - zip ( new zipresourceimporter ( ) ) , <nl> - class ( new classresourceimporter ( ) ) , <nl> - xapk ( new xapkresourceimporter ( ) ) , <nl> - apk ( new apkresourceimporter ( ) ) , <nl> - dex ( new dexresourceimporter ( ) ) , <nl> + <nl> + zip ( new zipresourceimporter ( ) , " zip " , " jar " , " war " , " ear " ) , <nl> + class ( new classresourceimporter ( ) , " class " ) , <nl> + xapk ( new xapkresourceimporter ( ) , " xapk " ) , <nl> + apk ( new apkresourceimporter ( ) , " apk " ) , <nl> + dex ( new dexresourceimporter ( ) , " dex " ) , <nl> ; <nl>  <nl> + public static final hashmap < string , import > extensionmap = new hashmap < > ( ) ; <nl> + <nl> private final importer importer ; <nl> + private final string [ ] extensions ; <nl> + <nl> + static <nl> + { <nl> + for ( import i : values ( ) ) <nl> + for ( string s : i . extensions ) <nl> + extensionmap . put ( s , i ) ; <nl> + } <nl>  <nl> - import ( importer importer ) { this . importer = importer ; } <nl> + import ( importer importer , string . . . extensions ) { this . importer = importer ; <nl> + this . extensions = extensions ; <nl> + } <nl>  <nl> public importer getimporter ( ) <nl> { <nl> mmm a / src / main / java / the / bytecode / club / bytecodeviewer / resources / importing / importresource . java <nl> ppp b / src / main / java / the / bytecode / club / bytecodeviewer / resources / importing / importresource . java <nl>
public class importresource implements runnable <nl> } <nl> } <nl>  <nl> - public static boolean importfile ( file file ) throws exception <nl> + / * * <nl> + * imports a file using file - specific importers / decoders <nl> + * / <nl> + public static boolean importknownfile ( file file ) throws exception <nl> { <nl> - final string fn = file . getname ( ) ; <nl> + final string fn = filenameutils . getname ( file . getname ( ) ) . tolowercase ( ) ; <nl> + final string extension = fn . contains ( " : " ) ? null : filenameutils . getextension ( fn ) ; <nl>  <nl> - / / check for zip archives <nl> - if ( fn . endswith ( " . jar " ) | | fn . endswith ( " . zip " ) | | fn . endswith ( " . war " ) | | fn . endswith ( " . ear " ) ) <nl> - import . zip . getimporter ( ) . open ( file ) ; <nl> + switch ( extension ) <nl> + { <nl> + / / check for zip archives <nl> + case " jar " : <nl> + case " zip " : <nl> + case " war " : <nl> + case " ear " : <nl> + import . zip . getimporter ( ) . open ( file ) ; <nl> + break ; <nl>  <nl> - / / check for xapks <nl> - else if ( fn . endswith ( " . xapk " ) ) <nl> - import . xapk . getimporter ( ) . open ( file ) ; <nl> + / / check for xapks <nl> + case " xapk " : <nl> + import . xapk . getimporter ( ) . open ( file ) ; <nl> + break ; <nl>  <nl> - / / check for apks <nl> - else if ( fn . endswith ( " . apk " ) ) <nl> - import . apk . getimporter ( ) . open ( file ) ; <nl> + / / check for apks <nl> + case " apk " : <nl> + import . apk . getimporter ( ) . open ( file ) ; <nl> + break ; <nl>  <nl> - / / check for dex <nl> - else if ( fn . endswith ( " . dex " ) ) <nl> - import . dex . getimporter ( ) . open ( file ) ; <nl> - <nl> - / / return false <nl> - else <nl> - return false ; <nl> + / / check for dex <nl> + case " dex " : <nl> + import . dex . getimporter ( ) . open ( file ) ; <nl> + break ; <nl> + <nl> + default : <nl> + return false ; <nl> + } <nl>  <nl> return true ; <nl> } <nl> mmm a / src / main / java / the / bytecode / club / bytecodeviewer / resources / importing / impl / directoryresourceimporter . java <nl> ppp b / src / main / java / the / bytecode / club / bytecodeviewer / resources / importing / impl / directoryresourceimporter . java <nl>
import java . util . hashmap ; <nl>  <nl> public enum resourcetype <nl> { <nl> + <nl> + <nl> class_file ( iconresources . classicon , " class " ) , <nl> java_archive ( iconresources . jaricon , " jar " , " war " , " ear " ) , <nl> zip_archive ( iconresources . zipicon , " zip " ) , <nl> mmm a / src / main / java / the / bytecode / club / bytecodeviewer / resources / importing / importresource . java <nl> ppp b / src / main / java / the / bytecode / club / bytecodeviewer / resources / importing / importresource . java <nl>
public class bytecodeviewer <nl> / * * <nl> * gets all of the loaded classes as an array list <nl> * <nl> + * <nl> + * bytecodeviewer . getresourcecontainers ( ) . foreach ( container - > { <nl> + * execute ( new arraylist < > ( container . resourceclasses . values ( ) ) ) ; <nl> + * } ) ; <nl> + * <nl> * @ return the loaded classes as an array list <nl> * / <nl> + @ deprecated <nl> public static arraylist < classnode > getloadedclasses ( ) <nl> { <nl> arraylist < classnode > a = new arraylist < > ( ) ; <nl> mmm a / src / main / java / the / bytecode / club / bytecodeviewer / plugin / preinstalled / changeclassfileversions . java <nl> ppp b / src / main / java / the / bytecode / club / bytecodeviewer / plugin / preinstalled / changeclassfileversions . java <nl>
<nl> + package the . bytecode . club . bytecodeviewer . plugin . preinstalled ; <nl> + <nl> + import org . objectweb . asm . tree . classnode ; <nl> + import the . bytecode . club . bytecodeviewer . bytecodeviewer ; <nl> + import the . bytecode . club . bytecodeviewer . api . plugin ; <nl> + import the . bytecode . club . bytecodeviewer . api . pluginconsole ; <nl> + <nl> + import java . nio . charset . standardcharsets ; <nl> + import java . util . arraylist ; <nl> + <nl> + / * * <nl> + * as long as there are no new opcodes or api changes you can use this plugin to downgrade compiled code <nl> + * <nl> + * num ) import a jdk - 11 ( or higher ) jar resource inside of bcv <nl> + * num ) run this plugin <nl> + * num ) export as zip , then rename as jar - your classfiles will now run on jdk - 8 ( or whatever you selected ) <nl> + * <nl> + * @ author konloch <nl> + * @ since num / 11 / 2021 <nl> + * / <nl> + public class changeclassfileversions extends plugin <nl> + { <nl> + @ override <nl> + public void execute ( arraylist < classnode > classnodelist ) <nl> + { <nl> + / / prompt dialogue for version number <nl> + <nl> + int newversion = integer . parseint ( bytecodeviewer . showinput ( " class version number : ( 52 = jdk num ) " ) ) ; <nl> + <nl> + / / update the classfile version <nl> + classnodelist . foreach ( classnode - > classnode . version = newversion ) ; <nl> + <nl> + / / update the the resource byte [ ] <nl> + bytecodeviewer . updateallclassnodebytearrays ( ) ; <nl> + <nl> + / / force refresh all tabs <nl> + bytecodeviewer . refreshalltabs ( ) ; <nl> + <nl> + / / alert the changes <nl> + bytecodeviewer . showmessage ( " set all of the class versions to " + newversion ) ; <nl> + } <nl> + } <nl> \ no newline at end of file
public class externalresources <nl> * / <nl> public string getpython3command ( boolean blocktillselected ) <nl> { <nl> - / / check if ' python ' command is bound as python num . x <nl> + / / check if ' pypy3 ' command is bound as python num . x <nl> + <nl> + / * testcommand ( new string [ ] { " pypy3 " , " - - version " } , " python num " , ( ) - > { <nl> + configuration . python3 = " pypy3 " ; <nl> + } ) ; <nl> + if ( ! configuration . python3 . isempty ( ) ) <nl> + return configuration . python3 ; * / <nl> + <nl> + <nl> + / / check if ' python3 ' command is bound as python num . x <nl> + testcommand ( new string [ ] { " python3 " , " - - version " } , " python num " , ( ) - > { <nl> + configuration . python3 = " python3 " ; <nl> + } ) ; <nl> + if ( ! configuration . python3 . isempty ( ) ) <nl> + return configuration . python3 ; <nl> + <nl> + <nl> + / / check if ' python ' command is bound as python num . x <nl> testcommand ( new string [ ] { " python " , " - - version " } , " python num " , ( ) - > { <nl> configuration . python3 = " python " ; <nl> } ) ;
public class jframeconsole extends jframe <nl> return textarea ; <nl> } <nl>  <nl> + public string trim ( string s ) <nl> + { <nl> + int len = s . length ( ) ; <nl> + int max = num _000 ; <nl> + if ( len > = max ) <nl> + { <nl> + int skipped = len - max ; <nl> + s = s . substring ( 0 , max ) ; <nl> + s + = " \n \ rskipping " + skipped + " chars , allowing " + max ; <nl> + } <nl> + <nl> + return s ; <nl> + } <nl> + <nl> private static final long serialversionuid = - 5056940543411437508l ; <nl> } <nl> mmm a / src / main / java / the / bytecode / club / bytecodeviewer / plugin / preinstalled / showallstrings . java <nl> ppp b / src / main / java / the / bytecode / club / bytecodeviewer / plugin / preinstalled / showallstrings . java <nl>
import java . security . permission ; <nl>  <nl> public class securityman extends securitymanager <nl> { <nl> - private int blocking = num ; / / might be insecure due to assholes targeting bcv <nl> + private int blocking = num ; <nl> + private int silentexec = num ; <nl> private boolean printing = false ; <nl> private boolean printingpackage = false ; <nl>  <nl> + public void silenceexec ( boolean b ) { <nl> + silentexec + = ( b ? num : - 1 ) ; <nl> + } <nl> + <nl> public void resumeblocking ( ) { <nl> blocking + + ; <nl> } <nl>
<nl> + package the . bytecode . club . bytecodeviewer . plugin . preinstalled ; <nl> + <nl> + import org . objectweb . asm . tree . classnode ; <nl> + import the . bytecode . club . bytecodeviewer . bytecodeviewer ; <nl> + import the . bytecode . club . bytecodeviewer . api . plugin ; <nl> + import the . bytecode . club . bytecodeviewer . api . pluginconsole ; <nl> + <nl> + import java . nio . charset . standardcharsets ; <nl> + import java . util . arraylist ; <nl> + <nl> + / * * <nl> + * @ author konloch <nl> + * @ since num / 11 / 2021 <nl> + * / <nl> + public class viewmanifest extends plugin <nl> + { <nl> + @ override <nl> + public void execute ( arraylist < classnode > classnodelist ) <nl> + { <nl> + pluginconsole frame = new pluginconsole ( " view manifest " ) ; <nl> + frame . setvisible ( true ) ; <nl> + <nl> + <nl> + byte [ ] encodedandroidmanifest = bytecodeviewer . getfilecontents ( " androidmanifest . xml " ) ; <nl> + if ( encodedandroidmanifest ! = null ) <nl> + { <nl> + frame . appendtext ( " android apk manifest : \ r " ) ; <nl> + byte [ ] decodedandroidmanifest = bytecodeviewer . getfilecontents ( " decoded resources / androidmanifest . xml " ) ; <nl> + if ( decodedandroidmanifest ! = null ) <nl> + frame . appendtext ( new string ( decodedandroidmanifest , standardcharsets . utf_8 ) ) ; <nl> + else <nl> + frame . appendtext ( " enable settings > decode apk resources ! " ) ; <nl> + } <nl> + <nl> + byte [ ] jarmanifest = bytecodeviewer . getfilecontents ( " meta - inf / manifest . mf " ) ; <nl> + if ( jarmanifest ! = null ) <nl> + { <nl> + if ( ! frame . gettextarea ( ) . gettext ( ) . isempty ( ) ) <nl> + frame . appendtext ( " \ r \ r \ r \ r " ) ; <nl> + <nl> + frame . appendtext ( " java jar manifest : \ r " ) ; <nl> + frame . appendtext ( new string ( jarmanifest , standardcharsets . utf_8 ) ) ; <nl> + } <nl> + <nl> + if ( frame . gettextarea ( ) . gettext ( ) . isempty ( ) ) <nl> + frame . appendtext ( " manifest not found ! " ) ; <nl> + } <nl> + } <nl> \ no newline at end of file
import static the . bytecode . club . bytecodeviewer . util . miscutils . guesslanguage ; <nl> * + add decompile as zip for krakatau - bytecode , jd - gui and smali for cli <nl> * + add decompile all as zip for cli <nl> * <nl> + * <nl> + * + allow class files to be opened without needing the . class extension <nl> + * ^ easiest way to do this is to read the file header cafebabe on resource view <nl> + * + look into removing the loaded classes from inside the filecontainer & then generate the classnodes on demand <nl> + * ^ this has the added benefit of only extracting on decompilation / when needed . it would also mean everything <nl> + * could be treated as byte [ ] file resources instead of juggling between classes and file resources . <nl> + * ^ an added bonus would be you could also support bcel ( along with other bytecode manipulation libraries ) <nl> + * and add support for https : / / github . com / ptnkjke / java - bytecode - editor visualizer as a plugin <nl> + * <nl> * @ author konloch <nl> * @ author the entire bcv community <nl> * /
public enum language <nl> ioutils . tostring ( resources . class . getresourceasstream ( resourcepath ) , standardcharsets . utf_8 ) , <nl> new typetoken < linkedmap < string , string > > ( ) { } . gettype ( ) ) ; <nl>  <nl> + hashset < string > existingkeys = new hashset < > ( ) ; <nl> + for ( translation t : translation . values ( ) ) <nl> + existingkeys . add ( t . name ( ) ) ; <nl> + <nl> for ( string key : translationmap . keyset ( ) ) <nl> - system . out . println ( key + " , " ) ; <nl> + if ( ! existingkeys . contains ( key ) & & ! key . startswith ( " <nl> + system . err . println ( key + " , " ) ; <nl> } <nl>  <nl> public string getresourcepath ( )
public abstract class paneupdaterthread implements runnable <nl> } <nl> } <nl>  <nl> - if ( bytecodeviewer . viewer . showclassmethods . isselected ( ) ) { <nl> - if ( ! methods . isempty ( ) ) { <nl> + <nl> + if ( bytecodeviewer . viewer . showclassmethods . isselected ( ) ) <nl> + { <nl> + if ( ! methods . isempty ( ) ) <nl> + { <nl> methodslist = new jcombobox < > ( ) ; <nl> - for ( integer line : methods . getmethodslines ( ) ) { <nl> + <nl> + for ( integer line : methods . getmethodslines ( ) ) <nl> methodslist . additem ( line ) ; <nl> - } <nl> + <nl> methodslist . setrenderer ( new methodsrenderer ( this ) ) ; <nl> methodslist . addactionlistener ( e - > <nl> {
public class dex2jar { <nl> file realoutputf2 = new file ( realoutput ) ; <nl> while ( realoutputf2 . exists ( ) ) <nl> realoutputf2 . delete ( ) ; <nl> + <nl> + <nl> + / / or else after each apk decompile the file directory will be flooded with - error . zip <nl> + for ( file localfile : new file ( " . " ) . listfiles ( ) ) <nl> + { <nl> + if ( localfile . getname ( ) . length ( ) = = num & & localfile . getname ( ) . endswith ( " - error . zip " ) ) <nl> + localfile . delete ( ) ; <nl> + } <nl> } catch ( exception e ) { <nl> new the . bytecode . club . bytecodeviewer . api . exceptionui ( e ) ; <nl> }
public class testconnections <nl> } <nl>  <nl> @ test <nl> - public void testisolation ( ) throws exception <nl> + public void testmaximumpoollimit ( ) throws exception <nl> { <nl> hikariconfig config = new hikariconfig ( ) ; <nl> + config . setminimumidle ( 1 ) ; <nl> + config . setmaximumpoolsize ( 4 ) ; <nl> + config . setinitializationfailfast ( true ) ; <nl> + config . setconnectiontestquery ( " values num " ) ; <nl> config . setdatasourceclassname ( " com . zaxxer . hikari . mocks . stubdatasource " ) ; <nl> - config . settransactionisolation ( " transaction_repeatable_read " ) ; <nl> - config . validate ( ) ; <nl> - <nl> - int transactionisolation = config . gettransactionisolation ( ) ; <nl> - assert . assertsame ( connection . transaction_repeatable_read , transactionisolation ) ; <nl> + <nl> + stubconnection . count . set ( 0 ) ; <nl> + <nl> + final hikaridatasource ds = new hikaridatasource ( config ) ; <nl> + <nl> + thread [ ] threads = new thread [ 20 ] ; <nl> + for ( int i = num ; i < threads . length ; i + + ) <nl> + { <nl> + threads [ i ] = new thread ( new runnable ( ) { <nl> + public void run ( ) <nl> + { <nl> + try <nl> + { <nl> + connection connection = ds . getconnection ( ) ; <nl> + thread . sleep ( 1000 ) ; <nl> + connection . close ( ) ; <nl> + } <nl> + catch ( exception e ) <nl> + { <nl> + <nl> + e . printstacktrace ( ) ; <nl> + } <nl> + } <nl> + } ) ; <nl> + } <nl> + <nl> + for ( int i = num ; i < threads . length ; i + + ) <nl> + { <nl> + threads [ i ] . start ( ) ; <nl> + } <nl> + <nl> + for ( int i = num ; i < threads . length ; i + + ) <nl> + { <nl> + threads [ i ] . join ( ) ; <nl> + } <nl> + <nl> + assert . assertequals ( 4 , stubconnection . count . get ( ) ) ; <nl> } <nl> } <nl> mmm a / src / test / java / com / zaxxer / hikari / mocks / stubconnection . java <nl> ppp b / src / test / java / com / zaxxer / hikari / mocks / stubconnection . java <nl>
public final class hikaripool implements hikaripoolmbean <nl> } <nl> } <nl>  <nl> + void shutdown ( ) <nl> + { <nl> + <nl> + } <nl> + <nl> / / * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * <nl> / / hikaripoolmbean methods <nl> / / * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *
public class disklogstrategy implements logstrategy { <nl>  <nl> file folder = new file ( foldername ) ; <nl> if ( ! folder . exists ( ) ) { <nl> + <nl> folder . mkdirs ( ) ; <nl> } <nl>  <nl> mmm a / logger / src / test / java / com . orhanobut . logger / logassert . java <nl> ppp b / logger / src / test / java / com . orhanobut . logger / logassert . java <nl>
import org . apache . ibatis . session . configuration ; <nl> public class unknowntypehandler extends basetypehandler < object > { <nl>  <nl> private static final objecttypehandler object_type_handler = new objecttypehandler ( ) ; <nl> - private final configuration configuration ; <nl> + <nl> + private final configuration config ; <nl> private final supplier < typehandlerregistry > typehandlerregistrysupplier ; <nl>  <nl> / * * <nl>
public class sqlprovidertest { <nl> } <nl>  <nl> / / test for map with @ param <nl> - @ test <nl> + @ ignore ( " <nl> public void shouldgetusersbynamewithparamname ( ) { <nl> sqlsession sqlsession = sqlsessionfactory . opensession ( ) ; <nl> try {
<nl> + / * <nl> + * copyright num - 2012 the mybatis team <nl> + * <nl> + * licensed under the apache license , version num . 0 ( the " license " ) ; <nl> + * you may not use this file except in compliance with the license . <nl> + * you may obtain a copy of the license at <nl> + * <nl> + * http : / / www . apache . org / licenses / license - 2 . 0 <nl> + * <nl> + * unless required by applicable law or agreed to in writing , software <nl> + * distributed under the license is distributed on an " as is " basis , <nl> + * without warranties or conditions of any kind , either express or implied . <nl> + * see the license for the specific language governing permissions and <nl> + * limitations under the license . <nl> + * / <nl> + <nl> + / * * <nl> + * <nl> + * / <nl> + package org . apache . ibatis . logging . log4j2 ;
public class baseexecutortest extends basedatatest { <nl> assertequals ( " * * * * * * * * " , author . getpassword ( ) ) ; <nl> assertequals ( " sally @ ibatis . apache . org " , author . getemail ( ) ) ; <nl> assertequals ( null , author . getbio ( ) ) ; <nl> + } catch ( executorexception e ) { <nl> + if ( executor instanceof cachingexecutor ) { <nl> + <nl> + asserttrue ( e . getmessage ( ) . contains ( " out params is not supported " ) ) ; <nl> + } else { <nl> + throw e ; <nl> + } <nl> } finally { <nl> executor . rollback ( true ) ; <nl> executor . close ( false ) ;
public class baseexecutortest extends basedatatest { <nl> } <nl> } <nl>  <nl> - @ test <nl> + @ test ( expected = executorexception . class ) <nl> public void shouldselectauthorviaoutparams ( ) throws exception { <nl> datasource ds = createblogdatasource ( ) ; <nl> connection connection = ds . getconnection ( ) ;
import java . lang . reflect . type ; <nl> * / <nl> public abstract class typereference < t > { <nl>  <nl> - private final type rawtype ; <nl> + private type rawtype ; <nl>  <nl> protected typereference ( ) { <nl> type superclass = getclass ( ) . getgenericsuperclass ( ) ; <nl> - if ( superclass instanceof class ) { <nl> - throw new runtimeexception ( " missing type parameter . " ) ; <nl> + if ( superclass instanceof class ) { <nl> + throw new runtimeexception ( " missing type parameter . " ) ; <nl> + } <nl> + rawtype = ( ( parameterizedtype ) superclass ) . getactualtypearguments ( ) [ 0 ] ; <nl> + <nl> + if ( rawtype instanceof parameterizedtype ) { <nl> + rawtype = ( ( parameterizedtype ) rawtype ) . getrawtype ( ) ; <nl> } <nl> - rawtype = ( ( parameterizedtype ) superclass ) . getactualtypearguments ( ) [ 0 ] ; <nl> } <nl>  <nl> public final type getrawtype ( ) { <nl> mmm a / src / test / java / org / apache / ibatis / submitted / generictypes / generictypestest . java <nl> ppp b / src / test / java / org / apache / ibatis / submitted / generictypes / generictypestest . java <nl>
public class lrucache implements cache { <nl> } <nl>  <nl> public void setsize ( final int size ) { <nl> - keymap = new linkedhashmap < object , object > ( size , . 75f , true ) { <nl> + <nl> + keymap = collections . synchronizedmap ( new linkedhashmap < object , object > ( size , . 75f , true ) { <nl> private static final long serialversionuid = num l ; <nl>  <nl> protected boolean removeeldestentry ( map . entry < object , object > eldest ) { <nl>
package org . apache . ibatis . jdbc ; <nl> import java . sql . connection ; <nl> import java . sql . databasemetadata ; <nl> import java . sql . sqlexception ; <nl> + import java . util . arraylist ; <nl> + import java . util . collection ; <nl> import java . util . hashmap ; <nl> import java . util . map ; <nl> - import java . util . map . entry ; <nl>  <nl> import javax . sql . datasource ; <nl>  <nl> public class datasourceutils { <nl>  <nl> - private static map < string , string > databasenames = new hashmap < string , string > ( ) { <nl> - { <nl> - put ( " derby " , " derby " ) ; <nl> - put ( " db2 " , " db2 " ) ; <nl> - put ( " hsql " , " hsql " ) ; <nl> - put ( " sqlserver " , " microsoft " ) ; <nl> - put ( " mysql " , " mysql " ) ; <nl> - put ( " oracle " , " oracle " ) ; <nl> - put ( " postgres " , " postgresql " ) ; <nl> - put ( " sybase " , " sybase " ) ; <nl> - } <nl> - } ; <nl> + / * * <nl> + * for each type , the supported databaseproductnames <nl> + * <nl> + * <nl> + * / <nl> + private static map < string , collection < string > > type_name = new hashmap < string , collection < string > > ( ) ; <nl>  <nl> - public static string getdatabasename ( datasource datasource ) { <nl> - string productname = getdatabaseproductname ( datasource ) ; <nl> - string databasename = null ; <nl> - for ( entry < string , string > databasenameentry : databasenames . entryset ( ) ) { <nl> - if ( productname . contains ( databasenameentry . getvalue ( ) ) ) { <nl> - databasename = databasenameentry . getkey ( ) ; <nl> - break ; <nl> - } <nl> + / * * <nl> + * for each databaseproductname , the related type <nl> + * / <nl> + private static map < string , string > name_type = new hashmap < string , string > ( ) ; <nl> + <nl> + static { <nl> + / / data kindly borrowed from dbvisualizer ( http : / / www . dbvis . com / ) <nl> + register ( " cache " , " cache " ) ; <nl> + register ( " db2 " , " db2 " ) ; <nl> + register ( " db2 " , " db2 ( datadirect ) " ) ; <nl> + register ( " generic " , " db2 for as / 400 ( jtopen ) " ) ; <nl> + register ( " firebird " , " firebird " ) ; <nl> + register ( " frontbase " , " frontbase " ) ; <nl> + register ( " neoview " , " hp neoview " ) ; <nl> + register ( " hsql " , " hsqldb server " ) ; <nl> + register ( " hsql " , " hsqldb embedded " ) ; <nl> + register ( " h2 " , " h2 server " ) ; <nl> + register ( " h2 " , " h2 embedded " ) ; <nl> + register ( " informix " , " informix " ) ; <nl> + register ( " informix " , " informix ( datadirect ) " ) ; <nl> + register ( " derby " , " javadb / derby server " ) ; <nl> + register ( " derby " , " javadb / derby embedded " ) ; <nl> + register ( " jdatastore " , " jdatastore " ) ; <nl> + register ( " generic " , " jdbc / odbc bridge " ) ; <nl> + register ( " maxdb " , " maxdb " ) ; <nl> + register ( " generic " , " mckoi " ) ; <nl> + register ( " mimer " , " mimer " ) ; <nl> + register ( " mysql " , " mysql " ) ; <nl> + register ( " netezza " , " netezza " ) ; <nl> + register ( " oracle " , " oracle thin " ) ; <nl> + register ( " oracle " , " oracle oci " ) ; <nl> + register ( " oracle " , " oracle ( datadirect ) " ) ; <nl> + register ( " pervasive " , " pervasive " ) ; <nl> + register ( " postgresql " , " postgresql " ) ; <nl> + register ( " progress " , " progress " ) ; <nl> + register ( " sqlite " , " sqlite " ) ; <nl> + register ( " sqlserver " , " sql server ( datadirect ) " ) ; <nl> + register ( " sqlserver " , " sql server ( jtds ) " ) ; <nl> + register ( " sqlserver " , " sql server ( microsoft jdbc driver ) " ) ; <nl> + register ( " sqlserver " , " sql server num ( microsoft jdbc driver ) " ) ; <nl> + register ( " sybase - ase " , " sybase ase ( jtds ) " ) ; <nl> + register ( " sybase - ase " , " sybase ase ( jconnect ) " ) ; <nl> + register ( " sybase - asa " , " sybase sql anywhere ( jconnect ) " ) ; <nl> + register ( " sybase " , " sybase ( datadirect ) " ) ; <nl> + } <nl> + <nl> + private static void register ( string type , string databaseproductname ) { <nl> + collection < string > names = type_name . get ( type ) ; <nl> + if ( names = = null ) { <nl> + names = new arraylist < string > ( ) ; <nl> + type_name . put ( type , names ) ; <nl> } <nl> - return databasename ; <nl> + type_name . put ( type , names ) ; <nl> + <nl> + name_type . put ( databaseproductname , type ) ; <nl> } <nl>  <nl> - private static string getdatabaseproductname ( datasource datasource ) { <nl> + public static string getdatabasename ( datasource datasource ) { <nl> connection con = null ; <nl> try { <nl> con = datasource . getconnection ( ) ; <nl> if ( con = = null ) { <nl> throw new runtimeexception ( " connection returned by datasource [ " + datasource + " ] was null " ) ; <nl> } <nl> + <nl> databasemetadata metadata = con . getmetadata ( ) ; <nl> if ( metadata = = null ) { <nl> throw new runtimeexception ( " databasemetadata returned by connection [ " + con + " ] was null " ) ; <nl> } <nl> - return metadata . getdatabaseproductname ( ) ; <nl> + <nl> + string productname = metadata . getdatabaseproductname ( ) ; <nl> + return name_type . get ( productname ) ; <nl> } catch ( sqlexception e ) { <nl> throw new runtimeexception ( " could not get database product name " , e ) ; <nl> } finally {
public class scriptrunner { <nl> } catch ( exception e ) { <nl> / / ignore to workaround a bug in some connection pools <nl> } <nl> - commitconnection ( ) ; <nl> + commitconnection ( ) ; <nl> } <nl>  <nl> private void printresults ( statement statement , boolean hasresults ) {
org . gradle . daemon = false <nl> android . useandroidx = true <nl> android . enablejetifier = true <nl> # fixme : enable when https : / / github . com / realm / realm - java / issues / 7605 is resolved <nl> - android . experimental . androidtest . useunifiedtestplatform = false <nl> \ no newline at end of file <nl> + android . experimental . androidtest . useunifiedtestplatform = false <nl> + <nl> + # <nl> + # explicit building of core so that builds don ' t fail . we should find out if we want to support <nl> + # using binaries or otherwise remove the logic around this and just always build core . <nl> + buildcore = true
public class okhttpnetworktransport extends osjavanetworktransport { <nl> private synchronized okhttpclient getclient ( long timeoutms ) { <nl> if ( client = = null ) { <nl> client = new okhttpclient . builder ( ) <nl> - . calltimeout ( timeoutms , timeunit . milliseconds ) <nl> + <nl> + / / the timeout is num x the defined timeout which is acceptable . <nl> + . connecttimeout ( timeoutms , timeunit . milliseconds ) <nl> + . readtimeout ( timeoutms , timeunit . milliseconds ) <nl> + . writetimeout ( timeoutms , timeunit . milliseconds ) <nl> . followredirects ( true ) <nl> . addinterceptor ( new logginginterceptor ( httplogobfuscator ) ) <nl> / / using custom connection pool to evict idle connection after num seconds rather than num minutes ( which is the default ) <nl> mmm a / realm / realm - library / src / objectserver / java / io / realm / mongodb / appconfiguration . java <nl> ppp b / realm / realm - library / src / objectserver / java / io / realm / mongodb / appconfiguration . java <nl>
def runbuild ( buildflags , instrumentationtesttarget ) { <nl> def runpublish ( ) { <nl> stage ( ' publish release ' ) { <nl> withcredentials ( [ <nl> + [ $ class : ' stringbinding ' , credentialsid : ' maven - central - java - ring - file ' , variable : ' sign_key ' ] , <nl> + [ $ class : ' stringbinding ' , credentialsid : ' maven - central - java - ring - file - password ' , variable : ' sign_key_password ' ] , <nl> [ $ class : ' stringbinding ' , credentialsid : ' slack - webhook - java - ci - channel ' , variable : ' slack_url_ci ' ] , <nl> [ $ class : ' stringbinding ' , credentialsid : ' slack - webhook - releases - channel ' , variable : ' slack_url_release ' ] , <nl> [ $ class : ' usernamepasswordmultibinding ' , credentialsid : ' maven - central - credentials ' , passwordvariable : ' maven_central_password ' , usernamevariable : ' maven_central_user ' ] , <nl> [ $ class : ' amazonwebservicescredentialsbinding ' , accesskeyvariable : ' docs_s3_access_key ' , credentialsid : ' mongodb - realm - docs - s3 ' , secretkeyvariable : ' docs_s3_secret_key ' ] , <nl> [ $ class : ' amazonwebservicescredentialsbinding ' , accesskeyvariable : ' realm_s3_access_key ' , credentialsid : ' realm - s3 ' , secretkeyvariable : ' realm_s3_secret_key ' ] <nl> ] ) { <nl> + <nl> sh " " " <nl> set + x <nl> sh tools / publish_release . sh ' $ maven_central_user ' ' $ maven_central_password ' \ <nl> ' $ realm_s3_access_key ' ' $ realm_s3_secret_key ' \ <nl> ' $ docs_s3_access_key ' ' $ docs_s3_secret_key ' \ <nl> ' $ slack_url_release ' \ <nl> - ' $ slack_url_ci ' <nl> + ' $ slack_url_ci ' , ' - psignbuild = true - psignsecretringfile = \ " $ { sign_key } \ " - psignpassword = $ { sign_key_password } - penablelto = true - pbuildcore = true ' <nl> " " " <nl> } <nl> } <nl> mmm a / build . gradle <nl> ppp b / build . gradle <nl>
try { <nl> def buildflags = " " <nl> def instrumentationtesttarget = " connectedandroidtest " <nl> def deviceserial = " " <nl> + <nl> + <nl> if ( ! releasebranches . contains ( currentbranch ) ) { <nl> / / build development branch <nl> useemulator = true <nl> mmm a / realm / realm - library / src / main / cpp / io_realm_internal_osrealmconfig . cpp <nl> ppp b / realm / realm - library / src / main / cpp / io_realm_internal_osrealmconfig . cpp <nl>
public class osrealmconfig implements nativeobject { <nl> schema_mode_immutable ( schema_mode_value_immutable ) , <nl> schema_mode_readonly ( schema_mode_value_readonly ) , <nl> schema_mode_reset_file ( schema_mode_value_reset_file ) , <nl> - schema_mode_additive ( schema_mode_value_additive ) , <nl> + schema_mode_additive_discovered ( schema_mode_value_additive_discovered ) , <nl> + <nl> + <nl> + <nl> schema_mode_manual ( schema_mode_value_manual ) ; <nl>  <nl> final byte value ; <nl>
public class osrealmconfig implements nativeobject { <nl> schema_mode_immutable ( schema_mode_value_immutable ) , <nl> schema_mode_readonly ( schema_mode_value_readonly ) , <nl> schema_mode_reset_file ( schema_mode_value_reset_file ) , <nl> - schema_mode_additive ( schema_mode_value_additive ) , <nl> + schema_mode_additive_discovered ( schema_mode_value_additive_discovered ) , <nl> + <nl> + <nl> + <nl> schema_mode_manual ( schema_mode_value_manual ) ; <nl>  <nl> final byte value ; <nl>
public class ossharedrealmtests { <nl> asserttrue ( listenercalled . get ( ) ) ; <nl> } <nl>  <nl> + / / test for https : / / github . com / realm / realm - core / issues / 3707 <nl> + @ test <nl> + public void emittableinstructionsforcustomclasses ( ) { <nl> + final atomicboolean listenercalled = new atomicboolean ( false ) ; <nl> + assertfalse ( sharedrealm . hastable ( " newtable " ) ) ; <nl> + sharedrealm . registerschemachangedcallback ( new ossharedrealm . schemachangedcallback ( ) { <nl> + @ override <nl> + public void onschemachanged ( ) { <nl> + asserttrue ( sharedrealm . hastable ( " newtable " ) ) ; <nl> + listenercalled . set ( true ) ; <nl> + } <nl> + } ) ; <nl> + <nl> + / / change schema using another realm <nl> + / / classes not starting with class_ were treated differently by sync <nl> + ossharedrealm bgrealm = ossharedrealm . getinstance ( config , ossharedrealm . versionid . live ) ; <nl> + bgrealm . begintransaction ( ) ; <nl> + bgrealm . createtable ( " newtable " ) ; <nl> + bgrealm . committransaction ( ) ; <nl> + bgrealm . close ( ) ; <nl> + <nl> + / / refresh existing instance <nl> + sharedrealm . refresh ( ) ; <nl> + asserttrue ( sharedrealm . hastable ( " newtable " ) ) ; <nl> + assertfalse ( listenercalled . get ( ) ) ; <nl> + } <nl> + <nl> @ test <nl> public void isclosed ( ) { <nl> sharedrealm . close ( ) ;
dependencies { <nl> exclude group : ' io . reactivex . rxjava2 ' , module : ' rxjava ' <nl> } <nl>  <nl> + <nl> + / / tasks as they introduce version num . 0 . 0 strictly , even when specifying num . 0 . 1 from here <nl> + androidtestimplementation " androidx . multidex : multidex : 2 . 0 . 0 " <nl> + <nl> kapt project ( ' : realm - annotations - processor ' ) / / see https : / / github . com / realm / realm - java / issues / 5799 <nl> objectserverimplementation ' com . squareup . okhttp3 : okhttp : 3 . 12 . 0 ' / / going above this requires minsdk num <nl> objectserverimplementation " org . mongodb : bson : 3 . 12 . 0 "
std : : string num_to_string ( t pnumber ) <nl> # define max_jint num x7fffffffl <nl> # define max_jsize max_jint <nl>  <nl> + <nl> / / helper macros for better readability <nl> - / / use s64 ( ) when logging <nl> # define s ( x ) static_cast < size_t > ( x ) <nl> # define b ( x ) static_cast < bool > ( x ) <nl> # define s64 ( x ) static_cast < int64_t > ( x ) <nl>
public class realmresults < e extends realmmodel > extends abstractlist < e > implemen <nl> boolean contains = false ; <nl> if ( object instanceof realmobjectproxy ) { <nl> realmobjectproxy proxy = ( realmobjectproxy ) object ; <nl> - row row = proxy . realmget $ proxystate ( ) . getrow $ realm ( ) ; <nl> - contains = ! ( row instanceof invalidrow ) & & collection . contains ( ( uncheckedrow ) row ) ; <nl> + <nl> + if ( proxy . realmget $ proxystate ( ) . getrealm $ realm ( ) = = realm ) { <nl> + row row = proxy . realmget $ proxystate ( ) . getrow $ realm ( ) ; <nl> + contains = ! ( row instanceof invalidrow ) & & collection . contains ( ( uncheckedrow ) row ) ; <nl> + } <nl> } <nl> return contains ; <nl> }
struct resultswrapper { <nl> } <nl> } <nl>  <nl> + <nl> + inline void refresh_snapshot ( ) <nl> + { <nl> + m_snapshot = m_results . snapshot ( ) ; <nl> + } <nl> + <nl> inline bool is_detached ( ) <nl> { <nl> return m_snapshot . get_mode ( ) ! = results : : mode : : empty ; <nl>
java_io_realm_internal_collection_nativeaggregate ( jnienv * env , jclass , jlong nat <nl> break ; <nl> case io_realm_internal_collection_aggregate_function_average : <nl> value = wrapper - > get_results ( ) . average ( index ) ; <nl> + <nl> + if ( ! value ) { <nl> + value = optional < mixed > ( 0 . 0 ) ; <nl> + } <nl> break ; <nl> case io_realm_internal_collection_aggregate_function_sum : <nl> value = wrapper - > get_results ( ) . sum ( index ) ;
abstract class baserealm implements closeable { <nl>  <nl> / / used by realmlist / realmresults <nl> / / invariant : if dynamicclassname ! = null - > clazz = = dynamicrealmobject <nl> + <nl> < e extends realmmodel > e get ( class < e > clazz , string dynamicclassname , long rowindex ) { <nl> final boolean isdynamicrealmobject = dynamicclassname ! = null ; <nl> final table table = isdynamicrealmobject ? schema . gettable ( dynamicclassname ) : schema . gettable ( clazz ) ; <nl> mmm a / realm / realm - library / src / main / java / io / realm / realmresults . java <nl> ppp b / realm / realm - library / src / main / java / io / realm / realmresults . java <nl>
public class notificationstest { <nl> realmchangelistener < realm > listener = new realmchangelistener < realm > ( ) { <nl> @ override <nl> public void onchange ( realm object ) { <nl> - try { <nl> - fail ( " this handler should not be notified " ) ; <nl> - } catch ( assertionfailederror e ) { <nl> - threadassertionerror [ 0 ] = e ; <nl> - handlernotified . countdown ( ) ; / / make sure that that await ( ) doesn ' t fail instead . <nl> - } <nl> + fail ( " this handler should not be notified " ) ; <nl> } <nl> } ; <nl> realm . addchangelistener ( listener ) ; <nl> realm . close ( ) ; <nl> - backgroundthreadclosed . countdown ( ) ; <nl> + backgroundthread2closed . countdown ( ) ; <nl> looper . loop ( ) ; <nl> } <nl>  <nl> } . start ( ) ; <nl>  <nl> - / / any realm_changed message should now only reach the open handler on thread1 <nl> - backgroundthreadclosed . await ( ) ; <nl> + testhelper . awaitorfail ( backgroundthread1started ) ; <nl> + testhelper . awaitorfail ( backgroundthread2closed ) ; <nl> realm realm = realm . getinstance ( realmconfig ) ; <nl> realm . begintransaction ( ) ; <nl> realm . committransaction ( ) ; <nl> + / / any realm_changed message should now only reach the open handler on thread1 <nl> try { <nl> + <nl> if ( ! handlernotified . await ( 5 , timeunit . seconds ) ) { <nl> fail ( " handler didn ' t receive message " ) ; <nl> } <nl> } finally { <nl> realm . close ( ) ; <nl> } <nl> - <nl> - if ( threadassertionerror [ 0 ] ! = null ) { <nl> - throw threadassertionerror [ 0 ] ; <nl> - } <nl> } <nl>  <nl> / / test that we handle a looper thread quiting it ' s looper before it is done executing the current loop ( = realm . close ( )
public class realmtest extends androidtestcase { <nl> realm . deleterealm ( realmconfig ) ; <nl> realm realm = realm . getinstance ( realmconfig ) ; <nl> realm . close ( ) ; <nl> - asserttrue ( realm . compactrealm ( realmconfig ) ) ; <nl> - realm = realm . getinstance ( realmconfig ) ; <nl> - assertfalse ( realm . isclosed ( ) ) ; <nl> - realm . close ( ) ; <nl> + <nl> + try { <nl> + asserttrue ( realm . compactrealm ( realmconfig ) ) ; <nl> + fail ( ) ; <nl> + } catch ( illegalargumentexception expected ) { <nl> + } <nl> } <nl>  <nl> public void testcompactencryptedpopulatedrealmfile ( ) { <nl>
public class realmtest extends androidtestcase { <nl>  <nl> populatetestrealm ( realm , num ) ; <nl> realm . close ( ) ; <nl> - <nl> - asserttrue ( realm . compactrealm ( realmconfig ) ) ; <nl> - <nl> - realm = realm . getinstance ( realmconfig ) ; <nl> - assertfalse ( realm . isclosed ( ) ) ; <nl> - assertequals ( 100 , realm . allobjects ( alltypes . class ) . size ( ) ) ; <nl> - realm . close ( ) ; <nl> + <nl> + try { <nl> + asserttrue ( realm . compactrealm ( realmconfig ) ) ; <nl> + fail ( ) ; <nl> + } catch ( illegalargumentexception expected ) { <nl> + } <nl> } <nl>  <nl> public void testcompactemptyrealmfile ( ) throws ioexception { <nl> mmm a / realm / realm - library / src / main / java / io / realm / baserealm . java <nl> ppp b / realm / realm - library / src / main / java / io / realm / baserealm . java <nl>
public class realmtest extends androidtestcase { <nl>  <nl> populatetestrealm ( realm , num ) ; <nl> realm . close ( ) ; <nl> - asserttrue ( realm . isclosed ( ) ) ; <nl> - <nl> - asserttrue ( realm . compactrealm ( realmconfig ) ) ; <nl> - <nl> - realm = realm . getinstance ( realmconfig ) ; <nl> - assertequals ( 100 , realm . allobjects ( alltypes . class ) . size ( ) ) ; <nl> - realm . close ( ) ; <nl> + <nl> + try { <nl> + asserttrue ( realm . compactrealm ( realmconfig ) ) ; <nl> + fail ( ) ; <nl> + } catch ( illegalargumentexception expected ) { <nl> + } <nl> } <nl>  <nl> public void testcompactemptyrealmfile ( ) throws ioexception { <nl> mmm a / realm / src / main / java / io / realm / baserealm . java <nl> ppp b / realm / src / main / java / io / realm / baserealm . java <nl>
public class realmtest extends androidtestcase { <nl> try { testrealm . createorupdateallfromjson ( alltypesprimarykey . class , jsonarrstream2 ) ; fail ( ) ; } catch ( illegalstateexception expected ) { } <nl> } <nl>  <nl> - / / check that finalizerrunnable can free native resources ( phantom refs ) <nl> + <nl> + / * / / check that finalizerrunnable can free native resources ( phantom refs ) <nl> public void testreferencecleaning ( ) throws nosuchfieldexception , illegalaccessexception { <nl> field sharedgroupreference = realm . class . getdeclaredfield ( " sharedgroup " ) ; <nl> sharedgroupreference . setaccessible ( true ) ; <nl>
<nl>  <nl> < ! - - checks for size violations . - - > <nl> < ! - - see http : / / checkstyle . sf . net / config_sizes . html - - > <nl> + < ! - - <nl> < module name = " linelength " > <nl> < property name = " max " value = " 120 " / > <nl> < property name = " severity " value = " warning " / > <nl> - < / module > <nl> + < / module > - - > <nl> < ! - - < module name = " methodlength " / > - - > <nl> < ! - - < module name = " parameternumber " / > - - > <nl>  <nl>
public class realmtest extends androidtestcase { <nl> new random ( 42 ) . nextbytes ( key ) ; <nl> realm realm = realm . getinstance ( getcontext ( ) , realm_name , key ) ; <nl> realm . close ( ) ; <nl> - asserttrue ( realm . compactrealmfile ( getcontext ( ) , realm_name , key ) ) ; <nl> + <nl> + try { <nl> + asserttrue ( realm . compactrealmfile ( getcontext ( ) , realm_name , key ) ) ; <nl> + } catch ( illegalargumentexception expected ) { <nl> + } <nl> } <nl>  <nl> public void testcompactencryptedpopulatedrealmfile ( ) { <nl>
public class realmtest extends androidtestcase { <nl> realm realm = realm . getinstance ( getcontext ( ) , realm_name , key ) ; <nl> populatetestrealm ( realm , num ) ; <nl> realm . close ( ) ; <nl> - asserttrue ( realm . compactrealmfile ( getcontext ( ) , realm_name , key ) ) ; <nl> + <nl> + try { <nl> + asserttrue ( realm . compactrealmfile ( getcontext ( ) , realm_name , key ) ) ; <nl> + } catch ( illegalargumentexception expected ) { <nl> + } <nl> } <nl>  <nl> public void testcompactemptyrealmfile ( ) throws ioexception { <nl> mmm a / realm / src / main / java / io / realm / realm . java <nl> ppp b / realm / src / main / java / io / realm / realm . java <nl>
public class realmtest extends androidtestcase { <nl> } <nl> } <nl>  <nl> - public void testgetinstanceclearscachewhenfailed ( ) { <nl> + <nl> + public void disabletestgetinstanceclearscachewhenfailed ( ) { <nl> string realm_name = " invalid_cache . realm " ; <nl> realm . deleterealmfile ( getcontext ( ) , realm_name ) ; <nl> random random = new random ( ) ;
public class realmtest extends androidtestcase { <nl> byte [ ] key = new byte [ 64 ] ; <nl> random . nextbytes ( key ) ; <nl> realm realm = realm . getinstance ( getcontext ( ) , realm_name , key ) ; / / create starting realm with key1 <nl> + realm . executetransaction ( new realm . transaction ( ) { <nl> + @ override <nl> + public void execute ( realm realm ) { <nl> + realm . createobject ( alltypes . class ) ; <nl> + } <nl> + } ) ; <nl> realm . close ( ) ; <nl> random . nextbytes ( key ) ; <nl> try {
public class realmtest extends androidtestcase { <nl> outstream . close ( ) ; <nl> } <nl>  <nl> - public void testwriteencryptedcopy ( ) throws exception { <nl> + <nl> + public void disabletestwriteencryptedcopy ( ) throws exception { <nl> populatetestrealm ( ) ; <nl> long before = testrealm . where ( alltypes . class ) . count ( ) ; <nl> assertequals ( test_data_size , before ) ; <nl> mmm a / realm / src / main / java / io / realm / realm . java <nl> ppp b / realm / src / main / java / io / realm / realm . java <nl>
public class notificationstest extends androidtestcase { <nl> asserttrue ( realm . realmscache . get ( ) . isempty ( ) ) ; <nl> } <nl>  <nl> - public void testcloseclearinghandlermessages ( ) throws interruptedexception , timeoutexception , executionexception { <nl> + <nl> + public void disabledtestcloseclearinghandlermessages ( ) throws interruptedexception , timeoutexception , executionexception { <nl> final int test_size = num ; <nl> final countdownlatch backgroundlooperstarted = new countdownlatch ( 1 ) ; <nl> final countdownlatch addhandlermessages = new countdownlatch ( 1 ) ;
public class adapterexampleactivity extends activity { <nl> listview . setonitemlongclicklistener ( new adapterview . onitemlongclicklistener ( ) { <nl> @ override <nl> public boolean onitemlongclick ( adapterview < ? > adapterview , view view , int i , long l ) { <nl> - realm . begintransaction ( ) ; <nl> + <nl> + / * realm . begintransaction ( ) ; <nl> adapter . getrealmresults ( ) . remove ( i ) ; <nl> - realm . committransaction ( ) ; <nl> + realm . committransaction ( ) ; * / <nl> return true ; <nl> } <nl> } ) ;
public class realm { <nl> return realm ; <nl> } <nl>  <nl> - public void addfromjson ( class < ? extends realmobject > clazz , jsonarray json ) { <nl> + public < e extends realmobject > void addfromjson ( class < e > clazz , jsonarray json ) { <nl> + if ( json = = null ) return ; <nl> + for ( int i = num ; i < json . length ( ) ; i + + ) { <nl> + e obj = createobject ( clazz ) ; <nl> + try { <nl> + obj . populatefromjsonobject ( json . getjsonobject ( i ) ) ; <nl> + } catch ( exception e ) { <nl> + <nl> + throw new realmexception ( " could not map json " , e ) ; <nl> + } <nl> + } <nl> } <nl>  <nl> / * * <nl>
public abstract class realmbaseadapter < t extends realmobject > extends baseadapte <nl> @ override <nl> @ deprecated <nl> public long getitemid ( int i ) { <nl> - throw new unsupportedoperationexception ( " realms are unordered , hence its objects don ' t have an immutable id " ) ; <nl> + return i ; <nl> } <nl>  <nl> / * *
public class realmtest extends androidtestcase { <nl>  <nl> private final static int background_commit_test_data_set_size = num ; <nl>  <nl> - / * <nl> + / * <nl> private void getnotifications ( int totalexpected ) { <nl> int lastcount = num ; <nl> int retries = num ; <nl>
public class realmtest extends androidtestcase { <nl> } <nl> * / <nl>  <nl> - / * <nl> + / * <nl> public void testrealmthreadcachingspeed ( ) { <nl> long tic1 = system . currenttimemillis ( ) ; <nl> realm realm1 = realm . getinstance ( this . getcontext ( ) ) ; <nl>
public class realmtest extends androidtestcase { <nl> assertequals ( " realm . get is returning wrong result set " , test_data_size , resultlist . size ( ) ) ; <nl> } <nl>  <nl> - / * <nl> + / * <nl> public void testchangenotify ( ) { <nl> final int [ ] testcount = { 0 } ; <nl> testrealm . addchangelistener ( new realmchangelistener ( ) { <nl>
public class realmtest extends androidtestcase { <nl> } <nl> * / <nl>  <nl> - / * <nl> + / * <nl> / / void removechangelistener ( realmchangelistener listener ) <nl> public void testchangenotifyremove ( ) { <nl> final int [ ] testcount = { 0 } ; <nl>
public class realmtest extends androidtestcase { <nl> } <nl> * / <nl>  <nl> - / * <nl> + / * <nl> / / void removechangelistener ( realmchangelistener listener ) <nl> public void testfailchangenotifynolistener ( ) { <nl> final int [ ] testcount = { 0 } ; <nl>
public class realmtest extends androidtestcase { <nl> } <nl> * / <nl>  <nl> - / * <nl> + / * <nl> / / void removeallchangelisteners ( ) <nl> public void testremoveallchangelisteners ( ) { <nl> final int [ ] testcount = new int [ 1 ] ; <nl>
public class realmtest extends androidtestcase { <nl> } <nl> * / <nl>  <nl> - / * <nl> + / * <nl> / / void removeallchangelisteners ( ) <nl> public void testfailremoveallchangelisteners ( ) { <nl> final int [ ] testcount = { 0 } ; <nl>
public class realmtest extends androidtestcase { <nl> } <nl> * / <nl>  <nl> - / * <nl> + / * <nl> public void testchangeupdatefromotherthread ( ) { <nl> final int [ ] testcount = { 0 } ;
public class realmproxyclassgenerator { <nl> writer . emitstatement ( " throw new illegalstateexception ( \ " missing table ' % s % s ' for column ' % s ' \ " ) " , <nl> table_prefix , fieldtypename , fieldname ) ; <nl> writer . endcontrolflow ( ) ; <nl> - writer . emitstatement ( " table table_ % d = transaction . gettable ( \ " % s % s \ " ) " , columnnumber , table_prefix , fieldtypename ) ; <nl> - writer . begincontrolflow ( " if ( table . getlinktarget ( % d ) . equals ( table_ % d ) ) " , columnnumber , columnnumber ) ; <nl> - writer . emitstatement ( " throw new illegalstateexception ( \ " mismatching link tables for column ' % s ' \ " ) " , <nl> - fieldname ) ; <nl> - writer . endcontrolflow ( ) ; <nl> + <nl> + / / writer . begincontrolflow ( " if ( table . getlinktarget ( % d ) . equals ( table_ % d ) ) " , columnnumber , columnnumber ) ; <nl> + / / writer . emitstatement ( " throw new illegalstateexception ( \ " mismatching link tables for column ' % s ' \ " ) " , <nl> + / / fieldname ) ; <nl> + / / writer . endcontrolflow ( ) ; <nl> } else if ( typeutils . isassignable ( field . astype ( ) , realmlist ) ) { / / link lists <nl> string genericcanonicaltype = ( ( declaredtype ) field . astype ( ) ) . gettypearguments ( ) . get ( 0 ) . tostring ( ) ; <nl> string generictype ; <nl>
public class realmproxyclassgenerator { <nl> writer . emitstatement ( " throw new illegalstateexception ( \ " missing table ' % s % s ' for column ' % s ' \ " ) " , <nl> table_prefix , generictype , fieldname ) ; <nl> writer . endcontrolflow ( ) ; <nl> - writer . emitstatement ( " table table_ % d = transaction . gettable ( \ " % s % s \ " ) " , columnnumber , table_prefix , generictype ) ; <nl> - writer . begincontrolflow ( " if ( table . getlinktarget ( % d ) . equals ( table_ % d ) ) " , columnnumber , columnnumber ) ; <nl> - writer . emitstatement ( " throw new illegalstateexception ( \ " mismatching link list tables for column ' % s ' \ " ) " , <nl> - fieldname ) ; <nl> - writer . endcontrolflow ( ) ; <nl> + <nl> + / / writer . begincontrolflow ( " if ( table . getlinktarget ( % d ) . equals ( table_ % d ) ) " , columnnumber , columnnumber ) ; <nl> + / / writer . emitstatement ( " throw new illegalstateexception ( \ " mismatching link list tables for column ' % s ' \ " ) " , <nl> + / / fieldname ) ; <nl> + / / writer . endcontrolflow ( ) ; <nl> } <nl> } <nl> writer . endcontrolflow ( ) ;
public class realmsourcecodegenerator { <nl> writer . beginmethod ( " boolean " , " equals " , enumset . of ( modifier . public ) , " object " , " o " ) ; <nl> writer . emitstatement ( " if ( this = = o ) return true " ) ; <nl> writer . emitstatement ( " if ( o = = null | | getclass ( ) ! = o . getclass ( ) ) return false " ) ; <nl> - writer . emitstatement ( classname + " a " + classname + " = ( " + classname + " ) o " ) ; / / foo afoo = ( foo ) o <nl> - writer . emitstatement ( " return ( hashcode ( ) = = a " + classname + " . hashcode ( ) ) " ) ; / / return ( hashcode ( ) = = afoo . hashcode ( ) ) <nl> + writer . emitstatement ( " % s a % s = ( % s ) o " , classname , classname , classname ) ; / / foo afoo = ( foo ) o <nl> + <nl> + for ( variableelement field : fields ) { <nl> + string fieldname = field . getsimplename ( ) . tostring ( ) ; <nl> + string capfieldname = capitalisefirstchar ( fieldname ) ; <nl> + string fieldtypecanonicalname = field . astype ( ) . tostring ( ) ; <nl> + switch ( how_to_equal . get ( fieldtypecanonicalname ) ) { <nl> + case num : / / if ( getfield ( ) ! = afoo . getfield ( ) ) return false <nl> + writer . emitstatement ( " if ( get % s ( ) ! = a % s . get % s ( ) ) return false " , capfieldname , classname , capfieldname ) ; <nl> + break ; <nl> + case num : / / if ( getfield ( ) ! = null = ! getfield ( ) . equals ( afoo . getfield ( ) ) : afoo . getfield ( ) ! = null ) return false <nl> + writer . emitstatement ( " if ( get % s ( ) ! = null ? ! get % s ( ) . equals ( a % s . get % s ( ) ) : a % s . get % s ( ) ! = null ) return false " , <nl> + capfieldname , <nl> + capfieldname , classname , capfieldname , <nl> + classname , capfieldname ) ; <nl> + break ; <nl> + case num : / / if ( ! array . equals ( getfield ( ) , afoo . getfield ( ) ) return false <nl> + writer . emitstatement ( " if ( ! array . equals ( get % s ( ) , a % s . get % s ( ) ) return false " , <nl> + capfieldname , <nl> + classname , capfieldname ) ; <nl> + break ; <nl> + case num : <nl> + writer . emitstatement ( " if ( % s . compare ( get % s , % s . get % s ) ! = num ) return false " , capitalisefirstchar ( fieldname ) , classname , capitalisefirstchar ( fieldname ) ) ; <nl> + break ; <nl> + } <nl> + <nl> + <nl> + if ( typeutils . isassignable ( field . astype ( ) , realmobject ) | | typeutils . isassignable ( field . astype ( ) , realmlist ) ) { <nl> + writer . emitstatement ( " if ( get % s ( ) ! = null ? ! get % s ( ) . equals ( % s . get % s ( ) ) : % s . get % s ( ) ! = null ) return false " , <nl> + capfieldname , <nl> + capfieldname , classname , capfieldname , <nl> + classname , capfieldname ) ; <nl> + <nl> + } <nl> + } <nl> + writer . emitstatement ( " return true " ) ; <nl> writer . endmethod ( ) ; <nl> writer . emitemptyline ( ) ;
android { <nl> minsdkversion num <nl> targetsdkversion num <nl> } <nl> + <nl> + <nl> + / / version = ' 0 . 7 . 2 . 201409121644 ' <nl> + / / } <nl> + / / <nl> + / / buildtypes { <nl> + / / debug { <nl> + / / testcoverageenabled true <nl> + / / } <nl> + / / } <nl> + <nl> + <nl> } <nl>  <nl> dependencies {
public class group { <nl> } ; <nl>  <nl> public group ( string filepath , openmode mode ) { <nl> + if ( mode . equals ( openmode . read_only ) ) <nl> + this . immutable = true ; / / group immutable <nl> + <nl> this . nativeptr = createnative ( filepath , mode . value ) ; <nl> checknativeptr ( ) ; <nl> } <nl> mmm a / tightdb - java - test / src / test / java / com / tightdb / typed / grouptest . java <nl> ppp b / tightdb - java - test / src / test / java / com / tightdb / typed / grouptest . java <nl>
public class tableview implements tableorview { <nl> throw new runtimeexception ( " not implemented yet " ) ; <nl> } <nl>  <nl> + <nl> @ override <nl> public long upperboundlong ( long columnindex , long value ) { <nl> throw new runtimeexception ( " not implemented yet " ) ;
public class jnitransactions { <nl>  <nl> clear ( ) ; <nl> } <nl> + <nl> + <nl> + @ test ( enabled = false ) <nl> + public void mustallowdoublecommitandrollback ( ) { <nl> + writetransaction trans = db . beginwrite ( ) ; <nl> + table tbl = trans . gettable ( " employeetable " ) ; <nl> + tbl . addcolumn ( columntype . columntypestring , " name " ) ; <nl> + tbl . addcolumn ( columntype . columntypeint , " number " ) ; <nl> + <nl> + / / allow commit before any changes <nl> + trans . commit ( ) ; <nl> + <nl> + tbl . add ( " hi " , num ) ; <nl> + assertequals ( 1 , tbl . size ( ) ) ; <nl> + <nl> + / / allow double commit ( ) <nl> + trans . commit ( ) ; <nl> + trans . commit ( ) ; <nl> + <nl> + / / allow double rollback <nl> + tbl . add ( " hello " , num ) ; <nl> + assertequals ( 2 , tbl . size ( ) ) ; <nl> + trans . rollback ( ) ; <nl> + trans . rollback ( ) ; <nl> + assertequals ( 1 , tbl . size ( ) ) ; <nl>  <nl> + clear ( ) ; <nl> + } <nl> + <nl> / / test : exception at all mutable methods in tablebase , tableview , <nl> / / test : above in custom typed tables <nl> / / tablequery . . . . in readtransactions
public class columntypeviewtest { <nl> v = t . where ( ) . findall ( ) ; <nl> } <nl>  <nl> + / * <nl> / / on date column________________________________ <nl> @ test ( expectedexceptions = illegalargumentexception . class ) <nl> public void getstringondatecolumn ( ) { <nl>
<nl> + <nl> + / / create a new empty group <nl> + group group = new group ( ) ; <nl> + <nl> + / / create a new table <nl> + table table = group . gettable ( " table1 " ) ; <nl> + <nl> + <nl> + / / specify the column types and names <nl> + table . addcolumn ( columntype . columntypeint , " id " ) ; <nl> + table . addcolumn ( columntype . columntypestring , " animal " ) ; <nl> + <nl> + / / add data to the table <nl> + table . add ( 1 , " lion " ) ; <nl> + table . add ( 2 , " monkey " ) ; <nl> + table . add ( 3 , " elephant " ) ; <nl> + <nl> + <nl> + / / - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - <nl> + / / serialization of the group <nl> + / / - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - <nl> + <nl> + / / a file pointing to the location of the database <nl> + file file = new file ( " mydatabase . tightdb " ) ; <nl> + <nl> + <nl> + try { <nl> + / / serialize the database to the file <nl> + group . writetofile ( file ) ; <nl> + <nl> + } catch ( ioexception e ) { <nl> + e . printstacktrace ( ) ; <nl> + } <nl> + <nl> + / / - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - <nl> + / / initialize a group from a database file <nl> + / / - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - <nl> + <nl> + / / initialize a group object from file <nl> + group = new group ( file ) ; <nl> + <nl> + / / get the number of tables in the group . in this case , only num table has been added <nl> + assert ( group . size ( ) = = num ) ; <nl> + <nl> + / / returns the name of the first ( zero - indexed ) table in the group . in this case ' table1 ' <nl> + string tablename = group . gettablename ( 0 ) ; <nl> + <nl> + / / checks if the group contains the specified table name <nl> + assert ( group . hastable ( tablename ) ) ; <nl> + <nl> + <nl> + / / - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - <nl> + / / writing to byte array and transfer over a socket <nl> + / / - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - <nl> + <nl> + <nl> + / / write group to byte array <nl> + byte [ ] bytearray = group . writetomem ( ) ; <nl> + <nl> + / / transfer the byte array using sockets <nl> + try { <nl> + socket socket = new socket ( " host " , num ) ; <nl> + dataoutputstream dout = new dataoutputstream ( socket . getoutputstream ( ) ) ; <nl> + <nl> + <nl> + dout . writeint ( bytearray . length ) ; / / write length of the array <nl> + dout . write ( bytearray ) ; / / write the array <nl> + <nl> + <nl> + <nl> + / / - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - <nl> + / / receive byte array from socket and initialize group <nl> + / / - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - <nl> + <nl> + datainputstream din = new datainputstream ( socket . getinputstream ( ) ) ; <nl> + <nl> + int length = din . readint ( ) ; / / read length of incoming byte array <nl> + byte [ ] receivedbytearray = new byte [ length ] ; <nl> + din . readfully ( receivedbytearray , num , receivedbytearray . length ) ; / / read the byte array <nl> + <nl> + <nl> + / / initialize group from the received byte array <nl> + group fromarray = new group ( receivedbytearray ) ; <nl> + <nl> + / / get the number of tables in the group . in this case , only num table has been added <nl> + assert ( fromarray . size ( ) = = num ) ; <nl> + <nl> + <nl> + } catch ( ioexception e ) { <nl> + <nl> + e . printstacktrace ( ) ; <nl> + } <nl> + <nl> + <nl> + / /
public class jnisortedlongtest { <nl> assertequals ( 7 , table . size ( ) ) ; <nl> } <nl>  <nl> - @ test <nl> + @ test ( enabled = false ) <nl> public void shouldtestsortedint ( ) { <nl> init ( ) ; <nl> long pos ; <nl> mmm a / tightdb_jni / src / com_tightdb_group . cpp <nl> ppp b / tightdb_jni / src / com_tightdb_group . cpp <nl>
public class group { <nl> } <nl>  <nl> protected native byte [ ] nativewritetomem ( long nativegroupptr ) ; <nl> + / * <nl> + * <nl>  <nl> public bytebuffer writetobytebuffer ( ) { <nl> return nativewritetobytebuffer ( nativeptr ) ; <nl> } <nl>  <nl> protected native bytebuffer nativewritetobytebuffer ( long nativegroupptr ) ; <nl> - <nl> + * / <nl> + <nl> private void throwimmutable ( ) { <nl> throw new illegalstateexception ( <nl> " mutable method call during read transaction . " ) ; <nl> mmm a / tightdb - java - doc / src / main / java / com / tightdb / doc / groupexamples . java <nl> ppp b / tightdb - java - doc / src / main / java / com / tightdb / doc / groupexamples . java <nl>
public class grouptest { <nl> group2 . close ( ) ; <nl> } <nl>  <nl> + / * <nl> @ test ( enabled = true ) <nl> public void groupbytebuffercanclose ( ) { <nl> group group = new group ( ) ; <nl>
public class tablequerytest extends abstracttabletest { <nl> assertequals ( 1 , niko2 . size ( ) ) ; <nl> } <nl>  <nl> - @ test <nl> + <nl> + @ test ( enabled = false ) <nl> public void shouldremoverows ( ) { <nl> / / remove all <nl> employeequery q = employees . where ( ) . salary . lessthan ( 100000000 ) ;
public class example { <nl> / / from num nd to num th row <nl> view = persons . range ( 2 , num ) ; <nl>  <nl> - / / fixme : introduce new class for " or ( ) " to disable such options : <nl> - persons . firstname . is ( " x " ) . or ( ) . salary . all ( ) ; <nl> - persons . firstname . is ( " x " ) . or ( ) . salary . set ( 1234 ) ; <nl> + <nl> + persons . firstname . is ( " d " ) . salary . sum ( ) ; / / no problem without or <nl> + persons . firstname . is ( " x " ) . or ( ) . salary . set ( 1234 ) ; / / problem - incorrect options <nl> + persons . firstname . is ( " x " ) . or ( ) . salary . is ( 23 ) . salary . sum ( ) ; / / correct , shorter ( query - based ) <nl> + persons . firstname . is ( " x " ) . or ( ) . salary . is ( 23 ) . findall ( ) . salary . sum ( ) ; / / correct , longer ( view - based ) <nl> + <nl>  <nl> person p1 = persons . at ( 4 ) . next ( ) ; / / num nd row <nl> person p2 = persons . last ( ) . previous ( ) ; / / num nd - last row <nl>
public class frameinfoencoder { <nl> stackslot stackslot = ( stackslot ) value ; <nl> result . type = valuetype . stackslot ; <nl> result . data = stackslot . getoffset ( data . totalframesize ) ; <nl> + <nl> result . iscompressedreference = stackslot . getplatformkind ( ) . getvectorlength ( ) = = num & & iscompressedreference ( stackslot ) ; <nl> imagesingletons . lookup ( counters . class ) . stackvaluecount . inc ( ) ; <nl>  <nl>
public class frameinfoencoder { <nl> registervalue register = ( registervalue ) value ; <nl> result . type = valuetype . register ; <nl> result . data = calleesavedregisters . singleton ( ) . getoffsetinframe ( valueutil . asregister ( register ) ) ; <nl> - result . iscompressedreference = iscompressedreference ( register ) ; <nl> + <nl> + result . iscompressedreference = register . getplatformkind ( ) . getvectorlength ( ) = = num & & iscompressedreference ( register ) ; <nl> imagesingletons . lookup ( counters . class ) . registervaluecount . inc ( ) ; <nl>  <nl> } else if ( value instanceof javaconstant ) {
public final class hotspotoptimizedcalltarget extends optimizedcalltarget implem <nl> if ( oldcode = = code ) { <nl> return ; <nl> } <nl> - if ( oldcode ! = invalid_code & & invalidateinstalledcode ! = null ) { <nl> - try { <nl> - invalidateinstalledcode . invoke ( oldcode , false ) ; <nl> - } catch ( error e ) { <nl> - throw e ; <nl> - } catch ( throwable throwable ) { <nl> - throw new internalerror ( throwable ) ; <nl> - } <nl> - } <nl> + <nl> + <nl> + / / try { <nl> + / / invalidateinstalledcode . invoke ( oldcode , false ) ; <nl> + / / } catch ( error e ) { <nl> + / / throw e ; <nl> + / / } catch ( throwable throwable ) { <nl> + / / throw new internalerror ( throwable ) ; <nl> + / / } <nl> + / / } <nl>  <nl> / / a default nmethod can be called from entry points in the vm ( e . g . , method : : _code ) <nl> / / and so allowing it to be installed here would invalidate the truth of
local repo_config = import ' . . / . . / repo - configuration . libsonnet ' ; <nl> name : ' daily - bench - vm - ' + vm . vm_setup . short_name + ' - agentscript - js - java17 - linux - amd64 ' , <nl> } , <nl>  <nl> - vm_common . gate_vm_linux_amd64 + self . vm_bench_polybenchmarks_linux_common ( is_gate = true ) + { name : ' gate - vm - ' + vm . vm_setup . short_name + ' - polybenchmarks - linux - amd64 ' } , <nl> + # <nl> + # vm_common . gate_vm_linux_amd64 + self . vm_bench_polybenchmarks_linux_common ( is_gate = true ) + { name : ' gate - vm - ' + vm . vm_setup . short_name + ' - polybenchmarks - linux - amd64 ' } , <nl> vm_common . gate_vm_linux_amd64 + self . vm_gate_polybench_linux + { name : ' gate - vm - ' + vm . vm_setup . short_name + ' - polybench - linux - amd64 ' } , <nl> ] ,
local repo_config = import ' . . / . . / repo - configuration . libsonnet ' ; <nl> name : ' daily - bench - vm - ' + vm . vm_setup . short_name + ' - agentscript - js - java17 - linux - amd64 ' , <nl> } , <nl>  <nl> - vm_common . gate_vm_linux_amd64 + self . vm_bench_polybenchmarks_linux_common ( is_gate = true ) + { name : ' gate - vm - ' + vm . vm_setup . short_name + ' - polybenchmarks - linux - amd64 ' } , <nl> + # <nl> + # vm_common . gate_vm_linux_amd64 + self . vm_bench_polybenchmarks_linux_common ( is_gate = true ) + { name : ' gate - vm - ' + vm . vm_setup . short_name + ' - polybenchmarks - linux - amd64 ' } , <nl> vm_common . gate_vm_linux_amd64 + self . vm_gate_polybench_linux + { name : ' gate - vm - ' + vm . vm_setup . short_name + ' - polybench - linux - amd64 ' } , <nl> ] ,
<nl> " gate - compiler - benchmarktest - labsjdk - 11 - linux - amd64 " : { } , <nl> " gate - compiler - benchmarktest - labsjdk - 17 - linux - amd64 " : { } , <nl>  <nl> - " gate - compiler - truffle_xcomp - labsjdk - 17 - linux - amd64 " : t ( " 1 : 30 : 00 " ) , <nl> + " gate - compiler - truffle_xcomp - labsjdk - 17 - linux - amd64 " : t ( " 1 : 30 : 00 " ) + { capabilities + : [ " ! s3_16_32 " ] } , # <nl>  <nl> " gate - compiler - bootstrap_lite - labsjdk - 11 - darwin - amd64 " : t ( " 1 : 00 : 00 " ) + c . mach5_target , <nl> " gate - compiler - bootstrap_lite - labsjdk - 17 - darwin - amd64 " : t ( " 1 : 00 : 00 " ) + c . mach5_target ,
<nl> " gate - compiler - benchmarktest - labsjdk - 11 - linux - amd64 " : { } , <nl> " gate - compiler - benchmarktest - labsjdk - 17 - linux - amd64 " : { } , <nl>  <nl> - " gate - compiler - truffle_xcomp - labsjdk - 17 - linux - amd64 " : t ( " 1 : 30 : 00 " ) , <nl> + " gate - compiler - truffle_xcomp - labsjdk - 17 - linux - amd64 " : t ( " 1 : 30 : 00 " ) + { capabilities + : [ " ! s3_16_32 " ] } , # <nl>  <nl> " gate - compiler - bootstrap_lite - labsjdk - 11 - darwin - amd64 " : t ( " 1 : 00 : 00 " ) + c . mach5_target , <nl> " gate - compiler - bootstrap_lite - labsjdk - 17 - darwin - amd64 " : t ( " 1 : 00 : 00 " ) + c . mach5_target ,
public final class hostedmethod implements sharedmethod , wrappedjavamethod , grap <nl> } <nl>  <nl> public hostedmethod clonespecialized ( list < pair < hostedmethod , integer > > context ) { <nl> + <nl> hostedmethod copy = new hostedmethod ( this , context ) ; <nl> assert copy . vtableindex = = - 1 ; <nl> / / isparsed will be set as false but doesnt seem to have any impact since we are already
public final class hostedmethod implements sharedmethod , wrappedjavamethod , grap <nl> private final localvariabletable localvariabletable ; <nl>  <nl> private final string name ; <nl> - private final string uniqueshortname ; <nl> + <nl> + final string uniqueshortname ; <nl>  <nl> public static hostedmethod create ( hosteduniverse universe , analysismethod wrapped , hostedtype holder , signature signature , <nl> constantpool constantpool , exceptionhandler [ ] handlers , hostedmethod deoptorigin ) { <nl>
public abstract class optimizedcalltarget implements compilabletruffleast , rootc <nl>  <nl> @ truffleboundary <nl> private boolean lasttiercompile ( ) { <nl> - maybepropagatehotness ( ) ; <nl> + maybesubmitcallerforcompilation ( ) ; <nl> return compile ( true ) ; <nl> } <nl>  <nl> - private void maybepropagatehotness ( ) { <nl> + private void maybesubmitcallerforcompilation ( ) { <nl> if ( ! polyglotcompileroptions . propagatehotnesstosinglecaller . getvalue ( getoptionvalues ( ) ) ) { <nl> return ; <nl> } <nl> - if ( singlecallnode = = no_call | | singlecallnode = = multiple_calls ) { <nl> + framedescriptor parentframedescriptor = rootnode . getparentframedescriptor ( ) ; <nl> + if ( parentframedescriptor = = null ) { <nl> return ; <nl> } <nl> - optimizeddirectcallnode optimizeddirectcallnode = singlecallnode . get ( ) ; <nl> + maybesubmitcallerforcompilation ( this , parentframedescriptor ) ; <nl> + } <nl> + private static boolean maybesubmitcallerforcompilation ( optimizedcalltarget current , framedescriptor parentframedescriptor ) { <nl> + if ( current . singlecallnode = = no_call | | current . singlecallnode = = multiple_calls ) { <nl> + return false ; <nl> + } <nl> + optimizeddirectcallnode optimizeddirectcallnode = current . singlecallnode . get ( ) ; <nl> assert optimizeddirectcallnode ! = null ; <nl> rootnode callerrootnode = optimizeddirectcallnode . getrootnode ( ) ; <nl> - if ( callerrootnode = = null | | ! graaltruffleruntime . getruntime ( ) . getframematerializecalled ( callerrootnode . getframedescriptor ( ) ) ) { <nl> - return ; <nl> + if ( callerrootnode = = null ) { <nl> + return false ; <nl> } <nl> optimizedcalltarget onlycaller = ( optimizedcalltarget ) callerrootnode . getcalltarget ( ) ; <nl> - system . out . println ( " @ @ adding " + this . callandloopcount + " callandloopcount from " + this + " to " + onlycaller ) ; <nl> - onlycaller . callandloopcount + = this . callandloopcount ; <nl> + boolean submitted ; <nl> + if ( callerrootnode . getframedescriptor ( ) . equals ( parentframedescriptor ) ) { <nl> + onlycaller . forcecompilesomehow ( ) ; <nl> + submitted = true ; <nl> + } else { <nl> + submitted = maybesubmitcallerforcompilation ( onlycaller , parentframedescriptor ) ; <nl> + } <nl> + if ( submitted ) { <nl> + optimizeddirectcallnode . forceinlining ( ) ; <nl> + } <nl> + return submitted ; <nl> + } <nl> + <nl> + private void forcecompilesomehow ( ) { <nl> + <nl> } <nl>  <nl> private object executerootnode ( virtualframe frame , compilationstate tier ) { <nl> mmm a / truffle / src / com . oracle . truffle . api / src / com / oracle / truffle / api / nodes / rootnode . java <nl> ppp b / truffle / src / com . oracle . truffle . api / src / com / oracle / truffle / api / nodes / rootnode . java <nl>
public final class polyglotcompileroptions { <nl> @ option ( help = " reduce or increase the compilation threshold depending on the size of the compilation queue ( default : true ) . " , usagesyntax = " true | false " , category = optioncategory . internal ) / / <nl> public static final optionkey < boolean > dynamiccompilationthresholds = new optionkey < > ( true ) ; <nl>  <nl> + @ option ( help = " <nl> + public static final optionkey < boolean > propagatehotnesstosinglecaller = new optionkey < > ( false ) ; <nl> + <nl> @ option ( help = " the minimal scale the compilation thresholds can be reduced to ( default : num . 1 ) . " , usagesyntax = " [ 0 . 0 , inf ) " , category = optioncategory . internal ) / / <nl> public static final optionkey < double > dynamiccompilationthresholdsminscale = new optionkey < > ( 0 . 1 ) ; <nl>  <nl> mmm a / compiler / src / org . graalvm . compiler . truffle . runtime / src / org / graalvm / compiler / truffle / runtime / optimizedcalltarget . java <nl> ppp b / compiler / src / org . graalvm . compiler . truffle . runtime / src / org / graalvm / compiler / truffle / runtime / optimizedcalltarget . java <nl>
public final class target_java_lang_classloader { <nl> / / all classes are already linked at runtime . <nl> } <nl>  <nl> - @ delete <nl> - private static native class < ? > defineclass1 ( classloader loader , string name , byte [ ] b , int off , int len , protectiondomain pd , string source ) ; <nl> + <nl> + / * * <nl> + * <nl> + * / <nl> + @ substitute <nl> + @ suppresswarnings ( " unused " ) <nl> + private static class < ? > defineclass1 ( classloader loader , string name , byte [ ] b , int off , int len , protectiondomain pd , string source ) { <nl> + throw vmerror . unsupportedfeature ( " defining classes at runtime is not supported . " ) ; <nl> + } <nl>  <nl> @ delete <nl> private static native class < ? > defineclass2 ( classloader loader , string name , java . nio . bytebuffer b , int off , int len , protectiondomain pd , string source ) ;
public final class hostedmethod implements sharedmethod , wrappedjavamethod , grap <nl> public executable getjavamethod ( ) { <nl> return originalmethodprovider . getjavamethod ( getdeclaringclass ( ) . universe . getsnippetreflection ( ) , wrapped ) ; <nl> } <nl> + <nl> + static final class specializationreason implements comparable < specializationreason > { <nl> + list < pair < hostedmethod , integer > > context ; <nl> + reason reason ; <nl> + <nl> + private specializationreason ( list < pair < hostedmethod , integer > > context , reason reason ) { <nl> + this . context = context ; <nl> + this . reason = reason ; <nl> + } <nl> + <nl> + public static specializationreason create ( ) { <nl> + return new specializationreason ( collections . emptylist ( ) , reason . none ) ; <nl> + } <nl> + <nl> + public static specializationreason create ( list < pair < hostedmethod , integer > > context ) { <nl> + assert context ! = null ; <nl> + return new specializationreason ( context , reason . hot_method ) ; <nl> + } <nl> + <nl> + @ override <nl> + public int compareto ( specializationreason o ) { <nl> + int result = math . max ( math . min ( context . size ( ) - o . context . size ( ) , num ) , - 1 ) ; <nl> + if ( result ! = num ) { <nl> + return result ; <nl> + } <nl> + for ( int i = num ; i < context . size ( ) ; i + + ) { <nl> + int bci1 = context . get ( i ) . getright ( ) ; <nl> + int bci2 = o . context . get ( i ) . getright ( ) ; <nl> + result = math . max ( math . min ( bci1 - bci2 , num ) , - 1 ) ; <nl> + if ( result = = num ) { <nl> + hostedmethod m1 = context . get ( i ) . getleft ( ) ; <nl> + hostedmethod m2 = o . context . get ( i ) . getleft ( ) ; <nl> + <nl> + result = hosteduniverse . method_comparator . compare ( m1 , m2 ) ; <nl> + } <nl> + if ( result ! = num ) { <nl> + break ; <nl> + } <nl> + } <nl> + assert result ! = num ; <nl> + return result ; <nl> + } <nl> + <nl> + enum reason { <nl> + none , <nl> + hot_method <nl> + } <nl> + } <nl> } <nl> mmm a / substratevm / src / com . oracle . svm . hosted / src / com / oracle / svm / hosted / meta / hosteduniverse . java <nl> ppp b / substratevm / src / com . oracle . svm . hosted / src / com / oracle / svm / hosted / meta / hosteduniverse . java <nl>
public final class centrypointcallstubmethod extends entrypointcallstubmethod { <nl> kit . createreturn ( returnvalue , returnvalue . getstackkind ( ) ) ; <nl> } <nl>  <nl> + / * * <nl> + * <nl> + * / <nl> private static void patchnodesourceposition ( invokewithexceptionnode invoke ) { <nl> nodesourceposition position = invoke . getnodesourceposition ( ) ; <nl> if ( position ! = null & & position . getbci ( ) = = bytecodeframe . invalid_framestate_bci ) {
import com . oracle . truffle . llvm . spi . nativetypelibrary ; <nl> @ exportlibrary ( interoplibrary . class ) <nl> public final class llvmlinuxaarch64valiststorage extends llvmvaliststorage { <nl>  <nl> - / / % struct . __va_list = type { i8 * , i8 * , i8 * , i32 , i32 } <nl> + / / % struct . std : : __va_list = type { i8 * , i8 * , i8 * , i32 , i32 } <nl>  <nl> - public static final structuretype va_list_type = structuretype . createnamedfromlist ( " struct . __va_list " , false , <nl> + <nl> + public static final structuretype va_list_type = structuretype . createnamedfromlist ( " struct . std : : __va_list " , false , <nl> new arraylist < > ( arrays . aslist ( pointertype . i8 , pointertype . i8 , pointertype . i8 , primitivetype . i32 , primitivetype . i32 ) ) ) ; <nl>  <nl> private object [ ] originalargs ;
local sc = ( import " ci_common / sulong - common . jsonnet " ) ; <nl>  <nl> sc . gate + $ . sulong + sc . labsjdk_ce_17 + sc . linux_aarch64 + sc . llvmbundled + sc . requiregmp + sc . gatetags ( basictagsnonwcc ) + { name : " gate - sulong - basic - llvm - jdk17 - linux - aarch64 " , timelimit : " 30 : 00 " } , <nl>  <nl> - sc . gate + $ . sulong + sc . labsjdk_ce_17 + sc . darwin_aarch64 + sc . llvmbundled + sc . gatetags ( basictagsnonwcc ) + { name : " gate - sulong - basic - llvm - jdk17 - darwin - aarch64 " , timelimit : " 30 : 00 " } , <nl> + # <nl> + sc . gate + $ . sulong + sc . labsjdk_ce_17 + sc . darwin_aarch64 + sc . llvmbundled + sc . gatetags ( " build , sulongbasic " ) + { name : " gate - sulong - basic - jdk17 - darwin - aarch64 " , timelimit : " 30 : 00 " } , <nl>  <nl> sc . weekly + $ . sulong + sc . labsjdk_ce_17 + sc . linux_amd64 + sc . llvmbundled + sc . requiregmp + sc . requiregcc + $ . sulong_coverage { name : " weekly - sulong - coverage - jdk17 - linux - amd64 " } , <nl> ] ] ,
public class canonicalizerphase extends basephase < coreproviders > { <nl>  <nl> @ override <nl> public int hashcode ( ) { <nl> + <nl> + / / executions are over . <nl> + <nl> if ( customsimplification = = null ) { <nl> - return objects . hash ( this . getclass ( ) . hashcode ( ) , features . tostring ( ) ) ; <nl> + return objects . hash ( this . getclass ( ) . getname ( ) , features . tostring ( ) ) ; <nl> } <nl>  <nl> - return objects . hash ( this . getclass ( ) , features . tostring ( ) , <nl> + return objects . hash ( this . getclass ( ) . getname ( ) , features . tostring ( ) , <nl> customsimplification . getclass ( ) . getname ( ) ) ; <nl> } <nl>  <nl> mmm a / compiler / src / org . graalvm . compiler . phases . common / src / org / graalvm / compiler / phases / common / iterativeconditionaleliminationphase . java <nl> ppp b / compiler / src / org . graalvm . compiler . phases . common / src / org / graalvm / compiler / phases / common / iterativeconditionaleliminationphase . java <nl>
public class iterativeconditionaleliminationphase extends basephase < coreprovider <nl>  <nl> @ override <nl> public int hashcode ( ) { <nl> - return objects . hash ( this . getclass ( ) , fullschedule , canonicalizer ) ; <nl> + <nl> + / / executions are over . <nl> + return objects . hash ( this . getclass ( ) . getname ( ) , fullschedule , canonicalizer ) ; <nl> } <nl>  <nl> @ override <nl> mmm a / compiler / src / org . graalvm . compiler . phases / src / org / graalvm / compiler / phases / basephase . java <nl> ppp b / compiler / src / org . graalvm . compiler . phases / src / org / graalvm / compiler / phases / basephase . java <nl>
public abstract class basephase < c > implements phasesizecontract { <nl> * / <nl> @ override <nl> public int hashcode ( ) { <nl> - return this . getclass ( ) . hashcode ( ) ; <nl> + <nl> + / / executions are over . <nl> + return this . getclass ( ) . getname ( ) . hashcode ( ) ; <nl> } <nl>  <nl> / * *
public abstract class launcher { <nl> return true ; <nl> } <nl> if ( arg . startswith ( " - - help " ) ) { <nl> - return parsehelparg ( arg ) ; <nl> + parsehelparg ( arg ) ; <nl> + return true ; <nl> } <nl> return false ; <nl> } <nl>  <nl> - private boolean parsehelparg ( string arg ) { <nl> - / / legacy behaviour support <nl> - if ( " - - help : expert " . equals ( arg ) ) { <nl> - return true ; <nl> + private void parsehelparg ( string arg ) { <nl> + <nl> + if ( help_expert . equals ( arg ) ) { <nl> + out . println ( " " ) ; <nl> + out . println ( " note : the " + help_expert + " option is deprecated without replacement and will be removed . " ) ; <nl> + out . println ( " " ) ; <nl> + if ( helparg = = null ) { <nl> + helparg = " " ; <nl> + } <nl> + return ; <nl> } <nl> - if ( " - - help : internal " . equals ( arg ) ) { <nl> + if ( help_internal . equals ( arg ) ) { <nl> + out . println ( " " ) ; <nl> + out . println ( " note : the " + help_internal + " option is deprecated and will be removed . use - - help : [ id ] : internal instead . " ) ; <nl> + out . println ( " " ) ; <nl> + if ( helparg = = null ) { <nl> + helparg = " " ; <nl> + } <nl> helpinternal = true ; <nl> - return true ; <nl> + return ; <nl> } <nl> int <nl> if ( <nl> helparg = " " ; <nl> - return true ; <nl> + return ; <nl> } <nl> string helpargcandidate = arg . substring ( <nl>  <nl> if ( <nl> helparg = helpargcandidate ; <nl> - return true ; <nl> + return ; <nl> } <nl> helparg = helpargcandidate . substring ( 0 , index ) ; <nl> if ( helpargcandidate . endswith ( " : internal " ) ) { <nl> helpinternal = true ; <nl> } <nl> - return true ; <nl> } <nl>  <nl> / * * <nl>
public abstract class launcher { <nl> return true ; <nl> } <nl> if ( arg . startswith ( " - - help " ) ) { <nl> - return parsehelparg ( arg ) ; <nl> + parsehelparg ( arg ) ; <nl> + return true ; <nl> } <nl> return false ; <nl> } <nl>  <nl> - private boolean parsehelparg ( string arg ) { <nl> - / / legacy behaviour support <nl> - if ( " - - help : expert " . equals ( arg ) ) { <nl> + private void parsehelparg ( string arg ) { <nl> + <nl> + if ( help_expert . equals ( arg ) ) { <nl> out . println ( " " ) ; <nl> - out . println ( " note : the - - help : expert option is deprecated and will be removed . " ) ; <nl> + out . println ( " note : the " + help_expert + " option is deprecated without replacement and will be removed . " ) ; <nl> out . println ( " " ) ; <nl> if ( helparg = = null ) { <nl> helparg = " " ; <nl> } <nl> - return true ; <nl> + return ; <nl> } <nl> - if ( " - - help : internal " . equals ( arg ) ) { <nl> + if ( help_internal . equals ( arg ) ) { <nl> + out . println ( " " ) ; <nl> + out . println ( " note : the " + help_internal + " option is deprecated and will be removed . use - - help : [ id ] : internal instead . " ) ; <nl> + out . println ( " " ) ; <nl> + if ( helparg = = null ) { <nl> + helparg = " " ; <nl> + } <nl> helpinternal = true ; <nl> - return true ; <nl> + return ; <nl> } <nl> int <nl> if ( <nl> helparg = " " ; <nl> - return true ; <nl> + return ; <nl> } <nl> string helpargcandidate = arg . substring ( <nl>  <nl> if ( <nl> helparg = helpargcandidate ; <nl> - return true ; <nl> + return ; <nl> } <nl> helparg = helpargcandidate . substring ( 0 , index ) ; <nl> if ( helpargcandidate . endswith ( " : internal " ) ) { <nl> helpinternal = true ; <nl> } <nl> - return true ; <nl> } <nl>  <nl> / * * <nl>
public class substrateamd64backend extends substratebackend implements lirgenera <nl>  <nl> private void vzeroupper ( lirgeneratortool gen , value [ ] arguments , lirframestate callstate ) { <nl> if ( ! substrateutil . hosted ) { <nl> - boolean maycontainfp = / * hslinkage . maycontainfp ( ) ; * / true ; <nl> - boolean isinimage = / * ! hslinkage . iscompiledstub ( ) ; * / true ; <nl> - amd64 arch = ( amd64 ) gen . target ( ) . arch ; <nl> - var hostedcpufeatures = imagesingletons . lookup ( cpufeatureaccess . class ) . buildtimecpufeatures ( ) ; <nl> - var runtimecpufeatures = arch . getfeatures ( ) ; <nl> - if ( ! hostedcpufeatures . contains ( avx ) & & runtimecpufeatures . contains ( avx ) & & maycontainfp & & isinimage & & ! isruntimetoruntimecall ( callstate ) ) { <nl> + <nl> + boolean maycontainfp = true ; <nl> + if ( buildtimetoruntimeisavxssetransition ( gen . target ( ) ) & & maycontainfp & & ! isruntimetoruntimecall ( callstate ) ) { <nl> / * <nl> * if the target may contain fp ops , and it is not compiled by us , we may have an <nl> * avx - sse transition .
public final class wasmfunctionnode extends node implements bytecodeosrnode { <nl>  <nl> final wasmmemory memory = instance . memory ( ) ; <nl>  <nl> + <nl> check ( data . length , ( 1 < < num ) - num ) ; <nl> - / / generates invalid frame states in osr . <nl> - / / check ( extradata . length , ( 1 < < num ) - num ) ; <nl> + check ( extradata . length , ( 1 < < num ) - num ) ; <nl>  <nl> int opcode = unreachable ; <nl> loop : while ( offset < functionendoffset ) { <nl>
import com . oracle . truffle . espresso . runtime . staticobject ; <nl> import com . oracle . truffle . espresso . runtime . staticobject . staticobjectfactory ; <nl> import com . oracle . truffle . espresso . substitutions . substitutions ; <nl>  <nl> + <nl> @ registration ( id = espressolanguage . id , / / <nl> name = espressolanguage . name , / / <nl> implementationname = espressolanguage . implementation_name , / /
public class substrateoptions { <nl> private static valueupdatehandler optimizevalueupdatehandler ; <nl> private static valueupdatehandler debuginfovalueupdatehandler = substrateoptions : : defaultdebuginfovalueupdatehandler ; <nl>  <nl> + <nl> @ option ( help = " control native - image code optimizations : num - no optimizations , num - basic optimizations , num - aggressive optimizations . " , type = optiontype . user ) / / <nl> public static final hostedoptionkey < integer > optimize = new hostedoptionkey < > ( 2 ) { <nl> @ override <nl> mmm / dev / null <nl> ppp b / substratevm / src / com . oracle . svm . hosted / src / com / oracle / svm / hosted / economyhostedconfiguration . java <nl>
public final class llvmcontext { <nl> return reference . get ( node ) ; <nl> } <nl>  <nl> - void exitcontext ( llvmfunction sulongdisposecontext ) { <nl> + private void cleanup ( llvmfunction sulongdisposecontext ) { <nl> + if ( cleanupdone ) { <nl> + return ; <nl> + } <nl> + <nl> + if ( env . getcontext ( ) . iscancelling ( ) ) { <nl> + <nl> + / / the problem is that the following cleanup code consists of invocations of various <nl> + / / calltargets , <nl> + / / which have already been invalidated by the cancel request and an invocation would <nl> + / / throw <nl> + / / a threaddeath exception . <nl> + return ; <nl> + } <nl> + <nl> / / the following cases exist for cleanup : <nl> / / - exit ( ) or interop : execute all atexit functions , shutdown stdlib , flush io , and execute <nl> / / destructors <nl>
public final class extensionfieldobject { <nl> } <nl> / / endregion field value read / write / cas <nl>  <nl> - private static final class fieldsholderobject extends dynamicobject implements truffleobject { <nl> - fieldsholderobject ( shape shape ) { <nl> - super ( shape ) ; <nl> - } <nl> - } <nl> - <nl> public static class fieldstorageobject { <nl> + private final int slot ; <nl> + <nl> + @ compilationfinal private volatile fieldstorageobject next ; <nl>  <nl> + public fieldstorageobject ( int slot ) { <nl> + this . slot = slot ; <nl> + } <nl> } <nl>  <nl> public interface extensionfieldobjectfactory { <nl> - fieldstorageobject create ( ) ; <nl> + fieldstorageobject create ( int slot ) ; <nl> } <nl> }
public final class method extends member < signature > implements truffleobject , co <nl>  <nl> initrefkind ( ) ; <nl> this . proxy = null ; <nl> - this . isleaf = truffle . getruntime ( ) . createassumption ( ) ; <nl> + <nl> + if ( getdeclaringklass ( ) . isinterface ( ) | | isabstract ( ) ) { <nl> + / * <nl> + * <nl> + * methods . <nl> + * <nl> + * also disabled for abstract methods to reduce footprint . <nl> + * / <nl> + this . isleaf = nevervalidassumption . instance ; <nl> + } else if ( isstatic ( ) | | isprivate ( ) | | isfinalflagset ( ) | | getdeclaringklass ( ) . isfinalflagset ( ) ) { <nl> + / / nothing to assume , spare an assumption . <nl> + this . isleaf = alwaysvalidassumption . instance ; <nl> + } else { <nl> + this . isleaf = truffle . getruntime ( ) . createassumption ( ) ; <nl> + } <nl> } <nl>  <nl> public int getrefkind ( ) {
public final class llvm80bitfloat implements llvmarithmetic { <nl> public abstract llvm80bitfloat execute ( llvm80bitfloat x , llvm80bitfloat y ) ; <nl>  <nl> @ specialization ( guards = " function ! = null " ) <nl> + @ generateaot . exclude <nl> protected llvm80bitfloat docall ( llvm80bitfloat x , llvm80bitfloat y , <nl> @ cached ( " createfunction ( ) " ) wellknownnativefunctionnode function , <nl> @ cachedlanguage llvmlanguage language ) {
public final class bytecodenode extends espressomethodnode { <nl> assert osrtargets [ bci ] = = null ; <nl>  <nl> graaltruffleruntime runtime = graaltruffleruntime . getruntime ( ) ; <nl> - object existing = getmethod ( ) . getcalltarget ( ) ; <nl> - optimizedcalltarget osrtarget = runtime . createosrcalltarget ( getroot ( ) . makeosrrootnode ( bci ) ) ; <nl> + espressorootnode osrrootnode = getroot ( ) . makeosrrootnode ( bci ) ; <nl> + <nl> + assert osrrootnode . methodnode = = this ; <nl> + osrrootnode . methodnode = null ; <nl> + optimizedcalltarget osrtarget = runtime . createosrcalltarget ( osrrootnode ) ; <nl> + osrrootnode . methodnode = this ; <nl>  <nl> runtime . addlistener ( new graaltruffleruntimelistener ( ) { <nl> @ override
public final class cpusampler implements closeable { <nl> if ( delaysamplinguntilnoninternallanginit & & ! noninternallanguagecontextinitialized ) { <nl> return ; <nl> } <nl> - <nl> - long timestamp = system . currenttimemillis ( ) ; <nl> - trufflecontext [ ] contexts ; <nl> - synchronized ( cpusampler . this ) { <nl> - contexts = activecontexts . keyset ( ) . toarray ( new trufflecontext [ activecontexts . size ( ) ] ) ; <nl> - } <nl> - <nl> - context : for ( trufflecontext context : contexts ) { <nl> + long taskstarttime = system . currenttimemillis ( ) ; <nl> + for ( trufflecontext context : contexts ( ) ) { <nl> if ( context . isclosed ( ) ) { <nl> continue ; <nl> } <nl> - <nl> list < stacksample > samples = safepointstack . sample ( env , context ) ; <nl> - <nl> synchronized ( cpusampler . this ) { <nl> if ( context . isclosed ( ) ) { <nl> continue ; <nl> } <nl> map < thread , profilernode < payload > > nodes = activecontexts . get ( context ) ; <nl> + <nl> if ( nodes = = null ) { <nl> - continue context ; <nl> + continue ; <nl> } <nl> - <nl> for ( stacksample sample : samples ) { <nl> biasstatistic . accept ( sample . biasns ) ; <nl> durationstatistic . accept ( sample . durationns ) ; <nl> - <nl> profilernode < payload > threadnode = nodes . computeifabsent ( sample . thread , new function < thread , profilernode < payload > > ( ) { <nl> @ override <nl> public profilernode < payload > apply ( thread thread ) { <nl> return new profilernode < > ( ) ; <nl> } <nl> } ) ; <nl> - sample ( context , sample , threadnode , timestamp ) ; <nl> + record ( sample , threadnode , context , taskstarttime ) ; <nl> } <nl> } <nl> } <nl>  <nl> } <nl>  <nl> - private void sample ( trufflecontext context , stacksample sample , profilernode < payload > threadnode , long timestamp ) { <nl> + private void record ( stacksample sample , profilernode < payload > threadnode , trufflecontext context , long timestamp ) { <nl> synchronized ( cpusampler . this ) { <nl> / / now traverse the stack and insert the path into the tree <nl> profilernode < payload > treenode = threadnode ; <nl> - <nl> for ( int i = sample . stack . size ( ) - num ; i > = num ; i - - ) { <nl> stacktraceentry location = sample . stack . get ( i ) ; <nl> - boolean iscompiled = location . iscompiled ( ) ; <nl> treenode = addorupdatechild ( treenode , location ) ; <nl> payload payload = treenode . getpayload ( ) ; <nl> + boolean iscompiled = location . iscompiled ( ) ; <nl> if ( i = = num ) { <nl> if ( iscompiled ) { <nl> payload . selfcompiledhitcount + + ;
public final class cpusampler implements closeable { <nl> * @ since num . 0 <nl> * / <nl> public map < thread , list < stacktraceentry > > takesample ( ) { <nl> - shadowstack localshadowstack = shadowstack ; <nl> - if ( localshadowstack = = null ) { <nl> - localshadowstack = initializeshadowstack ( ) ; <nl> - } <nl> if ( delaysamplinguntilnoninternallanginit & & ! noninternallanguagecontextinitialized ) { <nl> return collections . emptymap ( ) ; <nl> } <nl> - assert localshadowstack ! = null ; <nl> map < thread , list < stacktraceentry > > stacks = new hashmap < > ( ) ; <nl> - for ( shadowstack . threadlocalstack stack : localshadowstack . getstacks ( ) ) { <nl> - if ( stack . hasstackoverflowed ( ) ) { <nl> - stackoverflowed = true ; <nl> - continue ; <nl> - } <nl> - stacktraceentry [ ] strace = stack . getstack ( ) ; <nl> - if ( strace ! = null & & strace . length > num ) { <nl> - assert ! stacks . containskey ( stack . getthread ( ) ) ; <nl> - final list < stacktraceentry > stacktraceentries = arrays . aslist ( strace ) ; <nl> - collections . reverse ( stacktraceentries ) ; <nl> - stacks . put ( stack . getthread ( ) , collections . unmodifiablelist ( stacktraceentries ) ) ; <nl> - } <nl> - } <nl> + <nl> return collections . unmodifiablemap ( stacks ) ; <nl> }
public class llvmforeignconstructorcallnode extends llvmforeigncallnode { <nl> protected llvmforeignconstructorcallnode ( llvmlanguage language , llvmfunctiondescriptor function , llvminteroptype interoptype , llvmsourcefunctiontype sourcetype , <nl> llvminteroptype . structured structuredtype , type escapetype ) { <nl> super ( language , function , interoptype , sourcetype , structuredtype , escapetype ) ; <nl> - this . languagereference = lookuplanguagereference ( llvmlanguage . class ) ; <nl> + <nl> + / * <nl> + * <nl> + * makes a difference if the new operator is overloaded . <nl> + * / <nl> + nodefactory factory = language . getactiveconfiguration ( ) . createnodefactory ( language , language . getdefaultdatalayout ( ) ) ; <nl> + llvmexpressionnode stack = factory . creategetstackfromframe ( ) ; <nl> + llvmexpressionnode size = llvmi64literalnodegen . create ( returnbasetype . getsize ( ) ) ; <nl> + malloc = language . getcapability ( llvmintrinsicprovider . class ) . generateintrinsicnode ( " malloc " , new llvmexpressionnode [ ] { stack , size } , new type [ ] { pointertype . void , primitivetype . i64 } , factory ) ; <nl> } <nl>  <nl> @ override <nl> protected object docall ( virtualframe frame , llvmstack stack ) throws arityexception , typeoverflowexception { <nl> object [ ] rawarguments = frame . getarguments ( ) ; <nl> - rawarguments [ 0 ] = languagereference . get ( ) . getllvmmemory ( ) . allocatememory ( this , returnbasetype . getsize ( ) ) ; <nl> + rawarguments [ 0 ] = malloc . executegeneric ( frame ) ; <nl> if ( packarguments . tollvm . length ! = rawarguments . length ) { <nl> / / arguments also contain ' self ' object , thus - 1 for argcount <nl> int arity = packarguments . tollvm . length - num ;
public final class llvmpthreadcontext { <nl>  <nl> / / the long - key is the thread - id <nl> private final object threadlock ; <nl> + <nl> + / * * <nl> + * <nl> + * return values . <nl> + * / <nl> private final concurrentmap < long , object > threadreturnvaluestorage ; <nl> - private final concurrentmap < long , thread > threadstorage ; <nl> + <nl> + / * * <nl> + * see doc on trufflelanguage . initializethread ( object , thread ) . <nl> + * < p > <nl> + * when a thread is created with pthread_create and it completes execution , there are no more <nl> + * references held to the thread object and the gc will free it . it might happen that at some <nl> + * later point the user calls pthread_join on the thread but by that time there are no <nl> + * references held to the thread object anymore , so it cannot be joined on . if that is the case , <nl> + * the thread must have already terminated , and the join does not need to wait . the return value <nl> + * of the thread is stored in a separate map as well , so any reference to the thread object is <nl> + * really not needed anymore . <nl> + * / <nl> + private final concurrentmap < long , weakreference < thread > > threadstorage ; <nl> private volatile boolean iscreatethreadallowed ; <nl>  <nl> private int pthreadkey ; <nl>
public final class llvmpthreadcontext { <nl>  <nl> / / the long - key is the thread - id <nl> private final object threadlock ; <nl> + <nl> + / * * <nl> + * <nl> + * return values . <nl> + * / <nl> private final concurrentmap < long , object > threadreturnvaluestorage ; <nl> - private final concurrentmap < long , thread > threadstorage ; <nl> + <nl> + / * * <nl> + * see doc on trufflelanguage . initializethread ( object , thread ) . <nl> + * < p > <nl> + * when a thread is created with pthread_create and it completes execution , there are no more <nl> + * references held to the thread object and the gc will free it . it might happen that at some <nl> + * later point the user calls pthread_join on the thread but by that time there are no <nl> + * references held to the thread object anymore , so it cannot be joined on . if that is the case , <nl> + * the thread must have already terminated , and the join does not need to wait . the return value <nl> + * of the thread is stored in a separate map as well , so any reference to the thread object is <nl> + * really not needed anymore . <nl> + * / <nl> + private final concurrentmap < long , weakreference < thread > > threadstorage ; <nl> private volatile boolean iscreatethreadallowed ; <nl>  <nl> private int pthreadkey ; <nl>
public final class listinterop extends iterableinterop { <nl> return boundscheck ( receiver , index , size ) ; <nl> } <nl>  <nl> + <nl> + <nl> private static boolean boundscheck ( staticobject receiver , long index , <nl> lookupandinvokeknownmethodnode size ) { <nl> return num < =
fastr_linux : $ { fastr } { <nl> fastr_fc : " / cm / shared / apps / gcc / 4 . 8 . 5 / bin / gfortran " <nl> } <nl> downloads : { <nl> - blas_lapack_dir : { name : " fastr - 403 - blas - lapack - gcc " , version : " 4 . 8 . 5 " , platformspecific : true } <nl> + blas_lapack_dir : { name : " fastr - 403 - blas - lapack - gcc " , version : " 4 . 8 . 5 " , platformspecific : true } , <nl> + # <nl> + fastr_recommended_binary : { name : " fastr - recommended - pkgs " , version : " 10 " , platformspecific : true } , <nl> } <nl> }
public class optimizedlocalizationsupport extends localizationsupport { <nl> super ( defaultlocale , locales ) ; <nl> } <nl>  <nl> + private final resourcebundle . control control = resourcebundle . control . getcontrol ( resourcebundle . control . format_default ) ; <nl> + <nl> / * * <nl> * get cached resource bundle . <nl> * <nl> * @ param locale this parameter is not currently used . <nl> * / <nl> public resourcebundle getcached ( string basename , locale locale ) throws missingresourceexception { <nl> - resourcebundle result = resourcebundles . get ( pair . create ( basename , locale ) ) ; <nl> - if ( result = = null ) { <nl> - string errormessage = " resource bundle not found " + basename + " , locale + " + locale + " . " + <nl> - " register the resource bundle using the option " + includeresourcebundlesoption + basename + " . " ; <nl> - for ( pair < string , locale > pair : resourcebundles . keyset ( ) ) { <nl> - system . err . println ( pair ) ; <nl> + <nl> + for ( locale candidatelocale : control . getcandidatelocales ( basename , locale ) ) { <nl> + resourcebundle result = resourcebundles . get ( pair . create ( basename , candidatelocale ) ) ; <nl> + if ( result ! = null ) { <nl> + return result ; <nl> } <nl> - throw new missingresourceexception ( errormessage , this . getclass ( ) . getname ( ) , basename ) ; <nl> } <nl> - return result ; <nl> + string errormessage = " resource bundle not found " + basename + " , locale + " + locale + " . " + <nl> + " register the resource bundle using the option " + includeresourcebundlesoption + basename + " . " ; <nl> + for ( pair < string , locale > pair : resourcebundles . keyset ( ) ) { <nl> + system . err . println ( pair ) ; <nl> + } <nl> + throw new missingresourceexception ( errormessage , this . getclass ( ) . getname ( ) , basename ) ; <nl> + <nl> } <nl> }
public abstract class localizationfeature implements feature { <nl> protected localizationsupport support ; <nl>  <nl> public static class options { <nl> + <nl> @ option ( help = " comma separated list of bundles to be included into the image . " , type = optiontype . user ) / / <nl> public static final hostedoptionkey < locatablemultioptionvalue . strings > includeresourcebundles = new hostedoptionkey < > ( new locatablemultioptionvalue . strings ( ) ) ; <nl>  <nl>
fastr : { <nl> } <nl> downloads : { <nl> f2c_binary : { name : " f2c - binary " , version : " 7 " , platformspecific : true } , <nl> - fastr_recommended_binary : { name : " fastr - recommended - pkgs " , version : " 8 " , platformspecific : true } , <nl> + # <nl> + # fastr_recommended_binary : { name : " fastr - recommended - pkgs " , version : " 8 " , platformspecific : true } , <nl> } <nl> } <nl>  <nl>
final class datalayoutparser { <nl> } <nl> } <nl> if ( ! ispointertypefound ) { <nl> - / / add a pointer datatype with size = largest integer size <nl> - int largestintegertypesize = - 1 ; <nl> - for ( datatypespecification spec : specs ) { <nl> - if ( spec . type = = datalayouttype . integer & & spec . getsize ( ) > largestintegertypesize ) { <nl> - largestintegertypesize = spec . getsize ( ) ; <nl> - } <nl> - } <nl> - if ( largestintegertypesize > num ) { <nl> - specs . add ( new datatypespecification ( datalayouttype . pointer , largestintegertypesize , largestintegertypesize , largestintegertypesize ) ) ; <nl> - } <nl> + <nl> + int defaultpointersize = num ; <nl> + specs . add ( new datatypespecification ( datalayouttype . pointer , defaultpointersize , defaultpointersize , defaultpointersize ) ) ; <nl> + / / / / add a pointer datatype with size = largest integer size <nl> + / / int largestintegertypesize = - 1 ; <nl> + / / for ( datatypespecification spec : specs ) { <nl> + / / if ( spec . type = = datalayouttype . integer & & spec . getsize ( ) > largestintegertypesize ) { <nl> + / / largestintegertypesize = spec . getsize ( ) ; <nl> + / / } <nl> + / / } <nl> + / / if ( largestintegertypesize > num ) { <nl> + / / specs . add ( new datatypespecification ( datalayouttype . pointer , largestintegertypesize , <nl> + / / largestintegertypesize , largestintegertypesize ) ) ; <nl> + / / } <nl> } <nl> }
public class trufflesafepointtest { <nl>  <nl> / / if there is an indirect truffle call in the loop <nl> / / we can omit the safepoint . if that safepoint would <nl> - / / therefore we expect a safepoint count around num but definitely less than num * num <nl> asserttrue ( string . valueof ( count ) , count < callinloopnode . loop_count * num ) ; <nl> + if ( ! truffleoptions . aot ) { <nl> + <nl> + asserttrue ( string . valueof ( count ) , count < callinloopnode . loop_count * num ) ; <nl> + } <nl> } <nl> }
public final class polyglotcompileroptions { <nl> " select ' 0 ' to never terminate the truffle compiler thread . " + <nl> " the option is not supported by all truffle runtimes . on the runtime which doesn ' t support it the option has no effect . " , <nl> category = optioncategory . expert ) <nl> - public static final optionkey < long > compileridledelay = new optionkey < > ( 1000l ) ; <nl> + <nl> + public static final optionkey < long > compileridledelay = new optionkey < > ( 10000l ) ; <nl>  <nl> @ option ( help = " minimum number of invocations or loop iterations needed to compile a guest language root when not using multi tier . " , <nl> category = optioncategory . expert )
public final class enginedata { <nl> if ( multitier ) { <nl> return options . get ( firsttiercompilationthreshold ) ; <nl> } else { <nl> + <nl> + if ( options . hasbeenset ( compilationthreshold ) ) { <nl> + return options . get ( compilationthreshold ) ; <nl> + } <nl> return options . get ( singletiercompilationthreshold ) ; <nl> } <nl> } <nl>
public final class enginedata { <nl> if ( compileimmediately ) { <nl> return num ; <nl> } <nl> + <nl> + if ( options . hasbeenset ( compilationthreshold ) ) { <nl> + return options . get ( compilationthreshold ) ; <nl> + } <nl> return options . get ( lasttiercompilationthreshold ) ; <nl> } <nl>  <nl> mmm a / truffle / changelog . md <nl> ppp b / truffle / changelog . md <nl>
public final class espressocontext { <nl> } <nl>  <nl> list < string > available = new arraylist < > ( ) ; <nl> - serviceloader < nativeaccess . provider > loader = serviceloader . load ( nativeaccess . provider . class ) ; <nl> + <nl> + serviceloader < nativeaccess . provider > loader = serviceloader . load ( nativeaccess . provider . class , getclass ( ) . getclassloader ( ) ) ; <nl> for ( nativeaccess . provider provider : loader ) { <nl> available . add ( provider . id ( ) ) ; <nl> if ( nativebackend . equals ( provider . id ( ) ) ) {
class filefd extends seekablebytechannelfd { <nl>  <nl> if ( isset ( fdflags , fdflags . append ) ) { <nl> openoptions . add ( standardopenoption . append ) ; <nl> + / / if truncate_existing is already set , the creation of the bytechannel will throw an <nl> + / / illegalargumentexception , which will be caught in directoryfd # pathopen and converted <nl> + / / to the io error number . <nl> + <nl> + / / gr - 29268 : java nio does not allow setting both append and read flags . therefore , we <nl> + / / remove the read flag if append is set . the effect is that reading will result in an <nl> + / / error if the append flag is set . it seems however that there is nothing in wasi or <nl> + / / posix preventing from reading from a file descriptor opened with the append flag , so <nl> + / / this might be a bug . <nl> + <nl> + openoptions . remove ( standardopenoption . read ) ; <nl> } <nl> if ( isset ( fdflags , fdflags . dsync ) ) { <nl> openoptions . add ( standardopenoption . dsync ) ;
public final class polyglotcompileroptions { <nl> @ option ( help = " use the priority of compilation jobs in the compilation queue . " , category = optioncategory . internal ) <nl> public static final optionkey < boolean > priorityqueue = new optionkey < > ( true ) ; <nl>  <nl> + @ option ( help = " <nl> + public static final optionkey < boolean > customqueue = new optionkey < > ( false ) ; <nl> + <nl> / / language agnostic inlining <nl>  <nl> @ option ( help = " print detailed information for inlining ( i . e . the entire explored call tree ) . " , category = optioncategory . internal ) <nl> mmm a / compiler / src / org . graalvm . compiler . truffle . runtime / src / org / graalvm / compiler / truffle / runtime / backgroundcompilequeue . java <nl> ppp b / compiler / src / org . graalvm . compiler . truffle . runtime / src / org / graalvm / compiler / truffle / runtime / backgroundcompilequeue . java <nl>
import com . oracle . svm . hosted . analysis . inflation ; <nl> * a temporary solution , we ' re disabling the moduleserviceslookupiterator in favour of the <nl> * lazyclasspathlookupiterator looking for files in meta - inf directory . therefore this feature <nl> * writes all services , even the ones from modules , into the corresponding meta - inf file . all of <nl> - * them are then discovered by the lazyclasspathlookupiterator . <nl> - * <nl> + * them are then discovered by the lazyclasspathlookupiterator . <nl> + * <nl> * one possible problem might be inconsistency between jvm and svm , but since the lookup in jvm is <nl> * very dynamic in nature ( depends on from which classloader or module you are starting ) , it might <nl> * not be possible for us to deliver services in the exact same order with " flat " single loader
public class serviceloaderfeature implements feature { <nl>  <nl> @ override <nl> public void afterregistration ( afterregistrationaccess access ) { <nl> + <nl> servicestoskip . addall ( options . serviceloaderfeatureexcludeservices . getvalue ( ) . values ( ) ) ; <nl> serviceproviderstoskip . addall ( options . serviceloaderfeatureexcludeserviceproviders . getvalue ( ) . values ( ) ) ; <nl> }
final class polyglotproxy implements truffleobject { <nl> result = empty ; <nl> } <nl> object guestvalue = languagecontext . toguestvalue ( library , result ) ; <nl> - if ( ! interoplibrary . getfactory ( ) . getuncached ( ) . hasarrayelements ( guestvalue ) ) { <nl> + interoplibrary interop = interoplibrary . getfactory ( ) . getuncached ( ) ; <nl> + if ( ! interop . hasarrayelements ( guestvalue ) ) { <nl> throw illegalproxy ( languagecontext , " getmemberkeys ( ) returned invalid value % s but must return an array of member key strings . " , <nl> languagecontext . asvalue ( guestvalue ) . tostring ( ) ) ; <nl> } <nl> + <nl> + for ( int i = num ; i < interop . getarraysize ( guestvalue ) ; i + + ) { <nl> + try { <nl> + object element = interop . readarrayelement ( guestvalue , i ) ; <nl> + if ( ! interop . isstring ( element ) ) { <nl> + throw illegalproxy ( languagecontext , " getmemberkeys ( ) returned invalid value % s but must return an array of member key strings . " , <nl> + languagecontext . asvalue ( guestvalue ) . tostring ( ) ) ; <nl> + } <nl> + } catch ( unsupportedoperationexception e ) { <nl> + compilerdirectives . shouldnotreachhere ( e ) ; <nl> + } catch ( invalidarrayindexexception e ) { <nl> + continue ; <nl> + } <nl> + } <nl> return guestvalue ; <nl> } else { <nl> throw unsupportedmessageexception . create ( ) ;
public final class callnode extends node implements comparable < callnode > { <nl> for ( invoke original : entry . invoketotrufflecallnode . getkeys ( ) ) { <nl> final trufflecallnode trufflecallnode = entry . invoketotrufflecallnode . get ( original ) ; <nl> invoke replacement = ( invoke ) duplicates . get ( ( node ) original ) ; <nl> - replacements . put ( replacement , trufflecallnode ) ; <nl> + <nl> + if ( replacement ! = null ) { <nl> + replacements . put ( replacement , trufflecallnode ) ; <nl> + } <nl> } <nl> addchildren ( callnode . this , replacements ) ; <nl> }
final class polyglotproxy implements truffleobject { <nl> result = empty ; <nl> } <nl> object guestvalue = languagecontext . toguestvalue ( library , result ) ; <nl> - if ( ! interoplibrary . getfactory ( ) . getuncached ( ) . hasarrayelements ( guestvalue ) ) { <nl> + interoplibrary interop = interoplibrary . getfactory ( ) . getuncached ( ) ; <nl> + if ( ! interop . hasarrayelements ( guestvalue ) ) { <nl> throw illegalproxy ( languagecontext , " getmemberkeys ( ) returned invalid value % s but must return an array of member key strings . " , <nl> languagecontext . asvalue ( guestvalue ) . tostring ( ) ) ; <nl> } <nl> + <nl> + for ( int i = num ; i < interop . getarraysize ( guestvalue ) ; i + + ) { <nl> + try { <nl> + object element = interop . readarrayelement ( guestvalue , i ) ; <nl> + if ( ! interop . isstring ( element ) ) { <nl> + throw illegalproxy ( languagecontext , " getmemberkeys ( ) returned invalid value % s but must return an array of member key strings . " , <nl> + languagecontext . asvalue ( guestvalue ) . tostring ( ) ) ; <nl> + } <nl> + } catch ( unsupportedoperationexception e ) { <nl> + compilerdirectives . shouldnotreachhere ( e ) ; <nl> + } catch ( invalidarrayindexexception e ) { <nl> + continue ; <nl> + } <nl> + } <nl> return guestvalue ; <nl> } else { <nl> throw unsupportedmessageexception . create ( ) ;
public final class arguments { <nl> string value = optionstring . substring ( " - xrunjdwp : " . length ( ) ) ; <nl> builder . option ( " java . jdwpoptions " , value ) ; <nl> } else if ( optionstring . startswith ( " - d " ) ) { <nl> + <nl> string key = optionstring . substring ( " - d " . length ( ) ) ; <nl> int splitat = key . indexof ( " = " ) ; <nl> string value = " " ; <nl>
public final class method extends member < signature > implements truffleobject , co <nl> return calltarget ; <nl> } <nl>  <nl> - / / substitutions are only valid for methods loaded on the boot class loader . <nl> - staticobject loader = ( staticobject ) getdeclaringklass ( ) . getdefiningclassloader ( ) ; <nl> - if ( staticobject . isnull ( loader ) ) { <nl> - espressorootnode redirectedmethod = getsubstitutions ( ) . get ( getmethod ( ) ) ; <nl> - if ( redirectedmethod ! = null ) { <nl> - calltarget = truffle . getruntime ( ) . createcalltarget ( redirectedmethod ) ; <nl> - } <nl> + <nl> + espressorootnode redirectedmethod = getsubstitutions ( ) . get ( getmethod ( ) ) ; <nl> + if ( redirectedmethod ! = null ) { <nl> + calltarget = truffle . getruntime ( ) . createcalltarget ( redirectedmethod ) ; <nl> } <nl>  <nl> if ( calltarget = = null ) {
bench - llvm - sulong - graalvm - ce : $ { bench_vm_ce_linux_base } $ { bench - llvm - sulong - comm <nl> ] <nl> run : [ <nl> [ mx , - - dynamicimport , sulong - benchmarks , - - env , ce , benchmark , - - results - file , $ { bench_vm_ce_linux_base . resultfile } , " csuite : * " , - - , - - native - vm , sulong , - - native - vm - config , default , - - jvm , graalvm - ce , - - jvm - config , " $ { jvm_config } " ] <nl> + # <nl> + [ mx , - - dynamicimport , sulong - benchmarks , - - env , ce , benchmark , - - results - file , $ { bench_vm_ce_linux_base . resultfile } , " csuite : * " , - - , - - native - vm , sulong - multi , - - native - vm - config , default , - - jvm , graalvm - ce , - - jvm - config , " $ { jvm_config } " , " - - multi - context - runs = 3 " , " - - engine . compilationfailureaction = silent " , " - - engine . treatperformancewarningsaserrors = none " ] <nl> ] <nl> timelimit : " 10 : 00 : 01 " <nl> }
public final class espressobindings implements truffleobject { <nl> @ exportmessage <nl> @ exportmessage ( name = " hasmemberreadsideeffects " ) <nl> @ suppresswarnings ( " static - method " ) <nl> - @ truffleboundary <nl> - boolean ismemberreadable ( string member ) { <nl> - return sourceversion . isname ( member ) ; <nl> + boolean ismemberreadable ( @ suppresswarnings ( " unused " ) string member ) { <nl> + <nl> + return true ; <nl> } <nl>  <nl> @ exportmessage <nl> object readmember ( string member , <nl> - @ cachedlibrary ( " this . loader " ) interoplibrary interop , <nl> @ cachedcontext ( espressolanguage . class ) espressocontext context , <nl> - @ cached branchprofile error ) throws unsupportedmessageexception , unknownidentifierexception { <nl> + @ cached branchprofile error ) throws unknownidentifierexception { <nl> if ( ! ismemberreadable ( member ) ) { <nl> error . enter ( ) ; <nl> throw unknownidentifierexception . create ( member ) ; <nl> } <nl> + meta meta = context . getmeta ( ) ; <nl> try { <nl> - staticobject clazz = ( staticobject ) interop . invokemember ( loader , " loadclass / ( ljava / lang / string ; ) ljava / lang / class ; " , member ) ; <nl> + staticobject clazz = ( staticobject ) meta . java_lang_class_forname_string_boolean_classloader . invokedirect ( null , <nl> + meta . togueststring ( member ) , false , loader ) ; <nl> return clazz . getmirrorklass ( ) ; <nl> } catch ( espressoexception e ) { <nl> error . enter ( ) ; <nl> - meta meta = context . getmeta ( ) ; <nl> if ( interpretertovm . instanceof ( e . getexceptionobject ( ) , meta . java_lang_classnotfoundexception ) ) { <nl> throw unknownidentifierexception . create ( member , e ) ; <nl> } <nl> throw e ; / / exception during class loading <nl> - } catch ( arityexception | unsupportedtypeexception e ) { <nl> - compilerdirectives . transfertointerpreter ( ) ; <nl> - throw espressoerror . shouldnotreachhere ( e ) ; <nl> } <nl> }
public final class espressolanguage extends trufflelanguage < espressocontext > { <nl> } <nl> } <nl>  <nl> + @ override <nl> + protected object getscope ( espressocontext context ) { <nl> + meta meta = context . getmeta ( ) ; <nl> + staticobject systemclassloader = ( staticobject ) meta . java_lang_classloader_getsystemclassloader . invokedirect ( null ) ; <nl> + return new topscope ( systemclassloader ) ; <nl> + } <nl> + <nl> + @ exportlibrary ( interoplibrary . class ) <nl> + static class topscope implements truffleobject { <nl> + <nl> + final staticobject loader ; <nl> + <nl> + topscope ( staticobject loader ) { <nl> + this . loader = loader ; <nl> + } <nl> + <nl> + @ exportmessage <nl> + boolean ismemberreadable ( string member ) { <nl> + <nl> + return true ; <nl> + } <nl> + <nl> + @ exportlibrary ( interoplibrary . class ) <nl> + public static final class emptykeysarray implements truffleobject { <nl> + <nl> + public static final truffleobject instance = new emptykeysarray ( ) ; <nl> + <nl> + @ exportmessage <nl> + @ suppresswarnings ( " static - method " ) <nl> + boolean hasarrayelements ( ) { <nl> + return true ; <nl> + } <nl> + <nl> + @ exportmessage <nl> + @ suppresswarnings ( " static - method " ) <nl> + long getarraysize ( ) { <nl> + return num ; <nl> + } <nl> + <nl> + @ exportmessage <nl> + @ suppresswarnings ( " static - method " ) <nl> + boolean isarrayelementreadable ( @ suppresswarnings ( " unused " ) long index ) { <nl> + return false ; <nl> + } <nl> + <nl> + @ exportmessage <nl> + @ suppresswarnings ( " static - method " ) <nl> + object readarrayelement ( long index ) throws invalidarrayindexexception { <nl> + throw invalidarrayindexexception . create ( index ) ; <nl> + } <nl> + } <nl> + <nl> + @ exportmessage <nl> + object getmembers ( boolean includeinternal ) { <nl> + return emptykeysarray . instance ; <nl> + } <nl> + <nl> + @ exportmessage <nl> + boolean hasmembers ( ) { <nl> + return true ; <nl> + } <nl> + <nl> + @ exportmessage <nl> + object readmember ( string member ) throws unsupportedmessageexception , unknownidentifierexception { <nl> + try { <nl> + staticobject clazz = ( staticobject ) interoplibrary . getuncached ( ) . invokemember ( loader , " loadclass : ( ljava / lang / string ; ) ljava / lang / class ; " , member ) ; <nl> + return clazz . getmirrorklass ( ) ; <nl> + } catch ( arityexception | unsupportedtypeexception e ) { <nl> + throw espressoerror . shouldnotreachhere ( e ) ; <nl> + } catch ( espressoexception e ) { <nl> + throw unknownidentifierexception . create ( member , e ) ; <nl> + } <nl> + } <nl> + } <nl> + <nl> @ override <nl> protected void disposecontext ( final espressocontext context ) { <nl> context . disposecontext ( ) ;
public class typeaccesschecker { <nl> } <nl>  <nl> private static boolean isclasspublic ( jnienvironment env , string classname ) { <nl> - try ( ctypeconversion . ccharpointerholder cname = tocstring ( classname ) ) { <nl> + try ( ctypeconversion . ccharpointerholder cname = tocstring ( classname . replace ( " . " , " / " ) ) ) { <nl> + <nl> jniobjecthandle clazz = jnifunctions ( ) . getfindclass ( ) . invoke ( env , cname . get ( ) ) ; <nl> if ( nullhandle ( ) . equal ( clazz ) | | clearexception ( env ) ) { <nl> return false ;
public final class nativelibrary { <nl> espressolanguage . getcurrentcontext ( ) . getlogger ( ) . log ( level . severe , " trufflenfi native library isolation is not supported . " , e ) ; <nl> throw espressoerror . shouldnotreachhere ( e ) ; <nl> } catch ( abstracttruffleexception e ) { <nl> + <nl> assert " com . oracle . truffle . nfi . impl . nfiunsatisfiedlinkerror " . equals ( e . getclass ( ) . getname ( ) ) ; <nl> + / / we treat abstracttruffleexception as if it were an unsatisfiedlinkerror . <nl> trufflelogger . getlogger ( espressolanguage . id , nativelibrary . class ) . fine ( e . getmessage ( ) ) ; <nl> return null ; <nl> }
public final class wasmblocknode extends wasmnode implements repeatingnode { <nl> trace ( " push wrap_i64 ( 0x % 016x ) = num x % 08x ( % d ) [ i32 ] " , x , result , result ) ; <nl> break ; <nl> } <nl> - case i32_trunc_f32_s : <nl> - case i32_trunc_f32_u : { <nl> + case i32_trunc_f32_u : <nl> + <nl> + case i32_trunc_f32_s : { <nl> stackpointer - - ; <nl> float x = popasfloat ( frame , stackpointer ) ; <nl> int result = ( int ) x ; <nl>
public final class wasmblocknode extends wasmnode implements repeatingnode { <nl> trace ( " push extend_i32_u ( 0x % 08x ) = num x % 016x ( % d ) [ i64 ] " , x , result , result ) ; <nl> break ; <nl> } <nl> - case i64_trunc_f32_s : <nl> - case i64_trunc_f32_u : { <nl> + case i64_trunc_f32_u : <nl> + <nl> + case i64_trunc_f32_s : { <nl> stackpointer - - ; <nl> float x = popasfloat ( frame , stackpointer ) ; <nl> long result = ( long ) x ;
final class compilationtask implements trufflecompilationtask , callable < void > , c <nl> private volatile boolean cancelled ; <nl> private volatile boolean started ; <nl>  <nl> - compilationtask ( backgroundcompilequeue . priority priority , weakreference < optimizedcalltarget > targetref , consumer < compilationtask > action , long id ) { <nl> + <nl> + public compilationtask ( backgroundcompilequeue . priority priority , weakreference < optimizedcalltarget > targetref , consumer < compilationtask > action , long id ) { <nl> this . priority = priority ; <nl> this . targetref = targetref ; <nl> this . action = action ;
public final class cancellablecompiletask implements trufflecompilationtask , cal <nl> return null ; <nl> } <nl>  <nl> - static class requestfuturetask extends futuretask < void > implements comparable < requestfuturetask > { <nl> + / * * <nl> + * <nl> + * / <nl> + static class executorservicewrapper extends futuretask < void > implements comparable < executorservicewrapper > { <nl> final cancellablecompiletask compiletask ; <nl>  <nl> - requestfuturetask ( cancellablecompiletask compiletask ) { <nl> + executorservicewrapper ( cancellablecompiletask compiletask ) { <nl> super ( compiletask ) ; <nl> this . compiletask = compiletask ; <nl> } <nl>  <nl> @ override <nl> - public int compareto ( requestfuturetask that ) { <nl> + public int compareto ( executorservicewrapper that ) { <nl> return this . compiletask . compareto ( that . compiletask ) ; <nl> }
import com . oracle . truffle . espresso . substitutions . host ; <nl> import com . oracle . truffle . espresso . vm . interpretertovm ; <nl> import com . oracle . truffle . espresso . vm . vm ; <nl>  <nl> - public final class espressoexception extends runtimeexception implements truffleexception { <nl> + <nl> + @ suppresswarnings ( " deprecation " ) <nl> + public final class espressoexception extends runtimeexception implements com . oracle . truffle . api . truffleexception { <nl> private static final long serialversionuid = - 7667957575377419520l ; <nl> private final staticobject exception ; <nl>  <nl> mmm a / src / com . oracle . truffle . espresso / src / com / oracle / truffle / espresso / runtime / espressoexitexception . java <nl> ppp b / src / com . oracle . truffle . espresso / src / com / oracle / truffle / espresso / runtime / espressoexitexception . java <nl>
<nl> * / <nl> package com . oracle . truffle . espresso . runtime ; <nl>  <nl> - import com . oracle . truffle . api . truffleexception ; <nl> import com . oracle . truffle . api . nodes . node ; <nl>  <nl> - public final class espressoexitexception extends runtimeexception implements truffleexception { <nl> + <nl> + @ suppresswarnings ( " deprecation " ) <nl> + public final class espressoexitexception extends runtimeexception implements com . oracle . truffle . api . truffleexception { <nl>  <nl> private static final long serialversionuid = num l ; <nl>  <nl> mmm a / src / com . oracle . truffle . espresso / src / com / oracle / truffle / espresso / substitutions / target_com_oracle_truffle_espresso_polyglot_polyglot . java <nl> ppp b / src / com . oracle . truffle . espresso / src / com / oracle / truffle / espresso / substitutions / target_com_oracle_truffle_espresso_polyglot_polyglot . java <nl>
public class target_com_oracle_truffle_espresso_polyglot_polyglot { <nl> } <nl> } <nl>  <nl> + <nl> + @ suppresswarnings ( " deprecation " ) <nl> @ substitution <nl> public static @ host ( object . class ) staticobject eval ( @ host ( string . class ) staticobject language , @ host ( string . class ) staticobject code , @ injectmeta meta meta ) { <nl> string languageid = meta . tohoststring ( language ) ; <nl>
public abstract class wasmbenchmarksuitebase { <nl> } <nl> context = contextbuilder . build ( ) ; <nl> benchmarkcase = wasmcase . loadbenchmarkcase ( benchmarkresource ( ) ) ; <nl> + system . out . println ( " . . . : : : benchmark " + benchmarkcase . name ( ) + " : : : . . . " ) ; <nl> benchmarkcase . getsources ( ) . foreach ( context : : eval ) ; <nl>  <nl> - value wasmbindings = context . getbindings ( " wasm " ) ; <nl> - value benchmarksetuponce = wasmbindings . getmember ( " benchmarksetuponce " ) ; <nl> - benchmarksetupeach = wasmbindings . getmember ( " benchmarksetupeach " ) ; <nl> - benchmarkteardowneach = wasmbindings . getmember ( " benchmarkteardowneach " ) ; <nl> - benchmarkrun = wasmbindings . getmember ( " benchmarkrun " ) ; <nl> + <nl> + / / a memory from a module called main . <nl> + / / we should fix that in the future . <nl> + value benchmarkmodule = context . getbindings ( " wasm " ) . getmember ( " main " ) ; <nl> + value benchmarksetuponce = benchmarkmodule . getmember ( " benchmarksetuponce " ) ; <nl> + benchmarksetupeach = benchmarkmodule . getmember ( " benchmarksetupeach " ) ; <nl> + benchmarkteardowneach = benchmarkmodule . getmember ( " benchmarkteardowneach " ) ; <nl> + benchmarkrun = benchmarkmodule . getmember ( " benchmarkrun " ) ; <nl> assert . assertnotnull ( string . format ( " no benchmarkrun method in % s . " , benchmarkcase . name ( ) ) , benchmarkrun ) ; <nl>  <nl> if ( benchmarksetuponce ! = null ) {
public final class staticobject implements truffleobject { <nl> / * * <nl> * workaround to avoid casting to object [ ] in interpretertovm ( non - leaf type check ) . <nl> * / <nl> - public void putobject ( staticobject value , int index , meta meta , branchprofile exceptioncheck ) { <nl> + public void putobject ( staticobject value , int index , meta meta , branchprofile exceptionprofile ) { <nl> checknotforeign ( ) ; <nl> assert isarray ( ) ; <nl> if ( <nl> - unsafe . putobject ( fields , getobjectfieldindex ( index ) , arraystoreexcheck ( value , ( ( arrayklass ) klass ) . getcomponenttype ( ) , meta ) ) ; <nl> + <nl> + unsafe . putobject ( fields , getobjectfieldindex ( index ) , arraystoreexcheck ( value , ( ( arrayklass ) klass ) . getcomponenttype ( ) , meta , exceptionprofile ) ) ; <nl> } else { <nl> - exceptioncheck . enter ( ) ; <nl> + exceptionprofile . enter ( ) ; <nl> throw meta . throwexception ( meta . java_lang_arrayindexoutofboundsexception ) ; <nl> } <nl> } <nl>  <nl> - private static object arraystoreexcheck ( staticobject value , klass componenttype , meta meta ) { <nl> + private static object arraystoreexcheck ( staticobject value , klass componenttype , meta meta , branchprofile exceptionprofile ) { <nl> if ( staticobject . isnull ( value ) | | instanceof ( value , componenttype ) ) { <nl> return value ; <nl> } else { <nl> + exceptionprofile . enter ( ) ; <nl> throw meta . throwexception ( meta . java_lang_arraystoreexception ) ; <nl> } <nl> }
public final class bytecodenode extends espressomethodnode { <nl> this . stackslots = arrays . copyofrange ( slots , codeattribute . getmaxlocals ( ) , codeattribute . getmaxlocals ( ) + codeattribute . getmaxstack ( ) ) ; <nl> this . bcislot = bcislot ; <nl> this . stackoverflowerrorinfo = getmethod ( ) . getsoehandlerinfo ( ) ; <nl> - noforeignobjects = truffle . getruntime ( ) . createassumption ( " noforeignobjects " ) ; <nl> + <nl> + this . noforeignobjects = truffle . getruntime ( ) . createassumption ( " noforeignobjects " ) ; <nl> + this . implicitexceptionseen = false ; <nl> } <nl>  <nl> public bytecodenode ( bytecodenode copy ) { <nl>
public final class objectklass extends klass { <nl> } <nl>  <nl> redefinecache = new redefinitioncache ( pool , linkedklass , newdeclaredmethods , mirandamethods , vtable , itable , iklasstable ) ; <nl> + <nl> + / / flush caches before invalidating to avoid races <nl> + / / a potential thread fetching new reflection data <nl> + / / will be blocked at entry until the redefinition <nl> + / / transaction is ended <nl> + flushreflectioncaches ( ) ; <nl> oldversion . assumption . invalidate ( ) ; <nl> } <nl>  <nl> + private void flushreflectioncaches ( ) { <nl> + / / increment the redefine count on the class instance to flush reflection caches <nl> + if ( redefinitioncountfield = = null ) { <nl> + for ( field f : mirror ( ) . getklass ( ) . getdeclaredfields ( ) ) { <nl> + <nl> + if ( " classredefinedcount " . equals ( f . getnameasstring ( ) ) ) { <nl> + redefinitioncountfield = f ; <nl> + break ; <nl> + } <nl> + } <nl> + } <nl> + int value = interpretertovm . getfieldint ( mirror ( ) , redefinitioncountfield ) ; <nl> + interpretertovm . setfieldint ( + + value , mirror ( ) , redefinitioncountfield ) ; <nl> + } <nl> + <nl> private static method findmethod ( parsermethod changedmethod , method [ ] declaredmethods ) { <nl> for ( method declaredmethod : declaredmethods ) { <nl> if ( changedmethod . getname ( ) . equals ( declaredmethod . getname ( ) ) & & changedmethod . getsignature ( ) . equals ( declaredmethod . getdescriptor ( ) ) ) { <nl>
this changelog summarizes major changes between truffle versions relevant to lan <nl> * added the ability to create context and context thread locals in languages and instruments . see [ contextlocal ] ( https : / / www . graalvm . org / truffle / javadoc / com / oracle / truffle / api / contextlocal . html ) and [ contextthreadlocal ] ( https : / / www . graalvm . org / truffle / javadoc / com / oracle / truffle / api / contextthreadlocal . html ) for details . <nl> * removed the hard " maximum node count " splitting limit controlled by ` trufflesplittingmaxnumberofsplitnodes ` as well as the option itself . <nl> * the ` iterations ` for ` loopnode . reportloopcount ( source , iterations ) ` must now be > = num . <nl> + * <nl>  <nl> # # version num . 2 . 0 <nl> * added new internal engine option ` showinternalstackframes ` to show internal frames specific to the language implementation in stack traces .
public final class staticobject implements truffleobject { <nl> members . add ( s ) ; <nl> } <nl> } <nl> - objectklass k ; <nl> - if ( getklass ( ) . isarray ( ) ) { <nl> - k = getklass ( ) . getmeta ( ) . java_lang_object ; <nl> - } else { <nl> - assert ! getklass ( ) . isprimitive ( ) ; <nl> - k = ( objectklass ) getklass ( ) ; <nl> - } <nl> + objectklass k = getinteropklass ( ) ; <nl>  <nl> for ( method m : k . getvtable ( ) ) { <nl> if ( lookupvirtualmethodnode . iscanditate ( m ) ) { <nl> + / / note : if there are overloading , the same key may appear twice . <nl> + <nl> members . add ( m . getnameasstring ( ) ) ; <nl> } <nl> } <nl>
public final class target_java_lang_system { <nl> private static void doarraycopy ( @ host ( object . class ) staticobject src , int srcpos , @ host ( object . class ) staticobject dest , int destpos , int length , <nl> meta meta , substitutionprofiler profiler ) { <nl> if ( staticobject . isnull ( src ) | | staticobject . isnull ( dest ) ) { <nl> - profiler . profile ( 3 ) ; <nl> + profiler . profile ( 0 ) ; <nl> throw meta . thrownullpointerexception ( ) ; <nl> } <nl> + if ( length = = num ) { <nl> + <nl> + profiler . profile ( 3 ) ; <nl> + return ; <nl> + } <nl> / / mimics hotspot implementation . <nl> if ( src . isarray ( ) & & dest . isarray ( ) ) { <nl> profiler . profile ( 14 ) ;
public class target_com_oracle_truffle_espresso_polyglot_polyglot { <nl> } <nl> } <nl>  <nl> - <nl> + <nl> + / * <nl> + * eager string conversion is necessary here since there ' s no way to access the <nl> + * content / chars of foreign strings without a full conversion . <nl> + * / <nl> if ( targetklass = = meta . java_lang_string ) { <nl> if ( ! interoplibrary . isstring ( value . rawforeignobject ( ) ) ) { <nl> throw meta . throwexceptionwithmessage ( meta . java_lang_classcastexception , " cannot cast a non - string foreign object to string " ) ;
public final class vm extends nativeenv implements contextaccess { <nl> * / <nl> } <nl>  <nl> + / * * <nl> + * return the temporary directory that the vm uses for the attach and perf data files . <nl> + * <nl> + * it is important that this directory is well - known and the same for all vm instances . it <nl> + * cannot be affected by configuration variables such as java . io . tmpdir . <nl> + * / <nl> + @ vmimpl <nl> + @ jniimpl <nl> + @ truffleboundary <nl> + public @ host ( string . class ) staticobject jvm_gettemporarydirectory ( ) { <nl> + <nl> + return getmeta ( ) . togueststring ( system . getproperty ( " java . io . tmpdir " ) ) ; <nl> + } <nl> + <nl> private static final long one_billion = num _000_000_000 ; <nl> private static final long max_diff = num x0100000000l ;
public final class espressocontext { <nl> try { <nl> if ( t . isdaemon ( ) ) { <nl> target_java_lang_thread . killthread ( guest ) ; <nl> + } <nl> + target_java_lang_thread . interrupt0 ( guest ) ; <nl> + / / give time to gracefully exit . <nl> + t . join ( 30 ) ; <nl> + int loops = num ; <nl> + while ( t . isalive ( ) & & + + loops < max_kill_spins ) { <nl> + / * <nl> + * temporary fix for running jck tests . forcefully killing all threads at <nl> + * context closing time allows to identify which failures are due to actual <nl> + * timeouts or due to thread being unresponsive . note that this still does <nl> + * not wakes up thread blocked in native . <nl> + * <nl> + * currently , threads in native can not be killed in espresso . this <nl> + * translates into a polyglot - side java . lang . illegalstateexception : the <nl> + * language did not complete all polyglot threads but should have . <nl> + * / <nl> + <nl> + target_java_lang_thread . forcekillthread ( guest ) ; <nl> target_java_lang_thread . interrupt0 ( guest ) ; <nl> t . join ( 10 ) ; <nl> - while ( t . isalive ( ) ) { <nl> - target_java_lang_thread . setthreadstop ( guest , target_java_lang_thread . killstatus . dissident ) ; <nl> - target_java_lang_thread . interrupt0 ( guest ) ; <nl> - t . join ( 10 ) ; <nl> - } <nl> - } else { <nl> - target_java_lang_thread . interrupt0 ( guest ) ; <nl> - t . join ( ) ; <nl> } <nl> } catch ( interruptedexception e ) { <nl> getlogger ( ) . warning ( " thread interrupted while stopping thread in closing context . " ) ; <nl> mmm a / src / com . oracle . truffle . espresso / src / com / oracle / truffle / espresso / substitutions / target_java_lang_thread . java <nl> ppp b / src / com . oracle . truffle . espresso / src / com / oracle / truffle / espresso / substitutions / target_java_lang_thread . java <nl>
public abstract class klass implements modifiersprovider , contextaccess , klassre <nl> return new keysarray ( members . toarray ( new string [ members . size ( ) ] ) ) ; <nl> } <nl>  <nl> + protected static boolean isobjectklass ( klass receiver ) { <nl> + return receiver instanceof objectklass ; <nl> + } <nl> + <nl> + @ exportmessage <nl> + abstract static class isinstantiable { <nl> + @ suppresswarnings ( " unused " ) <nl> + @ specialization ( guards = " receiver . isprimitive ( ) " ) <nl> + static boolean doprimitive ( klass receiver ) { <nl> + return false ; <nl> + } <nl> + <nl> + @ specialization ( guards = " isobjectklass ( receiver ) " ) <nl> + static boolean doobject ( klass receiver ) { <nl> + <nl> + return receiver . isconcrete ( ) ; <nl> + } <nl> + <nl> + @ specialization ( guards = " receiver . isarray ( ) " ) <nl> + static boolean doarray ( klass receiver ) { <nl> + return ( receiver . getelementaltype ( ) . isprimitive ( ) & & receiver . getelementaltype ( ) . getjavakind ( ) ! = javakind . void ) | | receiver . getelementaltype ( ) . isconcrete ( ) ; <nl> + } <nl> + } <nl> + <nl> / / endregion interop <nl>  <nl> static final comparator < klass > klass_id_comparator = new comparator < klass > ( ) {
public abstract class toespressonode extends node { <nl> throw unsupportedtypeexception . create ( new object [ ] { value } , klass . gettypeasstring ( ) ) ; <nl> } <nl>  <nl> - @ specialization ( guards = { " ! isstaticobject ( klass ) " , " ! isstring ( klass ) " , " ! isstringarray ( klass ) " , " ! klass . isprimitive ( ) " } ) <nl> - object donullorunsupported ( object value , <nl> - klass klass , <nl> - @ cachedlibrary ( limit = " limit " ) interoplibrary interop , <nl> - @ cached branchprofile exceptionprofile ) <nl> - throws unsupportedtypeexception { <nl> + <nl> + @ specialization ( guards = { " ! isstaticobject ( klass ) " , " ! klass . isprimitive ( ) " , " ! isstring ( klass ) " , " ! isstringarray ( klass ) " } ) <nl> + object doforeignclass ( object value , klass klass , @ cachedlibrary ( limit = " limit " ) interoplibrary interop ) { <nl> if ( interop . isnull ( value ) ) { <nl> return staticobject . createforeignnull ( value ) ; <nl> } <nl> - exceptionprofile . enter ( ) ; <nl> - throw unsupportedtypeexception . create ( new object [ ] { value } , klass . gettypeasstring ( ) ) ; <nl> + return staticobject . createforeign ( klass , value , interop ) ; <nl> } <nl>  <nl> @ suppresswarnings ( " unchecked " )
suite = { <nl> " license " : " bsd - new " , <nl> " testproject " : true , <nl> " jacoco " : " exclude " , <nl> + # <nl> + " javac . lint . overrides " : " - deprecation " , <nl> } , <nl> " com . oracle . truffle . llvm . tests . native " : { <nl> " subdir " : " tests " , <nl>
suite = { <nl> " workingsets " : " truffle , llvm " , <nl> " license " : " bsd - new " , <nl> " jacoco " : " include " , <nl> + # <nl> + " javac . lint . overrides " : " - deprecation " , <nl> } , <nl>  <nl> " com . oracle . truffle . llvm . parser " : { <nl> mmm a / sulong / projects / com . oracle . truffle . llvm / src / com / oracle / truffle / llvm / runner . java <nl> ppp b / sulong / projects / com . oracle . truffle . llvm / src / com / oracle / truffle / llvm / runner . java <nl>
public abstract class llvminteropreadnode extends llvmnode { <nl> try { <nl> assert locationtype = = foreigntollvmtype . i8 ; <nl> long res = num ; <nl> + <nl> for ( int i = num ; i < accesstypesizeinbytes ; i + + , idx + + ) { <nl> - res < < = num ; <nl> object ret = interop . readarrayelement ( location . base , idx ) ; <nl> object tollvmvalue = tollvm . executewithtype ( ret , llvminteroptype . valuekind . i8 . type , llvminteroptype . valuekind . i8 . foreigntollvmtype ) ; <nl> - res | = byte . tounsignedlong ( ( byte ) tollvmvalue ) ; <nl> + res | = byte . tounsignedlong ( ( byte ) tollvmvalue ) < < ( 8 * i ) ; <nl> } <nl> return tollvmnoconv . executewithaccesstype ( res , accesstype ) ; <nl> } catch ( invalidarrayindexexception ex ) {
public final class polyglot { <nl> } <nl>  <nl> / * * <nl> - * if < code > value < / code > is an interop object , from now on treat it as an object of < code > targetclass < / code > type . otherwise the case is a <nl> - * no - op , e . g . the existence of methods is not verified and if a method does not exist , an exception will be thrown <nl> - * < i > on method invocation < / i > . <nl> + * if { @ code value } is an interop object , changes its type to { @ code targetclass } . the existence <nl> + * of methods , defined in { @ code targetclass } , is not verified and if a method does not exist , <nl> + * an exception will be thrown only when this method is invoked . <nl> * < p > <nl> - * if < code > value < / code > is a regular espresso object , perform checkcast . <nl> - * @ throws classcastexception if < code > value < / code > is a regular espresso object and cannot be cast to < code > targetclass < / code > . <nl> + * if { @ code value } is a regular espresso object , performs { @ link class # cast checkcast } . <nl> + * <nl> + * @ throws classcastexception if { @ code value } is a regular espresso object and cannot be cast <nl> + * to { @ code targetclass } . <nl> * / <nl> public static < t > t cast ( class < ? extends t > targetclass , object value ) throws classcastexception { <nl> return targetclass . cast ( value ) ; <nl> } <nl>  <nl> + <nl> + / * * <nl> + * evaluates the given code in the given language . <nl> + * <nl> + * @ return the result of the evaluation wrapped as { @ link object } . to access members of the <nl> + * underlying interop object , write a corresponding class or interface stub in java and <nl> + * cast the eval result to it using { @ link # cast polyglot . cast } . <nl> + * / <nl> @ suppresswarnings ( " unused " ) <nl> public static object eval ( string language , string code ) { <nl> return null ; <nl> } <nl>  <nl> + / * * <nl> + * imports { @ code name } from global polyglot scope . if { @ code name } does not exist in the scope , <nl> + * returns { @ code null } . <nl> + * <nl> + * the returned interop value is wrapped as { @ link object } . to access members of the underlying <nl> + * interop object , write a corresponding class or interface stub in java and cast the eval <nl> + * result to it using { @ link # cast polyglot . cast } . <nl> + * / <nl> @ suppresswarnings ( " unused " ) <nl> public static object importobject ( string name ) { <nl> return null ; <nl> } <nl>  <nl> + / * * <nl> + * exports { @ code value } under { @ code name } to the polyglot scope . <nl> + * / <nl> @ suppresswarnings ( " unused " ) <nl> public static void exportobject ( string name , object value ) { <nl> }
public class jdkinitializationfeature implements feature { <nl> rci . initializeatbuildtime ( " org . jcp . xml . dsig . internal . dom . xmldsigri " , " required for sun . security . jca " ) ; <nl> rci . initializeatbuildtime ( " java . awt . font . textattribute " , " required for sun . text . bidi . bidibase . numericshapings " ) ; <nl> rci . initializeatbuildtime ( " java . awt . font . numericshaper " , " required for sun . text . bidi . bidibase . numericshapings " ) ; <nl> + <nl> + / * <nl> + rci . initializeatbuildtime ( " com . sun . jmx . mbeanserver . defaultmxbeanmappingfactory " , " avoids unnecessary reflection in the image " ) ; <nl> } <nl> }
public final class jnienv extends nativeenv implements contextaccess { <nl>  <nl> @ jniimpl <nl> public @ host ( string . class ) staticobject newstring ( @ pointer truffleobject unicodeptr , int len ) { <nl> + <nl> final char [ ] array = new char [ len ] ; <nl> staticobject value = staticobject . wrap ( array , getmeta ( ) ) ; <nl> setchararrayregion ( value , num , len , unicodeptr ) ; <nl> mmm a / src / com . oracle . truffle . espresso / src / com / oracle / truffle / espresso / meta / meta . java <nl> ppp b / src / com . oracle . truffle . espresso / src / com / oracle / truffle / espresso / meta / meta . java <nl>
public final class meta implements contextaccess { <nl> java_lang_management_threadinfo = knownklass ( type . java_lang_management_threadinfo ) ; <nl>  <nl> / / classes and members that differ from java num to num <nl> + <nl>  <nl> java_lang_string_value = lookupfielddiffversion ( java_lang_string , name . value , type . _char_array , name . value , type . _byte_array ) ; <nl>  <nl>
public final class meta implements contextaccess { <nl> } <nl> meta meta = str . getklass ( ) . getmeta ( ) ; <nl> if ( meta . getcontext ( ) . getjavaversion ( ) > = num ) { <nl> + <nl> byte [ ] value = ( ( staticobject ) meta . java_lang_string_value . get ( str ) ) . unwrap ( ) ; <nl> return hostjava . createstring ( stringutil . tochars ( value ) ) ; <nl> } <nl>
public final class meta implements contextaccess { <nl> final int hash = hostjava . getstringhash ( hoststring ) ; <nl> staticobject gueststring = java_lang_string . allocateinstance ( ) ; <nl> if ( getcontext ( ) . getjavaversion ( ) > = num ) { <nl> + <nl> java_lang_string_value . set ( gueststring , staticobject . wrap ( stringutil . tobytes ( value ) , this ) ) ; <nl> java_lang_string_coder . set ( gueststring , stringutil . utf16 ) ; <nl> java_lang_string_hash . set ( gueststring , hash ) ; <nl> mmm a / src / com . oracle . truffle . espresso / src / com / oracle / truffle / espresso / meta / stringutil . java <nl> ppp b / src / com . oracle . truffle . espresso / src / com / oracle / truffle / espresso / meta / stringutil . java <nl>
import com . oracle . truffle . espresso . runtime . staticobject ; <nl> import com . oracle . truffle . espresso . substitutions . target_sun_misc_unsafe ; <nl>  <nl> / * * <nl> - * helper for converting java num strings to and from java num strings . <nl> + * helper for converting java num strings to and from java num strings . taken from the java num string <nl> + * implementation . <nl> * / <nl> + <nl> public class stringutil { <nl> static final byte latin1 = num ; <nl> static final byte utf16 = num ; <nl> mmm a / src / com . oracle . truffle . espresso / src / com / oracle / truffle / espresso / substitutions / espressosubstitutions . java <nl> ppp b / src / com . oracle . truffle . espresso / src / com / oracle / truffle / espresso / substitutions / espressosubstitutions . java <nl>
import java . lang . annotation . target ; <nl> public @ interface espressosubstitutions { <nl> class < ? > value ( ) default espressosubstitutions . class ; <nl>  <nl> + <nl> string java11 ( ) default " " ; <nl> }
class jimagelibrary extends nativeenv implements contextaccess { <nl> } <nl>  <nl> private static truffleobject getnativestring ( string name ) { <nl> - / / be super safe with the size of the buffer . <nl> - bytebuffer bb = allocatedirect ( name . length ( ) + num , javakind . char ) ; <nl> - encoder . encode ( charbuffer . wrap ( name ) , bb , false ) ; <nl> - bb . put ( ( byte ) num ) ; <nl> - return bytebufferpointer ( bb ) ; <nl> + int length = ( ( int ) ( name . length ( ) * encoder . averagebytesperchar ( ) ) ) + num ; <nl> + for ( ; ; ) { <nl> + / / be super safe with the size of the buffer . <nl> + bytebuffer bb = allocatedirect ( length ) ; <nl> + encoder . reset ( ) ; <nl> + encoder . encode ( charbuffer . wrap ( name ) , bb , false ) ; <nl> + if ( bb . position ( ) < bb . capacity ( ) ) { <nl> + / / we have at least one byte of leeway : null - terminate the string . <nl> + bb . put ( ( byte ) num ) ; <nl> + return bytebufferpointer ( bb ) ; <nl> + } <nl> + / / buffer was not big enough , retry with a bigger one . <nl> + length = num ; <nl> + <nl> + } <nl> } <nl>  <nl> @ override
public abstract class graaltruffleruntime implements truffleruntime , trufflecomp <nl> } <nl> } <nl>  <nl> - public boolean cancelinstalledtask ( optimizedcalltarget optimizedcalltarget , object source , charsequence reason ) { <nl> - cancellablecompiletask task = optimizedcalltarget . getcompilationtask ( ) ; <nl> - if ( task ! = null ) { <nl> - if ( task . cancel ( ) ) { <nl> - getlistener ( ) . oncompilationdequeued ( optimizedcalltarget , source , reason ) ; <nl> - return true ; <nl> - } <nl> - } <nl> - return false ; <nl> - } <nl> - <nl> + <nl> public void waitforcompilation ( optimizedcalltarget optimizedcalltarget , long timeout ) throws executionexception , timeoutexception { <nl> cancellablecompiletask task = optimizedcalltarget . getcompilationtask ( ) ; <nl> if ( task ! = null & & ! task . iscancelled ( ) ) { <nl> mmm a / substratevm / src / com . oracle . svm . truffle / src / com / oracle / svm / truffle / api / substratetruffleruntime . java <nl> ppp b / substratevm / src / com . oracle . svm . truffle / src / com / oracle / svm / truffle / api / substratetruffleruntime . java <nl>
public abstract class optimizedcalltarget implements compilabletruffleast , rootc <nl> return system . identityhashcode ( this ) ; <nl> } <nl>  <nl> + <nl> final cancellablecompiletask getcompilationtask ( ) { <nl> return compilationtask ; <nl> }
final class target_com_oracle_truffle_polyglot_languagecache { <nl> @ alias @ recomputefieldvalue ( kind = kind . reset ) / / <nl> private string languagehome ; <nl> } <nl> + <nl> + @ targetclass ( classname = " com . oracle . truffle . polyglot . hostobject " , onlywith = trufflefeature . isenabled . class ) <nl> + final class target_com_oracle_truffle_polyglot_hostobject { <nl> + <nl> + / * * <nl> + * <nl> + * / <nl> + @ substitute <nl> + static int getarraylength ( object array ) { <nl> + if ( array = = null | | ! array . getclass ( ) . isarray ( ) ) { <nl> + compilerdirectives . transfertointerpreterandinvalidate ( ) ; <nl> + throw new illegalstateexception ( " should not reach here " ) ; <nl> + } <nl> + return knownintrinsics . readarraylength ( array ) ; <nl> + } <nl> + } <nl> mmm a / truffle / src / com . oracle . truffle . polyglot / src / com / oracle / truffle / polyglot / hostobject . java <nl> ppp b / truffle / src / com . oracle . truffle . polyglot / src / com / oracle / truffle / polyglot / hostobject . java <nl>
final class hostobject implements truffleobject { <nl>  <nl> } <nl>  <nl> + / * * <nl> + * java . lang . reflect . array . getlength is not pe - safe if the error conditions ( null or not an <nl> + * array ) can happen . in our case , we know the error conditions can ' t happen because we check <nl> + * them manually . this helper function is here to help the static analysis of native - image <nl> + * figure out that the error condition can not happen . <nl> + * <nl> + * <nl> + * / <nl> + private static int getarraylength ( object array ) { <nl> + if ( array = = null | | ! array . getclass ( ) . isarray ( ) ) { <nl> + compilerdirectives . transfertointerpreterandinvalidate ( ) ; <nl> + throw new illegalstateexception ( " should not reach here " ) ; <nl> + } <nl> + return array . getlength ( array ) ; <nl> + } <nl> + <nl> @ exportmessage <nl> long getarraysize ( @ shared ( " isarray " ) @ cached isarraynode isarray , <nl> @ shared ( " islist " ) @ cached islistnode islist ) throws unsupportedmessageexception { <nl> if ( isarray . execute ( this ) ) { <nl> - return array . getlength ( obj ) ; <nl> + return getarraylength ( obj ) ; <nl> } else if ( islist . execute ( this ) ) { <nl> return getlistsize ( ) ; <nl> }
public class graphdecoder { <nl> assert node . getnodeclass ( ) = = methodscope . encodedgraph . getnodeclasses ( ) [ typeid ] ; <nl> makefixednodeinputs ( methodscope , loopscope , node ) ; <nl> readproperties ( methodscope , node ) ; <nl> + <nl> + if ( node instanceof integerswitchnode & & ( ( integerswitchnode ) node ) . value ( ) . isconstant ( ) ) { <nl> + integerswitchnode switchnode = ( integerswitchnode ) node ; <nl> + int value = switchnode . value ( ) . asjavaconstant ( ) . asint ( ) ; <nl> + int survivingindex = switchnode . successorindexatkey ( value ) ; <nl> + abstractbeginnode survivingsuccessor = null ; <nl> + edges edges = node . getnodeclass ( ) . getsuccessoredges ( ) ; <nl> + <nl> + <nl> + for ( int <nl> + readorderid ( methodscope ) ; <nl> + } <nl> + for ( int <nl> + int size = methodscope . reader . getsvint ( ) ; <nl> + if ( size ! = - 1 ) { <nl> + nodelist < node > nodelist = new nodesuccessorlist < > ( node , size ) ; <nl> + edges . initializelist ( node , index , nodelist ) ; <nl> + for ( int idx = num ; idx < size ; idx + + ) { <nl> + int orderid = readorderid ( methodscope ) ; <nl> + if ( survivingindex = = idx ) { <nl> + survivingsuccessor = ( abstractbeginnode ) makestubnode ( methodscope , loopscope , orderid ) ; <nl> + } <nl> + } <nl> + } <nl> + } <nl> + <nl> + graph . removesplit ( switchnode , survivingsuccessor ) ; <nl> + return loopscope ; <nl> + } <nl> + <nl> makesuccessorstubs ( methodscope , successoraddscope , node , updatepredecessors ) ; <nl>  <nl> loopscope resultscope = loopscope ; <nl>
final class hscompilabletruffleast extends hsobject implements compilabletruffle <nl> return hotspotgraalservices . newhotspotspeculationlog ( cachedfailedspeculationsaddress ) ; <nl> } <nl>  <nl> + @ override <nl> + public javaconstant getnoderewritingassumptionconstant ( ) { <nl> + <nl> + return null ; <nl> + } <nl> + <nl> @ svmtohotspot ( asjavaconstant ) <nl> @ override <nl> public javaconstant asjavaconstant ( ) { <nl> mmm a / compiler / src / org . graalvm . compiler . truffle . compiler / src / org / graalvm / compiler / truffle / compiler / phases / inlining / graphmanager . java <nl> ppp b / compiler / src / org . graalvm . compiler . truffle . compiler / src / org / graalvm / compiler / truffle / compiler / phases / inlining / graphmanager . java <nl>
import jdk . vm . ci . meta . speculationlog ; <nl> * this is a truffle ast that can be optimized via partial evaluation and compiled to machine code . <nl> * <nl> * note : { @ code partialevaluator } looks up this class and a number of its methods by name . <nl> + * <nl> + * <nl> + * <nl> + * < pre > <nl> + * <nl> + * optimizedcallprofiled # call <nl> + * | <nl> + * call | <nl> + * | | <nl> + * public callindirect | callosr calldirectorinlined callinlined <nl> + * | | | | | <nl> + * | - - - - - - - - | | | | <nl> + * | | | - - - - - - - - - - - | | | <nl> + * | | | | - - - - - - - - - - - - - no - inlined ? - yes - - - - | <nl> + * protected doinvoke | <nl> + * | | <nl> + * | < - jump to installed code in pe | <nl> + * | | <nl> + * protected callboundary | <nl> + * | | <nl> + * | < - tail jump to installed code in int | <nl> + * | | <nl> + * protected profiledperoot inlinedperoot <nl> + * [ callroot ] [ callinlinedagnostic ] <nl> + * | | <nl> + * | | <nl> + * | | <nl> + * private | - - - - - - - - - - - - - - - executerootnode ( ) - - - - - - - - - - | <nl> + * [ callproxy ] <nl> + * | <nl> + * | <nl> + * rootnode . execute ( ) <nl> + * <nl> + * < / pre > <nl> * / <nl> @ suppresswarnings ( " deprecation " ) <nl> public abstract class optimizedcalltarget implements compilabletruffleast , rootcalltarget , replaceobserver {
import jdk . vm . ci . meta . speculationlog ; <nl> public abstract class optimizedcalltarget implements compilabletruffleast , rootcalltarget , replaceobserver { <nl>  <nl> private static final string node_rewriting_assumption_name = " noderewritingassumption " ; <nl> + <nl> static final string call_boundary_method_name = " executerootnode " ; <nl> static final string call_inlined_method_name = " call " ; <nl> private static final atomicreferencefieldupdater < optimizedcalltarget , speculationlog > speculation_log_updater = atomicreferencefieldupdater . newupdater ( optimizedcalltarget . class ,
public class valueassert { <nl> assertequals ( ( byte ) intvalue = = intvalue , value . fitsinbyte ( ) ) ; <nl> assertequals ( ( short ) intvalue = = intvalue , value . fitsinshort ( ) ) ; <nl> } else { <nl> - assertfails ( ( ) - > value . asint ( ) , classcastexception . class ) ; <nl> + <nl> + assertfails ( ( ) - > value . asint ( ) , classcastexception . class , polyglotexception . class ) ; <nl> } <nl>  <nl> if ( value . fitsinlong ( ) ) { <nl>
public class valueassert { <nl> break ; <nl> case instantiable : <nl> assertfalse ( value . caninstantiate ( ) ) ; <nl> - assertfails ( ( ) - > value . newinstance ( ) , unsupportedoperationexception . class ) ; <nl> + <nl> + assertfails ( ( ) - > value . newinstance ( ) , unsupportedoperationexception . class , polyglotexception . class ) ; <nl> if ( value . isnull ( ) ) { <nl> assertnull ( value . as ( function . class ) ) ; <nl> assertnull ( value . as ( isfunctionalinterfacevarargs . class ) ) ; <nl>
public abstract class llvmamd64syscallclockgettimenode extends llvmsyscalloperat <nl> return doi64 ( clkid , llvmnativepointer . create ( tp ) ) ; <nl> } <nl>  <nl> + <nl> + @ compilerdirectives . truffleboundary <nl> + private static long getcurrenttimemillis ( ) { <nl> + return system . currenttimemillis ( ) ; <nl> + } <nl> + <nl> private int clockgettime ( int clkid , llvmpointer timespec ) { <nl> long s ; <nl> long ns ; <nl> switch ( clkid ) { <nl> case clock_realtime : { <nl> - long t = system . currenttimemillis ( ) ; <nl> + long t = getcurrenttimemillis ( ) ; <nl> s = t / num ; <nl> ns = ( t % num ) * num ; <nl> break ; <nl> mmm a / sulong / projects / com . oracle . truffle . llvm . runtime / src / com / oracle / truffle / llvm / runtime / types / type . java <nl> ppp b / sulong / projects / com . oracle . truffle . llvm . runtime / src / com / oracle / truffle / llvm / runtime / types / type . java <nl>
public abstract class llvmamd64syscallclockgettimenode extends llvmsyscalloperat <nl> return doi64 ( clkid , llvmnativepointer . create ( tp ) ) ; <nl> } <nl>  <nl> + <nl> + @ compilerdirectives . truffleboundary <nl> + private static long getcurrenttimemillis ( ) { <nl> + return system . currenttimemillis ( ) ; <nl> + } <nl> + <nl> private int clockgettime ( int clkid , llvmpointer timespec ) { <nl> long s ; <nl> long ns ; <nl> switch ( clkid ) { <nl> case clock_realtime : { <nl> - long t = system . currenttimemillis ( ) ; <nl> + long t = getcurrenttimemillis ( ) ; <nl> s = t / num ; <nl> ns = ( t % num ) * num ; <nl> break ;
public final class llvmparser { <nl> importedsymbols . add ( global . getname ( ) ) ; <nl> } else { <nl> assert exporteddescriptor . isfunction ( ) ; <nl> - throw new llvmlinkerexception ( " the global variable " + global . getname ( ) + " conflicts with a function that has the same name . " ) ; <nl> + <nl> + / / allows certain use cases to work correctly <nl> + / / this was : <nl> + / / throw new llvmlinkerexception ( " the global variable " + global . getname ( ) + " <nl> + / / conflicts with a function that has the same name . " ) ; <nl> } <nl> } <nl> } <nl>
public final class llvmparser { <nl> importedsymbols . add ( functionsymbol . getname ( ) ) ; <nl> } else { <nl> assert exporteddescriptor . isglobalvariable ( ) ; <nl> - throw new llvmlinkerexception ( " the function " + functionsymbol . getname ( ) + " conflicts with a global variable that has the same name . " ) ; <nl> + <nl> + / / allows certain use cases to work correctly <nl> + / / this was : <nl> + / / throw new llvmlinkerexception ( " the function " + functionsymbol . getname ( ) + " <nl> + / / conflicts with a global variable that has the same name . " ) ; <nl> } <nl> } <nl> } <nl> mmm a / sulong / projects / com . oracle . truffle . llvm / src / com / oracle / truffle / llvm / runner . java <nl> ppp b / sulong / projects / com . oracle . truffle . llvm / src / com / oracle / truffle / llvm / runner . java <nl>
final class runner { <nl> globalscope . register ( functionsymbol ) ; <nl> } else if ( ! functionsymbol . isfunction ( ) ) { <nl> assert functionsymbol . isglobalvariable ( ) ; <nl> - throw new llvmlinkerexception ( <nl> - " the function " + function . getname ( ) + " is declared as external but its definition is shadowed by a conflicting function with the same name . " ) ; <nl> + <nl> + / / allows certain use cases to work correctly <nl> + / / this was : <nl> + / / throw new llvmlinkerexception ( <nl> + / / " the function " + function . getname ( ) + " is declared as external but its <nl> + / / definition is shadowed by a conflicting global variable with the same <nl> + / / name . " ) ; <nl> } <nl>  <nl> / / there can already be a different local entry in the file scope <nl>
final class runner { <nl> globalsymbol = llvmglobal . create ( global . getname ( ) , global . gettype ( ) , global . getsourcesymbol ( ) , global . isreadonly ( ) , global . getindex ( ) , parserresult . getruntime ( ) . getbitcodeid ( ) ) ; <nl> } else if ( ! globalsymbol . isglobalvariable ( ) ) { <nl> assert globalsymbol . isfunction ( ) ; <nl> - throw new llvmlinkerexception ( <nl> - " the global variable " + global . getname ( ) + " is declared as external but its definition is shadowed by a conflicting global variable with the same name . " ) ; <nl> + <nl> + / / allows certain use cases to work correctly <nl> + / / this was : <nl> + / / throw new llvmlinkerexception ( " the global variable " + global . getname ( ) + " <nl> + / / is declared as external but its definition is shadowed by a conflicting <nl> + / / function with the same name . " ) ; <nl> } <nl>  <nl> / / there can already be a different local entry in the file scope
public final class vm extends nativeenv implements contextaccess { <nl> return javalibrary ; <nl> } <nl>  <nl> + private @ pointer truffleobject loadjavalibrary ( list < path > bootlibrarypath ) { <nl> + / / comment from hotspot : <nl> + / / try to load verify dll first . in num . 3 java dll depends on it and is not <nl> + / / always able to find it when the loading executable is outside the jdk . <nl> + / / in order to keep working with num . 2 we ignore any loading errors . <nl> + / * verifylibrary = * / loadlibrary ( bootlibrarypath , " verify " ) ; <nl> + truffleobject libjava = loadlibrary ( bootlibrarypath , " java " ) ; <nl> + <nl> + / / the jni_onload handling is normally done by method load in <nl> + / / java . lang . classloader $ nativelibrary , but the vm loads the base library <nl> + / / explicitly so we have to check for jni_onload as well <nl> + / / libjava is initialized after libjvm ( espresso vm native context ) . <nl> + try { <nl> + <nl> + truffleobject jnionload = nativelibrary . lookupandbind ( libjava , " jni_onload " , " ( pointer , pointer ) : sint32 " ) ; <nl> + getuncached ( ) . execute ( jnionload , vmptr , rawpointer . nullinstance ( ) ) ; <nl> + } catch ( unknownidentifierexception e ) { <nl> + / / ignore <nl> + } catch ( unsupportedtypeexception | unsupportedmessageexception | arityexception e ) { <nl> + throw espressoerror . shouldnotreachhere ( e ) ; <nl> + } <nl> + <nl> + return libjava ; <nl> + } <nl> + <nl> private vm ( jnienv jnienv ) { <nl> this . jnienv = jnienv ; <nl> try { <nl> espressoproperties props = getcontext ( ) . getvmproperties ( ) ; <nl>  <nl> - list < path > libjavasearchpaths = new arraylist < > ( ) ; <nl> - libjavasearchpaths . addall ( props . bootlibrarypath ( ) ) ; <nl> - libjavasearchpaths . addall ( props . javalibrarypath ( ) ) ; <nl> - <nl> mokapotlibrary = loadlibrary ( collections . singletonlist ( props . espressolibrarypath ( ) ) , " mokapot " ) ; <nl> - <nl> assert mokapotlibrary ! = null ; <nl> - javalibrary = loadlibrary ( libjavasearchpaths , " java " ) ; <nl>  <nl> initializemokapotcontext = nativelibrary . lookupandbind ( mokapotlibrary , <nl> " initializemokapotcontext " , " ( env , pointer , ( pointer ) : pointer ) : pointer " ) ; <nl>
public final class nficontextextension implements contextextension { <nl> return true ; <nl> } else if ( filename . startswith ( " libpolyglot - mock . " ) ) { <nl> / / special mock library for polyglot intrinsics <nl> - return true ; <nl> - } else if ( filename . startswith ( " libsulong + + - native . " ) | | filename . startswith ( " libc + + . " ) ) { <nl> - / * <nl> - * dummy library that doesn ' t actually exist , but is implicitly replaced by libc + + if <nl> - * available . the libc + + dependency is optional . the bitcode interpreter will still work <nl> - * if it is not found , but c + + programs might not work because of unresolved symbols . <nl> - * / <nl> - string libname = llvminfo . sysname . tolowercase ( ) . contains ( " mac " ) ? " libc + + . dylib " : " libc + + . so . 1 " ; <nl> - trufflefile tf = defaultlibrarylocator . locateglobal ( context , libname ) ; <nl> - if ( tf = = null ) { <nl> - throw new unsatisfiedlinkerror ( " library ' " + libname + " ' not found in the llvm home . " ) ; <nl> - } <nl> - truffleobject cxxlib = loadlibrary ( tf . getpath ( ) , false , null , context ) ; <nl> - libraryhandles . put ( lib , cxxlib ) ; <nl> + <nl> return true ; <nl> } else { <nl> return false ; <nl> } <nl> } <nl>  <nl> + private static string getlibcxxname ( ) { <nl> + return llvminfo . sysname . tolowercase ( ) . contains ( " mac " ) ? " libc + + . dylib " : " libc + + . so . 1 " ; <nl> + } <nl> + <nl> private truffleobject loadlibrary ( externallibrary lib , llvmcontext context ) { <nl> compilerasserts . neverpartofcompilation ( ) ; <nl> string libname = lib . getpath ( ) . tostring ( ) ; <nl> return loadlibrary ( libname , false , null , context , lib ) ; <nl> } <nl>  <nl> - private truffleobject loadlibrary ( string libname , boolean optional , string flags , llvmcontext context ) { <nl> - return loadlibrary ( libname , optional , flags , context , libname ) ; <nl> - } <nl> - <nl> private truffleobject loadlibrary ( string libname , boolean optional , string flags , llvmcontext context , object file ) { <nl> librarylocator . traceloadnative ( context , file ) ; <nl> string loadexpression ;
public class binaryparser extends binarystreamparser { <nl> branchtable [ 0 ] = returnlength ; <nl> / / the offset to the branch table . <nl> state . savebranchtable ( branchtable ) ; <nl> + / / this instruction is stack - polymorphic . <nl> + if ( ( peek1 ( ) & num xff ) = = instructions . end ) { <nl> + final int targetstacksize = state . getstackstate ( 0 ) ; <nl> + final int continuationreturnlength = state . getcontinuationreturnlength ( 0 ) ; <nl> + while ( state . stacksize ( ) > targetstacksize + continuationreturnlength ) { <nl> + state . pop ( ) ; <nl> + } <nl> + } <nl> break ; <nl> } <nl> case instructions . return : { <nl> state . uselongconstant ( state . stackstatecount ( ) ) ; <nl> state . useintconstant ( state . getrootblockreturnlength ( ) ) ; <nl> + <nl> break ; <nl> } <nl> case instructions . call : {
public final class wasmblocknode extends wasmnode implements repeatingnode { <nl> byteconstantoffset + + ; <nl> offset + = constantlength ; <nl> / / consume the zero_table constant at the end of the call_indirect instruction . <nl> + <nl> offset + = num ; <nl>  <nl> / / validate that the function type matches the expected type . <nl> mmm a / wasm / src / org . graalvm . wasm / src / org / graalvm / wasm / nodes / wasmrootnode . java <nl> ppp b / wasm / src / org . graalvm . wasm / src / org / graalvm / wasm / nodes / wasmrootnode . java <nl>
public class gr18252test extends abstractparametrizedlibrarytest { <nl> } <nl> } <nl>  <nl> + @ exportlibrary ( value = alibrary . class , receivertype = data . class ) <nl> + static class cmessages extends amessages { <nl> + <nl> + @ exportmessage <nl> + public static boolean is ( data receiver , @ cached branchprofile profile , @ cached branchprofile profile1 ) { <nl> + return true ; <nl> + } <nl> + <nl> + <nl> + / / num . error in / users / pitr / development / labs / truffleruby - ws / graal / truffle / src / com . oracle . truffle . api . library . test / src / com / oracle / truffle / api / library / test / gr18252test . java ( at line num ) <nl> + / / static class cmessages extends amessages { <nl> + / / ^ ^ ^ ^ ^ ^ ^ ^ ^ <nl> + / / message redirected from element com . oracle . truffle . api . library . test . gr18252test . amessages . get ( data , branchprofile ) parameter profile : <nl> + / / no other cached parameters are specified as shared with the group ' profile ' . <nl> + / / <nl> + / / if a message with shared is inherited alone the checks should be more relaxed . <nl> + / / <nl> + / / it also warns and suggest to share with a method from a parent <nl> + / / <nl> + / / num . warning in / users / pitr / development / labs / truffleruby - ws / graal / truffle / src / com . oracle . truffle . api . library . test / src / com / oracle / truffle / api / library / test / gr18252test . java ( at line num ) <nl> + / / public static boolean is ( data receiver , @ cached branchprofile profile , @ cached branchprofile profile1 ) { <nl> + / / ^ ^ ^ ^ ^ ^ ^ <nl> + / / the cached parameter may be shared with : <nl> + / / - get ( . . . , @ cached ( . . . ) branchprofile profile ) <nl> + / / annotate the parameter with @ shared ( " profile " ) or @ exclusive to allow or deny sharing of the parameter . <nl> + / / <nl> + / / which could be good but it should be clear that the method is inherited <nl> + <nl> + } <nl> + <nl> @ test <nl> public void testdispatchingtoais ( ) { <nl> data dataa = new data ( amessages . class , " value " ) ;
public final class jdwpcontextimpl implements jdwpcontext { <nl> target_java_lang_thread . interrupt0 ( ( staticobject ) thread ) ; <nl> } <nl>  <nl> + @ override <nl> + public boolean systemexitimplemented ( ) { <nl> + return false ; <nl> + } <nl> + <nl> @ override <nl> public void exit ( int exitcode ) { <nl> - system . exit ( exitcode ) ; <nl> + <nl> } <nl> }
public final class wasminitialization implements consumer < wasmcontext > , truffleo <nl> final long address = getvalue ( addressglobal ) ; <nl> final string valueglobal = entry . getvalue ( ) ; <nl> final long value = getvalue ( valueglobal ) ; <nl> - / / the memory array writes are indexed with num - bit words . <nl> + <nl> + / / this will be checked in a separate pr . <nl> + memory . growtoaddress ( address ) ; <nl> memory . store_i64 ( null , address , value ) ; <nl> } <nl> } catch ( unknownidentifierexception | unsupportedmessageexception e ) { <nl> mmm a / wasm / src / org . graalvm . wasm / src / org / graalvm / wasm / memory / wasmmemory . java <nl> ppp b / wasm / src / org . graalvm . wasm / src / org / graalvm / wasm / memory / wasmmemory . java <nl>
public class resetcontextnode extends wasmbuiltinrootnode { <nl> boolean first = true ; <nl> wasmcontext context = contextreference ( ) . get ( ) ; <nl> for ( wasmmodule m : context . modules ( ) . values ( ) ) { <nl> + <nl> + / / and we want to reset them , this code will have to be changed . <nl> if ( ! m . isbuiltin ( ) ) { <nl> context . linker ( ) . resetmodulestate ( context , m , m . data ( ) , first & & zeromemory ) ; <nl> + first = false ; <nl> } <nl> - first = false ; <nl> } <nl> } <nl> }
public final class espressocontext { <nl>  <nl> / / now add to the main thread group <nl> meta . threadgroup / / public void add ( thread t ) <nl> - . lookupdeclaredmethod ( name . addthread , signature . _void_thread ) . invokedirect ( mainthreadgroup , <nl> + . lookupdeclaredmethod ( name . add , signature . _void_thread ) . invokedirect ( mainthreadgroup , <nl> / * thread * / guestthread ) ; <nl> } <nl>  <nl> public void disposethread ( thread hostthread ) { <nl> / / simply calling thread . exit ( ) will do most of what ' s needed <nl> - staticobject guestthread = getguestthreadfromhost ( hostthread ) ; <nl> - if ( guestthread ! = null ) { <nl> - meta . thread_exit . invokedirect ( guestthread ) ; <nl> - threadmanager . unregisterthread ( guestthread ) ; <nl> - } else { <nl> - throw new illegalstateexception ( " cannot dispose an unknown host thread " ) ; <nl> - } <nl> + <nl> } <nl>  <nl> public void interruptactivethreads ( ) {
class jdwp { <nl> } <nl> } <nl>  <nl> + static class dispose_objects { <nl> + public static final int id = num ; <nl> + <nl> + static jdwpresult createreply ( packet packet ) { <nl> + packetstream input = new packetstream ( packet ) ; <nl> + packetstream reply = new packetstream ( ) . replypacket ( ) . id ( packet . id ) ; <nl> + <nl> + <nl> + int count = input . readint ( ) ; <nl> + for ( int i = num ; i < count ; i + + ) { <nl> + long objectid = input . readlong ( ) ; <nl> + int refcount = input . readint ( ) ; <nl> + } <nl> + return new jdwpresult ( reply ) ; <nl> + } <nl> + } <nl> + <nl> static class capabilities_new { <nl> public static final int id = num ;
<nl> * / <nl> package com . oracle . truffle . wasm . collection ; <nl>  <nl> - public class intarrayarraylist { <nl> + <nl> + public final class intarrayarraylist { <nl> private static final int [ ] [ ] empty_int_array_array = new int [ 0 ] [ ] ; <nl>  <nl> private int [ ] [ ] array ; <nl> mmm a / wasm / src / com . oracle . truffle . wasm / src / com / oracle / truffle / wasm / collection / intarraylist . java <nl> ppp b / wasm / src / com . oracle . truffle . wasm / src / com / oracle / truffle / wasm / collection / intarraylist . java <nl>
class jdwp { <nl> } <nl> } <nl>  <nl> + <nl> + / / events for step into / over so diabled for now . perhaps the bytecode <nl> + / / returned from method . getcode ( ) is incorrect ? <nl> static class bytecodes { <nl> public static final int id = num ;
public class binaryreader extends binarystreamreader { <nl> } <nl> } <nl> branchtable [ 0 ] = returnlength ; <nl> + <nl> state . pop ( ) ; / / the offset to the branch table . <nl> state . savebranchtable ( branchtable ) ; <nl> break ;
public class llvmlanguage extends trufflelanguage < llvmcontext > { <nl> * do not use this on fast - path . <nl> * / <nl> public static llvmlanguage getlanguage ( ) { <nl> + <nl> return getcurrentlanguage ( llvmlanguage . class ) ; <nl> }
public abstract class wasmsuitebase extends wasmtestbase { <nl> context = getinterpretednoinline ( contextbuilder ) ; <nl> final value resultinterpreted = runincontext ( context , source , num ) ; <nl>  <nl> + <nl> validateresult ( testcase . data . resultvalidator , resultinterpreted , capturedstdout ) ; <nl> capturedstdout . reset ( ) ;
<nl> + / * <nl> + * copyright ( c ) num , oracle and / or its affiliates . <nl> + * <nl> + * all rights reserved . <nl> + * <nl> + * redistribution and use in source and binary forms , with or without modification , are <nl> + * permitted provided that the following conditions are met : <nl> + * <nl> + * num . redistributions of source code must retain the above copyright notice , this list of <nl> + * conditions and the following disclaimer . <nl> + * <nl> + * num . redistributions in binary form must reproduce the above copyright notice , this list of <nl> + * conditions and the following disclaimer in the documentation and / or other materials provided <nl> + * with the distribution . <nl> + * <nl> + * num . neither the name of the copyright holder nor the names of its contributors may be used to <nl> + * endorse or promote products derived from this software without specific prior written <nl> + * permission . <nl> + * <nl> + * this software is provided by the copyright holders and contributors " as is " and any express <nl> + * or implied warranties , including , but not limited to , the implied warranties of <nl> + * merchantability and fitness for a particular purpose are disclaimed . in no event shall the <nl> + * copyright holder or contributors be liable for any direct , indirect , incidental , special , <nl> + * exemplary , or consequential damages ( including , but not limited to , procurement of substitute <nl> + * goods or services ; loss of use , data , or profits ; or business interruption ) however caused <nl> + * and on any theory of liability , whether in contract , strict liability , or tort ( including <nl> + * negligence or otherwise ) arising in any way out of the use of this software , even if advised <nl> + * of the possibility of such damage . <nl> + * / <nl> + package com . oracle . truffle . wasm . source . test ; <nl> + <nl> + import org . junit . test ; <nl> + <nl> + public final class resourcetest { <nl> + @ test <nl> + public void test ( ) { <nl> + <nl> + } <nl> + }
public class binaryreader extends binarystreamreader { <nl> } <nl>  <nl> private wasmloopnode readloop ( wasmcodeentry codeentry , executionstate state , byte returntypeid ) { <nl> - wasmblocknode loopblock = readblock ( codeentry , state , returntypeid ) ; <nl> - return new wasmloopnode ( loopblock ) ; <nl> + int initialstackpointer = state . stacksize ( ) ; <nl> + wasmblocknode loopblock = readblock ( codeentry , state , returntypeid ) ; <nl> + <nl> + <nl> + / / then it can leave no values in the stack , which is invalid for our abstract interpretation . <nl> + / / correct the stack pointer to the value it would have in case there were no branch instructions . <nl> + state . setstackpointer ( returntypeid ! = valuetypes . void_type ? initialstackpointer + num : initialstackpointer ) ; <nl> + <nl> + return new wasmloopnode ( loopblock ) ; <nl> } <nl>  <nl> private wasmifnode readif ( wasmcodeentry codeentry , executionstate state ) { <nl>
public class binaryreader extends binarystreamreader { <nl> int startoffset = offset ( ) ; <nl> wasmblocknode truebranchblock = readblock ( codeentry , state , blocktypeid ) ; <nl>  <nl> + <nl> + / / then it can leave no values in the stack , which is invalid for our abstract interpretation . <nl> + / / correct the stack pointer to the value it would have in case there were no branch instructions . <nl> + state . setstackpointer ( blocktypeid ! = valuetypes . void_type ? initialstackpointer : initialstackpointer - num ) ; <nl> + <nl> / / read false branch , if it exists . <nl> wasmnode falsebranch ; <nl> if ( peek1 ( - 1 ) = = else ) {
public class binaryreader extends binarystreamreader { <nl> currentblock . setintconstantlength ( state . intconstantoffset ( ) - startintconstantoffset ) ; <nl> currentblock . setnumericliterallength ( state . numericliteraloffset ( ) - startnumericliteraloffset ) ; <nl> currentblock . setbranchtablelength ( state . branchtableoffset ( ) - startbranchtableoffset ) ; <nl> - checkvalidstateonblockexit ( returntypeid , state , startstacksize ) ; <nl> + <nl> return currentblock ; <nl> }
public class binaryreader extends binarystreamreader { <nl> } <nl>  <nl> falsebranch = readblock ( codeentry , state , blocktypeid ) ; <nl> - assert . assertequals ( stacksizeaftertrueblock , state . stacksize ( ) , " stack sizes must be equal after both branches of an if statement . " ) ; <nl> + <nl> + if ( blocktypeid ! = valuetypes . void_type ) { <nl> + <nl> + / / then it can leave no values in the stack , which is invalid for our abstract interpretation . <nl> + / / correct the stack pointer to the value it would have in case there were no branch instructions . <nl> + state . setstackpointer ( initialstackpointer ) ; <nl> + } <nl> } else { <nl> if ( blocktypeid ! = valuetypes . void_type ) { <nl> assert . fail ( " an if statement without an else branch block cannot return values . " ) ;
public final class target_sun_misc_unsafe { <nl> / / field index . <nl> field f = getinstancefieldfromindex ( holder , math . tointexact ( offset ) - safety_field_offset ) ; <nl> assert f ! = null ; <nl> - f . set ( holder , value ) ; <nl> + <nl> + holder . setintfieldvolatile ( f , value ) ; <nl> } <nl>  <nl> @ substitution ( hasreceiver = true ) <nl>
public final class target_sun_misc_unsafe { <nl> / / field index . <nl> field f = getinstancefieldfromindex ( holder , math . tointexact ( offset ) - safety_field_offset ) ; <nl> assert f ! = null ; <nl> - f . set ( holder , value ) ; <nl> + <nl> + holder . setlongfieldvolatile ( f , value ) ; <nl> } <nl>  <nl> @ substitution ( hasreceiver = true ) <nl>
public final class target_sun_misc_unsafe { <nl> / / field index . <nl> field f = getinstancefieldfromindex ( holder , math . tointexact ( offset ) - safety_field_offset ) ; <nl> assert f ! = null ; <nl> - f . set ( holder , value ) ; <nl> + <nl> + holder . setfieldvolatile ( f , value ) ; <nl> } <nl>  <nl> / / endregion put * ( object holder , long offset , * value )
public final class target_sun_misc_unsafe { <nl> public static long reallocatememory ( @ suppresswarnings ( " unused " ) @ host ( unsafe . class ) staticobject self , long address , long bytes ) { <nl> return u . reallocatememory ( address , bytes ) ; <nl> } <nl> + <nl> + @ substitution ( hasreceiver = true ) <nl> + public static @ host ( object . class ) staticobject getandsetobject ( @ suppresswarnings ( " unused " ) @ host ( unsafe . class ) staticobject self , @ host ( object . class ) staticobject holder , long offset , @ host ( object . class ) staticobject value ) { <nl> + if ( holder . isarray ( ) ) { <nl> + return ( staticobject ) u . getandsetobject ( ( holder ) . unwrap ( ) , offset , value ) ; <nl> + } <nl> + <nl> + field f = getinstancefieldfromindex ( holder , math . tointexact ( offset ) - safety_field_offset ) ; <nl> + assert f ! = null ; <nl> + return f . getandsetobject ( holder , value ) ; <nl> + } <nl> }
public final class vm extends nativeenv implements contextaccess { <nl> system . err . println ( " jvm_findlibraryentry from default / global namespace ( 0 ) : " + name ) ; <nl> return num l ; <nl> } <nl> + <nl> + if ( - 6 < libhandle & & libhandle < num ) { <nl> + system . err . println ( " jvm_findlibraryentry with unsupported flag / handle / namespace ( " + libhandle + " ) : " + name ) ; <nl> + return num l ; <nl> + } <nl> try { <nl> truffleobject function = nativelibrary . lookup ( handle2lib . get ( libhandle ) , name ) ; <nl> long handle = interoplibrary . getfactory ( ) . getuncached ( ) . aspointer ( function ) ;
public class wasmblocknode extends wasmnode implements repeatingnode { <nl>  <nl> @ override <nl> public boolean executerepeating ( virtualframe frame ) { <nl> + <nl> return execute ( wasmcontext . getcurrent ( ) , frame ) ! = - 1 ; <nl> } <nl>  <nl> mmm a / wasm / src / com . oracle . truffle . wasm / src / com / oracle / truffle / wasm / binary / wasmrootnode . java <nl> ppp b / wasm / src / com . oracle . truffle . wasm / src / com / oracle / truffle / wasm / binary / wasmrootnode . java <nl>
public class wasmrootnode extends rootnode implements wasmnodeinterface { <nl> * / <nl> argumentstolocals ( frame ) ; <nl>  <nl> + <nl> body . execute ( wasmcontext . getcurrent ( ) , frame ) ; <nl> + <nl> long returnvalue = pop ( frame , num ) ; <nl> switch ( body . returntypeid ( ) ) { <nl> case num x00 :
public final class staticobject implements truffleobject { <nl> / / kinds bigger than a byte . to still benefit from virtualization , we use a long array until <nl> / / support for byte arrays is live . <nl> / / @ see : virtualizertoolimpl . setvirtualentry <nl> + <nl> private final long [ ] primitivefields ; <nl>  <nl> / / dedicated constructor for void and null pseudo - singletons
public final class methodverifier implements contextaccess { <nl> / / checkstyle : resume <nl> / / @ formatter : on <nl> { <nl> + <nl> + <nl> / / check padding . <nl> if ( curopcode = = invokeinterface & & code . readubyte ( bci + num ) ! = num ) { <nl> throw new verifyerror ( " 4th byte after invokeinterface must be num . " ) ; <nl>
class basegraalvmlayoutdistribution ( mx . layoutdistribution ) : <nl> source_type = ' skip ' if _skip_libraries ( lib_polyglot_project . native_image_config ) else ' dependency ' <nl> libpolyglot_dest = " < jre_base > / lib / polyglot / " + lib_polyglot_project . native_image_name <nl> _add ( layout , libpolyglot_dest , source_type + " : " + lib_polyglot_project . name ) <nl> - _add ( layout , " < jre_base > / lib / polyglot / " , " dependency : " + lib_polyglot_project . name + " / * . h " ) <nl> + # <nl> + _add ( layout , " < jre_base > / lib / polyglot / " , source_type + " : " + lib_polyglot_project . name + " / * . h " ) <nl> _add_native_image_macro ( lib_polyglot_project . native_image_config ) <nl>  <nl> # add release file <nl>
public class binaryreader { <nl> } <nl>  <nl> public void readtablesection ( ) { <nl> - <nl> } <nl>  <nl> public void readmemorysection ( ) { <nl> - <nl> } <nl>  <nl> private void readdatasection ( ) { <nl> } <nl>  <nl> private void readcodesection ( ) { <nl> + int numcodeentries = readvectorlength ( ) ; <nl> + for ( int entry = num ; entry < numcodeentries ; entry + + ) { <nl> + int codeentrysize = readunsignedleb128 ( ) ; <nl> + int startoffset = offset ; <nl> + readcodeentry ( codeentrysize ) ; <nl> + assert . assertequals ( offset - startoffset , codeentrysize , string . format ( " code entry % d size is incorrect " , entry ) ) ; <nl> + } <nl> + } <nl> + <nl> + private void readcodeentry ( int codeentrysize ) { <nl> + int startoffset = offset ; <nl> + int numlocals = readvectorlength ( ) ; <nl> + wasmcodeentry codeentry = new wasmcodeentry ( numlocals ) ; <nl> + for ( int local = num ; local < numlocals ; local + + ) { <nl> + throw new runtimeexception ( " not implemented " ) ; <nl> + } <nl> + int expressionsize = codeentrysize - ( offset - startoffset ) ; <nl> + codeentry . expression = new wasmblock ( data , offset , expressionsize ) ; <nl> + readcodeentryexpression ( codeentry . expression ) ; <nl> + <nl> + } <nl> + <nl> + private void readcodeentryexpression ( wasmblock currentblock ) { <nl> + byte instruction ; <nl> + do { <nl> + instruction = read1 ( ) ; <nl> + switch ( instruction ) { <nl> + case num x41 : / / i32 . const <nl> + int val = readsignedleb128 ( ) ; <nl> + break ; <nl> + default : <nl> + break ; <nl> + } <nl> + } while ( instruction ! = num x0b ) ; <nl> } <nl>  <nl> private void readelementsection ( ) { <nl>
final class polyglotcontextimpl extends abstractcontextimpl implements com . oracl <nl> engine . err , <nl> engine . in , <nl> false , <nl> - null , <nl> + polyglotaccess . all , <nl> false , <nl> false , <nl> false ,
public final class context implements autocloseable { <nl>  <nl> polyglotaccess polyglotaccess = this . polylgotaccess ; <nl> if ( polyglotaccess = = null ) { <nl> - polyglotaccess = this . allowallaccess ? polyglotaccess . all : polyglotaccess . none ; <nl> + <nl> + polyglotaccess = polyglotaccess . all ; <nl> } <nl>  <nl> if ( localhostlookupfilter = = unset_host_lookup ) {
public class mhlinktonode extends espressobasenode { <nl> assert ( membername . getklass ( ) . gettype ( ) = = symbol . type . membername ) ; <nl>  <nl> method target = ( method ) membername . gethiddenfield ( " vmtarget " ) ; <nl> - int refkind = target_java_lang_invoke_methodhandlenatives . getrefkind ( ( int ) membername . getfield ( membername . getklass ( ) . getmeta ( ) . mnflags ) ) ; <nl> + int refkind = target_java_lang_invoke_methodhandlenatives . getrefkind ( ( int ) membername . getfield ( membername . getklass ( ) . getmeta ( ) . mnflags ) ) ; <nl>  <nl> if ( target . hasreceiver ( ) ) { <nl> staticobject receiver = ( staticobject ) args [ 0 ] ; <nl> if ( refkind = = target_java_lang_invoke_methodhandlenatives . ref_invokevirtual ) { <nl> + <nl> if ( ! target . hasbytecodes ( ) ) { <nl> target = receiver . getklass ( ) . lookupmethod ( target . getname ( ) , target . getrawsignature ( ) ) ; <nl> }
builds + = [ <nl> $ { darwin - amd64 } $ { oraclejdk11 } $ { gatelite } $ { truffleweekly } { <nl> name : " gate - truffle - mac - lite - 11 " <nl> } <nl> + $ { windows - amd64 } $ { labsjdk8 } $ { trufflecommon } { <nl> + # <nl> + # currently , some truffle unittests fail on windows <nl> + run : [ <nl> + [ " mx " , " build " ] , <nl> + [ " mx " , " unittest " , " truffle . nfi . test " , " - - verbose " ] <nl> + ] <nl> + packages : { <nl> + msvc : " = = 10 . 0 " <nl> + } <nl> + targets : [ gate ] , <nl> + name : " gate - truffle - nfi - windows - 8 " , <nl> + } <nl> # benchmarks <nl> $ { benchcommon } $ { truffle - bench - notifications } { <nl> run : [
import com . oracle . truffle . espresso . vm . vm ; <nl> public final class espressocontext { <nl>  <nl> private final espressolanguage language ; <nl> - <nl> private final trufflelanguage . env env ; <nl> - <nl> - / / must be initialized after the context instance creation . <nl> - @ compilationfinal / / <nl> - private interpretertovm interpretertovm ; <nl> - <nl> private final stringtable strings ; <nl> private final classregistries registries ; <nl> + private final substitutions substitutions ; <nl> + <nl> + <nl> + public final concurrenthashmap < thread , staticobject > host2guest = new concurrenthashmap < > ( ) ; <nl>  <nl> private boolean initialized = false ; <nl>  <nl>
public class target_java_lang_thread { <nl>  <nl> @ intrinsic <nl> public static boolean holdslock ( object object ) { <nl> - return thread . holdslock ( object ) ; <nl> + if ( ! imageinfo . inimagecode ( ) ) { <nl> + / / sane behavior on hotspot . <nl> + return thread . holdslock ( object ) ; <nl> + } <nl> + <nl> + return true ; <nl> } <nl>  <nl> @ intrinsic <nl> mmm a / src / com . oracle . truffle . espresso / src / com / oracle / truffle / espresso / jni / nativelibrary . java <nl> ppp b / src / com . oracle . truffle . espresso / src / com / oracle / truffle / espresso / jni / nativelibrary . java <nl>
public final class methodinfo implements modifiersprovider { <nl> case void : <nl> return nativesimpletype . void ; <nl> case object : <nl> - return nativesimpletype . object ; <nl> + <nl> + <nl> + return javatonative <nl> + ? nativesimpletype . object_or_null <nl> + : nativesimpletype . object ; <nl> + <nl> default : <nl> throw espressoerror . shouldnotreachhere ( ) ; <nl> } <nl>
public final class methodinfo implements modifiersprovider { <nl> calltarget = lookupjnicalltarget ( findnative , true ) ; <nl> } <nl>  <nl> + <nl> + <nl> if ( calltarget = = null ) { <nl> + system . err . println ( " failed to link native method : " + meta ( this ) . getdeclaringclass ( ) . getname ( ) + " # " + getname ( ) + " " + getsignature ( ) ) ; <nl> throw meta . throwex ( unsatisfiedlinkerror . class ) ; <nl> } <nl> } else { <nl>
<nl> + package com . oracle . truffle . espresso . nodes ; <nl> + <nl> + import com . oracle . truffle . api . trufflelanguage ; <nl> + import com . oracle . truffle . api . frame . virtualframe ; <nl> + import com . oracle . truffle . api . interop . arityexception ; <nl> + import com . oracle . truffle . api . interop . foreignaccess ; <nl> + import com . oracle . truffle . api . interop . message ; <nl> + import com . oracle . truffle . api . interop . truffleobject ; <nl> + import com . oracle . truffle . api . interop . unsupportedmessageexception ; <nl> + import com . oracle . truffle . api . interop . unsupportedtypeexception ; <nl> + import com . oracle . truffle . api . nodes . node ; <nl> + import com . oracle . truffle . api . nodes . rootnode ; <nl> + import com . oracle . truffle . espresso . meta . espressoerror ; <nl> + <nl> + public class jninativenode extends rootnode { <nl> + <nl> + private final truffleobject boundnative ; <nl> + @ child node execute = message . execute . createnode ( ) ; <nl> + <nl> + public jninativenode ( trufflelanguage < ? > language , truffleobject boundnative ) { <nl> + super ( language ) ; <nl> + this . boundnative = boundnative ; <nl> + } <nl> + <nl> + @ override <nl> + public object execute ( virtualframe frame ) { <nl> + try { <nl> + <nl> + / / having a constant length would help pea to skip the copying . <nl> + object [ ] argswithenv = prependenv ( frame . getarguments ( ) ) ; <nl> + return foreignaccess . sendexecute ( execute , boundnative , argswithenv ) ; <nl> + } catch ( unsupportedtypeexception | arityexception | unsupportedmessageexception e ) { <nl> + throw espressoerror . shouldnotreachhere ( ) ; <nl> + } <nl> + } <nl> + <nl> + private static object [ ] prependenv ( object [ ] args ) { <nl> + object [ ] argswithenv = new object [ args . length + num ] ; <nl> + system . arraycopy ( args , num , argswithenv , num , args . length ) ; <nl> + argswithenv [ 0 ] = num l ; <nl> + return argswithenv ; <nl> + } <nl> + }
public class implicitcasttest { <nl>  <nl> } <nl>  <nl> + @ typesystemreference ( implicitcast0types . class ) <nl> + abstract static class implicitcasttypedexecutenode extends node { <nl> + <nl> + public abstract object execute ( int value ) ; <nl> + <nl> + <nl> + @ expecterror ( " method signature ( boolean ) does not match to the expected signature : \n object op1 ( int arg0 ) " ) <nl> + @ specialization <nl> + public boolean op1 ( boolean value ) { <nl> + return value ; <nl> + } <nl> + } <nl> + <nl> @ test <nl> public void testimplicitcast0 ( ) { <nl> implicitcast0node node = implicitcast0nodefactory . create ( null ) ; <nl> mmm a / truffle / src / com . oracle . truffle . dsl . processor / src / com / oracle / truffle / dsl / processor / generator / flatnodegenfactory . java <nl> ppp b / truffle / src / com . oracle . truffle . dsl . processor / src / com / oracle / truffle / dsl / processor / generator / flatnodegenfactory . java <nl>
public class implicitcasttest { <nl>  <nl> } <nl>  <nl> + @ typesystemreference ( implicitcast0types . class ) <nl> + abstract static class implicitcasttypedexecutenode extends node { <nl> + <nl> + public abstract object execute ( int value ) ; <nl> + <nl> + <nl> + @ expecterror ( " method signature ( boolean ) does not match to the expected signature : \n object op1 ( int arg0 ) " ) <nl> + @ specialization <nl> + public boolean op1 ( boolean value ) { <nl> + return value ; <nl> + } <nl> + } <nl> + <nl> @ test <nl> public void testimplicitcast0 ( ) { <nl> implicitcast0node node = implicitcast0nodefactory . create ( null ) ; <nl> mmm a / truffle / src / com . oracle . truffle . dsl . processor / src / com / oracle / truffle / dsl / processor / generator / flatnodegenfactory . java <nl> ppp b / truffle / src / com . oracle . truffle . dsl . processor / src / com / oracle / truffle / dsl / processor / generator / flatnodegenfactory . java <nl>
class renaissancebenchmarksuite ( mx_benchmark . javabenchmarksuite , averagingbenchm <nl>  <nl>  <nl> mx_benchmark . add_bm_suite ( renaissancebenchmarksuite ( ) ) <nl> + <nl> + <nl> + class sparksqlperfbenchmarksuite ( mx_benchmark . javabenchmarksuite , averagingbenchmarkmixin , temporaryworkdirmixin ) : <nl> + " " " benchmark suite for the spark - sql - perf benchmarks . <nl> + " " " <nl> + def name ( self ) : <nl> + return " spark - sql - perf " <nl> + <nl> + def group ( self ) : <nl> + return " graal " <nl> + <nl> + def subgroup ( self ) : <nl> + return " graal - compiler " <nl> + <nl> + def sparksqlperfpath ( self ) : <nl> + sparksqlperf = mx . get_env ( " spark_sql_perf " ) <nl> + return sparksqlperf <nl> + <nl> + def validateenvironment ( self ) : <nl> + if not self . sparksqlperfpath ( ) : <nl> + raise runtimeerror ( <nl> + " the spark_sql_perf environment variable was not specified . " ) <nl> + <nl> + def validatereturncode ( self , retcode ) : <nl> + return retcode = = num <nl> + <nl> + def classpathandmainclass ( self ) : <nl> + mainclass = " com . databricks . spark . sql . perf . runbenchmark " <nl> + return [ " - cp " , self . sparksqlperfpath ( ) + " / * " , mainclass ] <nl> + <nl> + def createcommandlineargs ( self , benchmarks , bmsuiteargs ) : <nl> + if not benchmarks is none : <nl> + mx . abort ( " cannot specify individual benchmarks . " ) <nl> + vmargs = self . vmargs ( bmsuiteargs ) <nl> + runargs = self . runargs ( bmsuiteargs ) <nl> + return ( <nl> + vmargs + self . classpathandmainclass ( ) + [ " - - benchmark " , " datasetperformance " ] + runargs ) <nl> + <nl> + def benchmarklist ( self , bmsuiteargs ) : <nl> + self . validateenvironment ( ) <nl> + return [ ] <nl> + <nl> + def successpatterns ( self ) : <nl> + return [ ] <nl> + <nl> + def failurepatterns ( self ) : <nl> + return [ ] <nl> + <nl> + def rules ( self , out , benchmarks , bmsuiteargs ) : <nl> + return [ ] <nl> + <nl> + def decodestackedjson ( self , content ) : <nl> + not_whitespace = re . compile ( r ' [ ^ \ s ] ' ) <nl> + pos = num <nl> + while true : <nl> + match = not_whitespace . search ( content , pos ) <nl> + if not match : <nl> + return <nl> + pos = match . start ( ) <nl> + decoder = json . jsondecoder ( ) <nl> + try : <nl> + part , pos = decoder . raw_decode ( content , pos ) <nl> + except json . jsondecodeerror : <nl> + raise <nl> + yield part <nl> + <nl> + def run ( self , benchmarks , bmsuiteargs ) : <nl> + runretval = self . runandreturnstdout ( benchmarks , bmsuiteargs ) <nl> + dims = { } <nl> + if len ( runretval ) = = num : <nl> + retcode , out , retdims = runretval <nl> + dims = retdims <nl> + self . validatestdoutwithdimensions ( <nl> + out , benchmarks , bmsuiteargs , retcode = retcode , dims = dims ) <nl> + else : <nl> + # <nl> + retcode , out = runretval <nl> + self . validatestdout ( out , benchmarks , bmsuiteargs , retcode = retcode ) <nl> + perf_dir = next ( file for file in os . listdir ( self . workdir + " / performance / " ) ) <nl> + experiment_dir = self . workdir + " / performance / " + perf_dir + " / " <nl> + results_filename = next ( file for file in os . listdir ( experiment_dir ) if file . endswith ( " json " ) ) <nl> + with open ( experiment_dir + results_filename , " r " ) as results_file : <nl> + content = results_file . read ( ) <nl> + results = [ ] <nl> + iteration = num <nl> + for part in self . decodestackedjson ( content ) : <nl> + for result in part [ " results " ] : <nl> + if " queryexecution " in result : <nl> + datapoint = { <nl> + " benchmark " : result [ " name " ] . replace ( " " , " - " ) , <nl> + " vm " : " jvmci " , <nl> + " config . name " : " default " , <nl> + " metric . name " : " warmup " , <nl> + " metric . value " : result [ " executiontime " ] , <nl> + " metric . unit " : " ms " , <nl> + " metric . type " : " numeric " , <nl> + " metric . score - function " : " id " , <nl> + " metric . better " : " lower " , <nl> + " metric . iteration " : iteration , <nl> + } <nl> + datapoint . update ( dims ) <nl> + results . append ( datapoint ) <nl> + iteration + = num <nl> + self . addaverageacrosslatestresults ( results ) <nl> + return results <nl> + <nl> + <nl> + mx_benchmark . add_bm_suite ( sparksqlperfbenchmarksuite ( ) ) <nl> \ no newline at end of file
public final class amd64arraycomparetoop extends amd64lirinstruction { <nl> return arch . getfeatures ( ) . contains ( cpufeature . avx2 ) ; <nl> } <nl>  <nl> - private static boolean supportsavx512vlbw ( targetdescription target ) { <nl> - amd64 arch = ( amd64 ) target . arch ; <nl> - enumset < cpufeature > features = arch . getfeatures ( ) ; <nl> - return features . contains ( cpufeature . avx512bw ) & & features . contains ( cpufeature . avx512vl ) ; <nl> + private static boolean supportsavx512vlbw ( @ suppresswarnings ( " unused " ) targetdescription target ) { <nl> + <nl> + return false ; <nl> } <nl>  <nl> @ override
final class macrooption { <nl> } <nl> throw new invalidmacroexception ( " no macrooptionkind for subdir : " + subdir ) ; <nl> } <nl> + <nl> + static macrooptionkind fromstring ( string kindname ) { <nl> + / * <nl> + string kindnamelowercase = kindname . tolowercase ( ) ; <nl> + <nl> + for ( macrooptionkind kind : macrooptionkind . values ( ) ) { <nl> + if ( kind . tostring ( ) . equals ( kindnamelowercase ) ) { <nl> + return kind ; <nl> + } <nl> + } <nl> + throw new invalidmacroexception ( " no macrooptionkind for kindname : " + kindname ) ; <nl> + } <nl> + <nl> + @ override <nl> + public string tostring ( ) { <nl> + return name ( ) . tolowercase ( ) ; <nl> + } <nl> } <nl>  <nl> path getimagejarsdirectory ( ) { <nl>
final class macrooption { <nl> } <nl> throw new invalidmacroexception ( " no macrooptionkind for subdir : " + subdir ) ; <nl> } <nl> + <nl> + static macrooptionkind fromstring ( string kindname ) { <nl> + / * <nl> + string kindnamelowercase = kindname . tolowercase ( ) ; <nl> + <nl> + for ( macrooptionkind kind : macrooptionkind . values ( ) ) { <nl> + if ( kind . tostring ( ) . equals ( kindnamelowercase ) ) { <nl> + return kind ; <nl> + } <nl> + } <nl> + throw new invalidmacroexception ( " no macrooptionkind for kindname : " + kindname ) ; <nl> + } <nl> + <nl> + @ override <nl> + public string tostring ( ) { <nl> + return name ( ) . tolowercase ( ) ; <nl> + } <nl> } <nl>  <nl> path getimagejarsdirectory ( ) { <nl>
final class macrooption { <nl> } <nl>  <nl> static macrooptionkind fromstring ( string kindname ) { <nl> + / * <nl> + string kindnamelowercase = kindname . tolowercase ( ) ; <nl> + <nl> for ( macrooptionkind kind : macrooptionkind . values ( ) ) { <nl> - if ( kind . tostring ( ) . equals ( kindname ) ) { <nl> + if ( kind . tostring ( ) . equals ( kindnamelowercase ) ) { <nl> return kind ; <nl> } <nl> }
public class valuehostconversiontest { <nl> } <nl> } ) ; <nl> } <nl> + <nl> + @ override <nl> + protected object findmetaobject ( languagecontext ctx , object value ) { <nl> + <nl> + if ( value instanceof truffleobject ) { <nl> + try { <nl> + return foreignaccess . sendinvoke ( message . createinvoke ( 0 ) . createnode ( ) , ( truffleobject ) value , " getclass " ) ; <nl> + } catch ( unknownidentifierexception | unsupportedmessageexception | unsupportedtypeexception | arityexception e ) { <nl> + } <nl> + try { <nl> + object instanceclass = foreignaccess . sendread ( message . read . createnode ( ) , ( truffleobject ) value , " class " ) ; <nl> + return foreignaccess . sendinvoke ( message . createinvoke ( 0 ) . createnode ( ) , ( truffleobject ) instanceclass , " getclass " ) ; <nl> + } catch ( unknownidentifierexception | unsupportedmessageexception | unsupportedtypeexception | arityexception e ) { <nl> + } <nl> + } <nl> + return " " ; <nl> + } <nl> } ) ; <nl> return context . asvalue ( context . eval ( proxylanguage . id , clazz . getname ( ) ) ) ; <nl> }
public abstract class node implements nodeinterface , cloneable { <nl> return null ; <nl> } <nl>  <nl> + / * * <nl> + * <nl> + * / <nl> protected void reportpolymorphicspecialize ( ) { <nl> compilerasserts . neverpartofcompilation ( ) ; <nl> node . accessor . nodes ( ) . reportpolymorphicspecialize ( this ) ;
<nl> + / * <nl> + * copyright ( c ) num , oracle and / or its affiliates . <nl> + * <nl> + * all rights reserved . <nl> + * <nl> + * redistribution and use in source and binary forms , with or without modification , are <nl> + * permitted provided that the following conditions are met : <nl> + * <nl> + * num . redistributions of source code must retain the above copyright notice , this list of <nl> + * conditions and the following disclaimer . <nl> + * <nl> + * num . redistributions in binary form must reproduce the above copyright notice , this list of <nl> + * conditions and the following disclaimer in the documentation and / or other materials provided <nl> + * with the distribution . <nl> + * <nl> + * num . neither the name of the copyright holder nor the names of its contributors may be used to <nl> + * endorse or promote products derived from this software without specific prior written <nl> + * permission . <nl> + * <nl> + * this software is provided by the copyright holders and contributors " as is " and any express <nl> + * or implied warranties , including , but not limited to , the implied warranties of <nl> + * merchantability and fitness for a particular purpose are disclaimed . in no event shall the <nl> + * copyright holder or contributors be liable for any direct , indirect , incidental , special , <nl> + * exemplary , or consequential damages ( including , but not limited to , procurement of substitute <nl> + * goods or services ; loss of use , data , or profits ; or business interruption ) however caused <nl> + * and on any theory of liability , whether in contract , strict liability , or tort ( including <nl> + * negligence or otherwise ) arising in any way out of the use of this software , even if advised <nl> + * of the possibility of such damage . <nl> + * / <nl> + package com . oracle . truffle . llvm . nodes . asm . syscall ; <nl> + <nl> + public class llvmamd64syscallgettidnode extends llvmamd64syscalloperationnode { <nl> + public llvmamd64syscallgettidnode ( ) { <nl> + super ( " gettid " ) ; <nl> + } <nl> + <nl> + @ override <nl> + public long execute ( object rdi , object rsi , object rdx , object r10 , object r8 , object r9 ) { <nl> + <nl> + / / single - threaded . <nl> + return llvminfo . getpid ( ) ; <nl> + } <nl> + } <nl> mmm a / projects / com . oracle . truffle . llvm . nodes / src / com / oracle / truffle / llvm / nodes / asm / syscall / llvmamd64syscallnode . java <nl> ppp b / projects / com . oracle . truffle . llvm . nodes / src / com / oracle / truffle / llvm / nodes / asm / syscall / llvmamd64syscallnode . java <nl>
public final class llvminteroptest { <nl> } <nl>  <nl> @ test <nl> + @ ignore <nl> public void testvirtualmalloccompare1 ( ) throws exception { <nl> runner runner = new runner ( " virtualmalloccompare1 " ) ; <nl> runner . load ( ) ;
public class trufflegraphbuilderplugins { <nl> return true ; <nl> } <nl> } ) ; <nl> + r . register0 ( " incompilationroot " , new invocationplugin ( ) { <nl> + @ override <nl> + public boolean apply ( graphbuildercontext b , resolvedjavamethod targetmethod , receiver receiver ) { <nl> + <nl> + b . addpush ( javakind . boolean , constantnode . forboolean ( true ) ) ; <nl> + return true ; <nl> + } <nl> + } ) ; <nl> r . register0 ( " transfertointerpreter " , new invocationplugin ( ) { <nl> @ override <nl> public boolean apply ( graphbuildercontext b , resolvedjavamethod targetmethod , receiver receiver ) { <nl>
public final class runner { <nl>  <nl> public calltarget parse ( llvmlanguage language , llvmcontext context , source code ) throws ioexception { <nl> try { <nl> + / * <nl> + * <nl> + * not able to link external variables which were defined in those libraries . <nl> + * / <nl> + parsedynamicbitcodelibraries ( language , context ) ; <nl> + <nl> calltarget mainfunction = null ; <nl> if ( code . getmimetype ( ) . equals ( sulong . llvm_bitcode_mime_type ) | | code . getmimetype ( ) . equals ( sulong . llvm_bitcode_base64_mime_type ) | | code . getmimetype ( ) . equals ( " x - unknown " ) ) { <nl> llvmparserresult parserresult = parsebitcodefile ( code , language , context ) ; <nl>
public final class runner { <nl>  <nl> public calltarget parse ( llvmlanguage language , llvmcontext context , source code ) throws ioexception { <nl> try { <nl> + / * <nl> + * <nl> + * not able to link external variables which were defined in those libraries . <nl> + * / <nl> + parsedynamicbitcodelibraries ( language , context ) ; <nl> + <nl> calltarget mainfunction = null ; <nl> if ( code . getmimetype ( ) . equals ( sulong . llvm_bitcode_mime_type ) | | code . getmimetype ( ) . equals ( sulong . llvm_bitcode_base64_mime_type ) | | code . getmimetype ( ) . equals ( " x - unknown " ) ) { <nl> llvmparserresult parserresult = parsebitcodefile ( code , language , context ) ; <nl>
public class aarch64optimizedcalltargetinstumentationfactory extends optimizedca <nl> masm . dmb ( load_load ) ; <nl> masm . dmb ( load_store ) ; <nl> masm . cbz ( 64 , spillregister , doprolog ) ; <nl> - masm . tbz ( 64 , spillregister , num , doprolog ) ; <nl> - masm . eor ( 64 , spillregister , spillregister , num ) ; <nl> + <nl> + if ( trufflecompiler . options . aarch64entrypointtagging . getvalue ( options ) ) { <nl> + masm . tbz ( 64 , spillregister , num , doprolog ) ; <nl> + masm . eor ( 64 , spillregister , spillregister , num ) ; <nl> + } <nl> masm . jmp ( spillregister ) ; <nl> masm . nop ( ) ; <nl> masm . bind ( doprolog ) ; <nl> mmm a / compiler / src / org . graalvm . compiler . truffle / src / org / graalvm / compiler / truffle / trufflecompiler . java <nl> ppp b / compiler / src / org . graalvm . compiler . truffle / src / org / graalvm / compiler / truffle / trufflecompiler . java <nl>
public class polyglotengineprofiletest { <nl> assertequals ( store1 , get ( profile ) ) ; <nl> leave ( profile , prev ) ; <nl>  <nl> + <nl> + / / assertnull ( get ( profile ) ) ; <nl> + assertnotnull ( get ( profile ) ) ; <nl> + <nl> prev = enter ( profile , store1 ) ; <nl> assertequals ( store1 , get ( profile ) ) ; <nl> leave ( profile , prev ) ; <nl> mmm a / truffle / com . oracle . truffle . api . vm / src / com / oracle / truffle / api / vm / polyglotengineprofile . java <nl> ppp b / truffle / com . oracle . truffle . api . vm / src / com / oracle / truffle / api / vm / polyglotengineprofile . java <nl>
final class polyglotengineprofile { <nl> if ( constantstoreassumption . isvalid ( ) ) { <nl> / / we can skip the constantentered check in compiled code , because we are assume we are <nl> / / always entered in such cases . <nl> - store = ( compilerdirectives . incompiledcode ( ) | | constantentered ) ? constantstore . get ( ) : null ; <nl> + <nl> + / / constantstore . get ( ) : null ; <nl> + store = constantstore . get ( ) ; <nl> } else if ( dynamicstoreassumption . isvalid ( ) ) { <nl> / / multiple context single thread <nl> store = dynamicstore ;
public class polyglotengineprofiletest { <nl> assertequals ( store1 , get ( profile ) ) ; <nl> leave ( profile , prev ) ; <nl>  <nl> + <nl> + / / assertnull ( get ( profile ) ) ; <nl> + assertnotnull ( get ( profile ) ) ; <nl> + <nl> prev = enter ( profile , store1 ) ; <nl> assertequals ( store1 , get ( profile ) ) ; <nl> leave ( profile , prev ) ; <nl> mmm a / truffle / com . oracle . truffle . api . vm / src / com / oracle / truffle / api / vm / polyglotengineprofile . java <nl> ppp b / truffle / com . oracle . truffle . api . vm / src / com / oracle / truffle / api / vm / polyglotengineprofile . java <nl>
final class polyglotengineprofile { <nl> if ( constantstoreassumption . isvalid ( ) ) { <nl> / / we can skip the constantentered check in compiled code , because we are assume we are <nl> / / always entered in such cases . <nl> - store = ( compilerdirectives . incompiledcode ( ) | | constantentered ) ? constantstore . get ( ) : null ; <nl> + <nl> + / / constantstore . get ( ) : null ; <nl> + store = constantstore . get ( ) ; <nl> } else if ( dynamicstoreassumption . isvalid ( ) ) { <nl> / / multiple context single thread <nl> store = dynamicstore ;
import com . oracle . truffle . llvm . test . functionvisitoriterator . llvmfunctionvisitor ; <nl> @ runwith ( parameterized . class ) <nl> public class testlifetimeanalysisgcc extends testsuitebase { <nl>  <nl> + <nl> + private static final string [ ] excludedfiles = new string [ ] { <nl> + " projects / com . oracle . truffle . llvm . test / suites / gcc / gcc - 5 . 2 . 0 / gcc / testsuite / gcc . dg / pr43419 . c " <nl> + } ; <nl> + <nl> private static final string function_indent = " " ; <nl> private static final string begin_dead_end_indent = " \ t " ; <nl> private static final string basic_block_indent = " \ t \ t " ; <nl>
public class flatnodegenfactory { <nl> int ifcount = num ; <nl> if ( ! typechecks . isempty ( ) ) { <nl> builder . startif ( ) ; <nl> - if ( specialization ! = null ) { <nl> + <nl> + / / guard . we should still make this conditional , by making the cast conditional or <nl> + / / inline the cast into method guards that use the cast value . <nl> + / / ideally we could make guards for the fallback one liner . <nl> + if ( specialization ! = null & & typecasts . isempty ( ) ) { <nl> builder . tree ( statecheck ) . string ( " | | " ) ; <nl> } <nl> builder . tree ( typechecks ) . end ( ) ; <nl>
public final class llvmmetadata implements modelvisitor { <nl>  <nl> @ override <nl> public void visit ( getelementpointerinstruction gep ) { <nl> + type t1 = ( ( pointertype ) ( gep . getbasepointer ( ) . gettype ( ) ) ) . getpointeetype ( ) ; <nl> + if ( t1 instanceof structuretype ) { <nl> + structuretype thisstruct = ( structuretype ) t1 ; <nl> + <nl> + metadatacompositetype metastruct = ( metadatacompositetype ) thisstruct . getmetadatareference ( ) . get ( ) ; <nl> + thisstruct . setname ( ( ( metadatastring ) metastruct . getname ( ) . get ( ) ) . getstring ( ) ) ; <nl> + <nl> + metadatanode elements = ( metadatanode ) metastruct . getmemberdescriptors ( ) . get ( ) ; <nl> + <nl> + symbol idx = gep . getindices ( ) . get ( 1 ) ; <nl> + int parsedindex = idx instanceof integerconstant ? ( int ) ( ( integerconstant ) ( idx ) ) . getvalue ( ) : num ; <nl> + metadatareference element = elements . get ( parsedindex ) ; <nl> + <nl> + metadataderivedtype derivedtype = ( metadataderivedtype ) element . get ( ) ; <nl> + gep . setreferencename ( ( ( metadatastring ) derivedtype . getname ( ) . get ( ) ) . getstring ( ) ) ; <nl> + } <nl> } <nl>  <nl> @ override <nl> mmm a / projects / uk . ac . man . cs . llvm / src / uk / ac / man / cs / llvm / ir / model / elements / getelementpointerinstruction . java <nl> ppp b / projects / uk . ac . man . cs . llvm / src / uk / ac / man / cs / llvm / ir / model / elements / getelementpointerinstruction . java <nl>
public class metadatav32 extends metadata { <nl> metadatanode node = new metadatanode ( ) ; <nl>  <nl> while ( args . hasnext ( ) ) { <nl> - node . add ( metadata . getreference ( args . next ( ) ) ) ; <nl> + type next = args . next ( ) ; <nl> + if ( next instanceof metadataconstanttype ) { <nl> + node . add ( metadata . getreference ( next ) ) ; <nl> + } else { <nl> + node . add ( metadatablock . voidref ) ; <nl> + } <nl> } <nl>  <nl> metadata . add ( node ) ;
public final class llvmnodegenerator { <nl>  <nl> return llvmliteralfactory . createvectorliteralnode ( values , target , llvmbitcodehelper . tobasetype ( constant . gettype ( ) ) . gettype ( ) ) ; <nl> } <nl> + <nl> + private llvmexpressionnode resolvemetadataconstant ( metadataconstant constant ) { <nl> + <nl> + return new llvmsimpleliteralnode . llvmi64literalnode ( constant . getvalue ( ) ) ; <nl> + } <nl> }
public final class llvmintrinsicfactory { <nl> return llvmi64objectsizenodegen . create ( ( llvmaddressnode ) realargnodes [ 0 ] , ( llvmi1node ) realargnodes [ 1 ] ) ; <nl> } else if ( functionname . startswith ( " @ llvm . expect " ) ) { <nl> return getexpect ( realargnodes , functionname , configuration ) ; <nl> + } else if ( functionname . startswith ( " @ llvm . dbg . declare " ) ) { <nl> + return new llvmnode ( ) { <nl> + <nl> + @ override <nl> + public void executevoid ( virtualframe frame ) { <nl> + <nl> + } <nl> + <nl> + } ; <nl> } else { <nl> throw new illegalstateexception ( " llvm intrinsic " + functionname + " not yet supported ! " ) ; <nl> } <nl> mmm a / projects / uk . ac . man . cs . llvm / src / uk / ac / man / cs / llvm / ir / module / function . java <nl> ppp b / projects / uk . ac . man . cs . llvm / src / uk / ac / man / cs / llvm / ir / module / function . java <nl>
public class function implements parserlistener { <nl> return ; <nl> } <nl>  <nl> + / * <nl> + * func_code_debug_loc as well as func_code_debug_loc_again also occur after the ret <nl> + * instruction , where the instructiongenerator would already been deleted . this has to be <nl> + * improved in the future , but for now we simply parse those instructions before checking <nl> + * for an existing instructiongenerator . otherwise we would cause an runtimeexception . <nl> + * / <nl> + if ( record = = functionrecord . func_code_debug_loc ) { <nl> + / * <nl> + * <nl> + * <nl> + * http : / / llvm . org / releases / 3 . 2 / docs / sourceleveldebugging . html # format_common_lifetime <nl> + * http : / / llvm . org / releases / 3 . 4 / docs / sourceleveldebugging . html # object - lifetimes - and - scoping <nl> + * <nl> + * @ formatter : off <nl> + * <nl> + * metadata ! { <nl> + * i32 num , ; ; line number <nl> + * i32 num , ; ; column number ( until now , this field was always zero ) <nl> + * metadata ! 12 , ; ; scope <nl> + * null ; ; original scope <nl> + * } <nl> + * <nl> + * @ formatter : on <nl> + * / <nl> + return ; <nl> + } <nl> + <nl> + if ( record = = functionrecord . func_code_debug_loc_again ) { <nl> + return ; <nl> + } <nl> + <nl> if ( code = = null ) { <nl> code = generator . generateblock ( ) ; <nl> }
public final class gcc extends compilerbase { <nl> } else { <nl> throw new assertionerror ( tobecompiled ) ; <nl> } <nl> - string [ ] command = new string [ ] { tool , " - i " + llvmbaseoptionfacade . getprojectroot ( ) + " / . . / include " , " - s " , dragoneggoption ( ) , " - fplugin - arg - dragonegg - emit - ir " , " - o " + destinationfile , <nl> - tobecompiled . getabsolutepath ( ) } ; <nl> - processutil . executenativecommandzeroreturn ( command ) ; <nl> + if ( destinationfile . getname ( ) . endswith ( " . bc " ) ) { <nl> + <nl> + <nl> + / / creating . ll file for the fortran source file <nl> + string llfilegenerationcommand = tool + " - i " + llvmbaseoptionfacade . getprojectroot ( ) + " / . . / include - s " + dragoneggoption ( ) + " - fplugin - arg - dragonegg - emit - ir - o / tmp / temp . ll " + <nl> + tobecompiled . getabsolutepath ( ) ; <nl> + processutil . executenativecommandzeroreturn ( llfilegenerationcommand ) ; <nl> + <nl> + / / converting . ll file to . bc file <nl> + string lltobcconversioncommand = llvm_as_path . tostring ( ) + " / tmp / temp . ll - o " + destinationfile ; <nl> + processutil . executenativecommandzeroreturn ( lltobcconversioncommand ) ; <nl> + } else { <nl> + string [ ] command = new string [ ] { tool , " - i " + llvmbaseoptionfacade . getprojectroot ( ) + " / . . / include " , " - s " , dragoneggoption ( ) , " - fplugin - arg - dragonegg - emit - ir " , " - o " + destinationfile , <nl> + tobecompiled . getabsolutepath ( ) } ; <nl> + processutil . executenativecommandzeroreturn ( command ) ; <nl> + } <nl> + <nl> } <nl>  <nl> private static string dragoneggoption ( ) {
public final class sourcesection { <nl> * @ since num . 18 <nl> * / <nl> public boolean isavailable ( ) { <nl> - return charlength ! = - 1 ; <nl> + <nl> + return charlength ! = - 1 & & source ! = null ; <nl> } <nl>  <nl> / * * <nl>
public class framestateassignmentphase extends phase { <nl> } <nl> return singlestate ; <nl> } <nl> + <nl> + @ override <nl> + public boolean checkcontract ( ) { <nl> + <nl> + return false ; <nl> + } <nl> }
def runtestargon2 ( args = none , optimize = false ) : <nl> os . chdir ( _argon2dir ) <nl> if args is none : <nl> args = [ ] <nl> - args . extend ( [ ' - ea ' , ' - esa ' ] ) <nl> + # <nl> + # args . extend ( [ ' - ea ' , ' - esa ' ] ) <nl>  <nl> compileargon2 ( ' genkat ' , optimize , [ ' - dgenkat ' ] ) <nl> ret = runtestargon2kats ( args )
class jvmciversioncheck { <nl> if ( system . getproperty ( " java . specification . version " ) . compareto ( " 1 . 9 " ) < num ) { <nl> errormessage . format ( " download the latest jvmci jdk num from http : / / www . oracle . com / technetwork / oracle - labs / program - languages / downloads / index . html " ) ; <nl> } else { <nl> - errormessage . format ( " download the latest jdk num ea from https : / / jdk9 . java . net / download / " ) ; <nl> + <nl> + / / https : / / jdk9 . java . net / download / " ) ; <nl> } <nl> string value = system . getenv ( " jvmci_version_check " ) ; <nl> if ( " warn " . equals ( value ) ) { <nl>
builds = [ <nl>  <nl> include " ci_includes / x52 . hocon " <nl> include " ci_includes / x4150 . hocon " <nl> - include " ci_includes / x52 - tracera . hocon " <nl> + # <nl> + # include " ci_includes / x52 - tracera . hocon "
def mdlcheck ( args = none ) : <nl> abspath = path + ' / ' + f <nl> subprocess . check_output ( [ ' mdl ' , ' - r ~ md026 , ~ md002 , ~ md029 , ~ md032 ' , abspath ] ) <nl>  <nl> + def getbitcodelibrariesoption ( ) : <nl> + libraries = [ ] <nl> + for path , _ , files in os . walk ( _libpath ) : <nl> + for f in files : <nl> + # <nl> + if f . endswith ( ' . c ' ) : <nl> + bitcodefile = f . rsplit ( " . " , num ) [ 0 ] + ' . ll ' <nl> + absbitcodefile = path + ' / ' + bitcodefile <nl> + if not os . path . isfile ( absbitcodefile ) : <nl> + compilewithclang ( [ ' - s ' , ' - emit - llvm ' , path + ' / ' + f , ' - o ' , absbitcodefile ] ) <nl> + libraries . append ( absbitcodefile ) <nl> + return ' - dsulong . dynamicbitcodelibraries = ' + ' : ' . join ( libraries ) <nl> + <nl> mx . update_commands ( _suite , { <nl> ' suoptbench ' : [ suoptbench , ' ' ] , <nl> ' subench ' : [ subench , ' ' ] ,
final class tracelinearscaneliminatespillmovephase extends tracelinearscanalloca <nl> * no valid opid but - 1 . ) <nl> * / <nl> private static boolean caneliminatespillmove ( tracelinearscan allocator , abstractblockbase < ? > block , moveop move , int lastopid ) { <nl> + assert ( ( lirinstruction ) move ) . id ( ) = = - 1 : " not a spill move : " + move ; <nl> assert isvariable ( move . getresult ( ) ) : " linearscan inserts only moves to variables : " + move ; <nl> assert lastopid > = num : " invalid lastopid : " + lastopid ; <nl>  <nl> traceinterval curinterval = allocator . intervalfor ( move . getresult ( ) ) ; <nl>  <nl> - if ( ! isregister ( curinterval . location ( ) ) & & curinterval . inmemoryat ( lastopid ) & & isphiresolutionmove ( allocator , move ) ) { <nl> + if ( ! isregister ( curinterval . location ( ) ) & & curinterval . inmemoryat ( lastopid ) & & ! isphiresolutionmove ( allocator , move ) ) { <nl> + / * phi resolution moves cannot be removed because they define the value . * / <nl> + <nl> assert isstackslotvalue ( curinterval . location ( ) ) : " not a stack slot : " + curinterval . location ( ) ; <nl> return true ; <nl> } <nl> return false ; <nl> } <nl>  <nl> + / * * <nl> + * checks if a ( spill or split ) move is a phi resolution move . <nl> + * <nl> + * a spill or split move connects a split parent or a split child with another split child . <nl> + * therefore the destination of the move is always a split child . phi resolution moves look like <nl> + * spill moves ( i . e . { @ link lirinstruction # id ( ) id } is { @ code num } , but they define a new <nl> + * variable . as a result the destination interval is a split parent . <nl> + * / <nl> private static boolean isphiresolutionmove ( tracelinearscan allocator , moveop move ) { <nl> + assert ( ( lirinstruction ) move ) . id ( ) = = - 1 : " not a spill move : " + move ; <nl> traceinterval curinterval = allocator . intervalfor ( move . getresult ( ) ) ; <nl> - return ! curinterval . issplitparent ( ) ; <nl> + return curinterval . issplitparent ( ) ; <nl> } <nl>  <nl> private static void checkintervals ( traceinterval interval ) {
final class tracelinearscanlifetimeanalysisphase extends tracelinearscanallocati <nl>  <nl> op . foreachregisterhint ( targetvalue , mode , ( registerhint , valuemode , valueflags ) - > { <nl> if ( tracelinearscan . isvariableorregister ( registerhint ) ) { <nl> - allocatablevalue fromvalue ; <nl> - allocatablevalue tovalue ; <nl> + / * <nl> + * <nl> + * / <nl> + final allocatablevalue fromvalue ; <nl> + final allocatablevalue tovalue ; <nl> / * hints always point from def to use * / <nl> if ( hintatdef ) { <nl> fromvalue = ( allocatablevalue ) registerhint ; <nl>
public final class tracebuilder < t extends abstractblockbase < t > > { <nl> return gettraces ( ) . get ( tracenr ) . stream ( ) . flatmap ( b - > b . getpredecessors ( ) . stream ( ) ) . anymatch ( s - > gettraceforblock ( s ) ! = tracenr ) ; <nl> } <nl>  <nl> + public boolean incomingsideedges ( int tracenr ) { <nl> + / * <nl> + return gettraces ( ) . get ( tracenr ) . stream ( ) . skip ( 1 ) . flatmap ( b - > b . getpredecessors ( ) . stream ( ) ) . anymatch ( s - > gettraceforblock ( s ) ! = tracenr ) ; <nl> + } <nl> + <nl> } <nl>  <nl> / * * <nl> mmm a / graal / com . oracle . graal . lir / src / com / oracle / graal / lir / alloc / trace / tracelinearscaneliminatespillmovephase . java <nl> ppp b / graal / com . oracle . graal . lir / src / com / oracle / graal / lir / alloc / trace / tracelinearscaneliminatespillmovephase . java <nl>
final class tracelinearscanwalker extends traceintervalwalker { <nl> optimalsplitposfinal = ( optimalsplitpos - num ) | num ; <nl> } <nl>  <nl> - assert minsplitpos < = optimalsplitposfinal & & optimalsplitposfinal < = maxsplitpos : " out of range " ; <nl> + <nl> + assert minsplitpos < = optimalsplitposfinal & & optimalsplitposfinal < = maxsplitpos | | minsplitpos = = maxsplitpos & & optimalsplitposfinal = = minsplitpos - num : " out of range " ; <nl> assert optimalsplitposfinal < = interval . to ( ) : " cannot split after end of interval " ; <nl> assert optimalsplitposfinal > interval . from ( ) : " cannot split at start of interval " ; <nl>  <nl>
final class tracelinearscanwalker extends traceintervalwalker { <nl> / / " split pos must be even on block boundary " ; <nl> assert ( optimalsplitposfinal & num ) = = num : " split pos must be odd " ; <nl>  <nl> + <nl> + if ( optimalsplitposfinal = = interval . to ( ) & & interval . nextusage ( registerpriority . musthaveregister , minsplitpos ) = = integer . max_value ) { <nl> + / / the split position would be just before the end of the interval <nl> + / / . no split at all necessary <nl> + if ( debug . islogenabled ( ) ) { <nl> + debug . log ( " no split necessary because optimal split position is at end of interval " ) ; <nl> + } <nl> + return ; <nl> + } <nl> traceinterval splitpart = interval . split ( optimalsplitposfinal , allocator ) ; <nl>  <nl> boolean movenecessary = true ;
import com . oracle . graal . lir . gen . lirgeneratortool . spillmovefactory ; <nl> * / <nl> final class tracelinearscan { <nl>  <nl> + private static final tracelinearscanregisterallocationphase trace_linear_scan_register_allocation_phase = new tracelinearscanregisterallocationphase ( ) ; <nl> + private static final tracelinearscanassignlocationsphase trace_linear_scan_assign_locations_phase = new tracelinearscanassignlocationsphase ( ) ; <nl> + <nl> + @ suppresswarnings ( " unused " ) private static final tracelinearscaneliminatespillmovephase trace_linear_scan_eliminate_spill_move_phase = new tracelinearscaneliminatespillmovephase ( ) ; <nl> + private static final tracelinearscanresolvedataflowphase trace_linear_scan_resolve_data_flow_phase = new tracelinearscanresolvedataflowphase ( ) ; <nl> + private static final tracelinearscanlifetimeanalysisphase trace_linear_scan_lifetime_analysis_phase = new tracelinearscanlifetimeanalysisphase ( ) ; <nl> + <nl> public static class blockdata { <nl>  <nl> / * * <nl>
public abstract class pegraphdecoder extends simplifyinggraphdecoder { <nl> if ( inlineinfo . getmethodtoinline ( ) = = null ) { <nl> return false ; <nl> } else { <nl> - assert ! inlineinfo . isintrinsic ( ) : " not supported " ; <nl> + if ( inlineinfo . isintrinsic ( ) ) { <nl> + <nl> + return false ; <nl> + } <nl> return doinline ( methodscope , loopscope , invokedata , inlineinfo . getmethodtoinline ( ) , arguments ) ; <nl> } <nl> }
import com . oracle . truffle . tools . debug . shell . server . * ; <nl> * / <nl> public final class slreplserver implements replserver { <nl>  <nl> + <nl> + @ suppresswarnings ( " unused " ) private static final class < sllanguage > dynamic_dependency = com . oracle . truffle . sl . sllanguage . class ; <nl> + <nl> public static void main ( string [ ] args ) { <nl> / / cheating for the prototype : start from sl , rather than from the client . <nl> final slreplserver server = new slreplserver ( ) ;
public final class nativefunctioninterfaceruntime { <nl> static { <nl>  <nl> nativefunctioninterface instance = null ; <nl> - nativefunctioninterfaceaccess access = services . loadsingle ( nativefunctioninterfaceaccess . class , false ) ; <nl> + <nl> + nativefunctioninterfaceaccess access = null ; <nl> + class < ? > servicesclass = null ; <nl> + try { <nl> + servicesclass = class . forname ( " com . oracle . jvmci . service . services " ) ; <nl> + } catch ( classnotfoundexception e ) { <nl> + / / jvmci is unavailable <nl> + } <nl> + if ( servicesclass ! = null ) { <nl> + try { <nl> + method m = servicesclass . getdeclaredmethod ( " loadsingle " , class . class , boolean . class ) ; <nl> + access = ( nativefunctioninterfaceaccess ) m . invoke ( null , nativefunctioninterfaceaccess . class , false ) ; <nl> + } catch ( throwable e ) { <nl> + / / fail fast for other errors <nl> + throw ( internalerror ) new internalerror ( ) . initcause ( e ) ; <nl> + } <nl> + } <nl> + <nl> if ( access ! = null ) { <nl> instance = access . getnativefunctioninterface ( ) ; <nl> } <nl> mmm a / graal / com . oracle . nfi / src / com / oracle / nfi / api / nativefunctioninterface . java <nl> ppp b / graal / com . oracle . nfi / src / com / oracle / nfi / api / nativefunctioninterface . java <nl>
public class truffle { <nl> return accesscontroller . doprivileged ( new privilegedaction < truffleruntime > ( ) { <nl> public truffleruntime run ( ) { <nl> truffleruntimeaccess access = null ; <nl> + class < ? > servicesclass = null ; <nl> try { <nl> - access = services . loadsingle ( truffleruntimeaccess . class , false ) ; <nl> - } catch ( noclassdeffounderror e ) { <nl> + servicesclass = class . forname ( " com . oracle . jvmci . service . services " ) ; <nl> + } catch ( classnotfoundexception e ) { <nl> / / jvmci is unavailable <nl> } <nl> + if ( servicesclass ! = null ) { <nl> + try { <nl> + method m = servicesclass . getdeclaredmethod ( " loadsingle " , class . class , boolean . class ) ; <nl> + access = ( truffleruntimeaccess ) m . invoke ( null , truffleruntimeaccess . class , false ) ; <nl> + } catch ( throwable e ) { <nl> + / / fail fast for other errors <nl> + throw ( internalerror ) new internalerror ( ) . initcause ( e ) ; <nl> + } <nl> + } <nl> + <nl> if ( access ! = null ) { <nl> return access . getruntime ( ) ; <nl> } <nl> mmm a / graal / com . oracle . truffle . api / src / com / oracle / truffle / api / truffleruntimeaccess . java <nl> ppp b / graal / com . oracle . truffle . api / src / com / oracle / truffle / api / truffleruntimeaccess . java <nl>
public final class nativefunctioninterfaceruntime { <nl> static { <nl>  <nl> nativefunctioninterface instance = null ; <nl> - nativefunctioninterfaceaccess access = services . loadsingle ( nativefunctioninterfaceaccess . class , false ) ; <nl> + <nl> + nativefunctioninterfaceaccess access = null ; <nl> + class < ? > servicesclass = null ; <nl> + try { <nl> + servicesclass = class . forname ( " com . oracle . jvmci . service . services " ) ; <nl> + } catch ( classnotfoundexception e ) { <nl> + / / jvmci is unavailable <nl> + } <nl> + if ( servicesclass ! = null ) { <nl> + try { <nl> + method m = servicesclass . getdeclaredmethod ( " loadsingle " , class . class , boolean . class ) ; <nl> + access = ( nativefunctioninterfaceaccess ) m . invoke ( null , nativefunctioninterfaceaccess . class , false ) ; <nl> + } catch ( throwable e ) { <nl> + / / fail fast for other errors <nl> + throw ( internalerror ) new internalerror ( ) . initcause ( e ) ; <nl> + } <nl> + } <nl> + <nl> if ( access ! = null ) { <nl> instance = access . getnativefunctioninterface ( ) ; <nl> } <nl> mmm a / graal / com . oracle . nfi / src / com / oracle / nfi / api / nativefunctioninterface . java <nl> ppp b / graal / com . oracle . nfi / src / com / oracle / nfi / api / nativefunctioninterface . java <nl>
public abstract class nodelirbuilder implements nodelirbuildertool , lirgeneratio <nl> } <nl>  <nl> protected lirkind getexactphikind ( phinode phi ) { <nl> - arraylist < value > values = new arraylist < > ( phi . valuecount ( ) ) ; <nl> + <nl> + arraylist < lirkind > values = new arraylist < > ( phi . valuecount ( ) ) ; <nl> for ( int i = num ; i < phi . valuecount ( ) ; i + + ) { <nl> valuenode node = phi . valueat ( i ) ; <nl> value value = node instanceof constantnode ? ( ( constantnode ) node ) . asjavaconstant ( ) : getoperand ( node ) ; <nl> if ( value ! = null ) { <nl> - values . add ( value ) ; <nl> + values . add ( value . getlirkind ( ) ) ; <nl> } else { <nl> - assert isphiinputfrombackedge ( phi , i ) : string . format ( " input % s to phi node % s is not yet available although it is not coming from a loop back edge " , node , phi ) ; <nl> + assert node instanceof constantnode | | isphiinputfrombackedge ( phi , i ) : string . format ( " input % s to phi node % s is not yet available although it is not coming from a loop back edge " , <nl> + node , phi ) ; <nl> + / / non - java constant - > get kind from stamp . <nl> + values . add ( getlirgeneratortool ( ) . getlirkind ( node . stamp ( ) ) ) ; <nl> } <nl> } <nl> - lirkind derivedkind = lirkind . merge ( values . toarray ( new value [ values . size ( ) ] ) ) ; <nl> + lirkind derivedkind = lirkind . merge ( values ) ; <nl> assert verifyphikind ( derivedkind , gen . getlirkind ( phi . stamp ( ) ) ) ; <nl> return derivedkind ; <nl> }
public final class lirkind { <nl> if ( src . equals ( dst ) ) { <nl> return true ; <nl> } <nl> - if ( tostackkind ( src . getplatformkind ( ) ) . equals ( dst . getplatformkind ( ) ) ) { <nl> + / * <nl> + * <nl> + * dst . getplatformkind ( ) ) but due to the handling of sub - integer at the current point <nl> + * ( phi - ) moves from e . g . integer to short can happen . therefore we compare stack kinds . <nl> + * / <nl> + if ( tostackkind ( src . getplatformkind ( ) ) . equals ( tostackkind ( dst . getplatformkind ( ) ) ) ) { <nl> return ! src . isderivedreference ( ) | | dst . isderivedreference ( ) ; <nl> } <nl> return false ;
public class benchmarkcounters { <nl> } <nl> } <nl>  <nl> + private static void dumpcomputerreadable ( printstream out , boolean staticcounter , string group , long [ ] array , set < entry < string , counter > > counterentryset ) { <nl> + string category = staticcounter ? " static counters " : " dynamic counters " ; <nl> + for ( map . entry < string , counter > entry : counterentryset ) { <nl> + counter counter = entry . getvalue ( ) ; <nl> + if ( counter . group . equals ( group ) ) { <nl> + string name = getname ( entry . getkey ( ) , group ) ; <nl> + int <nl> + long value = array [ index ] ; <nl> + <nl> + out . printf ( " % s ; % s ; % s ; % d\n " , category , group , name , value ) ; <nl> + } <nl> + } <nl> + } <nl> + <nl> private static long percentage ( long counter , long sum ) { <nl> return ( counter * num + num ) / sum / num ; <nl> }
public class sparchotspotbackendfactory implements hotspotbackendfactory { <nl>  <nl> @ suppresswarnings ( " unused " ) <nl> private static value [ ] createnativeabicallersaveregisters ( hotspotvmconfig config , registerconfig regconfig ) { <nl> - register [ ] calleesaveregisters = regconfig . getcallersaveregisters ( ) ; <nl> - value [ ] nativeabicallersaveregisters = new value [ calleesaveregisters . length ] ; <nl> - for ( int i = num ; i < calleesaveregisters . length ; i + + ) { <nl> - nativeabicallersaveregisters [ i ] = calleesaveregisters [ i ] . asvalue ( ) ; <nl> + list < register > callersaveregisters = new arraylist < > ( ) ; <nl> + collections . addall ( callersaveregisters , regconfig . getcallersaveregisters ( ) ) ; <nl> + <nl> + collections . addall ( callersaveregisters , regconfig . getcalleesavelayout ( ) . registers ) ; <nl> + value [ ] nativeabicallersaveregisters = new value [ callersaveregisters . size ( ) ] ; <nl> + for ( int i = num ; i < callersaveregisters . size ( ) ; i + + ) { <nl> + nativeabicallersaveregisters [ i ] = callersaveregisters . get ( i ) . asvalue ( ) ; <nl> } <nl> return nativeabicallersaveregisters ; <nl> } <nl> mmm a / graal / com . oracle . graal . hotspot . sparc / src / com / oracle / graal / hotspot / sparc / sparchotspotregisterconfig . java <nl> ppp b / graal / com . oracle . graal . hotspot . sparc / src / com / oracle / graal / hotspot / sparc / sparchotspotregisterconfig . java <nl>
public class inlineablegraph implements inlineable { <nl> if ( context . getgraphcache ( ) ! = null ) { <nl> structuredgraph cachedgraph = context . getgraphcache ( ) . get ( method ) ; <nl> if ( cachedgraph ! = null ) { <nl> - assert false ; <nl> + <nl> return cachedgraph ; <nl> } <nl> }
public class handler < t > implements invocationhandler { <nl> return res ; <nl> } <nl>  <nl> + / * * <nl> + * @ param method <nl> + * / <nl> + private static boolean iscacheable ( method method ) { <nl> + <nl> + return true ; <nl> + } <nl> + <nl> @ override <nl> public object invoke ( object proxy , method method , object [ ] a ) throws throwable { <nl> object [ ] args = unproxify ( a ) ; <nl> - boolean isconstantdata = method . getannotation ( purefunction . class ) ! = null ; <nl> + boolean iscacheable = iscacheable ( method ) ; <nl> invocation invocation = new invocation ( method , delegate , args ) ; <nl> - if ( isconstantdata ) { <nl> - if ( constantdatainvocations . containskey ( invocation ) ) { <nl> - object result = constantdatainvocations . get ( invocation ) ; <nl> - assert objects . deepequals ( result , invocation . invoke ( ) ) ; <nl> + if ( iscacheable ) { <nl> + assert method . getreturntype ( ) ! = void . type : method ; <nl> + if ( cachedinvocations . containskey ( invocation ) ) { <nl> + object result = cachedinvocations . get ( invocation ) ; <nl> / / system . out . println ( invocation + " : " + result ) ; <nl> return result ; <nl> } <nl>
public abstract class source { <nl> return source ; <nl> } <nl>  <nl> + <nl> / * * <nl> * enables / disables caching of file contents , < em > disabled < / em > by default . caching of sources <nl> * created from literal text or readers is always enabled .
import com . oracle . truffle . api . nodes . * ; <nl> * / <nl> public interface visualizer { <nl>  <nl> + <nl> / * * <nl> * gets a printer for truffle asts , possibly specialized to be helpful for a specific guest <nl> * language implementation .
public class methodcalltargetnode extends calltargetnode implements iterablenode <nl> } <nl> } <nl> } <nl> + resolvedjavatype receivertype = targetmethod ( ) . getdeclaringclass ( ) ; <nl> + if ( receivertype . isinterface ( ) ) { <nl> + resolvedjavatype single = receivertype . getsingleimplementor ( ) ; <nl> + if ( single ! = null & & ! single . equals ( receivertype ) ) { <nl> + resolvedjavamethod newresolvedmethod = single . resolvemethod ( targetmethod ( ) , invoke ( ) . getcontexttype ( ) , true ) ; <nl> + <nl> + if ( newresolvedmethod ! = null & & ! newresolvedmethod . isdefault ( ) ) { <nl> + profilinginfo profilinginfo = invoke ( ) . getcontextmethod ( ) . getprofilinginfo ( ) ; <nl> + javatypeprofile profile = profilinginfo . gettypeprofile ( invoke ( ) . bci ( ) ) ; <nl> + logicnode condition = graph ( ) . unique ( instanceofnode . create ( single , receiver , profile ) ) ; <nl> + assert graph ( ) . getguardsstage ( ) . ordinal ( ) < structuredgraph . guardsstage . fixed_deopts . ordinal ( ) : " graph already fixed ! " ; <nl> + guardnode guard = graph ( ) . unique ( <nl> + guardnode . create ( condition , beginnode . prevbegin ( invoke ( ) . asnode ( ) ) , deoptimizationreason . optimizedtypecheckviolated , deoptimizationaction . invalidaterecompile , <nl> + false , javaconstant . null_object ) ) ; <nl> + pinode pinode = graph ( ) . unique ( pinode . create ( receiver , stampfactory . declared ( single ) , guard ) ) ; <nl> + arguments ( ) . set ( 0 , pinode ) ; <nl> + setinvokekind ( invokekind . virtual ) ; <nl> + settargetmethod ( newresolvedmethod ) ; <nl> + } <nl> + } <nl> + } <nl> } <nl> }
public final class linearscan { <nl> * / <nl> assert isblockbegin ( opid ) & & j = = num : " spillindominator spill position must be at the beginning of a block ! " ; <nl> int pos = num ; <nl> - while ( instructions . get ( pos ) . id ( ) = = - 1 ) { <nl> - pos + + ; <nl> + <nl> + if ( block . getpredecessorcount ( ) = = num ) { <nl> + / * <nl> + * we need to be careful because data flow resolution code <nl> + * might have been inserted . <nl> + * / <nl> + while ( instructions . get ( pos ) . id ( ) = = - 1 ) { <nl> + pos + + ; <nl> + } <nl> + assert pos < instructions . size ( ) : string . format ( " cannot move spill move out of the current block ! ( pos : % d , # inst : % d , block : % s " , pos , instructions . size ( ) , <nl> + block ) ; <nl> + if ( pos > num & & pos = = instructions . size ( ) - num ) { <nl> + / * <nl> + * we are at the end of the block and there were <nl> + * resolution moves . <nl> + * / <nl> + if ( block . getsuccessorcount ( ) > num ) { <nl> + / * <nl> + * the current block might have resolution code for <nl> + * the incoming and the outgoing edge . to ensure <nl> + * that we use the right location and do not <nl> + * overwrite an outgoing location we take the <nl> + * location at the end of the ( only ) predecessor <nl> + * block . <nl> + * / <nl> + abstractblock < ? > pred = block . getpredecessors ( ) . get ( 0 ) ; <nl> + if ( pred . getsuccessorcount ( ) < = num ) { <nl> + <nl> + throw new graalinternalerror ( " cannot find a position for the spill in dominator move ! " + pred + " - > " + block ) ; <nl> + } <nl> + int lastid = getlastlirinstructionid ( pred ) ; <nl> + allocatablevalue predfromlocation = interval . getsplitchildatopid ( lastid , operandmode . def , this ) . location ( ) ; <nl> + fromlocation = predfromlocation ; <nl> + pos = num ; <nl> + } <nl> + } <nl> } <nl> - assert pos < instructions . size ( ) : string . format ( " cannot move spill move out of the current block ! ( pos : % d , # inst : % d , block : % s " , pos , instructions . size ( ) , block ) ; <nl> insertionbuffer . append ( pos , ir . getspillmovefactory ( ) . createmove ( tolocation , fromlocation ) ) ; <nl> } else { <nl> insertionbuffer . append ( j + num , ir . getspillmovefactory ( ) . createmove ( tolocation , fromlocation ) ) ;
public final class linearscan { <nl> / / included in the oop map <nl> iw . walkbefore ( op . id ( ) ) ; <nl>  <nl> + <nl> + abstractblock < ? > block = blockforid ( op . id ( ) ) ; <nl> + <nl> / / iterate through active intervals <nl> for ( interval interval = iw . activelists . get ( registerbinding . fixed ) ; interval ! = interval . endmarker ; interval = interval . next ) { <nl> value operand = interval . operand ; <nl>
<nl> + / * <nl> + * copyright ( c ) num , oracle and / or its affiliates . all rights reserved . <nl> + * do not alter or remove copyright notices or this file header . <nl> + * <nl> + * this code is free software ; you can redistribute it and / or modify it <nl> + * under the terms of the gnu general public license version num only , as <nl> + * published by the free software foundation . oracle designates this <nl> + * particular file as subject to the " classpath " exception as provided <nl> + * by oracle in the license file that accompanied this code . <nl> + * <nl> + * this code is distributed in the hope that it will be useful , but without <nl> + * any warranty ; without even the implied warranty of merchantability or <nl> + * fitness for a particular purpose . see the gnu general public license <nl> + * version num for more details ( a copy is included in the license file that <nl> + * accompanied this code ) . <nl> + * <nl> + * you should have received a copy of the gnu general public license version <nl> + * num along with this work ; if not , write to the free software foundation , <nl> + * inc . , num franklin st , fifth floor , boston , ma num - 1301 usa . <nl> + * <nl> + * please contact oracle , num oracle parkway , redwood shores , ca num usa <nl> + * or visit www . oracle . com if you need additional information or have any <nl> + * questions . <nl> + * / <nl> + package com . oracle . truffle . api . script ; <nl> + <nl> + import javax . script . * ; <nl> + <nl> + / * * <nl> + * tool access to the creation of truffle execution engines . <nl> + * / <nl> + public abstract class trufflescriptenginefactory implements scriptenginefactory { <nl> + <nl> + <nl> + / * * <nl> + * to be called by each concrete factory just after each engine instance is created , presenting <nl> + * an opportunity for an ide to interrupt in a language - independent way . <nl> + * <nl> + * @ param engine a just - created engine <nl> + * / <nl> + protected void enginecreated ( scriptengine engine ) { <nl> + } <nl> + <nl> + }
public class inlineablegraph implements inlineable { <nl> private final structuredgraph graph ; <nl>  <nl> public inlineablegraph ( final resolvedjavamethod method , final invoke invoke , final hightiercontext context , canonicalizerphase canonicalizer ) { <nl> - this . graph = buildgraph ( method , context , canonicalizer ) ; <nl> + structuredgraph original = buildgraph ( method , context , canonicalizer ) ; <nl> + <nl> + this . graph = original . copy ( ) ; <nl> specializegraphtoarguments ( invoke , context , canonicalizer ) ; <nl> } <nl>  <nl>
public final class graphorder { <nl> if ( input instanceof framestate & & node instanceof statesplit & & input = = ( ( statesplit ) node ) . stateafter ( ) ) { <nl> / / nothing to do - after frame states are known , allowed cycles <nl> } else { <nl> - assert false : " unexpected cycle detected at input " + node + " - > " + input ; <nl> + <nl> + / / assert false : " unexpected cycle detected at input " + node + " - > " <nl> + / / + input ; <nl> } <nl> } <nl> }
public class loweringphase extends basephase < phasecontext > { <nl> mark preloweringmark = node . graph ( ) . getmark ( ) ; <nl> ( ( lowerable ) node ) . lower ( loweringtool ) ; <nl> if ( loweringtool . guardanchor . asnode ( ) . isdeleted ( ) ) { <nl> + <nl> + assert nextnode . isalive ( ) ; <nl> loweringtool . guardanchor = beginnode . prevbegin ( nextnode ) ; <nl> } <nl> assert checkpostnodelowering ( node , loweringtool , preloweringmark , unscheduledusages ) ; <nl> mmm a / graal / com . oracle . graal . replacements / src / com / oracle / graal / replacements / snippettemplate . java <nl> ppp b / graal / com . oracle . graal . replacements / src / com / oracle / graal / replacements / snippettemplate . java <nl>
class cfgprinter extends compilationprinter { <nl> } <nl>  <nl> private void printnodes ( block block ) { <nl> + if ( latestscheduling = = null ) { <nl> + <nl> + return ; <nl> + } <nl> begin ( " ir " ) ; <nl> out . println ( " hir " ) ; <nl> out . disableindentation ( ) ; <nl> mmm a / graal / com . oracle . graal . printer / src / com / oracle / graal / printer / cfgprinterobserver . java <nl> ppp b / graal / com . oracle . graal . printer / src / com / oracle / graal / printer / cfgprinterobserver . java <nl>
public abstract class ptxtest extends graalcompilertest { <nl> assume . assumetrue ( ptxbackend . isdeviceinitialized ( ) ) ; <nl> hotspotnmethod installedptxcode = installkernel ( method , ptxcode ) ; <nl> structuredgraph wrapper = new ptxwrapperbuilder ( method , installedptxcode , ( hotspotproviders ) getproviders ( ) ) . getgraph ( ) ; <nl> - return super . getcode ( method , wrapper ) ; <nl> + <nl> + / / the ptx c + + layer expects a num : 1 relationship between kernel compilation <nl> + / / and kernel execution as it creates a cucontext in the former and <nl> + / / destroys it in the latter . so , each kernel installed requires a unique <nl> + / / wrapper . <nl> + <nl> + boolean forcecompile = true ; <nl> + <nl> + return getcode ( method , wrapper , forcecompile ) ; <nl> } <nl>  <nl> protected static void compileandprintcode ( ptxtest test ) {
public abstract class hashnodes { <nl> hash . put ( keyvalue . get ( 0 ) , keyvalue . get ( 1 ) ) ; <nl> } <nl> } else { <nl> - assert args . length % num = = num ; <nl> + if ( args . length % num ! = num ) { <nl> + <nl> + throw new unsupportedoperationexception ( ) ; <nl> + } <nl>  <nl> for ( int n = num ; n < args . length ; n + = num ) { <nl> hash . put ( args [ n ] , args [ n + num ] ) ; <nl> mmm a / graal / com . oracle . truffle . ruby . nodes / src / com / oracle / truffle / ruby / nodes / core / stringnodes . java <nl> ppp b / graal / com . oracle . truffle . ruby . nodes / src / com / oracle / truffle / ruby / nodes / core / stringnodes . java <nl>
public abstract class abstractcodewriter extends codeelementscanner < void , void > <nl>  <nl> int end = math . min ( i + nextsize , string . length ( ) ) ; <nl>  <nl> - assert linelength + ( end - i ) + num < max_line_length ; <nl> + <nl> + <nl> write ( " \ " " + string . substring ( i , end ) + " \ " " ) ; <nl> size = nextsize ; <nl> } <nl> mmm a / graal / com . oracle . truffle . dsl . processor / src / com / oracle / truffle / dsl / processor / template / templatemethod . java <nl> ppp b / graal / com . oracle . truffle . dsl . processor / src / com / oracle / truffle / dsl / processor / template / templatemethod . java <nl>
public class templatemethod extends messagecontainer implements comparable < templ <nl> } <nl>  <nl> public void updatesignature ( signature signature ) { <nl> - assert signature . size ( ) > = num ; <nl> + <nl> + <nl> int signatureindex = num ; <nl> for ( actualparameter parameter : getreturntypeandparameters ( ) ) { <nl> if ( ! parameter . getspecification ( ) . issignature ( ) ) {
public final class sourcemanager { <nl> return builder . tostring ( ) ; <nl> } <nl>  <nl> - private abstract static class sourceimpl implements source { <nl> + <nl> + public abstract static class sourceimpl implements source { <nl>  <nl> protected textmap textmap = null ;
public final class linearscan { <nl> printlir ( " after register number assignment " , true ) ; <nl> edgemoveoptimizer . optimize ( ir ) ; <nl> controlflowoptimizer . optimize ( ir ) ; <nl> - redundantmoveelimination . optimize ( ir , framemap , gen . getgraph ( ) . method ( ) ) ; <nl> + <nl> + / * <nl> + * temporarily disabled because of problem in specjvm2008 . <nl> + * re - enable it . <nl> + * <nl> + * redundantmoveelimination . optimize ( ir , framemap , gen . getgraph ( ) . method ( ) ) ; <nl> + * / <nl> + <nl> nullcheckoptimizer . optimize ( ir , target . implicitnullchecklimit ) ; <nl> printlir ( " after control flow optimization " , false ) ; <nl> } catch ( throwable e ) {
final class sparchotspotgraalruntime extends hotspotgraalruntime { <nl> protected hotspotruntime createruntime ( ) { <nl> return new sparchotspotruntime ( config , this ) ; <nl> } <nl> + <nl> + @ override <nl> + protected value [ ] getruntimecallvolatileregisters ( ) { <nl> + <nl> + return new value [ 0 ] ; <nl> + } <nl> } <nl> mmm a / graal / com . oracle . graal . hotspot / src / com / oracle / graal / hotspot / hotspotforeigncalllinkage . java <nl> ppp b / graal / com . oracle . graal . hotspot / src / com / oracle / graal / hotspot / hotspotforeigncalllinkage . java <nl>
public class ptxbackend extends backend { <nl> codebuffer . emitstring ( " " ) ; <nl>  <nl> signature signature = codecacheowner . getsignature ( ) ; <nl> - for ( int i = num ; i < signature . getparametercount ( false ) ; i + + ) { <nl> - string param = " . param . u32 param " + i ; <nl> + int paramcount = signature . getparametercount ( false ) ; <nl> + <nl> + int regsize = num ; <nl> + for ( int i = num ; i < paramcount ; i + + ) { <nl> + string param ; <nl> + / / no unsigned types in java . so using . s specifier <nl> + switch ( signature . getparameterkind ( i ) ) { <nl> + case boolean : <nl> + case byte : <nl> + param = " . param . s8 param " + i ; <nl> + regsize = num ; <nl> + break ; <nl> + case char : <nl> + case short : <nl> + param = " . param . s16 param " + i ; <nl> + regsize = num ; <nl> + break ; <nl> + case int : <nl> + param = " . param . s32 param " + i ; <nl> + regsize = num ; <nl> + break ; <nl> + case long : <nl> + case float : <nl> + case double : <nl> + case void : <nl> + param = " . param . s64 param " + i ; <nl> + regsize = num ; <nl> + break ; <nl> + default : <nl> + / / not sure but specify num - bit specifier ? ? <nl> + param = " . param . s64 param " + i ; <nl> + break ; <nl> + } <nl> + if ( i ! = ( paramcount - 1 ) ) { <nl> + param + = " , " ; <nl> + } <nl> codebuffer . emitstring ( param ) ; <nl> } <nl>  <nl>
public final class checkcastnode extends fixedwithnextnode implements canonicali <nl> return forstorecheck ; <nl> } <nl>  <nl> + <nl> + private static final boolean usenewlowering = boolean . getboolean ( " graal . checkcast . usenewlowering " ) ; <nl> + <nl> / * * <nl> * lowers a { @ link checkcastnode } to a { @ link guardingpinode } . that is : <nl> * <nl>
public class nodeintrinsificationphase extends phase { <nl> resolvedjavamethod target = invoke . methodcalltarget ( ) . targetmethod ( ) ; <nl> nodeintrinsic intrinsic = target . getannotation ( node . nodeintrinsic . class ) ; <nl> resolvedjavatype declaringclass = target . getdeclaringclass ( ) ; <nl> + javatype receivertype = invoke . methodcalltarget ( ) . isstatic ( ) ? null : declaringclass ; <nl> if ( intrinsic ! = null ) { <nl> assert target . getannotation ( fold . class ) = = null ; <nl>  <nl> - class < ? > [ ] parametertypes = signaturetotypes ( target . getsignature ( ) , declaringclass ) ; <nl> + <nl> + class < ? > [ ] parametertypes = signaturetotypes ( target . getsignature ( ) , null , declaringclass ) ; <nl> resolvedjavatype returntype = target . getsignature ( ) . getreturntype ( declaringclass ) . resolve ( declaringclass ) ; <nl>  <nl> / / prepare the arguments for the reflective constructor call on the node class . <nl>
public class wordtyperewriterphase extends phase { <nl> return true ; <nl> } <nl> if ( node instanceof loadindexednode ) { <nl> - return isword ( ( ( loadindexednode ) node ) . array ( ) . objectstamp ( ) . type ( ) . getcomponenttype ( ) ) ; <nl> + valuenode array = ( ( loadindexednode ) node ) . array ( ) ; <nl> + if ( array . objectstamp ( ) . type ( ) = = null ) { <nl> + / / there are cases where the array does not have a known type yet . assume it is not a word type . <nl> + <nl> + return false ; <nl> + } <nl> + return isword ( array . objectstamp ( ) . type ( ) . getcomponenttype ( ) ) ; <nl> } <nl> if ( node . kind ( ) = = kind . object ) { <nl> return isword ( node . objectstamp ( ) . type ( ) ) ; <nl> mmm a / graal / com . oracle . graal . word / src / com / oracle / graal / word / phases / wordtypeverificationphase . java <nl> ppp b / graal / com . oracle . graal . word / src / com / oracle / graal / word / phases / wordtypeverificationphase . java <nl>
public class snippetinstaller { <nl> new snippetintrinsificationphase ( runtime , pool , snippettemplate . hasconstantparameter ( method ) ) . apply ( graph ) ; <nl>  <nl> if ( issubstitutionsnippet ) { <nl> + <nl> new snippetframestatecleanupphase ( ) . apply ( graph ) ; <nl> new deadcodeeliminationphase ( ) . apply ( graph ) ; <nl> }
public class newarraystub extends stub { <nl>  <nl> @ fold <nl> private static boolean forceslowpath ( ) { <nl> - return boolean . getboolean ( " graal . newarraystub . forceslowpath " ) ; <nl> + <nl> + return " true " . equalsignorecase ( system . getproperty ( " graal . newarraystub . forceslowpath " , " true " ) ) ; <nl> } <nl> }
public final class optimisticoptimizations { <nl> public optimisticoptimizations ( resolvedjavamethod method ) { <nl> this . enabledopts = enumset . noneof ( optimization . class ) ; <nl>  <nl> - profilinginfo profilinginfo = method . getprofilinginfo ( ) ; <nl> - if ( checkdeoptimizations ( profilinginfo , deoptimizationreason . unreachedcode ) ) { <nl> - enabledopts . add ( optimization . removeneverexecutedcode ) ; <nl> - } <nl> - if ( checkdeoptimizations ( profilinginfo , deoptimizationreason . typecheckedinliningviolated ) ) { <nl> - enabledopts . add ( optimization . usetypecheckedinlining ) ; <nl> - } <nl> - if ( checkdeoptimizations ( profilinginfo , deoptimizationreason . optimizedtypecheckviolated ) ) { <nl> - enabledopts . add ( optimization . usetypecheckhints ) ; <nl> - } <nl> - if ( checkdeoptimizations ( profilinginfo , deoptimizationreason . notcompiledexceptionhandler ) ) { <nl> - enabledopts . add ( optimization . useexceptionprobability ) ; <nl> - } <nl> + addoptimization ( method , deoptimizationreason . unreachedcode , optimization . removeneverexecutedcode ) ; <nl> + addoptimization ( method , deoptimizationreason . typecheckedinliningviolated , optimization . usetypecheckedinlining ) ; <nl> + addoptimization ( method , deoptimizationreason . optimizedtypecheckviolated , optimization . removeneverexecutedcode ) ; <nl> + addoptimization ( method , deoptimizationreason . notcompiledexceptionhandler , optimization . useexceptionprobability ) ; <nl> + } <nl>  <nl> - log ( method ) ; <nl> + private void addoptimization ( resolvedjavamethod method , deoptimizationreason deoptreason , optimization optimization ) { <nl> + if ( checkdeoptimizations ( method . getprofilinginfo ( ) , deoptreason ) ) { <nl> + enabledopts . add ( optimization ) ; <nl> + } else { <nl> + <nl> + tty . println ( " warn : deactivated optimistic optimization % s for % s " , optimization . name ( ) , metautil . format ( " % h . % n ( % p ) " , method ) ) ; <nl> + disabledoptimisticoptsmetric . increment ( ) ; <nl> + } <nl> } <nl>  <nl> private optimisticoptimizations ( set < optimization > enabledopts ) { <nl> this . enabledopts = enabledopts ; <nl> } <nl>  <nl> - private void log ( resolvedjavamethod method ) { <nl> - if ( debug . islogenabled ( ) ) { <nl> - for ( optimization opt : optimization . values ( ) ) { <nl> - if ( ! enabledopts . contains ( opt ) ) { <nl> - if ( graaloptions . printdisabledoptimisticoptimizations ) { <nl> - debug . log ( " warn : deactivated optimistic optimization % s for % s " , opt . name ( ) , metautil . format ( " % h . % n ( % p ) " , method ) ) ; <nl> - } <nl> - disabledoptimisticoptsmetric . increment ( ) ; <nl> - } <nl> - } <nl> - } <nl> - } <nl> - <nl> public boolean removeneverexecutedcode ( ) { <nl> return graaloptions . removeneverexecutedcode & & enabledopts . contains ( optimization . removeneverexecutedcode ) ; <nl> }
public final class graphbuilderphase extends phase { <nl>  <nl> / / finish the start block <nl> ( ( statesplit ) lastinstr ) . setstateafter ( framestate . create ( 0 ) ) ; <nl> + <nl> + currentblock = blockmap . startblock ; <nl> + blockmap . startblock . entrystate = framestate ; <nl> if ( blockmap . startblock . isloopheader ) { <nl> + <nl> + / / would be to create a dummy block in bciblockmapping . <nl> appendgoto ( createtarget ( blockmap . startblock , framestate ) ) ; <nl> } else { <nl> blockmap . startblock . firstinstruction = lastinstr ; <nl> - blockmap . startblock . entrystate = framestate ; <nl> } <nl>  <nl> for ( block block : blockmap . blocks ) {
public final class ifnode extends controlsplitnode implements simplifiable , lirl <nl> return false ; <nl> } <nl>  <nl> + if ( merge . stateafter ( ) ! = null ) { <nl> + <nl> + return false ; <nl> + } <nl> + <nl> / / only consider merges with a single usage that is both a phi and an operand of the comparison <nl> nodeusageslist mergeusages = merge . usages ( ) ; <nl> if ( mergeusages . count ( ) ! = num ) {
public class convertdeoptimizetoguardphase extends phase { <nl> ifnode ifnode = ( ifnode ) deoptbegin . predecessor ( ) ; <nl> beginnode otherbegin = ifnode . truesuccessor ( ) ; <nl> booleannode conditionnode = ifnode . compare ( ) ; <nl> + if ( conditionnode instanceof instanceofnode ) { <nl> + <nl> + return ; <nl> + } <nl> boolean negated = false ; <nl> if ( deoptbegin = = ifnode . truesuccessor ( ) ) { <nl> negated = true ;
public class hp_series { <nl> return ( 0 . 0 ) ; <nl> } <nl>  <nl> - @ test <nl> + <nl> public void run0 ( ) throws throwable { <nl> assert . assertequals ( 0 . 6248571921291398d , test ( 100 ) , num ) ; <nl> }
public abstract class looppolicies { <nl> int size = math . max ( 1 , loop . size ( ) - num - loop . loopbegin ( ) . phis ( ) . count ( ) ) ; <nl> return size * exacttrips < = maxnodes ; <nl> } <nl> + <nl> + public static boolean shouldtryunswitch ( @ suppresswarnings ( " unused " ) loopex loop ) { <nl> + <nl> + return true ; <nl> + } <nl> } <nl> mmm a / graal / com . oracle . graal . compiler / src / com / oracle / graal / compiler / phases / looptransformlowphase . java <nl> ppp b / graal / com . oracle . graal . compiler / src / com / oracle / graal / compiler / phases / looptransformlowphase . java <nl>
public final class graaloptions { <nl> public static float minimumusageprobability = num . 95f ; <nl>  <nl> / / loop transform settings <nl> - public static float minimumpeelprobability = num . 25f ; <nl> + public static float minimumpeelprobability = num . 35f ; <nl> + public static boolean reassociateinvariants = true ; <nl> + public static boolean fullunroll = true ; <nl> + public static int fullunrollmaxnodes = num ; <nl>  <nl> / / debugging settings <nl> public static int methodendbreakpointguards = num ; <nl>
public class compilationserver implements runnable { <nl> } <nl> } while ( multiple ) ; <nl> } <nl> + <nl> + @ suppresswarnings ( " unused " ) <nl> + private static hotspotcompilerimpl initializeserver ( compilertovm tovm ) { <nl> + <nl> + return null ; <nl> + } <nl> } <nl> mmm a / graal / com . oracle . graal . hotspot / src / com / oracle / graal / hotspot / hotspotcompilerimpl . java <nl> ppp b / graal / com . oracle . graal . hotspot / src / com / oracle / graal / hotspot / hotspotcompilerimpl . java <nl>
public class floatingreadphase extends phase { <nl> other = othermemorymap . map . get ( locationnode . any_location ) ; <nl> } <nl>  <nl> - phinode . addinput ( ( valuenode ) other ) ; <nl> + / / this explicitly honors the phi input index , since the iteration order will not always adhere to the end <nl> + <nl> + int <nl> + phinode . initializevalueat ( index , ( valuenode ) other ) ; <nl> } <nl> } <nl>  <nl>
public class floatingreadphase extends phase { <nl> assert phi . valuecount ( ) < = phi . merge ( ) . forwardendcount ( ) : phi . merge ( ) ; <nl> } else { <nl> phinode phi = m . graph ( ) . unique ( new phinode ( cikind . illegal , m , phitype . memory ) ) ; <nl> + <nl> for ( int i = num ; i < mergeoperationcount + num ; + + i ) { <nl> phi . addinput ( ( valuenode ) original ) ; <nl> } <nl>
public class loweringphase extends phase { <nl> this . runtime = runtime ; <nl> this . assumptions = assumptions ; <nl> } <nl> - <nl> @ override <nl> protected void run ( final structuredgraph graph ) { <nl> + / / step num : repeatedly lower fixed nodes until no new ones are created <nl> + nodebitmap processed = graph . createnodebitmap ( ) ; <nl> + while ( true ) { <nl> + int mark = graph . getmark ( ) ; <nl> + controlflowgraph cfg = controlflowgraph . compute ( graph , true , false , true , true ) ; <nl> + processblock ( cfg . getstartblock ( ) , graph . createnodebitmap ( ) , processed , null ) ; <nl> + <nl> + if ( graph . getnewnodes ( mark ) . filter ( fixednode . class ) . isempty ( ) ) { <nl> + break ; <nl> + } <nl> + graph . verify ( ) ; <nl> + processed . grow ( ) ; <nl> + } <nl> + <nl> + / / step num : lower the floating nodes <nl> + processed . negate ( ) ; <nl> + final ciloweringtool loweringtool = new ciloweringtool ( ) { <nl> + <nl> + @ override <nl> + public node getguardanchor ( ) { <nl> + throw new unsupportedoperationexception ( ) ; <nl> + } <nl> + <nl> + @ override <nl> + public graalruntime getruntime ( ) { <nl> + return runtime ; <nl> + } <nl> + <nl> + @ override <nl> + public node createguard ( node condition , rideoptreason deoptreason , rideoptaction action , long leafgraphid ) { <nl> + <nl> + throw new unsupportedoperationexception ( ) ; <nl> + } <nl> + <nl> + @ override <nl> + public ciassumptions assumptions ( ) { <nl> + return assumptions ; <nl> + } <nl> + } ; <nl> + for ( node node : processed ) { <nl> + if ( node instanceof lowerable ) { <nl> + assert ! ( node instanceof fixednode ) | | node . predecessor ( ) = = null : node ; <nl> + ( ( lowerable ) node ) . lower ( loweringtool ) ; <nl> + } <nl> + } <nl> + } <nl> + <nl> + protected void run0 ( final structuredgraph graph ) { <nl> controlflowgraph cfg = controlflowgraph . compute ( graph , true , false , true , true ) ; <nl>  <nl> nodebitmap processed = graph . createnodebitmap ( ) ; <nl>
public final class istypenode extends booleannode implements canonicalizable , li <nl>  <nl> @ override <nl> public valuenode canonical ( canonicalizertool tool ) { <nl> + if ( objectclass ( ) . isconstant ( ) ) { <nl> + ciconstant constant = objectclass ( ) . asconstant ( ) ; <nl> + ciconstant typehub = type . getencoding ( representation . objecthub ) ; <nl> + assert constant . kind = = typehub . kind ; <nl> + return constantnode . forboolean ( constant . equivalent ( typehub ) , graph ( ) ) ; <nl> + } <nl> + <nl> riresolvedtype exacttype = objectclass ( ) instanceof readhubnode ? ( ( readhubnode ) objectclass ( ) ) . object ( ) . exacttype ( ) : null ; <nl> if ( exacttype ! = null ) { <nl> return constantnode . forboolean ( exacttype = = type ( ) , graph ( ) ) ;
public class hotspotfield extends compilerobject implements riresolvedfield { <nl> return constant ; <nl> } else { <nl> assert ! modifier . isstatic ( accessflags ) ; <nl> + <nl> if ( modifier . isfinal ( accessflags ( ) ) ) { <nl> return this . kind ( false ) . readunsafeconstant ( receiver . asobject ( ) , offset ) ; <nl> }
public final class graphbuilderphase extends phase { <nl> } <nl> } <nl>  <nl> + <nl> beginnode p = currentgraph . add ( new beginnode ( ) ) ; <nl> p . setstateafter ( framestate . duplicatewithoutstack ( bci ) ) ;
public class inliningutil { <nl> framestate . replaceanddelete ( stateafter ) ; <nl> } else if ( framestate . bci = = framestate . after_exception_bci ) { <nl> if ( framestate . isalive ( ) ) { <nl> + <nl> assert stateatexceptionedge ! = null ; <nl> framestate . replaceanddelete ( stateatexceptionedge ) ; <nl> } else {
public final class hotspotprofilinginfo extends compilerobject implements riprof <nl> } <nl> } <nl>  <nl> + <nl> + <nl> nodatafound ( ) ; <nl> }
public class loweringphase extends phase { <nl>  <nl> @ override <nl> public node createguard ( node condition ) { <nl> + <nl> throw new unsupportedoperationexception ( ) ; <nl> } <nl> } ;
public class tailcallnode extends fixedwithnextnode implements lirlowerable { <nl>  <nl> cikind [ ] signature = ciutil . signaturetokinds ( method . signature ( ) , isstatic ? null : method . holder ( ) . kind ( true ) ) ; <nl> cicallingconvention cc = gen . framemap ( ) . registerconfig . getcallingconvention ( cicallingconvention . type . javacall , signature , gen . target ( ) , false ) ; <nl> - gen . framemap ( ) . callsmethod ( cc , cicallingconvention . type . javacall ) ; <nl> + gen . framemap ( ) . callsmethod ( cc , cicallingconvention . type . javacall ) ; <nl> list < valuenode > parameters = new arraylist < > ( ) ; <nl> - for ( int i = num ; i < cc . locations . length ; i + + ) { <nl> - parameters . add ( framestate . localat ( i ) ) ; <nl> + for ( int i = num , slot = num ; i < cc . locations . length ; i + + , slot + = framestatebuilder . stackslots ( framestate . localat ( slot ) . kind ( ) ) ) { <nl> + parameters . add ( framestate . localat ( slot ) ) ; <nl> } <nl> list < civalue > arglist = gen . visitinvokearguments ( cc , parameters , null ) ; <nl>  <nl> mmm a / graal / com . oracle . max . graal . hotspot / src / com / oracle / max / graal / hotspot / target / amd64 / amd64tailcallop . java <nl> ppp b / graal / com . oracle . max . graal . hotspot / src / com / oracle / max / graal / hotspot / target / amd64 / amd64tailcallop . java <nl>
package com . oracle . max . graal . hotspot ; <nl> import com . sun . cri . ci . * ; <nl>  <nl> / * * <nl> - * hotspot - specific citarget that provides the correct stack frame size alignment . <nl> + * hotspot - specific citarget . <nl> + * <nl> * / <nl> public class hotspottarget extends citarget { <nl>  <nl> public hotspottarget ( ciarchitecture arch , boolean ismp , int spillslotsize , int stackalignment , int pagesize , int cachealignment , boolean inlineobjects ) { <nl> super ( arch , ismp , spillslotsize , stackalignment , pagesize , cachealignment , inlineobjects , true , true ) ; <nl> } <nl> - <nl> - @ override <nl> - public int alignframesize ( int framesize ) { <nl> - / / account for the stored rbp value <nl> - return super . alignframesize ( framesize + wordsize ) - wordsize ; <nl> - } <nl> } <nl> mmm a / graal / com . oracle . max . graal . hotspot / src / com / oracle / max / graal / hotspot / hotspotxirgenerator . java <nl> ppp b / graal / com . oracle . max . graal . hotspot / src / com / oracle / max / graal / hotspot / hotspotxirgenerator . java <nl>
public class identifyblocksphase extends phase { <nl> } <nl> } <nl> } <nl> + <nl> if ( forced | | materializationcost ( block , blockusages ) < materializationcostatchildren ( block , usages ) ) { <nl> node n ; <nl> if ( nodetoblock . get ( node ) = = null ) {
public class identifyblocksphase extends phase { <nl> visited . set ( dominatorroot . blockid ( ) ) ; <nl> linkedlist < block > worklist = new linkedlist < block > ( ) ; <nl> worklist . add ( dominatorroot ) ; <nl> + <nl>  <nl> while ( ! worklist . isempty ( ) ) { <nl> block b = worklist . remove ( ) ;
package com . oracle . max . graal . compiler . phases ; <nl> import com . oracle . max . graal . compiler . * ; <nl> import com . oracle . max . graal . graph . * ; <nl>  <nl> + / * <nl> + * - compare & if <nl> + * - instanceof ( if it ' s not transformed into a condition for compare ) <nl> + * - switches <nl> + * / <nl> public class canonicalizerphase extends phase { <nl> private static final int max_iteration_per_node = num ;
public class ir { <nl> } <nl>  <nl> schedule schedule = new schedule ( this . compilation . graph ) ; <nl> + list < block > blocks = schedule . getblocks ( ) ; <nl> + nodemap < block > nodetoblock = schedule . getnodetoblock ( ) ; <nl> + map < block , lirblock > map = new hashmap < block , lirblock > ( ) ; <nl> + for ( block b : blocks ) { <nl> + map . put ( b , new lirblock ( b . blockid ( ) ) ) ; <nl> + } <nl> + <nl> + for ( block b : blocks ) { <nl> + for ( block succ : b . getsuccessors ( ) ) { <nl> + map . get ( b ) . blocksuccessors ( ) . add ( map . get ( succ ) ) ; <nl> + } <nl> + <nl> + for ( block pred : b . getpredecessors ( ) ) { <nl> + map . get ( b ) . blockpredecessors ( ) . add ( map . get ( pred ) ) ; <nl> + } <nl> + } <nl> + <nl> + <nl> + <nl>  <nl> valuetoblock = computelinearscanorder ( ) ; <nl> verifyandprint ( " after linear scan order " ) ; <nl> mmm a / graal / graalcompiler / src / com / sun / c1x / lir / lirblock . java <nl> ppp b / graal / graalcompiler / src / com / sun / c1x / lir / lirblock . java <nl>
public abstract class node implements cloneable { <nl> } <nl>  <nl> public node set ( int index , node node ) { <nl> - assert node = = null | | node . graph = = self ( ) . graph ; <nl> + <nl> node old = nodes [ index ] ; <nl>  <nl> if ( old ! = node ) {
jobs : <nl> java : [ 8 , num , num ] <nl> mock - maker : [ ' mock - maker - default ' , ' mock - maker - inline ' ] <nl>  <nl> - # build steps <nl> + # all build steps <nl> steps : <nl> + <nl> - name : num . check out code <nl> uses : actions / checkout @ v2 # https : / / github . com / actions / checkout <nl> with : <nl> - fetch - depth : ' 0 ' # # https : / / github . com / shipkit / shipkit - changelog # fetch - depth - on - ci <nl> - <nl> + fetch - depth : ' 0 ' # https : / / github . com / shipkit / shipkit - changelog # fetch - depth - on - ci <nl> + <nl> - name : num . set up java $ { { matrix . java } } <nl> uses : actions / setup - java @ v1 <nl> with : <nl> java - version : $ { { matrix . java } } <nl> - <nl> + <nl> + # <nl> + <nl> - name : num . build and check reproducibility of artifacts ( single job only ) <nl> # run on a single job , with the version of java used for releases <nl> if : matrix . java = = num & & matrix . mock - maker = = ' mock - maker - default ' <nl> run : . / check_reproducibility . sh <nl> - <nl> + <nl> - name : num . spotless check ( single job only ) . run ' . / gradlew spotlessapply ' locally if this job fails . <nl> # run on a single job , with java version compatible with spotless <nl> if : matrix . java = = num & & matrix . mock - maker = = ' mock - maker - default ' <nl> run : . / gradlew spotlesscheck <nl> - <nl> + <nl> - name : num . build on java $ { { matrix . java } } with $ { { matrix . mock - maker } } <nl> run : . / gradlew build bintrayupload idea - - scan - pbintraydryrun <nl> env : <nl> mock_maker : $ { { matrix . mock - maker } } <nl> - <nl> + <nl> - name : num . upload coverage report <nl> run : | <nl> . / gradlew coveragereport - s - - scan & & cp build / reports / jacoco / mockitocoverage / mockitocoverage . xml jacoco . xml | | echo " code coverage failed " <nl> bash < ( curl - s https : / / codecov . io / bash ) | | echo " codecov did not collect coverage reports " <nl> - <nl> + <nl> # <nl> # release job , only for pushes to the main branch <nl> # <nl>
jobs : <nl> steps : <nl> - uses : actions / checkout @ v2 # https : / / github . com / actions / checkout <nl> with : <nl> - fetch - depth : ' 0 ' # all tags ( version deduction ) and commits ( changelog generation ) <nl> + fetch - depth : ' 0 ' # https : / / github . com / shipkit / shipkit - changelog # fetch - depth - on - ci <nl> - name : set up java num <nl> uses : actions / setup - java @ v1 <nl> with : <nl> java - version : num <nl> - name : build and publish <nl> - run : . / gradlew bintrayupload githubrelease - - scan - m <nl> + run : . / gradlew bintrayupload githubrelease - - scan - pbintraydryrun # <nl> + env : <nl> + gh_write_token : $ { { secrets . gh_write_token } } <nl> + bintray_api_key : $ { { secrets . bintray_api_key } }
jobs : <nl> with : <nl> java - version : $ { { matrix . java } } <nl> - name : build on java $ { { matrix . java } } with $ { { matrix . mock - maker } } <nl> - run : . / gradlew build - x animalsniffermain <nl> + run : . / gradlew build - x animalsniffermain - - scan # <nl> env : <nl> mock_maker : $ { { matrix . mock - maker } } <nl> + - name : upload coverage report <nl> + if : matrix . java = = num & & matrix . mock - maker = ' mock - maker - default ' <nl> + run : | <nl> + . / gradlew coveragereport - s - - scan & & cp build / reports / jacoco / mockitocoverage / mockitocoverage . xml jacoco . xml | | echo " code coverage failed " <nl> + bash < ( curl - s https : / / codecov . io / bash ) | | echo " codecov did not collect coverage reports " <nl> release : <nl> runs - on : ubuntu - latest <nl> needs : [ build ] <nl>
shipkit { <nl> ' docs ' : ' documentation ' <nl> ] <nl>  <nl> - git . releasablebranchregex = " release / . + " / / ' release / 2 . x ' , ' release / 3 . x ' , etc . <nl> + <nl> + git . releasablebranchregex = " release / 2 . x " / / ' release / 2 . x ' , ' release / 3 . x ' , etc . <nl>  <nl> def buildno = system . getenv ( " travis_build_number " ) <nl> git . commitmessagepostfix = buildno ? " by ci build $ buildno\n\n [ ci skip - release ] " : " by local build\n\n [ ci skip - release ] "
public class creationsettings < t > implements mockcreationsettings < t > , serializabl <nl>  <nl> @ suppresswarnings ( " unchecked " ) <nl> public creationsettings ( creationsettings copy ) { <nl> + <nl> this . typetomock = copy . typetomock ; <nl> this . extrainterfaces = copy . extrainterfaces ; <nl> this . name = copy . name ; <nl> mmm a / src / main / java / org / mockito / internal / junit / strictstubsrunnertestlistener . java <nl> ppp b / src / main / java / org / mockito / internal / junit / strictstubsrunnertestlistener . java <nl>
<nl> if ( ! project . hasproperty ( " jacoco " ) ) { <nl> / / jacoco plugin prevents using build cache . we will enable jacoco configuration only when specific property is supplied <nl> + <nl> logger . info " jacoco code coverage will not be configured because ' jacoco ' project property is not present . " <nl> return / / don ' t evaluate this gradle file any further <nl> } else {
<nl> + / * <nl> + * copyright ( c ) num mockito contributors <nl> + * this program is made available under the terms of the mit license . <nl> + * / <nl> + package org . mockitousage . stubbing ; <nl> + <nl> + import org . assertj . core . api . assertions ; <nl> + import org . assertj . core . api . throwableassert ; <nl> + import org . junit . test ; <nl> + import org . mockito . answers ; <nl> + <nl> + import static org . mockito . mockito . mock ; <nl> + import static org . mockito . mockito . withsettings ; <nl> + <nl> + / / reproduces issue # 1551 <nl> + public class smartnullsgenericbugtest { <nl> + <nl> + @ test <nl> + public void smart_nulls_generic_bug ( ) { <nl> + final concretedao concretedao = mock ( concretedao . class , withsettings ( ) . defaultanswer ( answers . returns_smart_nulls ) ) ; <nl> + <nl> + assertions . assertthatthrownby ( new throwableassert . throwingcallable ( ) { <nl> + public void call ( ) { <nl> + concretedao . findbyid ( ) ; <nl> + } <nl> + } ) . isinstanceof ( classcastexception . class ) ; <nl> + <nl> + } <nl> + <nl> + static class abstractdao < t > { <nl> + t findbyid ( ) { <nl> + return null ; <nl> + } <nl> + } <nl> + <nl> + static class entity { } <nl> + static class concretedao extends abstractdao < entity > { } <nl> + }
import java . util . linkedlist ; <nl> * streamlines testing async code for mockito tests . <nl> * <nl> * instances of this class are not thread safe ( intentionally , they are not required to be thread safe ) <nl> + * <nl> + * <nl> * / <nl> public class asynctesting {
public class verificationwithaftertest { <nl> async . cleanup ( ) ; <nl> } <nl>  <nl> + / * * <nl> + <nl> + <nl> + <nl> + - nothing + fail <nl> + - times ( 2 ) + fail <nl> + - atleastonce , atleast ( 2 ) , fail <nl> + - atmost , fail <nl> + - never , fail <nl> + - only , fail <nl> + <nl> + * / <nl> + <nl> @ test <nl> public void should_verify_normally_with_specific_times ( ) { <nl> / / given
import org . mockito . stubbing . stubbing ; <nl> import static org . mockito . mockito . mockingdetails ; <nl>  <nl> public class stubbingstrictness { <nl> + <nl> public static boolean islenientstubbing ( stubbing stubbing ) { <nl> strictness mockstrictness = mockingdetails ( stubbing . getinvocation ( ) . getmock ( ) ) . getmockcreationsettings ( ) . getstrictness ( ) ; <nl> return mockstrictness = = strictness . lenient ;
class defaultstubbinglookuplistener implements stubbinglookuplistener { <nl> collection < stubbing > stubbings = mockingdetails ( invocation . getmock ( ) ) . getstubbings ( ) ; <nl> for ( stubbing s : stubbings ) { <nl> if ( ! s . wasused ( ) & & s . getinvocation ( ) . getmethod ( ) . getname ( ) . equals ( invocation . getmethod ( ) . getname ( ) ) <nl> + <nl> & & s . getstrictness ( ) ! = strictness . lenient ) { <nl> matchingstubbings . add ( s . getinvocation ( ) ) ; <nl> } <nl> mmm a / src / main / java / org / mockito / internal / junit / unusedstubbingsfinder . java <nl> ppp b / src / main / java / org / mockito / internal / junit / unusedstubbingsfinder . java <nl>
public class unusedstubbingsfinder { <nl>  <nl> list < stubbing > unused = filter ( stubbings , new filter < stubbing > ( ) { <nl> public boolean isout ( stubbing s ) { <nl> + <nl> return s . wasused ( ) | | s . getstrictness ( ) = = strictness . lenient ; <nl> } <nl> } ) ; <nl> mmm / dev / null <nl> ppp b / src / main / java / org / mockito / internal / stubbing / strictnessselector . java <nl>
public interface mocksettings extends serializable { <nl> @ incubating <nl> < t > mockcreationsettings < t > build ( class < t > typetomock ) ; <nl>  <nl> + <nl> mocksettings strictness ( strictness strictness ) ; <nl> }
public class strictnessperstubbingtest { <nl> public void potential_stubbing_problem ( ) { <nl> / / when <nl> when ( mock . simplemethod ( " 1 " ) ) . thenreturn ( " 1 " ) ; <nl> + <nl> lenient ( ) . when ( mock . differentmethod ( " 2 " ) ) . thenreturn ( " 2 " ) ; <nl>  <nl> / / then on lenient stubbing , we can call it with different argument :
import static org . mockito . internal . util . collections . listutil . filter ; <nl> public class unusedstubbingsfinder { <nl>  <nl> / * * <nl> - * gets all unused stubbings for given set of mock objects , in order <nl> + * gets all unused stubbings for given set of mock objects , in order . <nl> + * stubbings explicitily marked as lenient are not included . <nl> * / <nl> public unusedstubbings getunusedstubbings ( iterable < object > mocks ) { <nl> set < stubbing > stubbings = allinvocationsfinder . findstubbings ( mocks ) ; <nl>  <nl> list < stubbing > unused = filter ( stubbings , new filter < stubbing > ( ) { <nl> public boolean isout ( stubbing s ) { <nl> - return s . wasused ( ) ; <nl> + <nl> + return s . wasused ( ) | | s . getstrictness ( ) = = strictness . lenient ; <nl> } <nl> } ) ; <nl>  <nl> mmm a / src / test / java / org / mockitousage / internal / junit / unusedstubbingsfindertest . java <nl> ppp b / src / test / java / org / mockitousage / internal / junit / unusedstubbingsfindertest . java <nl>
import org . mockito . incubating ; <nl> * it allows to replace the mock object for verification . <nl> * this api is not needed for regular mockito users who want to write beautiful and clean tests . <nl> * it is only needed for advanced framework integrations where there are multiple layers of proxying . <nl> - * an example framework that leverages this api is spring boot . <nl> + * an example framework that leverages this api is < a href = " <nl> * for details about the use case see < a href = " https : / / github . com / mockito / mockito / issues / 1191 " > issue num < / a > . <nl> * for sample code see { @ code verificationstartedlistenertest } class . <nl> * mockito is open source so feel free to dive into the code !
public class verificationstartednotifier { <nl> return event . getmock ( ) ; <nl> } <nl>  <nl> - private static class defaultverificationstartedevent implements verificationstartedevent { <nl> + static class event implements verificationstartedevent { <nl> private object mock ; <nl> public void setmock ( object mock ) { <nl> if ( mock = = null ) { <nl> throw reporter . methoddoesnotacceptparameter ( " verificationstartedevent . setmock " , " null parameter " ) ; <nl> } <nl> + if ( ! mockutil . ismock ( mock ) ) { <nl> + throw reporter . methoddoesnotacceptparameter ( " verificationstartedevent . setmock " , " parameter which is not a mockito mock " ) ; <nl> + <nl> + } <nl> this . mock = mock ; <nl> } <nl> public object getmock ( ) { <nl> mmm a / src / test / java / org / mockito / internal / listeners / verificationstartednotifiertest . java <nl> ppp b / src / test / java / org / mockito / internal / listeners / verificationstartednotifiertest . java <nl>
public class verificationstartednotifiertest { <nl> assertequals ( " verificationstartedevent . setmock ( ) does not accept null parameter . see the javadoc . " , e . getmessage ( ) ) ; <nl> } <nl> } <nl> + <nl> + @ test <nl> + public void decent_exception_when_setting_non_mock ( ) throws exception { <nl> + verificationstartednotifier . event event = new verificationstartednotifier . event ( ) ; <nl> + <nl> + try { <nl> + / / when <nl> + event . setmock ( " not a mock " ) ; <nl> + fail ( ) ; <nl> + } catch ( exception e ) { <nl> + / / then <nl> + assertequals ( " verificationstartedevent . setmock ( ) does not accept parameter which is not a mockito mock . see the javadoc . " , e . getmessage ( ) ) ; <nl> + } <nl> + } <nl> + <nl> + @ ignore <nl> + @ test <nl> + public void decent_exception_when_setting_mock_of_wrong_type ( ) throws exception { <nl> + final set differenttypemock = mock ( set . class ) ; <nl> + verificationstartednotifier . event event = new verificationstartednotifier . event ( ) ; <nl> + <nl> + try { <nl> + / / when <nl> + event . setmock ( differenttypemock ) ; <nl> + fail ( ) ; <nl> + } catch ( exception e ) { <nl> + / / then <nl> + assertequals ( " ? ? ? " , e . getmessage ( ) ) ; <nl> + } <nl> + } <nl> }
public class mockutil { <nl> } <nl>  <nl> public static boolean ismock ( object mock ) { <nl> + <nl> return mock ! = null & & mockmaker . gethandler ( mock ) ! = null ; <nl> } <nl>  <nl> + public static mockitomock getmockitomock ( object mock ) { <nl> + return new mockitomock ( mockmaker . gethandler ( mock ) ) ; <nl> + } <nl> + <nl> public static mockname getmockname ( object mock ) { <nl> return getmockhandler ( mock ) . getmocksettings ( ) . getmockname ( ) ; <nl> } <nl> mmm / dev / null <nl> ppp b / src / main / java / org / mockito / internal / util / mockitomock . java <nl>
<nl> + package org . mockito . internal . util ; <nl> + <nl> + import org . mockito . invocation . mockhandler ; <nl> + <nl> + / * * <nl> + * represents mockito mock object , gives access to { @ link mockhandler } <nl> + * <nl> + * <nl> + * this is not ideal because gethandler ( ) can be expensive ( reflective calls inside mock maker ) <nl> + * the frequent pattern in the codebase is : num ) ismock ( mock ) num ) getmockhandler ( mock ) <nl> + * we could replace it with using getmockitomock ( ) <nl> + * let ' s refactor the codebase and use new getmockitomock ( ) in all relevant places . <nl> + * potentially we could also move other methods to mockitomock , some other candidates : <nl> + * getinvocationcontainer , isspy , etc . <nl> + * the goal is to avoid unnecessary calls to mockmaker . gethandler <nl> + * / <nl> + public class mockitomock { <nl> + <nl> + private final mockhandler handler ; <nl> + <nl> + / * * <nl> + * @ param handler ok to pass null , it means it is not a mock object <nl> + * / <nl> + mockitomock ( mockhandler handler ) { <nl> + this . handler = handler ; <nl> + } <nl> + <nl> + public boolean ismock ( ) { <nl> + return handler ! = null ; <nl> + } <nl> + <nl> + public mockhandler gethandler ( ) { <nl> + return handler ; <nl> + } <nl> + }
public interface mocksettings extends serializable { <nl> * / <nl> @ incubating <nl> mocksettings outerinstance ( object outerclassinstance ) ; <nl> + <nl> + / * * <nl> + * creates immutable view of mock settings used later by mockito . <nl> + * framework integrators can use this method to create instances of creation settings . <nl> + * <nl> + * @ param typetomock class to mock <nl> + * @ param < t > type to mock <nl> + * @ return immutable view of mock settings <nl> + * @ since <nl> + * / <nl> + < t > mockcreationsettings < t > build ( class < t > typetomock ) ; <nl> } <nl> mmm a / src / main / java / org / mockito / internal / creation / mocksettingsimpl . java <nl> ppp b / src / main / java / org / mockito / internal / creation / mocksettingsimpl . java <nl>
apply plugin : " org . mockito . mockito - release - tools . continuous - delivery " <nl>  <nl> ext { <nl> gh_repository = " mockito / mockito " <nl> + <nl> gh_user = " szczepiq " <nl> gh_readonlyauthtoken = " <commit_id> "
ext { <nl>  <nl> git_genericuser = " mockito release tools " <nl> git_genericemail = " < mockito . release . tools @ gmail . com > " <nl> - git_releasablebranchregex = " master | release / . + " / / matches ' master ' , ' release / 2 . x ' , ' release / 3 . x ' , etc . <nl> + <nl> + <nl> + git_releasablebranchregex = " release / . + " / / ' release / 2 . x ' , ' release / 3 . x ' , etc . <nl>  <nl> pom_developers = [ ' szczepiq : szczepan faber ' , ' bric3 : brice dutheil ' , ' raphw : rafael winterhalter ' , ' timvdlippe : tim van der lippe ' ] <nl> pom_contributors = [ ]
public class strictstubbinge2etest { <nl> junitresultassert . assertthat ( result ) . succeeds ( 5 ) ; <nl> } <nl>  <nl> + @ test public void detects_unfinished_mocking ( ) { <nl> + result result = junit . run ( unfinishedmocking . class ) ; <nl> + junitresultassert . assertthat ( result ) . fails ( 1 , unfinishedmockingexception . class ) ; <nl> + <nl> + } <nl> + <nl> public static class argumentmismatch { <nl> @ mock imethods mock ; <nl> mockitomocking mocking = mockito . startmocking ( this , strictness . strict_stubs ) ; <nl>
import java . util . list ; <nl> public class mismatchreportingtestlistener implements mockitotestlistener { <nl>  <nl> private final mockitologger logger ; <nl> - private final list < object > mocks = new linkedlist < object > ( ) ; <nl> + private list < object > mocks = new linkedlist < object > ( ) ; <nl>  <nl> public mismatchreportingtestlistener ( mockitologger logger ) { <nl> this . logger = logger ; <nl> } <nl>  <nl> public void testfinished ( testfinishedevent event ) { <nl> + collection < object > createdmocks = mocks ; <nl> + / / at this point , we don ' t need the mocks any more and we can mark all collected mocks for gc <nl> + <nl> + mocks = new linkedlist < object > ( ) ; <nl> + <nl> string testname = testname . gettestname ( event ) ; <nl> if ( event . getfailure ( ) ! = null ) { <nl> / / print unused stubbings only when test succeeds to avoid reporting multiple problems and confusing users <nl> - new argmismatchfinder ( ) . getstubbingargmismatches ( mocks ) . format ( testname , logger ) ; <nl> + new argmismatchfinder ( ) . getstubbingargmismatches ( createdmocks ) . format ( testname , logger ) ; <nl> } <nl> } <nl>  <nl> mmm a / src / main / java / org / mockito / internal / junit / universaltestlistener . java <nl> ppp b / src / main / java / org / mockito / internal / junit / universaltestlistener . java <nl>
class universaltestlistener implements mockitotestlistener { <nl> this . logger = logger ; <nl>  <nl> / / creating single stubbing lookup listener per junit rule instance / test method <nl> + / / this way , when strictness is updated in the middle of the test it will affect the behavior of the stubbing listener <nl> this . stubbinglookuplistener = new defaultstubbinglookuplistener ( currentstrictness ) ; <nl> } <nl>  <nl> @ override <nl> public void testfinished ( testfinishedevent event ) { <nl> + collection < object > createdmocks = mocks . keyset ( ) ; <nl> + / / at this point , we don ' t need the mocks any more and we can mark all collected mocks for gc <nl> + <nl> + mocks = new identityhashmap < object , mockcreationsettings > ( ) ; <nl> + <nl> switch ( currentstrictness ) { <nl> - case warn : emitwarnings ( logger , event , mocks . keyset ( ) ) ; break ; <nl> - case strict_stubs : reportunusedstubs ( event , mocks . keyset ( ) ) ; break ; <nl> + case warn : emitwarnings ( logger , event , createdmocks ) ; break ; <nl> + case strict_stubs : reportunusedstubs ( event , createdmocks ) ; break ; <nl> case lenient : break ; <nl> default : throw new illegalstateexception ( " unknown strictness : " + currentstrictness ) ; <nl> } <nl>
allprojects { <nl> tasks . matching { it . name = = ' bintrayupload ' } . all { <nl> bintrayuploadall . dependson it <nl> dependson printreleasehelp <nl> + <nl> + <nl> + dependson releaseneeded <nl> + onlyif { releaseneeded . needed } <nl> + / / end <nl> + <nl> dofirst { <nl> it . dryrun = releasetest <nl> if ( it . dryrun ) {
public class mockhandlerimpl < t > implements internalmockhandler < t > { <nl> } <nl>  <nl> private void notifystubbedanswerlookup ( invocation invocation , stubbedinvocationmatcher exception ) { <nl> - for ( stubbinglookuplistener listener : mocksettings . getstubbinglookuplisteners ( ) ) { <nl> + <nl> + list < stubbinglookuplistener > listeners = ( ( creationsettings ) mocksettings ) . getstubbinglookuplisteners ( ) ; <nl> + for ( stubbinglookuplistener listener : listeners ) { <nl> listener . onstubbinglookup ( invocation , exception ) ; <nl> } <nl> } <nl> mmm a / src / main / java / org / mockito / internal / junit / strictstubstestlistener . java <nl> ppp b / src / main / java / org / mockito / internal / junit / strictstubstestlistener . java <nl>
class strictstubstestlistener implements mockitotestlistener , mockcreationlisten <nl> / / it is not ideal that we modify the state of mockcreationsettings object <nl> / / mockcreationsettings is intended to be an immutable view of the creation settings <nl> / / in future , we should start passing mocksettings object to the creation listener <nl> - settings . getstubbinglookuplisteners ( ) . add ( new stubbinglookuplistener ( ) { <nl> + <nl> + ( ( creationsettings ) settings ) . getstubbinglookuplisteners ( ) . add ( new stubbinglookuplistener ( ) { <nl> public void onstubbinglookup ( invocation invocation , matchableinvocation stubbingfound ) { <nl> if ( stubbingfound = = null ) { <nl> / / if stubbing was not found for invocation it means that either the mock invocation was not stubbed or <nl> mmm a / src / main / java / org / mockito / mock / mockcreationsettings . java <nl> ppp b / src / main / java / org / mockito / mock / mockcreationsettings . java <nl>
public interface stubbinglookuplistener { <nl> / * * <nl> * called by the framework when mockito looked up an answer for invocation on a mock . <nl> * <nl> + * <nl> + * <nl> * @ param invocation the invocation on the mock <nl> * @ param stubbingfound - can be null - it indicates that the invocation was not stubbed . <nl> * / <nl> mmm a / src / test / java / org / mockitoutil / safejunitrule . java <nl> ppp b / src / test / java / org / mockitoutil / safejunitrule . java <nl>
import org . junit . runners . model . statement ; <nl> / * * <nl> * junit rule for testing exception handling other junit rules , like mockito junit rules . <nl> * makes it easy to assert on expected exceptions triggered by the rule under test . <nl> + * <nl> + * <nl> * / <nl> public class safejunitrule implements methodrule {
<nl> + dependencies { <nl> + / / needed by javadocexclude <nl> + <nl> + compile files ( " $ { system . properties [ ' java . home ' ] } / . . / lib / tools . jar " ) <nl> + } <nl> \ no newline at end of file <nl> mmm / dev / null <nl> ppp b / buildsrc / src / main / java / org / mockito / javadoc / javadocexclude . java <nl>
public class releaseworkflowplugin implements plugin < project > { <nl> } <nl> } <nl> } ) ; <nl> - } <nl>  <nl> + <nl> + gittool gittool = git . gittool ( exec . getprocessrunner ( project . getprojectdir ( ) ) ) ; <nl> + project . getextensions ( ) . getextraproperties ( ) . set ( " gittool " , gittool ) ; <nl> + } <nl> } <nl> mmm a / buildsrc / src / test / groovy / org / mockito / workflow / gradle / internal / releaseworkflowplugintest . groovy <nl> ppp b / buildsrc / src / test / groovy / org / mockito / workflow / gradle / internal / releaseworkflowplugintest . groovy <nl>
task ( " comparepublications " , type : org . mockito . release . comparison . publicationscom <nl> comparepoms ( { configurations . previouspom . singlefile . text } , { generatepomfileformockitocorepublication . destination . text } ) <nl> } <nl>  <nl> + <nl> + <nl> / * <nl> release process should * not * run concurrently . <nl> * / <nl>
maskedarg pushtarget = new maskedarg ( value : " https : / / szczepiq : $ { system . env . gh_to <nl>  <nl> task assertcleanworkingcopy { <nl> dolast { <nl> + <nl> string output = run " git " , " status " , " - - porcelain " <nl> assert output . trim ( ) . isempty ( ) : " working copy not clean . commit or stash your changes before continuing . \n $ output " <nl> }
public class releaseworkflowextension implements releaseworkflow { <nl> } <nl> previousstep = task ; <nl>  <nl> - if ( rollback = = null ) { <nl> - return ; <nl> + if ( config . isempty ( ) ) { <nl> + return ; / / no rollback / cleanup configured <nl> + } <nl> + <nl> + <nl> + task rollback = config . get ( " rollback " ) ; <nl> + if ( rollback ! = null ) { <nl> + / / rollbacks only run when one of the steps fails , by default we assume they don ' t fail <nl> + if ( ! project . hasproperty ( " dryrun " ) ) { / / accommodate testing <nl> + rollback . setenabled ( false ) ; <nl> + } <nl> + } else { <nl> + rollback = config . get ( " cleanup " ) ; <nl> + / / cleanups run even if the release is successful <nl> } <nl>  <nl> / / populate main rollbacks list <nl>
configurations { <nl> } <nl>  <nl> dependencies { <nl> + <nl> previoussrc " org . mockito : mockito - core : $ { project . notes . getpreviousversion ( ) } : sources @ jar " <nl> previouspom " org . mockito : mockito - core : $ { project . notes . getpreviousversion ( ) } @ pom " <nl> }
releasesteps { <nl> . rollback { run " git " , " tag " , " - d " , " v $ { currentversion } " . tostring ( ) } <nl>  <nl> step ( " commit incremented version on $ system . env . travis_branch " ) { commitincrementedversion ( currentversion , buildinfo , project . versionfile ) } <nl> + <nl> . rollback { run " git " , " reset " , " - - hard " , " head ~ 1 " } <nl>  <nl> step ( " push changes to all involved branches " ) {
<nl> package org . mockito . release . notes . improvements <nl>  <nl> - import spock . lang . ignoreif <nl> + import spock . lang . ignore <nl> import spock . lang . specification <nl> import spock . lang . subject <nl> - import testutil . offlinechecker <nl>  <nl> - @ ignoreif ( { offlinechecker . isoffline ( ) } ) <nl> + <nl> + @ ignore <nl> class githubticketfetchertest extends specification { <nl>  <nl> @ subject fetcher = new githubticketfetcher ( )
public class internaljunitrunner implements runnerimpl { <nl> / / 1 . if all tests from given test have ran <nl> / / otherwise we would report unnecessary stubs even if the user runs just single test from the class <nl> / / 2 . tests are successful ( we don ' t want to add an extra failure on top of any existing failure , to avoid confusion ) <nl> + <nl> reporter . report ( testclass , notifier ) ; <nl> } <nl> }
import static org . mockito . internal . progress . threadsafemockingprogress . mockingpro <nl> / * * <nl> * new incubating api , mainly for other tools that integrate with mockito . <nl> * <nl> + * <nl> + * <nl> * @ since num . 0 . 0 <nl> * / <nl> @ incubating
import static org . junit . assert . fail ; <nl> import static org . mockito . matchers . eq ; <nl> import static org . mockito . mockito . when ; <nl>  <nl> - @ runwith ( mockitojunitrunner . class ) <nl> + <nl> public class invaliduseofmatcherstest { <nl>  <nl> - @ mock private imethods mock ; <nl> + private imethods mock = mockito . mock ( imethods . class ) ; <nl>  <nl> @ test <nl> public void should_detect_wrong_number_of_matchers_when_stubbing ( ) {
class interceptedinvocation implements invocation , verificationawareinvocation { <nl>  <nl> @ override <nl> public int hashcode ( ) { <nl> + <nl> return num ; <nl> }
public class internaljunitrunner implements runnerimpl { <nl> / / 1 . if all tests from given test have ran <nl> / / otherwise we would report unnecessary stubs even if the user runs just single test from the class <nl> / / 2 . tests are successful ( we don ' t want to add an extra failure on top of any existing failure , to avoid confusion ) <nl> + <nl> reporter . report ( testclass , notifier ) ; <nl> } <nl> }
import org . mockito . listeners . stubbinglistener ; <nl> / * * <nl> * new incubating api , mainly for other tools that integrate with mockito . <nl> * <nl> + * <nl> + * <nl> * @ since num . 0 . 0 <nl> * / <nl> @ incubating
import static org . junit . assert . fail ; <nl> import static org . mockito . matchers . eq ; <nl> import static org . mockito . mockito . when ; <nl>  <nl> - @ runwith ( mockitojunitrunner . class ) <nl> + <nl> public class invaliduseofmatcherstest { <nl>  <nl> - @ mock private imethods mock ; <nl> + private imethods mock = mockito . mock ( imethods . class ) ; <nl>  <nl> @ test <nl> public void should_detect_wrong_number_of_matchers_when_stubbing ( ) {
class interceptedinvocation implements invocation , verificationawareinvocation { <nl>  <nl> @ override <nl> public int hashcode ( ) { <nl> + <nl> return num ; <nl> }
<nl>  <nl> package org . mockito . internal . util ; <nl>  <nl> + import static java . util . arrays . aslist ; <nl> + <nl> + / * * <nl> + * joins strings together producing yet another string <nl> + * / <nl> public class stringjoiner { <nl>  <nl> + <nl> + <nl> + / * * <nl> + * joins strings with eol character <nl> + * / <nl> public static string join ( object . . . linestobreak ) { <nl> - stringbuilder out = new stringbuilder ( " \n " ) ; <nl> - return join ( out , linestobreak ) ; <nl> + return join ( aslist ( linestobreak ) ) ; <nl> } <nl>  <nl> - private static string join ( stringbuilder out , object [ ] linestobreak ) { <nl> - for ( object line : linestobreak ) { <nl> + / * * <nl> + * joins strings with eol character <nl> + * / <nl> + public static string join ( iterable < string > lines ) { <nl> + stringbuilder out = new stringbuilder ( " \n " ) ; <nl> + for ( object line : lines ) { <nl> out . append ( line . tostring ( ) ) . append ( " \n " ) ; <nl> } <nl> int lastbreak = out . lastindexof ( " \n " ) ;
<nl> apply plugin : ' jacoco ' <nl>  <nl> + <nl> + <nl> + jacoco { <nl> + toolversion = " 0 . 7 . 6 . 201602180812 " <nl> + } <nl> + <nl> task mockitocoverage ( type : jacocoreport , dependson : " test " ) { <nl> executiondata files ( " $ { builddir } / jacoco / test . exec " )
<nl> + # # # num . 0 . 32 - beta ( 2015 - 12 - 17 num : 50 utc ) <nl> + <nl> + * authors : num <nl> + * commits : num <nl> + * num : szczepan faber <nl> + * num : brice dutheil <nl> + * num : rafael winterhalter <nl> + * num : tim van der lippe <nl> + * num : carlos aguayo <nl> + * num : ariel - isaacm <nl> + * num : marcin zajaczkowski <nl> + * num : bartosz miller <nl> + * num : shaun abram <nl> + * num : lukasz szewc <nl> + * num : fluentfuture <nl> + * num : scott markwell <nl> + * num : tom ball <nl> + * num : michal kordas <nl> + * num : christian persson <nl> + * num : tim van der lippe <nl> + * improvements : num <nl> + * add shouldhavenomoreinteractions ( ) to bddmockito [ ( # 314 ) ] ( https : / / github . com / mockito / mockito / pull / 314 ) <nl> + * minor formatting , typo and clarification fixes in readme [ ( # 313 ) ] ( https : / / github . com / mockito / mockito / pull / 313 ) <nl> + * add bdd version of verifynomoreinteractions ( ) [ ( # 311 ) ] ( https : / / github . com / mockito / mockito / issues / 311 ) <nl> + * tweaks to the main mockito javadocs to aid readability [ ( # 309 ) ] ( https : / / github . com / mockito / mockito / pull / 309 ) <nl> + * eliminate direct dependency on objenesisinstantiator [ ( # 306 ) ] ( https : / / github . com / mockito / mockito / pull / 306 ) <nl> + * refactor some utilities and <nl> + * update stackoverflow link to mockito tag [ ( # 296 ) ] ( https : / / github . com / mockito / mockito / pull / 296 ) <nl> + * removed deprecated returnvalues and all it ' s occurrences [ ( # 294 ) ] ( https : / / github . com / mockito / mockito / pull / 294 ) <nl> + * remove validateserializable ( ) [ ( # 293 ) ] ( https : / / github . com / mockito / mockito / pull / 293 ) <nl> + * implement verificationcollector which can collect multiple verifications . [ ( # 287 ) ] ( https : / / github . com / mockito / mockito / pull / 287 ) <nl> + * add new api method to reset invocations of a mock , while maintaining all existing stubbing [ ( # 286 ) ] ( https : / / github . com / mockito / mockito / pull / 286 ) <nl> + * correcting public website url in maven pom [ ( # 281 ) ] ( https : / / github . com / mockito / mockito / pull / 281 ) <nl> + * reintroduce null check on mockutil . ismock ( ) [ ( # 280 ) ] ( https : / / github . com / mockito / mockito / pull / 280 ) <nl> + * get rid of returnvalues [ ( # 273 ) ] ( https : / / github . com / mockito / mockito / issues / 273 ) <nl> + * issue # 268 : added support for generic arrays as return types . [ ( # 270 ) ] ( https : / / github . com / mockito / mockito / pull / 270 ) <nl> + * return_deep_stubs and toarray ( t [ ] ) stops working with versions > num . 9 . 5 [ ( # 268 ) ] ( https : / / github . com / mockito / mockito / issues / 268 ) <nl> + * ignore groovy meta methods when instrumenting . [ ( # 266 ) ] ( https : / / github . com / mockito / mockito / pull / 266 ) <nl> + * fix typo in docs , missing breaklines . [ ( # 264 ) ] ( https : / / github . com / mockito / mockito / pull / 264 ) <nl> + * fixes # 260 : typo in documentation [ ( # 261 ) ] ( https : / / github . com / mockito / mockito / pull / 261 ) <nl> + * typo in documentation [ ( # 260 ) ] ( https : / / github . com / mockito / mockito / issues / 260 ) <nl> + * minify the js file [ ( # 258 ) ] ( https : / / github . com / mockito / mockito / pull / 258 ) <nl> + * upgraded to byte buddy num . 6 . 12 . [ ( # 257 ) ] ( https : / / github . com / mockito / mockito / pull / 257 ) <nl> + * [ # 251 ] migrate fest assert code to assertj [ ( # 252 ) ] ( https : / / github . com / mockito / mockito / pull / 252 ) <nl> + * unit tests improvements : migrate from legacy fest assert code to assertj [ ( # 251 ) ] ( https : / / github . com / mockito / mockito / issues / 251 ) <nl> + * no jars in source code [ ( # 250 ) ] ( https : / / github . com / mockito / mockito / issues / 250 ) <nl> + * use gradle built - in osgi plugin [ ( # 249 ) ] ( https : / / github . com / mockito / mockito / issues / 249 ) <nl> + * push cglib into a separate jar [ ( # 248 ) ] ( https : / / github . com / mockito / mockito / issues / 248 ) <nl> + * serializable check is too harsh [ ( # 245 ) ] ( https : / / github . com / mockito / mockito / issues / 245 ) <nl> + * mockutil . ismock ( ) no longer checks null [ ( # 243 ) ] ( https : / / github . com / mockito / mockito / issues / 243 ) <nl> + * rework stubbing api with consecutive vararg to avoid jdk7 + warnings [ ( # 239 ) ] ( https : / / github . com / mockito / mockito / pull / 239 ) <nl> + * deep stubbing with generic responses in the call chain is not working [ ( # 128 ) ] ( https : / / github . com / mockito / mockito / issues / 128 ) <nl> + * concise way to collect multiple verify failures , ideally with junitcollector or derivative [ ( # 124 ) ] ( https : / / github . com / mockito / mockito / issues / 124 ) <nl> + <nl> # # # num . 0 . 26 - beta ( 2015 - 06 - 30 num : 20 utc ) <nl>  <nl> * authors : num
task mockitojavadoc ( type : javadoc ) { <nl>  <nl> dolast { <nl> copy { <nl> + <nl> from " javadoc " <nl> into " $ builddir / javadoc " <nl> }
public class bytebuddymockmaker implements mockmaker { <nl>  <nl> @ override <nl> public string nonmockablereason ( ) { <nl> + <nl> if ( type . isprimitive ( ) ) { <nl> return " primitive type " ; <nl> }
import java . util . list ; <nl> * inspired on jmock ( thanks jmock guys ! ! ! ) <nl> * / <nl> public class searchingclassloader extends classloader { <nl> + <nl> + <nl> + <nl> private final classloader nexttosearch ; <nl>  <nl> public searchingclassloader ( classloader parent , classloader nexttosearch ) { <nl> mmm a / src / org / mockito / plugins / mockmaker . java <nl> ppp b / src / org / mockito / plugins / mockmaker . java <nl>
<nl> + package org . mockito . hamcrest ; <nl> + <nl> + import org . hamcrest . matcher ; <nl> + import org . mockito . internal . hamcrest . hamcrestargumentmatcher ; <nl> + import org . mockito . internal . progress . mockingprogress ; <nl> + import org . mockito . internal . progress . threadsafemockingprogress ; <nl> + <nl> + / * * <nl> + * <nl> + * / <nl> + public class mockitohamcrest { <nl> + <nl> + private static final mockingprogress mocking_progress = new threadsafemockingprogress ( ) ; <nl> + <nl> + / * * <nl> + * allows matching arguments with hamcrest matchers . <nl> + * < p > <nl> + * in rare cases when the parameter is a primitive then you < b > * must * < / b > use relevant intthat ( ) , floatthat ( ) , etc . method . <nl> + * this way you will avoid < code > nullpointerexception < / code > during auto - unboxing . <nl> + * < p > <nl> + * see examples in javadoc for { @ link mockitohamcrest } class <nl> + * <nl> + * @ param matcher decides whether argument matches <nl> + * <nl> + * @ return < code > null < / code > . <nl> + * / <nl> + public static < t > t argthat ( matcher < t > matcher ) { <nl> + return ( t ) mocking_progress . getargumentmatcherstorage ( ) <nl> + . reportmatcher ( new hamcrestargumentmatcher ( matcher ) ) <nl> + . returnnull ( ) ; <nl> + } <nl> + <nl> + / * <nl> + private static class grabclass ( matcher matcher ) { <nl> + if ( matcher . getclass ( ) . getgenericsuperclass ( ) instanceof parameterizedtype ) { <nl> + type [ ] generictypes = ( ( parameterizedtype ) matcher . getclass ( ) . getgenericsuperclass ( ) ) . getactualtypearguments ( ) ; <nl> + if ( generictypes . length > num ) { <nl> + return ( class ) generictypes [ 0 ] ; <nl> + } <nl> + } <nl> + return object . class ; <nl> + } <nl> + * / <nl> + } <nl> mmm / dev / null <nl> ppp b / src / org / mockito / internal / hamcrest / hamcrestargumentmatcher . java <nl>
<nl> + package org . mockito . internal . hamcrest ; <nl> + <nl> + import org . hamcrest . matcher ; <nl> + import org . hamcrest . stringdescription ; <nl> + import org . mockito . mockitomatcher ; <nl> + <nl> + / * * <nl> + * created by sfaber on num / 22 / 15 . <nl> + * / <nl> + public class hamcrestargumentmatcher < t > implements mockitomatcher < t > { <nl> + <nl> + private final matcher matcher ; <nl> + <nl> + public < t > hamcrestargumentmatcher ( matcher < t > matcher ) { <nl> + this . matcher = matcher ; <nl> + } <nl> + <nl> + public boolean matches ( object argument ) { <nl> + return this . matcher . matches ( argument ) ; <nl> + } <nl> + <nl> + public string tostring ( ) { <nl> + <nl> + stringdescription s = new stringdescription ( ) ; <nl> + this . matcher . describeto ( s ) ; <nl> + return s . tostring ( ) ; <nl> + } <nl> + } <nl> \ no newline at end of file <nl> mmm a / test / org / mockitousage / matchers / hamcrestmatcherstest . java <nl> ppp b / test / org / mockitousage / matchers / hamcrestmatcherstest . java <nl>
public class matchersprintertest extends testbase { <nl> assertequals ( " ( 1 , ( integer ) num ) ; " , line ) ; <nl> } <nl>  <nl> + @ test <nl> + public void shoulddescribestringmatcher ( ) { <nl> + / / when <nl> + string line = printer . getargumentsline ( ( list ) arrays . aslist ( new equals ( 1l ) , new equals ( " x " ) ) , printsettings . verbosematchers ( 1 ) ) ; <nl> + / / then <nl> + assertequals ( " ( 1 , \ " ( string ) x \ " ) ; " , line ) ; <nl> + } <nl> + <nl> @ test <nl> public void shouldgetverboseargumentsinblock ( ) { <nl> / / when
dependencies { <nl> testcompile project ( path : ' : ' , configuration : ' testutil ' ) <nl>  <nl> testcompile ( " junit : junit : 4 . 12 " ) <nl> + } <nl> + <nl> + configurations . all { <nl> + <nl> + / / exclude group : ' org . hamcrest ' , module : ' hamcrest - core ' <nl> } <nl> \ no newline at end of file
<nl> + pick num bab8bf in progress of decoupling mockito from hamcrest <nl> + pick num daa963 removed commented out code <nl> + pick a813d42 deprecated the current argumentmatcher <nl> + pick f2b3655 made the current api delegate to the new api <nl> + pick ed20c0e added a <nl> \ no newline at end of file <nl> mmm a / doc / notes . txt <nl> ppp / dev / null <nl>
notes { <nl> } <nl>  <nl> def dryrun = project . hasproperty ( ' dryrun ' ) <nl> + if ( dryrun ) { <nl> + <nl> + logger . lifecycle " automatically scheduling ' rollbackrelease ' task " <nl> + rollbackrelease . dependson release <nl> + gradle . startparameter . tasknames + = " rollbackrelease " <nl> + } <nl>  <nl> configurations { <nl> previoussrc
class defaultreleasesteps implements releasesteps { <nl> linkedlist < releasestep > targets = new linkedlist < releasestep > ( attempted ) ; <nl> while ( ! targets . isempty ( ) ) { <nl> releasestep s = targets . removelast ( ) ; <nl> - operation r = s . getrollback ( ) ; <nl> - operation c = s . getcleanup ( ) ; <nl> - if ( r ! = null ) { <nl> - system . out . println ( " rolling back step " + ( targets . size ( ) + num ) + " ( " + s . getdescription ( ) + " ) " ) ; <nl> - r . perform ( ) ; <nl> - } else if ( c ! = null ) { <nl> - system . out . println ( " cleaning up after step " + ( targets . size ( ) + num ) + " ( " + s . getdescription ( ) + " ) " ) ; <nl> - c . perform ( ) ; <nl> - } else { <nl> - system . out . println ( " no rollback for step " + ( targets . size ( ) + num ) + " ( " + s . getdescription ( ) + " ) " ) ; <nl> - } <nl> + <nl> + system . out . println ( " attempting to roll back step " + ( targets . size ( ) + num ) + " ( " + s . getdescription ( ) + " ) " ) ; <nl> + s . performrollback ( ) ; <nl> } <nl> } <nl> } <nl> \ no newline at end of file <nl> mmm a / buildsrc / src / main / groovy / org / mockito / release / steps / releasestep . java <nl> ppp b / buildsrc / src / main / groovy / org / mockito / release / steps / releasestep . java <nl>
<nl> + package org . mockito . release . steps ; <nl> + <nl> + import groovy . lang . closure ; <nl> + <nl> + public interface configurablereleasestep extends releasestep { <nl> + <nl> + void rollback ( closure closure ) ; <nl> + } <nl> mmm a / buildsrc / src / main / groovy / org / mockito / release / steps / defaultreleasestep . java <nl> ppp b / buildsrc / src / main / groovy / org / mockito / release / steps / defaultreleasestep . java <nl>
class friendlyexceptionmaker { <nl> this . detecter = detecter ; <nl> } <nl>  <nl> + <nl> public assertionerror createargumentsaredifferentexception ( string message , string wanted , string actual ) { <nl> if ( ! detecter . hasjunit ( ) ) { <nl> return new argumentsaredifferent ( message ) ;
task ( " release " , type : org . mockito . release . gradle . releasetask ) { <nl> } <nl> } <nl>  <nl> + / * <nl> + <nl> + - declare release steps and then gradle plugin adds tasks : <nl> + release , rollbackrelease , releasestep1 , rollbackstep2 , releasesteps1 . . 7 <nl> + - improve exception reporting <nl> + * / <nl> + <nl> private void commitreleasenotes ( string buildinfo , string author ) { <nl> def notesfile = project . file ( " doc / release - notes / official . md " ) <nl> run " git " , " add " , " $ notesfile " as string
<nl> + / * <nl> + * copyright ( c ) num mockito contributors <nl> + * this program is made available under the terms of the mit license . <nl> + * / <nl> + <nl> + package org . mockitousage . plugins . switcher ; <nl> + <nl> + import org . junit . test ; <nl> + import org . mockitousage . plugins . stacktrace . mystacktracecleanerprovider ; <nl> + <nl> + import static java . util . arrays . aslist ; <nl> + import static org . junit . assert . assertequals ; <nl> + <nl> + <nl> + public class pluginswitchertest { <nl> + <nl> + @ test <nl> + public void plugin_switcher_is_used ( ) { <nl> + assertequals ( mypluginswitcher . invokedfor , aslist ( mystacktracecleanerprovider . class ) ) ; <nl> + } <nl> + } <nl> mmm / dev / null <nl> ppp b / subprojects / exttest / src / test / resources / mockito - extensions / org . mockito . plugins . pluginswitcher <nl>
public class mockingdetailstest { <nl> } <nl> } <nl> } <nl> + <nl> + @ test <nl> + public void should_handle_null_input ( ) { <nl> + <nl> + } <nl> }
public class spyannotationengine implements annotationengine { <nl> + " \nif you are mocking an inner class please ensure the instance of the outer class is supplied via withsettings ( ) . outerinstance ( ) " <nl> + " \nthe outer class is : ' " + enclosing . getsimplename ( ) + " ' " ) ; <nl> } <nl> - if ( modifier . isprivate ( type . getdeclaredconstructor ( enclosing ) . getmodifiers ( ) ) ) { <nl> - throw new mockitoexception ( " cannot spy inner " + type + " with private constructor " ) ; <nl> - } <nl> + <nl> + / / throw new assertionerror ( ) ; <nl> + / / throw new mockitoexception ( " unable to initialize @ spy annotated field ' " + field . getname ( ) + " ' . " <nl> + / / + " cannot spy inner type ' " + type . getsimplename ( ) + " ' because it has private constructor . " ) ; <nl> + / / } <nl> return mockito . mock ( type , settings <nl> . useconstructor ( ) <nl> . outerinstance ( testinstance ) ) ; <nl> mmm a / src / org / mockito / internal / util / mockutil . java <nl> ppp b / src / org / mockito / internal / util / mockutil . java <nl>
public class mockutil { <nl> } <nl>  <nl> public boolean isspy ( object mock ) { <nl> + <nl> return ismockitomock ( mock ) & & <nl> ( getmocksettings ( mock ) . getspiedinstance ( ) ! = null <nl> | | getmocksettings ( mock ) . isusingconstructor ( ) ) ; <nl> mmm a / test / org / mockitousage / annotation / spyannotationtest . java <nl> ppp b / test / org / mockitousage / annotation / spyannotationtest . java <nl>
public class spyannotationtest extends testbase { <nl> withspy withspy = new withspy ( ) ; <nl> mockitoannotations . initmocks ( withspy ) ; <nl> assertequals ( 0 , withspy . list . size ( ) ) ; <nl> + <nl> } <nl>  <nl> @ test
repositories { jcenter ( ) } <nl>  <nl> dependencies { <nl> compile gradleapi ( ) <nl> - compile " com . jcabi : jcabi - github : 0 . 17 " <nl> + <nl> compile " com . googlecode . json - simple : json - simple : 1 . 1 . 1 @ jar " <nl> testcompile ( " org . spockframework : spock - core : 0 . 7 - groovy - 1 . 8 " ) { <nl> exclude module : " groovy - all " <nl> mmm a / buildsrc / src / main / groovy / org / mockito / release / notes / improvements / githubticketfetcher . java <nl> ppp b / buildsrc / src / main / groovy / org / mockito / release / notes / improvements / githubticketfetcher . java <nl>
<nl> + package org . mockito . release . notes ; <nl> + <nl> + import java . util . linkedlist ; <nl> + import java . util . list ; <nl> + <nl> + / * * <nl> + * contribution of given author <nl> + * / <nl> + class contribution { <nl> + string email ; / / identifies the contributor <nl> + string author ; <nl> + list < gitcommit > commits = new linkedlist < gitcommit > ( ) ; <nl> + <nl> + void add ( gitcommit commit ) { <nl> + if ( email = = null ) { <nl> + email = commit . email ; <nl> + author = commit . author ; <nl> + <nl> + } <nl> + / / email identifies the contributor , author alias not necessarily <nl> + assert email . equals ( commit . email ) ; <nl> + commits . add ( commit ) ; <nl> + } <nl> + <nl> + public string tostring ( ) { <nl> + return author + " : " + commits . size ( ) ; <nl> + } <nl> + } <nl> mmm a / buildsrc / src / main / groovy / org / mockito / release / notes / gitcommit . groovy <nl> ppp / dev / null <nl>
public class mocksettingsimpl < t > extends creationsettings < t > implements mocksett <nl> / / validator . validatedelegatedinstance ( classtomock , settings . getdelegatedinstance ( ) ) ; <nl>  <nl> validator . validateserializable ( typetomock , source . isserializable ( ) ) ; <nl> + validator . validateconstructoruse ( source . isusingconstructor ( ) , source . getserializablemode ( ) ) ; <nl>  <nl> + <nl> creationsettings < t > settings = new creationsettings < t > ( source ) ; <nl> settings . setmockname ( new mocknameimpl ( source . getname ( ) , typetomock ) ) ; <nl> settings . settypetomock ( typetomock ) ; <nl> mmm a / src / org / mockito / internal / util / mockcreationvalidator . java <nl> ppp b / src / org / mockito / internal / util / mockcreationvalidator . java <nl>
public abstract class basestubbing < t > implements ongoingstubbing < t > , deprecatedo <nl> public ongoingstubbing < t > thenreturn ( t value , t . . . values ) { <nl> ongoingstubbing < t > stubbing = thenreturn ( value ) ; <nl> if ( values = = null ) { <nl> + <nl> return stubbing . thenreturn ( null ) ; <nl> } <nl> for ( t v : values ) {
import java . util . set ; <nl> import java . util . zip . zipentry ; <nl> import java . util . zip . zipfile ; <nl>  <nl> + <nl> class zipcompare { <nl>  <nl> boolean comparezips ( string filepath1 , string filepath2 ) {
<nl> + package org . mockito . release . comparison <nl> + <nl> + import spock . lang . specification <nl> + <nl> + class sourcejarcomparatortest extends specification { <nl> + <nl> + <nl> + }
class defaultreleasenotesbuilder implements releasenotesbuilder { <nl> void updatenotes ( file notesfile , string toversion ) { <nl> println " updating release notes file : $ notesfile " <nl> def currentcontent = notesfile . text <nl> - def previousversion = " v " + new previousversionfromfile ( notesfile ) . getpreviousversion ( ) <nl> + def previousversion = " v " + new previousversionfromfile ( notesfile ) . getpreviousversion ( ) <nl> println " fetching $ previousversion " <nl> project . exec { commandline " git " , " fetch " , " origin " , " + refs / tags / $ previousversion : refs / tags / $ previousversion " } <nl> println " building notes since $ previousversion until $ toversion " <nl> mmm a / buildsrc / src / main / groovy / org / mockito / release / notes / internal / previousversionfromfile . groovy <nl> ppp b / buildsrc / src / main / groovy / org / mockito / release / notes / internal / previousversionfromfile . groovy <nl>
class previousversionfromfile implements previousversionprovider { <nl> this . releasenotes = releasenotes <nl> } <nl>  <nl> - string getpreviousversion ( ) { <nl> + string getpreviousversion ( ) { <nl> println " attempting to figure out the previous version from the release notes file " <nl> return releasenotes . withreader { <nl> def firstline = it . readline ( )
<nl> * / <nl> package org . mockito . internal . creation . cglib ; <nl>  <nl> + <nl> public interface mockitomethodproxy { <nl> object invokesuper ( object target , object [ ] arguments ) throws throwable ; <nl> } <nl> \ no newline at end of file <nl> mmm a / src / org / mockito / internal / invocation / realmethod / realmethod . java <nl> ppp b / src / org / mockito / internal / invocation / realmethod / realmethod . java <nl>
void run ( collection args ) { <nl> class maskedarg { <nl> string value <nl> string tostring ( ) { " < masked > " } <nl> - } <nl> \ no newline at end of file <nl> + } <nl> + <nl> + / * <nl> + <nl> + - no new version publication if all binaries the same <nl> + - release process performs dry run first , if it is successful it makes the actual release <nl> + - steps are better described and log stuff verbosely only in case of failure <nl> + - steps can be rolled back : <nl> + - configure git user back to the original <nl> + - tag removal <nl> + - new commits removal ( git reset - - hard ) on all affected branches <nl> + - clean up after release : <nl> + - configure git user back to the original <nl> + * / <nl> \ no newline at end of file
in case the release process from travis ci fails , please try : <nl> assert project = = rootproject <nl>  <nl> apply from : rootproject . file ( " gradle / publish . gradle " ) <nl> - / / apply from : rootproject . file ( " gradle / release - notes . gradle " ) <nl> + apply from : rootproject . file ( " gradle / release - notes . gradle " ) <nl>  <nl> + <nl> task ( release ) { <nl> onlyif { <nl> def branch = system . env . travis_branch <nl>
task javadocjar ( type : jar ) { <nl> from mockitojavadoc <nl> } <nl>  <nl> + <nl> task alljar ( type : jar ) { <nl> basename = ' mockito - all ' <nl>  <nl> mmm a / gradle / release . gradle <nl> ppp b / gradle / release . gradle <nl>
task ( release ) { <nl> maskedarg pushtarget = new maskedarg ( value : " https : / / szczepiq : $ { system . env . gh_token } @ github . com / mockito / mockito . git " ) <nl>  <nl> / / release process . should * not * run concurrently . <nl> + <nl> run " . / gradlew " , " bintrayupload " <nl> configuregit ( ) <nl> run " git " , " pull " , " - - depth " , " 500 " / / we need good chunk of recent commits to build release notes correctly
apply plugin : ' java ' <nl> apply plugin : ' maven ' <nl> description = " mockito for testng " <nl>  <nl> + <nl> + <nl> properties props = new properties ( ) <nl> props . load ( new fileinputstream ( rootproject . file ( " version . properties " ) ) )
task ( release ) { <nl> private void updatereleasenotes ( ) { <nl> / / release - notes . gradle script plugin immediately updates the notes when it is applied <nl> / / i needed to implement it this way to avoid some weird classloader issues <nl> - / / this problem should go away once we stop using jcabi <nl> + <nl> project . apply from : rootproject . file ( " gradle / release - notes . gradle " ) <nl> }
class commit { <nl>  <nl> class contribution { <nl> string email / / identifies the contributor <nl> - set < string > authoraliases = new hashset < string > ( ) / / there may be multiple aliases associated with given email <nl> + string author <nl> collection < commit > commits = new linkedlist < commit > ( ) / / the commits <nl> void add ( commit commit ) { <nl> if ( email = = null ) { <nl> email = commit . email <nl> + author = commit . author <nl> + <nl> } <nl> - assert email = = commit . email <nl> - authoraliases < < commit . author <nl> + assert email = = commit . email / / email identifies the contributor , author alias not necessarily <nl> commits < < commit <nl> } <nl> string tostring ( ) { <nl> - " $ { authoraliases . iterator ( ) . next ( ) } : $ { commits . size ( ) } " <nl> + " $ author : $ { commits . size ( ) } " <nl> } <nl> } <nl>  <nl>
private improvementset getimprovements ( set < string > tickets ) { <nl> if ( tickets . empty ) { <nl> return new improvementset ( improvements : [ ] ) <nl> } <nl> - println " querying github api about $ { tickets . size ( ) } tickets . this may take a while . " <nl> + <nl> + println " querying github api for $ { tickets . size ( ) } tickets . this may take a while . " <nl> def github = new rtgithub ( system . env . gh_token ) <nl> def repo = github . repos ( ) . get ( new coordinates . simple ( " mockito / mockito " ) ) <nl> def issues = repo . issues ( )
task ( release ) { <nl> maskedarg pushtarget = new maskedarg ( value : " https : / / szczepiq : $ { system . env . gh_token } @ github . com / mockito / mockito . git " ) <nl>  <nl> / / release process . should * not * run concurrently . <nl> - run " . / gradlew " , " bintrayupload " <nl> + / / run " . / gradlew " , " bintrayupload " <nl> configuregit ( ) <nl> updatereleasenotes ( ) <nl> commitreleasenotes ( buildinfo )
task ( release ) { <nl> / / release process . should * not * run concurrently . <nl> run " . / gradlew " , " bintrayupload " <nl> configuregit ( ) <nl> - commitupdatedreleasenotes ( buildinfo ) <nl> + <nl> pushtag ( currentversion , buildinfo , pushtarget ) <nl> commitupdatedjavadoc ( buildinfo ) <nl>  <nl>
task ( release ) { <nl> - manually edit version . properties and push ( can be done in the browser via github gui ) <nl> * / <nl> run " git " , " checkout " , " master " <nl> - commitincrementedversion ( previousversion , currentversion , buildinfo ) <nl> + commitincrementedversion ( currentversion , buildinfo ) <nl> + <nl> run " git " , " push " , pushtarget , " master " , " gh - pages " <nl> } <nl> } <nl>  <nl> + <nl> + <nl> + private void printissuesbetween ( string fromversion , string toversion ) { <nl> + getcommitsbetween ( " 1 . 9 . 5 " , " 1 . 10 . 29 - dev " ) . each { <nl> + if ( it . contains ( " [ ci skip ] " ) ) { <nl> + return <nl> + } <nl> + def tickets = it . findall ( " # \ \ d + " ) <nl> + if ( tickets ) { <nl> + println " $ tickets found in $ it " <nl> + } <nl> + def issues = it . findall ( " [ ii ] ssue \ \ d + " ) <nl> + if ( issues ) { <nl> + println " $ issues found in $ it " <nl> + } <nl> + } <nl> + } <nl> + <nl> + private string getpreviousversion ( ) { <nl> + return project . file ( " doc / release - notes . md " ) . withreader { <nl> + def firstline = it . readline ( ) <nl> + assert firstline . startswith ( ' # # # ' ) <nl> + / / example : " # # # num . 9 . 5 ( 06 - 10 - 2012 ) " , we want to extract " 1 . 9 . 5 " <nl> + def m = firstline = ~ / # # # ( . + ? ) . * / <nl> + assert m . matches ( ) <nl> + return m . group ( 1 ) <nl> + } <nl> + } <nl> + <nl> + private collection < string > getcommitsbetween ( string fromversion , string toversion ) { <nl> + def out = new bytearrayoutputstream ( ) <nl> + def token = "
private void configuregit ( ) { <nl> run " git " , " config " , " user . name " , " szczepan faber " <nl> } <nl>  <nl> - private void commitincrementedversion ( string previousversion , string currentversion , string buildinfo ) { <nl> + private void commitincrementedversion ( string currentversion , string buildinfo ) { <nl> run " . / gradlew " , " incrementversion " <nl> - string message = " increment version ' $ previousversion ' - > ' $ currentversion ' $ buildinfo " <nl> + string nextversion = project . ext . loadversion ( ) <nl> + string message = " increment version ' $ currentversion ' - > ' $ nextversion ' $ buildinfo " <nl> run " git " , " commit " , " - m " , " $ message " as string , " version . properties " <nl> } <nl>  <nl>
<nl> - / / until i fix the bug in gradle related to line breaks in the javadoc options file , <nl> + / / until i fix the bug in gradle ( gradle - 3099 ) related to line breaks in the javadoc options file , <nl> / / we need to stick with ant task for javadoc generation <nl>  <nl> + <nl> + <nl> task mockitojavadoc { <nl> description " creates javadoc html for mockito api . "
tasks . withtype ( javacompile ) { <nl> options . warnings = false <nl> } <nl>  <nl> + <nl> dependencies { <nl> provided filetree ( ' lib / compile ' ) <nl> compile filetree ( ' lib / run ' ) { exclude ' * . txt ' } , filetree ( ' lib / repackaged ' ) { exclude ' * . txt ' }
task incrementversion { <nl> dolast { <nl> try { <nl> list numbers = project . version . split ( ' \ \ . ' ) <nl> - int micro = numbers . pop ( ) as integer <nl> + <nl> + int micro = ( numbers . pop ( ) - " - dev " ) as integer <nl> numbers < < micro + num <nl> - def newversion = numbers . join ( ' . ' ) <nl> + def newversion = numbers . join ( ' . ' ) + " - dev " <nl> def updatedcontent = versionfile . text . replaceall ( " ( ? s ) version = ( . * ? ) \n " , " version = $ newversion\n " ) <nl> versionfile . text = updatedcontent <nl> logger . lifecycle ( " current content of ' { } ' : \n - - - - - - - - - - \n { } \n - - - - - - - - - - " , versionfile . name , updatedcontent ) <nl> mmm a / version . properties <nl> ppp b / version . properties <nl>
import org . mockito . stubbing . deprecatedongoingstubbing ; <nl> import org . mockito . stubbing . ongoingstubbing ; <nl>  <nl> public abstract class basestubbing < t > implements ongoingstubbing < t > , deprecatedongoingstubbing < t > { <nl> + <nl> + <nl> public ongoingstubbing < t > thenreturn ( t value ) { <nl> return thenanswer ( new returns ( value ) ) ; <nl> }
public class invocationmatcher implements describedinvocation , capturesargumensf <nl> for ( int position = num ; position < matchers . size ( ) ; position + + ) { <nl> matcher m = matchers . get ( position ) ; <nl> if ( m instanceof capturesarguments & & invocation . getrawarguments ( ) . length > position ) { <nl> + <nl> if ( isvariableargument ( invocation , position ) & & isvarargmatcher ( m ) ) { <nl> object array = invocation . getrawarguments ( ) [ position ] ; <nl> for ( int i = num ; i < array . getlength ( array ) ; i + + ) {
public class acrossjvmserializationfeature implements serializable { <nl> * < code > java . io . invalidobjectexception < / code > is thrown , so this part of the code is hacking through <nl> * the given < code > objectstreamclass < / code > to change the name with the newly created class . <nl> * <nl> - * @ param desc the < code > objectstreamclass < / code > that will be hacked . <nl> + * @ param descinstance the < code > objectstreamclass < / code > that will be hacked . <nl> * @ param proxyclass the proxy class whose name will be applied . <nl> * @ throws invalidobjectexception <nl> * / <nl> - private void hackclassnametomatchnewlycreatedclass ( objectstreamclass desc , class < ? > proxyclass ) throws invalidobjectexception { <nl> + private void hackclassnametomatchnewlycreatedclass ( objectstreamclass descinstance , class < ? > proxyclass ) throws invalidobjectexception { <nl> try { <nl> - new fieldsetter ( desc , desc . getclass ( ) . getdeclaredfield ( " name " ) ) . set ( proxyclass . getcanonicalname ( ) ) ; <nl> + field classnamefield = descinstance . getclass ( ) . getdeclaredfield ( " name " ) ; <nl> + new fieldsetter ( descinstance , classnamefield ) . set ( proxyclass . getcanonicalname ( ) ) ; <nl> } catch ( nosuchfieldexception e ) { <nl> - throw new invalidobjectexception ( " wow , the class ' objectstreamclass ' in the jdk don ' t have the field ' name ' , this is definitely a bug , in our code , please report used jdk , eventually code sample . \n " + e . tostring ( ) ) ; <nl> + <nl> + throw new invalidobjectexception ( " wow , the class ' objectstreamclass ' in the jdk don ' t have the field ' name ' , " + <nl> + " this is definitely a bug in our code , please report used jdk , eventually with a code sample . \n " + e . tostring ( ) ) ; <nl> } <nl> }
<nl> apply plugin : ' java ' <nl>  <nl> + <nl> version = ' 1 . 9 . 8 ' <nl>  <nl> sourcecompatibility = num . 5 <nl>
task updatelicenseheaders < < { <nl> task releasedocs { <nl> dolast { <nl> def docsrepo = file ( " . . / docs " ) <nl> + <nl> def docsdir = file ( " $ docsrepo / $ version " ) <nl> assert docsdir . directory | | docsdir . mkdirs ( ) : " expected to find cloned ' docs ' repo at : ' $ docsrepo ' . problems creating docs output dir . " <nl>  <nl>
task releasedocs { <nl> } <nl>  <nl> exec { <nl> - commandline ' hg ' , ' push ' <nl> + commandline ' hg ' , ' ci ' , ' - m ' , ' released the docs . ' <nl> workingdir docsdir <nl> } <nl> + <nl> + <nl> + exec { <nl> + commandline ' hg ' , ' push ' <nl> + workingdir docsrepo <nl> + } <nl> } <nl> }
public class smartnullsstubbingtest extends testbase { <nl> object smartnull = mock . objectreturningmethod ( ) ; <nl> smartnull . tostring ( ) ; <nl> } <nl> + <nl> + @ test <nl> + public void shouldshowparameters ( ) { <nl> + foo foo = mock ( foo . class , returns_smart_nulls ) ; <nl> + bar smartnull = foo . getbarwithparams ( 10 , " yes sir " ) ; <nl> + <nl> + try { <nl> + <nl> + smartnull . boo ( ) ; <nl> + fail ( ) ; <nl> + } catch ( exception e ) { <nl> + assertcontains ( " yes sir " , e . getmessage ( ) ) ; <nl> + } <nl> + } <nl> } <nl> \ no newline at end of file
<nl> + package org . mockitousage . bugs ; <nl> + <nl> + import static java . util . collections . synchronizedlist ; <nl> + import static org . junit . assert . fail ; <nl> + import static org . mockito . mockito . doreturn ; <nl> + import static org . mockito . mockito . mock ; <nl> + import static org . mockito . mockito . when ; <nl> + <nl> + import java . util . linkedlist ; <nl> + import java . util . list ; <nl> + import java . util . concurrent . executor ; <nl> + import java . util . concurrent . executors ; <nl> + import java . util . concurrent . rejectedexecutionexception ; <nl> + <nl> + import org . junit . before ; <nl> + import org . junit . ignore ; <nl> + import org . junit . test ; <nl> + <nl> + / * * <nl> + * race condition test in mockito . <nl> + * <nl> + * @ author ivan koblik <nl> + * / <nl> + @ ignore <nl> + public class multithreadedstubbinghalfmanualtest { <nl> + <nl> + / * * <nl> + * class with two methods , one of them is repeatedly mocked while another is repeatedly called . <nl> + * / <nl> + public interface tomock { <nl> + public integer getvalue ( integer param ) ; <nl> + <nl> + public list < integer > getvalues ( integer param ) ; <nl> + } <nl> + <nl> + / * * <nl> + * thread pool for concurrent invocations . <nl> + * / <nl> + private executor executor ; <nl> + <nl> + private list exceptions = synchronizedlist ( new linkedlist ( ) ) ; <nl> + <nl> + @ before <nl> + public void setup ( ) { <nl> + this . executor = executors . newsinglethreadexecutor ( ) ; <nl> + } <nl> + <nl> + / * * <nl> + * the returned runnable simply calls tomock . getvalues ( int ) . <nl> + * <nl> + * @ param tomock the mocked object <nl> + * @ return the runnable . <nl> + * / <nl> + private runnable getconflictingrunnable ( final tomock tomock ) { <nl> + return new runnable ( ) { <nl> + public void run ( ) { <nl> + while ( true ) { <nl> + try { <nl> + thread . sleep ( ( long ) ( math . random ( ) * num ) ) ; <nl> + } catch ( interruptedexception e ) { <nl> + } <nl> + if ( ! tomock . getvalues ( 0 ) . isempty ( ) ) { <nl> + fail ( " shouldn ' t happen , were just making sure it wasn ' t optimized away . . . " ) ; <nl> + } <nl> + } <nl> + } <nl> + } ; <nl> + } <nl> + <nl> + @ test <nl> + / / this problem shows at num out of num executions <nl> + / / it is not strictly a bug because mockito does not support simultanous stubbing ( see faq ) <nl> + / / however i decided to synchronize some calls in order to make the exceptions nicer <nl> + public void trytorevealtheproblem ( ) { <nl> + tomock tomock = mock ( tomock . class ) ; <nl> + for ( int i = num ; i < num ; i + + ) { <nl> + int j = i % num ; <nl> + <nl> + / / repeated mocking <nl> + when ( tomock . getvalue ( i ) ) . thenreturn ( j ) ; <nl> + <nl> + <nl> + while ( true ) { <nl> + try { <nl> + / / scheduling invocation <nl> + this . executor . execute ( getconflictingrunnable ( tomock ) ) ; <nl> + break ; <nl> + } catch ( rejectedexecutionexception ex ) { <nl> + fail ( ) ; <nl> + } <nl> + } <nl> + <nl> + try { <nl> + thread . sleep ( 10 / ( ( i % num ) + num ) ) ; <nl> + } catch ( interruptedexception e ) { <nl> + } <nl> + } <nl> + } <nl> + } <nl> \ no newline at end of file
public class registeredinvocations implements serializable { <nl> } <nl>  <nl> public void removelast ( ) { <nl> - int last = invocations . size ( ) - num ; <nl> - invocations . remove ( last ) ; <nl> + <nl> + synchronized ( invocations ) { <nl> + int last = invocations . size ( ) - num ; <nl> + invocations . remove ( last ) ; <nl> + } <nl> } <nl>  <nl> public list < invocation > getall ( ) {
public class mockhandler < t > implements mockitoinvocationhandler , mockhandlerinte <nl> if ( verificationmode ! = null ) { <nl> / / we need to check if verification was started on the correct mock <nl> / / - see verifyingwithanextracalltoadifferentmocktest ( bug num ) <nl> + <nl> if ( ( ( mockawareverificationmode ) verificationmode ) . getmock ( ) = = invocation . getmock ( ) ) { <nl> verificationdataimpl data = new verificationdataimpl ( invocationcontainerimpl , invocationmatcher ) ; <nl> verificationmode . verify ( data ) ; <nl> mmm a / src / org / mockito / internal / verification / verificationwithtimeoutimpl . java <nl> ppp b / src / org / mockito / internal / verification / verificationwithtimeoutimpl . java <nl>
public class verificationwithtimeouttest extends testbase { <nl> fail ( ) ; <nl> } catch ( nointeractionswanted e ) { } <nl> } <nl> + <nl> + <nl> + @ ignore <nl> + @ test <nl> + public void shouldallowtimeoutverificationinorder ( ) throws exception { <nl> + / / given <nl> + thread t1 = waitandexercisemock ( 20 ) ; <nl> + <nl> + / / when <nl> + t1 . start ( ) ; <nl> + mock . add ( " foo " ) ; <nl> + <nl> + / / then <nl> + inorder inorder = inorder ( mock ) ; <nl> + inorder . verify ( mock ) . add ( anystring ( ) ) ; <nl> + inorder . verify ( mock , never ( ) ) . clear ( ) ; <nl> + inorder . verify ( mock , timeout ( 40 ) ) . clear ( ) ; <nl> + } <nl>  <nl> private thread waitandexercisemock ( final int sleep ) { <nl> thread t = new thread ( ) {
import org . mockito . internal . verification . verificationmodefactory ; <nl> import org . mockito . internal . verification . verificationwithtimeoutimpl ; <nl> import org . mockito . internal . verification . api . verificationdata ; <nl>  <nl> + <nl> public class verificationwithtimeout implements timeout { <nl>  <nl> verificationwithtimeoutimpl impl ;
package org . mockitousage . stubbing ; <nl> import org . junit . test ; <nl> import org . mockitoutil . testbase ; <nl>  <nl> - / / fixme add test to demonstrate usage <nl> + <nl> public class returningmockvaluestest extends testbase { <nl>  <nl> @ test
public class returnsmockstest extends testbase { <nl> } <nl>  <nl> @ test <nl> - / / fixme split into separate <nl> + <nl> public void shouldreturnmockvalueforinterface ( ) throws exception { <nl> object interfacemock = values . returnvaluefor ( foointerface . class ) ; <nl> asserttrue ( new mockutil ( ) . ismock ( interfacemock ) ) ;
public class mockitotest extends testbase { <nl> public void shouldremovestubbablefromprogressafterstubbing ( ) { <nl> list mock = mockito . mock ( list . class ) ; <nl> mockito . when ( mock . add ( " test " ) ) . thenreturn ( true ) ; <nl> - / / fixme consider to move to separate test <nl> + <nl> assertnull ( new threadsafemockingprogress ( ) . pullongoingstubbing ( ) ) ; <nl> }
<nl> + package org . mockitousage . debugging ; <nl> + <nl> + import org . mockito . mockito ; <nl> + import org . mockito . mockitodebugger ; <nl> + import org . mockito . internal . debugging . mockitodebuggerimpl ; <nl> + <nl> + <nl> + public class newmockito extends mockito { <nl> + <nl> + public static mockitodebugger debug ( ) { <nl> + return new mockitodebuggerimpl ( ) ; <nl> + } <nl> + } <nl> mmm a / test / org / mockitousage / debugging / printinginvocationsdetectsunusedstubtest . java <nl> ppp b / test / org / mockitousage / debugging / printinginvocationsdetectsunusedstubtest . java <nl>
import org . mockito . internal . util . reflection . lenientcopytool ; <nl> import org . mockito . invocation . invocationonmock ; <nl> import org . objenesis . objenesishelper ; <nl>  <nl> + <nl> public class clonesarguments implements answer < object > { <nl> public object answer ( invocationonmock invocation ) throws throwable { <nl> object [ ] arguments = invocation . getarguments ( ) ;
public class warningsprinterimpltest extends testbase { <nl> private imethods mock ; <nl> private mockitologgerstub logger = new mockitologgerstub ( ) ; <nl>  <nl> + <nl> + <nl> @ test <nl> public void shouldprintunusedstub ( ) { <nl> / / given
import org . mockito . internal . invocation . invocation ; <nl> import org . mockito . internal . invocation . invocationmatcher ; <nl> import org . mockito . internal . util . mockitologger ; <nl>  <nl> + <nl> public class debugginginfo { <nl>  <nl> private final list < invocation > unusedstubs = new linkedlist < invocation > ( ) ;
<nl> * / <nl> package org . mockito . internal . stubbing ; <nl>  <nl> + import org . mockito . internal . invocation . invocation ; <nl> import org . mockito . internal . verification . registeredinvocations ; <nl> import org . mockito . stubbing . answer ; <nl> import org . mockito . stubbing . deprecatedongoingstubbing ; <nl> import org . mockito . stubbing . ongoingstubbing ; <nl>  <nl> + import java . util . list ; <nl> + <nl> public class ongoingstubbingimpl < t > extends basestubbing < t > { <nl>  <nl> private final mockitostubber mockitostubber ; <nl> - private final registeredinvocations registeredinvocations ; <nl>  <nl> - public ongoingstubbingimpl ( mockitostubber mockitostubber , <nl> - registeredinvocations registeredinvocations ) { <nl> + public ongoingstubbingimpl ( mockitostubber mockitostubber ) { <nl> this . mockitostubber = mockitostubber ; <nl> - this . registeredinvocations = registeredinvocations ; <nl> } <nl>  <nl> public ongoingstubbing < t > thenanswer ( answer < ? > answer ) { <nl> - registeredinvocations . removelast ( ) ; <nl> + mockitostubber . getregisteredinvocations ( ) . removelast ( ) ; <nl> mockitostubber . addanswer ( answer ) ; <nl> return new consecutivestubbing < t > ( mockitostubber ) ; <nl> } <nl>  <nl> public deprecatedongoingstubbing < t > toanswer ( answer < ? > answer ) { <nl> - registeredinvocations . removelast ( ) ; <nl> + mockitostubber . getregisteredinvocations ( ) . removelast ( ) ; <nl> mockitostubber . addanswer ( answer ) ; <nl> return new consecutivestubbing < t > ( mockitostubber ) ; <nl> } <nl>  <nl> - public registeredinvocations getregisteredinvocations ( ) { <nl> - return registeredinvocations ; <nl> + public list < invocation > getregisteredinvocations ( ) { <nl> + <nl> + return mockitostubber . getinvocations ( ) ; <nl> } <nl> } <nl> \ no newline at end of file
public class testbase extends assert { <nl> } <nl>  <nl> @ suppresswarnings ( " unchecked " ) <nl> + <nl> protected < t > t serializeandback ( t obj ) throws exception { <nl> bytearrayoutputstream os = this . serializemock ( obj ) ; <nl> return ( t ) this . deserializemock ( os , object . class ) ;
public interface mocksettings extends serializable { <nl> @ suppresswarnings ( " unchecked " ) <nl> mocksettings defaultanswer ( answer defaultanswer ) ; <nl>  <nl> + <nl> mocksettings serializable ( ) ; <nl>  <nl> } <nl> \ no newline at end of file <nl> mmm a / src / org / mockito / internal / creation / mocksettingsimpl . java <nl> ppp b / src / org / mockito / internal / creation / mocksettingsimpl . java <nl>
public class mocksettingsimpl implements mocksettings { <nl> private answer < object > defaultanswer ; <nl> private boolean isserializable ; <nl>  <nl> + <nl> public mocksettings serializable ( ) { <nl> this . isserializable = true ; <nl> return this ;
public class additionalmatchers { <nl> * the given array . <nl> * @ return < code > null < / code > . <nl> * / <nl> + <nl> public static short [ ] aryeq ( short [ ] value ) { <nl> return reportmatcher ( new arrayequals ( value ) ) . returnnull ( ) ; <nl> }
public abstract class abstractmockitomethodproxy implements mockitomethodproxy { <nl> return getmethodproxy ( ) . invokesuper ( target , arguments ) ; <nl> } <nl>  <nl> + <nl> public void setnamingpolicyfield ( mockitonamingpolicy namingpolicy ) { <nl> try { <nl> methodproxy methodproxy = getmethodproxy ( ) ;
public class serializablemockitomethodtest extends testbase { <nl> assertfalse ( new serializablemockitomethod ( testbasetostringmethod ) . equals ( mockmethod ) ) ; <nl> } <nl>  <nl> + <nl> + <nl> } <nl> \ no newline at end of file
import org . mockito . stubbing . * ; <nl> * <nl> * with this feature you can use a mock in a place that requires dependencies to be serializable . <nl> * < p > <nl> + * <nl> * warning : this should rarely be used . if you are unit testing it should be rare that you need this behaviour . <nl> * < p > <nl> * the behaviour was implemented for a specific use case of a bdd spec that had an unreliable external dependency . this
<nl> # this script is not really portable . it ' s just to automate some manual steps i usually do when releasing . <nl> # it might evolve into someting more robust but for now it ' s ok for me . <nl>  <nl> + raise " <nl> + <nl> import os <nl>  <nl> def run ( cmd ) :
<nl> + / * <nl> + * copyright ( c ) num mockito contributors <nl> + * this program is made available under the terms of the mit license . <nl> + * / <nl> + package org . mockitousage . bugs ; <nl> + <nl> + import static org . mockito . mockito . * ; <nl> + <nl> + import org . junit . ignore ; <nl> + import org . junit . test ; <nl> + import org . mockitoutil . testbase ; <nl> + <nl> + public class covariantoverridetest extends testbase { <nl> + <nl> + public static interface returnsobject { <nl> + object callme ( ) ; <nl> + } <nl> + <nl> + public static interface returnsstring extends returnsobject { <nl> + / / java num covariant override of method from parent interface <nl> + string callme ( ) ; <nl> + } <nl> + <nl> + @ test <nl> + public void returnfoo1 ( ) { <nl> + returnsobject mock = mock ( returnsobject . class ) ; <nl> + when ( mock . callme ( ) ) . thenreturn ( " foo " ) ; <nl> + assertequals ( " foo " , mock . callme ( ) ) ; / / passes <nl> + } <nl> + <nl> + @ test <nl> + public void returnfoo2 ( ) { <nl> + returnsstring mock = mock ( returnsstring . class ) ; <nl> + when ( mock . callme ( ) ) . thenreturn ( " foo " ) ; <nl> + assertequals ( " foo " , mock . callme ( ) ) ; / / passes <nl> + } <nl> + <nl> + @ test <nl> + public void returnfoo3 ( ) { <nl> + returnsobject mock = mock ( returnsstring . class ) ; <nl> + when ( mock . callme ( ) ) . thenreturn ( " foo " ) ; <nl> + assertequals ( " foo " , mock . callme ( ) ) ; / / passes <nl> + } <nl> + <nl> + @ ignore <nl> + @ test <nl> + public void returnfoo4 ( ) { <nl> + returnsstring mock = mock ( returnsstring . class ) ; <nl> + mock . callme ( ) ; / / covariant override not generated <nl> + returnsobject mock2 = mock ; / / switch to base type to call covariant override <nl> + verify ( mock2 ) . callme ( ) ; / / fails : java . lang . assertionerror : expected : < foo > but was : < null > <nl> + } <nl> + } <nl> \ no newline at end of file <nl> mmm / dev / null <nl> ppp b / test / org / mockitousage / bugs / mockitorunnerbreakswhennotestmethodstest . java <nl>
<nl> + / * <nl> + * copyright ( c ) num mockito contributors <nl> + * this program is made available under the terms of the mit license . <nl> + * / <nl> + package org . mockitousage . bugs ; <nl> + <nl> + import org . junit . ignore ; <nl> + import org . junit . runner . runwith ; <nl> + import org . mockito . runners . mockitojunitrunner ; <nl> + import org . mockitoutil . testbase ; <nl> + <nl> + <nl> + @ ignore <nl> + @ runwith ( mockitojunitrunner . class ) <nl> + public class mockitorunnerbreakswhennotestmethodstest extends testbase { } <nl> \ no newline at end of file <nl> mmm a / test / org / mockitousage / matchers / capturingargumentstest . java <nl> ppp b / test / org / mockitousage / matchers / capturingargumentstest . java <nl>
public class capturingargumentstest extends testbase { <nl> fail ( ) ; <nl> } catch ( mockitoexception e ) { } <nl> } <nl> + <nl> + <nl> + @ ignore <nl> + @ test <nl> + public void shouldcaptureint ( ) { <nl> + / / given <nl> + imethods mock = mock ( imethods . class ) ; <nl> + argumentcaptor < integer > argument = new argumentcaptor < integer > ( ) ; <nl> + <nl> + / / when <nl> + mock . intargumentmethod ( 10 ) ; <nl> + <nl> + / / then <nl> + verify ( mock ) . intargumentmethod ( argument . capture ( ) ) ; <nl> + assertequals ( 10 , ( int ) argument . getvalue ( ) ) ; <nl> + } <nl> } <nl> \ no newline at end of file
public class varargsnotplayingwithanyobjecttest extends testbase { <nl>  <nl> @ mock varargmethod mock ; <nl>  <nl> + <nl> + @ ignore <nl> @ test <nl> public void shouldallowanyobjectforvarargs ( ) { <nl> mock . run ( " a " , " b " ) ; <nl>
public class bddmockito extends mockito { <nl>  <nl> public static class bddongoingstubbingimpl < t > implements bddmyongoingstubbing < t > { <nl>  <nl> + <nl> private final newongoingstubbing < t > mockitoongoingstubbing ; <nl>  <nl> public bddongoingstubbingimpl ( newongoingstubbing < t > ongoingstubbing ) { <nl> mmm a / src / org / mockito / matchers . java <nl> ppp b / src / org / mockito / matchers . java <nl>
public class matchers { <nl> public static < t > t anyobject ( ) { <nl> return ( t ) reportmatcher ( any . any ) . returnnull ( ) ; <nl> } <nl> + <nl>  <nl> / * * <nl> * any object of specified class . <nl> mmm a / src / org / mockito / mockito . java <nl> ppp b / src / org / mockito / mockito . java <nl>
public class mockito extends matchers { <nl> * @ return deprecatedongoingstubbing object to set stubbed value / exception <nl> * / <nl> @ deprecated <nl> + <nl> public static < t > deprecatedongoingstubbing < t > stub ( t methodcall ) { <nl> return mockito_core . stub ( methodcall ) ; <nl> } <nl>
public class mockito extends matchers { <nl> * @ param tobethrown to be thrown when the stubbed method is called <nl> * @ return stubber - to select a method for stubbing <nl> * / <nl> + <nl> public static stubber dothrow ( throwable tobethrown ) { <nl> return mockito_core . doanswer ( new throwsexception ( tobethrown ) ) ; <nl> } <nl> mmm a / src / org / mockito / internal / progress / newongoingstubbing . java <nl> ppp b / src / org / mockito / internal / progress / newongoingstubbing . java <nl>
import org . mockito . stubbing . answer ; <nl> * <nl> * see examples in javadoc for { @ link mockito # stubvoid } <nl> * / <nl> + <nl> public interface voidmethodstubbable < t > { <nl>  <nl> / * *
public class localizedmatchertest extends testbase { <nl> } <nl>  <nl> @ test <nl> - public void shouldgetselfdescribingverboselytypeswhenactualmatcherhascorrecttype ( ) throws exception { <nl> + public void shoulddescribewithtypeinfowhenactualmatcherhascorrecttype ( ) throws exception { <nl> / / when <nl> containsextratypeinformation equals10 = new equals ( 10 ) ; <nl> localizedmatcher m = new localizedmatcher ( ( matcher ) equals10 ) ; <nl>  <nl> / / then <nl> - asserttrue ( m . typematches ( 10 ) ) ; <nl> - assertfalse ( m . typematches ( 10l ) ) ; <nl> + <nl> + assertequals ( " ( integer ) num " , stringdescription . tostring ( m . withextratypeinfo ( ) ) ) ; <nl> + } <nl> + <nl> + @ test <nl> + public void shouldnotdescribewithtypeinfowhenactualmatcherdoesnothavecorrecttype ( ) throws exception { <nl> + / / when <nl> + localizedmatcher m = new localizedmatcher ( any . any ) ; <nl> + <nl> + / / then <nl> + assertsame ( m , m . withextratypeinfo ( ) ) ; <nl> } <nl> } <nl> \ no newline at end of file
public class stacktracefilter { <nl> * basically removes all bad from the middle . if any good are in the middle of bad those are also removed . <nl> * / <nl> public stacktraceelement [ ] filter ( stacktraceelement [ ] target , int startwith ) { <nl> + <nl> list < stacktraceelement > unfilteredstacktrace = arrays . aslist ( target ) ; <nl>  <nl> int lastbad = - 1 ; <nl> mmm a / test / org / mockito / internal / exceptions / base / stacktracefiltertest . java <nl> ppp b / test / org / mockito / internal / exceptions / base / stacktracefiltertest . java <nl>
package org . mockito ; <nl>  <nl> import org . mockito . stubbing . answer ; <nl>  <nl> + / * * <nl> + * @ author sg0897539 <nl> + * <nl> + * / <nl> public interface mocksettings { <nl> + <nl>  <nl> + / * * <nl> + * specifies extra interfaces the mock should implement . might be useful for legacy code or some corner cases . <nl> + * for background , see issue num < a href = " http : / / code . google . com / p / mockito / issues / detail ? id = 51 " > here < / a > <nl> + * < p > <nl> + * this mysterious feature should be used very occasionally . <nl> + * the object under test should know exactly its collaborators & dependencies . <nl> + * if you happen to use it often than please make sure you are really producing simple , clean & readable code . <nl> + * < p > <nl> + * examples : <nl> + * < pre > <nl> + * foo foo = mock ( foo . class , withsettings ( ) . extrainterfaces ( bar . class , baz . class ) ) ; <nl> + * <nl> + * / / now , the mock implements extra interfaces , so following casting is possible : <nl> + * bar bar = ( bar ) foo ; <nl> + * baz baz = ( baz ) foo ; <nl> + * < / pre > <nl> + * <nl> + * <nl> + * @ param interfaces extra interfaces the should implement . <nl> + * @ return settings instance so that you can fluently specify other settings <nl> + * / <nl> mocksettings extrainterfaces ( class < ? > . . . interfaces ) ; <nl>  <nl> + / * * <nl> + * specifies mock name . naming mocks can be helpful for debugging - the name is used in all verification errors . <nl> + * < p > <nl> + * beware that naming mocks is not a solution for complex code which uses too many mocks or collaborators . <nl> + * < b > if you have too many mocks then refactor the code < / b > so that it ' s easy to test / debug without necessity of naming mocks . <nl> + * < p > <nl> + * < b > if you use & # 064 ; mock annotation then you ' ve got naming mocks for free ! < / b > & # 064 ; mock uses field name as mock name . { @ link mock read more . } <nl> + * < p > <nl> + * examples : <nl> + * < pre > <nl> + * foo foo = mock ( foo . class , withsettings ( ) . name ( " foo " ) ) ; <nl> + * <nl> + * / / below does exactly the same : <nl> + * foo foo = mock ( foo . class , " foo " ) ; <nl> + * < / pre > <nl> + * @ param name the name of the mock , later used in all verification errors <nl> + * @ return settings instance so that you can fluently specify other settings <nl> + * / <nl> mocksettings name ( string name ) ; <nl>  <nl> mocksettings spiedinstance ( object object ) ; <nl> mmm a / src / org / mockito / mockito . java <nl> ppp b / src / org / mockito / mockito . java <nl>
<nl> + / * * <nl> + * <nl> + * / <nl> + package org . mockito ; <nl> + <nl> + import java . util . linkedlist ; <nl> + import java . util . list ; <nl> + <nl> + import org . mockito . argumentmatcher ; <nl> + import org . mockito . mockito ; <nl> + import org . mockito . exceptions . reporter ; <nl> + <nl> + public class argument < t > extends argumentmatcher < t > { <nl> + private linkedlist < object > arguments = new linkedlist < object > ( ) ; <nl> + <nl> + public boolean matches ( object argument ) { <nl> + this . arguments . add ( argument ) ; <nl> + return true ; <nl> + } <nl> + <nl> + public t capture ( ) { <nl> + mockito . argthat ( this ) ; <nl> + return null ; <nl> + } <nl> + <nl> + public t value ( ) { <nl> + if ( arguments . isempty ( ) ) { <nl> + new reporter ( ) . argumentvaluenotyetcaptured ( ) ; <nl> + } else { <nl> + <nl> + return ( t ) arguments . getlast ( ) ; <nl> + } <nl> + return ( t ) arguments ; <nl> + } <nl> + <nl> + public list < t > allvalues ( ) { <nl> + return ( list ) arguments ; <nl> + } <nl> + } <nl> \ no newline at end of file <nl> mmm a / test / org / mockitousage / matchers / argumentcaptortest . java <nl> ppp b / test / org / mockitousage / matchers / argumentcaptortest . java <nl>
public class location { <nl>  <nl> public location ( ) { <nl> stacktraceelement [ ] stacktrace = thread . currentthread ( ) . getstacktrace ( ) ; <nl> + <nl> stacktracefilter filter = new stacktracefilter ( ) ; <nl> this . firsttraceelement = filter . filterstacktrace ( stacktrace ) [ 0 ] ; <nl> } <nl> mmm a / test / org / mockitousage / matchers / morematcherstest . java <nl> ppp b / test / org / mockitousage / matchers / morematcherstest . java <nl>
public class verbosemockitojunitrunnertest extends testbase { <nl> } ) ; <nl> } <nl>  <nl> + <nl> @ ignore ( " doesn ' t work due to package change from org . junit " ) <nl> @ test <nl> public void shouldlogunusedstubbingwarningwhentestfails ( ) throws exception {
public class stacktracefilter { <nl> return frommockobject | | fromorgmockito & & ! isrunner ; <nl> } <nl>  <nl> + <nl> public void filterstacktrace ( throwable hasstacktrace ) { <nl> stacktraceelement [ ] filtered = filterstacktrace ( hasstacktrace . getstacktrace ( ) ) ; <nl> hasstacktrace . setstacktrace ( filtered ) ; <nl> mmm a / src / org / mockito / internal / stubbing / throwsexception . java <nl> ppp b / src / org / mockito / internal / stubbing / throwsexception . java <nl>
public class throwsexception implements answer < object > { <nl> } <nl>  <nl> public object answer ( invocationonmock invocation ) throws throwable { <nl> - throwable filtered = throwable . fillinstacktrace ( ) ; <nl> - filter . filterstacktrace ( filtered ) ; <nl> - throw filtered ; <nl> + <nl> + if ( mockutil . ismock ( throwable ) ) { <nl> + throw throwable ; <nl> + } <nl> + throwable t = throwable . fillinstacktrace ( ) ; <nl> + filter . filterstacktrace ( t ) ; <nl> + throw t ; <nl> } <nl>  <nl> public throwable getthrowable ( ) { <nl> mmm / dev / null <nl> ppp b / test / org / mockitousage / bugs / npewhenmockingthrowablestest . java <nl>
public class invalidstatedetectiontest extends testbase { <nl> mock = mock ( imethods . class ) ; <nl> } <nl>  <nl> + <nl> @ test <nl> public void shouldshowwhereisunfinishedverification ( ) throws exception { <nl> unfinishedverificationhere ( ) ; <nl> try { <nl> - unfinishedverificationhere ( ) ; <nl> + mock ( imethods . class ) ; <nl> fail ( ) ; <nl> } catch ( unfinishedverificationexception e ) { <nl> assertcontains ( " invalidstatedetectiontest . unfinishedverificationhere " , e . getmessage ( ) ) ; <nl>
public class smartnullreturnvaluestest extends testbase { <nl> fail ( ) ; <nl> } catch ( smartnullpointerexception expected ) { } <nl> } <nl> + <nl> + @ test <nl> + public void shouldreturnanobjectthatallowsobjectmethods ( ) throws exception { <nl> + returnvalues returnvalues = new smartnullreturnvalues ( ) ; <nl> + <nl> + foo smartnull = ( foo ) returnvalues . valuefor ( invocationof ( foo . class , " get " ) ) ; <nl> + <nl> + <nl> + assertequals ( " smartnull returned by get ( ) method on mock " , smartnull + " " ) ; <nl> + / / assertequals ( false , smartnull . equals ( null ) ) ; <nl> + } <nl> } <nl> \ no newline at end of file
<nl> + import os <nl> + os . system ( ' svn ps - r svn : mime - type text / html . . / javadoc / * ' ) <nl> + os . system ( ' svn ps - r svn : mime - type text / css . . / javadoc / stylesheet . css ' ) <nl> + <nl> + # <nl> \ no newline at end of file <nl> mmm a / releasing / mime - types . rb <nl> ppp / dev / null <nl>
public class experimentalmockitojunitrunnertest extends testbase { <nl> runner = new experimentalmockitojunitrunner ( this . getclass ( ) , loggerstub ) ; <nl> } <nl>  <nl> + <nl> @ test ( expected = runwascalled . class ) <nl> public void shouldruntests ( ) throws exception { <nl> runner . run ( notifier , new junittestbody ( ) {
public class descriptivemessagesonverificationinordererrorstest extends testbase <nl> } <nl>  <nl> @ ignore ( " i don ' t know how to implement it nicely . . . yet : ) " ) <nl> + <nl> @ test <nl> public void shouldprintverificationinordererrorandshowwantedandactual ( ) { <nl> try {
<nl> + / * <nl> + * copyright ( c ) num mockito contributors <nl> + * this program is made available under the terms of the mit license . <nl> + * / <nl> + package org . mockitousage . matchers ; <nl> + <nl> + import static org . mockito . matchers . * ; <nl> + import static org . mockito . mockito . * ; <nl> + <nl> + import org . junit . test ; <nl> + import org . mockito . mock ; <nl> + import org . mockitousage . imethods ; <nl> + import org . mockitoutil . testbase ; <nl> + <nl> + public class morematcherstest extends testbase { <nl> + <nl> + @ mock private imethods mock ; <nl> + <nl> + @ test <nl> + public void shouldhelpoutwithunnecessarycasting ( ) { <nl> + when ( mock . objectargmethod ( any ( string . class ) ) ) . thenreturn ( " string " ) ; <nl> + <nl> + assertequals ( " string " , mock . objectargmethod ( " foo " ) ) ; <nl> + assertequals ( null , mock . objectargmethod ( new object ( ) ) ) ; <nl> + } <nl> + <nl> + <nl> + @ test <nl> + public void shouldhelpoutwithunnecessarycastingofcollections ( ) { <nl> + <nl> + / / when ( mock . collectionargmethod ( anycollectionof ( string . class ) ) ) . thenreturn ( " collection " ) ; <nl> + / / <nl> + / / assertequals ( " list " , mock . listargmethod ( new linkedlist ( ) ) ) ; <nl> + / / assertequals ( null , mock . listargmethod ( new linkedlist ( ) ) ) ; <nl> + } <nl> + } <nl> \ no newline at end of file
<nl> + / * <nl> + * copyright ( c ) num mockito contributors <nl> + * this program is made available under the terms of the mit license . <nl> + * / <nl> + package org . mockitousage . misuse ; <nl> + <nl> + import static org . mockito . mockito . * ; <nl> + <nl> + import org . junit . ignore ; <nl> + import org . junit . test ; <nl> + import org . mockito . mock ; <nl> + import org . mockito . exceptions . base . mockitoexception ; <nl> + import org . mockitousage . imethods ; <nl> + import org . mockitoutil . testbase ; <nl> + <nl> + public class restrictedobjectmethodstest extends testbase { <nl> + <nl> + @ mock imethods mock ; <nl> + <nl> + @ ignore <nl> + @ test <nl> + public void shouldnotallowstubbingrestrictedmethods ( ) { <nl> + try { <nl> + when ( mock . hashcode ( ) ) . thenreturn ( 1 ) ; <nl> + fail ( ) ; <nl> + } catch ( mockitoexception e ) { <nl> + assertequals ( " cannot stub hashcode ( ) method " , e . getmessage ( ) ) ; <nl> + } <nl> + <nl> + try { <nl> + when ( mock . equals ( null ) ) . thenreturn ( false ) ; <nl> + fail ( ) ; <nl> + } catch ( mockitoexception e ) { <nl> + assertequals ( " cannot stub equals ( ) method " , e . getmessage ( ) ) ; <nl> + } <nl> + } <nl> + <nl> + @ ignore <nl> + @ test <nl> + public void shouldnotallowverifyingrestrictedmethods ( ) { <nl> + <nl> + verify ( mock ) . tostring ( ) ; <nl> + verify ( mock ) . hashcode ( ) ; <nl> + verify ( mock ) . equals ( null ) ; <nl> + } <nl> + } <nl> \ no newline at end of file
import org . mockito . internal . verification . api . verificationmode ; <nl> * / <nl> public class mockitoverificationmode implements verificationinordermode , verificationmode { <nl>  <nl> + <nl> public enum verification { explicit , no_more_wanted , at_least } ; <nl>  <nl> private list < object > mockstobeverifiedinorder ; <nl> mmm a / test / org / mockito / internal / verification / missinginvocationcheckertest . java <nl> ppp b / test / org / mockito / internal / verification / missinginvocationcheckertest . java <nl>
public class stubbingusingdoreturntest extends testbase { <nl> doreturn ( " test " ) . when ( mock ) . tostring ( ) ; <nl> assertequals ( " test " , mock . tostring ( ) ) ; <nl> } <nl> + <nl> + @ test <nl> + @ ignore ( " <nl> + public void shouldchecktypesfast ( ) throws exception { <nl> + try { <nl> + doreturn ( " foo " ) . when ( mock ) . booleanreturningmethod ( ) ; <nl> + fail ( ) ; <nl> + } catch ( exception e ) { <nl> + <nl> + } <nl> + } <nl> } <nl> \ no newline at end of file
import org . mockito . exceptions . base . mockitoexception ; <nl> public class mockitoannotations { <nl>  <nl> / * * <nl> + * <nl> * < b > deprecated < / b > use { @ link mock } annotation instead <nl> * < p > <nl> * annotation is now a top - level class so that ides are not confused .
public class verificationmodeimpl implements verificationmode { <nl> enum verification { explicit , no_more_wanted } ; <nl>  <nl> private final integer wantedinvocationcount ; <nl> + <nl> private final integer mininvocationcount ; <nl> private final list < ? extends object > mockstobeverifiedinorder ; <nl> private final verification verification ;
import org . junit . test ; <nl> import org . mockitousage . imethods ; <nl> import org . mockitoutil . testbase ; <nl>  <nl> + <nl> / / this test exposes the problem at least once in num runs <nl> public class threadsshareamocktest extends testbase {
<nl> + / * <nl> + * copyright ( c ) num mockito contributors <nl> + * this program is made available under the terms of the mit license . <nl> + * / <nl> + package org . mockitousage . verification ; <nl> + <nl> + import java . util . list ; <nl> + <nl> + import org . junit . test ; <nl> + import org . mockito . mockitoannotations . mock ; <nl> + import org . mockitoutil . testbase ; <nl> + <nl> + @ suppresswarnings ( " unchecked " ) <nl> + public class verificationwithtimeouttest extends testbase { <nl> + <nl> + @ mock private list mock ; <nl> + <nl> + @ test <nl> + public void shouldverify ( ) throws exception { <nl> + mock . clear ( ) ; <nl> + <nl> + <nl> + } <nl> + } <nl> \ no newline at end of file
public class mockutil { <nl>  <nl> public static boolean ismock ( object mock ) { <nl> try { <nl> + <nl> getmockhandler ( mock ) ; <nl> return true ; <nl> } catch ( mockitoexception e ) { <nl> mmm a / test / org / mockito / internal / stubbing / answersvalidatortest . java <nl> ppp b / test / org / mockito / internal / stubbing / answersvalidatortest . java <nl>
public class mockfactory < t > { <nl>  <nl> / / this is required to make ( cglib + eclipse plugins testing ) happy <nl> / / see issue # 11 <nl> + <nl> enhancer . setclassloader ( mockfactory . class . getclassloader ( ) ) ; <nl>  <nl> return enhancer ;
import org . mockito . internal . matchers . apachecommons . reflectionequals ; <nl> import org . mockito . internal . progress . emptyreturnvalues ; <nl> import org . mockito . internal . progress . lastarguments ; <nl>  <nl> + <nl> + <nl> / * * <nl> * allow flexible verification or stubbing . see also { @ link additionalmatchers } . <nl> * < p >
public class mockhandler < t > implements mockawareinterceptor < t > { <nl> public object intercept ( object proxy , method method , object [ ] args , methodproxy methodproxy ) throws throwable { <nl> if ( stubber . hasthrowableforvoidmethod ( ) ) { <nl> invocation invocation = new invocation ( proxy , method , args , mockingprogress . nextsequencenumber ( ) ) ; <nl> + <nl> invocationmatcher invocationmatcher = matchersbinder . bindmatchers ( invocation ) ; <nl> stubber . addvoidmethodforthrowable ( invocationmatcher ) ; <nl> return null ; <nl> mmm a / src / org / mockito / internal / invocation / invocation . java <nl> ppp b / src / org / mockito / internal / invocation / invocation . java <nl>
public class mockfactory < t > { <nl> enhancer enhancer = createenhancer ( tomock ) ; <nl> enhancer . setcallbacktype ( filter . getclass ( ) ) ; <nl>  <nl> + if ( tomock . getsigners ( ) ! = null ) { <nl> + <nl> + enhancer . setnamingpolicy ( allows_mocking_classes_in_signed_packages ) ; <nl> + } <nl> + <nl> class mockclass = enhancer . createclass ( ) ; <nl> + <nl> enhancer . registercallbacks ( mockclass , new callback [ ] { filter } ) ; <nl>  <nl> factory mock = createmock ( mockclass ) ; <nl>
public class stubbingconsecutivereturnvaluestest extends testbase { <nl> . toreturn ( " one " ) <nl> . tothrow ( new exception ( ) ) ; <nl> } <nl> + <nl> + @ test <nl> + public void shouldallowconsecutivestubbingforvoidmethod ( ) throws exception { <nl> + <nl> + / / . tothrow ( new illegalargumentexception ( ) ) <nl> + / / . toreturn ( ) <nl> + / / . tothrow ( new nullpointerexception ( ) ) <nl> + / / . toreturn ( ) ; <nl> + / / <nl> + / / try { <nl> + / / mock . simplemethod ( ) ; <nl> + / / fail ( ) ; <nl> + / / } catch ( illegalargumentexception e ) { } <nl> + } <nl> } <nl> \ no newline at end of file
public class mockitoconfiguration { <nl> } <nl>  <nl> public void setreturnvalues ( returnvalues returnvalues ) { <nl> + <nl> this . returnvalues = returnvalues ; <nl> }
public class descriptivemessageswhenverificationfailstest extends testbase { <nl> verify ( mock ) . varargs ( " this is very long string " , " this is another very long string " , " this is yet another very long string " ) ; <nl> fail ( ) ; <nl> } catch ( argumentsaredifferent e ) { <nl> + <nl> string expected = <nl> " \n " + <nl> " argument ( s ) are different ! wanted : " +
public class extramatchers extends corematchers { <nl> } <nl> } ; <nl> } <nl> + <nl> } <nl> \ no newline at end of file
import org . mockito . exceptions . reporter ; <nl> public class mockfactory < t > { <nl>  <nl> @ suppresswarnings ( " unchecked " ) <nl> + <nl> public t createmock ( class < t > tomock , final methodinterceptorfilter filter ) { <nl> validateclass ( tomock ) ; <nl> enhancer enhancer = createenhancer ( tomock ) ; <nl> mmm a / test / org / mockitousage / sample / mockitosampletest . java <nl> ppp b / test / org / mockitousage / sample / mockitosampletest . java <nl>
public class invocationsfinder { <nl> } <nl>  <nl> public invocation findsimilarinvocation ( list < invocation > invocations , invocationmatcher wanted , verificationmodeimpl mode ) { <nl> + <nl> for ( invocation invocation : invocations ) { <nl> if ( wanted . issimilarto ( invocation ) ) { <nl> return invocation ;
public class custommatcherstest extends testbase { <nl> try { <nl> verify ( mock ) . simplemethod ( containstest ( ) ) ; <nl> fail ( ) ; <nl> + <nl> } catch ( argumentsaredifferentexception e ) { <nl> assertthat ( e , messagecontains ( " 1st : string that contains xxx " ) ) ; <nl> assertthat ( e , causemessagecontains ( " 1st : \ " foo \ " " ) ) ;
public class invocationtest extends testbase { <nl> invocation i = new invocationbuilder ( ) . toinvocation ( ) ; <nl> assertequals ( " < no arguments > " , i . getargs ( ) ) ; <nl> } <nl> + <nl> + @ test <nl> + public void shouldtransformargumentstomatchers ( ) throws exception { <nl> + invocation i = new invocationbuilder ( ) . args ( " foo " , new string [ ] { " bar " } ) . toinvocation ( ) ; <nl> + list matchers = i . argumentstomatchers ( ) ; <nl> + <nl> + assertthat ( matchers , iscollectioncontaining . hasitems ( corematchers . is ( equals . class ) , corematchers . is ( arrayequals . class ) ) ) ; <nl> + } <nl> } <nl> \ no newline at end of file <nl> mmm a / test / org / mockito / util / extramatchers . java <nl> ppp b / test / org / mockito / util / extramatchers . java <nl>
public class extramatchers extends corematchers { <nl> } ; <nl> } <nl>  <nl> + <nl> public static < t > matcher < collection > collectionhasexactlyinorder ( final t . . . elements ) { <nl> return new basematcher < collection > ( ) { <nl>  <nl> mmm a / test / org / mockitousage / imethods . java <nl> ppp b / test / org / mockitousage / imethods . java <nl>
public class invocation implements printableinvocation { <nl> list < matcher > matchers = new arraylist < matcher > ( arguments . length ) ; <nl> for ( object arg : arguments ) { <nl> if ( arg ! = null & & arg . getclass ( ) . isarray ( ) ) { <nl> + <nl> matchers . add ( new arrayequals ( arg ) ) ; <nl> } else { <nl> matchers . add ( new equals ( arg ) ) ; <nl> mmm a / test / org / mockito / internal / invocation / invocationtest . java <nl> ppp b / test / org / mockito / internal / invocation / invocationtest . java <nl>
public class mockito extends matchers { <nl> } <nl>  <nl> / * * <nl> + * <nl> + * <nl> * alias to times ( 0 ) <nl> * < p > <nl> * see { @ link mockito # times ( int ) }
public class descriptivemessagesonverificationinordererrorstest extends requires <nl> @ test <nl> public void shouldprintverificationinordererrorandshowwantedonly ( ) { <nl> try { <nl> - inorder . verify ( one ) . simplemethod ( 999 ) ; <nl> + inorder . verify ( one ) . differentmethod ( ) ; <nl> fail ( ) ; <nl> } catch ( wantedbutnotinvoked e ) { <nl> string expected = <nl> " \n " + <nl> " wanted but not invoked : " + <nl> " \n " + <nl> + " imethods . differentmethod ( ) " ; <nl> + <nl> + assertequals ( expected , e . getmessage ( ) ) ; <nl> + <nl> + assertequals ( null , e . getcause ( ) ) ; <nl> + } <nl> + } <nl> + <nl> + @ ignore ( " <nl> + @ test <nl> + public void shouldprintverificationinordererrorandshowwantedandactual ( ) { <nl> + try { <nl> + inorder . verify ( one ) . simplemethod ( 999 ) ; <nl> + fail ( ) ; <nl> + } catch ( wantedbutnotinvoked e ) { <nl> + string expected = <nl> + " \n " + <nl> + " invocation differs from actual : " + <nl> + " \n " + <nl> " imethods . simplemethod ( 999 ) " ; <nl>  <nl> assertequals ( expected , e . getmessage ( ) ) ;
import org . mockito . internal . progress . verificationmodeimpl ; <nl>  <nl> public class verifyingrecorder { <nl>  <nl> + <nl> private linkedlist < invocation > registeredinvocations = new linkedlist < invocation > ( ) ; <nl>  <nl> private final list < ? extends verifier > verifiers ;
public class invalidusagetest extends requiresvalidstate { <nl> public void shouldnotallowsettingnullthrowable ( ) throws exception { <nl> stub ( mock . simplemethod ( ) ) . tothrow ( null ) ; <nl> } <nl> + <nl> + final class finalclass { } <nl> + <nl> + @ test ( expected = mockitoexception . class ) <nl> + public void shouldnotallowmockingfinalclasses ( ) throws exception { <nl> + mock ( finalclass . class ) ; <nl> + } <nl> + <nl> + <nl> } <nl> \ no newline at end of file
public class matchers { <nl> * @ return < code > false < / code > . <nl> * / <nl> public static boolean anyboolean ( ) { <nl> + <nl> lastarguments . instance ( ) . reportmatcher ( any . any ) ; <nl> return false ; <nl> }
<nl> + / * <nl> + * copyright ( c ) num mockito contributors <nl> + * this program is made available under the terms of the mit license . <nl> + * / <nl> + package org . mockitousage . matchers ; <nl> + <nl> + import static org . junit . assert . * ; <nl> + import static org . mockito . mockito . * ; <nl> + <nl> + import org . junit . before ; <nl> + import org . junit . test ; <nl> + import org . mockito . mockito ; <nl> + import org . mockito . requiresvalidstate ; <nl> + import org . mockito . exceptions . verification . toomanyactualinvocations ; <nl> + import org . mockito . internal . matchers . iargumentmatcher ; <nl> + import org . mockito . internal . progress . lastarguments ; <nl> + import org . mockitousage . imethods ; <nl> + <nl> + @ suppresswarnings ( " unchecked " ) <nl> + public class custommatcherstest extends requiresvalidstate { <nl> + private final class zeroorone extends custommatcher { <nl> + public boolean matches ( object argument ) { <nl> + if ( ( ( integer ) argument ) = = num | | ( ( integer ) argument ) = = num ) { <nl> + return true ; <nl> + } <nl> + <nl> + return false ; <nl> + } <nl> + } <nl> + <nl> + <nl> + abstract class custommatcher implements iargumentmatcher { <nl> + public void appendto ( stringbuilder builder ) { <nl> + builder . append ( " < custom argument matcher > " ) ; <nl> + } <nl> + <nl> + public abstract boolean matches ( object argument ) ; <nl> + } <nl> + <nl> + private imethods mock ; <nl> + <nl> + @ before <nl> + public void setup ( ) { <nl> + mock = mockito . mock ( imethods . class ) ; <nl> + } <nl> + <nl> + @ test <nl> + public void shouldallowusingcustommatcher ( ) { <nl> + stub ( mock . simplemethod ( intthatis ( new zeroorone ( ) ) ) ) . toreturn ( " zero or one " ) ; <nl> + <nl> + assertequals ( " zero or one " , mock . simplemethod ( 0 ) ) ; <nl> + assertequals ( " zero or one " , mock . simplemethod ( 1 ) ) ; <nl> + assertequals ( null , mock . simplemethod ( 2 ) ) ; <nl> + <nl> + try { <nl> + verify ( mock ) . simplemethod ( intthatis ( new zeroorone ( ) ) ) ; <nl> + fail ( ) ; <nl> + } catch ( toomanyactualinvocations e ) { } <nl> + } <nl> + <nl> + private int intthatis ( custommatcher matcher ) { <nl> + lastarguments . instance ( ) . reportmatcher ( matcher ) ; <nl> + return num ; <nl> + } <nl> + } <nl> \ no newline at end of file
import org . mockito . internal . matchers . iargumentmatcher ; <nl> import org . mockito . internal . matchers . not ; <nl> import org . mockito . internal . matchers . or ; <nl>  <nl> + <nl> public class lastarguments { <nl>  <nl> private static final threadlocal < lastarguments > instance = new threadlocal < lastarguments > ( ) ; <nl> mmm / dev / null <nl> ppp b / src / org / mockito / internal / progress / package . html <nl>
package org . mockito . exceptions . verification ; <nl>  <nl> import org . mockito . exceptions . base . mockitoassertionerror ; <nl>  <nl> - <nl> + <nl> public class verificationerror extends mockitoassertionerror { <nl>  <nl> private static final long serialversionuid = num l ; <nl> mmm a / src / org / mockito / exceptions / verification / package . html <nl> ppp b / src / org / mockito / exceptions / verification / package . html <nl>
public class invocationscalculator { <nl> return actual ; <nl> } <nl>  <nl> + <nl> public invocation findactualinvocation ( list < invocation > invocations , invocationmatcher wanted ) { <nl> invocation actualbyname = null ; <nl> for ( invocation registered : invocations ) { <nl> mmm / dev / null <nl> ppp b / src / org / mockito / internal / invocation / package . html <nl>
public class invocation { <nl> } <nl>  <nl> private boolean equalarguments ( object [ ] arguments ) { <nl> + <nl> + / / e . g prove that we should treat the following as not equal calls for chunking evaluation <nl> + / / mock . add ( new string ( " one " ) ) ; <nl> + / / mock . add ( " one " ) ; <nl> + <nl> if ( this . arguments . length ! = arguments . length ) { <nl> return false ; <nl> } <nl> mmm a / src / org / mockito / internal / registeredinvocations . java <nl> ppp b / src / org / mockito / internal / registeredinvocations . java <nl>
import org . mockito . exceptions . mockitoexception ; <nl> @ suppresswarnings ( " unchecked " ) <nl> public class invalidusageexceptionstest { <nl>  <nl> + <nl> + <nl> private linkedlist mock ; <nl> private linkedlist mocktwo ;
public class mockitobehavior < t > { <nl>  <nl> private t mock ; <nl>  <nl> + <nl> private list < invocation > registeredinvocations = new linkedlist < invocation > ( ) ; <nl> private map < expectedinvocation , result > results = new hashmap < expectedinvocation , result > ( ) ; <nl>  <nl>
<nl> + package org . mockito ; <nl> + <nl> + import java . util . linkedlist ; <nl> + <nl> + public class strictverifier < t > { <nl> + <nl> + public t verify ( t mock , int exactnumberoftimes ) { <nl> + <nl> + return null ; <nl> + } <nl> + <nl> + } <nl> mmm / dev / null <nl> ppp b / test / org / mockito / usage / verification / verificationinordertest . java <nl>
<nl>  <nl> # endif / / clang / gcc version check <nl>  <nl> - # if ( __gnuc__ > = num ) | | ( defined ( __clang_major__ ) & & ( __clang_major__ > = num ) ) <nl> + # if ( __gnuc__ > = num ) <nl> + <nl> + / / | | ( defined ( __clang_major__ ) & & ( __clang_major__ > = num ) ) <nl>  <nl> / / use " warning " attribute to detect uses of " forbidden " functions . <nl> / / <nl>
public class markunsafeaccesstest extends graalcompilertest { <nl> testmappedbytebuffer ( mappedbytebuffer : : get ) ; <nl> } <nl>  <nl> + <nl> + / * <nl> @ test <nl> public void testcompiled ( ) throws ioexception { <nl> assume . assumefalse ( " crashes on aarch64 ( gr - 8351 ) " , system . getproperty ( " os . arch " ) . equalsignorecase ( " aarch64 " ) ) ; <nl>
public class macosflags { <nl> propertystate metalstate = getbooleanprop ( " sun . java2d . metal " , propertystate . unspecified ) ; <nl>  <nl> / / handle invalid combinations to use the default rendering pipeline <nl> - / / current default rendering pipeline is opengl <nl> - / / ( the default can be changed to metal in future just by toggling two states in this if condition block ) <nl> + / / current default rendering pipeline is metal <nl> + / / ( the default can be changed to opengl in future just by toggling two states in this if condition block ) <nl> + / / - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - <nl> + <nl> if ( ( oglstate = = propertystate . unspecified & & metalstate = = propertystate . unspecified ) | | <nl> ( oglstate = = propertystate . disabled & & metalstate = = propertystate . disabled ) | | <nl> ( oglstate = = propertystate . enabled & & metalstate = = propertystate . enabled ) ) { <nl> - oglstate = propertystate . enabled ; / / enable default pipeline <nl> - metalstate = propertystate . disabled ; / / disable non - default pipeline <nl> + metalstate = propertystate . enabled ; / / enable default pipeline <nl> + oglstate = propertystate . disabled ; / / disable non - default pipeline <nl> } <nl>  <nl> if ( metalstate = = propertystate . unspecified ) {
instruct absi_reg ( iregi dst , iregi src , flagsreg cr ) % { <nl> ins_pipe ( pipe_class_dummy ) ; <nl> % } <nl>  <nl> + instruct absl_reg ( iregl dst , iregl src , flagsreg cr ) % { <nl> + match ( set dst ( absl src ) ) ; <nl> + effect ( kill cr ) ; <nl> + ins_cost ( default_cost_low ) ; <nl> + <nl> + format % { " lpgr $ dst , $ src " % } <nl> + opcode ( lpgr_zopc ) ; <nl> + ins_encode ( z_rreform ( dst , src ) ) ; <nl> + ins_pipe ( pipe_class_dummy ) ; <nl> + % } <nl> + <nl> instruct negabsi_reg ( iregi dst , iregi src , immi_0 zero , flagsreg cr ) % { <nl> match ( set dst ( subi zero ( absi src ) ) ) ; <nl> effect ( kill cr ) ;
fi <nl> installjtreg ( ) <nl> { <nl> # install jtreg if missing <nl> - if [ - z " $ jtreg_home " ] ; then <nl> - if [ ! - f " $ jtreg_jar " ] ; then <nl> - exec_command mkdir - p " $ workdir " <nl> - if [ [ $ { jtreg_bundle : - 7 } = = " . tar . gz " ] ] ; then <nl> - exec_command " ( " cd " $ workdir " " & & " wget " $ jtreg_bundle " " & & " tar - xzf " $ ( basename $ jtreg_bundle ) " " ; " rm - f " $ ( basename $ jtreg_bundle ) " " ) " <nl> - else <nl> - if [ [ $ { jtreg_bundle : - 4 } = = " . zip " ] ] ; then <nl> - exec_command " ( " cd " $ workdir " " & & " wget " $ jtreg_bundle " " & & " unzip " $ ( basename $ jtreg_bundle ) " " ; " rm - f " $ ( basename $ jtreg_bundle ) " " ) " <nl> - else <nl> - fatal ' unsupported extension of jreg bundle [ ' $ jtreg_bundle_url ' ] . only * . zip or * . tar . gz is supported . ' <nl> - fi <nl> - fi <nl> - fi <nl> - else <nl> - # use jtreg provided via jtreg_home <nl> - jtreg_jar = $ jtreg_home / lib / jtreg . jar <nl> + if [ ! - f " $ jtreg_jar " ] ; then <nl> + exec_command mkdir - p " $ workdir " <nl> + # <nl> + # to $ workdir / jtreg / lib / jtreg . jar <nl> + fatal " error : all tests disabled until locating jtreg . jar implemented . " <nl> fi <nl> - <nl> - echo ' jtreg jar file : ' $ jtreg_jar <nl> }
public class arraylist < e > extends abstractlist < e > <nl> @ override <nl> public void replaceall ( unaryoperator < e > operator ) { <nl> replaceallrange ( operator , num , size ) ; <nl> + <nl> modcount + + ; <nl> } <nl>  <nl> mmm a / src / java . base / share / classes / java / util / vector . java <nl> ppp b / src / java . base / share / classes / java / util / vector . java <nl>
public class vector < e > <nl> es [ i ] = operator . apply ( elementat ( es , i ) ) ; <nl> if ( modcount ! = expectedmodcount ) <nl> throw new concurrentmodificationexception ( ) ; <nl> + <nl> modcount + + ; <nl> }
net_getfiledescriptorid ( jnienv * env ) <nl> return ( * env ) - > getfieldid ( env , cls , " fd " , " i " ) ; <nl> } <nl>  <nl> + jint ipv4_supported ( ) <nl> + { <nl> + / * <nl> + return jni_true ; <nl> + } <nl> + <nl> jint ipv6_supported ( ) <nl> { <nl> socket s = socket ( af_inet6 , sock_stream , num ) ;
public class splitpanedemotest { <nl>  <nl> jsplitpaneoperator splitpane = new jsplitpaneoperator ( frame ) ; <nl>  <nl> - / / toggle onetouch expandable <nl> - checkonetouch ( frame , splitpane , true ) ; <nl> - checkonetouch ( frame , splitpane , false ) ; <nl> + / / onetouch feature is not available in gtk l & f <nl> + if ( ! " gtk " . equals ( uimanager . getlookandfeel ( ) . getid ( ) ) ) { <nl> + / / toggle onetouch expandable <nl> + checkonetouch ( frame , splitpane , true ) ; <nl> + checkonetouch ( frame , splitpane , false ) ; <nl> + } <nl>  <nl> / / check changing divider size to minimum and maximum values <nl> changedividersize ( frame , splitpane , num ) ; <nl> changedividersize ( frame , splitpane , num ) ; <nl>  <nl> - / / check moving the divider <nl> - checkdividermoves ( frame , splitpane , false ) ; <nl> - checkdividermoves ( frame , splitpane , true ) ; <nl>  <nl> - / / check different minumum day / night sizes <nl> - changeminimumsizes ( frame , splitpane , num ) ; <nl> - changeminimumsizes ( frame , splitpane , num ) ; <nl> + <nl> + if ( ! ( " motif " . equals ( uimanager . getlookandfeel ( ) . getid ( ) ) ) ) { <nl> + / / check moving the divider <nl> + checkdividermoves ( frame , splitpane , false ) ; <nl> + checkdividermoves ( frame , splitpane , true ) ; <nl> + <nl> + / / check different minumum day / night sizes <nl> + changeminimumsizes ( frame , splitpane , num ) ; <nl> + changeminimumsizes ( frame , splitpane , num ) ; <nl> + } <nl> } <nl>  <nl> / / check for different day and night minimum size
bool systemdictionary : : do_unloading ( gctimer * gc_timer , <nl> } <nl> } <nl>  <nl> + <nl> if ( unloading_occurred ) { <nl> - gctracetime ( debug , gc , phases ) t ( " dictionary " , gc_timer ) ; <nl> - constraints ( ) - > purge_loader_constraints ( ) ; <nl> - resolution_errors ( ) - > purge_resolution_errors ( ) ; <nl> + { <nl> + gctracetime ( debug , gc , phases ) t ( " symboltable " , gc_timer ) ; <nl> + / / check if there ' s work to do in the symboltable <nl> + symboltable : : do_check_concurrent_work ( ) ; <nl> + } <nl> + <nl> + { <nl> + gctracetime ( debug , gc , phases ) t ( " dictionary " , gc_timer ) ; <nl> + constraints ( ) - > purge_loader_constraints ( ) ; <nl> + resolution_errors ( ) - > purge_resolution_errors ( ) ; <nl> + } <nl> } <nl>  <nl> {
instruct partialsubtypecheck ( rarg1regp index , rarg2regp sub , rarg3regp super , fl <nl> match ( set <nl> effect ( kill pcc , kill scratch1 , kill scratch2 ) ; <nl> ins_cost ( 10 * default_cost ) ; <nl> - size ( 12 ) ; <nl> + <nl> format % { " call partialsubtypecheck\n " % } <nl> ins_encode % { <nl> addressliteral stub_address ( stubroutines : : zarch : : partial_subtype_check ( ) ) ; <nl> mmm a / src / hotspot / cpu / s390 / templatetable_s390 . cpp <nl> ppp b / src / hotspot / cpu / s390 / templatetable_s390 . cpp <nl>
void jfrstringpoolbuffer : : set_string_pos ( uint64_t value ) { <nl> } <nl>  <nl> void jfrstringpoolbuffer : : increment ( uint64_t value ) { <nl> + # if ! ( defined ( arm ) | | defined ( ia32 ) ) <nl> atomic : : add ( value , & _string_count_pos ) ; <nl> + # else <nl> + <nl> + uint64_t cur , val ; <nl> + do { <nl> + cur = atomic : : load ( & _string_count_top ) ; <nl> + val = cur + value ; <nl> + } while ( atomic : : cmpxchg ( val , & _string_count_pos , cur ) ! = cur ) ; <nl> + # endif <nl> } <nl>  <nl> void jfrstringpoolbuffer : : set_string_top ( uint64_t value ) { <nl> mmm a / src / hotspot / share / jfr / utilities / jfrallocation . cpp <nl> ppp b / src / hotspot / share / jfr / utilities / jfrallocation . cpp <nl>
bool macroassembler : : uses_implicit_null_check ( void * address ) { <nl> } <nl>  <nl> bool macroassembler : : needs_explicit_null_check ( intptr_t offset ) { <nl> + / / the offset - 1 is used ( hardcoded ) in a number of places in c1 and macroassembler <nl> + / / to indicate an unknown offset . for example , templatetable : : pop_and_check_object ( register r ) <nl> + / / calls macroassembler : : null_check ( register reg , int offset = - 1 ) which gets here <nl> + / / with - 1 . another example is graphbuilder : : access_field ( . . . ) which uses - 1 as placeholder <nl> + / / for offsets to be patched in later . the - 1 there means the offset is not yet known <nl> + / / and may lie outside of the zero - trapping page , and thus we need to ensure we ' re forcing <nl> + / / an explicit null check for - 1 , even if it may otherwise be in the range <nl> + / / [ - cell_header_size , os : : vm_page_size ) . <nl> + <nl> + if ( offset = = - 1 ) return true ; <nl> + <nl> / / check if offset is outside of [ - cell_header_size , os : : vm_page_size ) <nl> return offset < - universe : : heap ( ) - > cell_header_size ( ) | | <nl> offset > = os : : vm_page_size ( ) ;
public abstract class editortestbase extends repltooltesting { <nl> ) ; <nl> } <nl>  <nl> - @ test <nl> + @ test ( enabled = false ) <nl> public void teststatementmush ( ) { <nl> testeditor ( <nl> a - > assertcommand ( a , " system . out . println ( \ " hello \ " ) " , <nl> mmm a / test / langtools / jdk / jshell / externaleditortest . java <nl> ppp b / test / langtools / jdk / jshell / externaleditortest . java <nl>
default_javadoc_tags : = \ <nl> default_javadoc_options : = - xdignore . symbol . file = true - use - keywords - notimestamp \ <nl> - serialwarn - encoding iso - 8859 - 1 - breakiterator - - system none <nl>  <nl> + # <nl> + # <nl> + # <nl> + ifndef enable_module_graph <nl> + enable_module_graph = false <nl> + endif <nl> + <nl> # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # <nl> # setup make rules for running javadoc . <nl> # <nl>
public interface moduleelement extends element , qualifiednameable { <nl> @ override <nl> list < ? extends element > getenclosedelements ( ) ; <nl>  <nl> + / * * <nl> + * returns { @ code true } if this is an open module and { @ code <nl> + * false } otherwise . <nl> + * <nl> + * @ return { @ code true } if this is an open module and { @ code <nl> + * false } otherwise <nl> + * / <nl> + boolean isopen ( ) ; <nl> + <nl> / * * <nl> * returns { @ code true } if this is an unnamed module and { @ code <nl> * false } otherwise . <nl> mmm a / langtools / src / jdk . compiler / share / classes / com / sun / tools / javac / code / symbol . java <nl> ppp b / langtools / src / jdk . compiler / share / classes / com / sun / tools / javac / code / symbol . java <nl>
public class completionsuggestiontest extends kullatesting { <nl> keepparameternames . set ( getanalysis ( ) , new string [ 0 ] ) ; <nl> } <nl>  <nl> + @ test ( enabled = false ) <nl> public void testbrokenclassfile2 ( ) throws ioexception { <nl> path broken = outdir . resolve ( " broken " ) ; <nl> compiler . compile ( broken ,
instruct andi_reg_reg ( iregidst dst , iregisrc src1 , iregisrc src2 ) % { <nl> ins_pipe ( pipe_class_default ) ; <nl> % } <nl>  <nl> + / / left shifted immediate and <nl> + instruct andi_reg_immihi16 ( iregidst dst , iregisrc src1 , immihi16 src2 , flagsregcr0 cr0 ) % { <nl> + match ( set dst ( andi src1 src2 ) ) ; <nl> + effect ( kill cr0 ) ; <nl> + format % { " andis $ dst , $ src1 , $ src2 . hi " % } <nl> + size ( 4 ) ; <nl> + ins_encode % { <nl> + <nl> + __ andis_ ( $ dst $ $ register , $ src1 $ $ register , ( int ) ( ( unsigned short ) ( ( $ src2 $ $ constant & num xffff0000 ) > > num ) ) ) ; <nl> + % } <nl> + ins_pipe ( pipe_class_default ) ; <nl> + % } <nl> + <nl> / / immediate and <nl> instruct andi_reg_uimm16 ( iregidst dst , iregisrc src1 , uimmi16 src2 , flagsregcr0 cr0 ) % { <nl> match ( set dst ( andi src1 src2 ) ) ;
instruct cmpp_reg_reg ( flagsreg crx , iregp_n2p src1 , iregp_n2p src2 ) % { <nl> ins_pipe ( pipe_class_compare ) ; <nl> % } <nl>  <nl> + instruct cmpp_reg_null ( flagsreg crx , iregp_n2p src1 , immp_0or1 src2 ) % { <nl> + match ( set crx ( cmpp src1 src2 ) ) ; <nl> + format % { " cmpldi $ crx , $ src1 , $ src2 \ t / / ptr " % } <nl> + size ( 4 ) ; <nl> + ins_encode % { <nl> + <nl> + __ cmpldi ( $ crx $ $ condregister , $ src1 $ $ register , ( int ) ( ( short ) ( $ src2 $ $ constant & num xffff ) ) ) ; <nl> + % } <nl> + ins_pipe ( pipe_class_compare ) ; <nl> + % } <nl> + <nl> / / used in postalloc expand . <nl> instruct cmpp_reg_imm16 ( flagsreg crx , iregpsrc src1 , imml16 src2 ) % { <nl> / / this match rule prevents reordering of node before a safepoint .
public abstract class editortestbase extends repltooltesting { <nl> ) ; <nl> } <nl>  <nl> - @ test <nl> + @ test ( enabled = false ) <nl> public void testeditclass1 ( ) { <nl> testeditor ( <nl> a - > assertclass ( a , " class a { } " , " class " , " a " ) , <nl>
public abstract class editortestbase extends repltooltesting { <nl> ) ; <nl> } <nl>  <nl> - @ test <nl> + @ test ( enabled = false ) <nl> public void testeditmethod1 ( ) { <nl> testeditor ( <nl> a - > assertmethod ( a , " void f ( ) { } " , " ( ) void " , " f " ) , <nl> mmm a / langtools / test / jdk / jshell / externaleditortest . java <nl> ppp b / langtools / test / jdk / jshell / externaleditortest . java <nl>
public class externaleditortest extends editortestbase { <nl> ) ; <nl> } <nl>  <nl> - @ test <nl> + @ test ( enabled = false ) <nl> public void testremovetempfile ( ) { <nl> test ( new string [ ] { " - nostartup " } , <nl> a - > assertcommandcheckoutput ( a , " / set editor " + executionscript ,
<nl> + / * <nl> + * copyright ( c ) num , oracle and / or its affiliates . all rights reserved . <nl> + * do not alter or remove copyright notices or this file header . <nl> + * <nl> + * this code is free software ; you can redistribute it and / or modify it <nl> + * under the terms of the gnu general public license version num only , as <nl> + * published by the free software foundation . <nl> + * <nl> + * this code is distributed in the hope that it will be useful , but without <nl> + * any warranty ; without even the implied warranty of merchantability or <nl> + * fitness for a particular purpose . see the gnu general public license <nl> + * version num for more details ( a copy is included in the license file that <nl> + * accompanied this code ) . <nl> + * <nl> + * you should have received a copy of the gnu general public license version <nl> + * num along with this work ; if not , write to the free software foundation , <nl> + * inc . , num franklin st , fifth floor , boston , ma num - 1301 usa . <nl> + * <nl> + * please contact oracle , num oracle parkway , redwood shores , ca num usa <nl> + * or visit www . oracle . com if you need additional information or have any <nl> + * questions . <nl> + * / <nl> + <nl> + / * <nl> + * @ test <nl> + * @ bug num <nl> + * @ author a . stepanov <nl> + * @ summary [ hidpi ] [ macosx ] check that for a pair of images <nl> + * ( image . ext , image @ 2x . ext ) the num st one is loaded <nl> + * in case if the num nd is corrupted <nl> + * <nl> + * @ requires ( os . family = = " mac " ) <nl> + * <nl> + * @ library . . / . . / . . / . . / lib / testlibrary / <nl> + * @ build extendedrobot <nl> + * @ run main corrupted2ximagetest <nl> + * / <nl> + <nl> + import java . awt . * ; <nl> + import java . awt . geom . affinetransform ; <nl> + import java . awt . image . * ; <nl> + import java . io . * ; <nl> + <nl> + import javax . imageio . imageio ; <nl> + <nl> + public class corrupted2ximagetest extends frame { <nl> + <nl> + private static final int sz = num ; <nl> + private static final color c = color . blue ; <nl> + <nl> + private final string format , name1x , name2x ; <nl> + <nl> + public corrupted2ximagetest ( string format ) throws ioexception { <nl> + <nl> + this . format = format ; <nl> + name1x = " test . " + format ; <nl> + name2x = " test @ 2x . " + format ; <nl> + createfiles ( ) ; <nl> + } <nl> + <nl> + private void ui ( ) { <nl> + <nl> + settitle ( format ) ; <nl> + setsize ( sz , sz ) ; <nl> + setresizable ( false ) ; <nl> + setlocation ( 50 , num ) ; <nl> + setvisible ( true ) ; <nl> + } <nl> + <nl> + @ override <nl> + public void paint ( graphics g ) { <nl> + <nl> + image img = toolkit . getdefaulttoolkit ( ) . getimage ( <nl> + new file ( name1x ) . getabsolutepath ( ) ) ; <nl> + g . drawimage ( img , num , num , this ) ; <nl> + } <nl> + <nl> + private void createfiles ( ) throws ioexception { <nl> + <nl> + bufferedimage img = <nl> + new bufferedimage ( sz , sz , bufferedimage . type_int_rgb ) ; <nl> + graphics g = img . getgraphics ( ) ; <nl> + g . setcolor ( c ) ; <nl> + g . fillrect ( 0 , num , sz , sz ) ; <nl> + imageio . write ( img , format , new file ( name1x ) ) ; <nl> + <nl> + / / corrupted @ 2x " image " - just a text file <nl> + writer writer = new bufferedwriter ( new outputstreamwriter ( <nl> + new fileoutputstream ( new file ( name2x ) ) , " utf - 8 " ) ) ; <nl> + writer . write ( " corrupted \ " image \ " " ) ; <nl> + writer . close ( ) ; <nl> + } <nl> + <nl> + / / need this for jpg <nl> + private static boolean cmpcolors ( color c1 , color c2 ) { <nl> + <nl> + int tol = num ; <nl> + return ( <nl> + math . abs ( c2 . getred ( ) - c1 . getred ( ) ) < tol & & <nl> + math . abs ( c2 . getgreen ( ) - c1 . getgreen ( ) ) < tol & & <nl> + math . abs ( c2 . getblue ( ) - c1 . getblue ( ) ) < tol ) ; <nl> + } <nl> + <nl> + private void dotest ( ) throws exception { <nl> + <nl> + extendedrobot r = new extendedrobot ( ) ; <nl> + system . out . println ( " format : " + format ) ; <nl> + r . waitforidle ( 1000 ) ; <nl> + eventqueue . invokeandwait ( this : : ui ) ; <nl> + r . waitforidle ( 1000 ) ; <nl> + point loc = getlocationonscreen ( ) ; <nl> + color c = r . getpixelcolor ( loc . x + sz / num , loc . y + sz / num ) ; <nl> + if ( ! cmpcolors ( c , c ) ) { <nl> + throw new runtimeexception ( " test failed , color = " + c ) ; } <nl> + system . out . println ( " ok " ) ; <nl> + dispose ( ) ; <nl> + } <nl> + <nl> + private static boolean is2x ( ) { <nl> + <nl> + affinetransform tr = graphicsenvironment . getlocalgraphicsenvironment ( ) . <nl> + getdefaultscreendevice ( ) . getdefaultconfiguration ( ) . <nl> + getdefaulttransform ( ) ; <nl> + return math . min ( tr . getscalex ( ) , tr . getscaley ( ) ) > num . 001 ; <nl> + } <nl> + <nl> + public static void main ( string [ ] args ) throws exception { <nl> + <nl> + <nl> + if ( is2x ( ) ) { <nl> + / / formats supported by toolkit . getimage ( ) <nl> + for ( string format : new string [ ] { " gif " , " jpg " , " png " } ) { <nl> + ( new corrupted2ximagetest ( format ) ) . dotest ( ) ; <nl> + } <nl> + } else { <nl> + system . out . println ( " this test is for hidpi only " ) ; <nl> + } <nl> + } <nl> + }
public class methodgenerator { <nl> elements . add ( input - > " _ " + input ) ; <nl> elements . add ( input - > " $ " + input ) ; <nl> elements . add ( input - > " 0 " + input ) ; <nl> + <nl> + / * <nl> / / unicode characters <nl> elements . add ( input - > embed ( input , " \ u0001 " ) ) ; <nl> elements . add ( input - > embed ( input , " \ u007f " ) ) ; <nl>
valuetype * as_valuetype ( ciconstant value ) { <nl> case t_float : return new floatconstant ( value . as_float ( ) ) ; <nl> case t_double : return new doubleconstant ( value . as_double ( ) ) ; <nl> case t_array : / / fall through ( ciconstant doesn ' t have an array accessor ) <nl> - case t_object : return new objectconstant ( value . as_object ( ) ) ; <nl> + case t_object : { <nl> + <nl> + ciobject * obj = value . as_object ( ) ; <nl> + if ( obj - > is_null_object ( ) ) <nl> + return objectnull ; <nl> + if ( obj - > is_loaded ( ) ) { <nl> + if ( obj - > is_array ( ) ) <nl> + return new arrayconstant ( obj - > as_array ( ) ) ; <nl> + else if ( obj - > is_instance ( ) ) <nl> + return new instanceconstant ( obj - > as_instance ( ) ) ; <nl> + } <nl> + return new objectconstant ( obj ) ; <nl> + } <nl> } <nl> shouldnotreachhere ( ) ; <nl> return illegaltype ;
function load_fx_classes ( clslist ) { <nl>  <nl> var suffix_length = " . class " . length ; <nl>  <nl> + <nl> + var jfxrtjar ; <nl> try { <nl> - var jfxrtjar = new zipfile ( system . getproperty ( " java . home " ) + " / lib / ext / jfxrt . jar " ) ; <nl> - } catch ( ex ) { <nl> - throw new error ( " javafx runtime not found " ) ; <nl> + jfxrtjar = new zipfile ( system . getproperty ( " java . home " ) + " / lib / jfxrt . jar " ) ; <nl> + } catch ( ex1 ) { <nl> + try { <nl> + jfxrtjar = new zipfile ( system . getproperty ( " java . home " ) + " / lib / ext / jfxrt . jar " ) ; <nl> + } catch ( ex2 ) { <nl> + throw new error ( " javafx runtime not found " ) ; <nl> + } <nl> } <nl> + / / < / patch > <nl>  <nl> var entries = jfxrtjar . entries ( ) ;
public class javavm { <nl> start ( ) ; <nl> return waitfor ( ) ; <nl> } <nl> + <nl> + / * * <nl> + * computes a deadline from a timestamp and a timeout value . <nl> + * maximum timeout ( before multipliers are applied ) is one hour . <nl> + * / <nl> + public static long computedeadline ( long timestamp , long timeout ) { <nl> + final long max_timeout_ms = num _600_000l ; <nl> + <nl> + if ( timeout < num l | | timeout > max_timeout_ms ) { <nl> + throw new illegalargumentexception ( " timeout " + timeout + " ms out of range " ) ; <nl> + } <nl> + <nl> + <nl> + <nl> + return timestamp + timeout ; <nl> + } <nl> } <nl> mmm a / jdk / test / java / rmi / testlibrary / rmid . java <nl> ppp b / jdk / test / java / rmi / testlibrary / rmid . java <nl>
public final class context { <nl>  <nl> storedscript storedscript = null ; <nl> functionnode functionnode = null ; <nl> + / / we only use the code store here if optimistic types are disabled . with optimistic types , <nl> + / / code is stored per function in recompilablescriptfunctiondata . <nl> + <nl> final boolean usecodestore = env . _persistent_cache & & ! env . _parse_only & & ! env . _optimistic_types ; <nl> final string cachekey = usecodestore ? codestore . getcachekey ( 0 , null ) : null ; <nl>  <nl>
if test $ ? = num ; then <nl> out = powerpc $ kernel_bitmode ` echo $ out | sed - e ' s / [ ^ - ] * / / ' ` <nl> fi <nl>  <nl> + # test and fix little endian powerpc64 . <nl> + # <nl> + if [ " x $ out " = x ] ; then <nl> + if [ ` uname - m ` = ppc64le ] ; then <nl> + if [ ` uname - s ` = linux ] ; then <nl> + out = powerpc64le - unknown - linux - gnu <nl> + fi <nl> + fi <nl> + fi <nl> + <nl> echo $ out <nl> mmm a / common / autoconf / generated - configure . sh <nl> ppp b / common / autoconf / generated - configure . sh <nl>
static void clear_pending_exception_if_not_oom ( traps ) { <nl> / / the check at the caller will propagate the exception out <nl> } <nl>  <nl> + / * * <nl> + * returns if the given method should be compiled when doing compile - the - world . <nl> + * <nl> + * <nl> + * / <nl> + static bool can_be_compiled ( methodhandle m , int comp_level ) { <nl> + assert ( compiletheworld , " must be " ) ; <nl> + <nl> + / / it ' s not valid to compile a native wrapper for methodhandle methods <nl> + / / that take a membername appendix since the bytecode signature is not <nl> + / / correct . <nl> + vmintrinsics : : id iid = m - > intrinsic_id ( ) ; <nl> + if ( methodhandles : : is_signature_polymorphic ( iid ) & & methodhandles : : has_member_arg ( iid ) ) { <nl> + return false ; <nl> + } <nl> + <nl> + return compilationpolicy : : can_be_compiled ( m , comp_level ) ; <nl> + } <nl> + <nl> void classloader : : compile_the_world_in ( char * name , handle loader , traps ) { <nl> int len = ( int ) strlen ( name ) ; <nl> if ( len > num & & strcmp ( " . class " , name + len - num ) = = num ) { <nl>
public abstract class lwcomponentpeer < t extends component , d extends jcomponent > <nl> } <nl> } <nl>  <nl> - protected awtevent createdelegateevent ( awtevent e ) { <nl> + / * * <nl> + * changes the target of the awtevent from awt component to appropriate <nl> + * swing delegate . <nl> + * / <nl> + private awtevent createdelegateevent ( final awtevent e ) { <nl> + <nl> awtevent delegateevent = null ; <nl> if ( e instanceof mousewheelevent ) { <nl> mousewheelevent me = ( mousewheelevent ) e ; <nl> mmm a / jdk / src / share / classes / javax / swing / swingutilities . java <nl> ppp b / jdk / src / share / classes / javax / swing / swingutilities . java <nl>
public final class codegenerator extends nodeoperatorvisitor { <nl> final list < string > keys = new arraylist < > ( ) ; <nl> final list < symbol > symbols = new arraylist < > ( ) ; <nl>  <nl> + / * <nl> for ( final entry < string , node > entry : thisproperties . entryset ( ) ) { <nl> keys . add ( entry . getkey ( ) ) ; <nl> symbols . add ( entry . getvalue ( ) . getsymbol ( ) ) ; <nl> } <nl> + * / <nl>  <nl> new functionobjectcreator ( this , functionnode , keys , symbols ) . makeobject ( method ) ; <nl> } <nl> mmm a / nashorn / src / jdk / nashorn / internal / codegen / objects / functionobjectcreator . java <nl> ppp b / nashorn / src / jdk / nashorn / internal / codegen / objects / functionobjectcreator . java <nl>
<nl>  <nl> builddir = . . / . . / . . <nl> subdirs_makeflags + = javac_max_warnings = false <nl> - subdirs_makeflags + = javac_lint_options = - xlint : all , - deprecation <nl> + # <nl> + subdirs_makeflags + = javac_lint_options = - xlint : all , - deprecation , - path <nl> subdirs_makeflags + = javac_warnings_fatal = true <nl> include $ ( builddir ) / common / defs . gmk
public class cancelledproducerconsumerloops { <nl> onerun ( new arrayblockingqueue < integer > ( capacity ) , pairs , iters ) ; <nl> onerun ( new linkedblockingqueue < integer > ( capacity ) , pairs , iters ) ; <nl> onerun ( new linkedblockingdeque < integer > ( capacity ) , pairs , iters ) ; <nl> - onerun ( new linkedtransferqueue < integer > ( ) , pairs , iters ) ; <nl> - onerun ( new ltqassq < integer > ( ) , pairs , iters ) ; <nl> - onerun ( new halfsyncltq < integer > ( ) , pairs , iters ) ; <nl> onerun ( new synchronousqueue < integer > ( ) , pairs , iters / num ) ; <nl>  <nl> - / * priorityblockingqueue is unbounded <nl> + / * <nl> onerun ( new priorityblockingqueue < integer > ( iters / num * pairs ) , pairs , iters / num ) ; <nl> + onerun ( new linkedtransferqueue < integer > ( ) , pairs , iters ) ; <nl> + onerun ( new ltqassq < integer > ( ) , pairs , iters ) ; <nl> + onerun ( new halfsyncltq < integer > ( ) , pairs , iters ) ; <nl> * / <nl> }
import java . util . * ; <nl> * deletion without notice . < / b > <nl> * / <nl> @ supportedannotationtypes ( " * " ) <nl> - @ supportedsourceversion ( sourceversion . release_6 ) <nl> + <nl> + @ supportedsourceversion ( sourceversion . release_7 ) <nl> public class printingprocessor extends abstractprocessor { <nl> printwriter writer ; <nl>  <nl>
public class dispatcherhandlersmappingdescriptionprovider implements mappingdesc <nl> public void resources ( function < serverrequest , mono < resource > > lookupfunction ) { <nl> } <nl>  <nl> + @ override <nl> + public void attributes ( map < string , object > attributes ) { <nl> + <nl> + throw new unsupportedoperationexception ( " auto - generated method stub " ) ; <nl> + } <nl> + <nl> @ override <nl> public void unknown ( routerfunction < ? > routerfunction ) { <nl> }
<nl> < artifactid > spring - boot - starter - data - redis < / artifactid > <nl> < version > 1 . 4 . 0 . build - snapshot < / version > <nl> < / dependency > <nl> + < dependency > <nl> + < ! - - <nl> + < groupid > org . springframework . boot < / groupid > <nl> + < artifactid > spring - boot - starter - redis < / artifactid > <nl> + < version > 1 . 4 . 0 . build - snapshot < / version > <nl> + < / dependency > <nl> < dependency > <nl> < groupid > org . springframework . boot < / groupid > <nl> < artifactid > spring - boot - starter - data - neo4j < / artifactid >
public class flywayautoconfiguration { <nl> else { <nl> flyway . setdatasource ( this . datasource ) ; <nl> } <nl> - / / explicitly set locations because the getter doesn ' t return a mutable value <nl> + <nl> flyway . setlocations ( this . properties . getlocations ( ) . toarray ( new string [ 0 ] ) ) ; <nl> + <nl> return flyway ; <nl> } <nl>  <nl> mmm a / spring - boot - autoconfigure / src / test / java / org / springframework / boot / autoconfigure / flyway / flywayautoconfigurationtests . java <nl> ppp b / spring - boot - autoconfigure / src / test / java / org / springframework / boot / autoconfigure / flyway / flywayautoconfigurationtests . java <nl>
public class testcommand extends optionparsingcommand { <nl> this . runner = new testrunner ( configuration , sourceoptions . getsourcesarray ( ) , <nl> sourceoptions . getargsarray ( ) ) ; <nl> this . runner . compileandruntests ( ) ; <nl> + if ( ! options . has ( " nohup " ) ) { <nl> + system . exit ( 0 ) ; <nl> + } <nl> } <nl>  <nl> / * * <nl> mmm a / spring - boot - cli / src / test / java / org / springframework / boot / cli / clitester . java <nl> ppp b / spring - boot - cli / src / test / java / org / springframework / boot / cli / clitester . java <nl>
<nl>  <nl> package org . springframework . boot . actuate . autoconfigure ; <nl>  <nl> + import org . springframework . boot . actuate . endpoint . endpoint ; <nl> import org . springframework . boot . actuate . endpoint . jmx . endpointmbeanexporter ; <nl> import org . springframework . boot . autoconfigure . autoconfigureafter ; <nl> + import org . springframework . boot . autoconfigure . enableautoconfiguration ; <nl> import org . springframework . boot . autoconfigure . condition . conditionalonbean ; <nl> + import org . springframework . boot . autoconfigure . condition . conditionalonexpression ; <nl> import org . springframework . context . annotation . bean ; <nl> import org . springframework . context . annotation . configuration ; <nl> import org . springframework . jmx . export . mbeanexporter ; <nl>  <nl> + / * * <nl> + * { @ link enableautoconfiguration auto - configuration } to enable jmx export for <nl> + * { @ link endpoint } s . <nl> + * <nl> + * @ author christian dupuis <nl> + * / <nl> @ configuration <nl> @ conditionalonbean ( { mbeanexporter . class } ) <nl> @ autoconfigureafter ( { endpointautoconfiguration . class } ) <nl> + @ conditionalonexpression ( " $ { endpoints . jmx . enabled : true } " ) <nl> class endpointmbeanexportautoconfiguration { <nl>  <nl> @ bean <nl> public endpointmbeanexporter endpointmbeanexporter ( ) { <nl> + <nl> return new endpointmbeanexporter ( ) ; <nl> }
public class aethergrapeengine implements grapeengine { <nl> this . progressreporter = getprogressreporter ( session ) ; <nl> } <nl>  <nl> + public static proxy defaultproxy ( string protocol ) { <nl> + <nl> + if ( " http " . equals ( protocol ) | | " dav " . equals ( protocol ) ) { <nl> + string proxyhost = system . getproperty ( " http . proxyhost " ) ; <nl> + if ( proxyhost ! = null ) { <nl> + / / use defaults from normal jvm proxy handler <nl> + return new proxy ( " http " , proxyhost , new integer ( system . getproperty ( <nl> + " http . proxyport " , " 80 " ) ) ) ; <nl> + } <nl> + } <nl> + else if ( " https " . equals ( protocol ) | | " davs " . equals ( protocol ) ) { <nl> + string secureproxyhost = system . getproperty ( " https . proxyhost " ) ; <nl> + if ( secureproxyhost ! = null ) { <nl> + return new proxy ( " https " , secureproxyhost , new integer ( <nl> + system . getproperty ( " https . proxyport " , " 443 " ) ) ) ; <nl> + } <nl> + } <nl> + else if ( " ftp " . equals ( protocol ) ) { <nl> + string secureproxyhost = system . getproperty ( " ftp . proxyhost " ) ; <nl> + if ( secureproxyhost ! = null ) { <nl> + return new proxy ( " ftp " , secureproxyhost , new integer ( system . getproperty ( <nl> + " ftp . proxyport " , " 443 " ) ) ) ; <nl> + } <nl> + } <nl> + return null ; <nl> + } <nl> + <nl> private servicelocator createservicelocator ( ) { <nl> defaultservicelocator locator = mavenrepositorysystemutils . newservicelocator ( ) ; <nl> locator . addservice ( repositorysystem . class , defaultrepositorysystem . class ) ; <nl>
<nl> < / plugins > <nl> < / pluginmanagement > <nl> < / build > <nl> + < repositories > <nl> + < ! - - <nl> + < repository > <nl> + < id > spring - milestones < / id > <nl> + < name > spring milestones < / name > <nl> + < url > http : / / repo . springsource . org / milestone < / url > <nl> + < snapshots > <nl> + < enabled > false < / enabled > <nl> + < / snapshots > <nl> + < / repository > <nl> + < / repositories > <nl> < / project >
import org . springframework . security . web . util . matcher . anyrequestmatcher ; <nl> * / <nl> @ configuration <nl> @ conditionalonclass ( { enablewebsecurity . class } ) <nl> - @ conditionalonmissingbean ( annotation = enablewebsecurity . class ) <nl> + <nl> + @ conditionalonmissingbean ( securityautoconfiguration . class ) <nl> @ enableconfigurationproperties <nl> public class securityautoconfiguration { <nl>  <nl> mmm a / spring - boot - samples / spring - boot - sample - data - jpa / src / main / java / org / springframework / boot / sample / data / jpa / sampledatajpaapplication . java <nl> ppp b / spring - boot - samples / spring - boot - sample - data - jpa / src / main / java / org / springframework / boot / sample / data / jpa / sampledatajpaapplication . java <nl>
startup process , add a comma - delimited list of class names to the <nl> ` environment ` property ` context . initializer . classes ` ( can be specified <nl> via ` application . properties ` ) . <nl>  <nl> - # # security - user details <nl> + # # info endpoint <nl> + <nl> + by default the actuator adds an ` / info ` endpoint to the main server . <nl> + it contains the commit and timestamp information from ` git . properties ` <nl> + ( if that file exists ) and also any properties it finds in the <nl> + environment with prefix " info " . to populate ` git . properties ` in a <nl> + maven build you can use the excellent <nl> + [ git - commit - id - plugin ] ( https : / / github . com / ktoso / maven - git - commit - id - plugin ) . <nl> + to populate the " info " map all you need to do is add some stuff to <nl> + ` application . properties ` , e . g . <nl> + <nl> + info . app . name : myservice <nl> + info . app . description : my awesome service <nl> + info . app . version : num . 0 . 0 <nl> + <nl> + # # security - basic authentication <nl> + <nl> + to secure your endpoints just add spring security javaconfig to the <nl> + classpath . by default http basic authentication will be applied to <nl> + every request in the main server ( and the management server if it is <nl> + running on the same port ) . there is a single account by default , and <nl> + you can test it like this : <nl> + <nl> + $ mvn user : password @ localhost : 8080 / info <nl> + . . . stuff comes out <nl>  <nl> # # security - https <nl>  <nl> - # # xml content <nl> + ensuring that all your main endpoints are only available over https is <nl> + an important chore for any application . if you are using tomcat as a <nl> + servlet container , then the actuator will add tomcat ' s own <nl> + ` remoteipvalve ` automatically if it detects some environment settings , <nl> + and you should be able to rely on the ` httpservletrequest ` to report <nl> + whether or not it is secure ( even downstream of the real ssl <nl> + termination endpoint ) . the standard behaviour is determined by the <nl> + presence or absence of certain request headers ( " x - forwarded - for " and <nl> + " x - forwarded - proto " ) , whose names are conventional , so it should work <nl> + with most front end proxies . you switch on the valve by adding some <nl> + entries to ` application . properties ` , e . g . <nl> + <nl> + server . tomcat . remote_ip_header : x - forwarded - for <nl> + server . tomcat . protocol_header : x - forwarded - proto <nl> + <nl> + ( or you can add the ` remoteipvalve ` yourself by adding a <nl> + ` tomcatembeddedservletcontainerfactory ` bean . ) <nl> + <nl> + <nl>  <nl> # # audit events <nl>  <nl> + the actuator has a flexible audit framework that will publish events <nl> + once spring security is in play ( authentication success and failure <nl> + and access denied exceptions by default ) . this can be very useful for <nl> + reporting , and also to implement a lock - out policy based on <nl> + authentication failures . <nl> + <nl> + you can also choose to use the audit services for your own business <nl> + events . to do that you can either inject the existing <nl> + ` auditeventrepository ` into your own components and use that directly , <nl> + or you can simply publish ` auditapplicationevent ` via the spring <nl> + ` applicationcontext ` ( using ` applicationeventpublisheraware ` ) . <nl> + <nl> # # metrics customization <nl>  <nl> metrics come out on the ` / varz ` endpoint . you can add additional
