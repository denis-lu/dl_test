{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "285e112b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de5c7499",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_data(file_path):\n",
    "    data = pd.read_json(file_path, orient='records', lines=True)\n",
    "    data = data.iloc[0:765,:4]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd5c0b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tmp_label_process(labeled_data):\n",
    "    high_low_labels = labeled_data['quality'].apply(lambda x:1 if x == 1 else 0)\n",
    "    return high_low_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ee7a106",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modelId</th>\n",
       "      <th>modelcard_text</th>\n",
       "      <th>modelcard_titles_combined</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DrishtiSharma/wav2vec2-large-xls-r-300m-ab-v4</td>\n",
       "      <td>\\n&lt;!-- This model card has been generated auto...</td>\n",
       "      <td>Model description Intended uses &amp; limitations...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Helsinki-NLP/opus-mt-es-nl</td>\n",
       "      <td>\\n### opus-mt-es-nl\\n\\n* source languages: es\\...</td>\n",
       "      <td>opus-mt-es-nl Benchmarks</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Helsinki-NLP/opus-mt-sv-tiv</td>\n",
       "      <td>\\n### opus-mt-sv-tiv\\n\\n* source languages: sv...</td>\n",
       "      <td>opus-mt-sv-tiv Benchmarks</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MultiBertGunjanPatrick/multiberts-seed-15</td>\n",
       "      <td># MultiBERTs Seed 15 (uncased)\\n\\nSeed 15 Mult...</td>\n",
       "      <td>MultiBERTs Seed 15 (uncased) Model description...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SauravMaheshkar/clr-finetuned-bert-large-uncased</td>\n",
       "      <td>![](https://github.com/SauravMaheshkar/CommonL...</td>\n",
       "      <td>FineTuning</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>Niggendar/waiANINSFWPONYXL_v20</td>\n",
       "      <td>\\n# Model Card for Model ID\\n\\n&lt;!-- Provide a ...</td>\n",
       "      <td>Model Card for Model ID Model Details Model De...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>jayasuryajsk/Llama-3-8b-Telugu-Romanized</td>\n",
       "      <td># Llama-3-8b-Telugu_Romanized\\n\\nLlama-3 8B fi...</td>\n",
       "      <td>Llama-3-8b-Telugu_Romanized Model Details Mode...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>mradermacher/Chaotic-Soliloquy-4x8B-GGUF</td>\n",
       "      <td>## About\\n\\n&lt;!-- ### quantize_version: 1 --&gt;\\n...</td>\n",
       "      <td>About Usage Provided Quants FAQ / Model Reques...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>gradientai/Llama-3-8B-Instruct-262k</td>\n",
       "      <td>&lt;img src=\"https://cdn-uploads.huggingface.co/p...</td>\n",
       "      <td>Llama-3 8B Instruct 262k The Gradient AI Team ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>blockblockblock/miqu-evil-dpo-bpw3.7-exl2</td>\n",
       "      <td>\\n# miqu-evil-dpo\\n\\n# **Model Details**\\n\\n##...</td>\n",
       "      <td>miqu-evil-dpo Model Details Description Prompt...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>765 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              modelId  \\\n",
       "0       DrishtiSharma/wav2vec2-large-xls-r-300m-ab-v4   \n",
       "1                          Helsinki-NLP/opus-mt-es-nl   \n",
       "2                         Helsinki-NLP/opus-mt-sv-tiv   \n",
       "3           MultiBertGunjanPatrick/multiberts-seed-15   \n",
       "4    SauravMaheshkar/clr-finetuned-bert-large-uncased   \n",
       "..                                                ...   \n",
       "760                    Niggendar/waiANINSFWPONYXL_v20   \n",
       "761          jayasuryajsk/Llama-3-8b-Telugu-Romanized   \n",
       "762          mradermacher/Chaotic-Soliloquy-4x8B-GGUF   \n",
       "763               gradientai/Llama-3-8B-Instruct-262k   \n",
       "764         blockblockblock/miqu-evil-dpo-bpw3.7-exl2   \n",
       "\n",
       "                                        modelcard_text  \\\n",
       "0    \\n<!-- This model card has been generated auto...   \n",
       "1    \\n### opus-mt-es-nl\\n\\n* source languages: es\\...   \n",
       "2    \\n### opus-mt-sv-tiv\\n\\n* source languages: sv...   \n",
       "3    # MultiBERTs Seed 15 (uncased)\\n\\nSeed 15 Mult...   \n",
       "4    ![](https://github.com/SauravMaheshkar/CommonL...   \n",
       "..                                                 ...   \n",
       "760  \\n# Model Card for Model ID\\n\\n<!-- Provide a ...   \n",
       "761  # Llama-3-8b-Telugu_Romanized\\n\\nLlama-3 8B fi...   \n",
       "762  ## About\\n\\n<!-- ### quantize_version: 1 -->\\n...   \n",
       "763  <img src=\"https://cdn-uploads.huggingface.co/p...   \n",
       "764  \\n# miqu-evil-dpo\\n\\n# **Model Details**\\n\\n##...   \n",
       "\n",
       "                             modelcard_titles_combined  quality  \n",
       "0     Model description Intended uses & limitations...        0  \n",
       "1                             opus-mt-es-nl Benchmarks        0  \n",
       "2                            opus-mt-sv-tiv Benchmarks        0  \n",
       "3    MultiBERTs Seed 15 (uncased) Model description...        0  \n",
       "4                                           FineTuning        0  \n",
       "..                                                 ...      ...  \n",
       "760  Model Card for Model ID Model Details Model De...        0  \n",
       "761  Llama-3-8b-Telugu_Romanized Model Details Mode...        0  \n",
       "762  About Usage Provided Quants FAQ / Model Reques...        0  \n",
       "763  Llama-3 8B Instruct 262k The Gradient AI Team ...        1  \n",
       "764  miqu-evil-dpo Model Details Description Prompt...        0  \n",
       "\n",
       "[765 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = 'D:\\Research\\RQ1\\modelcard_data (update).json'\n",
    "\n",
    "labeled_data = load_all_data(file_path)\n",
    "\n",
    "labeled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "532ac202",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Model description Intended uses & limitations Training and evaluation data Training procedure Training hyperparameters Training results Framework versions'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_data.iloc[0 , 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58ca3f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_bad_labels = tmp_label_process(labeled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba1f860b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_num = np.sum(good_bad_labels == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14e6a94d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive samples: 54\n"
     ]
    }
   ],
   "source": [
    "print(\"Positive samples:\", pos_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74161cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(file_path, model_type):\n",
    "    mylogger = logger.mylog(\"dl\")\n",
    "    labeled_data = load_all_data(file_path)\n",
    "    good_bad_labels = tmp_label_process(labeled_data)\n",
    "    pos_num = np.sum(good_bad_labels == 1)\n",
    "    print(\"Positive samples:\", pos_num)\n",
    "    glo._init()\n",
    "    fold_num = 0\n",
    "    kf = KFold(n_splits=10, random_state=3407, shuffle=True)\n",
    "    for train_index, test_index in kf.split(labeled_data):\n",
    "        train_x, train_y = list(labeled_data.iloc[train_index, 2]), list(good_bad_labels.iloc[train_index])\n",
    "        test_x, test_y = list(labeled_data.iloc[test_index, 2]), list(good_bad_labels.iloc[test_index])\n",
    "        # Use single input models (CNN, bi-lstm, transformer)\n",
    "        dl_container(train_x, train_y, test_x, test_y, mylogger, \"score\", fold_num, model_type)\n",
    "        fold_num += 1\n",
    "\n",
    "    ## calculate 10-fold metrics at last\n",
    "    mylogger.info(\"==================Todo comment good_bad classifers=============\")\n",
    "    cal_last_metrics(mylogger, model_type, \"score\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
